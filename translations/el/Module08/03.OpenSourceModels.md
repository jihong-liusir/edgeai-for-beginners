<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1b09b5c867abbccfdbc826d857ae0c2",
  "translation_date": "2025-09-24T22:28:13+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "el"
}
-->
# Συνεδρία 3: Ανακάλυψη και Διαχείριση Μοντέλων Ανοιχτού Κώδικα

## Επισκόπηση

Αυτή η συνεδρία επικεντρώνεται στην πρακτική ανακάλυψη και διαχείριση μοντέλων με το Foundry Local. Θα μάθετε πώς να καταγράφετε διαθέσιμα μοντέλα, να δοκιμάζετε διαφορετικές επιλογές και να κατανοείτε βασικά χαρακτηριστικά απόδοσης. Η προσέγγιση δίνει έμφαση στην πρακτική εξερεύνηση με το foundry CLI για να σας βοηθήσει να επιλέξετε τα κατάλληλα μοντέλα για τις ανάγκες σας.

## Στόχοι Μάθησης

- Εξοικείωση με τις εντολές του foundry CLI για ανακάλυψη και διαχείριση μοντέλων
- Κατανόηση της προσωρινής μνήμης μοντέλων και των μοτίβων τοπικής αποθήκευσης
- Μάθετε να δοκιμάζετε και να συγκρίνετε γρήγορα διαφορετικά μοντέλα
- Δημιουργία πρακτικών ροών εργασίας για επιλογή και αξιολόγηση μοντέλων
- Εξερεύνηση του αυξανόμενου οικοσυστήματος μοντέλων μέσω του Foundry Local

## Προαπαιτούμενα

- Ολοκληρωμένη Συνεδρία 1: Εισαγωγή στο Foundry Local
- Εγκατεστημένο και προσβάσιμο Foundry Local CLI
- Επαρκής χώρος αποθήκευσης για λήψη μοντέλων (τα μοντέλα μπορεί να κυμαίνονται από 1GB έως 20GB+)
- Βασική κατανόηση τύπων μοντέλων και περιπτώσεων χρήσης

## Μέρος 6: Πρακτική Άσκηση

### Άσκηση: Ανακάλυψη και Σύγκριση Μοντέλων

Δημιουργήστε το δικό σας σενάριο αξιολόγησης μοντέλων βασισμένο στο Δείγμα 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Η Αποστολή Σας

1. **Εκτελέστε το σενάριο Δείγμα 03**: `samples\03\list_and_bench.cmd`
2. **Δοκιμάστε διαφορετικά μοντέλα**: Δοκιμάστε τουλάχιστον 3 διαφορετικά μοντέλα
3. **Συγκρίνετε την απόδοση**: Σημειώστε τις διαφορές στην ταχύτητα και την ποιότητα απόκρισης
4. **Καταγράψτε τα ευρήματα**: Δημιουργήστε ένα απλό διάγραμμα σύγκρισης

### Παράδειγμα Μορφής Σύγκρισης

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## Μέρος 7: Αντιμετώπιση Προβλημάτων και Βέλτιστες Πρακτικές

### Συνηθισμένα Προβλήματα και Λύσεις

**Το Μοντέλο Δεν Ξεκινά:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Ανεπαρκής Μνήμη:**
- Ξεκινήστε με μικρότερα μοντέλα (`phi-4-mini`)
- Κλείστε άλλες εφαρμογές
- Αναβαθμίστε τη RAM αν συχνά φτάνετε σε όρια

**Αργή Απόδοση:**
- Βεβαιωθείτε ότι το μοντέλο έχει φορτωθεί πλήρως (ελέγξτε την αναλυτική έξοδο)
- Κλείστε περιττές εφαρμογές στο παρασκήνιο
- Εξετάστε ταχύτερη αποθήκευση (SSD)

### Βέλτιστες Πρακτικές

1. **Ξεκινήστε Μικρά**: Ξεκινήστε με το `phi-4-mini` για να επικυρώσετε τη ρύθμιση
2. **Ένα Μοντέλο τη Φορά**: Σταματήστε προηγούμενα μοντέλα πριν ξεκινήσετε νέα
3. **Παρακολουθήστε Πόρους**: Ελέγξτε τη χρήση μνήμης
4. **Δοκιμάστε Συνεπώς**: Χρησιμοποιήστε τα ίδια ερωτήματα για δίκαιες συγκρίσεις
5. **Καταγράψτε Αποτελέσματα**: Κρατήστε σημειώσεις για την απόδοση των μοντέλων στις περιπτώσεις χρήσης σας

## Μέρος 8: Επόμενα Βήματα και Αναφορές

### Προετοιμασία για τη Συνεδρία 4

- **Εστίαση Συνεδρίας 4**: Εργαλεία και τεχνικές βελτιστοποίησης
- **Προαπαιτούμενα**: Εξοικείωση με την εναλλαγή μοντέλων και τη βασική δοκιμή απόδοσης
- **Συνιστάται**: Έχετε εντοπίσει 2-3 αγαπημένα μοντέλα από αυτή τη συνεδρία

### Πρόσθετοι Πόροι

- **[Foundry Local Documentation](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Επίσημη τεκμηρίωση
- **[CLI Reference](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Πλήρης αναφορά εντολών
- **[Model Mondays](https://aka.ms/model-mondays)**: Εβδομαδιαία παρουσίαση μοντέλων
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Κοινότητα και θέματα
- **[Sample 03: Model Discovery](samples/03/README.md)**: Παράδειγμα σεναρίου

### Βασικά Σημεία

✅ **Ανακάλυψη Μοντέλων**: Χρησιμοποιήστε το `foundry model list` για να εξερευνήσετε διαθέσιμα μοντέλα  
✅ **Γρήγορη Δοκιμή**: Το μοτίβο `list_and_bench.cmd` για γρήγορη αξιολόγηση  
✅ **Παρακολούθηση Απόδοσης**: Βασική μέτρηση χρήσης πόρων και χρόνου απόκρισης  
✅ **Επιλογή Μοντέλων**: Πρακτικές οδηγίες για την επιλογή μοντέλων ανά περίπτωση χρήσης  
✅ **Διαχείριση Προσωρινής Μνήμης**: Κατανόηση διαδικασιών αποθήκευσης και καθαρισμού  

Τώρα έχετε τις πρακτικές δεξιότητες για να ανακαλύψετε, να δοκιμάσετε και να επιλέξετε κατάλληλα μοντέλα για τις εφαρμογές AI σας χρησιμοποιώντας την απλή προσέγγιση CLI του Foundry Local.

## Στόχοι Μάθησης
- Ανακαλύψτε και αξιολογήστε μοντέλα ανοιχτού κώδικα για τοπική επεξεργασία
- Συγκεντρώστε και εκτελέστε επιλεγμένα μοντέλα Hugging Face στο Foundry Local
- Εφαρμόστε στρατηγικές επιλογής μοντέλων για ακρίβεια, καθυστέρηση και ανάγκες πόρων
- Διαχειριστείτε μοντέλα τοπικά με προσωρινή μνήμη και εκδόσεις

## Μέρος 1: Ανακάλυψη Μοντέλων με το Foundry CLI

### Βασικές Εντολές Διαχείρισης Μοντέλων

Το foundry CLI παρέχει απλές εντολές για ανακάλυψη και διαχείριση μοντέλων:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Εκτέλεση των Πρώτων Μοντέλων Σας

Ξεκινήστε με δημοφιλή, καλά δοκιμασμένα μοντέλα για να κατανοήσετε τα χαρακτηριστικά απόδοσης:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b-instruct --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-distill-qwen-7b --verbose
```

**Σημείωση:** Η σημαία `--verbose` παρέχει λεπτομερείς πληροφορίες εκκίνησης, όπως:
- Πρόοδος λήψης μοντέλου (κατά την πρώτη εκτέλεση)
- Λεπτομέρειες κατανομής μνήμης
- Πληροφορίες σύνδεσης υπηρεσίας
- Μετρήσεις αρχικοποίησης απόδοσης

### Κατανόηση Κατηγοριών Μοντέλων

**Μικρά Γλωσσικά Μοντέλα (SLMs):**
- `phi-4-mini`: Γρήγορο, αποδοτικό, ιδανικό για γενική συνομιλία
- `phi-4`: Πιο ικανή έκδοση με καλύτερη λογική

**Μεσαία Μοντέλα:**
- `qwen2.5-7b-instruct`: Εξαιρετική λογική και μεγαλύτερο πλαίσιο
- `deepseek-r1-distill-qwen-7b`: Βελτιστοποιημένο για δημιουργία κώδικα

**Μεγαλύτερα Μοντέλα:**
- `llama-3.2`: Το τελευταίο μοντέλο ανοιχτού κώδικα της Meta
- `qwen2.5-14b-instruct`: Λογική επιπέδου επιχείρησης

## Μέρος 2: Γρήγορη Δοκιμή και Σύγκριση Μοντέλων

### Προσέγγιση Δείγματος 03: Απλή Λίστα και Αξιολόγηση

Βασισμένο στο μοτίβο Δείγμα 03, εδώ είναι η ελάχιστη ροή εργασίας:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Δοκιμή Απόδοσης Μοντέλων

Μόλις ένα μοντέλο εκτελείται, δοκιμάστε το με συνεπή ερωτήματα:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### Εναλλακτική Δοκιμή με PowerShell

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## Μέρος 3: Διαχείριση Προσωρινής Μνήμης και Αποθήκευσης Μοντέλων

### Κατανόηση της Προσωρινής Μνήμης Μοντέλων

Το Foundry Local διαχειρίζεται αυτόματα τις λήψεις και την προσωρινή μνήμη μοντέλων:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Σκέψεις για την Αποθήκευση Μοντέλων

**Τυπικά Μεγέθη Μοντέλων:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b-instruct`: ~4.1 GB  
- `deepseek-r1-distill-qwen-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b-instruct`: ~8.2 GB

**Βέλτιστες Πρακτικές Αποθήκευσης:**
- Κρατήστε 2-3 μοντέλα στην προσωρινή μνήμη για γρήγορη εναλλαγή
- Αφαιρέστε μη χρησιμοποιούμενα μοντέλα για ελευθέρωση χώρου: `foundry cache clean`
- Παρακολουθήστε τη χρήση δίσκου, ειδικά σε μικρότερους SSDs
- Εξετάστε την ισορροπία μεταξύ μεγέθους μοντέλου και δυνατοτήτων

### Παρακολούθηση Απόδοσης Μοντέλων

Ενώ τα μοντέλα εκτελούνται, παρακολουθήστε τους πόρους του συστήματος:

**Διαχείριση Εργασιών Windows:**
- Παρακολουθήστε τη χρήση μνήμης (τα μοντέλα παραμένουν φορτωμένα στη RAM)
- Ελέγξτε τη χρήση CPU κατά την επεξεργασία
- Ελέγξτε την είσοδο/έξοδο δίσκου κατά τη φόρτωση μοντέλων

**Παρακολούθηση από τη Γραμμή Εντολών:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## Μέρος 4: Πρακτικές Οδηγίες Επιλογής Μοντέλων

### Επιλογή Μοντέλων Ανά Περίπτωση Χρήσης

**Για Γενική Συνομιλία και Ερωτήσεις:**
- Ξεκινήστε με: `phi-4-mini` (γρήγορο, αποδοτικό)
- Αναβαθμίστε σε: `phi-4` (καλύτερη λογική)
- Προχωρημένο: `qwen2.5-7b-instruct` (μεγαλύτερο πλαίσιο)

**Για Δημιουργία Κώδικα:**
- Συνιστάται: `deepseek-r1-distill-qwen-7b`
- Εναλλακτική: `qwen2.5-7b-instruct` (επίσης καλό για κώδικα)

**Για Σύνθετη Λογική:**
- Καλύτερο: `qwen2.5-7b-instruct` ή `qwen2.5-14b-instruct`
- Οικονομική επιλογή: `phi-4`

### Οδηγός Απαιτήσεων Υλικού

**Ελάχιστες Απαιτήσεις Συστήματος:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Συνιστάται για Καλύτερη Απόδοση:**
- 32GB+ RAM για άνετη εναλλαγή πολλών μοντέλων
- Αποθήκευση SSD για ταχύτερη φόρτωση μοντέλων
- Σύγχρονος επεξεργαστής με καλή απόδοση μονού νήματος
- Υποστήριξη NPU (Windows 11 Copilot+ PCs) για επιτάχυνση

### Ροή Εργασίας Εναλλαγής Μοντέλων

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b-instruct

REM Verify model is running
foundry service status
```

## Μέρος 5: Απλή Αξιολόγηση Μοντέλων

### Βασική Δοκιμή Απόδοσης

Εδώ είναι μια απλή προσέγγιση για τη σύγκριση της απόδοσης μοντέλων:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b-instruct", "deepseek-r1-distill-qwen-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Χειροκίνητη Αξιολόγηση Ποιότητας

Για κάθε μοντέλο, δοκιμάστε με συνεπή ερωτήματα και αξιολογήστε χειροκίνητα:

**Ερωτήματα Δοκιμής:**
1. "Εξήγησε την κβαντική υπολογιστική με απλούς όρους."
2. "Γράψε μια συνάρτηση Python για ταξινόμηση λίστας."
3. "Ποια είναι τα πλεονεκτήματα και τα μειονεκτήματα της απομακρυσμένης εργασίας;"
4. "Περίληψη των πλεονεκτημάτων της edge AI."

**Κριτήρια Αξιολόγησης:**
- **Ακρίβεια**: Είναι σωστές οι πληροφορίες;
- **Σαφήνεια**: Είναι η εξήγηση εύκολη στην κατανόηση;
- **Πληρότητα**: Καλύπτει πλήρως την ερώτηση;
- **Ταχύτητα**: Πόσο γρήγορα απαντά;

### Παρακολούθηση Χρήσης Πόρων

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## Μέρος 6: Επόμενα Βήματα
- Εγγραφείτε στο Model Mondays για νέα μοντέλα και συμβουλές: https://aka.ms/model-mondays
- Συνεισφέρετε ευρήματα στο `models.json` της ομάδας σας
- Προετοιμαστείτε για τη Συνεδρία 4: σύγκριση LLMs vs SLMs, τοπική vs cloud επεξεργασία, και πρακτικές επιδείξεις

---

