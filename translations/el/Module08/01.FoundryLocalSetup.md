<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-22T19:19:18+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "el"
}
-->
# Συνεδρία 1: Ξεκινώντας με το Foundry Local

## Επισκόπηση

Το Microsoft Foundry Local φέρνει τις δυνατότητες του Azure AI Foundry απευθείας στο περιβάλλον ανάπτυξης των Windows 11, επιτρέποντας την ανάπτυξη AI με διατήρηση της ιδιωτικότητας, χαμηλή καθυστέρηση και εργαλεία επιπέδου επιχείρησης. Αυτή η συνεδρία καλύπτει την πλήρη εγκατάσταση, ρύθμιση και πρακτική ανάπτυξη δημοφιλών μοντέλων όπως phi, qwen, deepseek και GPT-OSS-20B.

## Στόχοι Μάθησης

Μέχρι το τέλος αυτής της συνεδρίας, θα μπορείτε:
- Να εγκαταστήσετε και να ρυθμίσετε το Foundry Local στα Windows 11
- Να εξοικειωθείτε με εντολές CLI και επιλογές ρύθμισης
- Να κατανοήσετε στρατηγικές προσωρινής αποθήκευσης μοντέλων για βέλτιστη απόδοση
- Να εκτελέσετε επιτυχώς τα μοντέλα phi, qwen, deepseek και GPT-OSS-20B
- Να δημιουργήσετε την πρώτη σας εφαρμογή AI χρησιμοποιώντας το Foundry Local

## Προαπαιτούμενα

### Απαιτήσεις Συστήματος
- **Windows 11**: Έκδοση 22H2 ή νεότερη
- **RAM**: Ελάχιστο 16GB, συνιστάται 32GB
- **Αποθηκευτικός Χώρος**: 50GB ελεύθερος χώρος για μοντέλα και προσωρινή αποθήκευση
- **Υλικό**: Συσκευή με NPU ή GPU προτιμάται (Copilot+ PC ή NVIDIA GPU)
- **Δίκτυο**: Γρήγορη σύνδεση στο διαδίκτυο για λήψη μοντέλων

### Περιβάλλον Ανάπτυξης
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## Μέρος 1: Εγκατάσταση και Ρύθμιση

### Βήμα 1: Εγκατάσταση του Foundry Local

Εγκαταστήστε το Foundry Local χρησιμοποιώντας το Winget ή κατεβάστε τον εγκαταστάτη από το GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Βήμα 2: Επαλήθευση Εγκατάστασης

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Μέρος 2: Κατανόηση του CLI

### Βασική Δομή Εντολών

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Μέρος 3: Διαχείριση και Προσωρινή Αποθήκευση Μοντέλων

Το Foundry Local εφαρμόζει έξυπνη προσωρινή αποθήκευση μοντέλων για βελτιστοποίηση της απόδοσης και του αποθηκευτικού χώρου:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Μέρος 4: Πρακτική Ανάπτυξη Μοντέλων

### Εκτέλεση Μοντέλων Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Εργασία με Μοντέλα Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### Εκτέλεση Μοντέλων DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### Εκτέλεση GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Μέρος 5: Δημιουργία της Πρώτης σας Εφαρμογής

### Απλή Διεπαφή Συνομιλίας (Συμβατή με API OpenAI)

Δημιουργήστε μια βασική εφαρμογή συνομιλίας χρησιμοποιώντας το REST API του Foundry Local, συμβατό με το OpenAI. Βεβαιωθείτε ότι ένα μοντέλο εκτελείται σε άλλο τερματικό.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Εκτέλεση της Εφαρμογής Συνομιλίας

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## Μέρος 6: Αντιμετώπιση Προβλημάτων και Βέλτιστες Πρακτικές

### Συνηθισμένα Προβλήματα και Λύσεις

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Παρακολούθηση Πόρων Συστήματος (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Βέλτιστες Πρακτικές

- Προτιμήστε τις εντολές `foundry model ...`, `foundry cache ...` και `foundry service ...` (δείτε την αναφορά CLI)
- Αναβαθμίζετε τακτικά για πρόσβαση σε νέα μοντέλα και διορθώσεις
- Ξεκινήστε με μικρότερα μοντέλα (Phi mini, Qwen 7B) και αυξήστε σταδιακά
- Παρακολουθήστε CPU/GPU/μνήμη ενώ ρυθμίζετε προτροπές και παραμέτρους

## Μέρος 7: Πρακτικές Ασκήσεις

### Άσκηση 1: Γρήγορη Εκτέλεση Πολλαπλών Μοντέλων

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Άσκηση 2: Βασική Αξιολόγηση Καθυστέρησης

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Αναφορές

- Ξεκινήστε με το Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- Αναφορά CLI και επισκόπηση εντολών: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Μεταγλώττιση μοντέλων Hugging Face για το Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

