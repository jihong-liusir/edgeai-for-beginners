<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-10-11T12:48:22+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "et"
}
-->
# 3. sessioon: Avatud lähtekoodiga mudelite avastamine ja haldamine

## Ülevaade

Selles sessioonis keskendutakse praktilisele mudelite avastamisele ja haldamisele Foundry Locali abil. Õpid, kuidas loetleda saadaolevaid mudeleid, testida erinevaid valikuid ja mõista põhilisi jõudlusomadusi. Lähenemine rõhutab praktilist uurimistööd Foundry CLI abil, et aidata sul valida oma kasutusjuhtumite jaoks sobivaid mudeleid.

## Õpieesmärgid

- Omandada Foundry CLI käskude kasutamine mudelite avastamiseks ja haldamiseks
- Mõista mudelite vahemälu ja kohaliku salvestuse mustreid
- Õppida kiiresti testima ja võrdlema erinevaid mudeleid
- Luua praktilised töövood mudelite valimiseks ja võrdlemiseks
- Avastada Foundry Locali kaudu kättesaadavate mudelite kasvavat ökosüsteemi

## Eeltingimused

- Lõpetatud 1. sessioon: Foundry Localiga alustamine
- Foundry Local CLI on paigaldatud ja kättesaadav
- Piisav salvestusruum mudelite allalaadimiseks (mudelid võivad olla vahemikus 1GB kuni 20GB+)
- Põhiline arusaam mudelitüüpidest ja kasutusjuhtumitest

## Ülevaade

Selles sessioonis uuritakse, kuidas tuua avatud lähtekoodiga mudeleid Foundry Locali.

## Osa 6: Praktiline harjutus

### Harjutus: Mudelite avastamine ja võrdlemine

Loo oma mudelite hindamise skript, tuginedes näidisele 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Sinu ülesanne

1. **Käivita näidis 03 skript**: `samples\03\list_and_bench.cmd`
2. **Proovi erinevaid mudeleid**: Testi vähemalt 3 erinevat mudelit
3. **Võrdle jõudlust**: Pane tähele kiiruse ja vastuste kvaliteedi erinevusi
4. **Dokumenteeri tulemused**: Loo lihtne võrdlustabel

### Näidisvõrdluse formaat

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## Osa 7: Tõrkeotsing ja parimad praktikad

### Levinumad probleemid ja lahendused

**Mudel ei käivitu:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Ebapiisav mälu:**
- Alusta väiksemate mudelitega (`phi-4-mini`)
- Sule teised rakendused
- Uuenda RAM-i, kui sageli esineb mälupuudust

**Aeglane jõudlus:**
- Veendu, et mudel on täielikult laaditud (kontrolli üksikasjalikku väljundit)
- Sule mittevajalikud taustarakendused
- Kaalu kiiremat salvestusruumi (SSD)

### Parimad praktikad

1. **Alusta väikselt**: Kontrolli seadistust `phi-4-mini` abil
2. **Üks mudel korraga**: Peata eelmine mudel enne uue käivitamist
3. **Jälgi ressursse**: Hoia silm peal mälukasutusel
4. **Testi järjepidevalt**: Kasuta samu küsimusi õiglasemaks võrdlemiseks
5. **Dokumenteeri tulemused**: Tee märkmeid mudelite jõudluse kohta oma kasutusjuhtumite jaoks

## Osa 8: Järgmised sammud ja viited

### Valmistumine 4. sessiooniks

- **4. sessiooni fookus**: Optimeerimise tööriistad ja tehnikad
- **Eeltingimused**: Mugavus mudelite vahetamisel ja põhiline jõudluse testimine
- **Soovitus**: Ole valinud 2-3 lemmikmudelit sellest sessioonist

### Lisamaterjalid

- **[Foundry Local dokumentatsioon](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Ametlik dokumentatsioon
- **[CLI viide](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Täielik käskude viide
- **[Model Mondays](https://aka.ms/model-mondays)**: Iganädalased mudelite tutvustused
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Kogukond ja probleemid
- **[Näidis 03: Mudelite avastamine](samples/03/README.md)**: Praktiline näidisskript

### Peamised järeldused

✅ **Mudelite avastamine**: Kasuta `foundry model list`, et uurida saadaolevaid mudeleid  
✅ **Kiire testimine**: Kasuta `list_and_bench.cmd` mustrit kiireks hindamiseks  
✅ **Jõudluse jälgimine**: Põhiline ressursside kasutuse ja reageerimisaja mõõtmine  
✅ **Mudelivalik**: Praktilised juhised mudelite valimiseks vastavalt kasutusjuhtumile  
✅ **Vahemälu haldamine**: Salvestusruumi ja puhastamise protseduuride mõistmine  

Nüüd on sul praktilised oskused avastada, testida ja valida sobivaid mudeleid oma AI-rakenduste jaoks, kasutades Foundry Locali lihtsat CLI lähenemist: kogukonna mudelite valimine, Hugging Face'i sisu integreerimine ja "too oma mudel" (BYOM) strateegiate rakendamine. Samuti avastad Model Mondays seeria pidevaks õppimiseks ja mudelite avastamiseks.

Viited:
- Foundry Local dokumentatsioon: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Hugging Face'i mudelite kompileerimine: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Model Mondays: https://aka.ms/model-mondays
- Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

## Õpieesmärgid
- Avastada ja hinnata avatud lähtekoodiga mudeleid kohalikuks järeldamiseks
- Kompileerida ja käivitada valitud Hugging Face'i mudeleid Foundry Localis
- Rakendada mudelite valiku strateegiaid täpsuse, viivituse ja ressursivajaduste põhjal
- Hallata mudeleid kohapeal vahemälu ja versioonihalduse abil

## Osa 1: Mudelite avastamine Foundry CLI abil

### Põhilised mudelite haldamise käsud

Foundry CLI pakub lihtsaid käske mudelite avastamiseks ja haldamiseks:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Esimeste mudelite käivitamine

Alusta populaarsete ja hästi testitud mudelitega, et mõista nende jõudlusomadusi:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**Märkus:** Lipp `--verbose` annab üksikasjalikku teavet käivitamise kohta, sealhulgas:
- Mudeli allalaadimise edenemine (esmakordsel käivitamisel)
- Mälu jaotamise üksikasjad
- Teenuse sidumise teave
- Jõudluse algandmed

### Mudelikategooriate mõistmine

**Väikesed keelemudelid (SLM):**
- `phi-4-mini`: Kiire, tõhus, suurepärane üldiseks vestluseks
- `phi-4`: Võimekam versioon parema loogikaga

**Keskmised mudelid:**
- `qwen2.5-7b`: Suurepärane loogika ja pikem kontekst
- `deepseek-r1-7b`: Optimeeritud koodi genereerimiseks

**Suuremad mudelid:**
- `llama-3.2`: Meta uusim avatud lähtekoodiga mudel
- `qwen2.5-14b`: Ettevõtte tasemel loogika

## Osa 2: Kiire mudelite testimine ja võrdlemine

### Näidis 03 lähenemine: Lihtne loetelu ja võrdlus

Tuginedes meie näidisele 03, on siin minimaalne töövoog:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Mudelite jõudluse testimine

Kui mudel töötab, testi seda järjepidevate küsimustega:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### PowerShelli testimise alternatiiv

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## Osa 3: Mudelite vahemälu ja salvestuse haldamine

### Mudelite vahemälu mõistmine

Foundry Local haldab automaatselt mudelite allalaadimist ja vahemällu salvestamist:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Mudelite salvestuse kaalutlused

**Tüüpilised mudelite suurused:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b`: ~4.1 GB  
- `deepseek-r1-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b`: ~8.2 GB

**Salvestuse parimad praktikad:**
- Hoia 2-3 mudelit vahemälus kiireks vahetamiseks
- Eemalda kasutamata mudelid ruumi vabastamiseks: `foundry cache clean`
- Jälgi kettakasutust, eriti väiksemate SSD-de puhul
- Kaalu mudeli suuruse ja võimekuse kompromisse

### Mudelite jõudluse jälgimine

Kui mudelid töötavad, jälgi süsteemi ressursse:

**Windowsi tegumihaldur:**
- Jälgi mälukasutust (mudelid jäävad RAM-i laadituks)
- Jälgi protsessori kasutust järeldamise ajal
- Kontrolli ketta I/O-d mudeli esialgse laadimise ajal

**Käsurea jälgimine:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## Osa 4: Praktilised mudelite valiku juhised

### Mudelite valimine kasutusjuhtumi järgi

**Üldiseks vestluseks ja küsimustele vastamiseks:**
- Alusta: `phi-4-mini` (kiire, tõhus)
- Uuenda: `phi-4` (parem loogika)
- Edasijõudnutele: `qwen2.5-7b` (pikem kontekst)

**Koodi genereerimiseks:**
- Soovitatav: `deepseek-r1-7b`
- Alternatiiv: `qwen2.5-7b` (ka koodiks hea)

**Keeruliseks loogikaks:**
- Parim: `qwen2.5-7b` või `qwen2.5-14b`
- Soodne valik: `phi-4`

### Riistvaranõuete juhend

**Minimaalsed süsteeminõuded:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Soovitatav parima jõudluse jaoks:**
- 32GB+ RAM mugavaks mitme mudeli vahetamiseks
- SSD salvestusruum kiireks mudelite laadimiseks
- Kaasaegne protsessor hea ühe tuuma jõudlusega
- NPU tugi (Windows 11 Copilot+ arvutid) kiirenduseks

### Mudelite vahetamise töövoog

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## Osa 5: Lihtne mudelite võrdlemine

### Põhiline jõudluse testimine

Siin on lihtne lähenemine mudelite jõudluse võrdlemiseks:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Käsitsi kvaliteedi hindamine

Testi iga mudelit järjepidevate küsimustega ja hinda käsitsi:

**Testküsimused:**
1. "Selgita kvantarvutust lihtsate sõnadega."
2. "Kirjuta Pythonis funktsioon nimekirja sorteerimiseks."
3. "Millised on kaugtöö plussid ja miinused?"
4. "Kokkuvõte serva-AI eelistest."

**Hindamiskriteeriumid:**
- **Täpsus**: Kas info on õige?
- **Selgus**: Kas selgitus on kergesti mõistetav?
- **Täielikkus**: Kas see vastab täielikult küsimusele?
- **Kiirus**: Kui kiiresti see vastab?

### Ressursside kasutuse jälgimine

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## Osa 6: Järgmised sammud
- Telli Model Mondays, et saada uusi mudeleid ja näpunäiteid: https://aka.ms/model-mondays
- Jaga oma leide oma meeskonna `models.json` failis
- Valmista ette 4. sessiooniks: LLM-ide ja SLM-ide võrdlemine, kohaliku ja pilvepõhise järeldamise võrdlus ning praktilised demod

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valesti tõlgenduste eest.