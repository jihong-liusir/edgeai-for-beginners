<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c37dfe660161e652077f6b7b23bb2167",
  "translation_date": "2025-10-11T14:52:04+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "et"
}
-->
# Section 3: Praktiline rakendusjuhend

## Ülevaade

See põhjalik juhend aitab teil valmistuda EdgeAI kursuseks, mis keskendub praktiliste tehisintellekti lahenduste loomisele, mis töötavad tõhusalt servaseadmetel. Kursus rõhutab praktilist arendust, kasutades kaasaegseid raamistikke ja tipptasemel mudeleid, mis on optimeeritud servaseadmete jaoks.

## 1. Arenduskeskkonna seadistamine

### Programmeerimiskeeled ja raamistikud

**Python keskkond**
- **Versioon**: Python 3.10 või uuem (soovitatav: Python 3.11)
- **Pakihaldur**: pip või conda
- **Virtuaalne keskkond**: Kasutage venv või conda keskkondi isolatsiooniks
- **Peamised teegid**: Spetsiifilised EdgeAI teegid paigaldatakse kursuse käigus

**Microsoft .NET keskkond**
- **Versioon**: .NET 8 või uuem
- **IDE**: Visual Studio 2022, Visual Studio Code või JetBrains Rider
- **SDK**: Veenduge, et .NET SDK on paigaldatud platvormidevaheliseks arenduseks

### Arendustööriistad

**Koodiredaktorid ja IDE-d**
- Visual Studio Code (soovitatav platvormidevaheliseks arenduseks)
- PyCharm või Visual Studio (keelespetsiifiliseks arenduseks)
- Jupyter Notebooks interaktiivseks arenduseks ja prototüüpimiseks

**Versioonihaldus**
- Git (viimane versioon)
- GitHubi konto juurdepääsuks repositooriumidele ja koostööks

## 2. Riistvaranõuded ja soovitused

### Minimaalsed süsteeminõuded
- **CPU**: Mitmetuumaline protsessor (Intel i5/AMD Ryzen 5 või samaväärne)
- **RAM**: Minimaalselt 8GB, soovitatavalt 16GB
- **Salvestusruum**: 50GB vaba ruumi mudelite ja arendustööriistade jaoks
- **OS**: Windows 10/11, macOS 10.15+ või Linux (Ubuntu 20.04+)

### Arvutusressursside strateegia
Kursus on loodud erinevate riistvarakonfiguratsioonide jaoks:

**Kohalik arendus (CPU/NPU fookus)**
- Peamine arendus toimub CPU ja NPU kiirenduse abil
- Sobib enamikele kaasaegsetele sülearvutitele ja lauaarvutitele
- Keskendutakse tõhususele ja praktilistele juurutusstsenaariumidele

**Pilve GPU ressursid (valikuline)**
- **Azure Machine Learning**: Intensiivseks treenimiseks ja katsetamiseks
- **Google Colab**: Tasuta tase hariduslikel eesmärkidel
- **Kaggle Notebooks**: Alternatiivne pilvearvutuse platvorm

### Servaseadmete kaalutlused
- ARM-põhiste protsessorite mõistmine
- Mobiilsete ja IoT riistvarapiirangute tundmine
- Energiatarbimise optimeerimise oskused

## 3. Põhimudelite perekonnad ja ressursid

### Peamised mudelite perekonnad

**Microsoft Phi-4 perekond**
- **Kirjeldus**: Kompaktsed ja tõhusad mudelid, mis on loodud servaseadmete jaoks
- **Tugevused**: Suurepärane jõudluse ja suuruse suhe, optimeeritud järelduste tegemiseks
- **Ressurss**: [Phi-4 kollektsioon Hugging Face'is](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Kasutusjuhtumid**: Koodi genereerimine, matemaatiline järeldamine, üldine vestlus

**Qwen-3 perekond**
- **Kirjeldus**: Alibaba uusim põlvkond mitmekeelsetest mudelitest
- **Tugevused**: Tugevad mitmekeelsed võimed, tõhus arhitektuur
- **Ressurss**: [Qwen-3 kollektsioon Hugging Face'is](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Kasutusjuhtumid**: Mitmekeelsed rakendused, kultuuridevahelised AI lahendused

**Google Gemma-3n perekond**
- **Kirjeldus**: Google'i kergekaalulised mudelid, mis on optimeeritud servaseadmete jaoks
- **Tugevused**: Kiire järeldamine, mobiilisõbralik arhitektuur
- **Ressurss**: [Gemma-3n kollektsioon Hugging Face'is](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Kasutusjuhtumid**: Mobiilirakendused, reaalajas töötlemine

### Mudeli valikukriteeriumid
- **Jõudluse ja suuruse kompromissid**: Millal valida väiksemad vs suuremad mudelid
- **Ülesandespetsiifiline optimeerimine**: Mudelite sobitamine konkreetsete kasutusjuhtumitega
- **Juurutuspiirangud**: Mälu, latentsuse ja energiatarbimise kaalutlused

## 4. Kvantiseerimis- ja optimeerimistööriistad

### Llama.cpp raamistik
- **Repositoorium**: [Llama.cpp GitHubis](https://github.com/ggml-org/llama.cpp)
- **Eesmärk**: Kõrge jõudlusega järeldusmootor LLM-ide jaoks
- **Peamised omadused**:
  - CPU-optimeeritud järeldamine
  - Mitmed kvantiseerimisformaadid (Q4, Q5, Q8)
  - Platvormidevaheline ühilduvus
  - Mälu tõhus kasutamine
- **Paigaldamine ja põhiline kasutamine**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Repositoorium**: [Microsoft Olive GitHubis](https://github.com/microsoft/olive)
- **Eesmärk**: Mudelite optimeerimise tööriistakomplekt servaseadmete jaoks
- **Peamised omadused**:
  - Automaatne mudelite optimeerimise töövoog
  - Riistvarateadlik optimeerimine
  - Integratsioon ONNX Runtime'iga
  - Jõudluse võrdluse tööriistad
- **Paigaldamine ja põhiline kasutamine**:
  ```bash
  # Install Olive
  pip install olive-ai
  ```
  
  # Näidis Python skript mudeli optimeerimiseks
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (macOS kasutajatele)
- **Repositoorium**: [Apple MLX GitHubis](https://github.com/ml-explore/mlx)
- **Eesmärk**: Masinõppe raamistik Apple Siliconi jaoks
- **Peamised omadused**:
  - Native optimeerimine Apple Siliconile
  - Mälu tõhus kasutamine
  - PyTorch-sarnane API
  - Ühtse mälu arhitektuuri tugi
- **Paigaldamine ja põhiline kasutamine**:
  ```bash
  # Install MLX
  pip install mlx
  ```
  
  ```python
  # Example Python script for loading and optimizing a model
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Repositoorium**: [ONNX Runtime GitHubis](https://github.com/microsoft/onnxruntime)
- **Eesmärk**: Platvormidevaheline järelduskiirendus ONNX mudelite jaoks
- **Peamised omadused**:
  - Riistvaraspetsiifilised optimeerimised (CPU, GPU, NPU)
  - Graafi optimeerimine järeldamiseks
  - Kvantiseerimise tugi
  - Mitmekeelne tugi (Python, C++, C#, JavaScript)
- **Paigaldamine ja põhiline kasutamine**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. Soovitatav lugemine ja ressursid

### Oluline dokumentatsioon
- **ONNX Runtime dokumentatsioon**: Platvormidevahelise järelduse mõistmine
- **Hugging Face Transformers juhend**: Mudelite laadimine ja järeldamine
- **Edge AI disainimustrid**: Parimad tavad servaseadmete juurutamiseks

### Tehnilised artiklid
- "Efficient Edge AI: A Survey of Quantization Techniques"
- "Model Compression for Mobile and Edge Devices"
- "Optimizing Transformer Models for Edge Computing"

### Kogukonna ressursid
- **EdgeAI Slack/Discord kogukonnad**: Kaaslaste tugi ja arutelud
- **GitHubi repositooriumid**: Näidisrakendused ja juhendid
- **YouTube'i kanalid**: Tehnilised süvitsiminekud ja juhendid

## 6. Hindamine ja kontroll

### Kursuse-eelne kontrollnimekiri
- [ ] Python 3.10+ paigaldatud ja kontrollitud
- [ ] .NET 8+ paigaldatud ja kontrollitud
- [ ] Arenduskeskkond seadistatud
- [ ] Hugging Face konto loodud
- [ ] Põhiline tutvumine sihtmudelite perekondadega
- [ ] Kvantiseerimistööriistad paigaldatud ja testitud
- [ ] Riistvaranõuded täidetud
- [ ] Pilvearvutuse kontod seadistatud (vajadusel)

## Peamised õpieesmärgid

Selle juhendi lõpuks suudate:

1. Seadistada täieliku arenduskeskkonna EdgeAI rakenduste arendamiseks
2. Paigaldada ja konfigureerida vajalikud tööriistad ja raamistikud mudelite optimeerimiseks
3. Valida sobivad riist- ja tarkvarakonfiguratsioonid oma EdgeAI projektide jaoks
4. Mõista peamisi kaalutlusi AI mudelite juurutamiseks servaseadmetel
5. Valmistada oma süsteemi kursuse praktilisteks harjutusteks

## Täiendavad ressursid

### Ametlik dokumentatsioon
- **Python dokumentatsioon**: Ametlik Python keele dokumentatsioon
- **Microsoft .NET dokumentatsioon**: Ametlik .NET arendusressurss
- **ONNX Runtime dokumentatsioon**: Põhjalik juhend ONNX Runtime'ile
- **TensorFlow Lite dokumentatsioon**: Ametlik TensorFlow Lite dokumentatsioon

### Arendustööriistad
- **Visual Studio Code**: Kergekaaluline koodiredaktor AI arenduse laiendustega
- **Jupyter Notebooks**: Interaktiivne arvutuskeskkond ML katsetamiseks
- **Docker**: Konteineriplatvorm ühtsete arenduskeskkondade jaoks
- **Git**: Versioonihaldussüsteem koodi haldamiseks

### Õpperessursid
- **EdgeAI teadusartiklid**: Viimased akadeemilised uuringud tõhusate mudelite kohta
- **Veebikursused**: Täiendavad õppematerjalid AI optimeerimise kohta
- **Kogukonna foorumid**: Küsimuste ja vastuste platvormid EdgeAI arenduse väljakutseteks
- **Võrdlusandmestikud**: Standardandmestikud mudelite jõudluse hindamiseks

## Õpitulemused

Pärast selle ettevalmistusjuhendi läbimist:

1. Teil on täielikult seadistatud arenduskeskkond EdgeAI arenduseks
2. Mõistate riist- ja tarkvaranõudeid erinevate juurutusstsenaariumide jaoks
3. Olete tuttav peamiste raamistikude ja tööriistadega, mida kursuse jooksul kasutatakse
4. Suudate valida sobivaid mudeleid vastavalt seadme piirangutele ja nõuetele
5. Omate põhiteadmisi optimeerimistehnikatest servaseadmete jaoks

## ➡️ Mis edasi

- [04: EdgeAI riistvara ja juurutamine](04.EdgeDeployment.md)

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valesti tõlgenduste eest.