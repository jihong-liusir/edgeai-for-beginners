<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a35d3b47e6ae98ad9b3e89fb73917e90",
  "translation_date": "2025-10-11T11:11:34+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "et"
}
-->
# Section 1: EdgeAI Põhitõed

EdgeAI esindab paradigmat, mis toob tehisintellekti võimekuse otse servaseadmetesse, mitte ei tugine ainult pilvepõhisele töötlemisele. Oluline on mõista, kuidas EdgeAI võimaldab kohalikku AI töötlemist piiratud ressurssidega seadmetel, säilitades samal ajal mõistliku jõudluse ja lahendades privaatsuse, latentsuse ja võrguühenduseta töötamisega seotud väljakutseid.

## Sissejuhatus

Selles õppetükis uurime EdgeAI-d ja selle põhimõisteid. Käsitleme traditsioonilist AI arvutusparadigmat, servaarvutuse väljakutseid, EdgeAI-d võimaldavaid võtmetehnoloogiaid ja praktilisi rakendusi erinevates tööstusharudes.

## Õppeeesmärgid

Selle õppetüki lõpuks suudad:

- Mõista traditsioonilise pilvepõhise AI ja EdgeAI lähenemisviiside erinevust.
- Tuvastada võtmetehnoloogiad, mis võimaldavad AI töötlemist servaseadmetel.
- Tunnustada EdgeAI rakenduste eeliseid ja piiranguid.
- Rakendada EdgeAI teadmisi reaalses maailmas ja kasutusjuhtumites.

## Traditsioonilise AI arvutusparadigma mõistmine

Traditsiooniliselt tuginevad generatiivse AI rakendused suure jõudlusega arvutustaristule, et käitada suuri keelemudeleid (LLM) tõhusalt. Organisatsioonid paigutavad need mudelid tavaliselt GPU klastritesse pilvekeskkondades, kasutades nende võimekust API-liideste kaudu.

See tsentraliseeritud mudel töötab hästi paljude rakenduste puhul, kuid sellel on servaarvutuse stsenaariumides kaasasündinud piirangud. Traditsiooniline lähenemine hõlmab kasutaja päringute saatmist kaugserveritesse, nende töötlemist võimsa riistvara abil ja tulemuste tagastamist interneti kaudu. Kuigi see meetod pakub juurdepääsu tipptasemel mudelitele, tekitab see sõltuvusi internetiühendusest, suurendab latentsust ja tõstatab privaatsuse küsimusi, kui tundlikke andmeid tuleb edastada välistele serveritele.

Traditsioonilise AI arvutusparadigma puhul tuleb mõista mõningaid põhikontseptsioone, nimelt:

- **☁️ Pilvepõhine töötlemine**: AI mudelid töötavad võimsal serveritaristul, millel on suured arvutusressursid.
- **🔌 API-põhine juurdepääs**: Rakendused kasutavad AI võimekust kaug-API-kõnede kaudu, mitte kohalikult.
- **🎛️ Tsentraliseeritud mudelihaldus**: Mudeleid hallatakse ja uuendatakse tsentraalselt, tagades järjepidevuse, kuid nõudes võrguühendust.
- **📈 Ressursside skaleeritavus**: Pilvetaristu saab dünaamiliselt skaleerida, et toime tulla erinevate arvutusnõudmistega.

## Servaarvutuse väljakutsed

Servaseadmed, nagu sülearvutid, mobiiltelefonid ja asjade interneti (IoT) seadmed, näiteks Raspberry Pi ja NVIDIA Orin Nano, esitavad ainulaadseid arvutuspiiranguid. Neil seadmetel on tavaliselt piiratud töötlemisvõimsus, mälu ja energiavarud võrreldes andmekeskuste taristuga.

Traditsiooniliste LLM-ide käitamine sellistel seadmetel on ajalooliselt olnud keeruline nende riistvarapiirangute tõttu. Kuid serva AI töötlemise vajadus on muutunud üha olulisemaks erinevates olukordades. Mõelge olukordadele, kus internetiühendus on ebausaldusväärne või puudub, näiteks kaugemates tööstuskohtades, transiidis olevates sõidukites või piirkondades, kus võrguühendus on kehv. Lisaks võivad rakendused, mis nõuavad kõrgeid turvastandardeid, nagu meditsiiniseadmed, finantssüsteemid või valitsuse rakendused, vajada tundlike andmete kohalikku töötlemist privaatsuse ja vastavusnõuete säilitamiseks.

### Servaarvutuse põhipiirangud

Servaarvutuskeskkonnad seisavad silmitsi mitmete põhiliste piirangutega, mida traditsioonilised pilvepõhised AI lahendused ei kohta:

- **Piiratud töötlemisvõimsus**: Servaseadmetel on tavaliselt vähem CPU tuumasid ja madalamad taktsagedused võrreldes serveriklassi riistvaraga.
- **Mälu piirangud**: Saadaval olev RAM ja salvestusmaht on servaseadmetel oluliselt väiksemad.
- **Energiapiirangud**: Aku toitel töötavad seadmed peavad tasakaalustama jõudlust ja energiatarbimist pikema tööaja tagamiseks.
- **Termohaldus**: Kompaktne vormifaktor piirab jahutusvõimalusi, mõjutades pidevat jõudlust koormuse all.

## Mis on EdgeAI?

### Kontseptsioon: EdgeAI määratlus

EdgeAI viitab tehisintellekti algoritmide juurutamisele ja käitamisele otse servaseadmetel—füüsilisel riistvaral, mis asub võrgu "servas", lähedal andmete genereerimisele ja kogumisele. Need seadmed hõlmavad nutitelefone, IoT sensoreid, nutikaameraid, autonoomseid sõidukeid, kantavaid seadmeid ja tööstusseadmeid. Erinevalt traditsioonilistest AI süsteemidest, mis tuginevad töötlemiseks pilveserveritele, toob EdgeAI intelligentsuse otse andmeallikasse.

EdgeAI keskmes on AI töötlemise detsentraliseerimine, viies selle tsentraliseeritud andmekeskustest eemale ja jaotades selle üle digitaalse ökosüsteemi ulatusliku seadmete võrgu. See esindab fundamentaalset arhitektuurilist muutust AI süsteemide kujundamisel ja juurutamisel.

EdgeAI võtmekontseptuaalsed sambad hõlmavad:

- **Lähedustöötlemine**: Arvutus toimub füüsiliselt lähedal andmete päritolule.
- **Detsentraliseeritud intelligentsus**: Otsustusvõime jaotatakse mitme seadme vahel.
- **Andmesuveräänsus**: Informatsioon jääb kohaliku kontrolli alla, sageli ei lahku seadmest.
- **Autonoomne toimimine**: Seadmed suudavad toimida intelligentselt ilma pideva ühenduvuseta.
- **Sisseehitatud AI**: Intelligentsus muutub igapäevaste seadmete lahutamatuks osaks.

### EdgeAI arhitektuuri visualiseerimine

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                  │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                      │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────────────────────────────────────────┐   Direct Response   ┌───────────┐
│              Edge Devices with Embedded AI        │───────────────────>│ End Users │
│  ┌─────────┐  ┌──────────────┐  ┌──────────────┐ │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │ │
│  └─────────┘  └──────────────┘  └──────────────┘ │
└──────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI esindab paradigmat, mis toob tehisintellekti võimekuse otse servaseadmetesse, mitte ei tugine ainult pilvepõhisele töötlemisele. See lähenemine võimaldab AI mudeleid käitada kohapeal seadmetel, millel on piiratud arvutusressursid, pakkudes reaalajas järeldusvõimekust ilma pideva internetiühenduseta.

EdgeAI hõlmab mitmesuguseid tehnoloogiaid ja tehnikaid, mis on mõeldud AI mudelite tõhusamaks muutmiseks ja nende juurutamiseks piiratud ressurssidega seadmetel. Eesmärk on säilitada mõistlik jõudlus, vähendades oluliselt AI mudelite arvutus- ja mälunõudeid.

Vaatame põhilisi lähenemisviise, mis võimaldavad EdgeAI rakendusi erinevatel seadmetüüpidel ja kasutusjuhtudel.

### EdgeAI põhialused

EdgeAI tugineb mitmele põhimõttele, mis eristavad seda traditsioonilisest pilvepõhisest AI-st:

- **Kohalik töötlemine**: AI järeldus toimub otse servaseadmel, ilma et oleks vaja välist ühenduvust.
- **Ressursside optimeerimine**: Mudelid on optimeeritud spetsiaalselt sihtseadmete riistvarapiirangute jaoks.
- **Reaalajas jõudlus**: Töötlemine toimub minimaalse latentsusega ajakriitiliste rakenduste jaoks.
- **Privaatsus disainis**: Tundlikud andmed jäävad seadmesse, suurendades turvalisust ja vastavust.

## EdgeAI-d võimaldavad võtmetehnoloogiad

### Mudeli kvantiseerimine

Üks olulisemaid tehnikaid EdgeAI-s on mudeli kvantiseerimine. See protsess hõlmab mudeli parameetrite täpsuse vähendamist, tavaliselt 32-bitistest ujukomaarvudest 8-bitisteks täisarvudeks või isegi madalama täpsusega formaatideks. Kuigi täpsuse vähendamine võib tunduda murettekitav, on uuringud näidanud, et paljud AI mudelid suudavad säilitada oma jõudluse isegi oluliselt vähendatud täpsusega.

Kvantiseerimine töötab, kaardistades ujukomaarvude vahemiku väiksemale diskreetsete väärtuste kogumile. Näiteks 32 bitti kasutamise asemel iga parameetri esindamiseks võib kvantiseerimine kasutada ainult 8 bitti, mis toob kaasa 4-kordse mälunõuete vähenemise ja sageli kiiremad järeldusajad.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Erinevad kvantiseerimistehnikad hõlmavad:

- **Post-treeningu kvantiseerimine (PTQ)**: Rakendatakse pärast mudeli treenimist, ilma et oleks vaja uuesti treenimist.
- **Kvantiseerimisest teadlik treenimine (QAT)**: Hõlmab kvantiseerimise mõju treenimise ajal, et saavutada parem täpsus.
- **Dünaamiline kvantiseerimine**: Kvantiseerib kaalud int8-ks, kuid arvutab aktivatsioonid dünaamiliselt.
- **Staatiline kvantiseerimine**: Eelnevalt arvutab kõik kvantiseerimisparameetrid nii kaaludele kui aktivatsioonidele.

EdgeAI juurutuste puhul sõltub sobiva kvantiseerimisstrateegia valik konkreetse mudeli arhitektuurist, jõudlusnõuetest ja sihtseadme riistvaravõimekusest.

### Mudeli tihendamine ja optimeerimine

Lisaks kvantiseerimisele aitavad mitmesugused tihendustehnikad vähendada mudeli suurust ja arvutusnõudeid. Nende hulka kuuluvad:

**Pügamine**: See tehnika eemaldab neuralvõrkudest mittevajalikud ühendused või neuronid. Identifitseerides ja kõrvaldades parameetrid, mis mudeli jõudlusele vähe kaasa aitavad, võib pügamine oluliselt vähendada mudeli suurust, säilitades samal ajal täpsuse.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Teadmiste destilleerimine**: See lähenemine hõlmab väiksema "õpilasmudeli" treenimist, et jäljendada suurema "õpetajamudeli" käitumist. Õpilasmudel õpib õpetaja väljundeid ligikaudselt jäljendama, saavutades sageli sarnase jõudluse oluliselt väiksema parameetrite arvuga.

**Mudeli arhitektuuri optimeerimine**: Teadlased on välja töötanud spetsiaalsed arhitektuurid, mis on mõeldud spetsiaalselt serva juurutamiseks, nagu MobileNets, EfficientNets ja muud kerged arhitektuurid, mis tasakaalustavad jõudlust ja arvutustõhusust.

### Väikesed keelemudelid (SLM)

EdgeAI-s on esile kerkinud trend väikeste keelemudelite (SLM) arendamisel. Need mudelid on algusest peale loodud kompaktseks ja tõhusaks, pakkudes samal ajal tähenduslikke loomuliku keele võimekusi. SLM-id saavutavad selle läbi hoolikate arhitektuurivalikute, tõhusate treenimistehnikate ja keskendunud treenimise konkreetsetele domeenidele või ülesannetele.

Erinevalt traditsioonilistest lähenemistest, mis hõlmavad suurte mudelite tihendamist, treenitakse SLM-e sageli väiksemate andmekogumite ja optimeeritud arhitektuuridega, mis on spetsiaalselt serva juurutamiseks mõeldud. See lähenemine võib tuua kaasa mudeleid, mis on mitte ainult väiksemad, vaid ka tõhusamad konkreetsete kasutusjuhtumite jaoks.

## Riistvarakiirendus EdgeAI jaoks

Kaasaegsed servaseadmed sisaldavad üha enam spetsiaalset riistvara, mis on mõeldud AI töökoormuste kiirendamiseks:

### Neuraaltöötlusüksused (NPU-d)

NPU-d on spetsiaalsed protsessorid, mis on mõeldud spetsiaalselt neuralvõrkude arvutuste jaoks. Need kiibid suudavad AI järeldusülesandeid täita palju tõhusamalt kui traditsioonilised CPU-d, sageli madalama energiatarbimisega. Paljud kaasaegsed nutitelefonid, sülearvutid ja IoT seadmed sisaldavad nüüd NPU-sid, et võimaldada seadmesisest AI töötlemist.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Seadmed NPU-dega hõlmavad:

- **Apple**: A-seeria ja M-seeria kiibid Neural Engine'iga
- **Qualcomm**: Snapdragon protsessorid Hexagon DSP/NPU-ga
- **Samsung**: Exynos protsessorid NPU-ga
- **Intel**: Movidius VPU-d ja Habana Labs kiirendid
- **Microsoft**: Windows Copilot+ PC-d NPU-dega

### 🎮 GPU kiirendus

Kuigi servaseadmetel ei pruugi olla andmekeskustes leiduvate võimsate GPU-dega võrreldavat jõudlust, sisaldavad paljud siiski integreeritud või eraldiseisvaid GPU-sid, mis suudavad AI töökoormusi kiirendada. Kaasaegsed mobiilsed GPU-d ja integreeritud graafikaprotsessorid võivad pakkuda AI järeldusülesannete jaoks märkimisväärset jõudluse paranemist.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU optimeerimine

Isegi ainult CPU-ga seadmed võivad EdgeAI-st kasu saada läbi optimeeritud rakenduste. Kaasaegsed CPU-d sisaldavad spetsiaalseid juhiseid AI töökoormuste jaoks ning tarkvararaamistikud on välja töötatud, et maksimeerida CPU jõudlust AI järelduste jaoks.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

EdgeAI-ga töötavate tarkvarainseneride jaoks on kriitiline mõista, kuidas kasutada neid riistvarakiirenduse võimalusi, et optimeerida järelduste jõudlust ja energiatõhusust sihtseadmetel.

## EdgeAI eelised

### Privaatsus ja turvalisus

Üks EdgeAI suurimaid eeliseid on paranenud privaatsus ja turvalisus. Töötledes andmeid kohapeal seadmes, ei lahku tundlik teave kunagi kasutaja kontrolli alt. See on eriti oluline rakenduste puhul, mis käsitlevad isikuandmeid, meditsiinilist teavet või konfidentsiaalseid ärilisi andmeid.

### Vähendatud latentsus

EdgeAI kõrvaldab vajaduse saata andmeid kaugserveritesse töötlemiseks, vähendades oluliselt latentsust. See on kriitiline reaalajas rakenduste jaoks, nagu autonoomsed sõidukid, tööstusautomaatika või interaktiivsed rakendused, kus on vaja koheseid vastuseid.

### Võrguühenduseta võimekus

EdgeAI võimaldab AI funktsionaalsust isegi siis, kui internetiühendus puudub. See on väärtuslik rakenduste jaoks kaugemates asukohtades, reisimise ajal või olukordades, kus võrgu usaldusväärsus on probleem.

### Kulutõhusus

Vähendades sõltuvust pilvepõhistest AI teenustest, võib EdgeAI aidata vähendada tegevuskulusid, eriti rakenduste puhul, millel on suur kasutusmaht. Organisatsioonid saavad vältida pidevaid API kulusid ja vähendada ribalaiuse nõudeid.

### Skaleeritavus

EdgeAI jaotab arvutuskoormuse servaseadmete vahel, mitte ei tsentraliseeri seda andmekeskustes. See võib aidata vähendada taristukulusid ja parandada kogu süsteemi skaleeritavust.

## EdgeAI rakendused

### Nutiseadmed ja IoT

EdgeAI toetab paljusid nutiseadmete funktsioone, alates häälassistentidest, mis suudavad käske kohapeal töödelda, kuni nutikaamerateni, mis suudavad tuvastada objekte ja inimesi ilma videot pilve saatmata. IoT seadmed kasutavad EdgeAI-d ennustava hoolduse, keskkonnaseire ja automatiseeritud otsuste tegemiseks.

### Mobiilirakendused

Nutitelefonid ja tahvelarvutid kasutavad EdgeAI-d mitmesuguste funktsioonide jaoks, sealhulgas fototöötlus, reaalajas tõlkimine, liitreaalsus ja isikupärastatud soov
- [02: EdgeAI Rakendused](02.RealWorldCaseStudies.md)

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valesti tõlgenduste eest.