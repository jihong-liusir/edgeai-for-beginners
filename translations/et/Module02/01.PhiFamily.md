<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-10-11T12:24:20+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "et"
}
-->
# Section 1: Microsoft Phi mudelite perekonna põhialused

Microsofti Phi mudelite perekond esindab tehisintellekti paradigmas muutust, näidates, et kompaktsed ja tõhusad mudelid suudavad saavutada silmapaistvaid tulemusi, olles samal ajal oluliselt ressursisäästlikumad kui traditsioonilised suured keelemudelid. Oluline on mõista, kuidas Phi perekond võimaldab võimsaid AI-võimeid väiksemate arvutusnõuetega, säilitades samas kõrge jõudluse erinevates ülesannetes.

## Ressursid arendajatele

### Azure AI Foundry mudelikataloog
Phi mudelite perekond (välja arvatud Phi-silica) on saadaval [Azure AI Foundry mudelikataloogi](https://ai.azure.com/explore/models?q=phi) kaudu, mis teeb arendajatele lihtsaks nende mudelite kasutamise, peenhäälestamise ja rakendustes juurutamise. Kataloog pakub sujuvat viisi erinevate Phi variantide katsetamiseks ja nende integreerimiseks oma projektidesse.

### Azure AI Foundry
Phi mudeleid saab juurutada ja katsetada [Azure AI Foundry](https://ai.azure.com) keskkonnas, mis pakub terviklikku platvormi AI lahenduste loomiseks, testimiseks ja juurutamiseks minimaalse seadistusega.

### Foundry Local
Kohalikuks arenduseks ja juurutamiseks tutvu [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) lahendusega, mis võimaldab Phi mudeleid käivitada arendusmasinas optimeeritud konfiguratsioonidega.

### Dokumentatsiooni ressursid
- [Microsoft Research: Phi mudelite tehnilised aruanded](https://ai.azure.com/labs/projects/phi-4)
- [Phi Kokkaraamat](https://aka.ms/phicookbook)

## Sissejuhatus

Selles õppetükis uurime Microsofti Phi mudelite perekonda ja selle põhikontseptsioone. Käsitleme Phi perekonna arengut, uuenduslikke treeningmetoodikaid, mis muudavad Phi mudelid tõhusaks, perekonna peamisi variante ja praktilisi rakendusi erinevates olukordades.

## Õppe-eesmärgid

Selle õppetüki lõpuks suudad:

- Mõista Microsofti Phi mudelite perekonna disainifilosoofiat ja arengut.
- Tuvastada peamised uuendused, mis võimaldavad Phi mudelitel saavutada kõrge jõudluse väiksema parameetrite arvuga.
- Tunnustada erinevate Phi mudelite variantide eeliseid ja piiranguid.
- Rakendada teadmisi Phi mudelitest, et valida sobivaid variante reaalses maailmas kasutamiseks.

## Traditsioonilise AI mudeli paradigma mõistmine

Traditsiooniliselt nõudis kõrge jõudluse saavutamine loomuliku keele töötlemises massiivseid keelemudeleid, millel on miljardeid või sadu miljardeid parameetreid. Organisatsioonid juurutavad tavaliselt neid mudeleid võimsates GPU klastrites, kasutades nende võimeid API-liideste või spetsiaalse riistvara kaudu.

Kuigi see lähenemine töötab paljude rakenduste puhul hästi, on sellel praktilise juurutamise osas olulisi piiranguid. Traditsiooniline meetod hõlmab mudeleid, mis vajavad märkimisväärseid arvutusressursse, suurt mälumahtu ja suurt energiatarbimist. Kuigi see lähenemine pakub tipptasemel võimeid, tekitab see sõltuvusi kallistest riistvaradest, suurendab tegevuskulusid ja piirab juurutamise paindlikkust.

## Tõhusa AI juurutamise väljakutse

Tõhusama AI vajadus on muutunud üha olulisemaks erinevates olukordades. Mõtle rakendustele, mis vajavad kohalikku juurutamist privaatsuse huvides, kulutundlikele lahendustele, kus pilve API kulud muutuvad takistuseks, serva arvutamise stsenaariumidele piiratud riistvararesurssidega või reaalajas rakendustele, kus latentsus on kriitiline.

### Peamised juurutamise piirangud

Traditsiooniliste suurte mudelite juurutamine seisab silmitsi mitmete põhiliste piirangutega, mis piiravad nende praktilist rakendatavust:

- **Kulupiirangud**: Suured arvutuskulud muudavad pideva juurutamise paljudele organisatsioonidele kalliks.
- **Ressursipiirangud**: Piiratud juurdepääs tipptasemel GPU infrastruktuurile piirab juurutamisvõimalusi.
- **Privaatsusnõuded**: Tundlikud rakendused vajavad kohalikku töötlemist, et säilitada andmete privaatsus.
- **Latentsustundlikkus**: Reaalajas rakendused vajavad viivitamatuid vastuseid ilma pilvega seotud viivitusteta.

## Microsofti Phi mudelite filosoofia

Microsofti Phi mudelite perekond esindab AI mudelite disainifilosoofia fundamentaalset muutust, keskendudes tõhususele ja praktilisele juurutamisele, säilitades samas tugeva jõudluse. Phi mudelid saavutavad selle uuenduslike arhitektuuride, kvaliteetsete treeningmetoodikate ja spetsiaalsete optimeerimistehnikate abil.

Phi perekond hõlmab erinevaid lähenemisviise, mis on loodud maksimeerima jõudlust parameetri kohta, võimaldades juurutamist tavapärasel riistvaral ja pakkudes samal ajal olulisi AI-võimeid. Eesmärk on säilitada konkurentsivõimeline jõudlus, vähendades oluliselt arvutusnõudeid, mälukasutust ja tegevuskulusid.

### Phi disaini põhialused

Phi mudelid põhinevad mitmel põhimõttel, mis eristavad neid traditsioonilistest suurtest keelemudelitest:

- **Tõhusus esikohal**: Optimeeritud maksimaalse jõudluse saavutamiseks parameetri kohta, mitte absoluutse mastaabi järgi.
- **Kvaliteetne treening**: Keskendutakse kvaliteetsele, kureeritud treeningandmestikule, mitte massiivsetele andmehulkadele.
- **Juurutamise paindlikkus**: Loodud töötama tõhusalt erinevatel riistvarakonfiguratsioonidel.
- **Spetsialiseeritud võimed**: Sageli optimeeritud konkreetsete ülesannete või valdkondade jaoks, et maksimeerida tõhusust.

## Tehnoloogiad, mis võimaldavad Phi perekonda

### "Õpiku" treeningmeetod

Üks Phi perekonna kõige revolutsioonilisemaid aspekte on "õpiku kvaliteediga" treeningmetoodika. Selle asemel, et treenida massiivsete filtreerimata internetiandmete peal, kasutavad Phi mudelid hoolikalt kureeritud, kvaliteetset hariduslikku sisu, mis on loodud tõhusalt õpetama loogikat, matemaatikat, kodeerimist ja üldteadmisi.

See lähenemine töötab, luues sünteetilist hariduslikku sisu, mis peegeldab kvaliteetseid õpikuid ja akadeemilisi materjale. Treeningandmed on spetsiaalselt loodud pedagoogiliselt mõistlikuks, keskendudes selgetele selgitustele, samm-sammulisele loogikale ja struktureeritud teadmiste esitamisele.

### Täiustatud loogikatreening

Viimased Phi mudelid sisaldavad keerukaid loogikatreeningu metoodikaid, mis võimaldavad lahendada keerulisi mitmeastmelisi probleeme. Need tehnikad hõlmavad:

**Chain-of-Thought treening**: Mudelid õpivad jagama keerulisi probleeme vahepealseteks loogikaetappideks, muutes nende probleemilahendusprotsessi läbipaistvamaks ja usaldusväärsemaks.

**Inference-Time Scaling**: Mudelid genereerivad üksikasjalikke loogikaahelaid, mis kasutavad vastuse genereerimise ajal täiendavaid arvutusressursse, et parandada täpsust.

**Edge-of-Capability treening**: Treeningandmed valitakse spetsiaalselt mudeli praeguste võimete piiril, et edendada keeruliste loogikamustrite õppimist.

### Arhitektuurilised uuendused

Phi perekond sisaldab mitmeid arhitektuurilisi optimeerimisi, mis on loodud spetsiaalselt tõhususe jaoks:

**Parameetrite tõhusus**: Hoolikalt valitud arhitektuurilised lahendused, mis maksimeerivad iga mudeli parameetri mõju.

**Multimodaalne integreerimine**: Tõhus tekst-, visuaal- ja kõnetöötluse integreerimine kompaktsetes arhitektuurides.

**Riistvara optimeerimine**: Spetsiaalsed variandid, mis on optimeeritud konkreetsete riistvaraplatvormide ja juurutamisstsenaariumide jaoks.

## Riistvara optimeerimine Phi mudelite jaoks

Kaasaegsed juurutamiskeskkonnad saavad kasu Phi mudelite tõhususest erinevates riistvarakonfiguratsioonides:

### CPU-optimeeritud juurutamine

Phi mudelid on loodud tõhusalt töötama ainult CPU-riistvaral, muutes need juurutatavaks tavapärasel arvutustaristul ilma spetsiaalsete AI kiirenditeta.

### GPU kiirendus

Kuigi Phi mudelid ei vaja võimsaid GPU-sid, saavad nad kasutada olemasolevaid GPU ressursse jõudluse parandamiseks, pakkudes paindlikkust juurutamiskonfiguratsioonides.

### Servaseadmete integreerimine

Spetsiaalsed variandid, nagu Phi-3-Silica, on optimeeritud konkreetsete serva arvutamise platvormide jaoks, saavutades märkimisväärseid tõhususnäitajaid, näiteks 650 tokenit sekundis vaid 1,5W energiatarbimisega.

## Phi mudelite perekonna eelised

### Kulutõhusus

Phi mudelid vähendavad oluliselt tegevuskulusid, nõudes oluliselt vähem arvutustaristut, säilitades samas konkurentsivõimelise jõudluse. See muudab AI kättesaadavaks organisatsioonidele, kellel on piiratud eelarve või suuremahulised rakendused, kus iga päringu maksumus on oluline.

### Juurutamise paindlikkus

Phi mudelite tõhusus võimaldab juurutamist laias valikus riistvarakonfiguratsioonides, alates isiklikest sülearvutitest kuni ettevõtte serveriteni, pakkudes organisatsioonidele suuremat paindlikkust AI taristu valikutes.

### Privaatsus ja turvalisus

Phi mudelite tõhusus võimaldab kohalikku juurutamist privaatsustundlikes rakendustes, tagades, et tundlikud andmed ei lahku organisatsiooni kontrolli alt, pakkudes samal ajal võimsaid AI-võimeid.

### Reaalajas jõudlus

Vähendatud arvutusnõuded tähendavad kiiremaid päringuaegu, võimaldades reaalajas rakendusi, mis vajavad viivitamatuid vastuseid, ilma et see kahjustaks AI võimete kvaliteeti.

### Kättesaadav AI

Vähendades AI juurutamise takistusi, muudavad Phi mudelid arenenud AI-võimed kättesaadavaks organisatsioonidele, kellel on piiratud ressursid, võimaldades väiksematel meeskondadel ja üksikarendajatel kasutada keerukaid keelemõistmise võimeid.

## Praktilised näited ja kasutusjuhtumid

Enne tehnilise arengu süvenemist uurime mõningaid konkreetseid näiteid, mida Phi mudelid suudavad saavutada:

### Matemaatilise loogika näide

Phi-4-mini-reasoning paistab silma samm-sammulise matemaatilise probleemilahenduse osas. Näiteks, kui küsida "Kuidas lahendada 3*x^2+4*x+5=1?", pakub mudel üksikasjalikke loogikaetappe:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Mitmekeelne tugi näide

Phi-3.5-mini-instruct demonstreerib tugevat mitmekeelset võimekust erinevates keeltes. Siin on näide küsimuse vormingust:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Multimodaalsed võimed näide

Phi-4-multimodal suudab samaaegselt töödelda teksti, pilte ja kõnet. Siin on mõned praktilised rakendused:

**Reisiplaneerimine kõne sisendi abil:**
Vaata, kuidas Phi-4 Multimodal analüüsib kõnekeelt, et aidata planeerida reisi Seattle'isse, demonstreerides selle arenenud kõnetöötluse ja soovituste võimeid.

**Matemaatiliste probleemide lahendamine piltidest:**
Vaata, kuidas Phi-4 Multimodal lahendab keerulisi matemaatilisi probleeme visuaalsete sisendite kaudu, demonstreerides selle võimet töödelda ja lahendada pilte sisaldavaid võrrandeid.

**Funktsioonikutsumise näide:**
Funktsioonikutsumise abil saavad Phi-4-mini ja Phi-4-multimodal laiendada oma tekstitöötluse võimeid, integreerides otsingumootoreid, ühendades erinevaid tööriistu ja palju muud. Näiteks mudel suudab Phi-4-mini abil hankida Premier League'i mänguinfot, näidates selle võimet sujuvalt suhelda väliste andmeallikatega.

### Koodi genereerimise näide

Phi-4-multimodal suudab genereerida struktureeritud projektikoodi nii pildisisu kui ka antud küsimuste põhjal, nagu näidatud praktilises töövoos:

1. Laadi üles pildi kujundus või disain.
2. Anna kontekst projekti nõuete kohta.
3. Mudel genereerib täielikud, funktsionaalsed koodistruktuurid.
4. Koodi saab kohandada konkreetsete raamistikute või keelte järgi.

### Serva juurutamise näide

Saame juurutada kvantiseeritud mudeli servaseadmetes. Kombineerides Microsoft Olive'i ja ONNX GenAI Runtime'i, saame juurutada Phi-4-mini Windowsis, iPhone'is, Androidis ja teistel seadmetel. See on näide, mis töötab iPhone 12 Pro peal.

Juurutamisprotsess hõlmab:
- Mudeli kvantiseerimist mobiili optimeerimiseks.
- ONNX runtime'i integreerimist platvormidevaheliseks ühilduvuseks.
- Kohalikku päringut ilma internetiühenduseta.
- Reaalajas jõudlust minimaalse energiatarbimisega.

## Phi perekonna areng

### Phi-1 ja Phi-2: Alusmudelid

Varased Phi mudelid kehtestasid kvaliteetsete treeningandmete ja tõhusate arhitektuuride põhimõtted:

- **Phi-1 (1.3B parameetrit)**: Tutvustas kureeritud treeningandmete kontseptsiooni põhilise keelemõistmise ja koodi genereerimise jaoks.
- **Phi-2 (2.7B parameetrit)**: Parandas loogikavõimeid sünteetiliste NLP andmete ja hoolikalt filtreeritud veebisisu abil.

### Phi-3 perekond: Peavoolu kasutuselevõtt

Phi-3 seeria tähistas läbimurret SLM võimekuses mitme spetsialiseeritud variandiga:

- **Phi-3-mini (3.8B parameetrit)**: Üldised keeleülesanded erakordse tõhususega, ületades kaks korda suuremaid mudeleid.
- **Phi-3-small (7B parameetrit)**: Täiustatud jõudlus, mis ületab GPT-3.5 Turbo mitmel võrdlusnäitajal.
- **Phi-3-medium (14B parameetrit)**: Ettevõtte tasemel jõudlus, mis ületab Gemini 1.0 Pro.
- **Phi-3-vision (4.2B parameetrit)**: Multimodaalsed võimed piltide ja teksti töötlemiseks.
- **Phi-3-Silica (3.3B parameetrit)**: Spetsiaalne optimeerimine Windows 11 sisseehitatud juurutamiseks.

### Phi-4 perekond: Täiustatud loogika

Viimane põlvkond nihutab loogikavõimekuse piire:

- **Phi-4 (14B parameetrit)**: Keerulise loogika spetsialiseerumine, eriti matemaatikas.
- **Phi-4-mini (3.8B parameetrit)**: Täiustatud loogika funktsioonikutsumise ja pika konteksti toega.
- **Phi-4-multimodal**: Samaaegne kõne-, visuaal- ja tekstitöötluse võimekus.
- **Phi-4-reasoning (14B parameetrit)**: Spetsialiseeritud keeruliste mitmeastmeliste loogikaülesannete jaoks.
- **Phi-4-reasoning-plus (14B parameetrit)**: Täiustatud täpsus täiendava tugevdatud õppe kaudu.
- **Phi-4-mini-reasoning (3
Phi perekond näitab, et AI tuleviku rakendamine ei seisne ainult suuremate mudelite loomises, vaid targemate ja tõhusamate mudelite arendamises, mis suudavad edukalt töötada erinevates riistvarakeskkondades, säilitades samal ajal kõrged jõudlusstandardid.

## Arenduse ja integreerimise näited

### Kiire alustamine Transformeritega

Siin on juhend, kuidas alustada Phi mudelite kasutamist Hugging Face Transformers raamatukoguga:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Peenhäälestamise näide

Järgmine näide näitab, kuidas peenhäälestada Phi-4-mini-instruct konkreetsete ülesannete jaoks:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Spetsialiseeritud viipade vormingud

**Loogikaülesannete jaoks (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Matemaatiliste ülesannete jaoks (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobiilirakendused ONNX-iga

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Jõudluse võrdlused ja saavutused

Phi mudelite perekond on saavutanud märkimisväärseid tulemusi erinevates võrdlustes, sageli ületades palju suuremaid mudeleid:

### Olulised jõudluse saavutused

**Matemaatilise loogika tipptase:**
- Phi-4 saavutab 82,5% täpsuse AIME 2025 (matemaatikaolümpiaadi kvalifikatsioon)
- Phi-4-reasoning (14B) ületab DeepSeek-R1-Distill-70B (5x suurem) loogikaülesannete võrdlustes
- Phi-4-mini-reasoning (3.8B) konkureerib matemaatilise loogika ülesannetes mudelitega, mis on kaks korda suuremad

**Tõhususe saavutused:**
- Phi-3-Silica töötleb 650 tokenit sekundis, tarbides vaid 1,5W energiat
- Phi-4-mini (3.8B) saavutab sarnase jõudluse palju suuremate mudelitega

**Võrdluste tulemused:**
- **MMLU (Massiivne Multiteemaline Keeleline Mõistmine)**: Konkurentsivõimeline jõudlus 57 akadeemilises valdkonnas
- **HumanEval**: Tugevad koodi genereerimise võimed, eriti Pythonis
- **MGSM**: Mitmekeelne algkooli matemaatika probleemide lahendamine
- **DROP**: Keerukad mõistmise ja loogikaülesanded
- **SimpleQA**: Faktipõhiste vastuste täpsus

### 📊 Mudelite võrdlustabel

| Mudel | Parameetrid | Konteksti pikkus | Peamised tugevused | Parimad kasutusjuhtumid |
|-------|------------|----------------|---------------|----------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Üldine tõhusus | Mobiilirakendused, lihtsad vestlusrobotid |
| **Phi-3.5-mini** | 3.8B | 128K | Mitmekeelne tugi | Rahvusvahelised rakendused |
| **Phi-4-mini** | 3.8B | 128K | Täiustatud loogika, funktsioonide kutsumine | Äriautomaatika |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matemaatiline loogika | Haridusplatvormid |
| **Phi-4** | 14B | 32K | Keerukas loogika | Uurimistöö, arenenud analüüs |
| **Phi-4-reasoning** | 14B | 32K/64K | Mitmeastmeline loogika | Teaduslik arvutus |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimaalne täpsus loogikaülesannetes | Kriitiliste otsuste tegemine |
| **Phi-4-multimodal** | 5.6B | Muutuv | Kõne, visuaal, tekst | Multimeedia rakendused |

## Mudeli valiku juhend

### Põhirakenduste jaoks
- **Phi-3-mini**: Lihtne teksti genereerimine, põhiline küsimuste-vastuste süsteem, kiired vastused
- **Phi-4-mini**: Täiustatud loogika funktsioonide kutsumise võimekusega

### Matemaatiliste ja loogikaülesannete jaoks
- **Phi-4**: Keerukate matemaatiliste probleemide lahendamine ja loogika
- **Phi-4-reasoning**: Mitmeastmeline loogika koos detailsete selgitustega
- **Phi-4-reasoning-plus**: Maksimaalne täpsus kriitiliste loogikaülesannete jaoks
- **Phi-4-mini-reasoning**: Tõhus matemaatiline loogika ressursipiirangutega keskkondades

### Multimodaalsete rakenduste jaoks
- **Phi-3-vision**: Pildi ja teksti töötlemise kombinatsioonid
- **Phi-4-multimodal**: Kõikehõlmavad kõne-, visuaal- ja tekstivõimed

### Ettevõtte rakenduste jaoks
- **Phi-3-medium**: Täiustatud keeleline mõistmine ärirakenduste jaoks
- **Phi-3-Silica**: Optimeeritud konkreetsete riistvaraplatvormide jaoks

## Rakendusplatvormid ja juurdepääsetavus

### Pilveplatvormid
- **Azure AI Foundry**: Täisfunktsionaalne rakendus koos ettevõtte tööriistadega
- **Hugging Face**: Avatud lähtekoodiga mudelite hoidla ja kogukonna ressursid
- **NVIDIA API kataloog**: Mikroteenuste rakendamise võimalused

### Kohalikud arendusraamistikud
- **Ollama**: Kerge raamistik kohalike mudelite rakendamiseks
- **ONNX Runtime**: Optimeeritud erinevate riistvarakonfiguratsioonide jaoks  
- **DirectML**: Windowsi optimeeritud jõudlus
- **llama.cpp**: Platvormidevaheline järeldusmootor

### Õppematerjalid
- **Phi portaal**: Microsofti ametlik Phi dokumentatsiooni keskus
- **Phi kokaraamat**: Põhjalikud näited ja juhendid
- **Tehnilised aruanded**: Süvitsi uurimustööd arxivis
- **Kogukonna ruumid**: Hugging Face interaktiivsed demod

### Phi mudelitega alustamine

#### Arendusplatvormid
1. **Azure AI Foundry**: Lihtne kohalik CLI ja mudelite haldamine.
2. **Hugging Face Transformers**: Kiire kohalik katsetamine
3. **Ollama**: Lihtne kohalik rakendus testimiseks

#### Õppimise tee
1. **Mõista põhikontseptsioone**: Uuri põhjalikult disainiprintsiipe
2. **Katseta variante**: Proovi erinevaid Phi mudeleid, et mõista nende võimekust
3. **Harjuta rakendamist**: Rakenda mudeleid testkeskkondades
4. **Laienda rakendust**: Suurenda kasutust järk-järgult eduka piloodi põhjal

#### Parimad tavad
- **Alusta väikselt**: Alusta Phi-mini mudelitega esialgseks arenduseks
- **Optimeeri viipeid**: Kasuta korrektset vestlusvormingut parimate tulemuste saavutamiseks
- **Jälgi jõudlust**: Jälgi järelduskiirust ja täpsusmõõdikuid
- **Arvesta riistvaraga**: Sobita mudeli suurus olemasolevate arvutusressurssidega

## Kokkuvõte

Microsofti Phi mudelite perekond esindab revolutsioonilist lähenemist AI mudelite disainile, näidates, et väiksemad ja tõhusamad mudelid võivad saavutada märkimisväärseid tulemusi erinevates ülesannetes. Keskendudes kvaliteetsele treeningandmestikule ja arhitektuurilistele optimeerimistele, pakub Phi perekond erakordseid võimeid oluliselt väiksemate arvutusnõuetega võrreldes traditsiooniliste suurte keelemudelitega.

## Olulised õpieesmärgid

1. Mõista Microsofti Phi mudelite perekonna disainifilosoofiat ja arengut Phi-1-st Phi-4-ni
2. Tuvasta peamised uuendused, sealhulgas "õpiku kvaliteediga" treening ja arhitektuurilised optimeerimised
3. Tunnista erinevate Phi variantide eeliseid ja piiranguid erinevates rakendussituatsioonides
4. Rakenda teadmisi, et valida sobivad Phi mudelid konkreetsete kasutusjuhtumite ja riistvarapiirangute jaoks
5. Rakenda optimeerimistehnikaid Phi mudelite rakendamiseks ressursipiirangutega seadmetel
6. Selgita Phi mudelite perekonna arhitektuurilisi eeliseid võrreldes traditsiooniliste suurte keelemudelitega
7. Vali sobiv Phi variant konkreetsete rakenduste nõuete ja riistvarapiirangute põhjal
8. Rakenda Phi mudeleid nii pilve- kui ka servarakendustes optimeeritud konfiguratsioonidega
9. Rakenda kvantiseerimis- ja optimeerimistehnikaid, et parandada Phi mudelite jõudlust sihtseadmetel
10. Hinda kompromisse mudeli suuruse, jõudluse ja võimekuse vahel Phi perekonnas

## Mis edasi

- [02: Qwen perekonna põhialused](02.QwenFamily.md)

---

**Lahtiütlus**:  
See dokument on tõlgitud, kasutades AI tõlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi püüame tagada täpsust, palun arvestage, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algkeeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul on soovitatav kasutada professionaalset inimtõlget. Me ei vastuta selle tõlke kasutamisest tulenevate arusaamatuste või valede tõlgenduste eest.