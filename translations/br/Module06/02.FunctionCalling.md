<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-17T23:00:54+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "br"
}
-->
# Seção02: Chamadas de Função em Modelos de Linguagem Pequenos (SLMs)

## Índice
1. [O que é Chamada de Função?](../../../Module06)
2. [Como Funciona a Chamada de Função](../../../Module06)
3. [Cenários de Aplicação](../../../Module06)
4. [Configurando Chamadas de Função com Phi-4-mini e Ollama](../../../Module06)
5. [Trabalhando com Chamadas de Função do Qwen3](../../../Module06)
6. [Integração Local com Foundry](../../../Module06)
7. [Melhores Práticas e Solução de Problemas](../../../Module06)
8. [Exemplos Avançados](../../../Module06)

## O que é Chamada de Função?

A chamada de função é uma capacidade poderosa que permite que Modelos de Linguagem Pequenos (SLMs) interajam com ferramentas externas, APIs e serviços. Em vez de serem limitados aos seus dados de treinamento, os SLMs agora podem:

- **Conectar-se a APIs externas** (serviços meteorológicos, bancos de dados, motores de busca)
- **Executar funções específicas** com base em solicitações do usuário
- **Recuperar informações em tempo real** de várias fontes
- **Realizar tarefas computacionais** por meio de ferramentas especializadas
- **Encadear múltiplas operações** para fluxos de trabalho complexos

Essa capacidade transforma os SLMs de geradores de texto estáticos em agentes de IA dinâmicos que podem realizar tarefas do mundo real.

## Como Funciona a Chamada de Função

O processo de chamada de função segue um fluxo de trabalho sistemático:

### 1. Integração de Ferramentas
- **Ferramentas Externas**: SLMs podem se conectar a APIs meteorológicas, bancos de dados, serviços web e outros sistemas externos
- **Definições de Função**: Cada ferramenta é definida com parâmetros específicos, formatos de entrada/saída e descrições
- **Compatibilidade com APIs**: Ferramentas são integradas por meio de interfaces padronizadas (APIs REST, SDKs, etc.)

### 2. Definição de Função
As funções são definidas com três componentes principais:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Detecção de Intenção
- **Processamento de Linguagem Natural**: O SLM analisa a entrada do usuário para entender a intenção
- **Correspondência de Função**: Determina quais funções são necessárias para atender à solicitação
- **Extração de Parâmetros**: Identifica e extrai os parâmetros necessários da mensagem do usuário

### 4. Geração de Saída JSON
O SLM gera um JSON estruturado contendo:
- Nome da função a ser chamada
- Parâmetros necessários com valores apropriados
- Contexto de execução e metadados

### 5. Execução Externa
- **Validação de Parâmetros**: Garante que todos os parâmetros necessários estejam presentes e formatados corretamente
- **Execução da Função**: O aplicativo executa a função especificada com os parâmetros fornecidos
- **Tratamento de Erros**: Gerencia falhas, timeouts e respostas inválidas

### 6. Integração de Resposta
- **Processamento de Resultados**: A saída da função é retornada ao SLM
- **Integração de Contexto**: O SLM incorpora os resultados em sua resposta
- **Comunicação com o Usuário**: Apresenta as informações em um formato natural e conversacional

## Cenários de Aplicação

### Recuperação de Dados
Converta consultas em linguagem natural em chamadas de API estruturadas:
- **"Mostre meus pedidos recentes"** → Consulta ao banco de dados com ID do usuário e filtros de data
- **"Qual é a previsão do tempo em Tóquio?"** → Chamada de API meteorológica com parâmetro de localização
- **"Encontre e-mails de John na semana passada"** → Consulta ao serviço de e-mail com remetente e filtros de data

### Execução de Operações
Transforme solicitações do usuário em chamadas de função específicas:
- **"Agende uma reunião para amanhã às 14h"** → Integração com API de calendário
- **"Envie uma mensagem para a equipe"** → API de plataforma de comunicação
- **"Crie um backup dos meus arquivos"** → Operação no sistema de arquivos

### Tarefas Computacionais
Realize operações matemáticas ou lógicas complexas:
- **"Calcule juros compostos sobre $10.000 a 5% por 10 anos"** → Função de cálculo financeiro
- **"Analise este conjunto de dados para tendências"** → Ferramentas de análise estatística
- **"Otimize esta rota para entrega"** → Algoritmos de otimização de rotas

### Fluxos de Trabalho de Processamento de Dados
Encadeie múltiplas chamadas de função para operações complexas:
1. **Recupere dados** de várias fontes
2. **Analise e valide** as informações
3. **Transforme** os dados no formato necessário
4. **Armazene os resultados** em sistemas apropriados
5. **Gere relatórios** ou visualizações

### Integração com UI/UX
Permita atualizações dinâmicas na interface:
- **"Mostre os dados de vendas no painel"** → Geração e exibição de gráficos
- **"Atualize o mapa com novas localizações"** → Integração de dados geoespaciais
- **"Atualize a exibição de inventário"** → Sincronização de dados em tempo real

## Configurando Chamadas de Função com Phi-4-mini e Ollama

O Phi-4-mini da Microsoft suporta chamadas de função únicas e paralelas por meio do Ollama. Veja como configurá-lo:

### Pré-requisitos
- Versão 0.5.13 ou superior do Ollama
- Modelo Phi-4-mini (recomendado: `phi4-mini:3.8b-fp16`)

### Etapas de Instalação

#### 1. Instale e Execute o Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Crie um Template Customizado de ModelFile
Devido a limitações atuais nos templates padrão do Ollama, você precisa criar um ModelFile customizado com o seguinte template:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Crie o Modelo Customizado
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Exemplo de Chamada de Função Única

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Exemplo de Chamada de Função Paralela

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Trabalhando com Chamadas de Função do Qwen3

O Qwen3 oferece capacidades avançadas de chamada de função com excelente desempenho e flexibilidade. Veja como implementá-lo:

### Usando o Framework Qwen-Agent

O Qwen-Agent fornece um framework de alto nível que simplifica a implementação de chamadas de função:

#### Instalação
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Configuração Básica

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Implementação de Funções Customizadas

Você também pode definir funções customizadas para o Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Recursos Avançados do Qwen3

#### Controle de Modo de Pensamento
O Qwen3 suporta alternância dinâmica entre modos de pensamento e não-pensamento:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Chamadas de Função em Múltiplas Etapas
O Qwen3 se destaca em encadear múltiplas chamadas de função:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Integração Local com Foundry

O Foundry Local da Microsoft fornece uma API compatível com OpenAI para executar modelos localmente com maior privacidade e desempenho.

### Configuração e Instalação

#### Windows
Baixe o instalador na [página de lançamentos do Foundry Local](https://github.com/microsoft/Foundry-Local/releases) e siga as instruções de instalação.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Uso Básico

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Recursos Avançados do Foundry Local

#### Gerenciamento de Modelos
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Otimização de Desempenho
O Foundry Local seleciona automaticamente a melhor variante de modelo para seu hardware:
- **GPU CUDA**: Baixa modelos otimizados para GPU
- **NPU Qualcomm**: Usa variantes aceleradas por NPU
- **Apenas CPU**: Seleciona modelos otimizados para CPU

## Melhores Práticas e Solução de Problemas

### Melhores Práticas para Definição de Funções

#### 1. Nomes Claros e Descritivos
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Definições Abrangentes de Parâmetros
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Validação de Entrada e Tratamento de Erros
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Problemas Comuns e Soluções

#### Problema 1: Função Não Está Sendo Chamada
**Sintomas**: O modelo responde com texto em vez de chamar a função

**Soluções**:
1. **Verifique a descrição da função**: Certifique-se de que ela corresponde claramente à intenção do usuário
2. **Revise as definições de parâmetros**: Certifique-se de que todos os parâmetros necessários estão devidamente definidos
3. **Reveja o prompt do sistema**: Inclua instruções claras sobre quando usar funções
4. **Teste com solicitações explícitas**: Tente "Por favor, use a função meteorológica para obter dados de Londres"

#### Problema 2: Parâmetros Incorretos
**Sintomas**: Função chamada com parâmetros errados ou ausentes

**Soluções**:
1. **Adicione exemplos de parâmetros**: Inclua valores de exemplo nas descrições dos parâmetros
2. **Use restrições de enumeração**: Limite os valores dos parâmetros a opções específicas quando possível
3. **Implemente valores padrão**: Forneça padrões sensatos para parâmetros opcionais

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Problema 3: Falhas em Chamadas de Função Paralelas
**Sintomas**: Apenas uma função é executada quando várias deveriam ser

**Soluções**:
1. **Verifique o suporte do modelo**: Certifique-se de que seu modelo suporta chamadas de função paralelas
2. **Atualize o prompt do sistema**: Inclua "algumas ferramentas" ou "múltiplas ferramentas" na mensagem do sistema
3. **Use versões apropriadas do modelo**: Phi-4-mini:3.8b-fp16 recomendado para Ollama

#### Problema 4: Problemas de Template com Ollama
**Sintomas**: Chamadas de função não funcionam com a configuração padrão do Ollama

**Soluções**:
1. **Use ModelFile customizado**: Aplique o template corrigido fornecido neste tutorial
2. **Atualize o Ollama**: Certifique-se de que está usando a versão 0.5.13 ou superior
3. **Verifique a quantização do modelo**: Níveis de quantização mais altos (Q8_0, fp16) funcionam melhor do que versões altamente quantizadas

### Otimização de Desempenho

#### 1. Design Eficiente de Funções
- **Mantenha as funções focadas**: Cada função deve ter um único propósito claro
- **Minimize dependências externas**: Reduza chamadas de API e solicitações de rede sempre que possível
- **Cache de resultados**: Armazene dados frequentemente solicitados para melhorar os tempos de resposta

#### 2. Operações em Lote e Assíncronas
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Gerenciamento de Recursos
- **Pooling de conexões**: Reutilize conexões de banco de dados e APIs
- **Limitação de taxa**: Implemente limitação de taxa adequada para APIs externas
- **Tratamento de timeouts**: Defina timeouts razoáveis para todas as chamadas externas

## Exemplos Avançados

### Sistema de Colaboração Multi-Agente

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Sistema de Seleção Dinâmica de Ferramentas

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Formato padrão de resultado para todas as chamadas de função"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Agente de IA pronto para produção com capacidades abrangentes de chamada de função"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Inicializar funções principais de negócios
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Registrar todas as funções de negócios disponíveis"""
        
        # Funções de CRM
        self.register_function(
            name="get_customer_info",
            description="Recuperar informações do cliente do CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # chamadas por minuto
        )
        
        # Funções de Vendas
        self.register_function(
            name="create_sales_opportunity",
            description="Criar uma nova oportunidade de vendas",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Funções de Análise
        self.register_function(
            name="generate_sales_report",
            description="Gerar relatório de desempenho de vendas",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Funções de Notificação
        self.register_function(
            name="send_notification",
            description="Enviar notificação para membros da equipe",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Registrar uma nova função com o agente"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Por favor, forneça o conteúdo do arquivo Markdown que você deseja traduzir, e eu realizarei a tradução seguindo as regras especificadas.
"""Execute uma função com tratamento abrangente de erros e registro de logs"""
start_time = datetime.now()

try:
    # Validar se a função existe
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Função '{function_name}' não encontrada",
            timestamp=start_time
        )
    
    # Verificar limites de taxa
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Limite de taxa excedido para a função '{function_name}'",
            timestamp=start_time
        )
    
    # Validar parâmetros
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Executar função
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Registrar execução bem-sucedida
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Registrar execução com falha
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Verificar se a chamada da função está dentro dos limites de taxa"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Reiniciar contador se um minuto tiver passado
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Verificar se está dentro do limite
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Validar parâmetros da função"""
    func_params = self.functions[function_name]['parameters']
    
    # Verificar parâmetros obrigatórios
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Parâmetro obrigatório ausente: {param_name}"
            )
    
    # Validar tipos e restrições dos parâmetros
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Validação de tipo
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"O parâmetro '{param_name}' deve ser uma string"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"O parâmetro '{param_name}' deve ser um número"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"O parâmetro '{param_name}' deve ser um booleano"
                )
            
            # Validação de enum
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"O parâmetro '{param_name}' deve ser um dos seguintes: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Registrar chamada de função para fins de auditoria"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Opcionalmente, escrever em sistema de registro externo
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Escrever entrada de log em sistema de registro externo"""
    # A implementação dependeria da sua infraestrutura de registro
    # Ex.: enviar para ELK stack, CloudWatch, etc.
    pass

# Implementações de Funções de Negócio
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Recuperar informações do cliente do sistema CRM"""
    # Simular chamada de banco de dados/API
    await asyncio.sleep(0.1)  # Simular atraso de rede
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Produto A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Produto B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """Criar uma nova oportunidade de vendas"""
    # Simular chamada de API do CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """Gerar relatório abrangente de vendas"""
    # Simular agregação de dados
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'medium', channel: str = 'email') -> Dict:
    """Enviar notificação pelo canal especificado"""
    # Simular chamada ao serviço de notificações
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Obter definições de funções compatíveis com OpenAI para todas as funções registradas"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Exemplo de Uso para Integração Empresarial
async def enterprise_demo():
    """Demonstrar capacidades de agentes de IA empresariais"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Exemplo 1: Processamento de consulta de cliente
    print("=== Processamento de Consulta de Cliente ===")
    
    # Obter informações do cliente
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Informações do Cliente Recuperadas: {result.data['name']}")
        print(f"Tempo de Execução: {result.execution_time:.3f}s")
    
    # Exemplo 2: Criação de oportunidade de vendas
    print("\n=== Criação de Oportunidade de Vendas ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Oportunidade Criada: {result.data['opportunity_id']}")
    
    # Exemplo 3: Operações em lote
    print("\n=== Operações em Lote ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Nova oportunidade criada',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Tarefa {i+1} concluída com sucesso")
        else:
            print(f"Tarefa {i+1} falhou: {result.error}")
    
    # Exibir log de auditoria
    print(f"\n=== Log de Auditoria ({len(agent.audit_log)} entradas) ===")
    for entry in agent.audit_log[-3:]:  # Mostrar as últimas 3 entradas
        print(f"{entry['timestamp']}: {entry['function_name']} - {'SUCESSO' if entry['success'] else 'FALHA'}")

# Executar demonstração empresarial
# asyncio.run(enterprise_demo())

## Conclusão

A chamada de funções em Modelos de Linguagem Pequenos representa uma mudança de paradigma, transformando assistentes de IA estáticos em agentes dinâmicos e capazes de interagir com o mundo real. Este tutorial abordou:

### Principais Lições

1. **Entendimento Fundamental**: A chamada de funções permite que os SLMs se estendam além de seus dados de treinamento, conectando-se a ferramentas e serviços externos.

2. **Flexibilidade de Implementação**: Existem várias abordagens, desde implementações de baixo nível com templates personalizados até frameworks avançados como Qwen-Agent e Foundry Local.

3. **Considerações de Produção**: Implementações empresariais exigem atenção ao tratamento de erros, limites de taxa, segurança e registro de auditoria.

4. **Otimização de Desempenho**: Um design adequado de funções, execução eficiente e cache inteligente podem melhorar significativamente os tempos de resposta.

### Direções Futuras

À medida que a tecnologia SLM continua a evoluir, podemos esperar:

- **Melhoria na Precisão de Chamada de Funções**: Detecção de intenção e extração de parâmetros mais precisas
- **Processamento Paralelo Avançado**: Orquestração mais sofisticada de múltiplas funções
- **Melhores Padrões de Integração**: Protocolos padronizados para integração de ferramentas
- **Recursos de Segurança Avançados**: Mecanismos aprimorados de autenticação e autorização
- **Expansão do Ecossistema**: Biblioteca crescente de funções e integrações pré-construídas

### Como Começar

Para começar a implementar chamadas de funções em seus projetos:

1. **Comece Simples**: Inicie com cenários básicos de função única
2. **Escolha Seu Framework**: Decida entre implementação direta (Ollama/Phi-4) ou assistida por framework (Qwen-Agent)
3. **Desenhe Funções Cuidadosamente**: Foque em definições de funções claras e bem documentadas
4. **Implemente Tratamento de Erros**: Construa um tratamento robusto de erros desde o início
5. **Escale Gradualmente**: Progrida de cenários simples para complexos à medida que ganha experiência

A chamada de funções transforma os SLMs de geradores de texto impressionantes em agentes de IA práticos, capazes de resolver problemas do mundo real. Seguindo os padrões e práticas descritos neste tutorial, você pode construir sistemas de IA poderosos e confiáveis que vão além das interfaces de chat tradicionais.

### Recursos e Referências
- **Modelos Phi-4**: [Coleção Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Documentação Qwen3**: [Documentação Oficial do Qwen](https://qwen.readthedocs.io/)
- **Ollama**: [Site Oficial](https://ollama.com/)
- **Foundry Local**: [Repositório GitHub](https://github.com/microsoft/Foundry-Local)
- **Melhores Práticas para Chamadas de Função**: [Guia Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)

Lembre-se de que chamadas de função são um campo em constante evolução, e manter-se atualizado com os últimos desenvolvimentos nos frameworks e modelos escolhidos ajudará você a construir agentes de IA mais eficazes.


## ➡️ O que vem a seguir

- [03: Integração do Protocolo de Contexto de Modelo (MCP)](./03.IntroduceMCP.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automatizadas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações equivocadas decorrentes do uso desta tradução.