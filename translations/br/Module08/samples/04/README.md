<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T21:20:01+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "br"
}
-->
# Exemplo 04: Aplicativos de Chat para Produ√ß√£o com Chainlit

Um exemplo abrangente demonstrando v√°rias abordagens para construir aplicativos de chat prontos para produ√ß√£o usando o Microsoft Foundry Local, com interfaces web modernas, respostas em streaming e tecnologias avan√ßadas de navegador.

## O que est√° inclu√≠do

- **üöÄ Aplicativo de Chat Chainlit** (`app.py`): Aplicativo de chat pronto para produ√ß√£o com streaming
- **üåê Demonstra√ß√£o WebGPU** (`webgpu-demo/`): Infer√™ncia de IA baseada em navegador com acelera√ß√£o de hardware
- **üé® Integra√ß√£o com Open WebUI** (`open-webui-guide.md`): Interface profissional semelhante ao ChatGPT
- **üìö Notebook Educacional** (`chainlit_app.ipynb`): Materiais interativos de aprendizado

## In√≠cio R√°pido

### 1. Aplicativo de Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```
  
Abre em: `http://localhost:8080`

### 2. Demonstra√ß√£o WebGPU no Navegador

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```
  
Abre em: `http://localhost:5173`

### 3. Configura√ß√£o do Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```
  
Abre em: `http://localhost:3000`

## Padr√µes de Arquitetura

### Matriz de Decis√£o Local vs Nuvem

| Cen√°rio                  | Recomenda√ß√£o         | Motivo                          |
|--------------------------|----------------------|---------------------------------|
| **Dados Sens√≠veis**      | üè† Local (Foundry)   | Os dados nunca saem do dispositivo |
| **Racioc√≠nio Complexo**  | ‚òÅÔ∏è Nuvem (Azure OpenAI) | Acesso a modelos maiores       |
| **Chat em Tempo Real**   | üè† Local (Foundry)   | Menor lat√™ncia, respostas mais r√°pidas |
| **An√°lise de Documentos**| üîÑ H√≠brido           | Local para extra√ß√£o, nuvem para an√°lise |
| **Gera√ß√£o de C√≥digo**    | üè† Local (Foundry)   | Privacidade + modelos especializados |
| **Tarefas de Pesquisa**  | ‚òÅÔ∏è Nuvem (Azure OpenAI) | Necessidade de base de conhecimento ampla |

### Compara√ß√£o de Tecnologias

| Tecnologia   | Caso de Uso                  | Vantagens                     | Desvantagens                |
|--------------|------------------------------|-------------------------------|-----------------------------|
| **Chainlit** | Desenvolvedores Python, prototipagem r√°pida | Configura√ß√£o f√°cil, suporte a streaming | Apenas Python              |
| **WebGPU**   | M√°xima privacidade, cen√°rios offline | Nativo do navegador, sem necessidade de servidor | Tamanho limitado de modelo |
| **Open WebUI** | Implanta√ß√£o em produ√ß√£o, equipes | Interface profissional, gerenciamento de usu√°rios | Requer Docker              |

## Pr√©-requisitos

- **Foundry Local**: Instalado e em execu√ß√£o ([Download](https://aka.ms/foundry-local-installer))
- **Python**: Vers√£o 3.10+ com ambiente virtual
- **Modelo**: Pelo menos um carregado (`foundry model run phi-4-mini`)
- **Navegador**: Chrome/Edge com suporte a WebGPU para demonstra√ß√µes
- **Docker**: Para Open WebUI (opcional)

## Instala√ß√£o e Configura√ß√£o

### 1. Configura√ß√£o do Ambiente Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```
  
### 2. Configura√ß√£o do Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```
  

## Aplicativos de Exemplo

### Aplicativo de Chat Chainlit

**Recursos:**
- üöÄ **Streaming em Tempo Real**: Os tokens aparecem conforme s√£o gerados
- üõ°Ô∏è **Tratamento de Erros Robusto**: Degrada√ß√£o e recupera√ß√£o elegantes
- üé® **Interface Moderna**: Interface de chat profissional pronta para uso
- üîß **Configura√ß√£o Flex√≠vel**: Vari√°veis de ambiente e detec√ß√£o autom√°tica
- üì± **Design Responsivo**: Funciona em dispositivos desktop e m√≥veis

**In√≠cio R√°pido:**  
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```
  

### Demonstra√ß√£o WebGPU no Navegador

**Recursos:**
- üåê **IA Nativa do Navegador**: Sem necessidade de servidor, executa inteiramente no navegador
- ‚ö° **Acelera√ß√£o WebGPU**: Acelera√ß√£o de hardware quando dispon√≠vel
- üîí **M√°xima Privacidade**: Nenhum dado sai do seu dispositivo
- üéØ **Instala√ß√£o Zero**: Funciona em qualquer navegador compat√≠vel
- üîÑ **Fallback Elegante**: Reverte para CPU se WebGPU n√£o estiver dispon√≠vel

**Execu√ß√£o:**  
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```
  

### Integra√ß√£o com Open WebUI

**Recursos:**
- üé® **Interface Semelhante ao ChatGPT**: UI profissional e familiar
- üë• **Suporte Multiusu√°rio**: Contas de usu√°rio e hist√≥rico de conversas
- üìÅ **Processamento de Arquivos**: Upload e an√°lise de documentos
- üîÑ **Troca de Modelos**: Troca f√°cil entre diferentes modelos
- üê≥ **Implanta√ß√£o com Docker**: Configura√ß√£o pronta para produ√ß√£o em cont√™iner

**Configura√ß√£o R√°pida:**  
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```
  

## Refer√™ncia de Configura√ß√£o

### Vari√°veis de Ambiente

| Vari√°vel    | Descri√ß√£o                  | Padr√£o         | Exemplo               |
|-------------|----------------------------|----------------|-----------------------|
| `MODEL`     | Alias do modelo a ser usado | `phi-4-mini`   | `qwen2.5-7b-instruct` |
| `BASE_URL`  | Endpoint do Foundry Local  | Detectado automaticamente | `http://localhost:51211` |
| `API_KEY`   | Chave de API (opcional para local) | `""`          | `sua-chave-de-api`    |

## Solu√ß√£o de Problemas

### Problemas Comuns

**Aplicativo Chainlit:**

1. **Servi√ßo n√£o dispon√≠vel:**  
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```
  
2. **Conflitos de porta:**  
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```
  
3. **Problemas no ambiente Python:**  
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P ‚Üí Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```
  

**Demonstra√ß√£o WebGPU:**

1. **WebGPU n√£o suportado:**
   - Atualize para Chrome/Edge 113+
   - Habilite WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - Verifique o status da GPU: `chrome://gpu`
   - A demonstra√ß√£o reverter√° automaticamente para CPU

2. **Erros de carregamento de modelo:**
   - Certifique-se de que h√° conex√£o com a internet para download do modelo
   - Verifique o console do navegador para erros de CORS
   - Confirme que est√° servindo via HTTP (n√£o file://)

**Open WebUI:**

1. **Conex√£o recusada:**  
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```
  
2. **Modelos n√£o aparecem:**  
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```
  

### Lista de Valida√ß√£o

```cmd
# ‚úÖ 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# ‚úÖ 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# ‚úÖ 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```
  

## Uso Avan√ßado

### Otimiza√ß√£o de Desempenho

**Chainlit:**
- Use streaming para melhor percep√ß√£o de desempenho
- Implemente pooling de conex√µes para alta concorr√™ncia
- Cache de respostas de modelo para consultas repetidas
- Monitore o uso de mem√≥ria com hist√≥ricos de conversas grandes

**WebGPU:**
- Use WebGPU para m√°xima privacidade e velocidade
- Implemente quantiza√ß√£o de modelo para modelos menores
- Use Web Workers para processamento em segundo plano
- Cache modelos compilados no armazenamento do navegador

**Open WebUI:**
- Use volumes persistentes para hist√≥rico de conversas
- Configure limites de recursos para o cont√™iner Docker
- Implemente estrat√©gias de backup para dados de usu√°rios
- Configure proxy reverso para termina√ß√£o SSL

### Padr√µes de Integra√ß√£o

**H√≠brido Local/Nuvem:**  
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```
  
**Pipeline Multi-Modal:**  
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```
  

## Implanta√ß√£o em Produ√ß√£o

### Considera√ß√µes de Seguran√ßa

- **Chaves de API**: Use vari√°veis de ambiente, nunca codifique diretamente
- **Rede**: Use HTTPS em produ√ß√£o, considere VPN para acesso da equipe
- **Controle de Acesso**: Implemente autentica√ß√£o para Open WebUI
- **Privacidade de Dados**: Audite quais dados permanecem locais e quais v√£o para a nuvem
- **Atualiza√ß√µes**: Mantenha o Foundry Local e os cont√™ineres atualizados

### Monitoramento e Manuten√ß√£o

- **Verifica√ß√µes de Sa√∫de**: Implemente monitoramento de endpoints
- **Logs**: Centralize os logs de todos os componentes
- **M√©tricas**: Acompanhe tempos de resposta, taxas de erro e uso de recursos
- **Backup**: Backup regular dos dados de conversas e configura√ß√µes

## Refer√™ncias e Recursos

### Documenta√ß√£o
- [Documenta√ß√£o Chainlit](https://docs.chainlit.io/) - Guia completo do framework
- [Documenta√ß√£o Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Documenta√ß√£o oficial da Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - Integra√ß√£o com WebGPU
- [Documenta√ß√£o Open WebUI](https://docs.openwebui.com/) - Configura√ß√£o avan√ßada

### Arquivos de Exemplo
- [`app.py`](../../../../../Module08/samples/04/app.py) - Aplicativo Chainlit para produ√ß√£o
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook educacional
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Infer√™ncia de IA baseada em navegador
- [`open-webui-guide.md`](./open-webui-guide.md) - Configura√ß√£o completa do Open WebUI

### Exemplos Relacionados
- [Documenta√ß√£o da Sess√£o 4](../../04.CuttingEdgeModels.md) - Guia completo da sess√£o
- [Exemplos do Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Exemplos oficiais

---

