<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T08:33:14+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "br"
}
-->
# EdgeAI para Iniciantes: Caminhos de Aprendizado e Cronograma de Estudos

### Caminho de Aprendizado Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 2 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 3 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 4-5 | Módulo 4: Otimização de Modelos (6 frameworks) | 4 horas |
| Dia 6 | Módulo 5: SLMOps | 3 horas |
| Dia 7 | Módulo 6-7: Agentes de IA & Ferramentas de Desenvolvimento | 4 horas |
| Dia 8 | Módulo 8: Toolkit Local Foundry (Implementação Moderna) | 1 hora |

### Caminho de Aprendizado Concentrado (2 semanas)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Agentes de IA | 2 horas |
| Dia 13-14 | Módulo 7: Ferramentas de Desenvolvimento | 3 horas |

### Estudo em Meio Período (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implantação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Sistemas Agentes de SLM | 2 horas |
| Dia 13-14 | Módulo 7: Exemplos de Implementação de EdgeAI | 2 horas |

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|----------------|-------------|--------------|
| Módulo 0: Introdução ao EdgeAI | | | |
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implantação de SLM | | | |
| Módulo 4: Otimização de Modelos (6 frameworks) | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Sistemas Agentes de SLM | | | |
| Módulo 7: Exemplos de Implementação de EdgeAI | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

### Estudo em Meio Período (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implantação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

## Introdução

Bem-vindo ao guia de estudos "EdgeAI para Iniciantes"! Este documento foi criado para ajudá-lo a navegar pelos materiais do curso de forma eficaz e maximizar sua experiência de aprendizado. Ele oferece caminhos de aprendizado estruturados, cronogramas de estudo sugeridos, resumos de conceitos-chave e recursos complementares para aprofundar seu entendimento sobre tecnologias de Edge AI.

Este é um curso conciso de 20 horas que fornece conhecimentos essenciais sobre EdgeAI em um formato eficiente, ideal para profissionais ocupados e estudantes que desejam adquirir rapidamente habilidades práticas neste campo emergente.

## Visão Geral do Curso

Este curso está organizado em oito módulos abrangentes:

0. **Introdução ao EdgeAI** - Fundamentos e contexto com aplicações na indústria e objetivos de aprendizado  
1. **Fundamentos e Transformação do EdgeAI** - Compreensão dos conceitos principais e da mudança tecnológica  
2. **Fundamentos de Modelos de Linguagem Pequenos (SLM)** - Exploração de várias famílias de SLM e suas arquiteturas  
3. **Implantação de Modelos de Linguagem Pequenos (SLM)** - Estratégias práticas de implantação  
4. **Conversão de Formato de Modelos e Quantização** - Otimização avançada com 6 frameworks, incluindo OpenVINO  
5. **SLMOps - Operações de Modelos de Linguagem Pequenos** - Gerenciamento do ciclo de vida de produção e implantação  
6. **Sistemas Agentes de SLM** - Agentes de IA, chamadas de função e Protocolo de Contexto de Modelos  
7. **Exemplos de Implementação de EdgeAI** - Toolkit de IA, desenvolvimento no Windows e implementações específicas de plataforma  
8. **Microsoft Foundry Local – Toolkit Completo para Desenvolvedores** - Desenvolvimento local com integração híbrida ao Azure (Módulo 08)

## Como Usar Este Guia de Estudos

- **Aprendizado Progressivo**: Siga os módulos na ordem para uma experiência de aprendizado mais coerente  
- **Pontos de Verificação de Conhecimento**: Use as perguntas de autoavaliação após cada seção  
- **Prática Prática**: Complete os exercícios sugeridos para reforçar os conceitos teóricos  
- **Recursos Complementares**: Explore materiais adicionais para os tópicos que mais lhe interessam  

## Recomendações de Cronograma de Estudos

### Caminho de Aprendizado Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 6 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 8 horas |
| Dia 5 | Módulo 3: Implantação de SLM | 3 horas |
| Dia 6 | Módulo 8: Toolkit Local Foundry | 3 horas |

### Estudo em Meio Período (3 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 0: Introdução + Módulo 1: Fundamentos do EdgeAI | 7-9 horas |
| Semana 2 | Módulo 2: Fundamentos de SLM | 7-8 horas |
| Semana 3 | Módulo 3: Implantação de SLM (3h) + Módulo 8: Toolkit Local Foundry (2-3h) | 5-6 horas |

## Módulo 0: Introdução ao EdgeAI

### Objetivos de Aprendizado Principais

- Compreender o que é Edge AI e por que ele é relevante no cenário tecnológico atual  
- Identificar as principais indústrias transformadas pelo Edge AI e seus casos de uso específicos  
- Compreender as vantagens dos Modelos de Linguagem Pequenos (SLMs) para implantação em dispositivos de borda  
- Estabelecer expectativas claras de aprendizado e resultados para o curso completo  
- Reconhecer oportunidades de carreira e requisitos de habilidades no campo do Edge AI  

### Áreas de Foco de Estudo

#### Seção 1: Paradigma e Definição de Edge AI
- **Conceitos Prioritários**:  
  - Edge AI vs. processamento tradicional em nuvem  
  - A convergência de hardware, otimização de modelos e demandas de negócios  
  - Implantação de IA em tempo real, preservação de privacidade e eficiência de custos  

#### Seção 2: Aplicações na Indústria
- **Conceitos Prioritários**:  
  - Manufatura & Indústria 4.0: Manutenção preditiva e controle de qualidade  
  - Saúde: Imagens diagnósticas e monitoramento de pacientes  
  - Sistemas Autônomos: Veículos autônomos e transporte  
  - Cidades Inteligentes: Gestão de tráfego e segurança pública  
  - Tecnologia de Consumo: Smartphones, wearables e casas inteligentes  

#### Seção 3: Fundamentos de Modelos de Linguagem Pequenos
- **Conceitos Prioritários**:  
  - Características e comparações de desempenho dos SLMs  
  - Eficiência de parâmetros vs. trade-offs de capacidade  
  - Restrições de implantação em dispositivos de borda e estratégias de otimização  

#### Seção 4: Estrutura de Aprendizado e Caminho de Carreira
- **Conceitos Prioritários**:  
  - Arquitetura do curso e abordagem de domínio progressivo  
  - Habilidades técnicas e metas de implementação prática  
  - Oportunidades de avanço na carreira e aplicações na indústria  

### Perguntas de Autoavaliação

1. Quais são as três principais tendências tecnológicas que possibilitaram o Edge AI?  
2. Compare as vantagens e desafios do Edge AI em relação à IA baseada em nuvem.  
3. Nomeie três indústrias onde o Edge AI oferece valor crítico para os negócios e explique por quê.  
4. Como os Modelos de Linguagem Pequenos tornam o Edge AI prático para implantação no mundo real?  
5. Quais são as principais habilidades técnicas que você desenvolverá ao longo deste curso?  
6. Descreva a abordagem de aprendizado em quatro fases usada neste curso.  

### Exercícios Práticos

1. **Pesquisa de Indústria**: Escolha uma aplicação industrial e pesquise uma implementação real de Edge AI (30 minutos)  
2. **Exploração de Modelos**: Navegue pelos Modelos de Linguagem Pequenos disponíveis no Hugging Face e compare seus contadores de parâmetros e capacidades (30 minutos)  
3. **Planejamento de Aprendizado**: Revise a estrutura completa do curso e crie seu cronograma de estudo pessoal (15 minutos)  

### Materiais Complementares

- [Visão Geral do Mercado de Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Visão Geral de Modelos de Linguagem Pequenos - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Fundação de Computação de Borda](https://www.edgecomputing.org/)  

## Módulo 1: Fundamentos e Transformação do EdgeAI

### Objetivos de Aprendizado Principais

- Compreender as diferenças entre IA baseada em nuvem e IA baseada em borda  
- Dominar técnicas de otimização para ambientes com restrição de recursos  
- Analisar aplicações reais de tecnologias EdgeAI  
- Configurar um ambiente de desenvolvimento para projetos EdgeAI  

### Áreas de Foco de Estudo

#### Seção 1: Fundamentos do EdgeAI
- **Conceitos Prioritários**:  
  - Paradigmas de computação em borda vs. nuvem  
  - Técnicas de quantização de modelos  
  - Opções de aceleração de hardware (NPUs, GPUs, CPUs)  
  - Vantagens de privacidade e segurança  

- **Materiais Complementares**:  
  - [Documentação do TensorFlow Lite](https://www.tensorflow.org/lite)  
  - [GitHub do ONNX Runtime](https://github.com/microsoft/onnxruntime)  
  - [Documentação do Edge Impulse](https://docs.edgeimpulse.com)  

#### Seção 2: Estudos de Caso do Mundo Real
- **Conceitos Prioritários**:  
  - Ecossistema de modelos Microsoft Phi & Mu  
  - Implementações práticas em diferentes indústrias  
  - Considerações de implantação  

#### Seção 3: Guia de Implementação Prática
- **Conceitos Prioritários**:  
  - Configuração do ambiente de desenvolvimento  
  - Ferramentas de quantização e otimização  
  - Métodos de avaliação para implementações EdgeAI  

#### Seção 4: Hardware de Implantação em Borda
- **Conceitos Prioritários**:  
  - Comparações de plataformas de hardware  
  - Estratégias de otimização para hardware específico  
  - Considerações de implantação  

### Perguntas de Autoavaliação

1. Compare e contraste implementações de IA baseada em nuvem com IA baseada em borda.  
2. Explique três técnicas principais para otimizar modelos para implantação em borda.  
3. Quais são as principais vantagens de executar modelos de IA na borda?  
4. Descreva o processo de quantização de um modelo e como isso afeta o desempenho.  
5. Explique como diferentes aceleradores de hardware (NPUs, GPUs, CPUs) influenciam a implantação de EdgeAI.  

### Exercícios Práticos

1. **Configuração Rápida de Ambiente**: Configure um ambiente de desenvolvimento mínimo com os pacotes essenciais (30 minutos)  
2. **Exploração de Modelos**: Baixe e examine um modelo de linguagem pequeno pré-treinado (1 hora)  
3. **Quantização Básica**: Experimente uma quantização simples em um modelo pequeno (1 hora)  

## Módulo 2: Fundamentos de Modelos de Linguagem Pequenos

### Objetivos de Aprendizado Principais

- Compreender os princípios arquitetônicos de diferentes famílias de SLM  
- Comparar capacidades de modelos em diferentes escalas de parâmetros  
- Avaliar modelos com base em eficiência, capacidade e requisitos de implantação  
- Reconhecer casos de uso apropriados para diferentes famílias de modelos  

### Áreas de Foco de Estudo

#### Seção 1: Família de Modelos Microsoft Phi
- **Conceitos Prioritários**:  
  - Evolução da filosofia de design  
  - Arquitetura com foco em eficiência  
  - Capacidades especializadas  

#### Seção 2: Família Qwen
- **Conceitos Prioritários**:  
  - Contribuições de código aberto  
  - Opções de implantação escaláveis  
  - Arquitetura avançada de raciocínio  

#### Seção 3: Família Gemma
- **Conceitos Prioritários**:  
  - Inovação orientada por pesquisa  
  - Capacidades multimodais  
  - Otimização para dispositivos móveis  

#### Seção 4: Família BitNET
- **Conceitos Prioritários**:  
  - Tecnologia de quantização de 1-bit  
  - Framework de otimização de inferência  
  - Considerações de sustentabilidade  

#### Seção 5: Modelo Microsoft Mu
- **Conceitos Prioritários**:  
  - Arquitetura orientada para dispositivos  
  - Integração com sistemas Windows  
  - Operação com preservação de privacidade  

#### Seção 6: Phi-Silica
- **Conceitos Prioritários**:  
  - Arquitetura otimizada para NPU  
  - Métricas de desempenho  
  - Integração para desenvolvedores  

### Perguntas de Autoavaliação

1. Compare as abordagens arquitetônicas das famílias de modelos Phi e Qwen.  
2. Explique como a tecnologia de quantização do BitNET difere da quantização tradicional.  
3. Quais são as vantagens exclusivas do modelo Mu para integração com Windows?  
4. Descreva como o Phi-Silica utiliza hardware NPU para otimização de desempenho.  
5. Para um aplicativo móvel com conectividade limitada, qual família de modelos seria mais apropriada e por quê?  

### Exercícios Práticos  

1. **Comparação de Modelos**: Benchmark rápido de dois modelos SLM diferentes (1 hora)  
2. **Geração de Texto Simples**: Implementação básica de geração de texto com um modelo pequeno (1 hora)  
3. **Otimização Rápida**: Aplicar uma técnica de otimização para melhorar a velocidade de inferência (1 hora)  

## Módulo 3: Implantação de Modelos de Linguagem Pequenos  

### Objetivos de Aprendizagem  

- Selecionar modelos apropriados com base em restrições de implantação  
- Dominar técnicas de otimização para diferentes cenários de implantação  
- Implementar SLMs em ambientes locais e na nuvem  
- Projetar configurações prontas para produção em aplicações EdgeAI  

### Áreas de Foco de Estudo  

#### Seção 1: Aprendizado Avançado de SLM  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de parâmetros  
  - Técnicas avançadas de otimização  
  - Estratégias de aquisição de modelos  

#### Seção 2: Implantação em Ambiente Local  
- **Conceitos Prioritários**:  
  - Implantação na plataforma Ollama  
  - Soluções locais da Microsoft Foundry  
  - Análise comparativa de frameworks  

#### Seção 3: Implantação em Nuvem com Contêineres  
- **Conceitos Prioritários**:  
  - Inferência de alto desempenho com vLLM  
  - Orquestração de contêineres  
  - Implementação do ONNX Runtime  

### Perguntas de Autoavaliação  

1. Quais fatores devem ser considerados ao escolher entre implantação local e na nuvem?  
2. Compare Ollama e Microsoft Foundry Local como opções de implantação.  
3. Explique os benefícios da containerização para implantação de SLM.  
4. Quais são as principais métricas de desempenho a serem monitoradas em um SLM implantado na borda?  
5. Descreva um fluxo completo de implantação, desde a seleção do modelo até a implementação em produção.  

### Exercícios Práticos  

1. **Implantação Local Básica**: Implantar um SLM simples usando Ollama (1 hora)  
2. **Verificação de Desempenho**: Executar um benchmark rápido no modelo implantado (30 minutos)  
3. **Integração Simples**: Criar um aplicativo mínimo que utilize o modelo implantado (1 hora)  

## Módulo 4: Conversão de Formato e Quantização de Modelos  

### Objetivos de Aprendizagem  

- Dominar técnicas avançadas de quantização de 1-bit a 8-bit de precisão  
- Compreender estratégias de conversão de formato (GGUF, ONNX)  
- Implementar otimização em seis frameworks (Llama.cpp, Olive, OpenVINO, MLX, síntese de fluxo de trabalho)  
- Implantar modelos otimizados para ambientes de produção na borda em hardware Intel, Apple e multiplataforma  

### Áreas de Foco de Estudo  

#### Seção 1: Fundamentos de Quantização  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de precisão  
  - Trade-offs entre desempenho e precisão  
  - Otimização de uso de memória  

#### Seção 2: Implementação no Llama.cpp  
- **Conceitos Prioritários**:  
  - Implantação multiplataforma  
  - Otimização de formato GGUF  
  - Técnicas de aceleração de hardware  

#### Seção 3: Microsoft Olive Suite  
- **Conceitos Prioritários**:  
  - Otimização orientada por hardware  
  - Implantação em nível empresarial  
  - Fluxos de trabalho de otimização automatizados  

#### Seção 4: Toolkit OpenVINO  
- **Conceitos Prioritários**:  
  - Otimização para hardware Intel  
  - Framework de Compressão de Redes Neurais (NNCF)  
  - Implantação de inferência multiplataforma  
  - OpenVINO GenAI para implantação de LLM  

#### Seção 5: Framework Apple MLX  
- **Conceitos Prioritários**:  
  - Otimização para Apple Silicon  
  - Arquitetura de memória unificada  
  - Capacidades de ajuste fino com LoRA  

#### Seção 6: Síntese de Fluxo de Trabalho para Desenvolvimento de Edge AI  
- **Conceitos Prioritários**:  
  - Arquitetura de fluxo de trabalho unificado  
  - Árvores de decisão para seleção de frameworks  
  - Validação de prontidão para produção  
  - Estratégias para garantir longevidade  

### Perguntas de Autoavaliação  

1. Compare estratégias de quantização em diferentes níveis de precisão (1-bit a 8-bit).  
2. Explique as vantagens do formato GGUF para implantação na borda.  
3. Como a otimização orientada por hardware no Microsoft Olive melhora a eficiência de implantação?  
4. Quais são os principais benefícios do NNCF do OpenVINO para compressão de modelos?  
5. Descreva como o Apple MLX utiliza a arquitetura de memória unificada para otimização.  
6. Como a síntese de fluxo de trabalho ajuda na seleção de frameworks de otimização ideais?  

### Exercícios Práticos  

1. **Quantização de Modelos**: Aplicar diferentes níveis de quantização a um modelo e comparar os resultados (1 hora)  
2. **Otimização com OpenVINO**: Usar NNCF para comprimir um modelo para hardware Intel (1 hora)  
3. **Comparação de Frameworks**: Testar o mesmo modelo em três frameworks de otimização diferentes (1 hora)  
4. **Benchmark de Desempenho**: Medir o impacto da otimização na velocidade de inferência e uso de memória (1 hora)  

## Módulo 5: SLMOps - Operações de Modelos de Linguagem Pequenos  

### Objetivos de Aprendizagem  

- Compreender os princípios de gerenciamento do ciclo de vida do SLMOps  
- Dominar técnicas de destilação e ajuste fino para implantação na borda  
- Implementar estratégias de implantação em produção com monitoramento  
- Construir fluxos de trabalho de operações e manutenção de SLM em nível empresarial  

### Áreas de Foco de Estudo  

#### Seção 1: Introdução ao SLMOps  
- **Conceitos Prioritários**:  
  - Mudança de paradigma do SLMOps nas operações de IA  
  - Arquitetura com foco em eficiência de custos e privacidade  
  - Impacto estratégico nos negócios e vantagens competitivas  

#### Seção 2: Destilação de Modelos  
- **Conceitos Prioritários**:  
  - Técnicas de transferência de conhecimento  
  - Implementação do processo de destilação em duas etapas  
  - Fluxos de trabalho de destilação no Azure ML  

#### Seção 3: Estratégias de Ajuste Fino  
- **Conceitos Prioritários**:  
  - Ajuste fino eficiente em parâmetros (PEFT)  
  - Métodos avançados LoRA e QLoRA  
  - Treinamento multi-adaptador e otimização de hiperparâmetros  

#### Seção 4: Implantação em Produção  
- **Conceitos Prioritários**:  
  - Conversão e quantização de modelos para produção  
  - Configuração de implantação no Foundry Local  
  - Benchmark de desempenho e validação de qualidade  

### Perguntas de Autoavaliação  

1. Como o SLMOps difere do MLOps tradicional?  
2. Explique os benefícios da destilação de modelos para implantação na borda.  
3. Quais são as principais considerações para ajuste fino de SLMs em ambientes com recursos limitados?  
4. Descreva um pipeline completo de implantação em produção para aplicações de IA na borda.  

### Exercícios Práticos  

1. **Destilação Básica**: Criar um modelo menor a partir de um modelo maior (1 hora)  
2. **Experimento de Ajuste Fino**: Ajustar um modelo para um domínio específico (1 hora)  
3. **Pipeline de Implantação**: Configurar um pipeline básico de CI/CD para implantação de modelos (1 hora)  

## Módulo 6: Sistemas Agentes SLM - Agentes de IA e Chamadas de Função  

### Objetivos de Aprendizagem  

- Construir agentes inteligentes de IA para ambientes de borda usando Modelos de Linguagem Pequenos  
- Implementar capacidades de chamadas de função com fluxos de trabalho sistemáticos  
- Dominar a integração do Protocolo de Contexto de Modelo (MCP) para interação padronizada com ferramentas  
- Criar sistemas agentes sofisticados com mínima intervenção humana  

### Áreas de Foco de Estudo  

#### Seção 1: Agentes de IA e Fundamentos de SLM  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de agentes (reflexivos, baseados em modelo, baseados em objetivos, agentes de aprendizado)  
  - Análise de trade-offs entre SLM e LLM  
  - Padrões de design específicos para agentes na borda  
  - Otimização de recursos para agentes  

#### Seção 2: Chamadas de Função em Modelos de Linguagem Pequenos  
- **Conceitos Prioritários**:  
  - Implementação de fluxos de trabalho sistemáticos (detecção de intenção, saída JSON, execução externa)  
  - Implementações específicas de plataforma (Phi-4-mini, modelos Qwen selecionados, Microsoft Foundry Local)  
  - Exemplos avançados (colaboração multi-agente, seleção dinâmica de ferramentas)  
  - Considerações de produção (limitação de taxa, registro de auditoria, medidas de segurança)  

#### Seção 3: Integração do Protocolo de Contexto de Modelo (MCP)  
- **Conceitos Prioritários**:  
  - Arquitetura de protocolo e design de sistema em camadas  
  - Suporte a múltiplos backends (Ollama para desenvolvimento, vLLM para produção)  
  - Protocolos de conexão (modos STDIO e SSE)  
  - Aplicações reais (automação web, processamento de dados, integração de APIs)  

### Perguntas de Autoavaliação  

1. Quais são as principais considerações arquitetônicas para agentes de IA na borda?  
2. Como as chamadas de função ampliam as capacidades dos agentes?  
3. Explique o papel do Protocolo de Contexto de Modelo na comunicação entre agentes.  

### Exercícios Práticos  

1. **Agente Simples**: Construir um agente de IA básico com chamadas de função (1 hora)  
2. **Integração MCP**: Implementar MCP em uma aplicação de agente (30 minutos)  

## Módulo 7: Exemplos de Implementação de EdgeAI  

### Objetivos de Aprendizagem  

- Dominar o AI Toolkit para Visual Studio Code para fluxos de trabalho abrangentes de desenvolvimento de EdgeAI  
- Obter expertise na plataforma Windows AI Foundry e estratégias de otimização de NPU  
- Implementar EdgeAI em múltiplas plataformas de hardware e cenários de implantação  
- Construir aplicações EdgeAI prontas para produção com otimizações específicas de plataforma  

### Áreas de Foco de Estudo  

#### Seção 1: AI Toolkit para Visual Studio Code  
- **Conceitos Prioritários**:  
  - Ambiente abrangente de desenvolvimento de Edge AI dentro do VS Code  
  - Catálogo de modelos e descoberta para implantação na borda  
  - Testes locais, otimização e fluxos de trabalho de desenvolvimento de agentes  
  - Monitoramento de desempenho e avaliação para cenários de borda  

#### Seção 2: Guia de Desenvolvimento de EdgeAI no Windows  
- **Conceitos Prioritários**:  
  - Visão geral abrangente da plataforma Windows AI Foundry  
  - API Phi Silica para inferência eficiente em NPU  
  - APIs de Visão Computacional para processamento de imagens e OCR  
  - CLI do Foundry Local para desenvolvimento e testes locais  

#### Seção 3: Implementações Específicas de Plataforma  
- **Conceitos Prioritários**:  
  - Implantação no NVIDIA Jetson Orin Nano (67 TOPS de desempenho em IA)  
  - Aplicativos móveis com .NET MAUI e ONNX Runtime GenAI  
  - Soluções Azure EdgeAI com arquitetura híbrida nuvem-borda  
  - Otimização do Windows ML com suporte universal de hardware  
  - Aplicações Foundry Local com implementação RAG focada em privacidade  

### Perguntas de Autoavaliação  

1. Como o AI Toolkit simplifica o fluxo de trabalho de desenvolvimento de EdgeAI?  
2. Compare estratégias de implantação em diferentes plataformas de hardware.  
3. Quais são as vantagens do Windows AI Foundry para desenvolvimento na borda?  
4. Explique o papel da otimização de NPU em aplicações modernas de Edge AI.  
5. Como a API Phi Silica utiliza hardware NPU para otimização de desempenho?  
6. Compare os benefícios da implantação local vs. na nuvem para aplicações sensíveis à privacidade.  

### Exercícios Práticos  

1. **Configuração do AI Toolkit**: Configurar o AI Toolkit e otimizar um modelo (1 hora)  
2. **Windows AI Foundry**: Construir uma aplicação simples de IA no Windows usando a API Phi Silica (1 hora)  
3. **Implantação Multiplataforma**: Implantar o mesmo modelo em duas plataformas diferentes (1 hora)  
4. **Otimização de NPU**: Testar o desempenho da NPU com ferramentas do Windows AI Foundry (30 minutos)  

## Módulo 8: Microsoft Foundry Local – Kit de Ferramentas Completo para Desenvolvedores (Modernizado)  

### Objetivos de Aprendizagem  

- Instalar e configurar o Foundry Local com integração moderna de SDK  
- Implementar sistemas avançados de multi-agentes com padrões de coordenador  
- Construir roteadores inteligentes de modelos com seleção automática baseada em tarefas  
- Implantar soluções de IA prontas para produção com monitoramento abrangente  
- Integrar com Azure AI Foundry para cenários de implantação híbrida  
- Dominar padrões modernos de SDK com FoundryLocalManager e cliente OpenAI  

### Áreas de Foco de Estudo  

#### Seção 1: Instalação e Configuração Modernas  
- **Conceitos Prioritários**:  
  - Integração do SDK FoundryLocalManager  
  - Descoberta automática de serviços e monitoramento de saúde  
  - Padrões de configuração baseados em ambiente  
  - Considerações para implantação em produção  

#### Seção 2: Sistemas Avançados de Multi-Agentes  
- **Conceitos Prioritários**:  
  - Padrão de coordenador com agentes especialistas  
  - Especialização de agentes em recuperação, raciocínio e execução  
  - Mecanismos de loop de feedback para refinamento  
  - Monitoramento de desempenho e rastreamento de estatísticas  

#### Seção 3: Roteamento Inteligente de Modelos  
- **Conceitos Prioritários**:  
  - Algoritmos de seleção de modelos baseados em palavras-chave  
  - Suporte a múltiplos modelos (geral, raciocínio, código, criativo)  
  - Configuração de variáveis de ambiente para flexibilidade  
  - Verificação de saúde do serviço e tratamento de erros  

#### Seção 4: Implementação Pronta para Produção  
- **Conceitos Prioritários**:  
  - Tratamento abrangente de erros e mecanismos de fallback  
  - Monitoramento de solicitações e rastreamento de desempenho  
  - Exemplos interativos em Jupyter notebooks com benchmarks  
  - Padrões de integração com aplicações existentes  

### Perguntas de Autoavaliação  

1. Como a abordagem moderna do FoundryLocalManager difere de chamadas REST manuais?  
2. Explique o padrão de coordenador e como ele orquestra agentes especialistas.  
3. Como o roteador inteligente seleciona modelos apropriados com base no conteúdo da consulta?  
4. Quais são os principais componentes de um sistema de agentes de IA pronto para produção?  
5. Como implementar monitoramento abrangente de saúde para serviços do Foundry Local?  
6. Compare os benefícios da abordagem modernizada vs. padrões de implementação tradicionais.  

### Exercícios Práticos  

1. **Configuração do SDK Moderno**: Configurar o FoundryLocalManager com descoberta automática de serviços (30 minutos)  
2. **Sistema Multi-Agente**: Executar o coordenador avançado com agentes especialistas (30 minutos)  
3. **Roteamento Inteligente**: Testar o roteador de modelos com diferentes tipos de consulta (30 minutos)  
4. **Exploração Interativa**: Usar os Jupyter notebooks para explorar recursos avançados (45 minutos)  
5. **Implantação em Produção**: Implementar padrões de monitoramento e tratamento de erros (30 minutos)  
6. **Integração Híbrida**: Configurar cenários de fallback com Azure AI Foundry (30 minutos)  

## Guia de Alocação de Tempo  

Para ajudar você a aproveitar ao máximo o cronograma de 20 horas do curso, aqui está uma sugestão de como alocar seu tempo:  

| Atividade | Alocação de Tempo | Descrição |  
|-----------|-------------------|-----------|  
| Leitura de Materiais Essenciais | 9 horas | Foco nos conceitos essenciais de cada módulo |  
| Exercícios Práticos | 6 horas | Implementação prática de técnicas essenciais |
| Autoavaliação | 2 horas | Teste sua compreensão por meio de perguntas e reflexões |
| Mini-Projeto | 3 horas | Aplicação do conhecimento em uma pequena implementação prática |

### Áreas de Foco Principais por Restrição de Tempo

**Se você tem apenas 10 horas:**
- Complete o Módulo 0 (Introdução) e os Módulos 1, 2 e 3 (conceitos principais de EdgeAI)
- Realize pelo menos um exercício prático por módulo
- Foque em entender os conceitos principais, em vez de detalhes de implementação

**Se você pode dedicar as 20 horas completas:**
- Complete todos os oito módulos (incluindo Introdução)
- Realize os exercícios práticos principais de cada módulo
- Complete um mini-projeto do Módulo 7
- Explore pelo menos 2-3 recursos suplementares

**Se você tem mais de 20 horas:**
- Complete todos os módulos (incluindo Introdução) com exercícios detalhados
- Desenvolva múltiplos mini-projetos
- Explore técnicas avançadas de otimização no Módulo 4
- Implemente o deployment em produção a partir do Módulo 5

## Recursos Essenciais

Estes recursos cuidadosamente selecionados oferecem o maior valor para seu tempo de estudo limitado:

### Documentação Essencial
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - A ferramenta mais eficiente para otimização de modelos
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Forma mais rápida de implementar SLMs localmente
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referência para um modelo otimizado para edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit de ferramentas abrangente de otimização da Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente integrado de desenvolvimento EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Plataforma de desenvolvimento EdgeAI específica para Windows

### Ferramentas que Economizam Tempo
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acesso rápido a modelos e deployment
- [Gradio](https://www.gradio.app/docs/interface) - Desenvolvimento rápido de UI para demonstrações de IA
- [Microsoft Olive](https://github.com/microsoft/Olive) - Otimização simplificada de modelos
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferência eficiente em CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework de compressão de redes neurais
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit de ferramentas para deployment de modelos de linguagem grandes

## Modelo de Rastreamento de Progresso

Use este modelo simplificado para acompanhar seu progresso de aprendizado ao longo do curso de 20 horas:

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|--------------------|--------------|-------------------------|
| Módulo 0: Introdução ao EdgeAI | | | |
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Deployment de SLM | | | |
| Módulo 4: Otimização de Modelos | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Agentes de IA | | | |
| Módulo 7: Ferramentas de Desenvolvimento | | | |
| Módulo 8: Toolkit Local Foundry | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

## Ideias de Mini-Projetos

Considere realizar um destes projetos para praticar os conceitos de EdgeAI (cada um projetado para levar de 2 a 4 horas):

### Projetos para Iniciantes (2-3 horas cada)
1. **Assistente de Texto Edge**: Crie uma ferramenta simples de preenchimento de texto offline usando um modelo de linguagem pequeno
2. **Dashboard de Comparação de Modelos**: Construa uma visualização básica de métricas de desempenho entre diferentes SLMs
3. **Experimento de Otimização**: Meça o impacto de diferentes níveis de quantização no mesmo modelo base

### Projetos Intermediários (3-4 horas cada)
4. **Workflow com AI Toolkit**: Use o AI Toolkit do VS Code para otimizar e implementar um modelo do início ao fim
5. **Aplicativo Windows AI Foundry**: Crie um aplicativo Windows usando a API Phi Silica e otimização NPU
6. **Deployment Multiplataforma**: Implemente o mesmo modelo otimizado no Windows (OpenVINO) e em dispositivos móveis (.NET MAUI)
7. **Agente de Chamadas de Função**: Desenvolva um agente de IA com capacidades de chamadas de função para cenários edge

### Projetos de Integração Avançada (4-5 horas cada)
8. **Pipeline de Otimização OpenVINO**: Implemente a otimização completa de modelos usando NNCF e o toolkit GenAI
9. **Pipeline SLMOps**: Implemente um ciclo completo de vida de modelo, desde o treinamento até o deployment em edge
10. **Sistema Edge Multi-Modelo**: Implemente múltiplos modelos especializados trabalhando juntos em hardware edge
11. **Sistema de Integração MCP**: Construa um sistema agente usando o Model Context Protocol para interação com ferramentas

## Referências

- Microsoft Learn (Foundry Local)
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Introdução: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referência CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integração com SDKs de inferência: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Como usar Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compilar modelos Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agentes (visão geral): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Ferramentas de Otimização e Inferência
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (introdução): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integração ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html
- Frameworks de Deployment e Modelos
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (docs): https://docs.vllm.ai/
  - Ollama (introdução): https://github.com/ollama/ollama#get-started
- Ferramentas de Desenvolvimento (Windows e VS Code)
  - AI Toolkit para VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (visão geral): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Comunidade de Aprendizado

Participe da discussão e conecte-se com outros aprendizes:
- Discussões no GitHub no [repositório EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Conclusão

EdgeAI representa a vanguarda da implementação de inteligência artificial, trazendo capacidades poderosas diretamente para dispositivos enquanto aborda preocupações críticas sobre privacidade, latência e conectividade. Este curso de 20 horas fornece o conhecimento essencial e as habilidades práticas para começar a trabalhar com tecnologias EdgeAI imediatamente.

O curso é deliberadamente conciso e focado nos conceitos mais importantes, permitindo que você adquira rapidamente uma expertise valiosa sem um compromisso de tempo excessivo. Lembre-se de que a prática prática, mesmo com exemplos simples, é a chave para reforçar o que você aprendeu.

Boa aprendizagem!

---

