<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-17T22:11:14+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "br"
}
-->
# EdgeAI para Iniciantes: Caminhos de Aprendizado e Cronograma de Estudos

### Caminho de Aprendizado Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 2 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 3 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 4-5 | Módulo 4: Otimização de Modelos (6 frameworks) | 4 horas |
| Dia 6 | Módulo 5: SLMOps | 3 horas |
| Dia 7 | Módulo 6-7: Agentes de IA & Ferramentas de Desenvolvimento | 5 horas |

### Caminho de Aprendizado Concentrado (2 semanas)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Agentes de IA | 2 horas |
| Dia 13-14 | Módulo 7: Ferramentas de Desenvolvimento | 3 horas |

### Estudo em Meio Período (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implantação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Sistemas Agentes de SLM | 2 horas |
| Dia 13-14 | Módulo 7: Exemplos de Implementação de EdgeAI | 2 horas |

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|----------------|-------------|--------------|
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implantação de SLM | | | |
| Módulo 4: Otimização de Modelos (6 frameworks) | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Sistemas Agentes de SLM | | | |
| Módulo 7: Exemplos de Implementação de EdgeAI | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

### Estudo em Meio Período (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implantação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

## Introdução

Bem-vindo ao guia de estudos EdgeAI para Iniciantes! Este documento foi criado para ajudá-lo a navegar pelos materiais do curso de forma eficaz e maximizar sua experiência de aprendizado. Ele oferece caminhos de aprendizado estruturados, cronogramas de estudo sugeridos, resumos de conceitos-chave e recursos complementares para aprofundar seu entendimento sobre tecnologias de EdgeAI.

Este é um curso conciso de 20 horas que fornece conhecimentos essenciais sobre EdgeAI em um formato eficiente, ideal para profissionais ocupados e estudantes que desejam adquirir rapidamente habilidades práticas neste campo emergente.

## Visão Geral do Curso

O curso está organizado em sete módulos abrangentes:

1. **Fundamentos e Transformação do EdgeAI** - Compreendendo os conceitos principais e a mudança tecnológica
2. **Fundamentos de Modelos de Linguagem Pequenos (SLM)** - Explorando várias famílias de SLM e suas arquiteturas
3. **Implantação de Modelos de Linguagem Pequenos** - Implementando estratégias práticas de implantação
4. **Conversão de Formato de Modelos e Quantização** - Otimização avançada com 6 frameworks, incluindo OpenVINO
5. **SLMOps - Operações de Modelos de Linguagem Pequenos** - Gerenciamento do ciclo de vida e implantação em produção
6. **Sistemas Agentes de SLM** - Agentes de IA, chamadas de função e Protocolo de Contexto de Modelos
7. **Exemplos de Implementação de EdgeAI** - Ferramentas de IA, desenvolvimento no Windows e implementações específicas de plataforma

## Como Usar Este Guia de Estudos

- **Aprendizado Progressivo**: Siga os módulos na ordem para uma experiência de aprendizado mais coerente
- **Pontos de Verificação de Conhecimento**: Use as perguntas de autoavaliação após cada seção
- **Prática Prática**: Complete os exercícios sugeridos para reforçar os conceitos teóricos
- **Recursos Complementares**: Explore materiais adicionais para os tópicos que mais lhe interessam

## Recomendações de Cronograma de Estudos

### Caminho de Aprendizado Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|-----------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 6 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 8 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 6 horas |

### Estudo em Meio Período (3 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|-----------------|
| Semana 1 | Módulo 1: Fundamentos do EdgeAI | 6-7 horas |
| Semana 2 | Módulo 2: Fundamentos de SLM | 7-8 horas |
| Semana 3 | Módulo 3: Implantação de SLM | 5-6 horas |

## Módulo 1: Fundamentos e Transformação do EdgeAI

### Objetivos de Aprendizado Principais

- Compreender as diferenças entre IA baseada em nuvem e IA baseada em borda
- Dominar técnicas de otimização para ambientes com restrição de recursos
- Analisar aplicações reais de tecnologias EdgeAI
- Configurar um ambiente de desenvolvimento para projetos EdgeAI

### Áreas de Foco do Estudo

#### Seção 1: Fundamentos do EdgeAI
- **Conceitos Prioritários**: 
  - Paradigmas de computação em borda vs. nuvem
  - Técnicas de quantização de modelos
  - Opções de aceleração de hardware (NPUs, GPUs, CPUs)
  - Vantagens de privacidade e segurança

- **Materiais Complementares**:
  - [Documentação do TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub do ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentação do Edge Impulse](https://docs.edgeimpulse.com)

#### Seção 2: Estudos de Caso Reais
- **Conceitos Prioritários**: 
  - Ecossistema de modelos Microsoft Phi & Mu
  - Implementações práticas em diferentes indústrias
  - Considerações de implantação

#### Seção 3: Guia de Implementação Prática
- **Conceitos Prioritários**: 
  - Configuração do ambiente de desenvolvimento
  - Ferramentas de quantização e otimização
  - Métodos de avaliação para implementações EdgeAI

#### Seção 4: Hardware de Implantação em Borda
- **Conceitos Prioritários**: 
  - Comparações de plataformas de hardware
  - Estratégias de otimização para hardware específico
  - Considerações de implantação

### Perguntas de Autoavaliação

1. Compare e contraste implementações de IA baseadas em nuvem e em borda.
2. Explique três técnicas principais para otimizar modelos para implantação em borda.
3. Quais são as principais vantagens de executar modelos de IA na borda?
4. Descreva o processo de quantização de um modelo e como isso afeta o desempenho.
5. Explique como diferentes aceleradores de hardware (NPUs, GPUs, CPUs) influenciam a implantação de EdgeAI.

### Exercícios Práticos

1. **Configuração Rápida do Ambiente**: Configure um ambiente de desenvolvimento mínimo com os pacotes essenciais (30 minutos)
2. **Exploração de Modelos**: Baixe e examine um modelo de linguagem pequeno pré-treinado (1 hora)
3. **Quantização Básica**: Experimente uma quantização simples em um modelo pequeno (1 hora)
- Árvores de decisão para seleção de frameworks  
- Validação de prontidão para produção  
- Estratégias para garantir longevidade tecnológica  

### Perguntas de Autoavaliação  

1. Compare estratégias de quantização em diferentes níveis de precisão (1-bit a 8-bit).  
2. Explique as vantagens do formato GGUF para implantação em dispositivos de borda.  
3. Como a otimização orientada por hardware no Microsoft Olive melhora a eficiência de implantação?  
4. Quais são os principais benefícios do NNCF do OpenVINO para compressão de modelos?  
5. Descreva como o Apple MLX utiliza a arquitetura de memória unificada para otimização.  
6. Como a síntese de fluxos de trabalho ajuda na seleção de frameworks de otimização ideais?  

### Exercícios Práticos  

1. **Quantização de Modelos**: Aplique diferentes níveis de quantização a um modelo e compare os resultados (1 hora).  
2. **Otimização com OpenVINO**: Use o NNCF para comprimir um modelo para hardware Intel (1 hora).  
3. **Comparação de Frameworks**: Teste o mesmo modelo em três frameworks de otimização diferentes (1 hora).  
4. **Benchmark de Desempenho**: Meça o impacto da otimização na velocidade de inferência e uso de memória (1 hora).  

## Módulo 5: SLMOps - Operações com Modelos de Linguagem Pequenos  

### Objetivos de Aprendizado  

- Compreender os princípios de gerenciamento do ciclo de vida do SLMOps  
- Dominar técnicas de distilação e ajuste fino para implantação em dispositivos de borda  
- Implementar estratégias de implantação em produção com monitoramento  
- Construir fluxos de trabalho de operações e manutenção de SLMs em nível empresarial  

### Áreas de Estudo  

#### Seção 1: Introdução ao SLMOps  
- **Conceitos Prioritários**:  
  - Mudança de paradigma do SLMOps nas operações de IA  
  - Arquitetura eficiente em custos e com foco em privacidade  
  - Impacto estratégico nos negócios e vantagens competitivas  

#### Seção 2: Distilação de Modelos  
- **Conceitos Prioritários**:  
  - Técnicas de transferência de conhecimento  
  - Implementação do processo de distilação em duas etapas  
  - Fluxos de trabalho de distilação no Azure ML  

#### Seção 3: Estratégias de Ajuste Fino  
- **Conceitos Prioritários**:  
  - Ajuste fino eficiente em parâmetros (PEFT)  
  - Métodos avançados como LoRA e QLoRA  
  - Treinamento multi-adaptador e otimização de hiperparâmetros  

#### Seção 4: Implantação em Produção  
- **Conceitos Prioritários**:  
  - Conversão e quantização de modelos para produção  
  - Configuração de implantação com Foundry Local  
  - Benchmark de desempenho e validação de qualidade  

### Perguntas de Autoavaliação  

1. Como o SLMOps difere do MLOps tradicional?  
2. Explique os benefícios da distilação de modelos para implantação em dispositivos de borda.  
3. Quais são as principais considerações para ajuste fino de SLMs em ambientes com recursos limitados?  
4. Descreva um pipeline completo de implantação em produção para aplicações de IA em dispositivos de borda.  

### Exercícios Práticos  

1. **Distilação Básica**: Crie um modelo menor a partir de um modelo maior (1 hora).  
2. **Experimento de Ajuste Fino**: Ajuste fino de um modelo para um domínio específico (1 hora).  
3. **Pipeline de Implantação**: Configure um pipeline básico de CI/CD para implantação de modelos (1 hora).  

## Módulo 6: Sistemas Agentes SLM - Agentes de IA e Chamadas de Função  

### Objetivos de Aprendizado  

- Construir agentes inteligentes de IA para ambientes de borda usando Modelos de Linguagem Pequenos  
- Implementar capacidades de chamadas de função com fluxos de trabalho sistemáticos  
- Dominar a integração do Protocolo de Contexto de Modelo (MCP) para interação padronizada com ferramentas  
- Criar sistemas agentes sofisticados com intervenção humana mínima  

### Áreas de Estudo  

#### Seção 1: Agentes de IA e Fundamentos de SLM  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de agentes (reflexivos, baseados em modelo, baseados em objetivos, agentes de aprendizado)  
  - Análise de trade-offs entre SLM e LLM  
  - Padrões de design específicos para agentes em dispositivos de borda  
  - Otimização de recursos para agentes  

#### Seção 2: Chamadas de Função em Modelos de Linguagem Pequenos  
- **Conceitos Prioritários**:  
  - Implementação de fluxos de trabalho sistemáticos (detecção de intenção, saída em JSON, execução externa)  
  - Implementações específicas de plataforma (Phi-4-mini, modelos Qwen selecionados, Microsoft Foundry Local)  
  - Exemplos avançados (colaboração entre múltiplos agentes, seleção dinâmica de ferramentas)  
  - Considerações de produção (limitação de taxa, registro de auditoria, medidas de segurança)  

#### Seção 3: Integração do Protocolo de Contexto de Modelo (MCP)  
- **Conceitos Prioritários**:  
  - Arquitetura do protocolo e design de sistema em camadas  
  - Suporte multi-backend (Ollama para desenvolvimento, vLLM para produção)  
  - Protocolos de conexão (modos STDIO e SSE)  
  - Aplicações reais (automação web, processamento de dados, integração com APIs)  

### Perguntas de Autoavaliação  

1. Quais são as principais considerações arquitetônicas para agentes de IA em dispositivos de borda?  
2. Como as chamadas de função ampliam as capacidades dos agentes?  
3. Explique o papel do Protocolo de Contexto de Modelo na comunicação entre agentes.  

### Exercícios Práticos  

1. **Agente Simples**: Construa um agente de IA básico com chamadas de função (1 hora).  
2. **Integração MCP**: Implemente o MCP em uma aplicação de agente (30 minutos).  

## Módulo 7: Exemplos de Implementação de EdgeAI  

### Objetivos de Aprendizado  

- Dominar o AI Toolkit para Visual Studio Code para fluxos de trabalho abrangentes de desenvolvimento de EdgeAI  
- Obter expertise na plataforma Windows AI Foundry e estratégias de otimização de NPU  
- Implementar EdgeAI em múltiplas plataformas de hardware e cenários de implantação  
- Construir aplicações EdgeAI prontas para produção com otimizações específicas de plataforma  

### Áreas de Estudo  

#### Seção 1: AI Toolkit para Visual Studio Code  
- **Conceitos Prioritários**:  
  - Ambiente de desenvolvimento abrangente de EdgeAI dentro do VS Code  
  - Catálogo de modelos e descoberta para implantação em dispositivos de borda  
  - Fluxos de trabalho de teste local, otimização e desenvolvimento de agentes  
  - Monitoramento de desempenho e avaliação para cenários de borda  

#### Seção 2: Guia de Desenvolvimento EdgeAI no Windows  
- **Conceitos Prioritários**:  
  - Visão geral abrangente da plataforma Windows AI Foundry  
  - API Phi Silica para inferência eficiente em NPU  
  - APIs de Visão Computacional para processamento de imagens e OCR  
  - CLI do Foundry Local para desenvolvimento e teste local  

#### Seção 3: Implementações Específicas de Plataforma  
- **Conceitos Prioritários**:  
  - Implantação no NVIDIA Jetson Orin Nano (desempenho de IA de 67 TOPS)  
  - Aplicações móveis com .NET MAUI e ONNX Runtime GenAI  
  - Soluções Azure EdgeAI com arquitetura híbrida entre nuvem e borda  
  - Otimização Windows ML com suporte universal de hardware  
  - Aplicações Foundry Local com implementação RAG focada em privacidade  

### Perguntas de Autoavaliação  

1. Como o AI Toolkit simplifica o fluxo de trabalho de desenvolvimento de EdgeAI?  
2. Compare estratégias de implantação em diferentes plataformas de hardware.  
3. Quais são as vantagens do Windows AI Foundry para desenvolvimento em dispositivos de borda?  
4. Explique o papel da otimização de NPU em aplicações modernas de EdgeAI.  
5. Como a API Phi Silica utiliza hardware NPU para otimização de desempenho?  
6. Compare os benefícios de implantação local versus na nuvem para aplicações sensíveis à privacidade.  

### Exercícios Práticos  

1. **Configuração do AI Toolkit**: Configure o AI Toolkit e otimize um modelo (1 hora).  
2. **Windows AI Foundry**: Construa uma aplicação simples de IA no Windows usando a API Phi Silica (1 hora).  
3. **Implantação Multiplataforma**: Implante o mesmo modelo em duas plataformas diferentes (1 hora).  
4. **Otimização de NPU**: Teste o desempenho de NPU com ferramentas do Windows AI Foundry (30 minutos).  

## Guia de Alocação de Tempo  

Para ajudar você a aproveitar ao máximo as 20 horas do curso, aqui está uma sugestão de como alocar seu tempo:  

| Atividade | Alocação de Tempo | Descrição |  
|-----------|-------------------|-----------|  
| Leitura de Materiais Essenciais | 9 horas | Foco nos conceitos fundamentais de cada módulo |  
| Exercícios Práticos | 6 horas | Implementação prática das principais técnicas |  
| Autoavaliação | 2 horas | Teste de compreensão por meio de perguntas e reflexão |  
| Mini-Projeto | 3 horas | Aplicação do conhecimento em uma implementação prática |  

### Áreas de Foco por Restrições de Tempo  

**Se você tem apenas 10 horas:**  
- Complete os Módulos 1, 2 e 3 (conceitos fundamentais de EdgeAI).  
- Realize pelo menos um exercício prático por módulo.  
- Foque na compreensão dos conceitos principais em vez de detalhes de implementação.  

**Se você pode dedicar as 20 horas completas:**  
- Complete todos os sete módulos.  
- Realize os principais exercícios práticos de cada módulo.  
- Conclua um mini-projeto do Módulo 7.  
- Explore pelo menos 2-3 recursos complementares.  

**Se você tem mais de 20 horas:**  
- Complete todos os módulos com exercícios detalhados.  
- Construa múltiplos mini-projetos.  
- Explore técnicas avançadas de otimização no Módulo 4.  
- Implemente a implantação em produção do Módulo 5.  

## Recursos Essenciais  

Estes recursos cuidadosamente selecionados oferecem o maior valor para seu tempo de estudo limitado:  

### Documentação Essencial  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Ferramenta de otimização de modelos mais eficiente  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Forma mais rápida de implantar SLMs localmente  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referência para um modelo otimizado para borda  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit de ferramentas abrangente de otimização da Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente integrado de desenvolvimento de EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Plataforma de desenvolvimento EdgeAI específica para Windows  

### Ferramentas que Economizam Tempo  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acesso rápido a modelos e implantação  
- [Gradio](https://www.gradio.app/docs/interface) - Desenvolvimento rápido de interfaces para demonstrações de IA  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Otimização simplificada de modelos  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferência eficiente em CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework de compressão de redes neurais  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit de ferramentas para implantação de modelos de linguagem grandes  

## Conclusão  

EdgeAI representa a vanguarda da implementação de inteligência artificial, trazendo capacidades poderosas diretamente para dispositivos enquanto aborda preocupações críticas sobre privacidade, latência e conectividade. Este curso de 20 horas fornece o conhecimento essencial e as habilidades práticas para começar a trabalhar com tecnologias de EdgeAI imediatamente.  

O curso é deliberadamente conciso e focado nos conceitos mais importantes, permitindo que você adquira rapidamente expertise valiosa sem um compromisso de tempo excessivo. Lembre-se de que a prática prática, mesmo com exemplos simples, é a chave para reforçar o que você aprendeu.  

Boa aprendizagem!  

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automatizadas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações equivocadas decorrentes do uso desta tradução.