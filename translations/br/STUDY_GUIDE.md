<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T18:06:22+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "br"
}
-->
# EdgeAI para Iniciantes: Caminhos de Aprendizado e Cronograma de Estudos

### Caminho de Aprendizado Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 2 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 3 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 4-5 | Módulo 4: Otimização de Modelos (6 frameworks) | 4 horas |
| Dia 6 | Módulo 5: SLMOps | 3 horas |
| Dia 7 | Módulo 6-7: Agentes de IA & Ferramentas de Desenvolvimento | 5 horas |

### Caminho de Aprendizado Concentrado (2 semanas)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Agentes de IA | 2 horas |
| Dia 13-14 | Módulo 7: Ferramentas de Desenvolvimento | 3 horas |

### Estudo em Meio Período (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implantação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implantação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Sistemas Agentes de SLM | 2 horas |
| Dia 13-14 | Módulo 7: Exemplos de Implementação de EdgeAI | 2 horas |

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|----------------|-------------|--------------|
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implantação de SLM | | | |
| Módulo 4: Otimização de Modelos (6 frameworks) | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Sistemas Agentes de SLM | | | |
| Módulo 7: Exemplos de Implementação de EdgeAI | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

### Estudo em Meio Período (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implantação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

## Introdução

Bem-vindo ao guia de estudos "EdgeAI para Iniciantes"! Este documento foi criado para ajudá-lo a navegar pelos materiais do curso de forma eficaz e maximizar sua experiência de aprendizado. Ele oferece caminhos de aprendizado estruturados, cronogramas de estudo sugeridos, resumos de conceitos-chave e recursos complementares para aprofundar seu entendimento sobre tecnologias de EdgeAI.

Este é um curso conciso de 20 horas que fornece conhecimentos essenciais sobre EdgeAI em um formato eficiente, ideal para profissionais ocupados e estudantes que desejam adquirir rapidamente habilidades práticas neste campo emergente.

## Visão Geral do Curso

Este curso está organizado em sete módulos abrangentes:

1. **Fundamentos e Transformação do EdgeAI** - Compreendendo os conceitos principais e a mudança tecnológica
2. **Fundamentos de Modelos de Linguagem Pequenos (SLM)** - Explorando várias famílias de SLM e suas arquiteturas
3. **Implantação de Modelos de Linguagem Pequenos (SLM)** - Implementando estratégias práticas de implantação
4. **Conversão de Formato de Modelos e Quantização** - Otimização avançada com 6 frameworks, incluindo OpenVINO
5. **SLMOps - Operações de Modelos de Linguagem Pequenos** - Gerenciamento do ciclo de vida e implantação em produção
6. **Sistemas Agentes de SLM** - Agentes de IA, chamadas de função e Protocolo de Contexto de Modelos
7. **Exemplos de Implementação de EdgeAI** - Ferramentas de IA, desenvolvimento no Windows e implementações específicas de plataforma
8. **Microsoft Foundry Local – Kit de Ferramentas Completo para Desenvolvedores** - Desenvolvimento local com integração híbrida ao Azure (Módulo 08)

## Como Usar Este Guia de Estudos

- **Aprendizado Progressivo**: Siga os módulos na ordem para uma experiência de aprendizado mais coerente
- **Pontos de Verificação de Conhecimento**: Use as perguntas de autoavaliação após cada seção
- **Prática Prática**: Complete os exercícios sugeridos para reforçar os conceitos teóricos
- **Recursos Complementares**: Explore materiais adicionais para os tópicos que mais lhe interessam

## Recomendações de Cronograma de Estudos

### Caminho de Aprendizado Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|-----------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 6 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 8 horas |
| Dia 5 | Módulo 3: Implantação de SLM | 3 horas |
| Dia 6 | Módulo 8: Kit de Ferramentas Foundry Local | 3 horas |

### Estudo em Meio Período (3 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|-----------------|
| Semana 1 | Módulo 1: Fundamentos do EdgeAI | 6-7 horas |
| Semana 2 | Módulo 2: Fundamentos de SLM | 7-8 horas |
| Semana 3 | Módulo 3: Implantação de SLM (3h) + Módulo 8: Kit de Ferramentas Foundry Local (2-3h) | 5-6 horas |

## Módulo 1: Fundamentos e Transformação do EdgeAI

### Objetivos de Aprendizado Principais

- Compreender as diferenças entre IA baseada em nuvem e IA baseada em borda
- Dominar técnicas de otimização para ambientes com restrição de recursos
- Analisar aplicações reais de tecnologias de EdgeAI
- Configurar um ambiente de desenvolvimento para projetos de EdgeAI

### Áreas de Foco do Estudo

#### Seção 1: Fundamentos do EdgeAI
- **Conceitos Prioritários**: 
  - Paradigmas de computação em borda vs. nuvem
  - Técnicas de quantização de modelos
  - Opções de aceleração de hardware (NPUs, GPUs, CPUs)
  - Vantagens de privacidade e segurança

- **Materiais Complementares**:
  - [Documentação do TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub do ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentação do Edge Impulse](https://docs.edgeimpulse.com)

#### Seção 2: Estudos de Caso Reais
- **Conceitos Prioritários**: 
  - Ecossistema de modelos Microsoft Phi & Mu
  - Implementações práticas em diferentes indústrias
  - Considerações de implantação

#### Seção 3: Guia de Implementação Prática
- **Conceitos Prioritários**: 
  - Configuração do ambiente de desenvolvimento
  - Ferramentas de quantização e otimização
  - Métodos de avaliação para implementações de EdgeAI

#### Seção 4: Hardware de Implantação em Borda
- **Conceitos Prioritários**: 
  - Comparações de plataformas de hardware
  - Estratégias de otimização para hardware específico
  - Considerações de implantação

### Perguntas de Autoavaliação

1. Compare e contraste a IA baseada em nuvem com implementações de IA baseada em borda.
2. Explique três técnicas principais para otimizar modelos para implantação em borda.
3. Quais são as principais vantagens de executar modelos de IA na borda?
4. Descreva o processo de quantização de um modelo e como isso afeta o desempenho.
5. Explique como diferentes aceleradores de hardware (NPUs, GPUs, CPUs) influenciam a implantação de EdgeAI.

### Exercícios Práticos

1. **Configuração Rápida do Ambiente**: Configure um ambiente de desenvolvimento mínimo com os pacotes essenciais (30 minutos)
2. **Exploração de Modelos**: Baixe e examine um modelo de linguagem pequeno pré-treinado (1 hora)
3. **Quantização Básica**: Experimente uma quantização simples em um modelo pequeno (1 hora)

## Módulo 2: Fundamentos de Modelos de Linguagem Pequenos

### Objetivos de Aprendizado Principais

- Compreender os princípios arquitetônicos de diferentes famílias de SLM
- Comparar capacidades de modelos em diferentes escalas de parâmetros
- Avaliar modelos com base em eficiência, capacidade e requisitos de implantação
- Reconhecer casos de uso apropriados para diferentes famílias de modelos

### Áreas de Foco do Estudo

#### Seção 1: Família de Modelos Microsoft Phi
- **Conceitos Prioritários**: 
  - Evolução da filosofia de design
  - Arquitetura com foco em eficiência
  - Capacidades especializadas

#### Seção 2: Família Qwen
- **Conceitos Prioritários**: 
  - Contribuições de código aberto
  - Opções de implantação escaláveis
  - Arquitetura avançada de raciocínio

#### Seção 3: Família Gemma
- **Conceitos Prioritários**: 
  - Inovação orientada por pesquisa
  - Capacidades multimodais
  - Otimização para dispositivos móveis

#### Seção 4: Família BitNET
- **Conceitos Prioritários**: 
  - Tecnologia de quantização de 1-bit
  - Framework de otimização de inferência
  - Considerações de sustentabilidade

#### Seção 5: Modelo Microsoft Mu
- **Conceitos Prioritários**: 
  - Arquitetura orientada para dispositivos
  - Integração com sistemas Windows
  - Operação com preservação de privacidade

#### Seção 6: Phi-Silica
- **Conceitos Prioritários**: 
  - Arquitetura otimizada para NPU
  - Métricas de desempenho
  - Integração para desenvolvedores

### Perguntas de Autoavaliação

1. Compare as abordagens arquitetônicas das famílias de modelos Phi e Qwen.
2. Explique como a tecnologia de quantização do BitNET difere da quantização tradicional.
3. Quais são as vantagens únicas do modelo Mu para integração com Windows?
4. Descreva como o Phi-Silica aproveita o hardware NPU para otimização de desempenho.
5. Para um aplicativo móvel com conectividade limitada, qual família de modelos seria mais apropriada e por quê?

### Exercícios Práticos

1. **Comparação de Modelos**: Benchmark rápido de dois modelos SLM diferentes (1 hora)
2. **Geração de Texto Simples**: Implementação básica de geração de texto com um modelo pequeno (1 hora)
3. **Otimização Rápida**: Aplique uma técnica de otimização para melhorar a velocidade de inferência (1 hora)

## Módulo 3: Implantação de Modelos de Linguagem Pequenos

### Objetivos de Aprendizado Principais

- Selecionar modelos apropriados com base em restrições de implantação
- Dominar técnicas de otimização para diversos cenários de implantação
- Implementar SLMs em ambientes locais e na nuvem
- Projetar configurações prontas para produção em aplicações de EdgeAI

### Áreas de Foco do Estudo

#### Seção 1: Aprendizado Avançado de SLM
- **Conceitos Prioritários**: 
  - Framework de classificação de parâmetros
  - Técnicas avançadas de otimização
  - Estratégias de aquisição de modelos

#### Seção 2: Implantação em Ambiente Local
- **Conceitos Prioritários**: 
  - Implantação na plataforma Ollama
  - Soluções locais Microsoft Foundry
  - Análise comparativa de frameworks

#### Seção 3: Implantação em Nuvem com Contêineres
- **Conceitos Prioritários**: 
  - Inferência de alto desempenho com vLLM
  - Orquestração de contêineres
  - Implementação com ONNX Runtime

### Perguntas de Autoavaliação

1. Quais fatores devem ser considerados ao escolher entre implantação local e na nuvem?
2. Compare Ollama e Microsoft Foundry Local como opções de implantação.
3. Explique os benefícios da conteinerização para implantação de SLM.
4. Quais são as principais métricas de desempenho a serem monitoradas para um SLM implantado na borda?
5. Descreva um fluxo completo de implantação, desde a seleção do modelo até a implementação em produção.

### Exercícios Práticos

1. **Implantação Local Básica**: Implante um SLM simples usando Ollama (1 hora)
2. **Verificação de Desempenho**: Execute um benchmark rápido no modelo implantado (30 minutos)
3. **Integração Simples**: Crie um aplicativo mínimo que utilize o modelo implantado (1 hora)

## Módulo 4: Conversão de Formato de Modelos e Quantização

### Objetivos de Aprendizado Principais

- Dominar técnicas avançadas de quantização de 1-bit a 8-bit de precisão
- Compreender estratégias de conversão de formato (GGUF, ONNX)
- Implementar otimização em seis frameworks (Llama.cpp, Olive, OpenVINO, MLX, síntese de workflow)
- Implantar modelos otimizados para ambientes de produção na borda em hardware Intel, Apple e multiplataforma

### Áreas de Foco do Estudo

#### Seção 1: Fundamentos de Quantização
- **Conceitos Prioritários**: 
  - Framework de classificação de precisão
  - Trade-offs entre desempenho e precisão
  - Otimização de footprint de memória

#### Seção 2: Implementação com Llama.cpp
- **Conceitos Prioritários**: 
  - Implantação multiplataforma
  - Otimização de formato GGUF
  - Técnicas de aceleração de hardware

#### Seção 3: Suite Microsoft Olive
- **Conceitos Prioritários**: 
  - Otimização orientada por hardware
  - Implantação em nível empresarial
  - Workflows automatizados de otimização

#### Seção 4: Toolkit OpenVINO
- **Conceitos Prioritários**: 
  - Otimização para hardware Intel
  - Framework de Compressão de Redes Neurais (NNCF)
  - Implantação de inferência multiplataforma
  - OpenVINO GenAI para implantação de LLM

#### Seção 5: Framework Apple MLX
- **Conceitos Prioritários**: 
  - Otimização para Apple Silicon
  - Arquitetura de memória unificada
  - Capacidades de ajuste fino com LoRA

#### Seção 6: Síntese do Fluxo de Trabalho de Desenvolvimento de Edge AI
- **Conceitos Prioritários**: 
  - Arquitetura de fluxo de trabalho unificada
  - Árvores de decisão para seleção de frameworks
  - Validação de prontidão para produção
  - Estratégias para garantir longevidade tecnológica

### Perguntas de Autoavaliação

1. Compare estratégias de quantização em diferentes níveis de precisão (1-bit a 8-bit).
2. Explique as vantagens do formato GGUF para implantação em edge.
3. Como a otimização orientada por hardware no Microsoft Olive melhora a eficiência de implantação?
4. Quais são os principais benefícios do NNCF do OpenVINO para compressão de modelos?
5. Descreva como o Apple MLX utiliza a arquitetura de memória unificada para otimização.
6. Como a síntese de fluxo de trabalho ajuda na seleção de frameworks de otimização ideais?

### Exercícios Práticos

1. **Quantização de Modelos**: Aplique diferentes níveis de quantização a um modelo e compare os resultados (1 hora)
2. **Otimização com OpenVINO**: Use o NNCF para comprimir um modelo para hardware Intel (1 hora)
3. **Comparação de Frameworks**: Teste o mesmo modelo em três frameworks de otimização diferentes (1 hora)
4. **Benchmark de Desempenho**: Meça o impacto da otimização na velocidade de inferência e uso de memória (1 hora)

## Módulo 5: SLMOps - Operações com Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem

- Compreender os princípios de gerenciamento do ciclo de vida do SLMOps
- Dominar técnicas de distilação e ajuste fino para implantação em edge
- Implementar estratégias de implantação em produção com monitoramento
- Construir fluxos de trabalho de operações e manutenção de SLMs em nível empresarial

### Áreas de Estudo

#### Seção 1: Introdução ao SLMOps
- **Conceitos Prioritários**: 
  - Mudança de paradigma do SLMOps nas operações de IA
  - Arquitetura com foco em eficiência de custos e privacidade
  - Impacto estratégico nos negócios e vantagens competitivas

#### Seção 2: Distilação de Modelos
- **Conceitos Prioritários**: 
  - Técnicas de transferência de conhecimento
  - Implementação do processo de distilação em duas etapas
  - Fluxos de trabalho de distilação no Azure ML

#### Seção 3: Estratégias de Ajuste Fino
- **Conceitos Prioritários**: 
  - Ajuste fino eficiente em parâmetros (PEFT)
  - Métodos avançados como LoRA e QLoRA
  - Treinamento multi-adaptador e otimização de hiperparâmetros

#### Seção 4: Implantação em Produção
- **Conceitos Prioritários**: 
  - Conversão e quantização de modelos para produção
  - Configuração de implantação com Foundry Local
  - Benchmark de desempenho e validação de qualidade

### Perguntas de Autoavaliação

1. Como o SLMOps difere do MLOps tradicional?
2. Explique os benefícios da distilação de modelos para implantação em edge.
3. Quais são as principais considerações para ajuste fino de SLMs em ambientes com recursos limitados?
4. Descreva um pipeline completo de implantação em produção para aplicações de IA em edge.

### Exercícios Práticos

1. **Distilação Básica**: Crie um modelo menor a partir de um modelo maior (1 hora)
2. **Experimento de Ajuste Fino**: Ajuste um modelo para um domínio específico (1 hora)
3. **Pipeline de Implantação**: Configure um pipeline básico de CI/CD para implantação de modelos (1 hora)

## Módulo 6: Sistemas Agentes SLM - Agentes de IA e Chamadas de Função

### Objetivos de Aprendizagem

- Construir agentes inteligentes de IA para ambientes edge usando Modelos de Linguagem Pequenos
- Implementar capacidades de chamadas de função com fluxos de trabalho sistemáticos
- Dominar a integração do Protocolo de Contexto de Modelo (MCP) para interação padronizada com ferramentas
- Criar sistemas agentes sofisticados com mínima intervenção humana

### Áreas de Estudo

#### Seção 1: Agentes de IA e Fundamentos de SLM
- **Conceitos Prioritários**: 
  - Framework de classificação de agentes (reflexivos, baseados em modelo, baseados em objetivos, agentes de aprendizado)
  - Análise de trade-offs entre SLM e LLM
  - Padrões de design de agentes específicos para edge
  - Otimização de recursos para agentes

#### Seção 2: Chamadas de Função em Modelos de Linguagem Pequenos
- **Conceitos Prioritários**: 
  - Implementação de fluxos de trabalho sistemáticos (detecção de intenção, saída em JSON, execução externa)
  - Implementações específicas de plataforma (Phi-4-mini, modelos Qwen selecionados, Microsoft Foundry Local)
  - Exemplos avançados (colaboração multi-agente, seleção dinâmica de ferramentas)
  - Considerações para produção (limitação de taxa, registro de auditoria, medidas de segurança)

#### Seção 3: Integração do Protocolo de Contexto de Modelo (MCP)
- **Conceitos Prioritários**: 
  - Arquitetura de protocolo e design de sistema em camadas
  - Suporte multi-backend (Ollama para desenvolvimento, vLLM para produção)
  - Protocolos de conexão (modos STDIO e SSE)
  - Aplicações reais (automação web, processamento de dados, integração com APIs)

### Perguntas de Autoavaliação

1. Quais são as principais considerações arquitetônicas para agentes de IA em edge?
2. Como as chamadas de função ampliam as capacidades dos agentes?
3. Explique o papel do Protocolo de Contexto de Modelo na comunicação entre agentes.

### Exercícios Práticos

1. **Agente Simples**: Construa um agente de IA básico com chamadas de função (1 hora)
2. **Integração MCP**: Implemente o MCP em uma aplicação de agente (30 minutos)

## Módulo 7: Exemplos de Implementação de EdgeAI

### Objetivos de Aprendizagem

- Dominar o AI Toolkit para Visual Studio Code para fluxos de trabalho abrangentes de desenvolvimento de EdgeAI
- Obter expertise na plataforma Windows AI Foundry e estratégias de otimização de NPU
- Implementar EdgeAI em múltiplas plataformas de hardware e cenários de implantação
- Construir aplicações EdgeAI prontas para produção com otimizações específicas de plataforma

### Áreas de Estudo

#### Seção 1: AI Toolkit para Visual Studio Code
- **Conceitos Prioritários**: 
  - Ambiente de desenvolvimento abrangente de Edge AI dentro do VS Code
  - Catálogo de modelos e descoberta para implantação em edge
  - Fluxos de trabalho de teste local, otimização e desenvolvimento de agentes
  - Monitoramento de desempenho e avaliação para cenários de edge

#### Seção 2: Guia de Desenvolvimento de EdgeAI no Windows
- **Conceitos Prioritários**: 
  - Visão geral abrangente da plataforma Windows AI Foundry
  - API Phi Silica para inferência eficiente em NPU
  - APIs de Visão Computacional para processamento de imagens e OCR
  - CLI do Foundry Local para desenvolvimento e teste local

#### Seção 3: Implementações Específicas de Plataforma
- **Conceitos Prioritários**: 
  - Implantação no NVIDIA Jetson Orin Nano (67 TOPS de desempenho em IA)
  - Aplicações móveis com .NET MAUI e ONNX Runtime GenAI
  - Soluções Azure EdgeAI com arquitetura híbrida cloud-edge
  - Otimização do Windows ML com suporte universal de hardware
  - Aplicações Foundry Local com implementação RAG focada em privacidade

### Perguntas de Autoavaliação

1. Como o AI Toolkit simplifica o fluxo de trabalho de desenvolvimento de EdgeAI?
2. Compare estratégias de implantação em diferentes plataformas de hardware.
3. Quais são as vantagens do Windows AI Foundry para desenvolvimento em edge?
4. Explique o papel da otimização de NPU em aplicações modernas de EdgeAI.
5. Como a API Phi Silica utiliza hardware NPU para otimização de desempenho?
6. Compare os benefícios de implantação local versus na nuvem para aplicações sensíveis à privacidade.

### Exercícios Práticos

1. **Configuração do AI Toolkit**: Configure o AI Toolkit e otimize um modelo (1 hora)
2. **Windows AI Foundry**: Construa uma aplicação simples de IA no Windows usando a API Phi Silica (1 hora)
3. **Implantação Multiplataforma**: Implante o mesmo modelo em duas plataformas diferentes (1 hora)
4. **Otimização de NPU**: Teste o desempenho da NPU com ferramentas do Windows AI Foundry (30 minutos)

## Módulo 8: Microsoft Foundry Local – Kit de Ferramentas Completo para Desenvolvedores

### Objetivos de Aprendizagem

- Instalar e configurar o Foundry Local no Windows
- Executar, descobrir e gerenciar modelos localmente via CLI do Foundry
- Integrar com clientes REST e SDK compatíveis com OpenAI
- Construir exemplos práticos: chat Chainlit, agentes e roteador de modelos
- Compreender padrões híbridos com Azure AI Foundry

### Áreas de Estudo

- Instalação e fundamentos do CLI (modelo, serviço, cache)
- Integração com SDK (clientes compatíveis com OpenAI e Azure OpenAI)
- Validação rápida com Open WebUI
- Padrões de agentes e chamadas de função
- Modelos como ferramentas (design de roteador e registro)

### Perguntas de Autoavaliação

1. Como descobrir o endpoint local e listar os modelos disponíveis?
2. Quais são as diferenças entre o uso do Foundry Local REST e Azure OpenAI?
3. Como você projetaria um roteador simples para selecionar modelos como ferramentas?
4. Quais categorias do CLI são mais relevantes para o desenvolvimento diário?
5. Como validar a prontidão do Foundry Local antes de executar aplicativos?

### Exercícios Práticos

1. Instale/atualize o Foundry Local e execute `phi-4-mini` localmente (30 minutos)
2. Chame `/v1/models` e execute um chat simples via REST (30 minutos)
3. Lance o exemplo de aplicativo Chainlit e converse localmente (30 minutos)
4. Execute o coordenador multi-agente e inspecione os resultados (30 minutos)
5. Experimente o roteador de modelos como ferramentas com substituições baseadas em ambiente (30 minutos)

## Guia de Alocação de Tempo

Para ajudar você a aproveitar ao máximo o cronograma de 20 horas do curso, aqui está uma sugestão de como alocar seu tempo:

| Atividade | Alocação de Tempo | Descrição |
|-----------|-------------------|-----------|
| Leitura de Materiais Principais | 9 horas | Foco nos conceitos essenciais de cada módulo |
| Exercícios Práticos | 6 horas | Implementação prática das principais técnicas |
| Autoavaliação | 2 horas | Teste de compreensão por meio de perguntas e reflexão |
| Mini-Projeto | 3 horas | Aplicação do conhecimento em uma implementação prática pequena |

### Áreas de Foco por Restrição de Tempo

**Se você tiver apenas 10 horas:**
- Complete os Módulos 1, 2 e 3 (conceitos principais de EdgeAI)
- Faça pelo menos um exercício prático por módulo
- Foque na compreensão dos conceitos principais em vez de detalhes de implementação

**Se puder dedicar as 20 horas completas:**
- Complete todos os sete módulos
- Realize os principais exercícios práticos de cada módulo
- Conclua um mini-projeto do Módulo 7
- Explore pelo menos 2-3 recursos suplementares

**Se tiver mais de 20 horas:**
- Complete todos os módulos com exercícios detalhados
- Construa múltiplos mini-projetos
- Explore técnicas avançadas de otimização no Módulo 4
- Implemente implantação em produção a partir do Módulo 5

## Recursos Essenciais

Esses recursos cuidadosamente selecionados oferecem o maior valor para seu tempo de estudo limitado:

### Documentação Essencial
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Ferramenta de otimização de modelos mais eficiente
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Forma mais rápida de implantar SLMs localmente
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referência para um modelo otimizado para edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit de ferramentas abrangente de otimização da Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente de desenvolvimento integrado para EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Plataforma de desenvolvimento de EdgeAI específica para Windows

### Ferramentas que Economizam Tempo
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acesso rápido a modelos e implantação
- [Gradio](https://www.gradio.app/docs/interface) - Desenvolvimento rápido de interface para demonstrações de IA
- [Microsoft Olive](https://github.com/microsoft/Olive) - Otimização simplificada de modelos
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferência eficiente em CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework de compressão de redes neurais
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit de ferramentas para implantação de modelos de linguagem grandes

## Modelo de Rastreamento de Progresso

Use este modelo simplificado para acompanhar seu progresso de aprendizado ao longo do curso de 20 horas:

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|-------------------|--------------|-------------------------|
| Módulo 1: Fundamentos de EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implantação de SLM | | | |
| Módulo 4: Otimização de Modelos | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Agentes de IA | | | |
| Módulo 7: Ferramentas de Desenvolvimento | | | |
| Módulo 8: Kit de Ferramentas Foundry Local | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

## Ideias de Mini-Projetos

Considere concluir um desses projetos para praticar conceitos de EdgeAI (cada um projetado para levar de 2 a 4 horas):

### Projetos para Iniciantes (2-3 horas cada)
1. **Assistente de Texto em Edge**: Crie uma ferramenta simples de conclusão de texto offline usando um modelo de linguagem pequeno
2. **Painel de Comparação de Modelos**: Construa uma visualização básica de métricas de desempenho entre diferentes SLMs
3. **Experimento de Otimização**: Meça o impacto de diferentes níveis de quantização no mesmo modelo base

### Projetos Intermediários (3-4 horas cada)
4. **Fluxo de Trabalho com AI Toolkit**: Use o AI Toolkit do VS Code para otimizar e implantar um modelo do início ao fim
5. **Aplicação com Windows AI Foundry**: Crie um aplicativo Windows usando a API Phi Silica e otimização de NPU
6. **Implantação Multiplataforma**: Implante o mesmo modelo otimizado no Windows (OpenVINO) e em dispositivos móveis (.NET MAUI)
7. **Agente com Chamadas de Função**: Construa um agente de IA com capacidades de chamadas de função para cenários em edge

### Projetos de Integração Avançada (4-5 horas cada)
8. **Pipeline de Otimização OpenVINO**: Implemente a otimização completa de modelos usando NNCF e o toolkit GenAI  
9. **Pipeline SLMOps**: Implemente um ciclo de vida completo de modelo, desde o treinamento até a implantação na borda  
10. **Sistema de Múltiplos Modelos na Borda**: Implante vários modelos especializados trabalhando juntos em hardware de borda  
11. **Sistema de Integração MCP**: Construa um sistema agente utilizando o Model Context Protocol para interação com ferramentas  

## Referências

- Microsoft Learn (Foundry Local)  
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Introdução: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Referência CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integração com SDKs de inferência: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Como abrir o WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Compilar modelos Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agentes (visão geral): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Ferramentas de Otimização e Inferência  
  - Microsoft Olive (documentação): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (introdução): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Integração do ONNX Runtime com Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (documentação): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (documentação): https://ml-explore.github.io/mlx/build/html/index.html  
- Frameworks de Implantação e Modelos  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (documentação): https://docs.vllm.ai/  
  - Ollama (introdução rápida): https://github.com/ollama/ollama#get-started  
- Ferramentas para Desenvolvedores (Windows e VS Code)  
  - AI Toolkit para VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (visão geral): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Comunidade de Aprendizado

Participe das discussões e conecte-se com outros aprendizes:  
- Discussões no GitHub no [repositório EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Conclusão

EdgeAI representa a vanguarda da implementação de inteligência artificial, trazendo capacidades poderosas diretamente para os dispositivos enquanto aborda preocupações críticas sobre privacidade, latência e conectividade. Este curso de 20 horas fornece o conhecimento essencial e as habilidades práticas para começar a trabalhar com tecnologias EdgeAI imediatamente.

O curso é propositalmente conciso e focado nos conceitos mais importantes, permitindo que você adquira rapidamente uma expertise valiosa sem um compromisso de tempo excessivo. Lembre-se de que a prática prática, mesmo com exemplos simples, é a chave para reforçar o que você aprendeu.

Boa aprendizagem!

---

