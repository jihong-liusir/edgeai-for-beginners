<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T23:53:47+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "br"
}
-->
# Seção 3: Ajuste Fino - Personalizando Modelos para Tarefas Específicas

## Índice
1. [Introdução ao Ajuste Fino](../../../Module05)
2. [Por que o Ajuste Fino é Importante](../../../Module05)
3. [Tipos de Ajuste Fino](../../../Module05)
4. [Ajuste Fino com Microsoft Olive](../../../Module05)
5. [Exemplos Práticos](../../../Module05)
6. [Melhores Práticas e Diretrizes](../../../Module05)
7. [Técnicas Avançadas](../../../Module05)
8. [Avaliação e Monitoramento](../../../Module05)
9. [Desafios Comuns e Soluções](../../../Module05)
10. [Conclusão](../../../Module05)

## Introdução ao Ajuste Fino

**Ajuste fino** é uma técnica poderosa de aprendizado de máquina que envolve adaptar um modelo pré-treinado para realizar tarefas específicas ou trabalhar com conjuntos de dados especializados. Em vez de treinar um modelo do zero, o ajuste fino aproveita o conhecimento já aprendido por um modelo pré-treinado e o ajusta para seu caso de uso particular.

### O que é Ajuste Fino?

O ajuste fino é uma forma de **aprendizado por transferência**, onde você:
- Começa com um modelo pré-treinado que aprendeu padrões gerais a partir de grandes conjuntos de dados
- Ajusta os parâmetros internos do modelo usando seu conjunto de dados específico
- Retém o conhecimento valioso enquanto especializa o modelo para sua tarefa

Pense nisso como ensinar um chef experiente a cozinhar uma nova culinária - ele já entende os fundamentos da cozinha, mas precisa aprender técnicas e sabores específicos para o novo estilo.

### Principais Benefícios

- **Eficiência de Tempo**: Muito mais rápido do que treinar do zero
- **Eficiência de Dados**: Requer conjuntos de dados menores para alcançar um bom desempenho
- **Custo-Benefício**: Menores requisitos computacionais
- **Melhor Desempenho**: Muitas vezes alcança resultados superiores em comparação ao treinamento do zero
- **Otimização de Recursos**: Torna a IA poderosa acessível a equipes e organizações menores

## Por que o Ajuste Fino é Importante

### Aplicações no Mundo Real

O ajuste fino é essencial em diversos cenários:

**1. Adaptação de Domínio**
- IA Médica: Adaptando modelos de linguagem geral para terminologia médica e notas clínicas
- Tecnologia Jurídica: Especializando modelos para análise de documentos legais e revisão de contratos
- Serviços Financeiros: Personalizando modelos para análise de relatórios financeiros e avaliação de riscos

**2. Especialização de Tarefas**
- Geração de Conteúdo: Ajuste fino para estilos ou tons de escrita específicos
- Geração de Código: Adaptando modelos para linguagens de programação ou frameworks específicos
- Tradução: Melhorando o desempenho para pares de idiomas específicos ou domínios técnicos

**3. Aplicações Corporativas**
- Atendimento ao Cliente: Criando chatbots que entendem a terminologia específica da empresa
- Documentação Interna: Construindo assistentes de IA familiarizados com processos organizacionais
- Soluções Específicas do Setor: Desenvolvendo modelos que compreendem jargões e fluxos de trabalho específicos do setor

## Tipos de Ajuste Fino

### 1. Ajuste Fino Completo (Ajuste por Instrução)

No ajuste fino completo, todos os parâmetros do modelo são atualizados durante o treinamento. Essa abordagem:
- Oferece máxima flexibilidade e potencial de desempenho
- Requer recursos computacionais significativos
- Resulta em uma versão completamente nova do modelo
- Ideal para cenários onde há muitos dados de treinamento e recursos computacionais disponíveis

### 2. Ajuste Fino Eficiente em Parâmetros (PEFT)

Os métodos PEFT atualizam apenas um pequeno subconjunto de parâmetros, tornando o processo mais eficiente:

#### Low-Rank Adaptation (LoRA)
- Adiciona pequenas matrizes de decomposição de rank treináveis aos pesos existentes
- Reduz drasticamente o número de parâmetros treináveis
- Mantém desempenho próximo ao ajuste fino completo
- Permite alternância fácil entre diferentes adaptações

#### QLoRA (LoRA Quantizado)
- Combina LoRA com técnicas de quantização
- Reduz ainda mais os requisitos de memória
- Permite ajuste fino de modelos maiores em hardware de consumo
- Equilibra eficiência com desempenho

#### Adapters
- Insere pequenas redes neurais entre camadas existentes
- Permite ajuste fino direcionado enquanto mantém o modelo base congelado
- Oferece uma abordagem modular para personalização de modelos

### 3. Ajuste Fino Específico de Tarefa

Focado em adaptar modelos para tarefas específicas:
- **Classificação**: Ajustando modelos para tarefas de categorização
- **Geração**: Otimizando para criação de conteúdo e geração de texto
- **Extração**: Ajuste fino para extração de informações e reconhecimento de entidades nomeadas
- **Resumo**: Especializando modelos para sumarização de documentos

## Ajuste Fino com Microsoft Olive

Microsoft Olive é uma ferramenta abrangente de otimização de modelos que simplifica o processo de ajuste fino enquanto oferece recursos de nível empresarial.

### O que é Microsoft Olive?

Microsoft Olive é uma ferramenta de otimização de modelos de código aberto que:
- Simplifica fluxos de trabalho de ajuste fino para diferentes alvos de hardware
- Oferece suporte integrado para arquiteturas de modelo populares (Llama, Phi, Qwen, Gemma)
- Disponibiliza opções de implantação na nuvem e localmente
- Integra-se perfeitamente com Azure ML e outros serviços de IA da Microsoft
- Suporta otimização e quantização automáticas

### Principais Recursos

- **Otimização Orientada ao Hardware**: Otimiza automaticamente modelos para hardware específico (CPU, GPU, NPU)
- **Suporte Multi-Formato**: Funciona com modelos PyTorch, Hugging Face e ONNX
- **Fluxos de Trabalho Automatizados**: Reduz configuração manual e tentativa e erro
- **Integração Empresarial**: Suporte integrado para Azure ML e implantações na nuvem
- **Arquitetura Extensível**: Permite técnicas de otimização personalizadas

### Instalação e Configuração

#### Instalação Básica

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dependências Opcionais

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verificar Instalação

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Exemplos Práticos

### Exemplo 1: Ajuste Fino Básico com Olive CLI

Este exemplo demonstra o ajuste fino de um pequeno modelo de linguagem para classificação de frases:

#### Passo 1: Preparar o Ambiente

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Passo 2: Ajustar o Modelo

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Passo 3: Otimizar para Implantação

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Exemplo 2: Configuração Avançada com Conjunto de Dados Personalizado

#### Passo 1: Preparar Conjunto de Dados Personalizado

Crie um arquivo JSON com seus dados de treinamento:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Passo 2: Criar Arquivo de Configuração

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Passo 3: Executar Ajuste Fino

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Exemplo 3: Ajuste Fino com QLoRA para Eficiência de Memória

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Melhores Práticas e Diretrizes

### Preparação de Dados

**1. Qualidade dos Dados Acima da Quantidade**
- Priorize exemplos de alta qualidade e diversidade em vez de grandes volumes de dados ruins
- Certifique-se de que os dados sejam representativos do seu caso de uso
- Limpe e pré-processe os dados de forma consistente

**2. Formato e Modelos de Dados**
- Use formatação consistente em todos os exemplos de treinamento
- Crie modelos claros de entrada-saída que correspondam ao seu caso de uso
- Inclua formatação de instruções apropriada para modelos ajustados por instrução

**3. Divisão do Conjunto de Dados**
- Reserve 10-20% dos dados para validação
- Mantenha distribuições semelhantes entre as divisões de treinamento/validação
- Considere amostragem estratificada para tarefas de classificação

### Configuração de Treinamento

**1. Seleção de Taxa de Aprendizado**
- Comece com taxas de aprendizado menores (1e-5 a 1e-4) para ajuste fino
- Use agendamento de taxa de aprendizado para melhor convergência
- Monitore curvas de perda para ajustar as taxas conforme necessário

**2. Otimização de Tamanho de Lote**
- Equilibre o tamanho do lote com a memória disponível
- Use acumulação de gradiente para tamanhos de lote efetivos maiores
- Considere a relação entre tamanho de lote e taxa de aprendizado

**3. Duração do Treinamento**
- Monitore métricas de validação para evitar overfitting
- Use parada antecipada quando o desempenho de validação estabilizar
- Salve checkpoints regularmente para recuperação e análise

### Seleção de Modelo

**1. Escolha do Modelo Base**
- Selecione modelos pré-treinados em domínios semelhantes sempre que possível
- Considere o tamanho do modelo em relação às suas restrições computacionais
- Avalie requisitos de licenciamento para uso comercial

**2. Seleção do Método de Ajuste Fino**
- Use LoRA/QLoRA para ambientes com restrições de recursos
- Escolha ajuste fino completo quando o desempenho máximo for crítico
- Considere abordagens baseadas em adaptadores para cenários de múltiplas tarefas

### Gerenciamento de Recursos

**1. Otimização de Hardware**
- Escolha hardware apropriado para o tamanho do modelo e método
- Utilize memória de GPU eficientemente com checkpointing de gradiente
- Considere soluções baseadas na nuvem para modelos maiores

**2. Gerenciamento de Memória**
- Use treinamento de precisão mista quando disponível
- Implemente acumulação de gradiente para restrições de memória
- Monitore o uso de memória da GPU durante o treinamento

## Técnicas Avançadas

### Treinamento Multi-Adaptador

Treine múltiplos adaptadores para diferentes tarefas enquanto compartilha o modelo base:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Otimização de Hiperparâmetros

Implemente ajuste sistemático de hiperparâmetros:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Funções de Perda Personalizadas

Implemente funções de perda específicas do domínio:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Avaliação e Monitoramento

### Métricas e Avaliação

**1. Métricas Padrão**
- **Acurácia**: Correção geral para tarefas de classificação
- **Perplexidade**: Medida de qualidade de modelagem de linguagem
- **BLEU/ROUGE**: Qualidade de geração de texto e sumarização
- **F1 Score**: Equilíbrio entre precisão e recall para classificação

**2. Métricas Específicas de Domínio**
- **Benchmarks Específicos de Tarefa**: Use benchmarks estabelecidos para seu domínio
- **Avaliação Humana**: Inclua avaliação humana para tarefas subjetivas
- **Métricas de Negócio**: Alinhe com objetivos reais de negócios

**3. Configuração de Avaliação**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitoramento do Progresso do Treinamento

**1. Rastreamento de Perda**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Monitoramento de Validação**
- Acompanhe a perda de validação junto com a perda de treinamento
- Monitore sinais de overfitting (perda de validação aumentando enquanto a perda de treinamento diminui)
- Use parada antecipada com base em métricas de validação

**3. Monitoramento de Recursos**
- Monitore utilização de GPU/CPU
- Acompanhe padrões de uso de memória
- Monitore velocidade e throughput de treinamento

## Desafios Comuns e Soluções

### Desafio 1: Overfitting

**Sintomas:**
- A perda de treinamento continua diminuindo enquanto a perda de validação aumenta
- Grande diferença entre desempenho de treinamento e validação
- Má generalização para novos dados

**Soluções:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Desafio 2: Limitações de Memória

**Soluções:**
- Use checkpointing de gradiente
- Implemente acumulação de gradiente
- Escolha métodos eficientes em parâmetros (LoRA, QLoRA)
- Utilize paralelismo de modelo para modelos grandes

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Desafio 3: Treinamento Lento

**Soluções:**
- Otimize pipelines de carregamento de dados
- Use treinamento de precisão mista
- Implemente estratégias de batching eficientes
- Considere treinamento distribuído para conjuntos de dados grandes

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Desafio 4: Desempenho Insatisfatório

**Passos de Diagnóstico:**
1. Verifique a qualidade e formatação dos dados
2. Confira a taxa de aprendizado e duração do treinamento
3. Avalie a escolha do modelo base
4. Revise o pré-processamento e tokenização

**Soluções:**
- Aumente a diversidade dos dados de treinamento
- Ajuste o agendamento da taxa de aprendizado
- Experimente diferentes modelos base
- Implemente técnicas de aumento de dados

## Conclusão

O ajuste fino é uma técnica poderosa que democratiza o acesso a capacidades de IA de última geração. Ao utilizar ferramentas como Microsoft Olive, as organizações podem adaptar modelos pré-treinados de forma eficiente às suas necessidades específicas, otimizando desempenho e recursos.

### Principais Lições

1. **Escolha a Abordagem Certa**: Selecione métodos de ajuste fino com base em seus recursos computacionais e requisitos de desempenho
2. **A Qualidade dos Dados Importa**: Invista em dados de treinamento de alta qualidade e representativos
3. **Monitore e Itere**: Avalie e melhore continuamente seus modelos
4. **Aproveite as Ferramentas**: Use frameworks como Olive para simplificar e otimizar o processo
5. **Considere a Implantação**: Planeje a otimização e implantação do modelo desde o início

## ➡️ Próximos Passos

- [04: Implantação - Implementação de Modelos Prontos para Produção](./04.SLMOps.Deployment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automatizadas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações equivocadas decorrentes do uso desta tradução.