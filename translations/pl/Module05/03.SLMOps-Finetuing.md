<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T15:53:03+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "pl"
}
-->
# Sekcja 3: Fine-Tuning - Dostosowywanie Modeli do Specyficznych Zadań

## Spis Treści
1. [Wprowadzenie do Fine-Tuning](../../../Module05)
2. [Dlaczego Fine-Tuning jest ważny](../../../Module05)
3. [Rodzaje Fine-Tuning](../../../Module05)
4. [Fine-Tuning z Microsoft Olive](../../../Module05)
5. [Przykłady praktyczne](../../../Module05)
6. [Najlepsze praktyki i wytyczne](../../../Module05)
7. [Zaawansowane techniki](../../../Module05)
8. [Ewaluacja i monitorowanie](../../../Module05)
9. [Typowe wyzwania i rozwiązania](../../../Module05)
10. [Podsumowanie](../../../Module05)

## Wprowadzenie do Fine-Tuning

**Fine-tuning** to potężna technika uczenia maszynowego, która polega na dostosowywaniu wcześniej wytrenowanego modelu do wykonywania określonych zadań lub pracy z wyspecjalizowanymi zestawami danych. Zamiast trenować model od zera, fine-tuning wykorzystuje wiedzę już zdobytą przez model i dostosowuje ją do konkretnego przypadku użycia.

### Czym jest Fine-Tuning?

Fine-tuning to forma **transfer learning**, w której:
- Rozpoczynasz od wcześniej wytrenowanego modelu, który nauczył się ogólnych wzorców z dużych zestawów danych
- Dostosowujesz wewnętrzne parametry modelu za pomocą swojego specyficznego zestawu danych
- Zachowujesz cenną wiedzę, jednocześnie specjalizując model do swojego zadania

To jak nauczenie doświadczonego szefa kuchni nowej kuchni - zna już podstawy gotowania, ale musi nauczyć się specyficznych technik i smaków dla nowego stylu.

### Kluczowe korzyści

- **Efektywność czasowa**: Znacznie szybsze niż trenowanie od zera
- **Efektywność danych**: Wymaga mniejszych zestawów danych, aby osiągnąć dobre wyniki
- **Kosztowo efektywne**: Niższe wymagania obliczeniowe
- **Lepsza wydajność**: Często osiąga lepsze wyniki niż trenowanie od zera
- **Optymalizacja zasobów**: Udostępnia potężne AI mniejszym zespołom i organizacjom

## Dlaczego Fine-Tuning jest ważny

### Zastosowania w rzeczywistości

Fine-tuning jest niezbędny w wielu scenariuszach:

**1. Adaptacja do domeny**
- AI w medycynie: Dostosowanie ogólnych modeli językowych do terminologii medycznej i notatek klinicznych
- Technologie prawne: Specjalizacja modeli do analizy dokumentów prawnych i przeglądu umów
- Usługi finansowe: Dostosowanie modeli do analizy raportów finansowych i oceny ryzyka

**2. Specjalizacja zadań**
- Generowanie treści: Fine-tuning dla określonych stylów pisania lub tonów
- Generowanie kodu: Dostosowanie modeli do konkretnych języków programowania lub frameworków
- Tłumaczenie: Poprawa wydajności dla określonych par językowych lub dziedzin technicznych

**3. Zastosowania korporacyjne**
- Obsługa klienta: Tworzenie chatbotów rozumiejących specyficzną terminologię firmy
- Dokumentacja wewnętrzna: Budowanie asystentów AI zaznajomionych z procesami organizacyjnymi
- Rozwiązania branżowe: Tworzenie modeli rozumiejących specyficzny żargon i przepływy pracy w sektorze

## Rodzaje Fine-Tuning

### 1. Pełny Fine-Tuning (Instruction Fine-Tuning)

W pełnym fine-tuningu wszystkie parametry modelu są aktualizowane podczas treningu. Podejście to:
- Zapewnia maksymalną elastyczność i potencjał wydajności
- Wymaga znacznych zasobów obliczeniowych
- Rezultatem jest całkowicie nowa wersja modelu
- Najlepsze w scenariuszach, gdzie masz duże ilości danych treningowych i zasoby obliczeniowe

### 2. Fine-Tuning z efektywnym wykorzystaniem parametrów (PEFT)

Metody PEFT aktualizują tylko niewielką część parametrów, co czyni proces bardziej efektywnym:

#### Low-Rank Adaptation (LoRA)
- Dodaje małe macierze dekompozycji rangi do istniejących wag
- Znacząco zmniejsza liczbę trenowanych parametrów
- Utrzymuje wydajność zbliżoną do pełnego fine-tuningu
- Umożliwia łatwe przełączanie między różnymi adaptacjami

#### QLoRA (Quantized LoRA)
- Łączy LoRA z technikami kwantyzacji
- Dalsze zmniejsza wymagania pamięciowe
- Umożliwia fine-tuning większych modeli na sprzęcie konsumenckim
- Równoważy efektywność z wydajnością

#### Adapters
- Wstawia małe sieci neuronowe między istniejące warstwy
- Pozwala na ukierunkowany fine-tuning przy zachowaniu bazowego modelu w stanie zamrożonym
- Umożliwia modułowe podejście do dostosowywania modelu

### 3. Fine-Tuning specyficzny dla zadania

Skupia się na dostosowywaniu modeli do konkretnych zadań:
- **Klasyfikacja**: Dostosowanie modeli do zadań kategoryzacji
- **Generowanie**: Optymalizacja dla tworzenia treści i generowania tekstu
- **Ekstrakcja**: Fine-tuning dla ekstrakcji informacji i rozpoznawania nazwanych jednostek
- **Podsumowanie**: Specjalizacja modeli do podsumowywania dokumentów

## Fine-Tuning z Microsoft Olive

Microsoft Olive to kompleksowe narzędzie do optymalizacji modeli, które upraszcza proces fine-tuningu, oferując jednocześnie funkcje klasy korporacyjnej.

### Czym jest Microsoft Olive?

Microsoft Olive to otwarte narzędzie do optymalizacji modeli, które:
- Usprawnia przepływy pracy związane z fine-tuningiem dla różnych platform sprzętowych
- Oferuje wbudowane wsparcie dla popularnych architektur modeli (Llama, Phi, Qwen, Gemma)
- Zapewnia opcje wdrożenia w chmurze i lokalnie
- Integruje się bezproblemowo z Azure ML i innymi usługami AI Microsoftu
- Obsługuje automatyczną optymalizację i kwantyzację

### Kluczowe funkcje

- **Optymalizacja sprzętowa**: Automatycznie optymalizuje modele dla określonego sprzętu (CPU, GPU, NPU)
- **Wsparcie dla wielu formatów**: Działa z modelami PyTorch, Hugging Face i ONNX
- **Automatyczne przepływy pracy**: Redukuje ręczną konfigurację i metodę prób i błędów
- **Integracja korporacyjna**: Wbudowane wsparcie dla Azure ML i wdrożeń w chmurze
- **Rozszerzalna architektura**: Pozwala na stosowanie niestandardowych technik optymalizacji

### Instalacja i konfiguracja

#### Podstawowa instalacja

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Opcjonalne zależności

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Weryfikacja instalacji

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Przykłady praktyczne

### Przykład 1: Podstawowy Fine-Tuning z Olive CLI

Ten przykład pokazuje fine-tuning małego modelu językowego do klasyfikacji fraz:

#### Krok 1: Przygotowanie środowiska

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Krok 2: Fine-Tuning modelu

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Krok 3: Optymalizacja do wdrożenia

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Przykład 2: Zaawansowana konfiguracja z niestandardowym zestawem danych

#### Krok 1: Przygotowanie niestandardowego zestawu danych

Utwórz plik JSON z danymi treningowymi:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Krok 2: Utworzenie pliku konfiguracyjnego

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Krok 3: Wykonanie Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Przykład 3: Fine-Tuning QLoRA dla efektywności pamięciowej

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Najlepsze praktyki i wytyczne

### Przygotowanie danych

**1. Jakość danych ponad ilość**
- Priorytetem są wysokiej jakości, różnorodne przykłady zamiast dużych ilości słabych danych
- Upewnij się, że dane są reprezentatywne dla Twojego przypadku użycia
- Regularnie czyść i przetwarzaj dane

**2. Format danych i szablony**
- Używaj spójnego formatowania we wszystkich przykładach treningowych
- Twórz jasne szablony wejścia-wyjścia dopasowane do Twojego przypadku użycia
- Uwzględnij odpowiednie formatowanie instrukcji dla modeli dostosowanych do instrukcji

**3. Podział zestawu danych**
- Zarezerwuj 10-20% danych na walidację
- Utrzymuj podobne rozkłady w podziałach treningowych/walidacyjnych
- Rozważ próbkowanie warstwowe dla zadań klasyfikacji

### Konfiguracja treningu

**1. Wybór współczynnika uczenia**
- Rozpocznij od mniejszych współczynników uczenia (1e-5 do 1e-4) dla fine-tuningu
- Używaj harmonogramu współczynnika uczenia dla lepszej konwergencji
- Monitoruj krzywe strat, aby dostosować współczynniki

**2. Optymalizacja rozmiaru partii**
- Zrównoważ rozmiar partii z dostępną pamięcią
- Używaj akumulacji gradientów dla większych efektywnych rozmiarów partii
- Rozważ zależność między rozmiarem partii a współczynnikiem uczenia

**3. Czas trwania treningu**
- Monitoruj metryki walidacyjne, aby uniknąć przeuczenia
- Używaj wczesnego zatrzymania, gdy wydajność walidacyjna się stabilizuje
- Regularnie zapisuj punkty kontrolne dla odzyskiwania i analizy

### Wybór modelu

**1. Wybór modelu bazowego**
- Wybieraj modele wytrenowane na podobnych domenach, jeśli to możliwe
- Rozważ rozmiar modelu w stosunku do swoich ograniczeń obliczeniowych
- Oceń wymagania licencyjne dla zastosowań komercyjnych

**2. Wybór metody Fine-Tuning**
- Używaj LoRA/QLoRA w środowiskach z ograniczonymi zasobami
- Wybierz pełny fine-tuning, gdy kluczowa jest maksymalna wydajność
- Rozważ podejścia oparte na adapterach dla scenariuszy wielozadaniowych

### Zarządzanie zasobami

**1. Optymalizacja sprzętu**
- Wybierz odpowiedni sprzęt dla rozmiaru modelu i metody
- Efektywnie wykorzystuj pamięć GPU za pomocą punktów kontrolnych gradientów
- Rozważ rozwiązania chmurowe dla większych modeli

**2. Zarządzanie pamięcią**
- Używaj treningu z mieszanymi precyzjami, jeśli dostępne
- Implementuj akumulację gradientów dla ograniczeń pamięciowych
- Monitoruj użycie pamięci GPU podczas treningu

## Zaawansowane techniki

### Trening wieloadapterowy

Trenuj wiele adapterów dla różnych zadań, jednocześnie dzieląc bazowy model:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optymalizacja hiperparametrów

Wprowadź systematyczne dostrajanie hiperparametrów:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Niestandardowe funkcje strat

Wprowadź funkcje strat specyficzne dla domeny:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Ewaluacja i monitorowanie

### Metryki i ewaluacja

**1. Standardowe metryki**
- **Dokładność**: Ogólna poprawność dla zadań klasyfikacji
- **Perpleksja**: Miara jakości modelowania języka
- **BLEU/ROUGE**: Jakość generowania tekstu i podsumowywania
- **F1 Score**: Zrównoważona precyzja i czułość dla klasyfikacji

**2. Metryki specyficzne dla domeny**
- **Benchmarki zadaniowe**: Używaj ustalonych benchmarków dla swojej domeny
- **Ocena ludzka**: Uwzględnij ocenę ludzką dla zadań subiektywnych
- **Metryki biznesowe**: Dopasuj do rzeczywistych celów biznesowych

**3. Konfiguracja ewaluacji**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitorowanie postępu treningu

**1. Śledzenie strat**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Monitorowanie walidacji**
- Śledź stratę walidacyjną obok straty treningowej
- Monitoruj oznaki przeuczenia (strata walidacyjna rośnie, podczas gdy strata treningowa maleje)
- Używaj wczesnego zatrzymania na podstawie metryk walidacyjnych

**3. Monitorowanie zasobów**
- Monitoruj wykorzystanie GPU/CPU
- Śledź wzorce użycia pamięci
- Monitoruj szybkość treningu i przepustowość

## Typowe wyzwania i rozwiązania

### Wyzwanie 1: Przeuczenie

**Objawy:**
- Strata treningowa nadal maleje, podczas gdy strata walidacyjna rośnie
- Duża różnica między wydajnością treningową a walidacyjną
- Słaba generalizacja do nowych danych

**Rozwiązania:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Wyzwanie 2: Ograniczenia pamięci

**Rozwiązania:**
- Używaj punktów kontrolnych gradientów
- Implementuj akumulację gradientów
- Wybierz metody efektywne pod względem parametrów (LoRA, QLoRA)
- Wykorzystaj równoległość modelu dla dużych modeli

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Wyzwanie 3: Wolny trening

**Rozwiązania:**
- Optymalizuj potoki ładowania danych
- Używaj treningu z mieszanymi precyzjami
- Implementuj efektywne strategie batchowania
- Rozważ trening rozproszony dla dużych zestawów danych

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Wyzwanie 4: Słaba wydajność

**Kroki diagnostyczne:**
1. Zweryfikuj jakość i formatowanie danych
2. Sprawdź współczynnik uczenia i czas trwania treningu
3. Oceń wybór modelu bazowego
4. Przejrzyj wstępne przetwarzanie i tokenizację

**Rozwiązania:**
- Zwiększ różnorodność danych treningowych
- Dostosuj harmonogram współczynnika uczenia
- Wypróbuj różne modele bazowe
- Wprowadź techniki augmentacji danych

## Podsumowanie

Fine-tuning to potężna technika, która demokratyzuje dostęp do najnowocześniejszych możliwości AI. Dzięki narzędziom takim jak Microsoft Olive, organizacje mogą efektywnie dostosowywać wcześniej wytrenowane modele do swoich specyficznych potrzeb, jednocześnie optymalizując wydajność i zasoby.

### Kluczowe wnioski

1. **Wybierz odpowiednie podejście**: Dobierz metody fine-tuningu w zależności od zasobów obliczeniowych i wymagań wydajnościowych
2. **Jakość danych ma znaczenie**: Zainwestuj w wysokiej jakości, reprezentatywne dane treningowe
3. **Monitoruj i iteruj**: Regularnie oceniaj i ulepszaj swoje modele
4. **Wykorzystaj narzędzia**: Używaj frameworków takich jak Olive, aby uprościć i zoptymalizować proces
5. **Planuj wdrożenie**: Od początku uwzględnij optymalizację i wdrożenie modelu

## ➡️ Co dalej

- [04: Wdrożenie - Implementacja modelu gotowego do produkcji](./04.SLMOps.Deployment.md)

---

**Zastrzeżenie**:  
Ten dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby zapewnić poprawność tłumaczenia, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za źródło autorytatywne. W przypadku informacji o kluczowym znaczeniu zaleca się skorzystanie z profesjonalnego tłumaczenia przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z użycia tego tłumaczenia.