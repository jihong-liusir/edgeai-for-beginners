<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a189d7d9d47816a518ca119d79dc19b",
  "translation_date": "2025-09-22T13:12:01+00:00",
  "source_file": "README.md",
  "language_code": "pl"
}
-->
# EdgeAI dla Początkujących

![Obraz okładki kursu](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.pl.png)

[![Współtwórcy GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)
[![Problemy GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)
[![Pull requesty GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

[![Obserwujący GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)
[![Forki GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)
[![Gwiazdy GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Postępuj zgodnie z poniższymi krokami, aby rozpocząć korzystanie z tych zasobów:

1. **Sforkuj repozytorium**: Kliknij [![Forki GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)
2. **Sklonuj repozytorium**: `git clone https://github.com/microsoft/edgeai-for-beginners.git`
3. [**Dołącz do Azure AI Foundry Discord i poznaj ekspertów oraz innych programistów**](https://discord.com/invite/ByRwuEEgH4)

### 🌐 Obsługa wielu języków

#### Obsługiwane za pomocą GitHub Action (Automatyczne i zawsze aktualne)

[Arabski](../ar/README.md) | [Bengalski](../bn/README.md) | [Bułgarski](../bg/README.md) | [Birmański (Myanmar)](../my/README.md) | [Chiński (uproszczony)](../zh/README.md) | [Chiński (tradycyjny, Hongkong)](../hk/README.md) | [Chiński (tradycyjny, Makau)](../mo/README.md) | [Chiński (tradycyjny, Tajwan)](../tw/README.md) | [Chorwacki](../hr/README.md) | [Czeski](../cs/README.md) | [Duński](../da/README.md) | [Holenderski](../nl/README.md) | [Fiński](../fi/README.md) | [Francuski](../fr/README.md) | [Niemiecki](../de/README.md) | [Grecki](../el/README.md) | [Hebrajski](../he/README.md) | [Hindi](../hi/README.md) | [Węgierski](../hu/README.md) | [Indonezyjski](../id/README.md) | [Włoski](../it/README.md) | [Japoński](../ja/README.md) | [Koreański](../ko/README.md) | [Malajski](../ms/README.md) | [Marathi](../mr/README.md) | [Nepalski](../ne/README.md) | [Norweski](../no/README.md) | [Perski (Farsi)](../fa/README.md) | [Polski](./README.md) | [Portugalski (Brazylia)](../br/README.md) | [Portugalski (Portugalia)](../pt/README.md) | [Pendżabski (Gurmukhi)](../pa/README.md) | [Rumuński](../ro/README.md) | [Rosyjski](../ru/README.md) | [Serbski (cyrylica)](../sr/README.md) | [Słowacki](../sk/README.md) | [Słoweński](../sl/README.md) | [Hiszpański](../es/README.md) | [Suahili](../sw/README.md) | [Szwedzki](../sv/README.md) | [Tagalog (Filipiński)](../tl/README.md) | [Tajski](../th/README.md) | [Turecki](../tr/README.md) | [Ukraiński](../uk/README.md) | [Urdu](../ur/README.md) | [Wietnamski](../vi/README.md)

**Jeśli chcesz, aby obsługiwane były dodatkowe języki, lista dostępnych znajduje się [tutaj](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Wprowadzenie

Witamy w **EdgeAI dla Początkujących** – kompleksowym kursie wprowadzającym w świat Edge Artificial Intelligence. Kurs ten łączy potężne możliwości sztucznej inteligencji z praktycznym wdrożeniem na urządzeniach brzegowych, umożliwiając wykorzystanie AI tam, gdzie dane są generowane i gdzie podejmowane są decyzje.

### Czego się nauczysz

Kurs prowadzi od podstawowych pojęć do gotowych do wdrożenia rozwiązań, obejmując:
- **Małe modele językowe (SLM)** zoptymalizowane pod kątem wdrożeń brzegowych
- **Optymalizację sprzętową** na różnych platformach
- **Wnioskowanie w czasie rzeczywistym** z zachowaniem prywatności
- **Strategie wdrożeniowe** dla aplikacji korporacyjnych

### Dlaczego EdgeAI jest ważne

Edge AI to zmiana paradygmatu, która odpowiada na współczesne wyzwania:
- **Prywatność i bezpieczeństwo**: Przetwarzanie danych lokalnie, bez przesyłania do chmury
- **Wydajność w czasie rzeczywistym**: Eliminacja opóźnień sieciowych w aplikacjach krytycznych czasowo
- **Efektywność kosztowa**: Redukcja kosztów przesyłu danych i obliczeń w chmurze
- **Odporność operacyjna**: Utrzymanie funkcjonalności podczas przerw w dostępie do sieci
- **Zgodność z regulacjami**: Spełnianie wymogów dotyczących suwerenności danych

### Edge AI

Edge AI oznacza uruchamianie algorytmów AI i modeli językowych lokalnie na sprzęcie – blisko miejsca, gdzie dane są generowane – bez konieczności korzystania z zasobów chmurowych do wnioskowania. Zmniejsza to opóźnienia, zwiększa prywatność i umożliwia podejmowanie decyzji w czasie rzeczywistym.

### Kluczowe zasady:
- **Wnioskowanie na urządzeniu**: Modele AI działają na urządzeniach brzegowych (telefony, routery, mikrokontrolery, komputery przemysłowe)
- **Działanie offline**: Funkcjonowanie bez stałego połączenia z internetem
- **Niskie opóźnienia**: Natychmiastowe odpowiedzi odpowiednie dla systemów czasu rzeczywistego
- **Suwerenność danych**: Przechowywanie wrażliwych danych lokalnie, co zwiększa bezpieczeństwo i zgodność

### Małe modele językowe (SLM)

SLM, takie jak Phi-4, Mistral-7B i Gemma, to zoptymalizowane wersje większych modeli LLM – trenowane lub destylowane w celu:
- **Zmniejszenia zużycia pamięci**: Efektywne wykorzystanie ograniczonej pamięci urządzeń brzegowych
- **Obniżenia zapotrzebowania na moc obliczeniową**: Optymalizacja pod kątem wydajności CPU i GPU na urządzeniach brzegowych
- **Szybszego uruchamiania**: Szybka inicjalizacja dla responsywnych aplikacji

Umożliwiają one potężne możliwości NLP, spełniając jednocześnie ograniczenia:
- **Systemów wbudowanych**: Urządzeń IoT i kontrolerów przemysłowych
- **Urządzeń mobilnych**: Smartfonów i tabletów z funkcjami offline
- **Urządzeń IoT**: Czujników i inteligentnych urządzeń o ograniczonych zasobach
- **Serwerów brzegowych**: Lokalnych jednostek przetwarzania z ograniczonymi zasobami GPU
- **Komputerów osobistych**: Scenariuszy wdrożeniowych na komputerach stacjonarnych i laptopach

## Architektura kursu

### [Moduł 01: Podstawy EdgeAI i Transformacja](./Module01/README.md)
**Temat**: Transformacyjna zmiana w kierunku wdrożeń Edge AI

#### Struktura rozdziału:
- [**Sekcja 1: Podstawy EdgeAI**](./Module01/01.EdgeAIFundamentals.md)
  - Porównanie tradycyjnego AI w chmurze z Edge AI
  - Wyzwania i ograniczenia przetwarzania brzegowego
  - Kluczowe technologie: kwantyzacja modeli, optymalizacja kompresji, Małe Modele Językowe (SLM)
  - Przyspieszenie sprzętowe: NPU, optymalizacja GPU, optymalizacja CPU
  - Zalety: bezpieczeństwo prywatności, niskie opóźnienia, funkcje offline, efektywność kosztowa

- [**Sekcja 2: Przypadki użycia w rzeczywistych scenariuszach**](./Module01/02.RealWorldCaseStudies.md)
  - Ekosystem modeli Microsoft Phi i Mu
  - Studium przypadku systemu raportowania AI Japan Airlines
  - Wpływ na rynek i kierunki rozwoju
  - Rozważania wdrożeniowe i najlepsze praktyki

- [**Sekcja 3: Praktyczny przewodnik wdrożeniowy**](./Module01/03.PracticalImplementationGuide.md)
  - Konfiguracja środowiska programistycznego (Python 3.10+, .NET 8+)
  - Wymagania sprzętowe i zalecane konfiguracje
  - Zasoby rodziny modeli podstawowych
  - Narzędzia do kwantyzacji i optymalizacji (Llama.cpp, Microsoft Olive, Apple MLX)
  - Lista kontrolna oceny i weryfikacji

- [**Sekcja 4: Platformy sprzętowe do wdrożeń Edge AI**](./Module01/04.EdgeDeployment.md)
  - Rozważania i wymagania dotyczące wdrożeń Edge AI
  - Sprzęt Intel do Edge AI i techniki optymalizacji
  - Rozwiązania Qualcomm AI dla systemów mobilnych i wbudowanych
  - NVIDIA Jetson i platformy przetwarzania brzegowego
  - Platformy Windows AI PC z przyspieszeniem NPU
  - Strategie optymalizacji specyficzne dla sprzętu

---

### [Moduł 02: Podstawy Małych Modeli Językowych](./Module02/README.md)
**Temat**: Teoretyczne zasady SLM, strategie wdrożeniowe i produkcyjne

#### Struktura rozdziału:
- [**Sekcja 1: Podstawy rodziny modeli Microsoft Phi**](./Module02/01.PhiFamily.md)
  - Ewolucja filozofii projektowania (Phi-1 do Phi-4)
  - Architektura zorientowana na efektywność
  - Specjalne możliwości (rozumowanie, multimodalność, wdrożenia brzegowe)

- [**Sekcja 2: Podstawy rodziny Qwen**](./Module02/02.QwenFamily.md)
  - Doskonałość open source (Qwen 1.0 do Qwen3) – dostępne na Hugging Face
  - Zaawansowana architektura rozumowania z trybem myślenia
  - Skalowalne opcje wdrożeniowe (0.5B-235B parametrów)

- [**Sekcja 3: Podstawy rodziny Gemma**](./Module02/03.GemmaFamily.md)
  - Innowacje napędzane badaniami (Gemma 3 i 3n)
  - Doskonałość multimodalna
  - Architektura zorientowana na urządzenia mobilne

- [**Sekcja 4: Podstawy rodziny BitNET**](./Module02/04.BitNETFamily.md)
  - Rewolucyjna technologia kwantyzacji (1.58-bit)
  - Specjalistyczne środowisko wnioskowania z https://github.com/microsoft/BitNet
  - Zrównoważone przywództwo AI dzięki ekstremalnej efektywności

- [**Sekcja 5: Podstawy modelu Microsoft Mu**](./Module02/05.mumodel.md)
  - Architektura zorientowana na urządzenia, wbudowana w Windows 11
  - Integracja systemowa z ustawieniami Windows 11
  - Prywatność dzięki działaniu offline

- [**Sekcja 6: Podstawy Phi-Silica**](./Module02/06.phisilica.md)
  - Architektura zoptymalizowana pod kątem NPU, wbudowana w Windows 11 Copilot+ PC
  - Wyjątkowa efektywność (650 tokenów/sekundę przy 1.5W)
  - Integracja deweloperska z Windows App SDK

---

### [Moduł 03: Wdrożenie Małych Modeli Językowych](./Module03/README.md)
**Temat**: Kompletny cykl życia SLM, od teorii po środowisko produkcyjne

#### Struktura rozdziału:
- [**Sekcja 1: Zaawansowana nauka SLM**](./Module03/01.SLMAdvancedLearning.md)
  - Ramy klasyfikacji parametrów (Micro SLM 100M-1.4B, Medium SLM 14B-30B)
  - Zaawansowane techniki optymalizacji (metody kwantyzacji, kwantyzacja BitNET 1-bit)
  - Strategie pozyskiwania modeli (Azure AI Foundry dla modeli Phi, Hugging Face dla wybranych modeli)

- [**Sekcja 2: Wdrożenie w środowisku lokalnym**](./Module03/02.DeployingSLMinLocalEnv.md)
  - Uniwersalna platforma wdrożeniowa Ollama
  - Lokalne rozwiązania klasy korporacyjnej Microsoft Foundry
  - Analiza porównawcza frameworków

- [**Sekcja 3: Wdrożenie w chmurze w kontenerach**](./Module03/03.DeployingSLMinCloud.md)
  - Wdrożenie wnioskowania wysokiej wydajności vLLM
  - Orkiestracja kontenerów Ollama
  - Implementacja zoptymalizowana pod kątem Edge w ONNX Runtime

---

### [Moduł 04: Konwersja i kwantyzacja formatu modelu](./Module04/README.md)
**Temat**: Kompletny zestaw narzędzi do optymalizacji modeli dla wdrożeń brzegowych na różnych platformach

#### Struktura rozdziału:
- [**Sekcja 1: Podstawy konwersji i kwantyzacji formatu modelu**](./Module04/01.Introduce.md)
  - Ramy klasyfikacji precyzji (ultraniska, niska, średnia precyzja)
  - Zalety i przypadki użycia formatów GGUF i ONNX
  - Korzyści z kwantyzacji dla efektywności operacyjnej
  - Porównania wydajności i zużycia pamięci
- [**Sekcja 2: Przewodnik po implementacji Llama.cpp**](./Module04/02.Llamacpp.md)
  - Instalacja na różnych platformach (Windows, macOS, Linux)
  - Konwersja do formatu GGUF i poziomy kwantyzacji (Q2_K do Q8_0)
  - Przyspieszenie sprzętowe (CUDA, Metal, OpenCL, Vulkan)
  - Integracja z Pythonem i wdrożenie REST API

- [**Sekcja 3: Microsoft Olive Optimization Suite**](./Module04/03.MicrosoftOlive.md)
  - Optymalizacja modeli uwzględniająca sprzęt z ponad 40 wbudowanymi komponentami
  - Automatyczna optymalizacja z dynamiczną i statyczną kwantyzacją
  - Integracja z Azure ML w środowiskach korporacyjnych
  - Obsługa popularnych modeli (Llama, Phi, wybrane modele Qwen, Gemma)

- [**Sekcja 4: OpenVINO Toolkit Optimization Suite**](./Module04/04.openvino.md)
  - Otwarty zestaw narzędzi Intela do wdrożeń AI na różnych platformach
  - Framework kompresji sieci neuronowych (NNCF) dla zaawansowanej optymalizacji
  - OpenVINO GenAI do wdrożeń dużych modeli językowych
  - Przyspieszenie sprzętowe na CPU, GPU, VPU i akceleratorach AI

- [**Sekcja 5: Apple MLX Framework - Szczegółowe omówienie**](./Module04/05.AppleMLX.md)
  - Zunifikowana architektura pamięci dla Apple Silicon
  - Obsługa modeli LLaMA, Mistral, Phi, wybranych modeli Qwen
  - Dostosowywanie modeli i fine-tuning LoRA
  - Integracja z Hugging Face z kwantyzacją 4-bitową/8-bitową

- [**Sekcja 6: Synteza przepływu pracy Edge AI**](./Module04/06.workflow-synthesis.md)
  - Zunifikowana architektura przepływu pracy integrująca różne frameworki optymalizacyjne
  - Drzewa decyzyjne wyboru frameworków i analiza kompromisów wydajności
  - Walidacja gotowości produkcyjnej i kompleksowe strategie wdrożeniowe
  - Strategie przyszłościowe dla nowo pojawiającego się sprzętu i architektur modeli

---

### [Moduł 05: SLMOps - Operacje na małych modelach językowych](./Module05/README.md)
**Temat**: Kompleksowe operacje na SLM od destylacji do wdrożenia produkcyjnego

#### Struktura rozdziałów:
- [**Sekcja 1: Wprowadzenie do SLMOps**](./Module05/01.IntroduceSLMOps.md)
  - Zmiana paradygmatu w operacjach AI dzięki SLMOps
  - Efektywność kosztowa i architektura z priorytetem prywatności
  - Strategiczny wpływ na biznes i przewagi konkurencyjne
  - Wyzwania i rozwiązania w rzeczywistych wdrożeniach

- [**Sekcja 2: Destylacja modelu - od teorii do praktyki**](./Module05/02.SLMOps-Distillation.md)
  - Transfer wiedzy z modeli nauczyciela do modeli ucznia
  - Implementacja procesu destylacji w dwóch etapach
  - Przykłady praktyczne destylacji w Azure ML
  - Redukcja czasu inferencji o 85% przy zachowaniu 92% dokładności

- [**Sekcja 3: Fine-Tuning - Dostosowywanie modeli do konkretnych zadań**](./Module05/03.SLMOps-Finetuing.md)
  - Techniki efektywnego dostrajania parametrów (PEFT)
  - Zaawansowane metody LoRA i QLoRA
  - Implementacja fine-tuningu w Microsoft Olive
  - Trening z wieloma adapterami i optymalizacja hiperparametrów

- [**Sekcja 4: Wdrożenie - Implementacja gotowa do produkcji**](./Module05/04.SLMOps.Deployment.md)
  - Konwersja modeli i kwantyzacja na potrzeby produkcji
  - Konfiguracja wdrożenia w Foundry Local
  - Benchmarking wydajności i walidacja jakości
  - Redukcja rozmiaru o 75% z monitorowaniem produkcji

---

### [Moduł 06: Systemy agentowe SLM - Agenci AI i wywoływanie funkcji](./Module06/README.md)
**Temat**: Implementacja systemów agentowych SLM od podstaw do zaawansowanego wywoływania funkcji i integracji Model Context Protocol

#### Struktura rozdziałów:
- [**Sekcja 1: Podstawy agentów AI i małych modeli językowych**](./Module06/01.IntroduceAgent.md)
  - Ramy klasyfikacji agentów (refleksyjni, oparte na modelu, oparte na celach, uczący się agenci)
  - Podstawy SLM i strategie optymalizacji (GGUF, kwantyzacja, frameworki edge)
  - Analiza kompromisów SLM vs LLM (redukcja kosztów o 10-30×, skuteczność zadań 70-80%)
  - Praktyczne wdrożenia z Ollama, VLLM i rozwiązaniami Microsoft edge

- [**Sekcja 2: Wywoływanie funkcji w małych modelach językowych**](./Module06/02.FunctionCalling.md)
  - Systematyczna implementacja przepływu pracy (detekcja intencji, wyjście JSON, zewnętrzne wykonanie)
  - Implementacje specyficzne dla platform (Phi-4-mini, wybrane modele Qwen, Microsoft Foundry Local)
  - Zaawansowane przykłady (współpraca wielu agentów, dynamiczny wybór narzędzi)
  - Rozważania produkcyjne (ograniczenia szybkości, logowanie audytowe, środki bezpieczeństwa)

- [**Sekcja 3: Integracja Model Context Protocol (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architektura protokołu i projekt systemu warstwowego
  - Obsługa wielu backendów (Ollama dla rozwoju, vLLM dla produkcji)
  - Protokoły połączeń (tryby STDIO i SSE)
  - Zastosowania w rzeczywistości (automatyzacja webowa, przetwarzanie danych, integracja API)

---

### [Moduł 07: Przykłady implementacji EdgeAI](./Module07/README.md)
**Temat**: Kompleksowe implementacje EdgeAI na różnych platformach i w różnych frameworkach

#### Struktura rozdziałów:
- [**Zestaw narzędzi AI dla Visual Studio Code**](./Module07/aitoolkit.md)
  - Kompleksowe środowisko rozwoju Edge AI w VS Code
  - Katalog modeli i ich odkrywanie na potrzeby wdrożeń edge
  - Lokalne testowanie, optymalizacja i przepływy pracy rozwoju agentów
  - Monitorowanie wydajności i ocena dla scenariuszy edge

- [**Przewodnik rozwoju EdgeAI na Windows**](./Module07/windowdeveloper.md)
  - Kompleksowy przegląd platformy Windows AI Foundry
  - API Phi Silica dla efektywnego wnioskowania na NPU
  - API Computer Vision do przetwarzania obrazów i OCR
  - Foundry Local CLI do lokalnego rozwoju i testowania

- [**EdgeAI na NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Wydajność AI na poziomie 67 TOPS w formacie wielkości karty kredytowej
  - Obsługa modeli generatywnych AI (transformery wizji, LLM, modele wizji-języka)
  - Zastosowania w robotyce, dronach, inteligentnych kamerach, urządzeniach autonomicznych
  - Przystępna platforma za $249 dla demokratyzacji rozwoju AI

- [**EdgeAI w aplikacjach mobilnych z .NET MAUI i ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - AI mobilne na różnych platformach z jedną bazą kodu w C#
  - Obsługa przyspieszenia sprzętowego (CPU, GPU, mobilne procesory AI)
  - Optymalizacje specyficzne dla platform (CoreML dla iOS, NNAPI dla Androida)
  - Kompleksowa implementacja pętli generatywnej AI

- [**EdgeAI w Azure z silnikiem małych modeli językowych**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architektura hybrydowa wdrożeń chmura-edge
  - Integracja usług Azure AI z ONNX Runtime
  - Wdrożenia na skalę korporacyjną i ciągłe zarządzanie modelami
  - Hybrydowe przepływy pracy AI dla inteligentnego przetwarzania dokumentów

- [**EdgeAI z Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Podstawa Windows AI Foundry dla wydajnego wnioskowania na urządzeniu
  - Uniwersalne wsparcie sprzętowe (AMD, Intel, NVIDIA, Qualcomm)
  - Automatyczna abstrakcja sprzętu i optymalizacja
  - Zunifikowany framework dla różnorodnego ekosystemu sprzętu Windows

- [**EdgeAI z aplikacjami Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Implementacja RAG z priorytetem prywatności przy użyciu zasobów lokalnych
  - Integracja modelu językowego Phi-4 z wyszukiwaniem semantycznym (tylko modele Phi)
  - Obsługa lokalnych baz danych wektorowych (SQLite, Qdrant)
  - Suwerenność danych i możliwości działania offline

### [Moduł 08: Microsoft Foundry Local – Kompletny zestaw narzędzi dla deweloperów](./Module08/README.md)
**Temat**: Tworzenie, uruchamianie i integracja AI lokalnie z Foundry Local; skalowanie i hybrydyzacja z Azure AI Foundry

#### Struktura rozdziałów:
- [**1: Rozpoczęcie pracy z Foundry Local**](./Module08/01.FoundryLocalSetup.md)
- [**2: Tworzenie rozwiązań AI z Azure AI Foundry**](./Module08/02.AzureAIFoundryIntegration.md)
- [**3: Modele open-source w Foundry Local**](./Module08/03.OpenSourceModels.md)
- [**4: Najnowocześniejsze modele i wnioskowanie na urządzeniu**](./Module08/04.CuttingEdgeModels.md)
- [**5: Agenci zasilani AI w Foundry Local**](./Module08/05.AIPoweredAgents.md)
- [**6: Modele jako narzędzia**](./Module08/06.ModelsAsTools.md)

## Cele kursu

Po ukończeniu tego kompleksowego kursu EdgeAI zdobędziesz wiedzę i umiejętności potrzebne do projektowania, implementacji i wdrożenia gotowych do produkcji rozwiązań EdgeAI. Nasze podejście strukturalne zapewnia opanowanie zarówno podstaw teoretycznych, jak i praktycznych umiejętności implementacyjnych.

### Kompetencje techniczne

**Podstawowa wiedza**
- Zrozumienie fundamentalnych różnic między architekturami AI opartymi na chmurze a edge
- Opanowanie zasad kwantyzacji modeli, kompresji i optymalizacji dla środowisk o ograniczonych zasobach
- Zrozumienie opcji przyspieszenia sprzętowego (NPU, GPU, CPU) i ich implikacji wdrożeniowych

**Umiejętności implementacyjne**
- Wdrożenie małych modeli językowych na różnych platformach edge (mobilnych, wbudowanych, IoT, serwerach edge)
- Zastosowanie frameworków optymalizacyjnych, takich jak Llama.cpp, Microsoft Olive, ONNX Runtime i Apple MLX
- Implementacja systemów wnioskowania w czasie rzeczywistym z wymaganiami subsekundowymi

**Ekspertyza produkcyjna**
- Projektowanie skalowalnych architektur EdgeAI dla aplikacji korporacyjnych
- Implementacja strategii monitorowania, konserwacji i aktualizacji dla wdrożonych systemów
- Zastosowanie najlepszych praktyk bezpieczeństwa dla implementacji EdgeAI z priorytetem prywatności

### Zdolności strategiczne

**Ramy decyzyjne**
- Ocena możliwości EdgeAI i identyfikacja odpowiednich przypadków użycia dla aplikacji biznesowych
- Analiza kompromisów między dokładnością modelu, szybkością wnioskowania, zużyciem energii i kosztami sprzętu
- Wybór odpowiednich rodzin SLM i konfiguracji na podstawie specyficznych ograniczeń wdrożeniowych

**Architektura systemu**
- Projektowanie kompleksowych rozwiązań EdgeAI integrujących się z istniejącą infrastrukturą
- Planowanie hybrydowych architektur edge-chmura dla optymalnej wydajności i efektywności kosztowej
- Implementacja przepływów danych i potoków przetwarzania dla aplikacji AI w czasie rzeczywistym

### Zastosowania w przemyśle

**Praktyczne scenariusze wdrożeniowe**
- **Produkcja**: Systemy kontroli jakości, predykcyjna konserwacja i optymalizacja procesów
- **Opieka zdrowotna**: Narzędzia diagnostyczne z priorytetem prywatności i systemy monitorowania pacjentów
- **Transport**: Podejmowanie decyzji przez pojazdy autonomiczne i zarządzanie ruchem
- **Inteligentne miasta**: Inteligentna infrastruktura i systemy zarządzania zasobami
- **Elektronika użytkowa**: Aplikacje mobilne zasilane AI i urządzenia inteligentnego domu

## Przegląd wyników nauki

### Wyniki nauki Modułu 01:
- Zrozumienie fundamentalnych różnic między architekturami AI opartymi na chmurze a edge
- Opanowanie podstawowych technik optymalizacji dla wdrożeń edge
- Rozpoznanie rzeczywistych zastosowań i historii sukcesu
- Zdobycie praktycznych umiejętności w implementacji rozwiązań EdgeAI

### Wyniki nauki Modułu 02:
- Głębokie zrozumienie różnych filozofii projektowania SLM i ich implikacji wdrożeniowych
- Opanowanie strategicznych zdolności decyzyjnych na podstawie ograniczeń obliczeniowych i wymagań wydajnościowych
- Zrozumienie kompromisów w elastyczności wdrożeniowej
- Posiadanie przyszłościowych spostrzeżeń na temat efektywnej architektury AI

### Wyniki nauki Modułu 03:
- Zdolności strategicznego wyboru modeli
- Opanowanie technik optymalizacji
- Opanowanie elastyczności wdrożeniowej
- Zdolności konfiguracji gotowej do produkcji

### Wyniki nauki Modułu 04:
- Głębokie zrozumienie granic kwantyzacji i praktycznych zastosowań
- Praktyczne doświadczenie z wieloma frameworkami optymalizacyjnymi (Llama.cpp, Olive, OpenVINO, MLX)
- Opanowanie optymalizacji sprzętu Intela z OpenVINO i NNCF
- Zdolności wyboru optymalizacji uwzględniającej sprzęt na różnych platformach
- Umiejętności wdrożeniowe dla środowisk edge computing na różnych platformach
- Strategiczny wybór frameworków i synteza przepływu pracy dla optymalnych rozwiązań Edge AI

### Wyniki nauki Modułu 05:
- Opanowanie paradygmatu SLMOps i zasad operacyjnych
- Implementacja destylacji modeli dla transferu wiedzy i optymalizacji efektywności
- Zastosowanie technik fine-tuningu dla dostosowania modeli do specyficznych dziedzin
- Wdrożenie gotowych do produkcji rozwiązań SLM z monitorowaniem i strategiami konserwacji

### Wyniki nauki Modułu 06:
- Zrozumienie podstawowych koncepcji agentów AI i architektury małych modeli językowych
- Opanowanie implementacji wywoływania funkcji na różnych platformach i w różnych frameworkach
- Integracja Model Context Protocol (MCP) dla standaryzowanej interakcji z narzędziami zewnętrznymi
- Budowa zaawansowanych systemów agentowych z minimalnymi wymaganiami interwencji człowieka

### Wyniki nauki Modułu 07:
- Opanowanie zestawu narzędzi AI dla Visual Studio Code dla kompleksowych przepływów pracy Edge AI
- Zdobycie ekspertyzy w platformie Windows AI Foundry i strategiach optymalizacji NPU
- Praktyczne doświadczenie z różnorodnymi platformami EdgeAI i strategiami implementacyjnymi
- Opanowanie technik optymalizacji specyficznych dla sprzętu na platformach NVIDIA, mobilnych, Azure i Windows
- Zrozumienie kompromisów wdrożeniowych między wydajnością, kosztami i wymaganiami prywatności
- Rozwój praktycznych umiejętności w budowie rzeczywistych aplikacji EdgeAI w różnych ekosystemach

## Oczekiwane wyniki kursu

Po pomy
- **Zarządzanie ryzykiem**: Identyfikacja i minimalizowanie ryzyk technicznych oraz operacyjnych w wdrożeniach EdgeAI  
- **Optymalizacja ROI**: Wykazanie mierzalnej wartości biznesowej wynikającej z implementacji EdgeAI  

### Możliwości rozwoju kariery  

**Profesjonalne role**  
- Architekt rozwiązań EdgeAI  
- Inżynier uczenia maszynowego (specjalizacja Edge)  
- Programista IoT AI  
- Programista aplikacji mobilnych AI  
- Konsultant AI dla przedsiębiorstw  

**Sektory przemysłowe**  
- Inteligentna produkcja i Przemysł 4.0  
- Pojazdy autonomiczne i transport  
- Technologie medyczne i urządzenia medyczne  
- Technologie finansowe i bezpieczeństwo  
- Elektronika użytkowa i aplikacje mobilne  

### Certyfikacja i weryfikacja  

**Rozwój portfolio**  
- Realizacja kompleksowych projektów EdgeAI, które pokazują praktyczne umiejętności  
- Wdrażanie rozwiązań gotowych do produkcji na różnych platformach sprzętowych  
- Dokumentowanie strategii optymalizacji i osiągniętych ulepszeń wydajności  

**Ścieżka ciągłego uczenia się**  
- Podstawa dla zaawansowanych specjalizacji AI  
- Przygotowanie do architektur hybrydowych chmura-edge  
- Brama do nowych technologii i frameworków AI  

Ten kurs stawia Cię na czele wdrożeń technologii AI, gdzie inteligentne funkcje są płynnie integrowane z urządzeniami i systemami, które napędzają współczesne życie.  

## Diagram struktury plików  

```
edgeai-for-beginners/
├── imgs/
│   └── cover.png
├── Module01/ (EdgeAI Fundamentals and Transformation)
│   ├── 01.EdgeAIFundamentals.md
│   ├── 02.RealWorldCaseStudies.md
│   ├── 03.PracticalImplementationGuide.md
│   ├── 04.EdgeDeployment.md
│   └── README.md
├── Module02/ (Small Language Model Foundations)
│   ├── 01.PhiFamily.md
│   ├── 02.QwenFamily.md
│   ├── 03.GemmaFamily.md
│   ├── 04.BitNETFamily.md
│   ├── 05.mumodel.md
│   ├── 06.phisilica.md
│   └── README.md
├── Module03/ (SLM Deployment Practice)
│   ├── 01.SLMAdvancedLearning.md
│   ├── 02.DeployingSLMinLocalEnv.md
│   ├── 03.DeployingSLMinCloud.md
│   └── README.md
├── Module04/ (Model Format Conversion and Quantization)
│   ├── 01.Introduce.md
│   ├── 02.Llamacpp.md
│   ├── 03.MicrosoftOlive.md
│   ├── 04.openvino.md
│   ├── 05.AppleMLX.md
│   ├── 06.workflow-synthesis.md
│   └── README.md
├── Module05/ (SLMOps - Small Language Model Operations)
│   ├── 01.IntroduceSLMOps.md
│   ├── 02.SLMOps-Distillation.md
│   ├── 03.SLMOps-Finetuing.md
│   ├── 04.SLMOps.Deployment.md
│   └── README.md
├── Module06/ (SLM Agentic Systems)
│   ├── 01.IntroduceAgent.md
│   ├── 02.FunctionCalling.md
│   ├── 03.IntroduceMCP.md
│   └── README.md
├── Module07/ (EdgeAI Implementation Samples)
│   ├── aitoolkit.md
│   ├── windowdeveloper.md
│   └── README.md
├── Module08/ (Hands on with Foundry Local)
│   ├── 01.FoundryLocalSetup.md
│   ├── 02.AzureAIFoundryIntegration.md
│   ├── 03.OpenSourceModels.md
│   ├── 04.CuttingEdgeModels.md
│   ├── 05.AIPoweredAgents.md
│   ├── 06.ModelsAsTools.md
│   └── README.md
├── CODE_OF_CONDUCT.md
├── LICENSE
├── README.md (This file)
├── SECURITY.md
├── STUDY_GUIDE.md
└── SUPPORT.md
```
  

## Funkcje kursu  

- **Progresywne uczenie się**: Stopniowe przechodzenie od podstawowych pojęć do zaawansowanych wdrożeń  
- **Integracja teorii i praktyki**: Każdy moduł zawiera zarówno podstawy teoretyczne, jak i operacje praktyczne  
- **Prawdziwe studia przypadków**: Oparte na rzeczywistych przykładach z Microsoft, Alibaba, Google i innych  
- **Praktyczne ćwiczenia**: Pełne pliki konfiguracyjne, procedury testowania API i skrypty wdrożeniowe  
- **Benchmarki wydajności**: Szczegółowe porównania szybkości wnioskowania, wykorzystania pamięci i wymagań zasobowych  
- **Rozważania na poziomie przedsiębiorstwa**: Praktyki bezpieczeństwa, ramy zgodności i strategie ochrony danych  

## Rozpoczęcie  

Rekomendowana ścieżka nauki:  
1. Rozpocznij od **Module01**, aby zbudować podstawowe zrozumienie EdgeAI  
2. Przejdź do **Module02**, aby dogłębnie poznać różne rodziny modeli SLM  
3. Naucz się **Module03**, aby opanować praktyczne umiejętności wdrożeniowe  
4. Kontynuuj z **Module04**, aby zgłębić zaawansowaną optymalizację modeli, konwersję formatów i syntezę frameworków  
5. Ukończ **Module05**, aby opanować SLMOps dla implementacji gotowych do produkcji  
6. Eksploruj **Module06**, aby zrozumieć systemy agentowe SLM i możliwości wywoływania funkcji  
7. Zakończ **Module07**, aby zdobyć praktyczne doświadczenie z AI Toolkit i różnorodnymi przykładami implementacji EdgeAI  
8. Eksploruj **Module08**, aby uzyskać kompletny zestaw narzędzi Foundry Local dla programistów (rozwój lokalny z hybrydową integracją Azure)  

Każdy moduł jest zaprojektowany jako niezależny, ale nauka w kolejności zapewni najlepsze rezultaty.  

## Przewodnik nauki  

Dostępny jest kompleksowy [Przewodnik nauki](STUDY_GUIDE.md), który pomoże Ci maksymalnie wykorzystać doświadczenie edukacyjne. Przewodnik oferuje:  

- **Strukturalne ścieżki nauki**: Optymalny harmonogram ukończenia kursu w 20 godzin  
- **Wskazówki dotyczące alokacji czasu**: Konkretne rekomendacje dotyczące równoważenia czytania, ćwiczeń i projektów  
- **Skupienie na kluczowych pojęciach**: Priorytetowe cele nauki dla każdego modułu  
- **Narzędzia samooceny**: Pytania i ćwiczenia do sprawdzenia zrozumienia  
- **Pomysły na mini-projekty**: Praktyczne zastosowania wzmacniające naukę  

Przewodnik jest zaprojektowany zarówno dla intensywnej nauki (1 tydzień), jak i nauki w niepełnym wymiarze godzin (3 tygodnie), z jasnymi wskazówkami, jak efektywnie zarządzać czasem, nawet jeśli możesz poświęcić tylko 10 godzin na kurs.  

---

**Przyszłość EdgeAI leży w ciągłym doskonaleniu architektur modeli, technik kwantyzacji i strategii wdrożeniowych, które priorytetowo traktują efektywność i specjalizację nad możliwościami ogólnego przeznaczenia. Organizacje, które przyjmą tę zmianę paradygmatu, będą dobrze przygotowane do wykorzystania transformacyjnego potencjału AI, jednocześnie zachowując kontrolę nad swoimi danymi i operacjami.**  

## Inne kursy  

Nasza ekipa tworzy inne kursy! Sprawdź:  

- [MCP dla początkujących](https://github.com/microsoft/mcp-for-beginners)  
- [AI Agents dla początkujących](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [Generative AI dla początkujących z użyciem .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)  
- [Generative AI dla początkujących z użyciem JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)  
- [Generative AI dla początkujących](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [ML dla początkujących](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)  
- [Data Science dla początkujących](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)  
- [AI dla początkujących](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)  
- [Cyberbezpieczeństwo dla początkujących](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)  
- [Web Dev dla początkujących](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)  
- [IoT dla początkujących](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)  
- [XR Development dla początkujących](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [Opanowanie GitHub Copilot dla programowania w parach z AI](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)  
- [Opanowanie GitHub Copilot dla programistów C#/.NET](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)  
- [Wybierz swoją własną przygodę z Copilot](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)  

---

