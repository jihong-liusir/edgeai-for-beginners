<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-17T15:09:25+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "pl"
}
-->
# Sekcja02: Wywoływanie funkcji w małych modelach językowych (SLMs)

## Spis treści
1. [Czym jest wywoływanie funkcji?](../../../Module06)
2. [Jak działa wywoływanie funkcji](../../../Module06)
3. [Scenariusze zastosowań](../../../Module06)
4. [Konfiguracja wywoływania funkcji z Phi-4-mini i Ollama](../../../Module06)
5. [Praca z wywoływaniem funkcji w Qwen3](../../../Module06)
6. [Integracja lokalna Foundry](../../../Module06)
7. [Najlepsze praktyki i rozwiązywanie problemów](../../../Module06)
8. [Zaawansowane przykłady](../../../Module06)

## Czym jest wywoływanie funkcji?

Wywoływanie funkcji to potężna funkcjonalność, która pozwala małym modelom językowym (SLMs) na interakcję z zewnętrznymi narzędziami, API i usługami. Zamiast ograniczać się do danych treningowych, SLM-y mogą teraz:

- **Łączyć się z zewnętrznymi API** (usługi pogodowe, bazy danych, wyszukiwarki)
- **Wykonywać określone funkcje** na podstawie żądań użytkownika
- **Pobierać informacje w czasie rzeczywistym** z różnych źródeł
- **Przeprowadzać zadania obliczeniowe** za pomocą wyspecjalizowanych narzędzi
- **Łączyć wiele operacji** w celu realizacji złożonych procesów

Ta funkcjonalność przekształca SLM-y z generatorów tekstu w dynamiczne agentów AI zdolnych do wykonywania rzeczywistych zadań.

## Jak działa wywoływanie funkcji

Proces wywoływania funkcji przebiega według określonego schematu:

### 1. Integracja narzędzi
- **Zewnętrzne narzędzia**: SLM-y mogą łączyć się z API pogodowymi, bazami danych, usługami internetowymi i innymi systemami
- **Definicje funkcji**: Każde narzędzie jest zdefiniowane z określonymi parametrami, formatami wejścia/wyjścia i opisami
- **Kompatybilność API**: Narzędzia są integrowane za pomocą standardowych interfejsów (REST API, SDK itp.)

### 2. Definicja funkcji
Funkcje są definiowane z trzema kluczowymi komponentami:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Wykrywanie intencji
- **Przetwarzanie języka naturalnego**: SLM analizuje dane wejściowe użytkownika, aby zrozumieć intencję
- **Dopasowanie funkcji**: Określa, które funkcje są potrzebne do realizacji żądania
- **Ekstrakcja parametrów**: Identyfikuje i wyodrębnia wymagane parametry z wiadomości użytkownika

### 4. Generowanie wyjścia JSON
SLM generuje ustrukturyzowany JSON zawierający:
- Nazwę funkcji do wywołania
- Wymagane parametry z odpowiednimi wartościami
- Kontekst wykonania i metadane

### 5. Wykonanie zewnętrzne
- **Walidacja parametrów**: Sprawdza, czy wszystkie wymagane parametry są obecne i poprawnie sformatowane
- **Wykonanie funkcji**: Aplikacja wykonuje określoną funkcję z podanymi parametrami
- **Obsługa błędów**: Zarządza awariami, przekroczeniami czasu i nieprawidłowymi odpowiedziami

### 6. Integracja odpowiedzi
- **Przetwarzanie wyników**: Wynik funkcji jest zwracany do SLM
- **Integracja kontekstu**: SLM włącza wyniki do swojej odpowiedzi
- **Komunikacja z użytkownikiem**: Przedstawia informacje w naturalnym, konwersacyjnym formacie

## Scenariusze zastosowań

### Pobieranie danych
Konwertowanie zapytań w języku naturalnym na ustrukturyzowane wywołania API:
- **"Pokaż moje ostatnie zamówienia"** → Zapytanie do bazy danych z ID użytkownika i filtrami daty
- **"Jaka jest pogoda w Tokio?"** → Wywołanie API pogodowego z parametrem lokalizacji
- **"Znajdź e-maile od Johna z zeszłego tygodnia"** → Zapytanie do usługi e-mail z nadawcą i filtrami daty

### Wykonywanie operacji
Przekształcanie żądań użytkownika w konkretne wywołania funkcji:
- **"Zaplanuj spotkanie na jutro o 14:00"** → Integracja z API kalendarza
- **"Wyślij wiadomość do zespołu"** → API platformy komunikacyjnej
- **"Utwórz kopię zapasową moich plików"** → Operacja systemu plików

### Zadania obliczeniowe
Obsługa złożonych operacji matematycznych lub logicznych:
- **"Oblicz odsetki składane od 10 000 USD przy 5% na 10 lat"** → Funkcja obliczeń finansowych
- **"Przeanalizuj ten zestaw danych pod kątem trendów"** → Narzędzia analizy statystycznej
- **"Optymalizuj trasę dla dostawy"** → Algorytmy optymalizacji tras

### Przetwarzanie danych
Łączenie wielu wywołań funkcji w celu realizacji złożonych operacji:
1. **Pobieranie danych** z wielu źródeł
2. **Parsowanie i walidacja** informacji
3. **Transformacja** danych do wymaganego formatu
4. **Przechowywanie wyników** w odpowiednich systemach
5. **Generowanie raportów** lub wizualizacji

### Integracja UI/UX
Umożliwienie dynamicznych aktualizacji interfejsu:
- **"Pokaż dane sprzedaży na pulpicie"** → Generowanie i wyświetlanie wykresów
- **"Zaktualizuj mapę o nowe lokalizacje"** → Integracja danych geograficznych
- **"Odśwież wyświetlanie zapasów"** → Synchronizacja danych w czasie rzeczywistym

## Konfiguracja wywoływania funkcji z Phi-4-mini i Ollama

Phi-4-mini firmy Microsoft obsługuje zarówno pojedyncze, jak i równoległe wywoływanie funkcji za pomocą Ollama. Oto jak to skonfigurować:

### Wymagania wstępne
- Ollama w wersji 0.5.13 lub wyższej
- Model Phi-4-mini (zalecany: `phi4-mini:3.8b-fp16`)

### Kroki instalacji

#### 1. Instalacja i uruchomienie Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Utworzenie niestandardowego szablonu ModelFile
Ze względu na obecne ograniczenia w domyślnych szablonach Ollama, należy utworzyć niestandardowy ModelFile z następującym szablonem:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Utworzenie niestandardowego modelu
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Przykład wywoływania pojedynczej funkcji

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Przykład wywoływania funkcji równoległych

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Praca z wywoływaniem funkcji w Qwen3

Qwen3 oferuje zaawansowane możliwości wywoływania funkcji z doskonałą wydajnością i elastycznością. Oto jak to zaimplementować:

### Korzystanie z frameworka Qwen-Agent

Qwen-Agent zapewnia wysokopoziomowy framework upraszczający implementację wywoływania funkcji:

#### Instalacja
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Podstawowa konfiguracja

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Implementacja niestandardowych funkcji

Możesz również definiować niestandardowe funkcje dla Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Zaawansowane funkcje Qwen3

#### Kontrola trybu myślenia
Qwen3 obsługuje dynamiczne przełączanie między trybem myślenia a trybem bez myślenia:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Wywoływanie funkcji wieloetapowych
Qwen3 doskonale radzi sobie z łączeniem wielu wywołań funkcji:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Integracja lokalna Foundry

Foundry Local firmy Microsoft zapewnia API kompatybilne z OpenAI do uruchamiania modeli lokalnie z ulepszoną prywatnością i wydajnością.

### Konfiguracja i instalacja

#### Windows
Pobierz instalator ze strony [Foundry Local releases](https://github.com/microsoft/Foundry-Local/releases) i postępuj zgodnie z instrukcjami instalacji.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Podstawowe użycie

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Zaawansowane funkcje Foundry Local

#### Zarządzanie modelami
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Optymalizacja wydajności
Foundry Local automatycznie wybiera najlepszy wariant modelu dla Twojego sprzętu:
- **CUDA GPU**: Pobiera modele zoptymalizowane pod kątem GPU
- **Qualcomm NPU**: Korzysta z wariantów przyspieszonych przez NPU
- **Tylko CPU**: Wybiera modele zoptymalizowane pod kątem CPU

## Najlepsze praktyki i rozwiązywanie problemów

### Najlepsze praktyki definiowania funkcji

#### 1. Jasne i opisowe nazewnictwo
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Kompleksowe definicje parametrów
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Walidacja danych wejściowych i obsługa błędów
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Typowe problemy i rozwiązania

#### Problem 1: Funkcja nie jest wywoływana
**Objawy**: Model odpowiada tekstem zamiast wywoływać funkcję

**Rozwiązania**:
1. **Sprawdź opis funkcji**: Upewnij się, że jasno odpowiada intencji użytkownika
2. **Zweryfikuj definicje parametrów**: Upewnij się, że wszystkie wymagane parametry są poprawnie zdefiniowane
3. **Przejrzyj prompt systemowy**: Dodaj jasne instrukcje dotyczące używania funkcji
4. **Testuj z wyraźnymi żądaniami**: Spróbuj "Proszę użyć funkcji pogodowej, aby uzyskać dane dla Londynu"

#### Problem 2: Nieprawidłowe parametry
**Objawy**: Funkcja wywoływana z błędnymi lub brakującymi parametrami

**Rozwiązania**:
1. **Dodaj przykłady parametrów**: Uwzględnij przykładowe wartości w opisach parametrów
2. **Użyj ograniczeń enum**: Ogranicz wartości parametrów do określonych opcji, jeśli to możliwe
3. **Zastosuj wartości domyślne**: Zapewnij sensowne wartości domyślne dla opcjonalnych parametrów

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Problem 3: Awaria wywoływania funkcji równoległych
**Objawy**: Tylko jedna funkcja jest wykonywana, gdy powinny działać wiele

**Rozwiązania**:
1. **Sprawdź wsparcie modelu**: Upewnij się, że Twój model obsługuje równoległe wywoływanie funkcji
2. **Zaktualizuj prompt systemowy**: Uwzględnij "niektóre narzędzia" lub "wiele narzędzi" w wiadomości systemowej
3. **Użyj odpowiednich wersji modelu**: Zalecany Phi-4-mini:3.8b-fp16 dla Ollama

#### Problem 4: Problemy z szablonem w Ollama
**Objawy**: Wywoływanie funkcji nie działa z domyślną konfiguracją Ollama

**Rozwiązania**:
1. **Użyj niestandardowego ModelFile**: Zastosuj poprawiony szablon podany w tym samouczku
2. **Zaktualizuj Ollama**: Upewnij się, że używasz wersji 0.5.13 lub wyższej
3. **Sprawdź kwantyzację modelu**: Wyższe poziomy kwantyzacji (Q8_0, fp16) działają lepiej niż mocno skwantyzowane wersje

### Optymalizacja wydajności

#### 1. Efektywne projektowanie funkcji
- **Skup się na funkcjach**: Każda funkcja powinna mieć jeden, jasny cel
- **Minimalizuj zależności zewnętrzne**: Ogranicz wywołania API i żądania sieciowe, jeśli to możliwe
- **Buforuj wyniki**: Przechowuj często żądane dane, aby poprawić czas odpowiedzi

#### 2. Grupowanie i operacje asynchroniczne
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Zarządzanie zasobami
- **Pula połączeń**: Ponowne użycie połączeń z bazą danych i API
- **Ograniczanie szybkości**: Wprowadź odpowiednie ograniczenia szybkości dla zewnętrznych API
- **Obsługa przekroczeń czasu**: Ustaw rozsądne limity czasu dla wszystkich wywołań zewnętrznych

## Zaawansowane przykłady

### System współpracy wieloagentowej

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### System dynamicznego wyboru narzędzi

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Standardowy format wyników dla wszystkich wywołań funkcji"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Agent AI gotowy do produkcji z kompleksowymi możliwościami wywoływania funkcji"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Inicjalizacja podstawowych funkcji biznesowych
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Rejestracja wszystkich dostępnych funkcji biznesowych"""
        
        # Funkcje CRM
        self.register_function(
            name="get_customer_info",
            description="Pobierz informacje o kliencie z CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # wywołań na minutę
        )
        
        # Funkcje sprzedaży
        self.register_function(
            name="create_sales_opportunity",
            description="Utwórz nową szansę sprzedaży",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Funkcje analityczne
        self.register_function(
            name="generate_sales_report",
            description="Generuj raport wydajności sprzedaży",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Funkcje powiadomień
        self.register_function(
            name="send_notification",
            description="Wyślij powiadomienie do członków zespołu",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Rejestracja nowej funkcji w agencie"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Proszę podać treść pliku markdown, który mam przetłumaczyć.
"""Wykonaj funkcję z kompleksową obsługą błędów i logowaniem"""
start_time = datetime.now()

try:
    # Sprawdź, czy funkcja istnieje
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Funkcja '{function_name}' nie została znaleziona",
            timestamp=start_time
        )
    
    # Sprawdź limity wywołań
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Przekroczono limit wywołań dla funkcji '{function_name}'",
            timestamp=start_time
        )
    
    # Zweryfikuj parametry
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Wykonaj funkcję
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Zaloguj pomyślne wykonanie
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Zaloguj nieudane wykonanie
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Sprawdź, czy wywołanie funkcji mieści się w limitach"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Zresetuj licznik, jeśli minęła minuta
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Sprawdź, czy limit nie został przekroczony
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Zweryfikuj parametry funkcji"""
    func_params = self.functions[function_name]['parameters']
    
    # Sprawdź wymagane parametry
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Brak wymaganego parametru: {param_name}"
            )
    
    # Zweryfikuj typy i ograniczenia parametrów
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Walidacja typu
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Parametr '{param_name}' musi być typu string"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Parametr '{param_name}' musi być typu number"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Parametr '{param_name}' musi być typu boolean"
                )
            
            # Walidacja wartości enum
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Parametr '{param_name}' musi być jednym z: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Zaloguj wywołanie funkcji do celów audytu"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Opcjonalnie zapisz do zewnętrznego systemu logowania
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Zapisz wpis logu do zewnętrznego systemu logowania"""
    # Implementacja zależy od infrastruktury logowania
    # np. wysyłanie do ELK stack, CloudWatch, itp.
    pass

# Implementacje funkcji biznesowych
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Pobierz informacje o kliencie z systemu CRM"""
    # Symulacja wywołania bazy danych/API
    await asyncio.sleep(0.1)  # Symulacja opóźnienia sieciowego
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Produkt A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Produkt B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """Utwórz nową szansę sprzedaży"""
    # Symulacja wywołania API CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """Wygeneruj kompleksowy raport sprzedaży"""
    # Symulacja agregacji danych
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'medium', channel: str = 'email') -> Dict:
    """Wyślij powiadomienie przez określony kanał"""
    # Symulacja wywołania usługi powiadomień
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Pobierz definicje funkcji kompatybilnych z OpenAI dla wszystkich zarejestrowanych funkcji"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Przykład użycia dla integracji korporacyjnej
async def enterprise_demo():
    """Demonstracja możliwości agenta AI dla przedsiębiorstw"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Przykład 1: Przetwarzanie zapytań klientów
    print("=== Przetwarzanie zapytań klientów ===")
    
    # Pobierz informacje o kliencie
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Pobrano informacje o kliencie: {result.data['name']}")
        print(f"Czas wykonania: {result.execution_time:.3f}s")
    
    # Przykład 2: Tworzenie szansy sprzedaży
    print("\n=== Tworzenie szansy sprzedaży ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Utworzono szansę: {result.data['opportunity_id']}")
    
    # Przykład 3: Operacje wsadowe
    print("\n=== Operacje wsadowe ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Utworzono nową szansę sprzedaży',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Zadanie {i+1} zakończone sukcesem")
        else:
            print(f"Zadanie {i+1} nie powiodło się: {result.error}")
    
    # Wyświetl log audytu
    print(f"\n=== Log audytu ({len(agent.audit_log)} wpisów) ===")
    for entry in agent.audit_log[-3:]:  # Pokaż ostatnie 3 wpisy
        print(f"{entry['timestamp']}: {entry['function_name']} - {'SUKCES' if entry['success'] else 'NIEPOWODZENIE'}")

# Uruchom demonstrację dla przedsiębiorstw
# asyncio.run(enterprise_demo())

## Podsumowanie

Wywoływanie funkcji w Małych Modelach Językowych (SLM) oznacza przejście od statycznych asystentów AI do dynamicznych, zdolnych agentów, które mogą wchodzić w interakcje ze światem rzeczywistym. Ten poradnik obejmował:

### Kluczowe wnioski

1. **Podstawy**: Wywoływanie funkcji umożliwia SLM rozszerzenie poza dane treningowe poprzez połączenie z zewnętrznymi narzędziami i usługami.

2. **Elastyczność implementacji**: Istnieje wiele podejść, od implementacji niskopoziomowych z własnymi szablonami po zaawansowane frameworki, takie jak Qwen-Agent i Foundry Local.

3. **Rozważania produkcyjne**: Wdrożenia korporacyjne wymagają uwagi na obsługę błędów, limity wywołań, bezpieczeństwo i logowanie audytowe.

4. **Optymalizacja wydajności**: Odpowiednie projektowanie funkcji, efektywne wykonanie i inteligentne buforowanie mogą znacząco poprawić czas odpowiedzi.

### Kierunki na przyszłość

W miarę rozwoju technologii SLM możemy oczekiwać:

- **Lepszej dokładności wywoływania funkcji**: Poprawa wykrywania intencji i ekstrakcji parametrów
- **Zaawansowanego przetwarzania równoległego**: Bardziej zaawansowana orkiestracja wielu funkcji
- **Lepszych standardów integracji**: Standaryzowane protokoły dla integracji narzędzi
- **Zaawansowanych funkcji bezpieczeństwa**: Ulepszone mechanizmy uwierzytelniania i autoryzacji
- **Rozszerzonego ekosystemu**: Rozwój biblioteki gotowych funkcji i integracji

### Jak zacząć

Aby rozpocząć implementację wywoływania funkcji w swoich projektach:

1. **Zacznij od prostych przypadków**: Rozpocznij od podstawowych scenariuszy z jedną funkcją
2. **Wybierz framework**: Wybierz między bezpośrednią implementacją (Ollama/Phi-4) a frameworkiem (Qwen-Agent)
3. **Projektuj funkcje ostrożnie**: Skup się na jasnych, dobrze udokumentowanych definicjach funkcji
4. **Implementuj obsługę błędów**: Od początku buduj solidną obsługę błędów
5. **Skaluj stopniowo**: Przechodź od prostych do bardziej złożonych scenariuszy w miarę zdobywania doświadczenia

Wywoływanie funkcji przekształca SLM z imponujących generatorów tekstu w praktyczne agentów AI zdolnych do rozwiązywania rzeczywistych problemów. Postępując zgodnie z wzorcami i praktykami przedstawionymi w tym poradniku, możesz budować potężne, niezawodne systemy AI, które wykraczają daleko poza tradycyjne interfejsy czatu.

### Zasoby i odniesienia
- **Modele Phi-4**: [Kolekcja Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Dokumentacja Qwen3**: [Oficjalna Dokumentacja Qwen](https://qwen.readthedocs.io/)
- **Ollama**: [Oficjalna Strona](https://ollama.com/)
- **Foundry Local**: [Repozytorium GitHub](https://github.com/microsoft/Foundry-Local)
- **Najlepsze praktyki wywoływania funkcji**: [Przewodnik Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)

Pamiętaj, że wywoływanie funkcji to dynamicznie rozwijająca się dziedzina, a śledzenie najnowszych zmian w wybranych frameworkach i modelach pomoże Ci tworzyć bardziej efektywnych agentów AI.


## ➡️ Co dalej

- [03: Integracja protokołu kontekstu modelu (MCP)](./03.IntroduceMCP.md)

---

**Zastrzeżenie**:  
Ten dokument został przetłumaczony za pomocą usługi tłumaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby tłumaczenie było precyzyjne, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za wiarygodne źródło. W przypadku informacji krytycznych zaleca się skorzystanie z profesjonalnego tłumaczenia wykonanego przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z korzystania z tego tłumaczenia.