<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "50eb9028095f21012291c453fc82b40c",
  "translation_date": "2025-09-17T15:16:55+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "pl"
}
-->
# Agenci AI i Małe Modele Językowe: Kompleksowy Przewodnik

## Wprowadzenie

W tym poradniku zgłębimy temat agentów AI oraz Małych Modeli Językowych (SLM) oraz ich zaawansowane strategie wdrażania w środowiskach obliczeniowych na krawędzi. Omówimy podstawowe pojęcia związane z agentową AI, techniki optymalizacji SLM oraz praktyczne strategie wdrażania na urządzeniach o ograniczonych zasobach.

Krajobraz sztucznej inteligencji przechodzi w 2025 roku fundamentalną zmianę. Podczas gdy rok 2023 był rokiem chatbotów, a 2024 przyniósł boom na copiloty, rok 2025 należy do agentów AI — inteligentnych systemów, które myślą, rozumują, planują, korzystają z narzędzi i wykonują zadania przy minimalnym wkładzie człowieka, coraz częściej napędzane przez wydajne Małe Modele Językowe.

## Cele nauki

Po ukończeniu tego poradnika będziesz w stanie:

- 🤖 Zrozumieć podstawowe pojęcia związane z agentami AI i systemami agentowymi
- 🔬 Zidentyfikować zalety Małych Modeli Językowych w porównaniu z Dużymi Modelami Językowymi w zastosowaniach agentowych
- 🚀 Poznać zaawansowane strategie wdrażania SLM w środowiskach obliczeniowych na krawędzi
- 📱 Wdrożyć praktyczne agenty oparte na SLM w aplikacjach rzeczywistych

## Zrozumienie agentów AI: Podstawy i klasyfikacja

### Definicja i podstawowe pojęcia

Agent sztucznej inteligencji (AI) to system lub program, który potrafi autonomicznie wykonywać zadania w imieniu użytkownika lub innego systemu, projektując swój przepływ pracy i wykorzystując dostępne narzędzia. W przeciwieństwie do tradycyjnej AI, która jedynie odpowiada na pytania, agent może działać niezależnie, aby osiągnąć cele.

### Ramy klasyfikacji agentów

Zrozumienie granic agentów pomaga w wyborze odpowiednich typów agentów dla różnych scenariuszy obliczeniowych:

- **🔬 Proste agenty reaktywne**: Systemy oparte na regułach, które reagują na bieżące postrzeganie (termostaty, podstawowa automatyzacja)
- **📱 Agenty oparte na modelu**: Systemy utrzymujące stan wewnętrzny i pamięć (roboty odkurzające, systemy nawigacyjne)
- **⚖️ Agenty oparte na celach**: Systemy planujące i wykonujące sekwencje działań w celu osiągnięcia celów (planery tras, harmonogramy zadań)
- **🧠 Agenty uczące się**: Systemy adaptacyjne, które poprawiają wydajność w czasie (systemy rekomendacji, spersonalizowani asystenci)

### Kluczowe zalety agentów AI

Agenci AI oferują kilka fundamentalnych zalet, które czynią je idealnymi dla aplikacji obliczeniowych na krawędzi:

**Autonomia operacyjna**: Agenci zapewniają niezależne wykonywanie zadań bez ciągłego nadzoru człowieka, co czyni je idealnymi dla aplikacji w czasie rzeczywistym. Wymagają minimalnego nadzoru, zachowując adaptacyjne zachowanie, co umożliwia wdrażanie na urządzeniach o ograniczonych zasobach przy zmniejszonym obciążeniu operacyjnym.

**Elastyczność wdrażania**: Systemy te umożliwiają działanie AI na urządzeniach bez konieczności połączenia z internetem, zwiększają prywatność i bezpieczeństwo dzięki lokalnemu przetwarzaniu, mogą być dostosowane do specyficznych zastosowań i są odpowiednie dla różnych środowisk obliczeniowych na krawędzi.

**Efektywność kosztowa**: Systemy agentowe oferują opłacalne wdrażanie w porównaniu z rozwiązaniami opartymi na chmurze, z niższymi kosztami operacyjnymi i mniejszymi wymaganiami dotyczącymi przepustowości dla aplikacji na krawędzi.

## Zaawansowane strategie Małych Modeli Językowych

### Podstawy SLM (Małych Modeli Językowych)

Mały Model Językowy (SLM) to model językowy, który może działać na typowym urządzeniu elektronicznym konsumenckim i wykonywać wnioskowanie z opóźnieniem wystarczająco niskim, aby być praktycznym w obsłudze żądań agentowych jednego użytkownika. W praktyce SLM to zazwyczaj modele z mniej niż 10 miliardami parametrów.

**Funkcje odkrywania formatów**: SLM oferują zaawansowane wsparcie dla różnych poziomów kwantyzacji, kompatybilności międzyplatformowej, optymalizacji wydajności w czasie rzeczywistym oraz możliwości wdrażania na krawędzi. Użytkownicy mogą korzystać z zwiększonej prywatności dzięki lokalnemu przetwarzaniu oraz wsparciu WebGPU dla wdrażania w przeglądarkach.

**Kolekcje poziomów kwantyzacji**: Popularne formaty SLM obejmują Q4_K_M dla zrównoważonej kompresji w aplikacjach mobilnych, serię Q5_K_S dla wdrożeń na krawędzi skoncentrowanych na jakości, Q8_0 dla niemal oryginalnej precyzji na wydajnych urządzeniach krawędziowych oraz eksperymentalne formaty, takie jak Q2_K dla scenariuszy o ultra-niskich zasobach.

### GGUF (General GGML Universal Format) dla wdrażania SLM

GGUF służy jako główny format do wdrażania kwantyzowanych SLM na CPU i urządzeniach krawędziowych, specjalnie zoptymalizowany dla aplikacji agentowych:

**Funkcje zoptymalizowane dla agentów**: Format zapewnia kompleksowe zasoby do konwersji i wdrażania SLM z ulepszonym wsparciem dla wywoływania narzędzi, generowania strukturalnych wyników oraz rozmów wieloetapowych. Kompatybilność międzyplatformowa zapewnia spójne zachowanie agentów na różnych urządzeniach krawędziowych.

**Optymalizacja wydajności**: GGUF umożliwia efektywne wykorzystanie pamięci w przepływach pracy agentów, wspiera dynamiczne ładowanie modeli dla systemów wieloagentowych oraz zapewnia zoptymalizowane wnioskowanie dla interakcji agentów w czasie rzeczywistym.

### Ramy SLM zoptymalizowane dla krawędzi

#### Optymalizacja Llama.cpp dla agentów

Llama.cpp oferuje najnowocześniejsze techniki kwantyzacji, specjalnie zoptymalizowane dla wdrażania agentowych SLM:

**Kwantyzacja specyficzna dla agentów**: Ramy wspierają Q4_0 (optymalne dla wdrażania agentów mobilnych z redukcją rozmiaru o 75%), Q5_1 (zrównoważona jakość-kompresja dla agentów na krawędzi) oraz Q8_0 (niemal oryginalna jakość dla systemów produkcyjnych agentów). Zaawansowane formaty umożliwiają ultra-skompresowanych agentów dla ekstremalnych scenariuszy krawędziowych.

**Korzyści z wdrożenia**: Wnioskowanie zoptymalizowane dla CPU z akceleracją SIMD zapewnia efektywne wykonanie agentów. Kompatybilność międzyplatformowa na architekturach x86, ARM i Apple Silicon umożliwia uniwersalne możliwości wdrażania agentów.

#### Ramy Apple MLX dla agentów SLM

Apple MLX oferuje natywną optymalizację, specjalnie zaprojektowaną dla agentów opartych na SLM na urządzeniach Apple Silicon:

**Optymalizacja agentów dla Apple Silicon**: Ramy wykorzystują zunifikowaną architekturę pamięci z integracją Metal Performance Shaders, automatyczną mieszana precyzję dla wnioskowania agentów oraz zoptymalizowaną przepustowość pamięci dla systemów wieloagentowych. Agenci SLM wykazują wyjątkową wydajność na chipach serii M.

**Funkcje rozwojowe**: Wsparcie API dla Python i Swift z optymalizacjami specyficznymi dla agentów, automatyczne różnicowanie dla uczenia się agentów oraz bezproblemowa integracja z narzędziami rozwojowymi Apple zapewniają kompleksowe środowiska rozwoju agentów.

## SLM vs LLM w systemach agentowych: Zaawansowane porównanie

### Zalety SLM w aplikacjach agentowych

**Efektywność operacyjna**: SLM oferują 10-30× redukcję kosztów w porównaniu z LLM dla zadań agentowych, umożliwiając odpowiedzi agentowe w czasie rzeczywistym na dużą skalę. Zapewniają szybsze czasy wnioskowania dzięki zmniejszonej złożoności obliczeniowej, co czyni je idealnymi dla interaktywnych aplikacji agentowych.

**Możliwości wdrażania na krawędzi**: SLM umożliwiają wykonywanie agentów na urządzeniach bez zależności od internetu, zwiększoną prywatność dzięki lokalnemu przetwarzaniu agentów oraz dostosowanie do specyficznych aplikacji agentowych odpowiednich dla różnych środowisk obliczeniowych na krawędzi.

**Optymalizacja specyficzna dla agentów**: SLM doskonale radzą sobie z wywoływaniem narzędzi, generowaniem strukturalnych wyników oraz rutynowymi przepływami decyzyjnymi, które stanowią 70-80% typowych zadań agentowych.

### Kiedy używać SLM vs LLM w systemach agentowych

**Idealne dla SLM**:
- **Powtarzalne zadania agentowe**: Wprowadzanie danych, wypełnianie formularzy, rutynowe wywołania API
- **Integracja narzędzi**: Zapytania do baz danych, operacje na plikach, interakcje z systemem
- **Strukturalne przepływy pracy**: Podążanie za zdefiniowanymi procesami agentowymi
- **Agenci specyficzni dla domeny**: Obsługa klienta, harmonogramowanie, podstawowa analiza
- **Przetwarzanie lokalne**: Operacje agentowe wrażliwe na prywatność

**Lepsze dla LLM**:
- **Złożone rozumowanie**: Rozwiązywanie nowych problemów, planowanie strategiczne
- **Rozmowy otwarte**: Ogólne rozmowy, kreatywne dyskusje
- **Zadania wymagające szerokiej wiedzy**: Badania wymagające rozległej wiedzy ogólnej
- **Nowe sytuacje**: Obsługa całkowicie nowych scenariuszy agentowych

### Hybrydowa architektura agentów

Optymalne podejście łączy SLM i LLM w heterogenicznych systemach agentowych:

**Inteligentna orkiestracja agentów**:
1. **SLM jako główny**: Obsługa 70-80% rutynowych zadań agentowych lokalnie
2. **LLM w razie potrzeby**: Kierowanie złożonych zapytań do większych modeli w chmurze
3. **Specjalistyczne SLM**: Różne małe modele dla różnych domen agentowych
4. **Optymalizacja kosztów**: Minimalizacja kosztownych wywołań LLM dzięki inteligentnemu kierowaniu

## Strategie wdrażania agentów SLM w produkcji

### Ollama: Uproszczone wdrażanie agentów SLM

Ollama upraszcza wdrażanie agentów SLM dzięki funkcjom gotowym do zastosowań w lokalnych i krawędziowych środowiskach:

**Możliwości wdrażania agentów**: Instalacja i uruchamianie SLM za pomocą jednego polecenia z automatycznym pobieraniem i buforowaniem modeli. Wsparcie dla różnych kwantyzowanych formatów SLM z REST API do integracji agentów oraz zarządzanie wieloma modelami dla złożonych systemów agentowych.

**Zaawansowane funkcje agentów**: Dostosowywanie SLM do specyficznych zadań agentowych, wdrażanie kontenerowe dla skalowalnych systemów agentowych, akceleracja GPU z automatycznym wykrywaniem oraz optymalizacja kwantyzacji modeli dla wdrażania agentów na krawędzi.

### VLLM: Wnioskowanie agentów SLM o wysokiej wydajności

VLLM zapewnia optymalizację wnioskowania na poziomie produkcyjnym dla scenariuszy agentowych o wysokiej przepustowości:

**Optymalizacje wydajności agentów**: PagedAttention dla efektywnego obliczania uwagi agentów, dynamiczne grupowanie dla optymalizacji przepustowości agentów oraz spekulacyjne dekodowanie dla zmniejszenia opóźnień agentów. Zaawansowane formaty kwantyzacji umożliwiają optymalną wydajność agentów SLM.

**Integracja agentów w przedsiębiorstwach**: Punkty końcowe API kompatybilne z OpenAI dla bezproblemowej integracji agentów, wsparcie dla wdrażania Kubernetes dla skalowalnych systemów agentowych oraz możliwości monitorowania dla optymalizacji wydajności agentów.

### Rozwiązania Microsoft dla agentów SLM na krawędzi

Microsoft oferuje kompleksowe możliwości wdrażania na krawędzi dla agentów SLM w przedsiębiorstwach:

**Funkcje obliczeniowe agentów na krawędzi**: Projektowanie architektury agentów offline-first z optymalizacją ograniczeń zasobów, zarządzanie lokalnym rejestrem SLM oraz możliwości synchronizacji agentów między krawędzią a chmurą zapewniają niezawodne wdrażanie agentów.

**Bezpieczeństwo i zgodność**: Lokalne przetwarzanie danych agentów dla zachowania prywatności, kontrola bezpieczeństwa przedsiębiorstwa dla systemów agentowych oraz rejestrowanie audytów dla raportowania zgodności agentów zapewniają kompleksowe bezpieczeństwo dla wdrożeń agentów na krawędzi.

## Zastosowania agentów SLM w rzeczywistości

### Agenci obsługi klienta SLM
- **Możliwości SLM**: Wyszukiwanie kont, resetowanie haseł, sprawdzanie statusu zamówień
- **Korzyści kosztowe**: 10-krotna redukcja kosztów wnioskowania w porównaniu z agentami LLM
- **Wydajność**: Szybsze czasy odpowiedzi przy zachowaniu spójnej jakości dla rutynowych zapytań

### Agenci procesów biznesowych SLM
- **Agenci przetwarzania faktur**: Ekstrakcja danych, walidacja informacji, przekazywanie do zatwierdzenia
- **Agenci zarządzania e-mailami**: Kategoryzowanie, priorytetyzowanie, automatyczne tworzenie odpowiedzi
- **Agenci harmonogramowania**: Koordynowanie spotkań, zarządzanie kalendarzami, wysyłanie przypomnień

### Osobiste cyfrowe asystenty SLM
- **Agenci zarządzania zadaniami**: Tworzenie, aktualizowanie, organizowanie list zadań
- **Agenci zbierania informacji**: Badanie tematów, lokalne podsumowywanie wyników
- **Agenci komunikacji**: Tworzenie e-maili, wiadomości, postów w mediach społecznościowych w sposób prywatny

### Agenci handlowi i finansowi SLM
- **Agenci monitorowania rynku**: Śledzenie cen, identyfikowanie trendów w czasie rzeczywistym
- **Agenci generowania raportów**: Automatyczne tworzenie codziennych/tygodniowych podsumowań
- **Agenci oceny ryzyka**: Analiza pozycji portfela przy użyciu lokalnych danych

### Agenci wsparcia zdrowotnego SLM
- **Agenci harmonogramowania pacjentów**: Koordynowanie wizyt, wysyłanie automatycznych przypomnień
- **Agenci dokumentacji**: Lokalna generacja podsumowań medycznych, raportów
- **Agenci zarządzania receptami**: Śledzenie uzupełnień, sprawdzanie interakcji w sposób prywatny

## Najlepsze praktyki wdrażania agentów SLM

### Wytyczne dotyczące wyboru SLM dla agentów

Podczas wyboru SLM do wdrożenia agentów należy wziąć pod uwagę następujące czynniki:

**Rozmiar modelu**: Wybierz ultra-skompresowane modele, takie jak Q2_K dla ekstremalnych aplikacji mobilnych agentów, zrównoważone modele, takie jak Q4_K_M dla ogólnych scenariuszy agentowych, oraz modele o wyższej precyzji, takie jak Q8_0 dla aplikacji agentowych wymagających wysokiej jakości.

**Dopasowanie do zastosowań agentów**: Dopasuj możliwości SLM do specyficznych wymagań agentów, uwzględniając takie czynniki jak zachowanie dokładności decyzji agentów, szybkość wnioskowania dla interakcji agentów w czasie rzeczywistym, ograniczenia pamięci dla wdrożeń agentów na krawędzi oraz wymagania
### Bezpieczeństwo i prywatność w systemach agentów SLM

Chociaż agenci SLM umożliwiają lokalne przetwarzanie danych dla zwiększonej prywatności, konieczne jest wdrożenie odpowiednich środków bezpieczeństwa w celu ochrony modeli agentów i danych w środowiskach brzegowych. Jest to szczególnie istotne przy wdrażaniu precyzyjnych formatów agentów w środowiskach korporacyjnych lub skompresowanych formatów agentów w aplikacjach obsługujących wrażliwe dane.

## Przyszłe trendy w rozwoju agentów SLM

Krajobraz agentów SLM stale się rozwija dzięki postępom w technikach kompresji, metodach optymalizacji i strategiach wdrażania na urządzeniach brzegowych. Przyszłe innowacje obejmują bardziej wydajne algorytmy kwantyzacji dla modeli agentów, ulepszone metody kompresji dla przepływów pracy agentów oraz lepszą integrację z akceleratorami sprzętowymi na urządzeniach brzegowych.

**Prognozy rynkowe dla agentów SLM**: Według najnowszych badań automatyzacja oparta na agentach może wyeliminować 40–60% powtarzalnych zadań poznawczych w przepływach pracy w przedsiębiorstwach do 2027 roku, a SLM odegrają kluczową rolę w tej transformacji dzięki swojej efektywności kosztowej i elastyczności wdrożeniowej.

**Trendy technologiczne w agentach SLM**:
- **Specjalistyczni agenci SLM**: Modele dostosowane do konkretnych zadań agentów i branż
- **Przetwarzanie agentów na urządzeniach brzegowych**: Ulepszone możliwości na urządzeniach z większą prywatnością i mniejszymi opóźnieniami
- **Orkiestracja agentów**: Lepsza koordynacja między wieloma agentami SLM z dynamicznym trasowaniem i równoważeniem obciążenia
- **Demokratyzacja**: Elastyczność SLM umożliwia szerszy udział w rozwoju agentów w różnych organizacjach

## Jak zacząć pracę z agentami SLM

### Krok 1: Wybierz SLM dla aplikacji agentów
Popularne opcje dla aplikacji agentów:
- **Microsoft Phi-4 Mini (3.8B)**: Doskonały do ogólnych zadań agentów z zrównoważoną wydajnością
- **NVIDIA Nemotron-4-Mini (4B)**: Wyjątkowy w wywoływaniu narzędzi w systemach agentów
- **Hugging Face SmolLM2 (1.7B)**: Bardzo wydajny dla prostych przepływów pracy agentów
- **DeepSeek-R1-Distill (1.5-8B)**: Silne zdolności rozumowania dla złożonych agentów

### Krok 2: Zdefiniuj zakres i wymagania agenta
Rozpocznij od skoncentrowanych, dobrze zdefiniowanych aplikacji agentów:
- **Agenci jednego obszaru**: Obsługa klienta LUB planowanie LUB badania
- **Jasne cele agenta**: Konkretne, mierzalne cele dla wydajności agenta
- **Ograniczona integracja narzędzi**: Maksymalnie 3-5 narzędzi na początkowym etapie wdrożenia agenta
- **Określone granice agenta**: Jasne ścieżki eskalacji dla złożonych scenariuszy

### Krok 3: Wdrożenie optymalizacji agentów SLM
Dostosuj SLM do konkretnych przypadków użycia agentów, zbierając specjalistyczne dane instruktażowe z interakcji agentów i wykorzystując te dane do tworzenia eksperckich wariantów SLM, które obniżają koszty i poprawiają wydajność w określonych zadaniach agentów.

### Krok 4: Wdrożenie środków bezpieczeństwa dla agentów SLM
- **Walidacja danych wejściowych agenta**: Sprawdzanie żądań pod kątem bezpieczeństwa i stosowności
- **Filtrowanie danych wyjściowych agenta**: Zapewnienie, że odpowiedzi spełniają standardy jakości
- **Integracja nadzoru ludzkiego**: Krytyczne decyzje agenta wymagają zatwierdzenia
- **Monitorowanie agenta**: Śledzenie wydajności i zgłaszanie problemów w czasie rzeczywistym

### Krok 5: Pomiar i optymalizacja wydajności agentów SLM
- **Wskaźniki ukończenia zadań przez agenta**: Jak często agent odnosi sukces?
- **Czas odpowiedzi agenta**: Czy interakcje są wystarczająco szybkie dla użytkowników?
- **Satysfakcja użytkowników z agentów**: Czy użytkownicy uważają agenta za pomocnego i niezawodnego?
- **Efektywność kosztowa agentów**: Porównanie z wcześniejszymi rozwiązaniami i alternatywami w chmurze

## Kluczowe wnioski z wdrożenia agentów SLM

1. **SLM są wystarczające dla agentów**: W przypadku większości zadań agentów małe modele działają równie dobrze jak duże, oferując znaczące korzyści
2. **Efektywność kosztowa agentów**: 10-30 razy tańsze w eksploatacji agenci SLM, co czyni je ekonomicznie opłacalnymi dla szerokiego wdrożenia
3. **Specjalizacja działa dla agentów**: Dostosowane SLM często przewyższają modele ogólnego przeznaczenia w określonych aplikacjach agentów
4. **Hybrydowa architektura agentów**: Wykorzystuj SLM do rutynowych zadań agentów, a LLM do złożonego rozumowania, gdy jest to konieczne
5. **Przyszłość to agenci SLM**: Małe modele językowe są przyszłością agentowej AI, umożliwiając demokratyzację i efektywne wdrożenie agentów

## ➡️ Co dalej

Przejście na agentów zasilanych przez SLM oznacza fundamentalną zmianę w podejściu do wdrażania AI. Skupiając się na efektywności, specjalizacji i praktycznej użyteczności, SLM sprawiają, że agenci AI stają się bardziej dostępni, przystępni cenowo i skuteczni w rzeczywistych zastosowaniach w każdej branży i środowisku obliczeniowym brzegowym.

W miarę postępów do 2025 roku, połączenie coraz bardziej zaawansowanych małych modeli i wyrafinowanych frameworków agentów otworzy nowe możliwości dla autonomicznych systemów, które mogą działać wydajnie na urządzeniach brzegowych, jednocześnie zachowując prywatność, obniżając koszty i zapewniając wyjątkowe doświadczenia użytkowników.

## ➡️ Co dalej

- [02: Wywoływanie funkcji w małych modelach językowych (SLM)](./02.FunctionCalling.md)

---

**Zastrzeżenie**:  
Ten dokument został przetłumaczony za pomocą usługi tłumaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby tłumaczenie było precyzyjne, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za wiarygodne źródło. W przypadku informacji krytycznych zaleca się skorzystanie z profesjonalnego tłumaczenia wykonanego przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z korzystania z tego tłumaczenia.