<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7c65ab2fd757b5fce2f114a3118d05da",
  "translation_date": "2025-09-17T14:26:02+00:00",
  "source_file": "Module02/README.md",
  "language_code": "pl"
}
-->
# Rozdział 02: Podstawy Małych Modeli Językowych

Ten obszerny rozdział wprowadzający oferuje kluczowe spojrzenie na Małe Modele Językowe (SLM), obejmując zasady teoretyczne, strategie praktycznej implementacji oraz rozwiązania gotowe do wdrożenia w produkcji. Rozdział ten tworzy niezbędną bazę wiedzy do zrozumienia nowoczesnych, wydajnych architektur AI i ich strategicznego zastosowania w różnych środowiskach obliczeniowych.

## Struktura Rozdziału i Ramy Progresywnego Uczenia

### **[Sekcja 1: Podstawy Rodziny Modeli Microsoft Phi](./01.PhiFamily.md)**
Pierwsza sekcja wprowadza przełomową rodzinę modeli Phi firmy Microsoft, pokazując, jak kompaktowe i wydajne modele osiągają znakomite wyniki przy znacznym ograniczeniu wymagań obliczeniowych. W tej sekcji omówiono:

- **Ewolucja Filozofii Projektowania**: Szczegółowe omówienie rozwoju rodziny Phi od Phi-1 do Phi-4, z naciskiem na rewolucyjną metodologię treningu „jakości podręcznikowej” oraz skalowanie w czasie wnioskowania
- **Architektura Skoncentrowana na Wydajności**: Dogłębna analiza optymalizacji parametrów, integracji multimodalnej oraz optymalizacji sprzętowej dla CPU, GPU i urządzeń brzegowych
- **Specjalistyczne Zdolności**: Szczegółowe omówienie wariantów dostosowanych do konkretnych dziedzin, takich jak Phi-4-mini-reasoning do zadań matematycznych, Phi-4-multimodal do przetwarzania wizji i języka oraz Phi-3-Silica do wdrożeń wbudowanych w Windows 11

Ta sekcja ustanawia fundamentalną zasadę, że wydajność modelu i jego możliwości mogą współistnieć dzięki innowacyjnym metodologiom treningowym i optymalizacji architektury.

### **[Sekcja 2: Podstawy Rodziny Qwen](./02.QwenFamily.md)**
Druga sekcja przechodzi do kompleksowego podejścia open-source firmy Alibaba, pokazując, jak transparentne i dostępne modele mogą osiągać konkurencyjne wyniki, zachowując jednocześnie elastyczność wdrożeniową. Kluczowe obszary obejmują:

- **Doskonałość Open Source**: Szczegółowe omówienie ewolucji Qwen od wersji 1.0 do Qwen3, z naciskiem na trening na ogromną skalę (36 bilionów tokenów) i możliwości wielojęzyczne w 119 językach
- **Zaawansowana Architektura Rozumowania**: Dogłębne omówienie innowacyjnych funkcji „trybu myślenia” w Qwen3, implementacji mixture-of-experts oraz wariantów specjalistycznych do kodowania (Qwen-Coder) i matematyki (Qwen-Math)
- **Skalowalne Opcje Wdrożeniowe**: Szczegółowa analiza zakresu parametrów od 0,5B do 235B, umożliwiająca scenariusze wdrożeniowe od urządzeń mobilnych po klastry korporacyjne

Ta sekcja podkreśla demokratyzację technologii AI dzięki dostępności open-source, przy jednoczesnym zachowaniu konkurencyjnych cech wydajnościowych.

### **[Sekcja 3: Podstawy Rodziny Gemma](./03.GemmaFamily.md)**
Trzecia sekcja bada kompleksowe podejście Google do otwartoźródłowej, multimodalnej AI, pokazując, jak rozwój oparty na badaniach może dostarczać dostępne, a jednocześnie potężne możliwości AI. W tej sekcji omówiono:

- **Innowacje Napędzane Badaniami**: Szczegółowe omówienie architektur Gemma 3 i Gemma 3n, z przełomową technologią Per-Layer Embeddings (PLE) i strategiami optymalizacji mobilnej
- **Multimodalna Doskonałość**: Dogłębna eksploracja integracji wizji i języka, możliwości przetwarzania dźwięku oraz funkcji wywoływania funkcji, które umożliwiają kompleksowe doświadczenia AI
- **Architektura Mobilna**: Szczegółowa analiza rewolucyjnych osiągnięć wydajnościowych Gemma 3n, dostarczających efektywność modeli o 2B-4B parametrach przy zużyciu pamięci na poziomie 2-3 GB

Ta sekcja pokazuje, jak najnowocześniejsze badania mogą być przekształcane w praktyczne, dostępne rozwiązania AI, które umożliwiają nowe kategorie aplikacji.

### **[Sekcja 4: Podstawy Rodziny BitNET](./04.BitNETFamily.md)**
Czwarta sekcja przedstawia rewolucyjne podejście Microsoftu do kwantyzacji 1-bitowej, reprezentujące granicę ultra-wydajnych wdrożeń AI. W tej zaawansowanej sekcji omówiono:

- **Rewolucyjna Kwantyzacja**: Szczegółowe omówienie kwantyzacji 1,58-bitowej z użyciem wag ternarnych {-1, 0, +1}, osiągającej przyspieszenie od 1,37x do 6,17x przy redukcji zużycia energii o 55-82%
- **Optymalizowane Ramy Wnioskowania**: Dogłębne omówienie implementacji bitnet.cpp z [https://github.com/microsoft/BitNet](https://github.com/microsoft/BitNet), specjalistycznych jąder i optymalizacji międzyplatformowych, które zapewniają bezprecedensowe zyski wydajnościowe
- **Zrównoważone Przywództwo AI**: Szczegółowa analiza korzyści środowiskowych, możliwości demokratyzacji wdrożeń i nowych scenariuszy aplikacyjnych umożliwionych przez ekstremalną wydajność

Ta sekcja pokazuje, jak rewolucyjne techniki kwantyzacji mogą dramatycznie poprawić wydajność AI, zachowując jednocześnie konkurencyjne wyniki.

### **[Sekcja 5: Podstawy Modelu Microsoft Mu](./05.mumodel.md)**
Piąta sekcja bada przełomowy model Mu firmy Microsoft, zaprojektowany specjalnie do wdrożeń na urządzeniach z systemem Windows. W tej specjalistycznej sekcji omówiono:

- **Architektura Skoncentrowana na Urządzeniach**: Szczegółowe omówienie specjalistycznego modelu na urządzeniach wbudowanego w urządzenia z systemem Windows 11
- **Integracja Systemowa**: Dogłębna analiza głębokiej integracji z systemem Windows 11, pokazująca, jak AI może poprawić funkcjonalność systemu dzięki natywnemu wdrożeniu
- **Projekt Chroniący Prywatność**: Szczegółowe omówienie działania offline, lokalnego przetwarzania i architektury skoncentrowanej na prywatności, która przechowuje dane użytkownika na urządzeniu

Ta sekcja pokazuje, jak specjalistyczne modele mogą poprawić funkcjonalność systemu operacyjnego Windows 11, zachowując jednocześnie prywatność i wydajność.

### **[Sekcja 6: Podstawy Phi-Silica](./06.phisilica.md)**
Sekcja końcowa analizuje model Phi-Silica firmy Microsoft, ultra-wydajny model językowy wbudowany w system Windows 11 dla komputerów Copilot+ z układami NPU. W tej zaawansowanej sekcji omówiono:

- **Wyjątkowe Wskaźniki Wydajności**: Szczegółowa analiza niezwykłych możliwości Phi-Silica, dostarczającego 650 tokenów na sekundę przy zużyciu zaledwie 1,5 wata mocy
- **Optymalizacja NPU**: Dogłębna eksploracja specjalistycznej architektury zaprojektowanej dla jednostek przetwarzania neuronowego w komputerach Copilot+ z systemem Windows 11
- **Integracja Deweloperska**: Szczegółowe omówienie integracji z Windows App SDK, technik inżynierii promptów i najlepszych praktyk wdrażania Phi-Silica w aplikacjach Windows 11

Ta sekcja ustanawia granicę możliwości sprzętowo zoptymalizowanych modeli językowych na urządzeniach, pokazując, jak specjalistyczne architektury modeli w połączeniu z dedykowanym sprzętem neuronowym mogą dostarczać wyjątkową wydajność AI na urządzeniach konsumenckich z systemem Windows 11.

## Kompleksowe Wyniki Nauki

Po ukończeniu tego rozdziału czytelnicy osiągną biegłość w:

1. **Zrozumieniu Architektury**: Dogłębne zrozumienie różnych filozofii projektowania SLM i ich implikacji dla scenariuszy wdrożeniowych
2. **Równowadze Wydajności i Efektywności**: Umiejętność strategicznego wyboru odpowiednich architektur modeli w oparciu o ograniczenia obliczeniowe i wymagania wydajnościowe
3. **Elastyczności Wdrożeniowej**: Zrozumienie kompromisów między optymalizacją własnościową (Phi), dostępnością open-source (Qwen), innowacjami badawczymi (Gemma) i rewolucyjną wydajnością (BitNET)
4. **Perspektywie Przyszłościowej**: Wgląd w pojawiające się trendy w efektywnych architekturach AI i ich implikacje dla strategii wdrożeń nowej generacji

## Skupienie na Praktycznej Implementacji

Rozdział zachowuje silną orientację praktyczną, zawierając:

- **Kompletne Przykłady Kodów**: Przykłady implementacji gotowych do produkcji dla każdej rodziny modeli, w tym procedury dostrajania, strategie optymalizacji i konfiguracje wdrożeniowe
- **Kompleksowe Benchmarki**: Szczegółowe porównania wydajności różnych architektur modeli, w tym metryki efektywności, oceny możliwości i optymalizację przypadków użycia
- **Bezpieczeństwo Korporacyjne**: Implementacje bezpieczeństwa na poziomie produkcyjnym, strategie monitorowania i najlepsze praktyki dla niezawodnego wdrożenia
- **Integracja z Ramami**: Praktyczne wskazówki dotyczące integracji z popularnymi ramami, takimi jak Hugging Face Transformers, vLLM, ONNX Runtime i narzędzia do specjalistycznej optymalizacji

## Strategiczna Mapa Drogowa Technologii

Rozdział kończy się analizą przyszłościową:

- **Ewolucja Architektury**: Pojawiające się trendy w projektowaniu i optymalizacji modeli
- **Integracja Sprzętowa**: Postępy w specjalistycznych akceleratorach AI i ich wpływ na strategie wdrożeniowe
- **Rozwój Ekosystemu**: Wysiłki standaryzacyjne i poprawa interoperacyjności między różnymi rodzinami modeli
- **Adopcja Korporacyjna**: Strategiczne rozważania dotyczące planowania wdrożeń AI w organizacjach

## Scenariusze Zastosowań w Rzeczywistości

Każda sekcja zawiera kompleksowe omówienie praktycznych zastosowań:

- **Obliczenia Mobilne i Brzegowe**: Optymalizowane strategie wdrożeniowe dla środowisk o ograniczonych zasobach
- **Aplikacje Korporacyjne**: Skalowalne rozwiązania dla inteligencji biznesowej, automatyzacji i obsługi klienta
- **Technologia Edukacyjna**: Dostępna AI dla spersonalizowanego uczenia się i generowania treści
- **Globalne Wdrożenia**: Wielojęzyczne i międzykulturowe aplikacje AI

## Standardy Doskonałości Technicznej

Rozdział kładzie nacisk na implementację gotową do produkcji poprzez:

- **Mistrzostwo Optymalizacji**: Zaawansowane techniki kwantyzacji, optymalizację wnioskowania i zarządzanie zasobami
- **Monitorowanie Wydajności**: Kompleksowe zbieranie metryk, systemy alertów i analitykę wydajności
- **Implementację Bezpieczeństwa**: Środki bezpieczeństwa na poziomie korporacyjnym, ochrona prywatności i ramy zgodności
- **Planowanie Skalowalności**: Strategie skalowania poziomego i pionowego dla rosnących wymagań obliczeniowych

Ten rozdział wprowadzający stanowi niezbędny wstęp do zaawansowanych strategii wdrażania SLM, zapewniając zarówno teoretyczne zrozumienie, jak i praktyczne umiejętności niezbędne do pomyślnej implementacji. Obszerne omówienie gwarantuje, że czytelnicy są dobrze przygotowani do podejmowania świadomych decyzji architektonicznych i wdrażania solidnych, wydajnych rozwiązań AI, które spełniają ich specyficzne wymagania organizacyjne, jednocześnie przygotowując się na przyszłe rozwinięcia technologiczne.

Rozdział ten łączy najnowsze badania nad AI z praktycznymi realiami wdrożeniowymi, podkreślając, że nowoczesne architektury SLM mogą dostarczać wyjątkową wydajność, zachowując jednocześnie efektywność operacyjną, opłacalność i zrównoważony rozwój środowiskowy.

---

**Zastrzeżenie**:  
Ten dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby tłumaczenie było precyzyjne, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za wiarygodne źródło. W przypadku informacji o kluczowym znaczeniu zaleca się skorzystanie z profesjonalnego tłumaczenia przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z użycia tego tłumaczenia.