<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-17T14:20:12+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "pl"
}
-->
# EdgeAI dla początkujących: Ścieżki nauki i harmonogram nauki

### Skoncentrowana ścieżka nauki (1 tydzień)

| Dzień | Temat | Szacowany czas |
|------|-------|------------------|
| Dzień 1 | Moduł 1: Podstawy EdgeAI | 3 godziny |
| Dzień 2 | Moduł 2: Podstawy SLM | 3 godziny |
| Dzień 3 | Moduł 3: Wdrażanie SLM | 2 godziny |
| Dzień 4-5 | Moduł 4: Optymalizacja modeli (6 frameworków) | 4 godziny |
| Dzień 6 | Moduł 5: SLMOps | 3 godziny |
| Dzień 7 | Moduły 6-7: Agenci AI i narzędzia deweloperskie | 5 godzin |

### Skoncentrowana ścieżka nauki (2 tygodnie)

| Dzień | Temat | Szacowany czas |
|------|-------|------------------|
| Dzień 1-2 | Moduł 1: Podstawy EdgeAI | 3 godziny |
| Dzień 3-4 | Moduł 2: Podstawy SLM | 3 godziny |
| Dzień 5-6 | Moduł 3: Wdrażanie SLM | 2 godziny |
| Dzień 7-8 | Moduł 4: Optymalizacja modeli | 4 godziny |
| Dzień 9-10 | Moduł 5: SLMOps | 3 godziny |
| Dzień 11-12 | Moduł 6: Agenci AI | 2 godziny |
| Dzień 13-14 | Moduł 7: Narzędzia deweloperskie | 3 godziny |

### Nauka w niepełnym wymiarze godzin (4 tygodnie)

| Tydzień | Temat | Szacowany czas |
|------|-------|------------------|
| Tydzień 1 | Moduły 1-2: Podstawy i fundamenty SLM | 6 godzin |
| Tydzień 2 | Moduły 3-4: Wdrażanie i optymalizacja | 6 godzin |
| Tydzień 3 | Moduły 5-6: SLMOps i agenci AI | 5 godzin |
| Tydzień 4 | Moduł 7: Narzędzia deweloperskie i integracja | 3 godziny |

| Dzień | Temat | Szacowany czas |
|------|-------|------------------|
| Dzień 1-2 | Moduł 1: Podstawy EdgeAI | 3 godziny |
| Dzień 3-4 | Moduł 2: Podstawy SLM | 3 godziny |
| Dzień 5-6 | Moduł 3: Wdrażanie SLM | 2 godziny |
| Dzień 7-8 | Moduł 4: Optymalizacja modeli | 4 godziny |
| Dzień 9-10 | Moduł 5: SLMOps | 3 godziny |
| Dzień 11-12 | Moduł 6: Systemy agentowe SLM | 2 godziny |
| Dzień 13-14 | Moduł 7: Przykłady implementacji EdgeAI | 2 godziny |

| Moduł | Data ukończenia | Czas poświęcony | Kluczowe wnioski |
|--------|----------------|-------------|--------------|
| Moduł 1: Podstawy EdgeAI | | | |
| Moduł 2: Fundamenty SLM | | | |
| Moduł 3: Wdrażanie SLM | | | |
| Moduł 4: Optymalizacja modeli (6 frameworków) | | | |
| Moduł 5: SLMOps | | | |
| Moduł 6: Systemy agentowe SLM | | | |
| Moduł 7: Przykłady implementacji EdgeAI | | | |
| Ćwiczenia praktyczne | | | |
| Mini-projekt | | | |

### Nauka w niepełnym wymiarze godzin (4 tygodnie)

| Tydzień | Temat | Szacowany czas |
|------|-------|------------------|
| Tydzień 1 | Moduły 1-2: Podstawy i fundamenty SLM | 6 godzin |
| Tydzień 2 | Moduły 3-4: Wdrażanie i optymalizacja | 6 godzin |
| Tydzień 3 | Moduły 5-6: SLMOps i agenci AI | 5 godzin |
| Tydzień 4 | Moduł 7: Narzędzia deweloperskie i integracja | 3 godziny |

## Wprowadzenie

Witamy w przewodniku nauki EdgeAI dla początkujących! Ten dokument został zaprojektowany, aby pomóc Ci efektywnie korzystać z materiałów kursu i maksymalizować doświadczenie edukacyjne. Zawiera uporządkowane ścieżki nauki, sugerowane harmonogramy nauki, podsumowania kluczowych pojęć oraz dodatkowe zasoby, które pogłębią Twoje zrozumienie technologii EdgeAI.

To zwięzły kurs trwający 20 godzin, który dostarcza podstawowej wiedzy o EdgeAI w efektywnym czasowo formacie, idealnym dla zapracowanych profesjonalistów i studentów, którzy chcą szybko zdobyć praktyczne umiejętności w tej rozwijającej się dziedzinie.

## Przegląd kursu

Kurs jest podzielony na siedem kompleksowych modułów:

1. **Podstawy i transformacja EdgeAI** - Zrozumienie kluczowych pojęć i zmiany technologicznej
2. **Fundamenty małych modeli językowych (SLM)** - Eksploracja różnych rodzin SLM i ich architektur
3. **Wdrażanie małych modeli językowych (SLM)** - Implementacja praktycznych strategii wdrożeniowych
4. **Konwersja formatów modeli i kwantyzacja** - Zaawansowana optymalizacja z użyciem 6 frameworków, w tym OpenVINO
5. **SLMOps - Operacje na małych modelach językowych** - Zarządzanie cyklem życia produkcji i wdrożenia
6. **Systemy agentowe SLM** - Agenci AI, wywoływanie funkcji i protokół kontekstu modelu
7. **Przykłady implementacji EdgeAI** - Narzędzia AI, rozwój na Windows i implementacje specyficzne dla platformy

## Jak korzystać z tego przewodnika nauki

- **Nauka progresywna**: Podążaj za modułami w kolejności dla najbardziej spójnego doświadczenia edukacyjnego
- **Punkty kontrolne wiedzy**: Korzystaj z pytań do samooceny po każdej sekcji
- **Ćwiczenia praktyczne**: Wykonuj sugerowane ćwiczenia, aby utrwalić teoretyczne pojęcia
- **Dodatkowe zasoby**: Eksploruj dodatkowe materiały dla tematów, które najbardziej Cię interesują

## Rekomendacje harmonogramu nauki

### Skoncentrowana ścieżka nauki (1 tydzień)

| Dzień | Temat | Szacowany czas |
|------|-------|-----------------|
| Dzień 1-2 | Moduł 1: Podstawy EdgeAI | 6 godzin |
| Dzień 3-4 | Moduł 2: Fundamenty SLM | 8 godzin |
| Dzień 5-6 | Moduł 3: Wdrażanie SLM | 6 godzin |

### Nauka w niepełnym wymiarze godzin (3 tygodnie)

| Tydzień | Temat | Szacowany czas |
|------|-------|-----------------|
| Tydzień 1 | Moduł 1: Podstawy EdgeAI | 6-7 godzin |
| Tydzień 2 | Moduł 2: Fundamenty SLM | 7-8 godzin |
| Tydzień 3 | Moduł 3: Wdrażanie SLM | 5-6 godzin |

## Moduł 1: Podstawy i transformacja EdgeAI

### Kluczowe cele nauki

- Zrozumienie różnic między AI opartym na chmurze a AI opartym na urządzeniach brzegowych
- Opanowanie podstawowych technik optymalizacji dla środowisk o ograniczonych zasobach
- Analiza rzeczywistych zastosowań technologii EdgeAI
- Konfiguracja środowiska deweloperskiego dla projektów EdgeAI

### Obszary nauki

#### Sekcja 1: Podstawy EdgeAI
- **Kluczowe pojęcia**: 
  - Paradigmaty obliczeń brzegowych vs. chmurowych
  - Techniki kwantyzacji modeli
  - Opcje przyspieszenia sprzętowego (NPU, GPU, CPU)
  - Zalety w zakresie prywatności i bezpieczeństwa

- **Dodatkowe materiały**:
  - [TensorFlow Lite Dokumentacja](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentacja](https://docs.edgeimpulse.com)

#### Sekcja 2: Studium przypadków
- **Kluczowe pojęcia**: 
  - Ekosystem modeli Microsoft Phi & Mu
  - Praktyczne implementacje w różnych branżach
  - Rozważania dotyczące wdrożenia

#### Sekcja 3: Przewodnik praktycznej implementacji
- **Kluczowe pojęcia**: 
  - Konfiguracja środowiska deweloperskiego
  - Narzędzia do kwantyzacji i optymalizacji
  - Metody oceny implementacji EdgeAI

#### Sekcja 4: Sprzęt do wdrożeń brzegowych
- **Kluczowe pojęcia**: 
  - Porównania platform sprzętowych
  - Strategie optymalizacji dla konkretnego sprzętu
  - Rozważania dotyczące wdrożenia

### Pytania do samooceny

1. Porównaj i skontrastuj AI oparte na chmurze z implementacjami AI opartymi na urządzeniach brzegowych.
2. Wyjaśnij trzy kluczowe techniki optymalizacji modeli dla wdrożeń brzegowych.
3. Jakie są główne zalety uruchamiania modeli AI na urządzeniach brzegowych?
4. Opisz proces kwantyzacji modelu i jego wpływ na wydajność.
5. Wyjaśnij, jak różne akceleratory sprzętowe (NPU, GPU, CPU) wpływają na wdrożenie EdgeAI.

### Ćwiczenia praktyczne

1. **Szybka konfiguracja środowiska**: Skonfiguruj minimalne środowisko deweloperskie z niezbędnymi pakietami (30 minut)
2. **Eksploracja modelu**: Pobierz i przeanalizuj wstępnie wytrenowany mały model językowy (1 godzina)
3. **Podstawowa kwantyzacja**: Wypróbuj prostą kwantyzację na małym modelu (1 godzina)
- Drzewa decyzyjne wyboru frameworków  
- Walidacja gotowości produkcyjnej  
- Strategie zapewnienia przyszłościowej technologii  

### Pytania do samooceny  

1. Porównaj strategie kwantyzacji na różnych poziomach precyzji (od 1-bit do 8-bit).  
2. Wyjaśnij zalety formatu GGUF dla wdrożeń na urządzeniach brzegowych.  
3. Jak optymalizacja uwzględniająca sprzęt w Microsoft Olive poprawia efektywność wdrożeń?  
4. Jakie są kluczowe korzyści z użycia NNCF w OpenVINO dla kompresji modeli?  
5. Opisz, w jaki sposób Apple MLX wykorzystuje zunifikowaną architekturę pamięci do optymalizacji.  
6. Jak synteza przepływu pracy pomaga w wyborze optymalnych frameworków optymalizacyjnych?  

### Ćwiczenia praktyczne  

1. **Kwantyzacja modelu**: Zastosuj różne poziomy kwantyzacji do modelu i porównaj wyniki (1 godzina).  
2. **Optymalizacja OpenVINO**: Użyj NNCF do kompresji modelu dla sprzętu Intel (1 godzina).  
3. **Porównanie frameworków**: Przetestuj ten sam model w trzech różnych frameworkach optymalizacyjnych (1 godzina).  
4. **Benchmark wydajności**: Zmierz wpływ optymalizacji na szybkość wnioskowania i wykorzystanie pamięci (1 godzina).  

## Moduł 5: SLMOps - Operacje na Małych Modelach Językowych  

### Kluczowe cele nauki  

- Zrozumienie zasad zarządzania cyklem życia SLMOps  
- Opanowanie technik destylacji i dostrajania dla wdrożeń na urządzeniach brzegowych  
- Implementacja strategii wdrożeń produkcyjnych z monitorowaniem  
- Tworzenie przepływów pracy klasy korporacyjnej dla operacji i utrzymania SLM  

### Obszary do nauki  

#### Sekcja 1: Wprowadzenie do SLMOps  
- **Kluczowe pojęcia**:  
  - Zmiana paradygmatu SLMOps w operacjach AI  
  - Efektywność kosztowa i architektura z priorytetem prywatności  
  - Strategiczny wpływ biznesowy i przewagi konkurencyjne  

#### Sekcja 2: Destylacja modelu  
- **Kluczowe pojęcia**:  
  - Techniki transferu wiedzy  
  - Implementacja procesu destylacji w dwóch etapach  
  - Przepływy pracy destylacji w Azure ML  

#### Sekcja 3: Strategie dostrajania  
- **Kluczowe pojęcia**:  
  - Dostrajanie efektywne pod względem parametrów (PEFT)  
  - Zaawansowane metody LoRA i QLoRA  
  - Trening wieloadapterowy i optymalizacja hiperparametrów  

#### Sekcja 4: Wdrożenie produkcyjne  
- **Kluczowe pojęcia**:  
  - Konwersja i kwantyzacja modelu na potrzeby produkcji  
  - Konfiguracja wdrożenia Foundry Local  
  - Benchmark wydajności i walidacja jakości  

### Pytania do samooceny  

1. Czym różni się SLMOps od tradycyjnego MLOps?  
2. Wyjaśnij korzyści z destylacji modelu dla wdrożeń na urządzeniach brzegowych.  
3. Jakie są kluczowe aspekty dostrajania SLM w środowiskach o ograniczonych zasobach?  
4. Opisz kompletny pipeline wdrożenia produkcyjnego dla aplikacji AI na urządzeniach brzegowych.  

### Ćwiczenia praktyczne  

1. **Podstawowa destylacja**: Utwórz mniejszy model na podstawie większego modelu nauczyciela (1 godzina).  
2. **Eksperyment z dostrajaniem**: Dostosuj model do konkretnej dziedziny (1 godzina).  
3. **Pipeline wdrożeniowy**: Skonfiguruj podstawowy pipeline CI/CD dla wdrożenia modelu (1 godzina).  

## Moduł 6: Agentowe Systemy SLM - Agenci AI i Wywoływanie Funkcji  

### Kluczowe cele nauki  

- Tworzenie inteligentnych agentów AI dla środowisk brzegowych z użyciem Małych Modeli Językowych  
- Implementacja możliwości wywoływania funkcji w systematycznych przepływach pracy  
- Opanowanie integracji Model Context Protocol (MCP) dla standaryzowanej interakcji z narzędziami  
- Tworzenie zaawansowanych systemów agentowych z minimalną interwencją człowieka  

### Obszary do nauki  

#### Sekcja 1: Agenci AI i podstawy SLM  
- **Kluczowe pojęcia**:  
  - Ramy klasyfikacji agentów (refleksyjni, oparte na modelu, oparte na celach, uczący się agenci)  
  - Analiza kompromisów między SLM a LLM  
  - Wzorce projektowe dla agentów specyficznych dla urządzeń brzegowych  
  - Optymalizacja zasobów dla agentów  

#### Sekcja 2: Wywoływanie funkcji w Małych Modelach Językowych  
- **Kluczowe pojęcia**:  
  - Implementacja systematycznych przepływów pracy (detekcja intencji, wyjście JSON, zewnętrzne wykonanie)  
  - Implementacje specyficzne dla platform (Phi-4-mini, wybrane modele Qwen, Microsoft Foundry Local)  
  - Zaawansowane przykłady (współpraca wieloagentowa, dynamiczny wybór narzędzi)  
  - Rozważania produkcyjne (ograniczenia szybkości, logowanie audytowe, środki bezpieczeństwa)  

#### Sekcja 3: Integracja Model Context Protocol (MCP)  
- **Kluczowe pojęcia**:  
  - Architektura protokołu i projekt systemu warstwowego  
  - Obsługa wielu backendów (Ollama dla rozwoju, vLLM dla produkcji)  
  - Protokoły połączeń (tryby STDIO i SSE)  
  - Zastosowania w rzeczywistości (automatyzacja webowa, przetwarzanie danych, integracja API)  

### Pytania do samooceny  

1. Jakie są kluczowe aspekty architektoniczne dla agentów AI na urządzeniach brzegowych?  
2. Jak wywoływanie funkcji zwiększa możliwości agentów?  
3. Wyjaśnij rolę Model Context Protocol w komunikacji agentów.  

### Ćwiczenia praktyczne  

1. **Prosty agent**: Zbuduj podstawowego agenta AI z wywoływaniem funkcji (1 godzina).  
2. **Integracja MCP**: Zaimplementuj MCP w aplikacji agenta (30 minut).  

## Moduł 7: Przykłady implementacji EdgeAI  

### Kluczowe cele nauki  

- Opanowanie AI Toolkit dla Visual Studio Code w kompleksowych przepływach pracy EdgeAI  
- Zdobycie wiedzy na temat platformy Windows AI Foundry i strategii optymalizacji NPU  
- Implementacja EdgeAI na różnych platformach sprzętowych i scenariuszach wdrożeniowych  
- Tworzenie aplikacji EdgeAI gotowych do produkcji z optymalizacjami specyficznymi dla platform  

### Obszary do nauki  

#### Sekcja 1: AI Toolkit dla Visual Studio Code  
- **Kluczowe pojęcia**:  
  - Kompleksowe środowisko rozwoju Edge AI w VS Code  
  - Katalog modeli i ich odkrywanie dla wdrożeń na urządzeniach brzegowych  
  - Lokalne testowanie, optymalizacja i rozwój agentów  
  - Monitorowanie wydajności i ocena dla scenariuszy brzegowych  

#### Sekcja 2: Przewodnik rozwoju EdgeAI na Windows  
- **Kluczowe pojęcia**:  
  - Kompleksowy przegląd platformy Windows AI Foundry  
  - API Phi Silica dla efektywnego wnioskowania na NPU  
  - API Computer Vision dla przetwarzania obrazów i OCR  
  - Foundry Local CLI dla lokalnego rozwoju i testowania  

#### Sekcja 3: Implementacje specyficzne dla platform  
- **Kluczowe pojęcia**:  
  - Wdrożenie na NVIDIA Jetson Orin Nano (67 TOPS wydajności AI)  
  - Aplikacje mobilne z .NET MAUI i ONNX Runtime GenAI  
  - Rozwiązania Azure EdgeAI z hybrydową architekturą chmura-brzeg  
  - Optymalizacja Windows ML z uniwersalnym wsparciem sprzętowym  
  - Aplikacje Foundry Local z implementacją RAG skoncentrowaną na prywatności  

### Pytania do samooceny  

1. Jak AI Toolkit usprawnia przepływ pracy rozwoju EdgeAI?  
2. Porównaj strategie wdrożeniowe na różnych platformach sprzętowych.  
3. Jakie są zalety Windows AI Foundry dla rozwoju na urządzeniach brzegowych?  
4. Wyjaśnij rolę optymalizacji NPU w nowoczesnych aplikacjach Edge AI.  
5. Jak API Phi Silica wykorzystuje sprzęt NPU do optymalizacji wydajności?  
6. Porównaj korzyści z lokalnego i chmurowego wdrożenia dla aplikacji wrażliwych na prywatność.  

### Ćwiczenia praktyczne  

1. **Konfiguracja AI Toolkit**: Skonfiguruj AI Toolkit i zoptymalizuj model (1 godzina).  
2. **Windows AI Foundry**: Zbuduj prostą aplikację Windows AI używając API Phi Silica (1 godzina).  
3. **Wdrożenie międzyplatformowe**: Wdróż ten sam model na dwóch różnych platformach (1 godzina).  
4. **Optymalizacja NPU**: Przetestuj wydajność NPU za pomocą narzędzi Windows AI Foundry (30 minut).  

## Przewodnik alokacji czasu  

Aby jak najlepiej wykorzystać 20-godzinny czas kursu, oto sugerowany podział czasu:  

| Aktywność | Alokacja czasu | Opis |  
|----------|----------------|-------------|  
| Czytanie materiałów podstawowych | 9 godzin | Skupienie na kluczowych pojęciach w każdym module |  
| Ćwiczenia praktyczne | 6 godzin | Praktyczna implementacja kluczowych technik |  
| Samoocena | 2 godziny | Testowanie zrozumienia poprzez pytania i refleksję |  
| Mini-projekt | 3 godziny | Zastosowanie wiedzy w małej praktycznej implementacji |  

### Kluczowe obszary w zależności od ograniczeń czasowych  

**Jeśli masz tylko 10 godzin:**  
- Ukończ moduły 1, 2 i 3 (podstawowe pojęcia EdgeAI).  
- Wykonaj co najmniej jedno ćwiczenie praktyczne na moduł.  
- Skup się na zrozumieniu kluczowych pojęć zamiast szczegółów implementacji.  

**Jeśli możesz poświęcić pełne 20 godzin:**  
- Ukończ wszystkie siedem modułów.  
- Wykonaj kluczowe ćwiczenia praktyczne z każdego modułu.  
- Zrealizuj jeden mini-projekt z modułu 7.  
- Przeglądaj co najmniej 2-3 dodatkowe zasoby.  

**Jeśli masz więcej niż 20 godzin:**  
- Ukończ wszystkie moduły z szczegółowymi ćwiczeniami.  
- Zbuduj wiele mini-projektów.  
- Eksploruj zaawansowane techniki optymalizacji w module 4.  
- Implementuj wdrożenie produkcyjne z modułu 5.  

## Zasoby niezbędne  

Te starannie wybrane zasoby zapewniają największą wartość w ograniczonym czasie nauki:  

### Dokumentacja obowiązkowa  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Najbardziej efektywne narzędzie do optymalizacji modeli  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Najszybszy sposób na lokalne wdrożenie SLM  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Odniesienie dla wiodącego modelu zoptymalizowanego dla urządzeń brzegowych  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kompleksowy zestaw narzędzi optymalizacyjnych Intela  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Zintegrowane środowisko rozwoju EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platforma rozwoju EdgeAI specyficzna dla Windows  

### Narzędzia oszczędzające czas  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Szybki dostęp do modeli i ich wdrożenie  
- [Gradio](https://www.gradio.app/docs/interface) - Szybki rozwój interfejsów użytkownika dla demonstracji AI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Uproszczona optymalizacja modeli  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Efektywne wnioskowanie na CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework kompresji sieci neuronowych  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Zestaw narzędzi do wdrożenia dużych modeli językowych  

## Szablon śledzenia postępów  

Użyj tego uproszczonego szablonu do śledzenia postępów w nauce podczas 20-godzinnego kursu:  

| Moduł | Data ukończenia | Czas spędzony | Kluczowe wnioski |  
|--------|----------------|-------------|---------------|  
| Moduł 1: Podstawy EdgeAI | | | |  
| Moduł 2: Podstawy SLM | | | |  
| Moduł 3: Wdrożenie SLM | | | |  
| Moduł 4: Optymalizacja modeli | | | |  
| Moduł 5: SLMOps | | | |  
| Moduł 6: Agenci AI | | | |  
| Moduł 7: Narzędzia rozwoju | | | |  
| Ćwiczenia praktyczne | | | |  
| Mini-projekt | | | |  

## Pomysły na mini-projekty  

Rozważ realizację jednego z tych projektów, aby przećwiczyć koncepcje EdgeAI (każdy zaprojektowany na 2-4 godziny):  

### Projekty dla początkujących (2-3 godziny każdy)  
1. **Asystent tekstowy na urządzeniu brzegowym**: Utwórz prosty offline'owy narzędzie do uzupełniania tekstu z użyciem małego modelu językowego.  
2. **Dashboard porównania modeli**: Zbuduj podstawową wizualizację metryk wydajności dla różnych SLM.  
3. **Eksperyment optymalizacyjny**: Zmierz wpływ różnych poziomów kwantyzacji na ten sam model bazowy.  

### Projekty dla średniozaawansowanych (3-4 godziny każdy)  
4. **Przepływ pracy AI Toolkit**: Użyj AI Toolkit w VS Code do optymalizacji i wdrożenia modelu od początku do końca.  
5. **Aplikacja Windows AI Foundry**: Utwórz aplikację Windows z użyciem API Phi Silica i optymalizacji NPU.  
6. **Wdrożenie międzyplatformowe**: Wdróż ten sam zoptymalizowany model na Windows (OpenVINO) i mobilne (.NET MAUI).  
7. **Agent z wywoływaniem funkcji**: Zbuduj agenta AI z możliwościami wywoływania funkcji dla scenariuszy brzegowych.  

### Zaawansowane projekty integracyjne (4-5 godzin każdy)  
8. **Pipeline optymalizacji OpenVINO**: Zaimplementuj kompletną optymalizację modelu z użyciem NNCF i zestawu narzędzi GenAI.  
9. **Pipeline SLMOps**: Zaimplementuj kompletny cykl życia modelu od treningu do wdrożenia na urządzeniach brzegowych.  
10. **System wielomodelowy na urządzeniach brzegowych**: Wdróż wiele wyspecjalizowanych modeli współpracujących na sprzęcie brzegowym.  
11. **System integracji MCP**: Zbuduj system agentowy z użyciem Model Context Protocol do interakcji z narzędziami.  

## Społeczność nauki  

Dołącz do dyskusji i nawiąż kontakt z innymi uczącymi się:  
- Dyskusje na GitHub w [repozytorium EdgeAI dla początkujących](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Podsumowanie  

EdgeAI reprezentuje granicę wdrożeń sztucznej inteligencji, przynosząc potężne możliwości bezpośrednio na urządzenia, jednocześnie rozwiązując klucz

---

**Zastrzeżenie**:  
Ten dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby tłumaczenie było precyzyjne, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za źródło autorytatywne. W przypadku informacji o kluczowym znaczeniu zaleca się skorzystanie z profesjonalnego tłumaczenia przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z użycia tego tłumaczenia.