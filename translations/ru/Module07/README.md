<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e9e31a2b5ff0f6a682a258fa859a8ff5",
  "translation_date": "2025-09-26T19:22:22+00:00",
  "source_file": "Module07/README.md",
  "language_code": "ru"
}
-->
# Глава 07: Примеры EdgeAI

Edge AI объединяет искусственный интеллект с вычислениями на периферии, позволяя выполнять интеллектуальную обработку непосредственно на устройствах без необходимости подключения к облаку. В этой главе рассматриваются пять различных реализаций EdgeAI на различных платформах и в рамках различных фреймворков, демонстрируя универсальность и мощь запуска моделей ИИ на периферии.

## 1. EdgeAI на NVIDIA Jetson Orin Nano

NVIDIA Jetson Orin Nano представляет собой прорыв в доступных вычислениях Edge AI, обеспечивая до 67 TOPS производительности ИИ в компактном форм-факторе размером с кредитную карту. Эта мощная платформа Edge AI делает разработку генеративного ИИ доступной для любителей, студентов и профессиональных разработчиков.

### Основные характеристики
- Обеспечивает до 67 TOPS производительности ИИ — на 1.7 раза больше, чем у предшественника
- 1024 CUDA-ядра и до 32 Tensor Cores для обработки ИИ
- 6-ядерный процессор Arm Cortex-A78AE v8.2 64-бит с максимальной частотой 1.5 ГГц
- Стоимость всего $249, что делает платформу самой доступной для разработчиков, студентов и создателей

### Применение
Jetson Orin Nano отлично подходит для запуска современных генеративных моделей ИИ, включая vision transformers, большие языковые модели и модели vision-language. Он специально разработан для использования в сценариях GenAI, и теперь вы можете запускать несколько LLM на устройстве размером с ладонь. Популярные сценарии включают роботов с поддержкой ИИ, умные дроны, интеллектуальные камеры и автономные устройства на периферии.

**Подробнее**: [NVIDIA's Jetson Orin Nano SuperComputer: The Next Big Thing in EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI в мобильных приложениях с .NET MAUI и ONNX Runtime GenAI

Это решение демонстрирует, как интегрировать генеративный ИИ и большие языковые модели (LLMs) в кроссплатформенные мобильные приложения с использованием .NET MAUI (Multi-platform App UI) и ONNX Runtime GenAI. Такой подход позволяет разработчикам .NET создавать сложные мобильные приложения с поддержкой ИИ, которые работают нативно на устройствах Android и iOS.

### Основные характеристики
- Построено на фреймворке .NET MAUI, предоставляющем единый код для приложений Android и iOS
- Интеграция ONNX Runtime GenAI позволяет запускать генеративные модели ИИ непосредственно на мобильных устройствах
- Поддерживает различные аппаратные ускорители, адаптированные для мобильных устройств, включая CPU, GPU и специализированные мобильные процессоры ИИ
- Оптимизации для платформ, такие как CoreML для iOS и NNAPI для Android через ONNX Runtime
- Реализует полный цикл генеративного ИИ, включая предварительную и постобработку, инференс, обработку логитов, поиск и выбор, а также управление KV-кэшем

### Преимущества разработки
Подход .NET MAUI позволяет разработчикам использовать свои существующие навыки C# и .NET при создании кроссплатформенных приложений с поддержкой ИИ. Фреймворк ONNX Runtime GenAI поддерживает множество архитектур моделей, включая Llama, Mistral, Phi, Gemma и другие. Оптимизированные ядра ARM64 ускоряют умножение матриц INT4, обеспечивая эффективную производительность на мобильном оборудовании при сохранении привычного опыта разработки на .NET.

### Сценарии использования
Это решение идеально подходит для разработчиков, которые хотят создавать мобильные приложения с поддержкой ИИ, используя технологии .NET, включая интеллектуальные чат-боты, приложения для распознавания изображений, инструменты перевода языков и системы персонализированных рекомендаций, которые работают полностью на устройстве для повышения конфиденциальности и возможности работы в офлайне.

**Подробнее**: [.NET MAUI ONNX Runtime GenAI Example](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI в Azure с Small Language Models Engine

Решение Microsoft на базе Azure для EdgeAI сосредоточено на эффективном развертывании Small Language Models (SLMs) в гибридных облачно-периферийных средах. Этот подход соединяет возможности облачных AI-сервисов с требованиями периферийного развертывания.

### Преимущества архитектуры
- Бесшовная интеграция с AI-сервисами Azure
- Запуск SLM/LLM и мультимодальных моделей на устройстве и в облаке с помощью ONNX Runtime
- Оптимизация для развертывания в масштабе предприятия
- Поддержка непрерывного обновления и управления моделями

### Сценарии использования
Реализация Azure EdgeAI отлично подходит для сценариев, требующих развертывания AI корпоративного уровня с возможностями управления через облако. Это включает интеллектуальную обработку документов, аналитику в реальном времени и гибридные AI-рабочие процессы, которые используют как облачные, так и периферийные вычислительные ресурсы.

**Подробнее**: [Azure EdgeAI SLM Engine](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## [4. EdgeAI с Windows ML](./windowdeveloper.md)

Windows ML представляет собой передовой runtime от Microsoft, оптимизированный для эффективного инференса моделей на устройстве и упрощенного развертывания, служащий основой Windows AI Foundry. Эта платформа позволяет разработчикам создавать приложения для Windows с поддержкой ИИ, используя весь спектр аппаратных возможностей ПК.

### Возможности платформы
- Работает на всех ПК с Windows 11 версии 24H2 (сборка 26100) или выше
- Поддерживает все x64 и ARM64 ПК, даже те, которые не имеют NPU или GPU
- Позволяет разработчикам использовать свои собственные модели и эффективно развертывать их на экосистеме партнеров по производству процессоров, включая AMD, Intel, NVIDIA и Qualcomm, охватывая CPU, GPU, NPU
- Благодаря инфраструктурным API разработчикам больше не нужно создавать несколько сборок приложения для разных процессоров

### Преимущества для разработчиков
Windows ML абстрагирует оборудование и провайдеры выполнения, позволяя сосредоточиться на написании кода. Кроме того, Windows ML автоматически обновляется для поддержки последних NPU, GPU и CPU по мере их выпуска. Платформа предоставляет единый фреймворк для разработки ИИ на разнообразной аппаратной экосистеме Windows.

**Подробнее**: 
- [Windows ML Overview](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Windows EdgeAI Development Guide](./windowdeveloper.md) - Полное руководство по разработке Edge AI для Windows

## [5. EdgeAI с Foundry Local Applications](./foundrylocal.md)

Foundry Local позволяет разработчикам Windows и Mac создавать приложения Retrieval Augmented Generation (RAG), используя локальные ресурсы в .NET, объединяя локальные языковые модели с возможностями семантического поиска. Этот подход обеспечивает конфиденциальные решения ИИ, работающие полностью на локальной инфраструктуре.

### Техническая архитектура
- Объединяет языковую модель Phi, локальные эмбеддинги и Semantic Kernel для создания сценария RAG
- Использует эмбеддинги как векторы (массивы) значений с плавающей точкой, представляющие контент и его семантическое значение
- Semantic Kernel выступает в роли основного оркестратора, интегрируя Phi и Smart Components для создания бесшовного конвейера RAG
- Поддержка локальных векторных баз данных, включая SQLite и Qdrant

### Преимущества реализации
RAG, или Retrieval Augmented Generation, — это просто способ "найти информацию и включить её в запрос". Локальная реализация обеспечивает конфиденциальность данных, предоставляя интеллектуальные ответы, основанные на пользовательских базах знаний. Этот подход особенно ценен для корпоративных сценариев, требующих суверенитета данных и возможности работы в офлайне.

**Подробнее**: 
- [Foundry Local](./foundrylocal.md)
- [Foundry Local RAG Samples](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

### Windows Foundry Local

Microsoft Foundry Local предоставляет REST-сервер, совместимый с OpenAI, на базе ONNX Runtime для запуска моделей локально на Windows. Ниже приведено краткое, проверенное резюме; подробности смотрите в официальной документации.

- Начало работы: https://learn.microsoft.com/azure/ai-foundry/foundry-local/get-started
- Архитектура: https://learn.microsoft.com/azure/ai-foundry/foundry-local/concepts/foundry-local-architecture
- Справочник CLI: https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli
- Полное руководство для Windows в этом репозитории: [foundrylocal.md](./foundrylocal.md)

Установка или обновление на Windows (cmd.exe):
```cmd
winget install Microsoft.FoundryLocal
winget upgrade --id Microsoft.FoundryLocal
foundry --version
```

Исследование категорий CLI:
```cmd
foundry model --help
foundry service --help
foundry cache --help
```

Запуск модели и обнаружение динамической конечной точки:
```cmd
foundry model run gpt-oss-20b
foundry service status
```

Быстрая проверка REST для списка моделей (замените PORT из статуса):
```cmd
curl -s http://localhost:PORT/v1/models
```

Советы:
- Интеграция SDK: https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Использование собственной модели (компиляция): https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## Ресурсы для разработки Windows EdgeAI

Для разработчиков, ориентированных на платформу Windows, мы создали подробное руководство, охватывающее всю экосистему Windows EdgeAI. Этот ресурс предоставляет детальную информацию о Windows AI Foundry, включая API, инструменты и лучшие практики для разработки EdgeAI на Windows.

### Платформа Windows AI Foundry
Платформа Windows AI Foundry предоставляет полный набор инструментов и API, специально разработанных для разработки Edge AI на устройствах Windows. Это включает специализированную поддержку оборудования с ускорением NPU, интеграцию Windows ML и методы оптимизации, специфичные для платформы.

**Полное руководство**: [Windows EdgeAI Development Guide](../windowdeveloper.md)

В руководстве рассматриваются:
- Обзор платформы Windows AI Foundry и её компонентов
- API Phi Silica для эффективного инференса на оборудовании NPU
- API компьютерного зрения для обработки изображений и OCR
- Интеграция и оптимизация runtime Windows ML
- CLI Foundry Local для локальной разработки и тестирования
- Стратегии оптимизации оборудования для устройств Windows
- Практические примеры реализации и лучшие практики

### [AI Toolkit для разработки Edge AI](./aitoolkit.md)
Для разработчиков, использующих Visual Studio Code, расширение AI Toolkit предоставляет комплексную среду разработки, специально предназначенную для создания, тестирования и развертывания приложений Edge AI. Этот инструмент упрощает весь процесс разработки Edge AI в VS Code.

**Руководство по разработке**: [AI Toolkit для разработки Edge AI](./aitoolkit.md)

Руководство AI Toolkit охватывает:
- Поиск и выбор моделей для развертывания на периферии
- Локальные тесты и оптимизация рабочих процессов
- Интеграция ONNX и Ollama для периферийных моделей
- Техники конверсии и квантования моделей
- Разработка агентов для периферийных сценариев
- Оценка производительности и мониторинг
- Подготовка к развертыванию и лучшие практики

## Заключение

Эти пять реализаций EdgeAI демонстрируют зрелость и разнообразие доступных сегодня решений Edge AI. От устройств с аппаратным ускорением, таких как Jetson Orin Nano, до программных фреймворков, таких как ONNX Runtime GenAI и Windows ML, разработчики имеют беспрецедентные возможности для развертывания интеллектуальных приложений на периферии.

Общая черта всех этих платформ — демократизация возможностей ИИ, делающая сложное машинное обучение доступным для разработчиков с различным уровнем навыков и для различных сценариев использования. Независимо от того, создаете ли вы мобильные приложения, настольное ПО или встроенные системы, эти решения EdgeAI предоставляют основу для следующего поколения интеллектуальных приложений, которые работают эффективно и конфиденциально на периферии.

Каждая платформа предлагает уникальные преимущества: Jetson Orin Nano для вычислений на периферии с аппаратным ускорением, ONNX Runtime GenAI для кроссплатформенной мобильной разработки, Azure EdgeAI для интеграции облака и периферии в корпоративных сценариях, Windows ML для нативных приложений Windows и Foundry Local для реализации RAG с акцентом на конфиденциальность. Вместе они представляют собой комплексную экосистему для разработки EdgeAI.

---

