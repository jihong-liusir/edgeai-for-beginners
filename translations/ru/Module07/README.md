<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cb6eadc312d5658a0cd71c0085b43742",
  "translation_date": "2025-09-22T13:56:58+00:00",
  "source_file": "Module07/README.md",
  "language_code": "ru"
}
-->
# Глава 07: Примеры EdgeAI

Edge AI объединяет искусственный интеллект с вычислениями на периферии, позволяя выполнять интеллектуальную обработку данных непосредственно на устройствах без необходимости подключения к облаку. В этой главе рассматриваются пять различных реализаций EdgeAI на различных платформах и с использованием различных фреймворков, демонстрируя универсальность и мощь работы моделей ИИ на периферии.

## 1. EdgeAI на NVIDIA Jetson Orin Nano

NVIDIA Jetson Orin Nano представляет собой прорыв в доступных вычислениях Edge AI, обеспечивая до 67 TOPS производительности ИИ в компактном форм-факторе размером с кредитную карту. Эта мощная платформа Edge AI делает разработку генеративного ИИ доступной для энтузиастов, студентов и профессиональных разработчиков.

### Основные характеристики
- Обеспечивает до 67 TOPS производительности ИИ — на 1,7 раза больше, чем у предшественника
- 1024 CUDA-ядра и до 32 Tensor-ядер для обработки ИИ
- 6-ядерный процессор Arm Cortex-A78AE v8.2 64-бит с максимальной частотой 1,5 ГГц
- Стоимость всего $249, что делает платформу самой доступной для разработчиков, студентов и создателей

### Применение
Jetson Orin Nano отлично подходит для работы с современными генеративными моделями ИИ, включая Vision Transformers, большие языковые модели и модели Vision-Language. Он специально разработан для использования в сценариях Generative AI, и теперь вы можете запускать несколько LLM на устройстве размером с ладонь. Популярные сценарии использования включают робототехнику с ИИ, умные дроны, интеллектуальные камеры и автономные устройства на периферии.

**Узнать больше**: [NVIDIA's Jetson Orin Nano SuperComputer: The Next Big Thing in EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI в мобильных приложениях с .NET MAUI и ONNX Runtime GenAI

Это решение демонстрирует, как интегрировать генеративный ИИ и большие языковые модели (LLM) в кроссплатформенные мобильные приложения с использованием .NET MAUI (Multi-platform App UI) и ONNX Runtime GenAI. Такой подход позволяет разработчикам .NET создавать сложные мобильные приложения с ИИ, которые работают нативно на устройствах Android и iOS.

### Основные характеристики
- Построено на фреймворке .NET MAUI, предоставляющем единый код для приложений Android и iOS
- Интеграция ONNX Runtime GenAI позволяет запускать генеративные модели ИИ непосредственно на мобильных устройствах
- Поддержка различных аппаратных ускорителей, включая CPU, GPU и специализированные мобильные процессоры ИИ
- Оптимизация для платформ, таких как CoreML для iOS и NNAPI для Android через ONNX Runtime
- Реализация полного цикла генеративного ИИ, включая пред- и постобработку, инференс, обработку логитов, поиск и выборку, а также управление кэшированием KV

### Преимущества разработки
Подход .NET MAUI позволяет разработчикам использовать свои существующие навыки C# и .NET для создания кроссплатформенных приложений с ИИ. Фреймворк ONNX Runtime GenAI поддерживает множество архитектур моделей, включая Llama, Mistral, Phi, Gemma и другие. Оптимизированные ядра ARM64 ускоряют умножение матриц с INT4-квантованием, обеспечивая эффективную производительность на мобильных устройствах при сохранении привычного опыта разработки на .NET.

### Сценарии использования
Это решение идеально подходит для разработчиков, которые хотят создавать мобильные приложения с ИИ, используя технологии .NET, включая интеллектуальные чат-боты, приложения для распознавания изображений, инструменты перевода языков и персонализированные системы рекомендаций, работающие полностью на устройстве для повышения конфиденциальности и возможности работы в оффлайн-режиме.

**Узнать больше**: [.NET MAUI ONNX Runtime GenAI Example](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI в Azure с движком Small Language Models

Решение EdgeAI от Microsoft на базе Azure сосредоточено на эффективном развертывании Small Language Models (SLM) в гибридных облачно-периферийных средах. Этот подход соединяет масштабируемые облачные сервисы ИИ с требованиями периферийного развертывания.

### Преимущества архитектуры
- Бесшовная интеграция с сервисами Azure AI
- Запуск SLM/LLM и мультимодальных моделей на устройствах и в облаке с использованием ONNX Runtime
- Оптимизация для развертывания в масштабе предприятия
- Поддержка непрерывного обновления и управления моделями

### Сценарии использования
Реализация Azure EdgeAI особенно эффективна в сценариях, требующих развертывания ИИ корпоративного уровня с возможностями управления через облако. Это включает интеллектуальную обработку документов, аналитику в реальном времени и гибридные рабочие процессы ИИ, использующие как облачные, так и периферийные вычислительные ресурсы.

**Узнать больше**: [Azure EdgeAI SLM Engine](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## 4. EdgeAI с Windows ML

Windows ML — это передовой рантайм от Microsoft, оптимизированный для производительного инференса моделей на устройствах и упрощенного развертывания, который служит основой для Windows AI Foundry. Эта платформа позволяет разработчикам создавать приложения для Windows с ИИ, использующие весь спектр возможностей аппаратного обеспечения ПК.

### Возможности платформы
- Работает на всех ПК с Windows 11 версии 24H2 (сборка 26100) или выше
- Поддерживает все x64 и ARM64 ПК, даже те, которые не имеют NPU или GPU
- Позволяет разработчикам использовать собственные модели и эффективно развертывать их на экосистеме аппаратных партнеров, включая AMD, Intel, NVIDIA и Qualcomm, охватывая CPU, GPU, NPU
- Благодаря инфраструктурным API разработчикам больше не нужно создавать несколько сборок приложений для разных типов оборудования

### Преимущества для разработчиков
Windows ML абстрагирует аппаратное обеспечение и провайдеров выполнения, позволяя сосредоточиться на написании кода. Кроме того, Windows ML автоматически обновляется для поддержки последних NPU, GPU и CPU по мере их выхода. Платформа предоставляет унифицированный фреймворк для разработки ИИ в разнообразной экосистеме оборудования Windows.

**Узнать больше**: 
- [Обзор Windows ML](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Руководство по разработке Windows EdgeAI](../windowdeveloper.md) - Полное руководство по разработке Edge AI на Windows

## 5. EdgeAI с Foundry Local Applications

Foundry Local позволяет разработчикам создавать приложения Retrieval Augmented Generation (RAG), используя локальные ресурсы в .NET, объединяя локальные языковые модели с возможностями семантического поиска. Этот подход обеспечивает конфиденциальные решения ИИ, работающие полностью на локальной инфраструктуре.

### Техническая архитектура
- Объединяет языковую модель Phi, локальные эмбеддинги и Semantic Kernel для создания сценария RAG
- Использует эмбеддинги как векторы (массивы) чисел с плавающей точкой, представляющие контент и его семантическое значение
- Semantic Kernel выступает основным оркестратором, интегрируя Phi и Smart Components для создания бесшовного конвейера RAG
- Поддержка локальных векторных баз данных, включая SQLite и Qdrant

### Преимущества реализации
RAG, или Retrieval Augmented Generation, — это просто способ "найти информацию и включить её в запрос". Локальная реализация обеспечивает конфиденциальность данных, предоставляя интеллектуальные ответы, основанные на пользовательских базах знаний. Этот подход особенно ценен для корпоративных сценариев, требующих суверенитета данных и возможности работы в оффлайн-режиме.

**Узнать больше**: [Примеры Foundry Local RAG](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

### Windows Foundry Local

Microsoft Foundry Local предоставляет REST-сервер, совместимый с OpenAI, на базе ONNX Runtime для запуска моделей локально на Windows. Ниже приведено краткое, проверенное описание; полные детали см. в официальной документации.

- Начало работы: https://learn.microsoft.com/azure/ai-foundry/foundry-local/get-started
- Архитектура: https://learn.microsoft.com/azure/ai-foundry/foundry-local/concepts/foundry-local-architecture
- Справочник CLI: https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli
- Полное руководство для Windows в этом репозитории: [foundrylocal.md](./foundrylocal.md)

Установка или обновление на Windows (cmd.exe):
```cmd
winget install Microsoft.FoundryLocal
winget upgrade --id Microsoft.FoundryLocal
foundry --version
```

Изучение категорий CLI:
```cmd
foundry model --help
foundry service --help
foundry cache --help
```

Запуск модели и обнаружение динамической конечной точки:
```cmd
foundry model run gpt-oss-20b
foundry service status
```

Быстрая проверка REST для списка моделей (замените PORT из статуса):
```cmd
curl -s http://localhost:PORT/v1/models
```

Советы:
- Интеграция SDK: https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Использование собственной модели (компиляция): https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## Ресурсы для разработки Windows EdgeAI

Для разработчиков, ориентированных на платформу Windows, мы создали полное руководство, охватывающее всю экосистему Windows EdgeAI. Этот ресурс предоставляет подробную информацию о Windows AI Foundry, включая API, инструменты и лучшие практики для разработки EdgeAI на Windows.

### Платформа Windows AI Foundry
Платформа Windows AI Foundry предоставляет полный набор инструментов и API, специально разработанных для разработки Edge AI на устройствах Windows. Это включает специализированную поддержку оборудования с ускорением NPU, интеграцию Windows ML и платформенные методы оптимизации.

**Полное руководство**: [Руководство по разработке Windows EdgeAI](../windowdeveloper.md)

В руководстве рассматриваются:
- Обзор платформы Windows AI Foundry и её компонентов
- API Phi Silica для эффективного инференса на оборудовании NPU
- API компьютерного зрения для обработки изображений и OCR
- Интеграция и оптимизация рантайма Windows ML
- CLI Foundry Local для локальной разработки и тестирования
- Стратегии оптимизации оборудования для устройств Windows
- Практические примеры реализации и лучшие практики

### Инструментарий ИИ для разработки Edge AI
Для разработчиков, использующих Visual Studio Code, расширение AI Toolkit предоставляет комплексную среду разработки, специально предназначенную для создания, тестирования и развертывания приложений Edge AI. Этот инструмент упрощает весь процесс разработки Edge AI в VS Code.

**Руководство по разработке**: [Инструментарий ИИ для разработки Edge AI](../aitoolkit.md)

Руководство по AI Toolkit охватывает:
- Поиск и выбор моделей для развертывания на периферии
- Локальные тестирование и оптимизация
- Интеграция ONNX и Ollama для моделей на периферии
- Методы конверсии и квантования моделей
- Разработка агентов для сценариев на периферии
- Оценка производительности и мониторинг
- Подготовка к развертыванию и лучшие практики

## Заключение

Эти пять реализаций EdgeAI демонстрируют зрелость и разнообразие доступных сегодня решений Edge AI. От устройств с аппаратным ускорением, таких как Jetson Orin Nano, до программных фреймворков, таких как ONNX Runtime GenAI и Windows ML, разработчики имеют беспрецедентные возможности для развертывания интеллектуальных приложений на периферии.

Общая черта всех этих платформ — демократизация возможностей ИИ, делающая сложное машинное обучение доступным для разработчиков с разным уровнем навыков и для различных сценариев использования. Независимо от того, создаёте ли вы мобильные приложения, настольное ПО или встроенные системы, эти решения EdgeAI предоставляют основу для следующего поколения интеллектуальных приложений, которые работают эффективно и конфиденциально на периферии.

Каждая платформа предлагает уникальные преимущества: Jetson Orin Nano для вычислений на периферии с аппаратным ускорением, ONNX Runtime GenAI для кроссплатформенной мобильной разработки, Azure EdgeAI для интеграции облака и периферии на уровне предприятия, Windows ML для нативных приложений Windows и Foundry Local для конфиденциальных реализаций RAG. Вместе они представляют собой комплексную экосистему для разработки EdgeAI.

---

