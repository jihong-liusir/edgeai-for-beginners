<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c86f39ae10a967d9b337934c067b64f9",
  "translation_date": "2025-10-02T11:01:56+00:00",
  "source_file": "Module07/README.md",
  "language_code": "ru"
}
-->
# Глава 07: Примеры EdgeAI

Edge AI объединяет искусственный интеллект и вычисления на периферии, позволяя выполнять интеллектуальную обработку данных непосредственно на устройствах без необходимости подключения к облаку. В этой главе рассматриваются пять различных реализаций EdgeAI на различных платформах и с использованием разных фреймворков, демонстрируя универсальность и мощь работы AI-моделей на периферии.

## 1. EdgeAI на NVIDIA Jetson Orin Nano

NVIDIA Jetson Orin Nano представляет собой прорыв в доступных вычислениях на периферии с использованием искусственного интеллекта, обеспечивая до 67 TOPS производительности AI в компактном форм-факторе размером с кредитную карту. Эта мощная платформа делает разработку генеративного AI доступной для энтузиастов, студентов и профессиональных разработчиков.

### Основные характеристики
- До 67 TOPS производительности AI — улучшение в 1,7 раза по сравнению с предыдущей моделью
- 1024 CUDA-ядра и до 32 Tensor-ядер для обработки AI
- 6-ядерный процессор Arm Cortex-A78AE v8.2 64-бит с максимальной частотой 1,5 ГГц
- Стоимость всего $249, что делает платформу доступной для разработчиков, студентов и создателей

### Применение
Jetson Orin Nano отлично подходит для работы с современными генеративными AI-моделями, включая Vision Transformers, большие языковые модели и модели Vision-Language. Он специально разработан для использования в сценариях Generative AI, и теперь вы можете запускать несколько LLM на устройстве размером с ладонь. Популярные сценарии использования включают роботов с AI, умные дроны, интеллектуальные камеры и автономные устройства на периферии.

**Узнать больше**: [Суперкомпьютер NVIDIA Jetson Orin Nano: следующий шаг в EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI в мобильных приложениях с .NET MAUI и ONNX Runtime GenAI

Это решение демонстрирует, как интегрировать генеративный AI и большие языковые модели (LLM) в кроссплатформенные мобильные приложения с использованием .NET MAUI (Multi-platform App UI) и ONNX Runtime GenAI. Такой подход позволяет разработчикам на .NET создавать сложные мобильные приложения с AI, которые работают нативно на устройствах Android и iOS.

### Основные характеристики
- Построено на фреймворке .NET MAUI, предоставляющем единый код для приложений на Android и iOS
- Интеграция ONNX Runtime GenAI позволяет запускать генеративные AI-модели непосредственно на мобильных устройствах
- Поддержка различных аппаратных ускорителей, включая CPU, GPU и специализированные мобильные AI-процессоры
- Оптимизация для платформ, таких как CoreML для iOS и NNAPI для Android через ONNX Runtime
- Реализация полного цикла генеративного AI, включая пред- и постобработку, инференс, обработку логитов, поиск и выборку, а также управление KV-кэшем

### Преимущества разработки
Подход .NET MAUI позволяет разработчикам использовать свои существующие навыки C# и .NET для создания кроссплатформенных AI-приложений. Фреймворк ONNX Runtime GenAI поддерживает множество архитектур моделей, включая Llama, Mistral, Phi, Gemma и другие. Оптимизированные ядра ARM64 ускоряют умножение матриц с INT4-квантованием, обеспечивая эффективную производительность на мобильном оборудовании при сохранении привычного опыта разработки на .NET.

### Сценарии использования
Это решение идеально подходит для разработчиков, которые хотят создавать мобильные приложения с AI на основе технологий .NET, включая интеллектуальные чат-боты, приложения для распознавания изображений, инструменты перевода языков и системы персонализированных рекомендаций, работающие полностью на устройстве для повышения конфиденциальности и автономности.

**Узнать больше**: [Пример .NET MAUI ONNX Runtime GenAI](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI в Azure с движком Small Language Models

Решение EdgeAI от Microsoft на базе Azure сосредоточено на эффективном развертывании Small Language Models (SLM) в гибридных облачно-периферийных средах. Этот подход соединяет возможности облачных AI-сервисов с требованиями периферийного развертывания.

### Преимущества архитектуры
- Бесшовная интеграция с Azure AI-сервисами
- Запуск SLM/LLM и мультимодальных моделей на устройствах и в облаке с использованием ONNX Runtime
- Оптимизация для развертывания в масштабе предприятия
- Поддержка непрерывного обновления и управления моделями

### Сценарии использования
Реализация Azure EdgeAI особенно эффективна в сценариях, требующих корпоративного уровня развертывания AI с возможностями управления через облако. Это включает интеллектуальную обработку документов, аналитику в реальном времени и гибридные AI-рабочие процессы, использующие как облачные, так и периферийные вычислительные ресурсы.

**Узнать больше**: [Движок Azure EdgeAI SLM](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## [4. EdgeAI с Windows ML](./windowdeveloper.md)

Windows ML — это передовая среда выполнения от Microsoft, оптимизированная для производительного инференса моделей на устройствах и упрощенного развертывания, которая служит основой Windows AI Foundry. Эта платформа позволяет разработчикам создавать приложения для Windows с AI, используя весь спектр возможностей аппаратного обеспечения ПК.

### Возможности платформы
- Работает на всех ПК с Windows 11 версии 24H2 (сборка 26100) или выше
- Поддерживает все x64 и ARM64 ПК, даже те, которые не оснащены NPU или GPU
- Позволяет разработчикам использовать собственные модели и эффективно развертывать их на экосистеме аппаратного обеспечения, включая AMD, Intel, NVIDIA и Qualcomm, охватывая CPU, GPU, NPU
- Благодаря инфраструктурным API разработчикам больше не нужно создавать несколько сборок приложений для разных типов оборудования

### Преимущества для разработчиков
Windows ML абстрагирует аппаратное обеспечение и провайдеры выполнения, позволяя сосредоточиться на написании кода. Кроме того, Windows ML автоматически обновляется для поддержки последних NPU, GPU и CPU по мере их выхода. Платформа предоставляет унифицированный фреймворк для разработки AI на разнообразном оборудовании Windows.

**Узнать больше**: 
- [Обзор Windows ML](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Руководство по разработке Windows EdgeAI](./windowdeveloper.md) - Полное руководство по разработке Edge AI на Windows

## [5. EdgeAI с Foundry Local Applications](./foundrylocal.md)

Foundry Local позволяет разработчикам на Windows и Mac создавать приложения Retrieval Augmented Generation (RAG), используя локальные ресурсы в .NET, объединяя локальные языковые модели с возможностями семантического поиска. Этот подход обеспечивает конфиденциальные AI-решения, работающие полностью на локальной инфраструктуре.

### Техническая архитектура
- Объединяет языковую модель Phi, локальные эмбеддинги и Semantic Kernel для создания сценария RAG
- Использует эмбеддинги как векторы (массивы) чисел с плавающей точкой, представляющие контент и его семантическое значение
- Semantic Kernel выступает основным оркестратором, интегрируя Phi и Smart Components для создания бесшовного RAG-пайплайна
- Поддержка локальных векторных баз данных, включая SQLite и Qdrant

### Преимущества реализации
RAG, или Retrieval Augmented Generation, — это просто способ "найти информацию и включить её в запрос". Локальная реализация обеспечивает конфиденциальность данных, предоставляя интеллектуальные ответы, основанные на пользовательских базах знаний. Этот подход особенно ценен для корпоративных сценариев, требующих суверенитета данных и автономной работы.

**Узнать больше**: 
- [Foundry Local](./foundrylocal.md)
- [Примеры Foundry Local RAG](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

### Windows Foundry Local

Microsoft Foundry Local предоставляет REST-сервер, совместимый с OpenAI, на базе ONNX Runtime для запуска моделей локально на Windows. Ниже приведено краткое, проверенное описание; полные детали см. в официальной документации.

- Начало работы: https://learn.microsoft.com/azure/ai-foundry/foundry-local/get-started
- Архитектура: https://learn.microsoft.com/azure/ai-foundry/foundry-local/concepts/foundry-local-architecture
- Справочник CLI: https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli
- Полное руководство для Windows в этом репозитории: [foundrylocal.md](./foundrylocal.md)

Установка или обновление на Windows (cmd.exe):
```cmd
winget install Microsoft.FoundryLocal
winget upgrade --id Microsoft.FoundryLocal
foundry --version
```

Изучение категорий CLI:
```cmd
foundry model --help
foundry service --help
foundry cache --help
```

Запуск модели и обнаружение динамического конечного пункта:
```cmd
foundry model run gpt-oss-20b
foundry service status
```

Быстрая проверка REST для списка моделей (замените PORT из статуса):
```cmd
curl -s http://localhost:PORT/v1/models
```

Советы:
- Интеграция SDK: https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Использование собственной модели (компиляция): https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## Ресурсы для разработки Windows EdgeAI

Для разработчиков, ориентированных на платформу Windows, мы создали подробное руководство, охватывающее всю экосистему Windows EdgeAI. Этот ресурс предоставляет детальную информацию о Windows AI Foundry, включая API, инструменты и лучшие практики для разработки EdgeAI на Windows.

### Платформа Windows AI Foundry
Платформа Windows AI Foundry предоставляет полный набор инструментов и API, специально разработанных для разработки Edge AI на устройствах Windows. Это включает специализированную поддержку оборудования с ускорением NPU, интеграцию Windows ML и платформенные методы оптимизации.

**Полное руководство**: [Руководство по разработке Windows EdgeAI](../windowdeveloper.md)

В этом руководстве рассматриваются:
- Обзор платформы Windows AI Foundry и её компонентов
- API Phi Silica для эффективного инференса на оборудовании с NPU
- API компьютерного зрения для обработки изображений и OCR
- Интеграция и оптимизация среды выполнения Windows ML
- CLI Foundry Local для локальной разработки и тестирования
- Стратегии оптимизации оборудования для устройств Windows
- Практические примеры реализации и лучшие практики

### [AI Toolkit для разработки Edge AI](./aitoolkit.md)
Для разработчиков, использующих Visual Studio Code, расширение AI Toolkit предоставляет комплексную среду разработки, специально предназначенную для создания, тестирования и развертывания приложений Edge AI. Этот инструмент упрощает весь процесс разработки Edge AI в VS Code.

**Руководство по разработке**: [AI Toolkit для разработки Edge AI](./aitoolkit.md)

Руководство по AI Toolkit охватывает:
- Поиск и выбор моделей для развертывания на периферии
- Локальные тестирование и оптимизация
- Интеграция ONNX и Ollama для периферийных моделей
- Методы конвертации и квантования моделей
- Разработка агентов для периферийных сценариев
- Оценка производительности и мониторинг
- Подготовка к развертыванию и лучшие практики

## Заключение

Эти пять реализаций EdgeAI демонстрируют зрелость и разнообразие доступных сегодня решений для периферийного AI. От устройств с аппаратным ускорением, таких как Jetson Orin Nano, до программных фреймворков, таких как ONNX Runtime GenAI и Windows ML, разработчики имеют беспрецедентные возможности для развертывания интеллектуальных приложений на периферии.

Общая черта всех этих платформ — демократизация возможностей AI, делающая сложное машинное обучение доступным для разработчиков с разным уровнем навыков и для различных сценариев использования. Независимо от того, создаёте ли вы мобильные приложения, настольное ПО или встроенные системы, эти решения EdgeAI предоставляют основу для следующего поколения интеллектуальных приложений, работающих эффективно и конфиденциально на периферии.

Каждая платформа предлагает уникальные преимущества: Jetson Orin Nano для вычислений на периферии с аппаратным ускорением, ONNX Runtime GenAI для кроссплатформенной мобильной разработки, Azure EdgeAI для интеграции облака и периферии в корпоративных масштабах, Windows ML для нативных приложений Windows и Foundry Local для конфиденциальных реализаций RAG. Вместе они представляют собой комплексную экосистему для разработки EdgeAI.

[Следующий AI Toolkit](aitoolkit.md)

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.