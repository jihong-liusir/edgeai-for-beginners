<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "65a22ed38b95f334dd8a893bf2c55806",
  "translation_date": "2025-10-02T11:00:37+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "ru"
}
-->
# AI Toolkit для Visual Studio Code - Руководство по разработке Edge AI

## Введение

Добро пожаловать в подробное руководство по использованию AI Toolkit для Visual Studio Code в разработке Edge AI. С переходом искусственного интеллекта от централизованных облачных вычислений к распределённым устройствам на периферии, разработчикам требуются мощные интегрированные инструменты, способные справляться с уникальными вызовами развертывания на периферии — от ограничений ресурсов до требований к работе в автономном режиме.

AI Toolkit для Visual Studio Code устраняет этот разрыв, предоставляя полноценную среду разработки, специально предназначенную для создания, тестирования и оптимизации AI-приложений, которые эффективно работают на периферийных устройствах. Независимо от того, разрабатываете ли вы для IoT-датчиков, мобильных устройств, встроенных систем или серверов на периферии, этот набор инструментов упрощает весь процесс разработки в привычной среде VS Code.

Это руководство познакомит вас с ключевыми концепциями, инструментами и лучшими практиками использования AI Toolkit в ваших проектах Edge AI — от выбора модели до её развертывания в производственной среде.

## Обзор

AI Toolkit для Visual Studio Code — это мощное расширение, которое упрощает разработку агентов и создание AI-приложений. Набор инструментов предоставляет обширные возможности для изучения, оценки и развертывания AI-моделей от множества провайдеров, включая Anthropic, OpenAI, GitHub, Google, а также поддерживает локальное выполнение моделей с использованием ONNX и Ollama.

Что отличает AI Toolkit, так это его комплексный подход ко всему жизненному циклу разработки AI. В отличие от традиционных инструментов, которые сосредоточены на отдельных аспектах, AI Toolkit предоставляет интегрированную среду, охватывающую поиск моделей, эксперименты, разработку агентов, оценку и развертывание — всё это в привычной среде VS Code.

Платформа специально разработана для быстрого прототипирования и развертывания в производственной среде, с такими функциями, как генерация подсказок, быстрые стартеры, бесшовная интеграция MCP (Model Context Protocol) и расширенные возможности оценки. Для разработки Edge AI это означает, что вы можете эффективно разрабатывать, тестировать и оптимизировать AI-приложения для сценариев развертывания на периферии, сохраняя полный рабочий процесс разработки в VS Code.

## Цели обучения

К концу этого руководства вы сможете:

### Основные навыки
- **Установить и настроить** AI Toolkit для Visual Studio Code для рабочих процессов разработки Edge AI
- **Ориентироваться и использовать** интерфейс AI Toolkit, включая Model Catalog, Playground и Agent Builder
- **Выбирать и оценивать** AI-модели, подходящие для развертывания на периферии, с учётом производительности и ограничений ресурсов
- **Конвертировать и оптимизировать** модели с использованием формата ONNX и техник квантования для периферийных устройств

### Навыки разработки Edge AI
- **Проектировать и реализовывать** приложения Edge AI с использованием интегрированной среды разработки
- **Тестировать модели** в условиях, приближенных к периферийным, с использованием локального вывода и мониторинга ресурсов
- **Создавать и настраивать** AI-агентов, оптимизированных для сценариев развертывания на периферии
- **Оценивать производительность моделей** с использованием метрик, актуальных для периферийных вычислений (задержка, использование памяти, точность)

### Оптимизация и развертывание
- **Применять техники квантования и обрезки** для уменьшения размера модели при сохранении приемлемой производительности
- **Оптимизировать модели** для конкретных периферийных аппаратных платформ, включая ускорение на CPU, GPU и NPU
- **Реализовывать лучшие практики** разработки Edge AI, включая управление ресурсами и стратегии резервирования
- **Готовить модели и приложения** к развертыванию на периферийных устройствах

### Продвинутые концепции Edge AI
- **Интегрировать с периферийными AI-фреймворками**, включая ONNX Runtime, Windows ML и TensorFlow Lite
- **Реализовывать многомодельные архитектуры** и сценарии федеративного обучения для периферийных сред
- **Устранять распространённые проблемы Edge AI**, такие как ограничения памяти, скорость вывода и совместимость оборудования
- **Проектировать стратегии мониторинга и логирования** для приложений Edge AI в производственной среде

### Практическое применение
- **Создавать комплексные решения Edge AI** от выбора модели до её развертывания
- **Демонстрировать владение** рабочими процессами разработки и техниками оптимизации, специфичными для периферии
- **Применять изученные концепции** к реальным сценариям использования Edge AI, включая IoT, мобильные и встроенные приложения
- **Оценивать и сравнивать** различные стратегии развертывания Edge AI и их компромиссы

## Основные функции для разработки Edge AI

### 1. Каталог моделей и их поиск
- **Поддержка множества провайдеров**: Просмотр и доступ к AI-моделям от Anthropic, OpenAI, GitHub, Google и других
- **Интеграция локальных моделей**: Упрощённый поиск моделей ONNX и Ollama для развертывания на периферии
- **Модели GitHub**: Прямая интеграция с хостингом моделей GitHub для упрощённого доступа
- **Сравнение моделей**: Сравнение моделей бок о бок для поиска оптимального баланса для ограничений периферийных устройств

### 2. Интерактивная площадка (Playground)
- **Интерактивная среда тестирования**: Быстрое экспериментирование с возможностями модели в контролируемой среде
- **Поддержка мультимодальности**: Тестирование с изображениями, текстом и другими типичными для периферии входными данными
- **Эксперименты в реальном времени**: Мгновенная обратная связь о реакции модели и её производительности
- **Оптимизация параметров**: Тонкая настройка параметров модели для требований развертывания на периферии

### 3. Конструктор подсказок (Agent Builder)
- **Генерация на естественном языке**: Создание начальных подсказок с использованием описаний на естественном языке
- **Итеративное улучшение**: Улучшение подсказок на основе ответов модели и её производительности
- **Декомпозиция задач**: Разделение сложных задач с помощью цепочек подсказок и структурированных выходных данных
- **Поддержка переменных**: Использование переменных в подсказках для динамического поведения агентов
- **Генерация производственного кода**: Создание готового кода для быстрого развития приложений

### 4. Массовое выполнение и оценка
- **Тестирование нескольких моделей**: Выполнение множества подсказок на выбранных моделях одновременно
- **Эффективное тестирование в масштабе**: Тестирование различных входных данных и конфигураций эффективно
- **Пользовательские тестовые случаи**: Запуск агентов с тестовыми случаями для проверки функциональности
- **Сравнение производительности**: Сравнение результатов на разных моделях и конфигурациях

### 5. Оценка моделей с использованием наборов данных
- **Стандартные метрики**: Тестирование AI-моделей с использованием встроенных оценщиков (F1, релевантность, сходство, связность)
- **Пользовательские оценщики**: Создание собственных метрик оценки для конкретных случаев использования
- **Интеграция наборов данных**: Тестирование моделей на обширных наборах данных
- **Измерение производительности**: Количественная оценка производительности модели для решений о развертывании на периферии

### 6. Возможности дообучения
- **Настройка моделей**: Адаптация моделей для конкретных случаев использования и областей
- **Специализированная адаптация**: Адаптация моделей к специализированным требованиям
- **Оптимизация для периферии**: Дообучение моделей с учётом ограничений развертывания на периферии
- **Обучение для конкретных областей**: Создание моделей, ориентированных на специфические случаи использования на периферии

### 7. Интеграция MCP-инструментов
- **Подключение внешних инструментов**: Подключение агентов к внешним инструментам через серверы Model Context Protocol
- **Действия в реальном мире**: Возможность агентов выполнять запросы к базам данных, доступ к API или выполнение пользовательской логики
- **Существующие MCP-серверы**: Использование инструментов через команды (stdio) или HTTP (server-sent event) протоколы
- **Разработка пользовательских MCP**: Создание и тестирование новых MCP-серверов в Agent Builder

### 8. Разработка и тестирование агентов
- **Поддержка вызова функций**: Возможность агентов динамически вызывать внешние функции
- **Тестирование интеграции в реальном времени**: Проверка интеграций с реальными запусками и использованием инструментов
- **Версионирование агентов**: Контроль версий агентов с возможностью сравнения результатов оценки
- **Отладка и трассировка**: Локальная трассировка и возможности отладки для разработки агентов

## Рабочий процесс разработки Edge AI

### Фаза 1: Поиск и выбор модели
1. **Изучение каталога моделей**: Используйте каталог моделей для поиска подходящих для развертывания на периферии
2. **Сравнение производительности**: Оцените модели по размеру, точности и скорости вывода
3. **Локальное тестирование**: Используйте модели Ollama или ONNX для локального тестирования перед развертыванием
4. **Оценка требований к ресурсам**: Определите потребности в памяти и вычислительных ресурсах для целевых периферийных устройств

### Фаза 2: Оптимизация модели
1. **Конвертация в ONNX**: Конвертируйте выбранные модели в формат ONNX для совместимости с периферией
2. **Применение квантования**: Уменьшите размер модели с помощью квантования INT8 или INT4
3. **Оптимизация оборудования**: Оптимизируйте для целевого периферийного оборудования (ARM, x86, специализированные ускорители)
4. **Проверка производительности**: Убедитесь, что оптимизированные модели сохраняют приемлемую точность

### Фаза 3: Разработка приложений
1. **Проектирование агентов**: Используйте Agent Builder для создания AI-агентов, оптимизированных для периферии
2. **Инженерия подсказок**: Разрабатывайте подсказки, которые эффективно работают с меньшими моделями для периферии
3. **Тестирование интеграции**: Проверяйте агентов в условиях, имитирующих периферийные
4. **Генерация кода**: Создавайте производственный код, оптимизированный для развертывания на периферии

### Фаза 4: Оценка и тестирование
1. **Массовая оценка**: Тестируйте множество конфигураций для поиска оптимальных настроек периферии
2. **Профилирование производительности**: Анализируйте скорость вывода, использование памяти и точность
3. **Симуляция периферии**: Тестируйте в условиях, аналогичных целевой среде развертывания на периферии
4. **Стресс-тестирование**: Оценивайте производительность при различных нагрузках

### Фаза 5: Подготовка к развертыванию
1. **Финальная оптимизация**: Применяйте финальные оптимизации на основе результатов тестирования
2. **Упаковка для развертывания**: Упаковывайте модели и код для развертывания на периферии
3. **Документация**: Документируйте требования к развертыванию и конфигурации
4. **Настройка мониторинга**: Подготовьте мониторинг и логирование для развертывания на периферии

## Целевая аудитория для разработки Edge AI

### Разработчики Edge AI
- Разработчики приложений, создающие устройства с AI и IoT-решения
- Разработчики встроенных систем, интегрирующие AI в устройства с ограниченными ресурсами
- Мобильные разработчики, создающие AI-приложения для смартфонов и планшетов

### Инженеры Edge AI
- Инженеры AI, оптимизирующие модели для развертывания на периферии и управляющие конвейерами вывода
- Инженеры DevOps, развертывающие и управляющие AI-моделями в распределённой периферийной инфраструктуре
- Инженеры производительности, оптимизирующие AI-нагрузки для ограничений периферийного оборудования

### Исследователи и преподаватели
- Исследователи AI, разрабатывающие эффективные модели и алгоритмы для периферийных вычислений
- Преподаватели, обучающие концепциям Edge AI и демонстрирующие техники оптимизации
- Студенты, изучающие вызовы и решения в развертывании Edge AI

## Сценарии использования Edge AI

### Умные IoT-устройства
- **Распознавание изображений в реальном времени**: Развертывание моделей компьютерного зрения на IoT-камерах и датчиках
- **Обработка голоса**: Реализация распознавания речи и обработки естественного языка на умных колонках
- **Предиктивное обслуживание**: Запуск моделей обнаружения аномалий на промышленных периферийных устройствах
- **Мониторинг окружающей среды**: Развертывание моделей анализа данных датчиков для экологических приложений

### Мобильные и встроенные приложения
- **Перевод на устройстве**: Реализация моделей перевода языка, работающих в автономном режиме
- **Дополненная реальность**: Развертывание моделей распознавания объектов и отслеживания в реальном времени для AR-приложений
- **Мониторинг здоровья**: Запуск моделей анализа здоровья на носимых устройствах и медицинском оборудовании
- **Автономные системы**: Реализация моделей принятия решений для дронов, роботов и транспортных средств

### Инфраструктура периферийных вычислений
- **Периферийные дата-центры**: Развертывание AI-моделей в периферийных дата-центрах для приложений с низкой задержкой
- **Интеграция CDN**: Интеграция возможностей AI-обработки в сети доставки контента
- **Периферия 5G**: Использование периферийных вычислений 5G для приложений с поддержкой AI
- **Туманные вычисления**: Реализация AI-обработки в средах туманных вычислений

## Установка и настройка

### Установка расширения
Установите расширение AI Toolkit напрямую из Visual Studio Code Marketplace:

**ID расширения**: `ms-windows-ai-studio.windows-ai-studio`

**Методы установки**:
1. **Marketplace VS Code**: Найдите "AI Toolkit" в представлении Extensions
2. **Командная строка**: `code --install-extension ms-windows-ai-studio.windows-ai-studio`
3. **Прямая установка**: Загрузите с [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### Предварительные требования для разработки Edge AI
- **Visual Studio Code**: Рекомендуется последняя версия
- **Среда Python**: Python 3.8+ с необходимыми библиотеками AI
- **ONNX Runtime** (опционально): Для вывода моделей ONNX
- **Ollama** (опционально): Для локального обслуживания моделей
- **Инструменты аппаратного ускорения**: CUDA, OpenVINO или ускорители, специфичные для платформы

### Первоначальная настройка
1. **Активация расширения**: Откройте VS Code и убедитесь, что AI Toolkit отображается в Activity Bar
2. **Настройка провайдеров моделей**: Настройте доступ к GitHub, OpenAI, Anthropic или другим провайдерам моделей
3. **Локальная среда**: Настройте среду Python и установите необходимые пакеты
4. **Аппаратное ускорение**: Настройте ускорение GPU/NPU, если доступно
5. **Интеграция MCP**: Настройте серверы Model Context Protocol, если необходимо

### Контрольный список для первого запуска
- [ ] Установлено и активировано расширение AI Toolkit
- [ ] Каталог моделей доступен, модели обнаруживаются
- [ ] Playground функционирует для тестирования моделей
- [ ] Agent Builder доступен для разработки подсказок
- [ ] Локальная среда разработки настроена
- [ ] Аппаратное ускорение (если доступно) настроено корректно

## Начало работы с AI Toolkit

### Краткое руководство

Рекомендуем начать с моделей, размещённых на GitHub, для наиболее упрощённого опыта:

1. **Установка**: Следуйте [руководству по установке](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup), чтобы настроить AI Toolkit на вашем устройстве
2. **Поиск моделей**: В дереве расширений выберите **CATALOG > Models**, чтобы изучить доступные модели
3. **Модели GitHub**: Начните с моделей, размещённых на GitHub, для оптимальной интеграции
4. **Тестирование в Playground**: На карточке модели выберите **Try in Playground**, чтобы начать экспериментировать с возможностями модели

### Пошаговая разработка Edge AI
2. Создайте начальные подсказки, используя описания на естественном языке  
3. Итеративно дорабатывайте и уточняйте подсказки на основе ответов модели  
4. Интегрируйте инструменты MCP для расширения возможностей агентов  

#### Шаг 3: Тестирование и оценка  
1. Используйте **Bulk Run** для тестирования нескольких подсказок на выбранных моделях  
2. Запускайте агентов с тестовыми сценариями для проверки функциональности  
3. Оценивайте точность и производительность с помощью встроенных или пользовательских метрик  
4. Сравнивайте различные модели и конфигурации  

#### Шаг 4: Тонкая настройка и оптимизация  
1. Настраивайте модели для специфических случаев использования  
2. Применяйте тонкую настройку для конкретных доменов  
3. Оптимизируйте для ограничений развертывания на периферийных устройствах  
4. Создавайте версии и сравнивайте различные конфигурации агентов  

#### Шаг 5: Подготовка к развертыванию  
1. Генерируйте готовый к производству код с помощью Agent Builder  
2. Настройте подключения к серверу MCP для использования в производственной среде  
3. Подготовьте пакеты развертывания для периферийных устройств  
4. Настройте метрики мониторинга и оценки  

## Лучшие практики разработки Edge AI  

### Выбор модели  
- **Ограничения по размеру**: Выбирайте модели, которые соответствуют ограничениям памяти целевых устройств  
- **Скорость вывода**: Отдавайте предпочтение моделям с быстрой скоростью вывода для приложений в реальном времени  
- **Компромисс точности**: Балансируйте точность модели с ограничениями ресурсов  
- **Совместимость форматов**: Предпочитайте форматы ONNX или оптимизированные для оборудования для развертывания на периферии  

### Техники оптимизации  
- **Квантование**: Используйте квантование INT8 или INT4 для уменьшения размера модели и повышения скорости  
- **Обрезка**: Удаляйте ненужные параметры модели для снижения вычислительных требований  
- **Дистилляция знаний**: Создавайте меньшие модели, сохраняющие производительность больших  
- **Аппаратное ускорение**: Используйте NPU, GPU или специализированные ускорители, если они доступны  

### Рабочий процесс разработки  
- **Итеративное тестирование**: Часто тестируйте в условиях, приближенных к периферийным  
- **Мониторинг производительности**: Постоянно отслеживайте использование ресурсов и скорость вывода  
- **Контроль версий**: Отслеживайте версии моделей и настройки оптимизации  
- **Документация**: Документируйте все решения по оптимизации и компромиссы производительности  

### Учет при развертывании  
- **Мониторинг ресурсов**: Отслеживайте использование памяти, процессора и энергии в производственной среде  
- **Резервные стратегии**: Реализуйте механизмы резервирования на случай сбоев модели  
- **Механизмы обновления**: Планируйте обновления моделей и управление версиями  
- **Безопасность**: Реализуйте соответствующие меры безопасности для приложений Edge AI  

## Интеграция с фреймворками Edge AI  

### ONNX Runtime  
- **Кроссплатформенное развертывание**: Развертывайте модели ONNX на различных периферийных платформах  
- **Оптимизация оборудования**: Используйте аппаратно-специфические оптимизации ONNX Runtime  
- **Поддержка мобильных устройств**: Используйте ONNX Runtime Mobile для смартфонов и планшетов  
- **Интеграция с IoT**: Развертывайте на IoT-устройствах с использованием легковесных дистрибутивов ONNX Runtime  

### Windows ML  
- **Устройства на Windows**: Оптимизируйте для периферийных устройств и ПК на базе Windows  
- **Ускорение с помощью NPU**: Используйте нейронные процессоры на устройствах Windows  
- **DirectML**: Применяйте DirectML для ускорения на GPU на платформах Windows  
- **Интеграция с UWP**: Интегрируйте с приложениями Universal Windows Platform  

### TensorFlow Lite  
- **Оптимизация для мобильных устройств**: Развертывайте модели TensorFlow Lite на мобильных и встроенных устройствах  
- **Аппаратные делегаты**: Используйте специализированные аппаратные делегаты для ускорения  
- **Микроконтроллеры**: Развертывайте на микроконтроллерах с помощью TensorFlow Lite Micro  
- **Кроссплатформенная поддержка**: Развертывайте на Android, iOS и встроенных системах Linux  

### Azure IoT Edge  
- **Гибрид облако-периферия**: Совмещайте обучение в облаке с выводом на периферии  
- **Развертывание модулей**: Развертывайте AI-модели как модули IoT Edge  
- **Управление устройствами**: Управляйте периферийными устройствами и обновлениями моделей удаленно  
- **Телеметрия**: Сбор данных о производительности и метрик моделей с периферийных развертываний  

## Расширенные сценарии Edge AI  

### Развертывание нескольких моделей  
- **Ансамбли моделей**: Развертывайте несколько моделей для повышения точности или надежности  
- **A/B тестирование**: Одновременно тестируйте разные модели на периферийных устройствах  
- **Динамический выбор**: Выбирайте модели в зависимости от текущих условий устройства  
- **Общий доступ к ресурсам**: Оптимизируйте использование ресурсов между несколькими развернутыми моделями  

### Федеративное обучение  
- **Распределенное обучение**: Обучайте модели на нескольких периферийных устройствах  
- **Сохранение конфиденциальности**: Держите данные обучения локально, обмениваясь улучшениями моделей  
- **Совместное обучение**: Позвольте устройствам учиться на коллективном опыте  
- **Координация периферия-облако**: Координируйте обучение между периферийными устройствами и облачной инфраструктурой  

### Обработка в реальном времени  
- **Обработка потоков**: Обрабатывайте непрерывные потоки данных на периферийных устройствах  
- **Вывод с низкой задержкой**: Оптимизируйте для минимальной задержки вывода  
- **Пакетная обработка**: Эффективно обрабатывайте пакеты данных на периферийных устройствах  
- **Адаптивная обработка**: Регулируйте обработку в зависимости от текущих возможностей устройства  

## Устранение неполадок в разработке Edge AI  

### Распространенные проблемы  
- **Ограничения памяти**: Модель слишком велика для памяти целевого устройства  
- **Скорость вывода**: Скорость вывода модели недостаточна для требований реального времени  
- **Снижение точности**: Оптимизация приводит к недопустимому снижению точности модели  
- **Совместимость оборудования**: Модель несовместима с целевым оборудованием  

### Стратегии отладки  
- **Профилирование производительности**: Используйте функции трассировки AI Toolkit для выявления узких мест  
- **Мониторинг ресурсов**: Отслеживайте использование памяти и процессора во время разработки  
- **Пошаговое тестирование**: Тестируйте оптимизации поэтапно, чтобы изолировать проблемы  
- **Симуляция оборудования**: Используйте инструменты разработки для симуляции целевого оборудования  

### Решения для оптимизации  
- **Дополнительное квантование**: Применяйте более агрессивные методы квантования  
- **Архитектура модели**: Рассмотрите другие архитектуры моделей, оптимизированные для периферии  
- **Оптимизация предобработки**: Оптимизируйте предобработку данных для ограничений периферии  
- **Оптимизация вывода**: Используйте аппаратно-специфические оптимизации вывода  

## Ресурсы и дальнейшие шаги  

### Официальная документация  
- [Документация для разработчиков AI Toolkit](https://aka.ms/AIToolkit/doc)  
- [Руководство по установке и настройке](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [Документация по интеллектуальным приложениям VS Code](https://code.visualstudio.com/docs/intelligentapps)  
- [Документация по Model Context Protocol (MCP)](https://modelcontextprotocol.io/)  

### Сообщество и поддержка  
- [Репозиторий AI Toolkit на GitHub](https://github.com/microsoft/vscode-ai-toolkit)  
- [Обсуждения и запросы функций на GitHub](https://aka.ms/AIToolkit/feedback)  
- [Сообщество Azure AI Foundry в Discord](https://aka.ms/azureaifoundry/discord)  
- [Маркетплейс расширений VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### Технические ресурсы  
- [Документация ONNX Runtime](https://onnxruntime.ai/)  
- [Документация Ollama](https://ollama.ai/)  
- [Документация Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [Документация Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### Обучающие материалы  
- [Курс "Основы Edge AI"](../Module01/README.md)  
- [Руководство по малым языковым моделям](../Module02/README.md)  
- [Стратегии развертывания на периферии](../Module03/README.md)  
- [Разработка Edge AI для Windows](./windowdeveloper.md)  

### Дополнительные ресурсы  
- **Статистика репозитория**: Более 1.8k звезд, 150+ форков, 18+ участников  
- **Лицензия**: Лицензия MIT  
- **Безопасность**: Применяются политики безопасности Microsoft  
- **Телеметрия**: Учитывает настройки телеметрии VS Code  

## Заключение  

AI Toolkit для Visual Studio Code представляет собой комплексную платформу для современной разработки AI, предоставляя упрощенные возможности разработки агентов, которые особенно ценны для приложений Edge AI. Благодаря обширному каталогу моделей, поддерживающему таких провайдеров, как Anthropic, OpenAI, GitHub и Google, а также локальному выполнению через ONNX и Ollama, этот инструмент предлагает гибкость, необходимую для различных сценариев развертывания на периферии.  

Сила инструмента заключается в его интегрированном подходе — от поиска моделей и экспериментов в Playground до сложной разработки агентов с Prompt Builder, комплексных возможностей оценки и бесшовной интеграции инструментов MCP. Для разработчиков Edge AI это означает быстрое прототипирование и тестирование AI-агентов перед развертыванием на периферии с возможностью быстрой итерации и оптимизации для сред с ограниченными ресурсами.  

Ключевые преимущества для разработки Edge AI включают:  
- **Быстрое экспериментирование**: Быстро тестируйте модели и агентов перед развертыванием  
- **Гибкость мультипровайдеров**: Доступ к моделям из различных источников для поиска оптимальных решений  
- **Локальная разработка**: Тестирование с ONNX и Ollama для автономной и конфиденциальной разработки  
- **Готовность к производству**: Генерация готового к производству кода и интеграция с внешними инструментами через MCP  
- **Комплексная оценка**: Использование встроенных и пользовательских метрик для проверки производительности Edge AI  

По мере того как AI продолжает двигаться в сторону сценариев развертывания на периферии, AI Toolkit для VS Code предоставляет среду разработки и рабочий процесс, необходимые для создания, тестирования и оптимизации интеллектуальных приложений для сред с ограниченными ресурсами. Независимо от того, разрабатываете ли вы IoT-решения, мобильные AI-приложения или встроенные интеллектуальные системы, обширный набор функций и интегрированный рабочий процесс инструмента поддерживают весь жизненный цикл разработки Edge AI.  

С учетом постоянного развития и активного сообщества (более 1.8k звезд на GitHub) AI Toolkit остается на переднем крае инструментов разработки AI, постоянно адаптируясь к потребностям современных разработчиков AI, работающих над сценариями развертывания на периферии.  

[Next Foundry Local](./foundrylocal.md)  

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.