<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ab6b3d55f53ea3d498b3c067b17f8816",
  "translation_date": "2025-09-17T18:21:19+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "ru"
}
-->
# AI Toolkit для Visual Studio Code - Руководство по разработке Edge AI

## Введение

Добро пожаловать в подробное руководство по использованию AI Toolkit для Visual Studio Code в разработке Edge AI. По мере того как искусственный интеллект переходит от централизованных облачных вычислений к распределённым устройствам на периферии, разработчикам требуются мощные интегрированные инструменты, способные справляться с уникальными вызовами развертывания на периферии — от ограничений ресурсов до требований к работе в автономном режиме.

AI Toolkit для Visual Studio Code устраняет этот разрыв, предоставляя полноценную среду разработки, специально предназначенную для создания, тестирования и оптимизации AI-приложений, которые эффективно работают на периферийных устройствах. Независимо от того, разрабатываете ли вы для IoT-сенсоров, мобильных устройств, встроенных систем или серверов на периферии, этот набор инструментов упрощает весь процесс разработки в привычной среде VS Code.

Это руководство проведет вас через ключевые концепции, инструменты и лучшие практики использования AI Toolkit в ваших проектах Edge AI — от выбора модели до развертывания в продакшене.

## Обзор

AI Toolkit предоставляет интегрированную среду разработки для полного жизненного цикла приложений Edge AI в рамках VS Code. Он обеспечивает бесшовную интеграцию с популярными AI-моделями от таких провайдеров, как OpenAI, Anthropic, Google и GitHub, а также поддерживает локальное развертывание моделей через ONNX и Ollama — важные функции для приложений Edge AI, требующих выполнения на устройстве.

Что отличает AI Toolkit для разработки Edge AI, так это его ориентация на весь процесс развертывания на периферии. В отличие от традиционных инструментов разработки AI, которые в основном ориентированы на облачные развертывания, AI Toolkit включает специализированные функции для оптимизации моделей, тестирования в условиях ограниченных ресурсов и оценки производительности, специфичной для периферии. Набор инструментов учитывает, что разработка Edge AI требует других подходов — меньших размеров моделей, более быстрого времени выполнения, автономной работы и оптимизации под конкретное оборудование.

Платформа поддерживает различные сценарии развертывания — от простого выполнения на устройстве до сложных архитектур с несколькими моделями на периферии. Она предоставляет инструменты для конверсии моделей, квантования и оптимизации, которые необходимы для успешного развертывания на периферии, сохраняя при этом продуктивность разработчика, которой славится VS Code.

## Цели обучения

К концу этого руководства вы сможете:

### Основные навыки
- **Установить и настроить** AI Toolkit для Visual Studio Code для рабочих процессов разработки Edge AI
- **Ориентироваться и использовать** интерфейс AI Toolkit, включая Model Catalog, Playground и Agent Builder
- **Выбирать и оценивать** AI-модели, подходящие для развертывания на периферии, с учетом производительности и ограничений ресурсов
- **Конвертировать и оптимизировать** модели с использованием формата ONNX и техник квантования для периферийных устройств

### Навыки разработки Edge AI
- **Проектировать и реализовывать** приложения Edge AI с использованием интегрированной среды разработки
- **Проводить тестирование моделей** в условиях, приближенных к периферийным, с использованием локального выполнения и мониторинга ресурсов
- **Создавать и настраивать** AI-агентов, оптимизированных для сценариев развертывания на периферии
- **Оценивать производительность моделей** с использованием метрик, релевантных для периферийных вычислений (задержка, использование памяти, точность)

### Оптимизация и развертывание
- **Применять техники квантования и обрезки** для уменьшения размера модели при сохранении приемлемой производительности
- **Оптимизировать модели** для конкретных периферийных аппаратных платформ, включая ускорение на CPU, GPU и NPU
- **Реализовывать лучшие практики** разработки Edge AI, включая управление ресурсами и стратегии резервирования
- **Готовить модели и приложения** к развертыванию в продакшене на периферийных устройствах

### Продвинутые концепции Edge AI
- **Интегрировать с периферийными AI-фреймворками**, включая ONNX Runtime, Windows ML и TensorFlow Lite
- **Реализовывать архитектуры с несколькими моделями** и сценарии федеративного обучения для периферийных сред
- **Устранять распространенные проблемы Edge AI**, включая ограничения памяти, скорость выполнения и совместимость оборудования
- **Проектировать стратегии мониторинга и логирования** для приложений Edge AI в продакшене

### Практическое применение
- **Создавать комплексные решения Edge AI** от выбора модели до развертывания
- **Демонстрировать владение** рабочими процессами разработки и техниками оптимизации, специфичными для периферии
- **Применять изученные концепции** к реальным сценариям использования Edge AI, включая IoT, мобильные и встроенные приложения
- **Оценивать и сравнивать** различные стратегии развертывания Edge AI и их компромиссы

## Основные функции для разработки Edge AI

### 1. Каталог моделей и их поиск
- **Поддержка локальных моделей**: Открывайте и используйте AI-модели, специально оптимизированные для развертывания на периферии
- **Интеграция с ONNX**: Доступ к моделям в формате ONNX для эффективного выполнения на периферии
- **Поддержка Ollama**: Используйте локально работающие модели через Ollama для обеспечения конфиденциальности и автономной работы
- **Сравнение моделей**: Сравнивайте модели бок о бок, чтобы найти оптимальный баланс между производительностью и потреблением ресурсов для периферийных устройств

### 2. Интерактивная площадка (Playground)
- **Локальная среда тестирования**: Тестируйте модели локально перед развертыванием на периферии
- **Мультимодальные эксперименты**: Тестируйте с изображениями, текстом и другими типичными для периферии входными данными
- **Настройка параметров**: Экспериментируйте с различными параметрами модели для оптимизации под ограничения периферии
- **Мониторинг производительности в реальном времени**: Наблюдайте за скоростью выполнения и использованием ресурсов во время разработки

### 3. Конструктор агентов для приложений на периферии
- **Инженерия подсказок**: Создавайте оптимизированные подсказки, которые эффективно работают с меньшими моделями на периферии
- **Интеграция MCP Tool**: Встраивайте инструменты Model Context Protocol для расширенных возможностей агентов на периферии
- **Генерация кода**: Создавайте готовый к продакшену код, оптимизированный для сценариев развертывания на периферии
- **Структурированные выходные данные**: Проектируйте агентов, которые предоставляют последовательные, структурированные ответы, подходящие для приложений на периферии

### 4. Оценка и тестирование моделей
- **Метрики производительности**: Оценивайте модели с использованием метрик, релевантных для развертывания на периферии (задержка, использование памяти, точность)
- **Пакетное тестирование**: Тестируйте несколько конфигураций моделей одновременно, чтобы найти оптимальные настройки для периферии
- **Пользовательская оценка**: Создавайте критерии оценки, специфичные для сценариев использования Edge AI
- **Профилирование ресурсов**: Анализируйте требования к памяти и вычислительным ресурсам для планирования развертывания на периферии

### 5. Конверсия и оптимизация моделей
- **Конверсия в ONNX**: Конвертируйте модели из различных форматов в ONNX для совместимости с периферией
- **Квантование**: Уменьшайте размер модели и улучшайте скорость выполнения с помощью техник квантования
- **Оптимизация под оборудование**: Оптимизируйте модели для конкретного периферийного оборудования (CPU, GPU, NPU)
- **Трансформация форматов**: Преобразуйте модели из Hugging Face и других источников для развертывания на периферии

### 6. Тонкая настройка для сценариев на периферии
- **Адаптация к домену**: Настраивайте модели для конкретных сценариев использования и условий на периферии
- **Локальное обучение**: Обучайте модели локально с поддержкой GPU для специфических требований периферии
- **Интеграция с Azure**: Используйте Azure Container Apps для облачной тонкой настройки перед развертыванием на периферии
- **Трансферное обучение**: Адаптируйте предварительно обученные модели для задач и ограничений, специфичных для периферии

### 7. Мониторинг производительности и трассировка
- **Анализ производительности на периферии**: Мониторьте производительность моделей в условиях, приближенных к периферийным
- **Сбор трассировки**: Собирайте подробные данные о производительности для оптимизации
- **Идентификация узких мест**: Определяйте проблемы производительности перед развертыванием на периферийных устройствах
- **Отслеживание использования ресурсов**: Мониторьте память, CPU и время выполнения для оптимизации на периферии

## Рабочий процесс разработки Edge AI

### Фаза 1: Поиск и выбор модели
1. **Изучите каталог моделей**: Используйте каталог моделей для поиска подходящих для развертывания на периферии
2. **Сравните производительность**: Оценивайте модели по размеру, точности и скорости выполнения
3. **Тестируйте локально**: Используйте модели Ollama или ONNX для локального тестирования перед развертыванием
4. **Оцените требования к ресурсам**: Определите потребности в памяти и вычислительных ресурсах для целевых периферийных устройств

### Фаза 2: Оптимизация модели
1. **Конвертируйте в ONNX**: Конвертируйте выбранные модели в формат ONNX для совместимости с периферией
2. **Примените квантование**: Уменьшите размер модели с помощью квантования INT8 или INT4
3. **Оптимизация под оборудование**: Оптимизируйте для целевого периферийного оборудования (ARM, x86, специализированные ускорители)
4. **Валидация производительности**: Убедитесь, что оптимизированные модели сохраняют приемлемую точность

### Фаза 3: Разработка приложений
1. **Проектирование агентов**: Используйте Agent Builder для создания AI-агентов, оптимизированных для периферии
2. **Инженерия подсказок**: Разрабатывайте подсказки, которые эффективно работают с меньшими моделями
3. **Тестирование интеграции**: Тестируйте агентов в условиях, симулирующих периферийные
4. **Генерация кода**: Создавайте готовый к продакшену код, оптимизированный для развертывания на периферии

### Фаза 4: Оценка и тестирование
1. **Пакетная оценка**: Тестируйте несколько конфигураций для поиска оптимальных настроек
2. **Профилирование производительности**: Анализируйте скорость выполнения, использование памяти и точность
3. **Симуляция периферии**: Тестируйте в условиях, похожих на целевую среду развертывания
4. **Стресс-тестирование**: Оценивайте производительность при различных нагрузках

### Фаза 5: Подготовка к развертыванию
1. **Финальная оптимизация**: Примените финальные оптимизации на основе результатов тестирования
2. **Упаковка для развертывания**: Упакуйте модели и код для развертывания на периферии
3. **Документация**: Задокументируйте требования к развертыванию и конфигурации
4. **Настройка мониторинга**: Подготовьте мониторинг и логирование для продакшена

## Целевая аудитория для разработки Edge AI

### Разработчики Edge AI
- Разработчики приложений, создающие устройства на периферии с поддержкой AI и IoT-решения
- Разработчики встроенных систем, интегрирующие AI в устройства с ограниченными ресурсами
- Мобильные разработчики, создающие AI-приложения для смартфонов и планшетов

### Инженеры Edge AI
- Инженеры AI, оптимизирующие модели для развертывания на периферии и управляющие конвейерами выполнения
- DevOps-инженеры, развертывающие и управляющие AI-моделями в распределённой инфраструктуре периферии
- Инженеры производительности, оптимизирующие AI-нагрузки для ограничений периферийного оборудования

### Исследователи и преподаватели
- Исследователи AI, разрабатывающие эффективные модели и алгоритмы для периферийных вычислений
- Преподаватели, обучающие концепциям Edge AI и демонстрирующие техники оптимизации
- Студенты, изучающие вызовы и решения в развертывании Edge AI

## Сценарии использования Edge AI

### Умные IoT-устройства
- **Распознавание изображений в реальном времени**: Развертывание моделей компьютерного зрения на IoT-камерах и сенсорах
- **Обработка голоса**: Реализация распознавания речи и обработки естественного языка на умных колонках
- **Предиктивное обслуживание**: Запуск моделей обнаружения аномалий на промышленных периферийных устройствах
- **Мониторинг окружающей среды**: Развертывание моделей анализа данных сенсоров для экологических приложений

### Мобильные и встроенные приложения
- **Перевод на устройстве**: Реализация моделей перевода, работающих в автономном режиме
- **Дополненная реальность**: Развертывание моделей распознавания и отслеживания объектов в реальном времени для AR-приложений
- **Мониторинг здоровья**: Запуск моделей анализа здоровья на носимых устройствах и медицинском оборудовании
- **Автономные системы**: Реализация моделей принятия решений для дронов, роботов и транспортных средств

### Инфраструктура периферийных вычислений
- **ЦОДы на периферии**: Развертывание AI-моделей в периферийных центрах обработки данных для приложений с низкой задержкой
- **Интеграция с CDN**: Встраивание возможностей AI-обработки в сети доставки контента
- **5G Edge**: Использование периферийных вычислений 5G для приложений с поддержкой AI
- **Туманные вычисления**: Реализация AI-обработки в средах туманных вычислений

## Установка и настройка

### Быстрая установка
Установите расширение AI Toolkit напрямую из Visual Studio Code Marketplace:

```
Install: AI Toolkit for Visual Studio Code (ms-windows-ai-studio.windows-ai-studio)
```

### Предварительные требования для разработки Edge AI
- **ONNX Runtime**: Установите ONNX Runtime для выполнения моделей
- **Ollama** (опционально): Установите Ollama для локального обслуживания моделей
- **Среда Python**: Настройте Python с необходимыми библиотеками AI
- **Инструменты для периферийного оборудования**: Установите инструменты разработки, специфичные для оборудования (CUDA, OpenVINO и др.)

### Первоначальная настройка
1. Откройте VS Code и установите расширение AI Toolkit
2. Настройте источники моделей (ONNX, Ollama, облачные провайдеры)
3. Настройте локальную среду разработки для тестирования на периферии
4. Настройте параметры аппаратного ускорения для вашей машины разработки

## Начало работы с разработкой Edge AI

### Шаг 1: Выбор модели
1. Откройте представление AI Toolkit в панели активности
2. Просмотрите каталог моделей для совместимых с периферией моделей
3. Отфильтруйте по размеру модели, формату (ONNX) и характеристикам производительности
4. Сравните модели с помощью встроенных инструментов сравнения

### Шаг 2: Локальное тестирование
1. Используйте Playground для локального тестирования выбранных моделей
2. Экспериментируйте с различными подсказками и параметрами
3. Мониторьте метрики производительности во время тестирования
4. Оценивайте ответы моделей на соответствие требованиям сценариев использования на периферии

### Шаг 3: Оптимизация модели
1. Используйте инструменты конверсии моделей для оптимизации развертывания на периферии
2. Примените квантование для уменьшения размера модели
3. Тестируйте оптимизированные модели для обеспечения приемлемой производительности
4. Документируйте настройки оптимизации и компромиссы производительности

### Шаг 4: Разработка агентов
1. Используйте Agent Builder для создания AI-агентов, оптимизированных для периферии
2. Разрабатывайте подсказки, которые эффективно работают с меньшими моделями
3. Интегрируйте необходимые инструменты и API для сценариев на периферии
4. Тестируйте агентов в условиях, симулирующих периферийные

### Шаг 5: Оценка и развертывание
1. Используйте пакетную оценку для тестирования нескольких конфигураций
2. Профилируйте производительность в различных условиях
3. Подготовьте пакеты для развертывания на целевых периферийных устройствах
4. Настройте мониторинг и логирование для продакшена

## Лучшие практики разработки Edge AI

### Выбор модели
- **Ограничения по размеру**: Выбирайте модели, которые соответствуют ограничениям памяти
- **Безопасность**: Реализуйте соответствующие меры безопасности для приложений Edge AI

## Интеграция с фреймворками Edge AI

### ONNX Runtime
- **Кроссплатформенная разработка**: Развёртывание моделей ONNX на различных edge-платформах
- **Оптимизация оборудования**: Используйте аппаратно-специфические оптимизации ONNX Runtime
- **Поддержка мобильных устройств**: Применяйте ONNX Runtime Mobile для приложений на смартфонах и планшетах
- **Интеграция с IoT**: Развёртывание на IoT-устройствах с использованием лёгких дистрибутивов ONNX Runtime

### Windows ML
- **Устройства на Windows**: Оптимизация для edge-устройств и ПК на базе Windows
- **Ускорение с помощью NPU**: Используйте нейронные процессоры на устройствах Windows
- **DirectML**: Применяйте DirectML для ускорения работы на GPU в Windows
- **Интеграция с UWP**: Встраивайте в приложения на платформе Universal Windows Platform

### TensorFlow Lite
- **Оптимизация для мобильных устройств**: Развёртывание моделей TensorFlow Lite на мобильных и встроенных устройствах
- **Аппаратные делегаты**: Используйте специализированные аппаратные делегаты для ускорения
- **Микроконтроллеры**: Развёртывание на микроконтроллерах с помощью TensorFlow Lite Micro
- **Кроссплатформенная поддержка**: Развёртывание на Android, iOS и встроенных системах Linux

### Azure IoT Edge
- **Гибрид облако-устройство**: Объединение обучения в облаке с выводом на edge-устройствах
- **Развёртывание модулей**: Развёртывание моделей AI в виде модулей IoT Edge
- **Управление устройствами**: Удалённое управление edge-устройствами и обновлениями моделей
- **Телеметрия**: Сбор данных о производительности и метрик моделей с edge-устройств

## Расширенные сценарии Edge AI

### Развёртывание нескольких моделей
- **Ансамбли моделей**: Развёртывание нескольких моделей для повышения точности или надёжности
- **A/B тестирование**: Одновременное тестирование различных моделей на edge-устройствах
- **Динамический выбор**: Выбор моделей на основе текущих условий устройства
- **Общий доступ к ресурсам**: Оптимизация использования ресурсов между несколькими моделями

### Федеративное обучение
- **Распределённое обучение**: Обучение моделей на нескольких edge-устройствах
- **Сохранение конфиденциальности**: Хранение данных обучения локально при обмене улучшениями моделей
- **Совместное обучение**: Обеспечение обучения устройств на основе коллективного опыта
- **Координация edge-облако**: Координация обучения между edge-устройствами и облачной инфраструктурой

### Обработка в реальном времени
- **Обработка потоков**: Обработка непрерывных потоков данных на edge-устройствах
- **Низкая задержка вывода**: Оптимизация для минимальной задержки вывода
- **Пакетная обработка**: Эффективная обработка пакетов данных на edge-устройствах
- **Адаптивная обработка**: Настройка обработки в зависимости от текущих возможностей устройства

## Устранение неполадок в разработке Edge AI

### Распространённые проблемы
- **Ограничения памяти**: Модель слишком большая для памяти целевого устройства
- **Скорость вывода**: Вывод модели слишком медленный для требований реального времени
- **Снижение точности**: Оптимизация приводит к недопустимому снижению точности модели
- **Совместимость оборудования**: Модель несовместима с целевым оборудованием

### Стратегии отладки
- **Профилирование производительности**: Используйте функции трассировки AI Toolkit для выявления узких мест
- **Мониторинг ресурсов**: Отслеживайте использование памяти и процессора в процессе разработки
- **Пошаговое тестирование**: Тестируйте оптимизации поэтапно для изоляции проблем
- **Симуляция оборудования**: Используйте инструменты разработки для симуляции целевого оборудования

### Решения для оптимизации
- **Дополнительная квантизация**: Применяйте более агрессивные методы квантизации
- **Архитектура модели**: Рассмотрите альтернативные архитектуры моделей, оптимизированные для edge
- **Оптимизация предварительной обработки**: Оптимизируйте предварительную обработку данных для ограничений edge
- **Оптимизация вывода**: Используйте аппаратно-специфические оптимизации вывода

## Ресурсы и дальнейшие шаги

### Документация
- [Руководство по моделям AI Toolkit](https://code.visualstudio.com/docs/intelligentapps/models)
- [Документация Model Playground](https://code.visualstudio.com/docs/intelligentapps/playground)
- [Документация ONNX Runtime](https://onnxruntime.ai/)
- [Документация Windows ML](https://docs.microsoft.com/en-us/windows/ai/)

### Сообщество и поддержка
- [GitHub AI Toolkit для VS Code](https://github.com/microsoft/vscode-ai-toolkit)
- [Сообщество ONNX](https://github.com/onnx/onnx)
- [Сообщество разработчиков Edge AI](https://docs.microsoft.com/en-us/azure/iot-edge/community)
- [Marketplace расширений VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### Учебные материалы
- [Курс основ Edge AI](./Module01/README.md)
- [Руководство по небольшим языковым моделям](./Module02/README.md)
- [Стратегии развёртывания Edge](./Module03/README.md)
- [Разработка Edge AI для Windows](./windowdeveloper.md)

## Заключение

AI Toolkit для Visual Studio Code предоставляет комплексную платформу для разработки Edge AI, начиная с поиска и оптимизации моделей и заканчивая их развёртыванием и мониторингом. Используя интегрированные инструменты и рабочие процессы, разработчики могут эффективно создавать, тестировать и развёртывать AI-приложения, которые работают на устройствах с ограниченными ресурсами.

Поддержка ONNX, Ollama и различных облачных провайдеров, в сочетании с возможностями оптимизации и оценки, делает AI Toolkit идеальным выбором для разработки Edge AI. Независимо от того, создаёте ли вы IoT-приложения, функции AI для мобильных устройств или встроенные интеллектуальные системы, AI Toolkit предоставляет необходимые инструменты и рабочие процессы для успешного развёртывания Edge AI.

По мере развития Edge AI, AI Toolkit для VS Code остаётся на передовой, предоставляя разработчикам передовые инструменты и возможности для создания приложений нового поколения с интеллектуальными функциями на edge-устройствах.

---

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.