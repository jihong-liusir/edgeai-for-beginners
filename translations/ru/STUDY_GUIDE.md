<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T13:54:26+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ru"
}
-->
# EdgeAI для начинающих: учебные пути и расписание занятий

### Интенсивный учебный путь (1 неделя)

| День | Тематика | Оценочное время |
|------|----------|-----------------|
| День 1 | Модуль 1: Основы EdgeAI | 3 часа |
| День 2 | Модуль 2: Основы SLM | 3 часа |
| День 3 | Модуль 3: Развертывание SLM | 2 часа |
| День 4-5 | Модуль 4: Оптимизация моделей (6 фреймворков) | 4 часа |
| День 6 | Модуль 5: SLMOps | 3 часа |
| День 7 | Модули 6-7: AI-агенты и инструменты разработки | 5 часов |

### Интенсивный учебный путь (2 недели)

| День | Тематика | Оценочное время |
|------|----------|-----------------|
| День 1-2 | Модуль 1: Основы EdgeAI | 3 часа |
| День 3-4 | Модуль 2: Основы SLM | 3 часа |
| День 5-6 | Модуль 3: Развертывание SLM | 2 часа |
| День 7-8 | Модуль 4: Оптимизация моделей | 4 часа |
| День 9-10 | Модуль 5: SLMOps | 3 часа |
| День 11-12 | Модуль 6: AI-агенты | 2 часа |
| День 13-14 | Модуль 7: Инструменты разработки | 3 часа |

### Частичная занятость (4 недели)

| Неделя | Тематика | Оценочное время |
|--------|----------|-----------------|
| Неделя 1 | Модули 1-2: Основы и SLM | 6 часов |
| Неделя 2 | Модули 3-4: Развертывание и оптимизация | 6 часов |
| Неделя 3 | Модули 5-6: SLMOps и AI-агенты | 5 часов |
| Неделя 4 | Модуль 7: Инструменты разработки и интеграция | 3 часа |

| День | Тематика | Оценочное время |
|------|----------|-----------------|
| День 1-2 | Модуль 1: Основы EdgeAI | 3 часа |
| День 3-4 | Модуль 2: Основы SLM | 3 часа |
| День 5-6 | Модуль 3: Развертывание SLM | 2 часа |
| День 7-8 | Модуль 4: Оптимизация моделей | 4 часа |
| День 9-10 | Модуль 5: SLMOps | 3 часа |
| День 11-12 | Модуль 6: Агентные системы SLM | 2 часа |
| День 13-14 | Модуль 7: Примеры реализации EdgeAI | 2 часа |

| Модуль | Дата завершения | Затраченное время | Основные выводы |
|--------|-----------------|-------------------|-----------------|
| Модуль 1: Основы EdgeAI | | | |
| Модуль 2: Основы SLM | | | |
| Модуль 3: Развертывание SLM | | | |
| Модуль 4: Оптимизация моделей (6 фреймворков) | | | |
| Модуль 5: SLMOps | | | |
| Модуль 6: Агентные системы SLM | | | |
| Модуль 7: Примеры реализации EdgeAI | | | |
| Практические упражнения | | | |
| Мини-проект | | | |

### Частичная занятость (4 недели)

| Неделя | Тематика | Оценочное время |
|--------|----------|-----------------|
| Неделя 1 | Модули 1-2: Основы и SLM | 6 часов |
| Неделя 2 | Модули 3-4: Развертывание и оптимизация | 6 часов |
| Неделя 3 | Модули 5-6: SLMOps и AI-агенты | 5 часов |
| Неделя 4 | Модуль 7: Инструменты разработки и интеграция | 3 часа |

## Введение

Добро пожаловать в учебное пособие "EdgeAI для начинающих"! Этот документ поможет вам эффективно изучить материалы курса и максимально использовать процесс обучения. В нем представлены структурированные учебные пути, рекомендуемые расписания занятий, ключевые концепции и дополнительные ресурсы для углубленного изучения технологий EdgeAI.

Курс рассчитан на 20 часов и предоставляет основные знания о EdgeAI в сжатом формате, что делает его идеальным для занятых профессионалов и студентов, желающих быстро освоить практические навыки в этой перспективной области.

## Обзор курса

Курс состоит из семи комплексных модулей:

1. **Основы EdgeAI и трансформация** — изучение ключевых концепций и технологических изменений
2. **Основы малых языковых моделей (SLM)** — исследование различных семейств SLM и их архитектур
3. **Развертывание малых языковых моделей** — внедрение практических стратегий развертывания
4. **Конвертация форматов моделей и квантизация** — продвинутая оптимизация с использованием 6 фреймворков, включая OpenVINO
5. **SLMOps — управление жизненным циклом малых языковых моделей** — управление производственными процессами и развертыванием
6. **Агентные системы SLM** — AI-агенты, вызов функций и протокол контекста модели
7. **Примеры реализации EdgeAI** — инструментарий AI, разработка для Windows и платформо-специфичные реализации
8. **Microsoft Foundry Local — полный набор инструментов для разработчиков** — локальная разработка с гибридной интеграцией Azure (Модуль 08)

## Как использовать это учебное пособие

- **Постепенное обучение**: Следуйте модулям по порядку для наиболее последовательного изучения
- **Контрольные точки знаний**: Используйте вопросы для самопроверки после каждого раздела
- **Практика**: Выполняйте предложенные упражнения для закрепления теоретических концепций
- **Дополнительные ресурсы**: Изучайте дополнительные материалы по темам, которые вас особенно интересуют

## Рекомендации по расписанию занятий

### Интенсивный учебный путь (1 неделя)

| День | Тематика | Оценочное время |
|------|----------|-----------------|
| День 1-2 | Модуль 1: Основы EdgeAI | 6 часов |
| День 3-4 | Модуль 2: Основы SLM | 8 часов |
| День 5 | Модуль 3: Развертывание SLM | 3 часа |
| День 6 | Модуль 8: Набор инструментов Foundry Local | 3 часа |

### Частичная занятость (3 недели)

| Неделя | Тематика | Оценочное время |
|--------|----------|-----------------|
| Неделя 1 | Модуль 1: Основы EdgeAI | 6-7 часов |
| Неделя 2 | Модуль 2: Основы SLM | 7-8 часов |
| Неделя 3 | Модуль 3: Развертывание SLM (3 ч) + Модуль 8: Набор инструментов Foundry Local (2-3 ч) | 5-6 часов |

## Модуль 1: Основы EdgeAI и трансформация

### Основные цели обучения

- Понять различия между облачным и периферийным AI
- Освоить основные методы оптимизации для сред с ограниченными ресурсами
- Анализировать реальные примеры применения технологий EdgeAI
- Настроить среду разработки для проектов EdgeAI

### Основные области изучения

#### Раздел 1: Основы EdgeAI
- **Приоритетные концепции**: 
  - Парадигмы облачных и периферийных вычислений
  - Методы квантизации моделей
  - Варианты аппаратного ускорения (NPU, GPU, CPU)
  - Преимущества в области конфиденциальности и безопасности

- **Дополнительные материалы**:
  - [Документация TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Документация Edge Impulse](https://docs.edgeimpulse.com)

#### Раздел 2: Реальные примеры
- **Приоритетные концепции**: 
  - Экосистема моделей Microsoft Phi и Mu
  - Практическое применение в различных отраслях
  - Особенности развертывания

#### Раздел 3: Практическое руководство
- **Приоритетные концепции**: 
  - Настройка среды разработки
  - Инструменты квантизации и оптимизации
  - Методы оценки реализации EdgeAI

#### Раздел 4: Аппаратное обеспечение для развертывания
- **Приоритетные концепции**: 
  - Сравнение платформ оборудования
  - Стратегии оптимизации для конкретного оборудования
  - Особенности развертывания

### Вопросы для самопроверки

1. Сравните и сопоставьте облачные и периферийные реализации AI.
2. Объясните три ключевых метода оптимизации моделей для периферийного развертывания.
3. Каковы основные преимущества выполнения AI-моделей на периферии?
4. Опишите процесс квантизации модели и как он влияет на производительность.
5. Объясните, как различные аппаратные ускорители (NPU, GPU, CPU) влияют на развертывание EdgeAI.

### Практические упражнения

1. **Быстрая настройка среды**: Настройте минимальную среду разработки с необходимыми пакетами (30 минут)
2. **Исследование модели**: Скачайте и изучите предварительно обученную малую языковую модель (1 час)
3. **Базовая квантизация**: Попробуйте простую квантизацию небольшой модели (1 час)

## Модуль 2: Основы малых языковых моделей (SLM)

### Основные цели обучения

- Понять архитектурные принципы различных семейств SLM
- Сравнить возможности моделей с разным количеством параметров
- Оценить модели с точки зрения эффективности, возможностей и требований к развертыванию
- Определить подходящие случаи использования для различных семейств моделей

### Основные области изучения

#### Раздел 1: Семейство моделей Microsoft Phi
- **Приоритетные концепции**: 
  - Эволюция философии дизайна
  - Архитектура с приоритетом эффективности
  - Специализированные возможности

#### Раздел 2: Семейство Qwen
- **Приоритетные концепции**: 
  - Вклад в открытый код
  - Масштабируемые варианты развертывания
  - Архитектура для продвинутого рассуждения

#### Раздел 3: Семейство Gemma
- **Приоритетные концепции**: 
  - Инновации, основанные на исследованиях
  - Мультимодальные возможности
  - Оптимизация для мобильных устройств

#### Раздел 4: Семейство BitNET
- **Приоритетные концепции**: 
  - Технология квантизации с точностью 1 бит
  - Фреймворк оптимизации для вывода
  - Устойчивость и экологичность

#### Раздел 5: Модель Microsoft Mu
- **Приоритетные концепции**: 
  - Архитектура с приоритетом устройства
  - Интеграция с Windows
  - Конфиденциальная работа

#### Раздел 6: Phi-Silica
- **Приоритетные концепции**: 
  - Оптимизированная архитектура для NPU
  - Метрики производительности
  - Интеграция для разработчиков

### Вопросы для самопроверки

1. Сравните архитектурные подходы семейств моделей Phi и Qwen.
2. Объясните, чем технология квантизации BitNET отличается от традиционной квантизации.
3. Каковы уникальные преимущества модели Mu для интеграции с Windows?
4. Опишите, как Phi-Silica использует аппаратное обеспечение NPU для оптимизации производительности.
5. Для мобильного приложения с ограниченным подключением, какое семейство моделей будет наиболее подходящим и почему?

### Практические упражнения

1. **Сравнение моделей**: Быстрая оценка двух различных моделей SLM (1 час)
2. **Простая генерация текста**: Базовая реализация генерации текста с использованием малой модели (1 час)
3. **Быстрая оптимизация**: Примените одну технику оптимизации для улучшения скорости вывода (1 час)

## Модуль 3: Развертывание малых языковых моделей

### Основные цели обучения

- Выбирать подходящие модели с учетом ограничений развертывания
- Освоить методы оптимизации для различных сценариев развертывания
- Реализовать SLM как в локальной, так и в облачной среде
- Разрабатывать конфигурации, готовые к производству, для приложений EdgeAI

### Основные области изучения

#### Раздел 1: Продвинутое изучение SLM
- **Приоритетные концепции**: 
  - Классификационная структура параметров
  - Продвинутые методы оптимизации
  - Стратегии получения моделей

#### Раздел 2: Развертывание в локальной среде
- **Приоритетные концепции**: 
  - Платформа Ollama
  - Локальные решения Microsoft Foundry
  - Сравнительный анализ фреймворков

#### Раздел 3: Контейнеризированное развертывание в облаке
- **Приоритетные концепции**: 
  - Высокопроизводительный вывод vLLM
  - Оркестрация контейнеров
  - Реализация ONNX Runtime

### Вопросы для самопроверки

1. Какие факторы следует учитывать при выборе между локальным и облачным развертыванием?
2. Сравните Ollama и Microsoft Foundry Local как варианты развертывания.
3. Объясните преимущества контейнеризации для развертывания SLM.
4. Какие ключевые метрики производительности следует отслеживать для SLM, развернутого на периферии?
5. Опишите полный рабочий процесс развертывания от выбора модели до реализации в производстве.

### Практические упражнения

1. **Базовое локальное развертывание**: Разверните простую SLM с использованием Ollama (1 час)
2. **Проверка производительности**: Проведите быструю оценку производительности развернутой модели (30 минут)
3. **Простая интеграция**: Создайте минимальное приложение, использующее вашу развернутую модель (1 час)

## Модуль 4: Конвертация форматов моделей и квантизация

### Основные цели обучения

- Освоить продвинутые методы квантизации от точности 1 бит до 8 бит
- Понять стратегии конвертации форматов (GGUF, ONNX)
- Реализовать оптимизацию в шести фреймворках (Llama.cpp, Olive, OpenVINO, MLX, синтез рабочих процессов)
- Развернуть оптимизированные модели для производственных периферийных сред на оборудовании Intel, Apple и кросс-платформенных устройствах

### Основные области изучения

#### Раздел 1: Основы квантизации
- **Приоритетные концепции**: 
  - Классификационная структура точности
  - Компромиссы между производительностью и точностью
  - Оптимизация памяти

#### Раздел 2: Реализация Llama.cpp
- **Приоритетные концепции**: 
  - Кросс-платформенное развертывание
  - Оптимизация формата GGUF
  - Техники аппаратного ускорения

#### Раздел 3: Набор инструментов Microsoft Olive
- **Приоритетные концепции**: 
  - Оптимизация с учетом оборудования
  - Развертывание корпоративного уровня
  - Автоматизированные рабочие процессы оптимизации

#### Раздел 4: Набор инструментов OpenVINO
- **Приоритетные концепции**: 
  - Оптимизация для оборудования Intel
  - Фреймворк компрессии нейронных сетей (NNCF)
  - Кросс-платформенное развертывание вывода
  - OpenVINO GenAI для развертывания LLM

#### Раздел 5: Фреймворк Apple MLX
- **Приоритетные концепции**:  
  - Оптимизация для Apple Silicon  
  - Архитектура объединенной памяти  
  - Возможности тонкой настройки LoRA  

#### Раздел 6: Синтез рабочего процесса разработки Edge AI  
- **Приоритетные концепции**:  
  - Архитектура унифицированного рабочего процесса  
  - Деревья решений для выбора фреймворков  
  - Проверка готовности к производству  
  - Стратегии обеспечения долгосрочной актуальности  

### Вопросы для самопроверки  

1. Сравните стратегии квантизации для различных уровней точности (от 1-бит до 8-бит).  
2. Объясните преимущества формата GGUF для развертывания на периферийных устройствах.  
3. Как аппаратно-ориентированная оптимизация в Microsoft Olive повышает эффективность развертывания?  
4. Какие ключевые преимущества OpenVINO NNCF для сжатия моделей?  
5. Опишите, как Apple MLX использует архитектуру объединенной памяти для оптимизации.  
6. Как синтез рабочего процесса помогает в выборе оптимальных фреймворков для оптимизации?  

### Практические задания  

1. **Квантизация модели**: Примените различные уровни квантизации к модели и сравните результаты (1 час).  
2. **Оптимизация с OpenVINO**: Используйте NNCF для сжатия модели для оборудования Intel (1 час).  
3. **Сравнение фреймворков**: Протестируйте одну и ту же модель в трех различных фреймворках оптимизации (1 час).  
4. **Сравнение производительности**: Измерьте влияние оптимизации на скорость вывода и использование памяти (1 час).  

## Модуль 5: SLMOps - Операции с малыми языковыми моделями  

### Основные цели обучения  

- Понять принципы управления жизненным циклом SLMOps  
- Освоить методы дистилляции и тонкой настройки для развертывания на периферии  
- Реализовать стратегии развертывания с мониторингом в производственной среде  
- Построить рабочие процессы для корпоративного уровня эксплуатации и обслуживания SLM  

### Основные области изучения  

#### Раздел 1: Введение в SLMOps  
- **Приоритетные концепции**:  
  - Парадигма SLMOps в операциях с ИИ  
  - Архитектура с приоритетом на экономичность и конфиденциальность  
  - Стратегическое влияние на бизнес и конкурентные преимущества  

#### Раздел 2: Дистилляция моделей  
- **Приоритетные концепции**:  
  - Техники передачи знаний  
  - Реализация двухэтапного процесса дистилляции  
  - Рабочие процессы дистилляции в Azure ML  

#### Раздел 3: Стратегии тонкой настройки  
- **Приоритетные концепции**:  
  - Эффективная по параметрам тонкая настройка (PEFT)  
  - Продвинутые методы LoRA и QLoRA  
  - Многоадаптерное обучение и оптимизация гиперпараметров  

#### Раздел 4: Развертывание в производственной среде  
- **Приоритетные концепции**:  
  - Конвертация и квантизация моделей для производства  
  - Конфигурация локального развертывания Foundry  
  - Бенчмаркинг производительности и проверка качества  

### Вопросы для самопроверки  

1. Чем SLMOps отличается от традиционного MLOps?  
2. Объясните преимущества дистилляции моделей для развертывания на периферии.  
3. Какие ключевые аспекты нужно учитывать при тонкой настройке SLM в условиях ограниченных ресурсов?  
4. Опишите полный конвейер развертывания для приложений Edge AI.  

### Практические задания  

1. **Базовая дистилляция**: Создайте меньшую модель на основе более крупной модели-учителя (1 час).  
2. **Эксперимент по тонкой настройке**: Настройте модель для конкретной области (1 час).  
3. **Конвейер развертывания**: Настройте базовый CI/CD конвейер для развертывания модели (1 час).  

## Модуль 6: Агентные системы SLM - ИИ-агенты и вызов функций  

### Основные цели обучения  

- Создавать интеллектуальных ИИ-агентов для периферийных сред с использованием малых языковых моделей  
- Реализовывать возможности вызова функций с систематическими рабочими процессами  
- Освоить интеграцию Model Context Protocol (MCP) для стандартизированного взаимодействия с инструментами  
- Создавать сложные агентные системы с минимальным вмешательством человека  

### Основные области изучения  

#### Раздел 1: ИИ-агенты и основы SLM  
- **Приоритетные концепции**:  
  - Классификация агентов (рефлекторные, модельные, целевые, обучающиеся агенты)  
  - Анализ компромиссов между SLM и LLM  
  - Шаблоны проектирования агентов для периферийных устройств  
  - Оптимизация ресурсов для агентов  

#### Раздел 2: Вызов функций в малых языковых моделях  
- **Приоритетные концепции**:  
  - Реализация систематического рабочего процесса (определение намерений, вывод JSON, внешнее выполнение)  
  - Реализация для конкретных платформ (Phi-4-mini, выбранные модели Qwen, Microsoft Foundry Local)  
  - Продвинутые примеры (сотрудничество агентов, динамический выбор инструментов)  
  - Производственные аспекты (ограничение скорости, аудит логов, меры безопасности)  

#### Раздел 3: Интеграция Model Context Protocol (MCP)  
- **Приоритетные концепции**:  
  - Архитектура протокола и многослойный системный дизайн  
  - Поддержка нескольких бэкендов (Ollama для разработки, vLLM для производства)  
  - Протоколы подключения (режимы STDIO и SSE)  
  - Применение в реальных задачах (автоматизация веба, обработка данных, интеграция API)  

### Вопросы для самопроверки  

1. Какие ключевые архитектурные аспекты нужно учитывать при создании агентов для Edge AI?  
2. Как вызов функций расширяет возможности агентов?  
3. Объясните роль Model Context Protocol в коммуникации агентов.  

### Практические задания  

1. **Простой агент**: Создайте базового ИИ-агента с возможностью вызова функций (1 час).  
2. **Интеграция MCP**: Реализуйте MCP в приложении агента (30 минут).  

## Модуль 7: Примеры реализации EdgeAI  

### Основные цели обучения  

- Освоить AI Toolkit для Visual Studio Code для комплексных рабочих процессов разработки EdgeAI  
- Получить опыт работы с платформой Windows AI Foundry и стратегиями оптимизации NPU  
- Реализовать EdgeAI на различных аппаратных платформах и сценариях развертывания  
- Создавать готовые к производству приложения EdgeAI с платформенными оптимизациями  

### Основные области изучения  

#### Раздел 1: AI Toolkit для Visual Studio Code  
- **Приоритетные концепции**:  
  - Комплексная среда разработки Edge AI в VS Code  
  - Каталог моделей и их поиск для развертывания на периферии  
  - Локальное тестирование, оптимизация и разработка агентов  
  - Мониторинг производительности и оценка для периферийных сценариев  

#### Раздел 2: Руководство по разработке Windows EdgeAI  
- **Приоритетные концепции**:  
  - Полный обзор платформы Windows AI Foundry  
  - API Phi Silica для эффективного вывода на NPU  
  - API компьютерного зрения для обработки изображений и OCR  
  - CLI Foundry Local для локальной разработки и тестирования  

#### Раздел 3: Реализация для конкретных платформ  
- **Приоритетные концепции**:  
  - Развертывание на NVIDIA Jetson Orin Nano (67 TOPS AI производительности)  
  - Мобильные приложения с .NET MAUI и ONNX Runtime GenAI  
  - Решения Azure EdgeAI с гибридной архитектурой облако-периферия  
  - Оптимизация Windows ML с универсальной поддержкой оборудования  
  - Приложения Foundry Local с конфиденциальной реализацией RAG  

### Вопросы для самопроверки  

1. Как AI Toolkit упрощает рабочий процесс разработки EdgeAI?  
2. Сравните стратегии развертывания на различных аппаратных платформах.  
3. Какие преимущества предоставляет Windows AI Foundry для разработки на периферии?  
4. Объясните роль оптимизации NPU в современных приложениях Edge AI.  
5. Как API Phi Silica использует аппаратное обеспечение NPU для оптимизации производительности?  
6. Сравните преимущества локального и облачного развертывания для приложений, чувствительных к конфиденциальности.  

### Практические задания  

1. **Настройка AI Toolkit**: Настройте AI Toolkit и оптимизируйте модель (1 час).  
2. **Windows AI Foundry**: Создайте простое приложение Windows AI с использованием API Phi Silica (1 час).  
3. **Кроссплатформенное развертывание**: Разверните одну и ту же модель на двух разных платформах (1 час).  
4. **Оптимизация NPU**: Протестируйте производительность NPU с инструментами Windows AI Foundry (30 минут).  

## Модуль 8: Microsoft Foundry Local – Полный набор инструментов для разработчиков  

### Основные цели обучения  

- Установить и настроить Foundry Local на Windows  
- Запускать, находить и управлять моделями локально через Foundry CLI  
- Интегрироваться с клиентами REST и SDK, совместимыми с OpenAI  
- Создавать практические примеры: чат Chainlit, агенты и маршрутизатор моделей  
- Понять гибридные паттерны с Azure AI Foundry  

### Основные области изучения  

- Установка и основы CLI (модели, сервисы, кэш)  
- Интеграция SDK (клиенты, совместимые с OpenAI, и Azure OpenAI)  
- Быстрая проверка через Open WebUI  
- Паттерны агентов и вызова функций  
- Модели как инструменты (дизайн маршрутизатора и реестра)  

### Вопросы для самопроверки  

1. Как найти локальную конечную точку и список доступных моделей?  
2. В чем различия между использованием Foundry Local REST и Azure OpenAI?  
3. Как вы бы спроектировали простой маршрутизатор для выбора моделей как инструментов?  
4. Какие категории CLI наиболее актуальны для повседневной разработки?  
5. Как проверить готовность Foundry Local перед запуском приложений?  

### Практические задания  

1. Установите/обновите Foundry Local и запустите `phi-4-mini` локально (30 минут).  
2. Вызовите `/v1/models` и выполните простой чат через REST (30 минут).  
3. Запустите пример приложения Chainlit и выполните локальный чат (30 минут).  
4. Запустите координатор мультиагентов и проанализируйте результаты (30 минут).  
5. Попробуйте маршрутизатор моделей как инструментов с переопределениями на основе окружения (30 минут).  

## Руководство по распределению времени  

Чтобы максимально эффективно использовать 20-часовой курс, предлагаем следующий план распределения времени:  

| Деятельность | Распределение времени | Описание |  
|--------------|-----------------------|----------|  
| Чтение основных материалов | 9 часов | Изучение ключевых концепций каждого модуля |  
| Практические задания | 6 часов | Практическая реализация ключевых техник |  
| Самопроверка | 2 часа | Проверка понимания через вопросы и размышления |  
| Мини-проект | 3 часа | Применение знаний в небольшой практической реализации |  

### Основные области фокуса при ограничении времени  

**Если у вас есть только 10 часов:**  
- Завершите модули 1, 2 и 3 (основные концепции EdgeAI).  
- Выполните хотя бы одно практическое задание из каждого модуля.  
- Сосредоточьтесь на понимании ключевых концепций, а не на деталях реализации.  

**Если вы можете посвятить полные 20 часов:**  
- Завершите все семь модулей.  
- Выполните ключевые практические задания из каждого модуля.  
- Завершите один мини-проект из модуля 7.  
- Изучите как минимум 2-3 дополнительных ресурса.  

**Если у вас есть больше 20 часов:**  
- Завершите все модули с детальными заданиями.  
- Реализуйте несколько мини-проектов.  
- Изучите продвинутые техники оптимизации из модуля 4.  
- Реализуйте развертывание в производственной среде из модуля 5.  

## Основные ресурсы  

Эти тщательно отобранные ресурсы предоставляют максимальную ценность для вашего ограниченного времени на обучение:  

### Обязательная документация для изучения  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Самый эффективный инструмент оптимизации моделей  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Самый быстрый способ локального развертывания SLM  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Справочник по ведущей модели, оптимизированной для периферии  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Комплексный набор инструментов оптимизации от Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Интегрированная среда разработки EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Платформа разработки EdgeAI для Windows  

### Инструменты для экономии времени  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Быстрый доступ к моделям и их развертывание  
- [Gradio](https://www.gradio.app/docs/interface) - Быстрая разработка пользовательских интерфейсов для демонстрации ИИ  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Упрощенная оптимизация моделей  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Эффективный вывод на CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Фреймворк для сжатия нейронных сетей  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Набор инструментов для развертывания больших языковых моделей  

## Шаблон для отслеживания прогресса  

Используйте этот упрощенный шаблон для отслеживания вашего прогресса в 20-часовом курсе:  

| Модуль | Дата завершения | Потраченное время | Основные выводы |  
|--------|-----------------|-------------------|-----------------|  
| Модуль 1: Основы EdgeAI | | | |  
| Модуль 2: Основы SLM | | | |  
| Модуль 3: Развертывание SLM | | | |  
| Модуль 4: Оптимизация моделей | | | |  
| Модуль 5: SLMOps | | | |  
| Модуль 6: ИИ-агенты | | | |  
| Модуль 7: Инструменты разработки | | | |  
| Модуль 8: Набор инструментов Foundry Local | | | |  
| Практические задания | | | |  
| Мини-проект | | | |  

## Идеи мини-проектов  

Рассмотрите возможность выполнения одного из этих проектов для практики концепций EdgeAI (каждый рассчитан на 2-4 часа):  

### Проекты для начинающих (2-3 часа каждый)  
1. **Текстовый помощник на периферии**: Создайте простой инструмент для оффлайн-дополнения текста с использованием малой языковой модели.  
2. **Панель сравнения моделей**: Постройте базовую визуализацию метрик производительности для различных SLM.  
3. **Эксперимент по оптимизации**: Измерьте влияние различных уровней квантизации на одну и ту же базовую модель.  

### Проекты среднего уровня (3-4 часа каждый)  
4. **Рабочий процесс AI Toolkit**: Используйте AI Toolkit в VS Code для оптимизации и развертывания модели от начала до конца.  
5. **Приложение Windows AI Foundry**: Создайте приложение для Windows с использованием API Phi Silica и оптимизации NPU.  
6. **Кроссплатформенное развертывание**: Разверните одну и ту же оптимизированную модель на Windows (OpenVINO) и мобильных устройствах (.NET MAUI).  
7. **Агент с вызовом функций**: Создайте ИИ-агента с возможностями вызова функций для периферийных сценариев.  

### Проекты для продвинутой интеграции (4-5 часов каждый)  
8. **Пайплайн оптимизации OpenVINO**: Реализуйте полный процесс оптимизации модели с использованием NNCF и GenAI toolkit  
9. **Пайплайн SLMOps**: Реализуйте полный жизненный цикл модели от обучения до развертывания на устройствах  
10. **Система с несколькими моделями на краевых устройствах**: Разверните несколько специализированных моделей, работающих совместно на краевом оборудовании  
11. **Система интеграции MCP**: Постройте агентную систему с использованием Model Context Protocol для взаимодействия с инструментами  

## Ссылки

- Microsoft Learn (Foundry Local)  
  - Обзор: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Начало работы: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Справочник CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Интеграция с SDK для инференса: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Как открыть WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Компиляция моделей Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Обзор: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Агенты (обзор): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Инструменты оптимизации и инференса  
  - Microsoft Olive (документация): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (начало работы): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Интеграция ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (документация): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (документация): https://ml-explore.github.io/mlx/build/html/index.html  
- Фреймворки развертывания и модели  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (документация): https://docs.vllm.ai/  
  - Ollama (быстрый старт): https://github.com/ollama/ollama#get-started  
- Инструменты для разработчиков (Windows и VS Code)  
  - AI Toolkit для VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (обзор): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Сообщество обучения

Присоединяйтесь к обсуждениям и общайтесь с другими участниками:  
- GitHub Discussions в [репозитории EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Заключение

EdgeAI представляет собой передовую область внедрения искусственного интеллекта, предоставляя мощные возможности непосредственно на устройствах, одновременно решая важные вопросы конфиденциальности, задержки и подключения. Этот 20-часовой курс предоставляет вам основные знания и практические навыки, чтобы начать работать с технологиями EdgeAI уже сейчас.

Курс специально разработан кратким и сосредоточенным на самых важных концепциях, чтобы вы могли быстро получить ценные знания без чрезмерных временных затрат. Помните, что практическая работа, даже с простыми примерами, является ключом к закреплению изученного материала.

Успехов в обучении!

---

