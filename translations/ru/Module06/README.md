<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-17T17:31:08+00:00",
  "source_file": "Module06/README.md",
  "language_code": "ru"
}
-->
# Глава 06: Агентные системы SLM: Полный обзор

Сфера искусственного интеллекта переживает фундаментальную трансформацию, переходя от простых чат-ботов к сложным AI-агентам, работающим на основе Малых Языковых Моделей (SLM). Этот подробный гид охватывает три ключевых аспекта современных агентных систем SLM: базовые концепции и стратегии развертывания, возможности вызова функций и революционную интеграцию Протокола Контекста Модели (MCP).

## [Раздел 1: Основы AI-агентов и Малых Языковых Моделей](./01.IntroduceAgent.md)

Первый раздел закладывает базовое понимание AI-агентов и Малых Языковых Моделей, обозначая 2025 год как эпоху AI-агентов после эры чат-ботов в 2023 году и бума копилотов в 2024 году. В этом разделе представлены **агентные AI-системы**, которые думают, рассуждают, планируют, используют инструменты и выполняют задачи с минимальным участием человека.

### Основные концепции:
- **Классификационная структура агентов**: От простых рефлекторных агентов до обучающихся агентов, предоставляющая полную таксономию для различных вычислительных сценариев
- **Основы SLM**: Определение Малых Языковых Моделей как моделей с менее чем 10 миллиардами параметров, способных выполнять практическое инференс на потребительских устройствах
- **Продвинутые стратегии оптимизации**: Охват формата развертывания GGUF, техник квантования (Q4_K_M, Q5_K_S, Q8_0) и оптимизированных для периферии фреймворков, таких как Llama.cpp и Apple MLX
- **Сравнение SLM и LLM**: Демонстрация снижения затрат в 10-30 раз с использованием SLM при сохранении эффективности для 70-80% типичных задач агентов

Раздел завершается практическими стратегиями развертывания с использованием Ollama, VLLM и решений Microsoft для периферии, устанавливая SLM как будущее экономичных и конфиденциальных агентных AI-систем.

## [Раздел 2: Вызов функций в Малых Языковых Моделях](./02.FunctionCalling.md)

Второй раздел подробно рассматривает **возможности вызова функций**, механизм, который превращает статические языковые модели в динамичных AI-агентов, способных взаимодействовать с реальным миром. Этот технический анализ охватывает полный рабочий процесс от определения намерений до интеграции ответов.

### Основные области реализации:
- **Систематический рабочий процесс**: Детальное изучение интеграции инструментов, определения функций, обнаружения намерений, генерации JSON-выхода и внешнего выполнения
- **Реализация на конкретных платформах**: Полные руководства для Phi-4-mini с Ollama, вызова функций Qwen3 и локальной интеграции Microsoft Foundry
- **Продвинутые примеры**: Системы сотрудничества между агентами, динамический выбор инструментов и корпоративные шаблоны интеграции с комплексной обработкой ошибок
- **Производственные аспекты**: Ограничение скорости, ведение журналов аудита, меры безопасности и стратегии оптимизации производительности

Этот раздел предоставляет как теоретическое понимание, так и практические шаблоны реализации, позволяя разработчикам создавать надежные системы вызова функций, способные справляться с задачами от простых API-запросов до сложных многоэтапных корпоративных рабочих процессов.

## [Раздел 3: Интеграция Протокола Контекста Модели (MCP)](./03.IntroduceMCP.md)

Последний раздел представляет **Протокол Контекста Модели (MCP)**, революционную структуру, стандартизирующую взаимодействие языковых моделей с внешними инструментами и системами. В этом разделе показано, как MCP создает мост между AI-моделями и реальным миром через четко определенные протоколы.

### Основные моменты интеграции:
- **Архитектура протокола**: Слоистый дизайн системы, охватывающий уровни приложения, клиента LLM, клиента MCP и обработки инструментов
- **Поддержка нескольких бэкендов**: Гибкая реализация, поддерживающая как Ollama (локальная разработка), так и vLLM (производственные) бэкенды
- **Протоколы подключения**: Режим STDIO для прямой коммуникации процессов и режим SSE для потоковой передачи через HTTP
- **Примеры реального применения**: Автоматизация веба, обработка данных и интеграция API с комплексной обработкой ошибок

Интеграция MCP демонстрирует, как SLM могут быть дополнены внешними возможностями, компенсируя их меньший объем параметров за счет расширенной функциональности при сохранении преимуществ локального развертывания и эффективности использования ресурсов.

## Стратегические последствия

Вместе эти три раздела представляют собой комплексную структуру для понимания и реализации агентных систем SLM. Эволюция от базовых концепций через вызов функций к интеграции MCP демонстрирует четкий путь к демократизации развертывания AI, где:

- **Эффективность сочетается с возможностями** благодаря оптимизированным малым моделям
- **Экономичность** способствует широкому внедрению
- **Стандартизированные протоколы** обеспечивают совместимость
- **Локальное развертывание** сохраняет конфиденциальность и снижает задержки

Этот прогресс представляет собой не просто технологическое достижение, но и смену парадигмы в сторону более доступных, эффективных и практичных AI-систем, которые могут эффективно работать в условиях ограниченных ресурсов, предоставляя при этом сложные агентные возможности.

Сочетание SLM с продвинутыми стратегиями развертывания, надежным вызовом функций и стандартизированными протоколами интеграции инструментов позиционирует эти системы как основу для следующего поколения AI-агентов, которые преобразят наше взаимодействие с искусственным интеллектом и его пользу в различных отраслях и приложениях.

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.