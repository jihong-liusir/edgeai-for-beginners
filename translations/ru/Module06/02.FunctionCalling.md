<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-17T17:25:10+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "ru"
}
-->
# Section02 : Вызов функций в малых языковых моделях (SLMs)

## Содержание
1. [Что такое вызов функций?](../../../Module06)
2. [Как работает вызов функций](../../../Module06)
3. [Сценарии применения](../../../Module06)
4. [Настройка вызова функций с Phi-4-mini и Ollama](../../../Module06)
5. [Работа с вызовом функций в Qwen3](../../../Module06)
6. [Локальная интеграция Foundry](../../../Module06)
7. [Лучшие практики и устранение неполадок](../../../Module06)
8. [Продвинутые примеры](../../../Module06)

## Что такое вызов функций?

Вызов функций — это мощная возможность, которая позволяет малым языковым моделям (SLMs) взаимодействовать с внешними инструментами, API и сервисами. Вместо того чтобы ограничиваться данными обучения, SLM теперь могут:

- **Подключаться к внешним API** (сервисы погоды, базы данных, поисковые системы)
- **Выполнять конкретные функции** на основе запросов пользователей
- **Получать информацию в реальном времени** из различных источников
- **Выполнять вычислительные задачи** с помощью специализированных инструментов
- **Объединять несколько операций** для сложных рабочих процессов

Эта возможность превращает SLM из статичных генераторов текста в динамичных AI-агентов, способных выполнять задачи в реальном мире.

## Как работает вызов функций

Процесс вызова функций следует систематическому рабочему процессу:

### 1. Интеграция инструментов
- **Внешние инструменты**: SLM могут подключаться к API погоды, базам данных, веб-сервисам и другим внешним системам
- **Определение функций**: Каждый инструмент определяется с конкретными параметрами, форматами ввода/вывода и описаниями
- **Совместимость API**: Инструменты интегрируются через стандартизированные интерфейсы (REST API, SDK и т.д.)

### 2. Определение функций
Функции определяются с тремя ключевыми компонентами:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Определение намерений
- **Обработка естественного языка**: SLM анализирует ввод пользователя, чтобы понять намерение
- **Сопоставление функций**: Определяет, какие функции необходимы для выполнения запроса
- **Извлечение параметров**: Идентифицирует и извлекает необходимые параметры из сообщения пользователя

### 4. Генерация JSON-выходных данных
SLM генерирует структурированный JSON, содержащий:
- Имя функции для вызова
- Необходимые параметры с соответствующими значениями
- Контекст выполнения и метаданные

### 5. Внешнее выполнение
- **Проверка параметров**: Убедитесь, что все необходимые параметры присутствуют и правильно отформатированы
- **Выполнение функции**: Приложение выполняет указанную функцию с предоставленными параметрами
- **Обработка ошибок**: Управляет сбоями, тайм-аутами и недействительными ответами

### 6. Интеграция ответа
- **Обработка результата**: Выходные данные функции возвращаются в SLM
- **Интеграция контекста**: SLM включает результаты в свой ответ
- **Коммуникация с пользователем**: Представляет информацию в естественном, разговорном формате

## Сценарии применения

### Извлечение данных
Преобразование запросов на естественном языке в структурированные вызовы API:
- **"Покажи мои последние заказы"** → Запрос к базе данных с идентификатором пользователя и фильтрами по дате
- **"Какая погода в Токио?"** → Вызов API погоды с параметром местоположения
- **"Найди письма от Джона за прошлую неделю"** → Запрос к сервису электронной почты с фильтрами отправителя и даты

### Выполнение операций
Преобразование запросов пользователей в конкретные вызовы функций:
- **"Запланируй встречу на завтра в 14:00"** → Интеграция с API календаря
- **"Отправь сообщение команде"** → API платформы для общения
- **"Создай резервную копию моих файлов"** → Операция файловой системы

### Вычислительные задачи
Обработка сложных математических или логических операций:
- **"Рассчитай сложные проценты на $10,000 при 5% на 10 лет"** → Функция финансовых расчетов
- **"Проанализируй этот набор данных на предмет трендов"** → Инструменты статистического анализа
- **"Оптимизируй маршрут для доставки"** → Алгоритмы оптимизации маршрута

### Рабочие процессы обработки данных
Объединение нескольких вызовов функций для сложных операций:
1. **Извлечение данных** из нескольких источников
2. **Разбор и проверка** информации
3. **Преобразование** данных в требуемый формат
4. **Сохранение результатов** в соответствующих системах
5. **Генерация отчетов** или визуализаций

### Интеграция UI/UX
Обеспечение динамического обновления интерфейса:
- **"Покажи данные о продажах на панели управления"** → Генерация и отображение графиков
- **"Обнови карту с новыми местоположениями"** → Интеграция геопространственных данных
- **"Обнови отображение инвентаря"** → Синхронизация данных в реальном времени

## Настройка вызова функций с Phi-4-mini и Ollama

Phi-4-mini от Microsoft поддерживает как одиночный, так и параллельный вызов функций через Ollama. Вот как это настроить:

### Предварительные условия
- Версия Ollama 0.5.13 или выше
- Модель Phi-4-mini (рекомендуется: `phi4-mini:3.8b-fp16`)

### Шаги установки

#### 1. Установите и запустите Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Создайте шаблон ModelFile
Из-за текущих ограничений в шаблонах Ollama необходимо создать пользовательский ModelFile с следующим шаблоном:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Создайте пользовательскую модель
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Пример одиночного вызова функции

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Пример параллельного вызова функций

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Работа с вызовом функций в Qwen3

Qwen3 предлагает продвинутые возможности вызова функций с отличной производительностью и гибкостью. Вот как это реализовать:

### Использование фреймворка Qwen-Agent

Qwen-Agent предоставляет высокоуровневый фреймворк, упрощающий реализацию вызова функций:

#### Установка
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Базовая настройка

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Реализация пользовательских функций

Вы также можете определить пользовательские функции для Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Продвинутые возможности Qwen3

#### Управление режимом мышления
Qwen3 поддерживает динамическое переключение между режимами мышления и немышления:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Многошаговый вызов функций
Qwen3 отлично справляется с объединением нескольких вызовов функций:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Локальная интеграция Foundry

Foundry Local от Microsoft предоставляет API, совместимый с OpenAI, для локального запуска моделей с улучшенной конфиденциальностью и производительностью.

### Настройка и установка

#### Windows
Скачайте установщик со страницы [Foundry Local releases](https://github.com/microsoft/Foundry-Local/releases) и следуйте инструкциям по установке.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Базовое использование

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Продвинутые возможности Foundry Local

#### Управление моделями
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Оптимизация производительности
Foundry Local автоматически выбирает лучший вариант модели для вашего оборудования:
- **CUDA GPU**: Загружает модели, оптимизированные для GPU
- **Qualcomm NPU**: Использует варианты с ускорением NPU
- **Только CPU**: Выбирает модели, оптимизированные для CPU

## Лучшие практики и устранение неполадок

### Лучшие практики определения функций

#### 1. Четкое и описательное именование
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Полные определения параметров
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Проверка ввода и обработка ошибок
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Распространенные проблемы и их решения

#### Проблема 1: Функция не вызывается
**Симптомы**: Модель отвечает текстом вместо вызова функции

**Решения**:
1. **Проверьте описание функции**: Убедитесь, что оно четко соответствует намерению пользователя
2. **Проверьте определения параметров**: Убедитесь, что все необходимые параметры правильно определены
3. **Проверьте системный запрос**: Включите четкие инструкции о том, когда использовать функции
4. **Тестируйте с явными запросами**: Попробуйте "Пожалуйста, используйте функцию погоды для получения данных о Лондоне"

#### Проблема 2: Неправильные параметры
**Симптомы**: Функция вызывается с неправильными или отсутствующими параметрами

**Решения**:
1. **Добавьте примеры параметров**: Включите примеры значений в описания параметров
2. **Используйте ограничения enum**: Ограничьте значения параметров конкретными опциями, если возможно
3. **Реализуйте резервные значения**: Предоставьте разумные значения по умолчанию для необязательных параметров

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Проблема 3: Сбои параллельного вызова функций
**Симптомы**: Выполняется только одна функция, когда должны выполняться несколько

**Решения**:
1. **Проверьте поддержку модели**: Убедитесь, что ваша модель поддерживает параллельный вызов функций
2. **Обновите системный запрос**: Включите "несколько инструментов" или "несколько функций" в системное сообщение
3. **Используйте подходящие версии модели**: Рекомендуется Phi-4-mini:3.8b-fp16 для Ollama

#### Проблема 4: Проблемы с шаблонами в Ollama
**Симптомы**: Вызов функций не работает с настройкой Ollama по умолчанию

**Решения**:
1. **Используйте пользовательский ModelFile**: Примените исправленный шаблон, предоставленный в этом руководстве
2. **Обновите Ollama**: Убедитесь, что вы используете версию 0.5.13 или выше
3. **Проверьте квантизацию модели**: Более высокие уровни квантизации (Q8_0, fp16) работают лучше, чем сильно квантизированные версии

### Оптимизация производительности

#### 1. Эффективный дизайн функций
- **Сосредоточьтесь на функциях**: Каждая функция должна иметь одну четкую цель
- **Минимизируйте внешние зависимости**: Сократите вызовы API и сетевые запросы, где это возможно
- **Кэшируйте результаты**: Сохраняйте часто запрашиваемые данные для улучшения времени отклика

#### 2. Пакетная обработка и асинхронные операции
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Управление ресурсами
- **Пул соединений**: Повторно используйте соединения с базами данных и API
- **Ограничение скорости**: Реализуйте правильное ограничение скорости для внешних API
- **Обработка тайм-аутов**: Установите разумные тайм-ауты для всех внешних вызовов

## Продвинутые примеры

### Система сотрудничества нескольких агентов

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Система динамического выбора инструментов

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```
Could you please provide the markdown file content that needs to be translated?
"""Выполнение функции с комплексной обработкой ошибок и ведением логов"""
start_time = datetime.now()

try:
    # Проверка наличия функции
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Функция '{function_name}' не найдена",
            timestamp=start_time
        )
    
    # Проверка лимитов вызовов
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Превышен лимит вызовов для функции '{function_name}'",
            timestamp=start_time
        )
    
    # Проверка параметров
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Выполнение функции
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Логирование успешного выполнения
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Логирование неудачного выполнения
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Проверка лимитов вызовов функции"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Сброс счетчика, если прошла минута
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Проверка, не превышен ли лимит
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Проверка параметров функции"""
    func_params = self.functions[function_name]['parameters']
    
    # Проверка обязательных параметров
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Отсутствует обязательный параметр: {param_name}"
            )
    
    # Проверка типов и ограничений параметров
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Проверка типа
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Параметр '{param_name}' должен быть строкой"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Параметр '{param_name}' должен быть числом"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Параметр '{param_name}' должен быть булевым значением"
                )
            
            # Проверка на соответствие перечислению
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Параметр '{param_name}' должен быть одним из: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Логирование вызова функции для аудита"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Опционально запись в внешнюю систему логирования
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Запись логов во внешнюю систему логирования"""
    # Реализация зависит от вашей инфраструктуры логирования
    # Например, отправка в ELK stack, CloudWatch и т.д.
    pass

# Реализация бизнес-функций
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Получение информации о клиенте из CRM-системы"""
    # Симуляция вызова базы данных/API
    await asyncio.sleep(0.1)  # Симуляция сетевой задержки
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Product A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Product B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                    estimated_value: float, expected_close_date: str) -> Dict:
    """Создание новой возможности продаж"""
    # Симуляция вызова API CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                                 product_category: str = None) -> Dict:
    """Генерация подробного отчета о продажах"""
    # Симуляция агрегации данных
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                             priority: str = 'medium', channel: str = 'email') -> Dict:
    """Отправка уведомления через указанный канал"""
    # Симуляция вызова сервиса уведомлений
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Получение определений функций, совместимых с OpenAI, для всех зарегистрированных функций"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Пример использования для корпоративной интеграции
async def enterprise_demo():
    """Демонстрация возможностей корпоративного AI-агента"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Пример 1: Обработка запросов клиентов
    print("=== Обработка запросов клиентов ===")
    
    # Получение информации о клиенте
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Информация о клиенте получена: {result.data['name']}")
        print(f"Время выполнения: {result.execution_time:.3f}с")
    
    # Пример 2: Создание возможности продаж
    print("\n=== Создание возможности продаж ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Возможность создана: {result.data['opportunity_id']}")
    
    # Пример 3: Пакетные операции
    print("\n=== Пакетные операции ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Создана новая возможность',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Задача {i+1} выполнена успешно")
        else:
            print(f"Задача {i+1} завершилась ошибкой: {result.error}")
    
    # Отображение журнала аудита
    print(f"\n=== Журнал аудита ({len(agent.audit_log)} записей) ===")
    for entry in agent.audit_log[-3:]:  # Показать последние 3 записи
        print(f"{entry['timestamp']}: {entry['function_name']} - {'УСПЕХ' if entry['success'] else 'ОШИБКА'}")

# Запуск демонстрации
# asyncio.run(enterprise_demo())

## Заключение

Вызов функций в Small Language Models представляет собой переход от статических AI-ассистентов к динамичным, способным агентам, которые могут взаимодействовать с реальным миром. Этот учебник охватывает:

### Основные выводы

1. **Понимание основ**: Вызов функций позволяет SLM выходить за рамки обучающих данных, подключаясь к внешним инструментам и сервисам.

2. **Гибкость реализации**: Существуют различные подходы, от низкоуровневой реализации с пользовательскими шаблонами до высокоуровневых фреймворков, таких как Qwen-Agent и Foundry Local.

3. **Учет производственных факторов**: Корпоративные развертывания требуют внимания к обработке ошибок, лимитам вызовов, безопасности и ведению аудита.

4. **Оптимизация производительности**: Правильное проектирование функций, эффективное выполнение и умное кэширование могут значительно улучшить время отклика.

### Будущие направления

С развитием технологий SLM можно ожидать:

- **Улучшение точности вызова функций**: Более точное определение намерений и извлечение параметров
- **Расширенная параллельная обработка**: Более сложная оркестрация нескольких функций
- **Лучшие стандарты интеграции**: Стандартизированные протоколы для интеграции инструментов
- **Расширенные функции безопасности**: Улучшенные механизмы аутентификации и авторизации
- **Расширение экосистемы**: Рост библиотеки готовых функций и интеграций

### Начало работы

Чтобы начать реализацию вызова функций в ваших проектах:

1. **Начните с простого**: Начните с базовых сценариев с одной функцией
2. **Выберите фреймворк**: Выберите между прямой реализацией (Ollama/Phi-4) или фреймворк-ориентированным подходом (Qwen-Agent)
3. **Тщательно проектируйте функции**: Сосредоточьтесь на четких, хорошо документированных определениях функций
4. **Реализуйте обработку ошибок**: Стройте надежную обработку ошибок с самого начала
5. **Масштабируйтесь постепенно**: Переходите от простых к сложным сценариям по мере накопления опыта

Вызов функций трансформирует SLM из впечатляющих генераторов текста в практичных AI-агентов, способных решать реальные задачи. Следуя описанным в этом учебнике шаблонам и практикам, вы сможете создавать мощные, надежные AI-системы, которые выходят далеко за рамки традиционных интерфейсов чата.

### Ресурсы и ссылки
- **Phi-4 Модели**: [Коллекция Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Документация Qwen3**: [Официальная документация Qwen](https://qwen.readthedocs.io/)
- **Ollama**: [Официальный сайт](https://ollama.com/)
- **Foundry Local**: [Репозиторий на GitHub](https://github.com/microsoft/Foundry-Local)
- **Лучшие практики вызова функций**: [Руководство Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)

Помните, что вызов функций — это развивающаяся область, и следить за последними изменениями в выбранных вами фреймворках и моделях поможет создавать более эффективных AI-агентов.


## ➡️ Что дальше

- [03: Интеграция протокола контекста модели (MCP)](./03.IntroduceMCP.md)

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.