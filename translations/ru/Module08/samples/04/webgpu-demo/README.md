<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7a474b8e201d5316c0095cdbc3bf0555",
  "translation_date": "2025-09-24T13:46:33+00:00",
  "source_file": "Module08/samples/04/webgpu-demo/README.md",
  "language_code": "ru"
}
-->
# Демонстрация WebGPU + ONNX Runtime

Этот демонстрационный проект показывает, как запускать модели ИИ прямо в браузере, используя WebGPU для аппаратного ускорения и ONNX Runtime Web.

## Что демонстрируется

- **ИИ в браузере**: Запуск моделей полностью в браузере
- **Аппаратное ускорение с WebGPU**: Ускорение вычислений при наличии поддержки
- **Конфиденциальность**: Данные не покидают ваше устройство
- **Без установки**: Работает в любом совместимом браузере
- **Плавное переключение**: Переход на CPU, если WebGPU недоступен

## Требования

**Совместимость браузера:**
- Chrome/Edge версии 113+ с включенным WebGPU
- Проверить статус WebGPU: `chrome://gpu`
- Включить WebGPU: `chrome://flags/#enable-unsafe-webgpu`

## Запуск демонстрации

### Вариант 1: Локальный сервер (рекомендуется)

```cmd
# Navigate to the demo directory
cd Module08\samples\04\webgpu-demo

# Start a local server
python -m http.server 5173

# Open browser to http://localhost:5173
```

### Вариант 2: Live Server в VS Code

1. Установите расширение "Live Server" в VS Code
2. Щелкните правой кнопкой мыши на `index.html` → "Open with Live Server"
3. Демонстрация откроется автоматически в браузере

## Что вы увидите

1. **Проверка WebGPU**: Проверка совместимости браузера
2. **Загрузка модели**: Скачивание и инициализация классификатора MNIST
3. **Выполнение предсказания**: Запуск предсказания на тестовых данных
4. **Метрики производительности**: Отображение времени загрузки и скорости предсказания
5. **Результаты**: Уверенность предсказания и сырые выходные данные

## Ожидаемая производительность

| Провайдер выполнения | Загрузка модели | Предсказание | Примечания |
|----------------------|-----------------|--------------|------------|
| **WebGPU**           | ~2-5с          | ~10-50мс     | Аппаратное ускорение |
| **CPU (WASM)**       | ~2-5с          | ~50-200мс    | Резервное выполнение на CPU |

## Устранение неполадок

**WebGPU недоступен:**
- Обновите Chrome/Edge до версии 113+
- Включите WebGPU в `chrome://flags`
- Убедитесь, что драйверы GPU актуальны
- Демонстрация автоматически переключится на CPU

**Ошибки загрузки:**
- Убедитесь, что вы запускаете через HTTP (не file://)
- Проверьте подключение к сети для скачивания модели
- Убедитесь, что CORS не блокирует ONNX модель

**Проблемы с производительностью:**
- WebGPU значительно ускоряет выполнение по сравнению с CPU
- Первая загрузка может быть медленнее из-за скачивания модели
- Последующие запуски используют кэш браузера

## Интеграция с Foundry Local

Эта демонстрация WebGPU дополняет Foundry Local, показывая:

- **Инференс на стороне клиента** для максимальной конфиденциальности
- **Оффлайн-работу** при отсутствии интернета  
- **Развертывание на периферии** для ограниченных ресурсов
- **Гибридные архитектуры**, объединяющие локальный и серверный инференс

Для производственных приложений рассмотрите:
- Использование Foundry Local для инференса на сервере
- Использование WebGPU для локальной предобработки/постобработки
- Реализацию интеллектуального маршрутизации между локальным и удаленным инференсом

## Технические детали

**Используемая модель:**
- Классификатор цифр MNIST (формат ONNX)
- Вход: изображения 28x28 в градациях серого
- Выход: распределение вероятностей по 10 классам
- Размер: ~500КБ (быстрая загрузка)

**ONNX Runtime Web:**
- Провайдер выполнения WebGPU для ускорения на GPU
- Провайдер выполнения WASM для резервного выполнения на CPU
- Автоматическая оптимизация и оптимизация графа

**API браузера:**
- WebGPU для доступа к аппаратным ресурсам
- Web Workers для фоновой обработки (в будущем)
- WebAssembly для эффективных вычислений

## Следующие шаги

- Попробуйте с пользовательскими моделями ONNX
- Реализуйте загрузку реальных изображений и классификацию
- Добавьте потоковый инференс для более крупных моделей
- Интегрируйте ввод с камеры/микрофона

---

