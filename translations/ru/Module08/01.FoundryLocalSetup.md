<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6503a980cb3bf2b2de2d2bc4ac6acc4c",
  "translation_date": "2025-09-24T13:16:22+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "ru"
}
-->
# –°–µ—Å—Å–∏—è 1: –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã —Å Foundry Local

## –û–±–∑–æ—Ä

Microsoft Foundry Local –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ Azure AI Foundry –ø—Ä—è–º–æ –≤ –≤–∞—à–µ–π —Å—Ä–µ–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Windows 11, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å, –Ω–∏–∑–∫—É—é –∑–∞–¥–µ—Ä–∂–∫—É –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ò–ò. –í —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –ø–æ–ª–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞, –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –≤–∫–ª—é—á–∞—è phi, qwen, deepseek –∏ GPT-OSS-20B.

## –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è

–ö –∫–æ–Ω—Ü—É —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏ –≤—ã —Å–º–æ–∂–µ—Ç–µ:
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Foundry Local –Ω–∞ Windows 11
- –û—Å–≤–æ–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã CLI –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –ü–æ–Ω—è—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –£—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª–∏ phi, qwen, deepseek –∏ GPT-OSS-20B
- –°–æ–∑–¥–∞—Ç—å —Å–≤–æ–µ –ø–µ—Ä–≤–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ò–ò —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Foundry Local

## –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- **Windows 11**: –í–µ—Ä—Å–∏—è 22H2 –∏–ª–∏ –Ω–æ–≤–µ–µ
- **–û–ó–£**: –º–∏–Ω–∏–º—É–º 16 –ì–ë, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 32 –ì–ë
- **–•—Ä–∞–Ω–∏–ª–∏—â–µ**: 50 –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π –∏ –∫—ç—à–∞
- **–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ**: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π NPU –∏–ª–∏ GPU (–Ω–∞–ø—Ä–∏–º–µ—Ä, Copilot+ PC –∏–ª–∏ NVIDIA GPU)
- **–°–µ—Ç—å**: –í—ã—Å–æ–∫–æ—Å–∫–æ—Ä–æ—Å—Ç–Ω–æ–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π

### –°—Ä–µ–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## –ß–∞—Å—Ç—å 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Foundry Local

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Foundry Local —Å –ø–æ–º–æ—â—å—é Winget –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π —Ñ–∞–π–ª —Å GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## –ß–∞—Å—Ç—å 2: –ü–æ–Ω–∏–º–∞–Ω–∏–µ CLI

### –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–º–∞–Ω–¥

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## –ß–∞—Å—Ç—å 3: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏

Foundry Local –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## –ß–∞—Å—Ç—å 4: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–µ–π Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### –†–∞–±–æ—Ç–∞ —Å –º–æ–¥–µ–ª—è–º–∏ Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–µ–π DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### –ó–∞–ø—É—Å–∫ GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## –ß–∞—Å—Ç—å 5: –°–æ–∑–¥–∞–Ω–∏–µ –≤–∞—à–µ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

### –°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (OpenAI SDK + Foundry Local)

–°–æ–∑–¥–∞–π—Ç–µ –≥–æ—Ç–æ–≤–æ–µ –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI SDK –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Foundry Local, —Å–ª–µ–¥—É—è —à–∞–±–ª–æ–Ω–∞–º –∏–∑ –Ω–∞—à–µ–≥–æ –ü—Ä–∏–º–µ—Ä–∞ 01.

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("‚ö†Ô∏è Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"üåê Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"üè† Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"‚ö†Ô∏è Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"üîß Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### –ó–∞–ø—É—Å–∫ —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## –ß–∞—Å—Ç—å 6: –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫ –∏ –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

### –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

| –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ |
|------------|----------|-----------------------|-------------|
| `MODEL` | –ü—Å–µ–≤–¥–æ–Ω–∏–º –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ | `phi-4-mini` | –ù–µ—Ç |
| `BASE_URL` | –ë–∞–∑–æ–≤—ã–π URL Foundry Local | `http://localhost:8000` | –ù–µ—Ç |
| `API_KEY` | API-–∫–ª—é—á (–æ–±—ã—á–Ω–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è) | `""` | –ù–µ—Ç |
| `AZURE_OPENAI_ENDPOINT` | –ö–æ–Ω–µ—á–Ω–∞—è —Ç–æ—á–∫–∞ Azure OpenAI | - | –î–ª—è Azure |
| `AZURE_OPENAI_API_KEY` | API-–∫–ª—é—á Azure OpenAI | - | –î–ª—è Azure |
| `AZURE_OPENAI_API_VERSION` | –í–µ—Ä—Å–∏—è API Azure | `2024-08-01-preview` | –ù–µ—Ç |

### –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

- **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ OpenAI SDK**: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π—Ç–µ OpenAI SDK –≤–º–µ—Å—Ç–æ –ø—Ä—è–º—ã—Ö HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏
- **FoundryLocalManager**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π SDK –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞–º–∏, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
- **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ
- **–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è**: –û–±–Ω–æ–≤–ª—è–π—Ç–µ Foundry Local, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å –¥–æ—Å—Ç—É–ø –∫ –Ω–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º
- **–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –º–∞–ª–æ–≥–æ**: –ù–∞—á–Ω–∏—Ç–µ —Å –Ω–µ–±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π (Phi mini, Qwen 7B) –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–π—Ç–µ –º–∞—Å—à—Ç–∞–±
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É CPU/GPU/–ø–∞–º—è—Ç–∏ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø–æ–¥—Å–∫–∞–∑–æ–∫ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

## –ß–∞—Å—Ç—å 7: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è

### –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 1: –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 2: –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ OpenAI SDK

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"‚úÖ {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"‚ùå {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b-instruct"]
for model in models_to_test:
    test_model_integration(model)
```

### –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 3: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"‚úÖ Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"‚úÖ {model_id}: Working")
            except Exception as e:
                print(f"‚ùå {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"‚ùå Service check failed: {e}")
        return False

comprehensive_health_check()
```

## –°—Å—ã–ª–∫–∏

- **–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã —Å Foundry Local**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ CLI –∏ –æ–±–∑–æ—Ä –∫–æ–º–∞–Ω–¥**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è OpenAI SDK**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **–ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–µ–π Hugging Face**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local –Ω–∞ GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **–ü—Ä–∏–º–µ—Ä 01: –ë—ã—Å—Ç—Ä—ã–π —á–∞—Ç —á–µ—Ä–µ–∑ OpenAI SDK**: samples/01/README.md
- **–ü—Ä–∏–º–µ—Ä 02: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SDK**: samples/02/README.md

---

