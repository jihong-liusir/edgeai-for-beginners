<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8ccc4f76611daedf918e34460128fc21",
  "translation_date": "2025-09-30T23:03:42+00:00",
  "source_file": "Module08/04.CuttingEdgeModels.md",
  "language_code": "ru"
}
-->
# –°–µ—Å—Å–∏—è 4: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å Chainlit

## –û–±–∑–æ—Ä

–≠—Ç–∞ —Å–µ—Å—Å–∏—è –ø–æ—Å–≤—è—â–µ–Ω–∞ —Å–æ–∑–¥–∞–Ω–∏—é –≥–æ—Ç–æ–≤—ã—Ö –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Chainlit –∏ Microsoft Foundry Local. –í—ã –Ω–∞—É—á–∏—Ç–µ—Å—å —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –¥–ª—è AI-–¥–∏–∞–ª–æ–≥–æ–≤, —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å –ø–æ—Ç–æ–∫–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –∏ —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–∞–¥–µ–∂–Ω—ã–µ —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ –¥–∏–∑–∞–π–Ω–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞.

**–ß—Ç–æ –≤—ã —Å–æ–∑–¥–∞–¥–∏—Ç–µ:**
- **–ß–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Chainlit**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –ø–æ—Ç–æ–∫–æ–≤—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏
- **–î–µ–º–æ WebGPU**: –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –≤ –±—Ä–∞—É–∑–µ—Ä–µ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏  
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Open WebUI**: –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —á–∞—Ç-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å Foundry Local
- **–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è

## –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è

- –°–æ–∑–¥–∞–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–µ –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å Chainlit
- –†–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å –ø–æ—Ç–æ–∫–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞
- –û—Å–≤–æ–∏—Ç—å —à–∞–±–ª–æ–Ω—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ SDK Foundry Local
- –ü—Ä–∏–º–µ–Ω—è—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –∏ –ø–ª–∞–≤–Ω—É—é –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
- –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞—Ç—å –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥
- –ü–æ–Ω—è—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ –¥–ª—è —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–≥–æ AI

## –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Foundry Local**: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∑–∞–ø—É—â–µ–Ω ([–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ](https://learn.microsoft.com/azure/ai-foundry/foundry-local/))
- **Python**: –í–µ—Ä—Å–∏—è 3.10 –∏–ª–∏ –≤—ã—à–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π
- **–ú–æ–¥–µ–ª—å**: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å (`foundry model run phi-4-mini`)
- **–ë—Ä–∞—É–∑–µ—Ä**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –≤–µ–±-–±—Ä–∞—É–∑–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π WebGPU (Chrome/Edge)
- **Docker**: –î–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Open WebUI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

## –ß–∞—Å—Ç—å 1: –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π

### –û–±–∑–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

```
User Browser ‚Üê‚Üí Chainlit UI ‚Üê‚Üí Python Backend ‚Üê‚Üí Foundry Local ‚Üê‚Üí AI Model
      ‚Üì              ‚Üì              ‚Üì              ‚Üì            ‚Üì
   Web UI      Event Handlers   OpenAI Client   HTTP API    Local GPU
```

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

**–®–∞–±–ª–æ–Ω—ã SDK Foundry Local:**
- `FoundryLocalManager(alias)`: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞–º–∏
- `manager.endpoint` –∏ `manager.api_key`: –î–µ—Ç–∞–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
- `manager.get_model_info(alias).id`: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

**–§—Ä–µ–π–º–≤–æ—Ä–∫ Chainlit:**
- `@cl.on_chat_start`: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞
- `@cl.on_message`: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π  
- `cl.Message().stream_token()`: –ü–æ—Ç–æ–∫–æ–≤–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è UI –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ WebSocket

## –ß–∞—Å—Ç—å 2: –õ–æ–∫–∞–ª—å–Ω–∞—è vs –æ–±–ª–∞—á–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Ä–µ—à–µ–Ω–∏–π

### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

| –ê—Å–ø–µ–∫—Ç | –õ–æ–∫–∞–ª—å–Ω–æ (Foundry) | –û–±–ª–∞–∫–æ (Azure OpenAI) |
|--------|--------------------|-----------------------|
| **–ó–∞–¥–µ—Ä–∂–∫–∞** | üöÄ 50-200 –º—Å (–±–µ–∑ —Å–µ—Ç–∏) | ‚è±Ô∏è 200-2000 –º—Å (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–µ—Ç–∏) |
| **–ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å** | üîí –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–∫–∏–¥–∞—é—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ | ‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ –æ–±–ª–∞–∫–æ |
| **–°—Ç–æ–∏–º–æ—Å—Ç—å** | üí∞ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ –ø–æ—Å–ª–µ –ø–æ–∫—É–ø–∫–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è | üí∏ –û–ø–ª–∞—Ç–∞ –∑–∞ —Ç–æ–∫–µ–Ω |
| **–û—Ñ—Ñ–ª–∞–π–Ω** | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ | ‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç |
| **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏** | ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º | ‚úÖ –î–æ—Å—Ç—É–ø –∫ —Å–∞–º—ã–º –∫—Ä—É–ø–Ω—ã–º –º–æ–¥–µ–ª—è–º |
| **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ** | ‚ö†Ô∏è –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è | ‚úÖ –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ |

### –®–∞–±–ª–æ–Ω—ã –≥–∏–±—Ä–∏–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

**–õ–æ–∫–∞–ª—å–Ω–æ —Å–Ω–∞—á–∞–ª–∞ —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º:**
```python
async def hybrid_completion(prompt: str, complexity_threshold: int = 100):
    if len(prompt.split()) < complexity_threshold:
        return await local_completion(prompt)  # Fast, private
    else:
        return await cloud_completion(prompt)   # Complex reasoning
```

**–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞—á:**
```python
async def smart_routing(prompt: str, task_type: str):
    routing_rules = {
        "code_generation": "local",     # Privacy-sensitive
        "creative_writing": "cloud",    # Benefits from larger models
        "data_analysis": "local",       # Fast iteration needed
        "research": "cloud"             # Requires broad knowledge
    }
    
    if routing_rules.get(task_type) == "local":
        return await foundry_completion(prompt)
    else:
        return await azure_completion(prompt)
```

## –ß–∞—Å—Ç—å 3: –ü—Ä–∏–º–µ—Ä 04 - –ß–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Chainlit

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```cmd
# Navigate to Module08 directory  
cd Module08

# Start your preferred model
foundry model run phi-4-mini

# Run the Chainlit application (avoiding port conflicts)
chainlit run samples\04\app.py -w --port 8080
```

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –ø–æ –∞–¥—Ä–µ—Å—É `http://localhost:8080` —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º —á–∞—Ç–∞.

### –û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ü—Ä–∏–º–µ—Ä 04 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω—ã, –≥–æ—Ç–æ–≤—ã–µ –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É:

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–≤:**
```python
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

# Global variables for client and model
client = None
model_name = None

async def initialize_client():
    global client, model_name
    alias = os.environ.get("MODEL", "phi-4-mini")
    
    try:
        # Use FoundryLocalManager for proper service management
        manager = FoundryLocalManager(alias)
        model_info = manager.get_model_info(alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-required"
        )
        model_name = model_info.id if model_info else alias
        return True
    except Exception as e:
        # Fallback to manual configuration
        base_url = os.environ.get("BASE_URL", "http://localhost:51211")
        client = OpenAI(base_url=f"{base_url}/v1", api_key="not-required")
        model_name = alias
        return True
```

**–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —á–∞—Ç–∞:**
```python
@cl.on_message
async def main(message: cl.Message):
    # Create streaming response
    msg = cl.Message(content="")
    await msg.send()
    
    stream = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": message.content}
        ],
        stream=True
    )
    
    # Stream tokens in real-time
    for chunk in stream:
        if chunk.choices[0].delta.content:
            await msg.stream_token(chunk.choices[0].delta.content)
    
    await msg.update()
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:**

| –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –ü—Ä–∏–º–µ—Ä |
|------------|----------|-----------------------|--------|
| `MODEL` | –ü—Å–µ–≤–¥–æ–Ω–∏–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Endpoint Foundry Local | –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ | `http://localhost:51211` |
| `API_KEY` | API-–∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ) | `""` | `your-api-key` |

**–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```cmd
# Use different model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Use different ports (avoid 51211 which is used by Foundry Local)
chainlit run samples\04\app.py -w --port 3000
chainlit run samples\04\app.py -w --port 5000
```

## –ß–∞—Å—Ç—å 4: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Jupyter Notebook

### –û–±–∑–æ—Ä –ø–æ–¥–¥–µ—Ä–∂–∫–∏ Notebook

–ü—Ä–∏–º–µ—Ä 04 –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –ø–æ–¥—Ä–æ–±–Ω—ã–π Jupyter Notebook (`chainlit_app.ipynb`), –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:

- **üìö –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç**: –ü–æ—à–∞–≥–æ–≤—ã–µ —É—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
- **üî¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ**: –ó–∞–ø—É—Å–∫ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —è—á–µ–π–∫–∞–º–∏ –∫–æ–¥–∞
- **üìä –í–∏–∑—É–∞–ª—å–Ω—ã–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏**: –ì—Ä–∞—Ñ–∏–∫–∏, –¥–∏–∞–≥—Ä–∞–º–º—ã –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- **üõ†Ô∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏**: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö Notebook

#### –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è Jupyter

```cmd
# Ensure you're in the Module08 directory
cd Module08

# Activate your virtual environment
.venv\Scripts\activate

# Install Jupyter and dependencies
pip install jupyter notebook jupyterlab ipykernel
pip install -r requirements.txt

# Register the kernel for VS Code
python -m ipykernel install --user --name=foundry-local --display-name="Foundry Local"
```

#### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ Notebook

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ VS Code:**
1. –û—Ç–∫—Ä–æ–π—Ç–µ VS Code –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Module08
2. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º `.ipynb`
3. –í—ã–±–µ—Ä–∏—Ç–µ —è–¥—Ä–æ "Foundry Local", –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ
4. –ù–∞—á–Ω–∏—Ç–µ –¥–æ–±–∞–≤–ª—è—Ç—å —è—á–µ–π–∫–∏ —Å –≤–∞—à–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Jupyter Lab:**
```cmd
# Start Jupyter Lab
jupyter lab

# Navigate to samples/04/ and create new notebook
# Choose Python 3 kernel
```

### –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Notebook

#### –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —è—á–µ–µ–∫

```python
# Cell 1: Imports and Setup
import os
import sys
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

print("‚úÖ Libraries imported successfully")
```

```python
# Cell 2: Configuration and Client Setup
class FoundryClientManager:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.client = None
        
    def initialize_client(self):
        # Client initialization logic
        pass

# Initialize and test
client_manager = FoundryClientManager()
result = client_manager.initialize_client()
print(f"Client initialized: {result}")
```

### –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è

#### –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 1: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞

```python
# Test different configuration methods
configurations = [
    {"method": "foundry_sdk", "model": "phi-4-mini"},
    {"method": "manual", "base_url": "http://localhost:51211", "model": "qwen2.5-7b"},
]

for config in configurations:
    print(f"\nüß™ Testing {config['method']} configuration...")
    # Implementation here
    result = test_configuration(config)
    print(f"Result: {'‚úÖ Success' if result['status'] == 'ok' else '‚ùå Failed'}")
```

#### –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 2: –°–∏–º—É–ª—è—Ü–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞

```python
import asyncio

async def simulate_streaming_response(text, delay=0.1):
    """Simulate how streaming works in Chainlit."""
    print("üåä Simulating streaming response...")
    
    for char in text:
        print(char, end='', flush=True)
        await asyncio.sleep(delay)
    
    print("\n‚úÖ Streaming complete!")

# Test the simulation
sample_text = "This is how streaming responses work in Chainlit applications!"
await simulate_streaming_response(sample_text)
```

## –ß–∞—Å—Ç—å 5: –î–µ–º–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≤ –±—Ä–∞—É–∑–µ—Ä–µ —Å WebGPU

### –û–±–∑–æ—Ä

WebGPU –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å AI-–º–æ–¥–µ–ª–∏ –ø—Ä—è–º–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏. –≠—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç ONNX Runtime Web —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ WebGPU.

### –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ WebGPU

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±—Ä–∞—É–∑–µ—Ä—É:**
- Chrome/Edge 113+ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º WebGPU
- –ü—Ä–æ–≤–µ—Ä–∫–∞: `chrome://gpu` ‚Üí –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —Å—Ç–∞—Ç—É—Å "WebGPU"
- –ü—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: `if (!('gpu' in navigator)) { /* no WebGPU */ }`

### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ WebGPU

–°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: `samples/04/webgpu-demo/`

**index.html:**
```html
<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WebGPU + ONNX Runtime Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
    <style>
        body { font-family: system-ui, sans-serif; margin: 2rem; }
        pre { background: #f5f5f5; padding: 1rem; overflow: auto; }
        .status { padding: 1rem; background: #e3f2fd; border-radius: 4px; }
    </style>
</head>
<body>
    <h1>üöÄ WebGPU + Foundry Local Integration</h1>
    <div id="status" class="status">Initializing...</div>
    <pre id="output"></pre>
    <script type="module" src="./main.js"></script>
</body>
</html>
```

**main.js:**
```javascript
const statusEl = document.getElementById('status');
const outputEl = document.getElementById('output');

function log(msg) {
    outputEl.textContent += `${msg}\n`;
    console.log(msg);
}

(async () => {
    try {
        if (!('gpu' in navigator)) {
            statusEl.textContent = '‚ùå WebGPU not available';
            return;
        }
        
        statusEl.textContent = 'üîç WebGPU detected. Loading model...';
        
        // Use a small ONNX model for demo
        const modelUrl = 'https://huggingface.co/onnx/models/resolve/main/vision/classification/mnist-12/mnist-12.onnx';
        
        const session = await ort.InferenceSession.create(modelUrl, {
            executionProviders: ['webgpu']
        });
        
        log('‚úÖ ONNX Runtime session created with WebGPU');
        log(`üìä Input names: ${session.inputNames.join(', ')}`);
        log(`üìä Output names: ${session.outputNames.join(', ')}`);
        
        // Create dummy input (MNIST expects 1x1x28x28)
        const inputData = new Float32Array(1 * 1 * 28 * 28).fill(0.1);
        const input = new ort.Tensor('float32', inputData, [1, 1, 28, 28]);
        
        const feeds = {};
        feeds[session.inputNames[0]] = input;
        
        const results = await session.run(feeds);
        const output = results[session.outputNames[0]];
        
        // Find prediction (argmax)
        let maxIdx = 0;
        for (let i = 1; i < output.data.length; i++) {
            if (output.data[i] > output.data[maxIdx]) maxIdx = i;
        }
        
        statusEl.textContent = '‚úÖ WebGPU inference complete!';
        log(`üéØ Predicted class: ${maxIdx}`);
        log(`üìà Confidence scores: [${Array.from(output.data).map(x => x.toFixed(3)).join(', ')}]`);
        
    } catch (error) {
        statusEl.textContent = `‚ùå Error: ${error.message}`;
        log(`Error: ${error.message}`);
        console.error(error);
    }
})();
```

### –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ –¥–µ–º–æ

```cmd
# Create demo directory
mkdir samples\04\webgpu-demo
cd samples\04\webgpu-demo

# Save HTML and JS files, then serve
python -m http.server 5173

# Open browser to http://localhost:5173
```

## –ß–∞—Å—Ç—å 6: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Open WebUI

### –û–±–∑–æ—Ä

Open WebUI –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ ChatGPT, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º—É API Foundry Local.

### –®–∞–≥ 1: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

```cmd
# Verify Foundry Local is running
foundry service status

# Start a model
foundry model run phi-4-mini

# Confirm API endpoint is accessible
curl http://localhost:51211/v1/models
```

### –®–∞–≥ 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Docker (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```cmd
# Pull Open WebUI image
docker pull ghcr.io/open-webui/open-webui:main

# Run with Foundry Local connection
docker run -d --name open-webui -p 3000:8080 ^
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 ^
  -e OPENAI_API_KEY=foundry-local-key ^
  -v open-webui-data:/app/backend/data ^
  ghcr.io/open-webui/open-webui:main
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** `host.docker.internal` –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º Docker –ø–æ–ª—É—á–∞—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Ö–æ—Å—Ç-–º–∞—à–∏–Ω–µ –Ω–∞ Windows.

### –®–∞–≥ 3: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

1. **–û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä:** –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ `http://localhost:3000`
2. **–ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞:** –°–æ–∑–¥–∞–π—Ç–µ —É—á–µ—Ç–Ω—É—é –∑–∞–ø–∏—Å—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
3. **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏:**
   - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Üí –ú–æ–¥–µ–ª–∏ ‚Üí OpenAI API  
   - –ë–∞–∑–æ–≤—ã–π URL: `http://host.docker.internal:51211/v1`
   - API-–∫–ª—é—á: `foundry-local-key` (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ª—é–±–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
4. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è:** –ú–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –ø–æ—è–≤–∏—Ç—å—Å—è –≤ –≤—ã–ø–∞–¥–∞—é—â–µ–º —Å–ø–∏—Å–∫–µ

### –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

**–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:**

1. **–û—Ç–∫–∞–∑ –≤ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏:**
   ```cmd
   # Check Foundry Local status
   foundry service ps
   netstat -ano | findstr :51211
   ```

2. **–ú–æ–¥–µ–ª–∏ –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è:**
   - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: `foundry model list`
   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ç–≤–µ—Ç API: `curl http://localhost:51211/v1/models`
   - –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä Open WebUI

## –ß–∞—Å—Ç—å 7: –°–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:**
```cmd
# Development with auto-reload and debugging
chainlit run samples\04\app.py -w --port 8080 --debug
```

**–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ:**
```cmd
# Production mode with optimizations
chainlit run samples\04\app.py --host 0.0.0.0 --port 8080 --no-cache
```

### –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ—Ä—Ç–∞–º–∏ –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è

**–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –ø–æ—Ä—Ç–∞ 51211:**
```cmd
# Check what's using Foundry Local port
netstat -ano | findstr :51211

# Use different port for Chainlit
chainlit run samples\04\app.py -w --port 8080
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è:**
```python
@cl.on_chat_start
async def health_check():
    try:
        # Test model availability
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1
        )
        return {"status": "healthy", "model": model_name}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

## –†–µ–∑—é–º–µ

–°–µ—Å—Å–∏—è 4 –æ—Ö–≤–∞—Ç–∏–ª–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Chainlit –¥–ª—è —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–≥–æ AI. –í—ã —É–∑–Ω–∞–ª–∏ –æ:

- ‚úÖ **–§—Ä–µ–π–º–≤–æ—Ä–∫–µ Chainlit**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π UI –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —á–∞—Ç-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
- ‚úÖ **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Foundry Local**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ SDK –∏ —à–∞–±–ª–æ–Ω—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏  
- ‚úÖ **–ò–Ω—Ñ–µ—Ä–µ–Ω—Å–µ WebGPU**: AI –≤ –±—Ä–∞—É–∑–µ—Ä–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ **–ù–∞—Å—Ç—Ä–æ–π–∫–µ Open WebUI**: –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —á–∞—Ç–∞
- ‚úÖ **–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–∞—Ö**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ü—Ä–∏–º–µ—Ä 04 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–¥–µ–∂–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ —á–∞—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ AI-–º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Microsoft Foundry Local, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –æ—Ç–ª–∏—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–ø—ã—Ç.

## –°—Å—ã–ª–∫–∏

- **[–ü—Ä–∏–º–µ—Ä 04: –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Chainlit](samples/04/README.md)**: –ü–æ–ª–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
- **[–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π Notebook Chainlit](samples/04/chainlit_app.ipynb)**: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
- **[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
- **[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Chainlit](https://docs.chainlit.io/)**: –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
- **[–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Open WebUI](https://github.com/microsoft/foundry-local/blob/main/docs/tutorials/chat-application-with-open-web-ui.md)**: –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —É—á–µ–±–Ω–∏–∫

---

**–û—Ç–∫–∞–∑ –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏**:  
–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –±—ã–ª –ø–µ—Ä–µ–≤–µ–¥–µ–Ω —Å –ø–æ–º–æ—â—å—é —Å–µ—Ä–≤–∏—Å–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ [Co-op Translator](https://github.com/Azure/co-op-translator). –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –Ω–∞—à–∏ —É—Å–∏–ª–∏—è –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—à–∏–±–∫–∏ –∏–ª–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –µ–≥–æ —Ä–æ–¥–Ω–æ–º —è–∑—ã–∫–µ —Å–ª–µ–¥—É–µ—Ç —Å—á–∏—Ç–∞—Ç—å –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–µ–ª–æ–≤–µ–∫–æ–º. –ú—ã –Ω–µ –Ω–µ—Å–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –ª—é–±—ã–µ –Ω–µ–¥–æ—Ä–∞–∑—É–º–µ–Ω–∏—è –∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏, –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞.