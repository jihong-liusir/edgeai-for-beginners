<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-18T17:14:41+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "cs"
}
-->
# Sekce 4: Nasazení - Implementace modelu připraveného pro produkci

## Přehled

Tento komplexní návod vás provede celým procesem nasazení jemně doladěných kvantovaných modelů pomocí Foundry Local. Pokryjeme konverzi modelu, optimalizaci kvantizace a konfiguraci nasazení od začátku do konce.

## Předpoklady

Než začnete, ujistěte se, že máte následující:

- ✅ Jemně doladěný ONNX model připravený k nasazení
- ✅ Počítač s Windows nebo Mac
- ✅ Python 3.10 nebo novější
- ✅ Minimálně 8 GB volné RAM
- ✅ Foundry Local nainstalovaný na vašem systému

## Část 1: Nastavení prostředí

### Instalace potřebných nástrojů

Otevřete svůj terminál (Command Prompt na Windows, Terminal na Mac) a postupně spusťte následující příkazy:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

⚠️ **Důležitá poznámka**: Budete také potřebovat CMake verze 3.31 nebo novější, který si můžete stáhnout z [cmake.org](https://cmake.org/download/).

## Část 2: Konverze modelu a kvantizace

### Výběr správného formátu

Pro jemně doladěné malé jazykové modely doporučujeme používat **ONNX formát**, protože nabízí:

- 🚀 Lepší optimalizaci výkonu
- 🔧 Nasazení nezávislé na hardwaru
- 🏭 Schopnosti připravené pro produkci
- 📱 Kompatibilitu napříč platformami

### Metoda 1: Konverze jedním příkazem (doporučeno)

Použijte následující příkaz pro přímou konverzi vašeho jemně doladěného modelu:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**Vysvětlení parametrů:**
- `--model_name_or_path`: Cesta k vašemu jemně doladěnému modelu
- `--device cpu`: Použití CPU pro optimalizaci
- `--precision int4`: Použití kvantizace INT4 (přibližně 75% snížení velikosti)
- `--output_path`: Výstupní cesta pro konvertovaný model

### Metoda 2: Přístup pomocí konfiguračního souboru (pokročilí uživatelé)

Vytvořte konfigurační soubor s názvem `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

Poté spusťte:

```bash
olive run --config ./finetuned_conversion_config.json
```

### Porovnání možností kvantizace

| Přesnost | Velikost souboru | Rychlost inferencí | Kvalita modelu | Doporučené použití |
|----------|------------------|--------------------|----------------|--------------------|
| FP16     | Základní × 0.5   | Rychlá             | Nejlepší       | Vysoce výkonný hardware |
| INT8     | Základní × 0.25  | Velmi rychlá       | Dobrá          | Vyvážená volba |
| INT4     | Základní × 0.125 | Nejrychlejší       | Přijatelná     | Omezené zdroje |

💡 **Doporučení**: Začněte s kvantizací INT4 pro vaše první nasazení. Pokud kvalita nebude uspokojivá, zkuste INT8 nebo FP16.

## Část 3: Konfigurace nasazení Foundry Local

### Vytvoření konfigurace modelu

Přejděte do adresáře modelů Foundry Local:

```bash
foundry cache cd ./models/
```

Vytvořte strukturu adresářů pro váš model:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

Vytvořte konfigurační soubor `inference_model.json` ve vašem adresáři modelu:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### Šablony konfigurací specifické pro model

#### Pro modely série Qwen:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## Část 4: Testování a optimalizace modelu

### Ověření instalace modelu

Zkontrolujte, zda Foundry Local rozpozná váš model:

```bash
foundry cache ls
```

Měli byste vidět `your-finetuned-model-int4` v seznamu.

### Zahájení testování modelu

```bash
foundry model run your-finetuned-model-int4
```

### Benchmarking výkonu

Sledujte klíčové metriky během testování:

1. **Doba odezvy**: Měření průměrné doby na odpověď
2. **Využití paměti**: Monitorování spotřeby RAM
3. **Využití CPU**: Kontrola zatížení procesoru
4. **Kvalita výstupu**: Hodnocení relevance a koherence odpovědí

### Kontrolní seznam validace kvality

- ✅ Model správně reaguje na dotazy z jemně doladěné domény
- ✅ Formát odpovědí odpovídá očekávané struktuře výstupu
- ✅ Žádné úniky paměti při dlouhodobém používání
- ✅ Konzistentní výkon napříč různými délkami vstupů
- ✅ Správné zpracování hraničních případů a neplatných vstupů

## Shrnutí

Gratulujeme! Úspěšně jste dokončili:

- ✅ Konverzi formátu jemně doladěného modelu
- ✅ Optimalizaci kvantizace modelu
- ✅ Konfiguraci nasazení Foundry Local
- ✅ Ladění výkonu a řešení problémů

---

**Prohlášení**:  
Tento dokument byl přeložen pomocí služby pro automatický překlad [Co-op Translator](https://github.com/Azure/co-op-translator). Ačkoli se snažíme o přesnost, mějte na paměti, že automatické překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho původním jazyce by měl být považován za autoritativní zdroj. Pro důležité informace doporučujeme profesionální lidský překlad. Neodpovídáme za žádné nedorozumění nebo nesprávné interpretace vyplývající z použití tohoto překladu.