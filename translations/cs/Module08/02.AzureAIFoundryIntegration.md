<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "41d82f77890d1e84c5c1a96a95649973",
  "translation_date": "2025-09-23T01:15:34+00:00",
  "source_file": "Module08/02.AzureAIFoundryIntegration.md",
  "language_code": "cs"
}
-->
# Sezení 2: Vytváření AI řešení s Azure AI Foundry

## Přehled

Na základě vašich znalostí z Foundry Local se toto sezení zaměřuje na vytváření pokročilých AI řešení prostřednictvím pokročilého návrhu promptů, bezproblémové integrace dat a automatizace úkolů. Naučíte se propojit lokální vývoj s možnostmi Azure AI Foundry a vytvářet podnikové aplikace, které využívají to nejlepší z obou světů.

## Cíle učení

Na konci tohoto sezení budete schopni:
- Ovládnout pokročilé techniky návrhu promptů pro konzistentní a spolehlivé odpovědi AI
- Implementovat robustní vzory integrace dat pro reálné aplikace
- Vytvářet akční AI úkoly, které přinášejí obchodní hodnotu
- Zajistit bezproblémové propojení mezi Foundry Local a Azure AI Foundry
- Vytvořit pracovní postupy pro monitorování výkonu a optimalizaci
- Nasadit AI řešení připravená pro produkci s odpovídajícím zpracováním chyb a škálováním

## Požadavky

- Dokončené Sezení 1: Začínáme s Foundry Local
- Aktivní instalace Foundry Local s běžícími modely
- Účet Azure (dostatečný je bezplatný tarif pro učení)
- Základní znalost REST API a JSON

## Část 1: Pokročilý návrh promptů

### Pochopení architektury promptů

Efektivní návrh promptů je základem spolehlivých AI aplikací. Foundry Local poskytuje rozšířené možnosti návrhu promptů:

```python
# prompt_engineering.py
class AdvancedPromptTemplates:
    
    @staticmethod
    def create_system_prompt(role, context, constraints):
        """Create structured system prompts for consistent behavior"""
        return f"""You are a {role}.

Context: {context}

Your constraints:
{constraints}

Always respond in a structured, professional manner."""

    @staticmethod
    def few_shot_template(task, examples, input_data):
        """Implement few-shot learning patterns"""
        prompt = f"Task: {task}\n\n"
        
        for i, example in enumerate(examples, 1):
            prompt += f"Example {i}:\n"
            prompt += f"Input: {example['input']}\n"
            prompt += f"Output: {example['output']}\n\n"
        
        prompt += f"Now apply this pattern:\nInput: {input_data}\nOutput:"
        return prompt
    
    @staticmethod
    def chain_of_thought_prompt(problem, reasoning_steps):
        """Implement Chain-of-Thought reasoning"""
        return f"""Problem: {problem}

Let's think through this step by step:

{reasoning_steps}

Based on this reasoning, the answer is:"""
```

### Implementace strategií promptů

```python
# foundry_prompt_engine.py
import requests
import json
from typing import Dict, List, Optional

class FoundryPromptEngine:
    def __init__(self, base_url="http://localhost:8000", model="phi-4-mini"):
        self.base_url = base_url
        self.model = model
        self.conversation_history = []
    
    def structured_completion(self, 
                            system_prompt: str,
                            user_prompt: str,
                            temperature: float = 0.7,
                            max_tokens: int = 500) -> Dict:
        """Execute structured completions with system prompts"""
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens,
            "response_format": {"type": "json_object"}  # For structured outputs
        }
        
        try:
            response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            return {"error": str(e)}
    
    def batch_prompting(self, prompts: List[str], **kwargs) -> List[Dict]:
        """Process multiple prompts efficiently"""
        results = []
        
        for prompt in prompts:
            result = self.structured_completion(
                system_prompt="You are a helpful assistant.",
                user_prompt=prompt,
                **kwargs
            )
            results.append(result)
        
        return results
    
    def adaptive_prompting(self, task: str, complexity: str = "medium") -> str:
        """Adapt prompts based on task complexity"""
        
        complexity_templates = {
            "simple": "Please provide a brief answer to: {task}",
            "medium": "Please provide a detailed explanation for: {task}\nInclude examples where relevant.",
            "complex": """Please provide a comprehensive analysis of: {task}
            
Structure your response as follows:
1. Overview
2. Key concepts
3. Examples
4. Implications
5. Conclusion"""
        }
        
        return complexity_templates.get(complexity, complexity_templates["medium"]).format(task=task)
```

### Praktické příklady návrhu promptů

```python
# examples/business_intelligence.py
from foundry_prompt_engine import FoundryPromptEngine

def create_business_analyst():
    """Create a specialized business intelligence assistant"""
    
    engine = FoundryPromptEngine()
    
    system_prompt = """You are an expert business intelligence analyst with 15 years of experience.
    
Your expertise includes:
- Financial analysis and forecasting
- Market research and competitive analysis
- Data visualization recommendations
- KPI development and tracking
- Strategic planning support

Always provide:
1. Clear, actionable insights
2. Supporting data or reasoning
3. Next steps or recommendations
4. Risk assessment where relevant

Format responses in clear sections with bullet points for easy consumption."""

    def analyze_business_data(data_description: str, question: str) -> str:
        user_prompt = f"""
Data Context: {data_description}

Business Question: {question}

Please provide a comprehensive analysis including trends, insights, and actionable recommendations."""

        response = engine.structured_completion(system_prompt, user_prompt)
        return response.get("choices", [{}])[0].get("message", {}).get("content", "Error in analysis")
    
    return analyze_business_data

# Usage example
analyst = create_business_analyst()
result = analyst(
    "Sales data showing 15% decline in Q3 across all product lines",
    "What are the potential causes and what actions should we take?"
)
print(result)
```

## Část 2: Vzory integrace dat

### Datové konektory Foundry Local

```python
# data_integration.py
import sqlite3
import pandas as pd
import json
from pathlib import Path
from typing import Any, Dict, List

class FoundryDataIntegration:
    def __init__(self, cache_dir="./data_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
    def connect_sqlite(self, db_path: str) -> sqlite3.Connection:
        """Connect to SQLite database"""
        return sqlite3.connect(db_path)
    
    def load_csv_data(self, file_path: str, **kwargs) -> pd.DataFrame:
        """Load and cache CSV data"""
        cache_file = self.cache_dir / f"{Path(file_path).stem}_cached.json"
        
        if cache_file.exists():
            return pd.read_json(cache_file)
        
        df = pd.read_csv(file_path, **kwargs)
        df.to_json(cache_file)
        return df
    
    def prepare_context_data(self, data: pd.DataFrame, max_rows: int = 100) -> str:
        """Prepare data for AI context"""
        
        # Sample data if too large
        if len(data) > max_rows:
            sample_data = data.sample(n=max_rows)
        else:
            sample_data = data
        
        # Create structured context
        context = {
            "shape": data.shape,
            "columns": list(data.columns),
            "dtypes": data.dtypes.to_dict(),
            "sample_data": sample_data.to_dict(orient="records")[:10],
            "summary_statistics": data.describe().to_dict() if data.select_dtypes(include=['number']).shape[1] > 0 else {}
        }
        
        return json.dumps(context, indent=2, default=str)
    
    def create_data_aware_prompt(self, data_context: str, question: str) -> str:
        """Create prompts that include data context"""
        
        return f"""You have access to the following dataset:

Dataset Information:
{data_context}

Question: {question}

Please analyze this data and provide insights. Reference specific data points and patterns you observe."""
```

### Příklad integrace dat v reálném světě

```python
# examples/customer_analysis.py
import pandas as pd
from foundry_prompt_engine import FoundryPromptEngine
from data_integration import FoundryDataIntegration

class CustomerInsightEngine:
    def __init__(self):
        self.prompt_engine = FoundryPromptEngine()
        self.data_integration = FoundryDataIntegration()
    
    def analyze_customer_data(self, csv_file: str, analysis_question: str) -> Dict:
        """Complete customer data analysis workflow"""
        
        # Load and prepare data
        df = self.data_integration.load_csv_data(csv_file)
        data_context = self.data_integration.prepare_context_data(df)
        
        # Create specialized system prompt
        system_prompt = """You are a customer analytics expert specializing in:
- Customer segmentation and behavior analysis
- Churn prediction and retention strategies
- Revenue optimization and pricing analysis
- Customer lifetime value calculation

Provide specific, actionable insights based on the data patterns you observe."""

        # Create data-aware prompt
        user_prompt = self.data_integration.create_data_aware_prompt(data_context, analysis_question)
        
        # Get AI analysis
        ai_response = self.prompt_engine.structured_completion(
            system_prompt, 
            user_prompt,
            temperature=0.3  # Lower temperature for analytical tasks
        )
        
        # Combine with statistical analysis
        statistical_summary = {
            "total_customers": len(df),
            "numeric_summary": df.describe().to_dict(),
            "categorical_summary": {col: df[col].value_counts().to_dict() 
                                  for col in df.select_dtypes(include=['object']).columns}
        }
        
        return {
            "ai_insights": ai_response.get("choices", [{}])[0].get("message", {}).get("content", ""),
            "statistical_analysis": statistical_summary,
            "data_quality": {
                "missing_values": df.isnull().sum().to_dict(),
                "duplicate_rows": df.duplicated().sum()
            }
        }

# Example usage
def demo_customer_analysis():
    """Demo customer analysis with sample data"""
    
    # Create sample customer data
    sample_data = pd.DataFrame({
        'customer_id': range(1, 1001),
        'age': pd.np.random.randint(18, 80, 1000),
        'purchase_amount': pd.np.random.normal(150, 50, 1000),
        'days_since_last_purchase': pd.np.random.randint(1, 365, 1000),
        'product_category': pd.np.random.choice(['Electronics', 'Clothing', 'Books', 'Home'], 1000),
        'satisfaction_score': pd.np.random.randint(1, 6, 1000)
    })
    
    sample_data.to_csv('sample_customers.csv', index=False)
    
    # Analyze
    engine = CustomerInsightEngine()
    results = engine.analyze_customer_data(
        'sample_customers.csv',
        "What customer segments exist and what retention strategies would you recommend?"
    )
    
    return results
```

## Část 3: Akční AI úkoly

### Rámec pro automatizaci úkolů

```python
# task_automation.py
from typing import Callable, Dict, List, Any
import schedule
import time
from datetime import datetime
import logging

class FoundryTaskAutomation:
    def __init__(self):
        self.tasks = {}
        self.results_history = []
        self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('foundry_tasks.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def register_task(self, 
                     task_id: str, 
                     task_function: Callable,
                     schedule_pattern: str = None,
                     dependencies: List[str] = None):
        """Register an automated task"""
        
        self.tasks[task_id] = {
            'function': task_function,
            'schedule': schedule_pattern,
            'dependencies': dependencies or [],
            'last_run': None,
            'status': 'registered'
        }
        
        if schedule_pattern:
            self._schedule_task(task_id, schedule_pattern)
    
    def _schedule_task(self, task_id: str, pattern: str):
        """Schedule task execution"""
        
        def execute_task():
            return self.execute_task(task_id)
        
        if pattern == "daily":
            schedule.every().day.at("09:00").do(execute_task)
        elif pattern == "hourly":
            schedule.every().hour.do(execute_task)
        elif pattern.startswith("every"):
            # Custom patterns: "every 30 minutes", "every 2 hours"
            parts = pattern.split()
            if len(parts) >= 3:
                interval = int(parts[1])
                unit = parts[2].rstrip('s')  # Remove plural
                
                if unit == "minute":
                    schedule.every(interval).minutes.do(execute_task)
                elif unit == "hour":
                    schedule.every(interval).hours.do(execute_task)
    
    def execute_task(self, task_id: str) -> Dict[str, Any]:
        """Execute a specific task"""
        
        if task_id not in self.tasks:
            return {"error": f"Task {task_id} not found"}
        
        task = self.tasks[task_id]
        
        # Check dependencies
        for dep_id in task['dependencies']:
            if dep_id not in self.tasks or self.tasks[dep_id]['status'] != 'completed':
                return {"error": f"Dependency {dep_id} not satisfied"}
        
        try:
            self.logger.info(f"Executing task: {task_id}")
            task['status'] = 'running'
            
            # Execute the task function
            result = task['function'](../../../Module08)
            
            # Update task status
            task['status'] = 'completed'
            task['last_run'] = datetime.now()
            
            # Store result
            task_result = {
                'task_id': task_id,
                'timestamp': datetime.now(),
                'result': result,
                'status': 'success'
            }
            
            self.results_history.append(task_result)
            self.logger.info(f"Task {task_id} completed successfully")
            
            return task_result
            
        except Exception as e:
            error_result = {
                'task_id': task_id,
                'timestamp': datetime.now(),
                'error': str(e),
                'status': 'error'
            }
            
            task['status'] = 'error'
            self.results_history.append(error_result)
            self.logger.error(f"Task {task_id} failed: {str(e)}")
            
            return error_result
    
    def run_scheduler(self):
        """Run the task scheduler"""
        self.logger.info("Starting Foundry task scheduler")
        
        while True:
            schedule.run_pending()
            time.sleep(60)  # Check every minute
```

### Příklady automatizace obchodních procesů

```python
# examples/business_automation.py
from foundry_prompt_engine import FoundryPromptEngine
from task_automation import FoundryTaskAutomation
import pandas as pd
import smtplib
from email.mime.text import MIMEText

class BusinessProcessAutomation:
    def __init__(self):
        self.prompt_engine = FoundryPromptEngine()
        self.task_automation = FoundryTaskAutomation()
        self.setup_business_tasks()
    
    def setup_business_tasks(self):
        """Register common business automation tasks"""
        
        # Daily sales report
        self.task_automation.register_task(
            "daily_sales_report",
            self.generate_sales_report,
            "daily"
        )
        
        # Hourly customer sentiment monitoring
        self.task_automation.register_task(
            "sentiment_monitoring",
            self.monitor_customer_sentiment,
            "hourly"
        )
        
        # Weekly competitor analysis
        self.task_automation.register_task(
            "competitor_analysis",
            self.analyze_competitors,
            "every 7 days"
        )
    
    def generate_sales_report(self) -> Dict[str, Any]:
        """Automated daily sales report generation"""
        
        # Simulate data loading (replace with actual data source)
        sales_data = pd.DataFrame({
            'date': pd.date_range('2024-01-01', periods=30),
            'revenue': pd.np.random.normal(10000, 2000, 30),
            'orders': pd.np.random.randint(50, 200, 30),
            'new_customers': pd.np.random.randint(10, 50, 30)
        })
        
        # AI-powered analysis
        system_prompt = """You are a sales analyst expert. Analyze daily sales data and provide:
1. Key performance indicators
2. Trends and patterns
3. Recommendations for improvement
4. Risk factors to watch

Format your response as a professional daily sales report."""

        latest_data = sales_data.tail(7)  # Last 7 days
        data_summary = f"""
Recent Sales Performance:
- Average daily revenue: ${latest_data['revenue'].mean():.2f}
- Average daily orders: {latest_data['orders'].mean():.1f}
- Average new customers: {latest_data['new_customers'].mean():.1f}
- Revenue trend: {((latest_data['revenue'].iloc[-1] / latest_data['revenue'].iloc[0]) - 1) * 100:.1f}%
"""

        response = self.prompt_engine.structured_completion(
            system_prompt,
            f"Analyze this sales data and create a daily report:\n{data_summary}"
        )
        
        report_content = response.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        # Send report (implement email sending)
        self.send_report_email("daily_sales_report", report_content)
        
        return {
            "report_type": "daily_sales",
            "data_period": "last_7_days",
            "report_content": report_content,
            "recipients": ["sales@company.com", "management@company.com"]
        }
    
    def monitor_customer_sentiment(self) -> Dict[str, Any]:
        """Automated customer sentiment monitoring"""
        
        # Simulate customer feedback data
        feedback_data = [
            "Great product, fast delivery!",
            "Customer service was not helpful",
            "Love the new features, very intuitive",
            "Pricing seems too high for the value",
            "Outstanding quality, will buy again"
        ]
        
        system_prompt = """You are a customer experience analyst. Analyze customer feedback and provide:
1. Overall sentiment score (1-10)
2. Key themes and concerns
3. Actionable recommendations
4. Priority issues to address

Be specific and actionable in your recommendations."""

        user_prompt = f"""Analyze this customer feedback data:

{chr(10).join([f"- {feedback}" for feedback in feedback_data])}

Provide a comprehensive sentiment analysis report."""

        response = self.prompt_engine.structured_completion(system_prompt, user_prompt)
        
        analysis = response.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        return {
            "analysis_type": "customer_sentiment",
            "feedback_count": len(feedback_data),
            "sentiment_analysis": analysis,
            "timestamp": datetime.now()
        }
    
    def analyze_competitors(self) -> Dict[str, Any]:
        """Weekly competitor analysis"""
        
        # Simulate competitor data
        competitor_data = {
            "Competitor A": {
                "pricing": "15% lower than us",
                "features": "Similar feature set, missing AI capabilities",
                "market_share": "22%",
                "recent_updates": "Launched mobile app last month"
            },
            "Competitor B": {
                "pricing": "25% higher than us",
                "features": "Premium features, enterprise focus",
                "market_share": "18%",
                "recent_updates": "Acquired smaller competitor"
            }
        }
        
        system_prompt = """You are a competitive intelligence analyst. Analyze competitor data and provide:
1. Competitive positioning assessment
2. Threats and opportunities
3. Strategic recommendations
4. Market trends analysis

Focus on actionable strategic insights."""

        user_prompt = f"""Analyze this competitive landscape:

{json.dumps(competitor_data, indent=2)}

Provide strategic recommendations for maintaining competitive advantage."""

        response = self.prompt_engine.structured_completion(system_prompt, user_prompt)
        
        return {
            "analysis_type": "competitive_intelligence",
            "competitors_analyzed": len(competitor_data),
            "strategic_analysis": response.get("choices", [{}])[0].get("message", {}).get("content", ""),
            "next_review_date": (datetime.now() + timedelta(days=7)).isoformat()
        }
    
    def send_report_email(self, report_type: str, content: str):
        """Send automated reports via email"""
        # Implementation depends on your email setup
        pass
```

## Část 4: Integrace Azure AI Foundry

### Zajištění propojení

```python
# azure_integration.py
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
import requests
import json

class AzureFoundryBridge:
    def __init__(self, project_connection_string: str = None):
        self.credential = DefaultAzureCredential()
        self.project_client = AIProjectClient.from_connection_string(
            conn_str=project_connection_string,
            credential=self.credential
        ) if project_connection_string else None
        
        self.local_base_url = "http://localhost:8000"
    
    def sync_models_to_azure(self, local_models: List[str]) -> Dict[str, Any]:
        """Sync local models to Azure AI Foundry"""
        
        sync_results = {}
        
        for model_name in local_models:
            try:
                # Get local model info
                local_info = self.get_local_model_info(model_name)
                
                # Deploy to Azure (simplified example)
                azure_deployment = self.deploy_to_azure(model_name, local_info)
                
                sync_results[model_name] = {
                    "status": "success",
                    "azure_endpoint": azure_deployment.get("endpoint"),
                    "local_config": local_info
                }
                
            except Exception as e:
                sync_results[model_name] = {
                    "status": "error",
                    "error": str(e)
                }
        
        return sync_results
    
    def get_local_model_info(self, model_name: str) -> Dict[str, Any]:
        """Get information about a local model"""
        
        response = requests.get(f"{self.local_base_url}/v1/models/{model_name}")
        return response.json() if response.status_code == 200 else {}
    
    def deploy_to_azure(self, model_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Deploy model to Azure AI Foundry"""
        
        if not self.project_client:
            return {"error": "Azure project client not configured"}
        
        # This is a simplified example - actual implementation depends on Azure AI Foundry APIs
        deployment_config = {
            "model_name": model_name,
            "instance_type": config.get("recommended_instance", "Standard_DS3_v2"),
            "scale_settings": {
                "scale_type": "Manual",
                "instance_count": 1
            }
        }
        
        # Deploy using Azure AI Foundry client
        # deployment = self.project_client.deployments.create(deployment_config)
        
        return {
            "endpoint": f"https://{model_name}.azureml.net/v1/",
            "deployment_id": f"deployment-{model_name}-001",
            "status": "deploying"
        }
    
    def hybrid_inference(self, 
                        prompt: str, 
                        prefer_local: bool = True,
                        fallback_to_azure: bool = True) -> Dict[str, Any]:
        """Perform inference with local-first, Azure fallback strategy"""
        
        if prefer_local:
            try:
                # Try local inference first
                local_response = requests.post(
                    f"{self.local_base_url}/v1/completions",
                    json={
                        "model": "phi-4-mini",
                        "prompt": prompt,
                        "max_tokens": 500
                    },
                    timeout=10
                )
                
                if local_response.status_code == 200:
                    return {
                        "source": "local",
                        "response": local_response.json(),
                        "latency": "low"
                    }
                    
            except Exception as e:
                if not fallback_to_azure:
                    return {"error": f"Local inference failed: {str(e)}"}
        
        if fallback_to_azure:
            # Fallback to Azure inference
            try:
                # This would use Azure AI Foundry endpoint
                azure_response = self.azure_inference(prompt)
                return {
                    "source": "azure",
                    "response": azure_response,
                    "latency": "medium"
                }
            except Exception as e:
                return {"error": f"Both local and Azure inference failed: {str(e)}"}
        
        return {"error": "No inference method available"}
    
    def azure_inference(self, prompt: str) -> Dict[str, Any]:
        """Perform inference using Azure AI Foundry"""
        # Implementation depends on your Azure setup
        return {"placeholder": "Azure inference result"}
```

### Vzory hybridního nasazení

```python
# hybrid_deployment.py
from azure_integration import AzureFoundryBridge
import asyncio
import aiohttp

class HybridDeploymentManager:
    def __init__(self):
        self.azure_bridge = AzureFoundryBridge()
        self.deployment_strategies = {
            "development": self.dev_strategy,
            "staging": self.staging_strategy,
            "production": self.production_strategy
        }
    
    async def dev_strategy(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Development: Local-only with fast iteration"""
        return await self.local_inference(request)
    
    async def staging_strategy(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Staging: Local primary, Azure backup"""
        local_result = await self.local_inference(request)
        
        if local_result.get("error"):
            return await self.azure_inference(request)
        
        return local_result
    
    async def production_strategy(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Production: Azure primary, local backup for specific scenarios"""
        
        # Route based on request characteristics
        if self.should_use_local(request):
            return await self.local_inference(request)
        else:
            return await self.azure_inference(request)
    
    def should_use_local(self, request: Dict[str, Any]) -> bool:
        """Determine if request should use local inference"""
        
        # Use local for:
        # - Privacy-sensitive requests
        # - Low-latency requirements
        # - Small model tasks
        
        privacy_keywords = ["personal", "confidential", "private", "sensitive"]
        request_text = request.get("prompt", "").lower()
        
        return any(keyword in request_text for keyword in privacy_keywords)
    
    async def local_inference(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Perform local inference"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://localhost:8000/v1/completions",
                json=request
            ) as response:
                return await response.json()
    
    async def azure_inference(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Perform Azure inference"""
        # Implementation depends on Azure AI Foundry setup
        return {"source": "azure", "result": "placeholder"}
```

## Část 5: Monitorování výkonu a optimalizace

### Komplexní monitorovací systém

```python
# monitoring.py
import time
import psutil
import json
from collections import deque
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

class FoundryPerformanceMonitor:
    def __init__(self, history_size: int = 1000):
        self.metrics_history = deque(maxlen=history_size)
        self.alert_thresholds = {
            "response_time": 5.0,  # seconds
            "memory_usage": 85,    # percentage
            "cpu_usage": 90,       # percentage
            "error_rate": 5        # percentage
        }
        self.alerts = []
    
    def record_request(self, 
                      request_id: str,
                      model: str,
                      prompt_length: int,
                      response_length: int,
                      response_time: float,
                      success: bool):
        """Record performance metrics for a request"""
        
        metric = {
            "timestamp": datetime.now(),
            "request_id": request_id,
            "model": model,
            "prompt_length": prompt_length,
            "response_length": response_length,
            "response_time": response_time,
            "success": success,
            "system_metrics": self.get_system_metrics()
        }
        
        self.metrics_history.append(metric)
        self.check_alerts(metric)
    
    def get_system_metrics(self) -> Dict[str, float]:
        """Get current system performance metrics"""
        return {
            "cpu_percent": psutil.cpu_percent(),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_usage": psutil.disk_usage('/').percent,
            "network_sent": psutil.net_io_counters().bytes_sent,
            "network_recv": psutil.net_io_counters().bytes_recv
        }
    
    def check_alerts(self, metric: Dict[str, Any]):
        """Check if current metrics trigger any alerts"""
        
        alerts = []
        
        # Response time alert
        if metric["response_time"] > self.alert_thresholds["response_time"]:
            alerts.append({
                "type": "response_time",
                "severity": "warning",
                "message": f"Response time {metric['response_time']:.2f}s exceeds threshold",
                "timestamp": metric["timestamp"]
            })
        
        # System resource alerts
        system_metrics = metric["system_metrics"]
        
        if system_metrics["memory_percent"] > self.alert_thresholds["memory_usage"]:
            alerts.append({
                "type": "memory_usage",
                "severity": "critical",
                "message": f"Memory usage {system_metrics['memory_percent']:.1f}% is critical",
                "timestamp": metric["timestamp"]
            })
        
        if system_metrics["cpu_percent"] > self.alert_thresholds["cpu_usage"]:
            alerts.append({
                "type": "cpu_usage",
                "severity": "warning",
                "message": f"CPU usage {system_metrics['cpu_percent']:.1f}% is high",
                "timestamp": metric["timestamp"]
            })
        
        self.alerts.extend(alerts)
        
        # Keep only recent alerts
        cutoff_time = datetime.now() - timedelta(hours=24)
        self.alerts = [alert for alert in self.alerts if alert["timestamp"] > cutoff_time]
    
    def generate_performance_report(self) -> Dict[str, Any]:
        """Generate comprehensive performance report"""
        
        if not self.metrics_history:
            return {"error": "No metrics data available"}
        
        recent_metrics = [m for m in self.metrics_history 
                         if m["timestamp"] > datetime.now() - timedelta(hours=24)]
        
        if not recent_metrics:
            return {"error": "No recent metrics data available"}
        
        # Calculate performance statistics
        response_times = [m["response_time"] for m in recent_metrics]
        success_rate = sum(1 for m in recent_metrics if m["success"]) / len(recent_metrics) * 100
        
        model_performance = {}
        for metric in recent_metrics:
            model = metric["model"]
            if model not in model_performance:
                model_performance[model] = []
            model_performance[model].append(metric["response_time"])
        
        # Calculate per-model averages
        model_averages = {
            model: sum(times) / len(times) 
            for model, times in model_performance.items()
        }
        
        return {
            "report_period": "24_hours",
            "total_requests": len(recent_metrics),
            "success_rate": success_rate,
            "average_response_time": sum(response_times) / len(response_times),
            "min_response_time": min(response_times),
            "max_response_time": max(response_times),
            "model_performance": model_averages,
            "active_alerts": len([a for a in self.alerts if a["timestamp"] > datetime.now() - timedelta(hours=1)]),
            "system_health": self.get_system_metrics(),
            "recommendations": self.generate_recommendations(recent_metrics)
        }
    
    def generate_recommendations(self, metrics: List[Dict[str, Any]]) -> List[str]:
        """Generate performance optimization recommendations"""
        
        recommendations = []
        
        # Analyze response times
        response_times = [m["response_time"] for m in metrics]
        avg_response_time = sum(response_times) / len(response_times)
        
        if avg_response_time > 3.0:
            recommendations.append("Consider using model quantization to improve response times")
            recommendations.append("Enable hardware acceleration (NPU/GPU) if available")
        
        # Analyze memory usage
        avg_memory = sum(m["system_metrics"]["memory_percent"] for m in metrics) / len(metrics)
        
        if avg_memory > 80:
            recommendations.append("High memory usage detected - consider reducing batch size or concurrent models")
            recommendations.append("Implement model unloading for unused models")
        
        # Analyze error rates
        error_rate = (1 - sum(1 for m in metrics if m["success"]) / len(metrics)) * 100
        
        if error_rate > 2:
            recommendations.append("Error rate is elevated - check model configurations and input validation")
        
        return recommendations
```

## Část 6: Praktická cvičení

### Cvičení 1: Pokročilý chatbot pro zákaznický servis

```python
# exercises/customer_service_bot.py
from foundry_prompt_engine import FoundryPromptEngine
from data_integration import FoundryDataIntegration

class CustomerServiceBot:
    def __init__(self):
        self.prompt_engine = FoundryPromptEngine()
        self.data_integration = FoundryDataIntegration()
        self.conversation_context = {}
    
    def handle_customer_inquiry(self, customer_id: str, message: str) -> Dict[str, Any]:
        """Handle customer service inquiries with context"""
        
        # Load customer context
        customer_data = self.load_customer_context(customer_id)
        
        # Create specialized system prompt
        system_prompt = f"""You are a professional customer service representative with access to customer data.

Customer Information:
{json.dumps(customer_data, indent=2)}

Guidelines:
1. Be empathetic and professional
2. Use customer's name and purchase history when relevant
3. Provide specific, actionable solutions
4. Escalate complex issues appropriately
5. Always confirm understanding before providing solutions

If you cannot resolve the issue, clearly explain next steps and escalation procedures."""

        # Process the inquiry
        response = self.prompt_engine.structured_completion(
            system_prompt,
            f"Customer message: {message}",
            temperature=0.3
        )
        
        # Log the interaction
        self.log_interaction(customer_id, message, response)
        
        return {
            "customer_id": customer_id,
            "response": response.get("choices", [{}])[0].get("message", {}).get("content", ""),
            "escalation_needed": self.detect_escalation_needed(message, response),
            "satisfaction_prediction": self.predict_satisfaction(message, response)
        }
    
    def load_customer_context(self, customer_id: str) -> Dict[str, Any]:
        """Load relevant customer context"""
        # Simulate customer data loading
        return {
            "name": f"Customer {customer_id}",
            "tier": "Gold",
            "recent_orders": ["Order #12345", "Order #12390"],
            "support_history": "2 previous tickets, both resolved",
            "preferences": "Prefers email communication"
        }
    
    def detect_escalation_needed(self, message: str, response: Dict[str, Any]) -> bool:
        """Detect if human escalation is needed"""
        escalation_keywords = ["angry", "furious", "legal", "lawsuit", "refund", "manager"]
        return any(keyword in message.lower() for keyword in escalation_keywords)
    
    def predict_satisfaction(self, message: str, response: Dict[str, Any]) -> str:
        """Predict customer satisfaction"""
        # Simplified satisfaction prediction
        negative_indicators = ["problem", "issue", "broken", "wrong", "unhappy"]
        negative_count = sum(1 for word in negative_indicators if word in message.lower())
        
        if negative_count > 2:
            return "low"
        elif negative_count > 0:
            return "medium"
        else:
            return "high"

# Exercise implementation
def exercise_1():
    bot = CustomerServiceBot()
    
    test_scenarios = [
        ("CUST001", "I received the wrong item in my order #12345"),
        ("CUST002", "The product I bought last week is already broken"),
        ("CUST003", "I love the new features in the latest update!")
    ]
    
    for customer_id, message in test_scenarios:
        result = bot.handle_customer_inquiry(customer_id, message)
        print(f"Customer {customer_id}: {message}")
        print(f"Response: {result['response']}")
        print(f"Escalation needed: {result['escalation_needed']}")
        print("-" * 50)
```

### Cvičení 2: Automatizovaný průzkum trhu

```python
# exercises/market_research.py
from foundry_prompt_engine import FoundryPromptEngine
import requests
from datetime import datetime

class MarketResearchEngine:
    def __init__(self):
        self.prompt_engine = FoundryPromptEngine()
    
    def analyze_market_trend(self, industry: str, timeframe: str = "6 months") -> Dict[str, Any]:
        """Analyze market trends for a specific industry"""
        
        # Simulate market data (replace with real data sources)
        market_data = self.fetch_market_data(industry, timeframe)
        
        system_prompt = """You are a senior market research analyst with expertise in trend analysis and competitive intelligence.

Provide comprehensive market analysis including:
1. Key trends and drivers
2. Market size and growth projections
3. Competitive landscape
4. Opportunities and threats
5. Strategic recommendations

Use data-driven insights and industry expertise."""

        user_prompt = f"""Analyze the {industry} market for the {timeframe} period:

Market Data:
{json.dumps(market_data, indent=2)}

Provide a comprehensive market analysis report."""

        response = self.prompt_engine.structured_completion(system_prompt, user_prompt)
        
        return {
            "industry": industry,
            "timeframe": timeframe,
            "analysis": response.get("choices", [{}])[0].get("message", {}).get("content", ""),
            "data_sources": market_data.get("sources", []),
            "confidence_score": self.calculate_confidence_score(market_data),
            "generated_at": datetime.now().isoformat()
        }
    
    def fetch_market_data(self, industry: str, timeframe: str) -> Dict[str, Any]:
        """Fetch market data from various sources"""
        # Simulate market data
        return {
            "market_size": "$50B",
            "growth_rate": "12.5% YoY",
            "key_players": ["Company A", "Company B", "Company C"],
            "emerging_trends": ["AI adoption", "Sustainability focus", "Remote work impact"],
            "sources": ["Industry Report X", "Market Survey Y", "Government Data Z"]
        }
    
    def calculate_confidence_score(self, data: Dict[str, Any]) -> float:
        """Calculate confidence score based on data quality"""
        # Simplified confidence calculation
        source_count = len(data.get("sources", []))
        return min(0.9, 0.3 + (source_count * 0.2))

# Exercise implementation
def exercise_2():
    research_engine = MarketResearchEngine()
    
    industries = ["FinTech", "HealthTech", "EdTech"]
    
    for industry in industries:
        result = research_engine.analyze_market_trend(industry)
        print(f"Market Analysis for {industry}:")
        print(f"Confidence Score: {result['confidence_score']:.2f}")
        print(f"Analysis: {result['analysis'][:200]}...")
        print("-" * 50)
```

## Část 7: Další kroky a náhled na Sezení 3

### Úspěchy sezení

V tomto sezení jste zvládli:
- ✅ Pokročilé techniky návrhu promptů pro konzistentní chování AI
- ✅ Robustní vzory integrace dat pro reálné aplikace
- ✅ Automatizaci úkolů pro optimalizaci obchodních procesů
- ✅ Integraci Azure AI Foundry a strategie hybridního nasazení
- ✅ Komplexní monitorování výkonu a optimalizaci

### Příprava na Sezení 3: Open-Source modely

1. **Prozkoumejte Hugging Face**: Vytvořte si účet a prohlédněte si katalog modelů
2. **Projděte si Model Mondays**: Podívejte se na nejnovější [sérii Model Mondays](https://aka.ms/model-mondays)
3. **Plánujte vlastní modely**: Zvažte, jaké specializované modely by mohly být přínosné pro vaše případy použití

### Další zdroje

- [Dokumentace Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)
- [GitHub repozitář Foundry Local](https://github.com/microsoft/Foundry-Local)
- [Pokročilý průvodce návrhem promptů](https://platform.openai.com/docs/guides/prompt-engineering)
- [Nejlepší postupy pro automatizaci obchodních procesů](https://docs.microsoft.com/en-us/power-automate/)

Nyní jste vybaveni k vytváření sofistikovaných AI řešení, která kombinují sílu lokální inference s možnostmi cloudového měřítka, čímž pokládáte základy pro podnikové AI aplikace.

---

