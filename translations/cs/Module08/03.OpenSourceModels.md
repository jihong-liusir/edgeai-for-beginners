<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1b09b5c867abbccfdbc826d857ae0c2",
  "translation_date": "2025-09-25T01:18:52+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "cs"
}
-->
# Sezení 3: Objevování a správa open-source modelů

## Přehled

Toto sezení se zaměřuje na praktické objevování a správu modelů pomocí Foundry Local. Naučíte se, jak zobrazit dostupné modely, testovat různé možnosti a porozumět základním charakteristikám výkonu. Přístup klade důraz na praktické zkoumání pomocí příkazového řádku Foundry CLI, které vám pomůže vybrat správné modely pro vaše použití.

## Cíle učení

- Ovládnout příkazy Foundry CLI pro objevování a správu modelů
- Porozumět vzorcům ukládání modelů do mezipaměti a místního úložiště
- Naučit se rychle testovat a porovnávat různé modely
- Vytvořit praktické pracovní postupy pro výběr a benchmarking modelů
- Prozkoumat rostoucí ekosystém modelů dostupných prostřednictvím Foundry Local

## Předpoklady

- Dokončené sezení 1: Začínáme s Foundry Local
- Nainstalovaný a dostupný Foundry Local CLI
- Dostatečný úložný prostor pro stahování modelů (modely mohou mít velikost od 1 GB do 20 GB+)
- Základní porozumění typům modelů a jejich použití

## Část 6: Praktické cvičení

### Cvičení: Objevování a porovnávání modelů

Vytvořte vlastní skript pro hodnocení modelů na základě vzoru Sample 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Vaše úkoly

1. **Spusťte skript Sample 03**: `samples\03\list_and_bench.cmd`
2. **Vyzkoušejte různé modely**: Otestujte alespoň 3 různé modely
3. **Porovnejte výkon**: Zaznamenejte rozdíly v rychlosti a kvalitě odpovědí
4. **Zdokumentujte zjištění**: Vytvořte jednoduchý porovnávací graf

### Příklad formátu porovnání

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## Část 7: Řešení problémů a osvědčené postupy

### Běžné problémy a jejich řešení

**Model se nespustí:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Nedostatek paměti:**
- Začněte s menšími modely (`phi-4-mini`)
- Zavřete ostatní aplikace
- Upgradujte RAM, pokud často narážíte na limity

**Pomalejší výkon:**
- Ujistěte se, že model je plně načten (zkontrolujte podrobný výstup)
- Zavřete nepotřebné aplikace na pozadí
- Zvažte rychlejší úložiště (SSD)

### Osvědčené postupy

1. **Začněte s malými modely**: Použijte `phi-4-mini` k ověření nastavení
2. **Jeden model najednou**: Zastavte předchozí modely před spuštěním nových
3. **Sledujte zdroje**: Mějte přehled o využití paměti
4. **Testujte konzistentně**: Používejte stejné výzvy pro spravedlivé porovnání
5. **Dokumentujte výsledky**: Vedení poznámek o výkonu modelů pro vaše použití

## Část 8: Další kroky a odkazy

### Příprava na sezení 4

- **Zaměření sezení 4**: Nástroje a techniky optimalizace
- **Předpoklady**: Pohodlná práce s přepínáním modelů a základním testováním výkonu
- **Doporučení**: Identifikujte 2-3 oblíbené modely z tohoto sezení

### Další zdroje

- **[Foundry Local Dokumentace](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Oficiální dokumentace
- **[CLI Reference](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Kompletní referenční příručka příkazů
- **[Model Mondays](https://aka.ms/model-mondays)**: Týdenní přehled modelů
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Komunita a problémy
- **[Sample 03: Model Discovery](samples/03/README.md)**: Praktický ukázkový skript

### Klíčové poznatky

✅ **Objevování modelů**: Použijte `foundry model list` k prozkoumání dostupných modelů  
✅ **Rychlé testování**: Vzor `list_and_bench.cmd` pro rychlé hodnocení  
✅ **Monitorování výkonu**: Základní měření využití zdrojů a doby odezvy  
✅ **Výběr modelů**: Praktické pokyny pro výběr modelů podle použití  
✅ **Správa mezipaměti**: Porozumění úložišti a postupům čištění  

Nyní máte praktické dovednosti pro objevování, testování a výběr vhodných modelů pro vaše AI aplikace pomocí jednoduchého přístupu Foundry Local CLI.

## Cíle učení

- Objevovat a hodnotit open-source modely pro místní inference
- Kompilovat a spouštět vybrané modely Hugging Face v Foundry Local
- Používat strategie výběru modelů pro přesnost, latenci a potřeby zdrojů
- Spravovat modely lokálně pomocí mezipaměti a verzování

## Část 1: Objevování modelů pomocí Foundry CLI

### Základní příkazy pro správu modelů

Foundry CLI poskytuje jednoduché příkazy pro objevování a správu modelů:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Spuštění prvních modelů

Začněte s populárními, dobře otestovanými modely, abyste porozuměli charakteristikám výkonu:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b-instruct --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-distill-qwen-7b --verbose
```

**Poznámka:** Příznak `--verbose` poskytuje podrobné informace o spuštění, včetně:
- Postupu stahování modelu (při prvním spuštění)
- Podrobností o alokaci paměti
- Informací o připojení služby
- Metrik inicializace výkonu

### Porozumění kategoriím modelů

**Malé jazykové modely (SLMs):**
- `phi-4-mini`: Rychlý, efektivní, skvělý pro obecný chat
- `phi-4`: Schopnější verze s lepším uvažováním

**Střední modely:**
- `qwen2.5-7b-instruct`: Vynikající uvažování a delší kontext
- `deepseek-r1-distill-qwen-7b`: Optimalizovaný pro generování kódu

**Velké modely:**
- `llama-3.2`: Nejnovější open-source model od Meta
- `qwen2.5-14b-instruct`: Podniková úroveň uvažování

## Část 2: Rychlé testování a porovnávání modelů

### Přístup Sample 03: Jednoduchý seznam a benchmark

Na základě vzoru Sample 03 je zde minimální pracovní postup:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Testování výkonu modelů

Jakmile model běží, testujte jej s konzistentními výzvami:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### Alternativa testování v PowerShellu

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## Část 3: Správa mezipaměti a úložiště modelů

### Porozumění mezipaměti modelů

Foundry Local automaticky spravuje stahování a ukládání modelů do mezipaměti:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Úvahy o úložišti modelů

**Typické velikosti modelů:**
- `phi-4-mini`: ~2,5 GB
- `qwen2.5-7b-instruct`: ~4,1 GB  
- `deepseek-r1-distill-qwen-7b`: ~4,3 GB
- `llama-3.2`: ~4,9 GB
- `qwen2.5-14b-instruct`: ~8,2 GB

**Osvědčené postupy pro úložiště:**
- Uchovávejte 2-3 modely v mezipaměti pro rychlé přepínání
- Odstraňte nepoužívané modely pro uvolnění místa: `foundry cache clean`
- Sledujte využití disku, zejména na menších SSD
- Zvažte kompromis mezi velikostí modelu a jeho schopnostmi

### Monitorování výkonu modelů

Během běhu modelů sledujte systémové zdroje:

**Správce úloh Windows:**
- Sledujte využití paměti (modely zůstávají načtené v RAM)
- Monitorujte využití CPU během inference
- Zkontrolujte diskové I/O během počátečního načítání modelu

**Monitorování z příkazového řádku:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## Část 4: Praktické pokyny pro výběr modelů

### Výběr modelů podle použití

**Pro obecný chat a otázky a odpovědi:**
- Začněte s: `phi-4-mini` (rychlý, efektivní)
- Přesuňte se na: `phi-4` (lepší uvažování)
- Pokročilé: `qwen2.5-7b-instruct` (delší kontext)

**Pro generování kódu:**
- Doporučeno: `deepseek-r1-distill-qwen-7b`
- Alternativa: `qwen2.5-7b-instruct` (také dobrý pro kód)

**Pro složité uvažování:**
- Nejlepší: `qwen2.5-7b-instruct` nebo `qwen2.5-14b-instruct`
- Cenově dostupná možnost: `phi-4`

### Průvodce požadavky na hardware

**Minimální systémové požadavky:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Doporučeno pro nejlepší výkon:**
- 32 GB+ RAM pro pohodlné přepínání mezi modely
- SSD úložiště pro rychlejší načítání modelů
- Moderní CPU s dobrým výkonem na jedno vlákno
- Podpora NPU (PC s Windows 11 Copilot+) pro akceleraci

### Pracovní postup přepínání modelů

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b-instruct

REM Verify model is running
foundry service status
```

## Část 5: Jednoduché benchmarkování modelů

### Základní testování výkonu

Zde je jednoduchý přístup k porovnání výkonu modelů:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b-instruct", "deepseek-r1-distill-qwen-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Manuální hodnocení kvality

Pro každý model testujte s konzistentními výzvami a manuálně vyhodnocujte:

**Testovací výzvy:**
1. "Vysvětlete kvantové počítání jednoduchými slovy."
2. "Napište Python funkci pro seřazení seznamu."
3. "Jaké jsou výhody a nevýhody práce na dálku?"
4. "Shrňte výhody edge AI."

**Kritéria hodnocení:**
- **Přesnost**: Jsou informace správné?
- **Srozumitelnost**: Je vysvětlení snadno pochopitelné?
- **Úplnost**: Řeší to celou otázku?
- **Rychlost**: Jak rychle odpovídá?

### Monitorování využití zdrojů

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## Část 6: Další kroky

- Přihlaste se k odběru Model Mondays pro nové modely a tipy: https://aka.ms/model-mondays
- Přispějte svými zjištěními do týmového `models.json`
- Připravte se na sezení 4: porovnání LLM vs SLM, místní vs cloudová inference a praktické ukázky

---

