<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-25T01:21:42+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "cs"
}
-->
# Uk√°zka 04: Produkƒçn√≠ chatovac√≠ aplikace s Chainlit

Komplexn√≠ uk√°zka p≈ôedstavuj√≠c√≠ r≈Øzn√© p≈ô√≠stupy k vytv√°≈ôen√≠ produkƒçnƒõ p≈ôipraven√Ωch chatovac√≠ch aplikac√≠ pomoc√≠ Microsoft Foundry Local, zahrnuj√≠c√≠ modern√≠ webov√© rozhran√≠, streamovan√© odpovƒõdi a nejnovƒõj≈°√≠ technologie prohl√≠≈æeƒç≈Ø.

## Co je zahrnuto

- **üöÄ Chainlit Chat App** (`app.py`): Produkƒçnƒõ p≈ôipraven√° chatovac√≠ aplikace se streamov√°n√≠m
- **üåê WebGPU Demo** (`webgpu-demo/`): AI inference v prohl√≠≈æeƒçi s hardwarovou akcelerac√≠
- **üé® Integrace Open WebUI** (`open-webui-guide.md`): Profesion√°ln√≠ rozhran√≠ podobn√© ChatGPT
- **üìö Edukaƒçn√≠ notebook** (`chainlit_app.ipynb`): Interaktivn√≠ v√Ωukov√© materi√°ly

## Rychl√Ω start

### 1. Chainlit Chat Application

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Otev≈ôe se na: `http://localhost:8080`

### 2. WebGPU Browser Demo

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Otev≈ôe se na: `http://localhost:5173`

### 3. Nastaven√≠ Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Otev≈ôe se na: `http://localhost:3000`

## Architektonick√© vzory

### Rozhodovac√≠ matice: Lok√°ln√≠ vs. cloud

| Sc√©n√°≈ô | Doporuƒçen√≠ | D≈Øvod |
|--------|------------|-------|
| **Citliv√° data** | üè† Lok√°ln√≠ (Foundry) | Data nikdy neopou≈°t√≠ za≈ô√≠zen√≠ |
| **Komplexn√≠ uva≈æov√°n√≠** | ‚òÅÔ∏è Cloud (Azure OpenAI) | P≈ô√≠stup k vƒõt≈°√≠m model≈Øm |
| **Chat v re√°ln√©m ƒçase** | üè† Lok√°ln√≠ (Foundry) | Ni≈æ≈°√≠ latence, rychlej≈°√≠ odpovƒõdi |
| **Anal√Ωza dokument≈Ø** | üîÑ Hybrid | Lok√°ln√≠ pro extrakci, cloud pro anal√Ωzu |
| **Generov√°n√≠ k√≥du** | üè† Lok√°ln√≠ (Foundry) | Soukrom√≠ + specializovan√© modely |
| **V√Ωzkumn√© √∫koly** | ‚òÅÔ∏è Cloud (Azure OpenAI) | Pot≈ôeba ≈°irok√© znalostn√≠ b√°ze |

### Porovn√°n√≠ technologi√≠

| Technologie | Pou≈æit√≠ | V√Ωhody | Nev√Ωhody |
|-------------|---------|--------|----------|
| **Chainlit** | Python v√Ωvoj√°≈ôi, rychl√© prototypov√°n√≠ | Snadn√© nastaven√≠, podpora streamov√°n√≠ | Pouze Python |
| **WebGPU** | Maxim√°ln√≠ soukrom√≠, offline sc√©n√°≈ôe | Nativn√≠ prohl√≠≈æeƒç, nen√≠ pot≈ôeba server | Omezen√° velikost modelu |
| **Open WebUI** | Produkƒçn√≠ nasazen√≠, t√Ωmy | Profesion√°ln√≠ UI, spr√°va u≈æivatel≈Ø | Vy≈æaduje Docker |

## P≈ôedpoklady

- **Foundry Local**: Nainstalov√°no a spu≈°tƒõno ([St√°hnout](https://aka.ms/foundry-local-installer))
- **Python**: Verze 3.10+ s virtu√°ln√≠m prost≈ôed√≠m
- **Model**: Alespo≈à jeden naƒçten√Ω (`foundry model run phi-4-mini`)
- **Prohl√≠≈æeƒç**: Chrome/Edge s podporou WebGPU pro demo
- **Docker**: Pro Open WebUI (voliteln√©)

## Instalace a nastaven√≠

### 1. Nastaven√≠ Python prost≈ôed√≠

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Nastaven√≠ Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## Uk√°zkov√© aplikace

### Chainlit Chat Application

**Funkce:**
- üöÄ **Streamov√°n√≠ v re√°ln√©m ƒçase**: Tokeny se zobrazuj√≠, jakmile jsou generov√°ny
- üõ°Ô∏è **Robustn√≠ zpracov√°n√≠ chyb**: Plynul√© zotaven√≠ p≈ôi probl√©mech
- üé® **Modern√≠ UI**: Profesion√°ln√≠ chatovac√≠ rozhran√≠ p≈ôipraven√© k pou≈æit√≠
- üîß **Flexibiln√≠ konfigurace**: Promƒõnn√© prost≈ôed√≠ a automatick√° detekce
- üì± **Responzivn√≠ design**: Funguje na desktopu i mobiln√≠ch za≈ô√≠zen√≠ch

**Rychl√Ω start:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU Browser Demo

**Funkce:**
- üåê **AI nativn√≠ pro prohl√≠≈æeƒç**: Nen√≠ pot≈ôeba server, bƒõ≈æ√≠ p≈ô√≠mo v prohl√≠≈æeƒçi
- ‚ö° **Akcelerace WebGPU**: Hardwarov√° akcelerace, pokud je dostupn√°
- üîí **Maxim√°ln√≠ soukrom√≠**: Data nikdy neopou≈°t√≠ va≈°e za≈ô√≠zen√≠
- üéØ **Bez instalace**: Funguje v jak√©mkoli kompatibiln√≠m prohl√≠≈æeƒçi
- üîÑ **Plynul√Ω p≈ôechod**: Automaticky p≈ôepne na CPU, pokud WebGPU nen√≠ dostupn√©

**Spu≈°tƒõn√≠:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Integrace Open WebUI

**Funkce:**
- üé® **Rozhran√≠ podobn√© ChatGPT**: Profesion√°ln√≠, zn√°m√© UI
- üë• **Podpora v√≠ce u≈æivatel≈Ø**: U≈æivatelsk√© √∫ƒçty a historie konverzac√≠
- üìÅ **Zpracov√°n√≠ soubor≈Ø**: Nahr√°v√°n√≠ a anal√Ωza dokument≈Ø
- üîÑ **P≈ôep√≠n√°n√≠ model≈Ø**: Snadn√© p≈ôep√≠n√°n√≠ mezi r≈Øzn√Ωmi modely
- üê≥ **Nasazen√≠ pomoc√≠ Dockeru**: Produkƒçnƒõ p≈ôipraven√© kontejnerov√© nastaven√≠

**Rychl√© nastaven√≠:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Referenƒçn√≠ konfigurace

### Promƒõnn√© prost≈ôed√≠

| Promƒõnn√° | Popis | V√Ωchoz√≠ | P≈ô√≠klad |
|----------|-------|---------|---------|
| `MODEL` | Alias modelu k pou≈æit√≠ | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Endpoint Foundry Local | Automaticky detekov√°no | `http://localhost:51211` |
| `API_KEY` | API kl√≠ƒç (voliteln√© pro lok√°ln√≠ pou≈æit√≠) | `""` | `your-api-key` |

## ≈òe≈°en√≠ probl√©m≈Ø

### Bƒõ≈æn√© probl√©my

**Chainlit Application:**

1. **Slu≈æba nen√≠ dostupn√°:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Konflikty port≈Ø:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Probl√©my s Python prost≈ôed√≠m:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P ‚Üí Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU Demo:**

1. **WebGPU nen√≠ podporov√°no:**
   - Aktualizujte na Chrome/Edge 113+
   - Aktivujte WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - Zkontrolujte stav GPU: `chrome://gpu`
   - Demo automaticky p≈ôepne na CPU

2. **Chyby p≈ôi naƒç√≠t√°n√≠ modelu:**
   - Zajistƒõte p≈ôipojen√≠ k internetu pro sta≈æen√≠ modelu
   - Zkontrolujte konzoli prohl√≠≈æeƒçe kv≈Øli CORS chyb√°m
   - Ovƒõ≈ôte, ≈æe pou≈æ√≠v√°te HTTP (ne file://)

**Open WebUI:**

1. **Spojen√≠ odm√≠tnuto:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Modely se nezobrazuj√≠:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Kontroln√≠ seznam validace

```cmd
# ‚úÖ 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# ‚úÖ 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# ‚úÖ 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Pokroƒçil√© pou≈æit√≠

### Optimalizace v√Ωkonu

**Chainlit:**
- Pou≈æ√≠vejte streamov√°n√≠ pro lep≈°√≠ vn√≠man√Ω v√Ωkon
- Implementujte pooling p≈ôipojen√≠ pro vysokou soubƒõ≈ænost
- Cache odpovƒõdi modelu pro opakovan√© dotazy
- Sledujte vyu≈æit√≠ pamƒõti p≈ôi velk√Ωch histori√≠ch konverzac√≠

**WebGPU:**
- Pou≈æ√≠vejte WebGPU pro maxim√°ln√≠ soukrom√≠ a rychlost
- Implementujte kvantizaci modelu pro men≈°√≠ modely
- Pou≈æ√≠vejte Web Workers pro zpracov√°n√≠ na pozad√≠
- Cache kompilovan√© modely v √∫lo≈æi≈°ti prohl√≠≈æeƒçe

**Open WebUI:**
- Pou≈æ√≠vejte perzistentn√≠ svazky pro historii konverzac√≠
- Konfigurujte limity zdroj≈Ø pro Docker kontejner
- Implementujte z√°lohovac√≠ strategie pro u≈æivatelsk√° data
- Nastavte reverzn√≠ proxy pro SSL terminaci

### Vzory integrace

**Hybridn√≠ lok√°ln√≠/cloud:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Multimod√°ln√≠ pipeline:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Produkƒçn√≠ nasazen√≠

### Bezpeƒçnostn√≠ √∫vahy

- **API kl√≠ƒçe**: Pou≈æ√≠vejte promƒõnn√© prost≈ôed√≠, nikdy je nezapisujte p≈ô√≠mo do k√≥du
- **S√≠≈•**: Pou≈æ√≠vejte HTTPS v produkci, zva≈æte VPN pro p≈ô√≠stup t√Ωmu
- **Kontrola p≈ô√≠stupu**: Implementujte autentizaci pro Open WebUI
- **Ochrana dat**: Auditujte, kter√° data z≈Øst√°vaj√≠ lok√°lnƒõ a kter√° jdou do cloudu
- **Aktualizace**: Udr≈æujte Foundry Local a kontejnery aktu√°ln√≠

### Monitoring a √∫dr≈æba

- **Kontroly stavu**: Implementujte monitoring endpoint≈Ø
- **Logov√°n√≠**: Centralizujte logy ze v≈°ech komponent
- **Metriky**: Sledujte ƒçasy odpovƒõd√≠, m√≠ru chyb, vyu≈æit√≠ zdroj≈Ø
- **Z√°lohov√°n√≠**: Pravidelnƒõ z√°lohujte data konverzac√≠ a konfigurace

## Odkazy a zdroje

### Dokumentace
- [Chainlit Dokumentace](https://docs.chainlit.io/) - Kompletn√≠ pr≈Øvodce frameworkem
- [Foundry Local Dokumentace](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Ofici√°ln√≠ dokumentace Microsoftu
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - Integrace WebGPU
- [Open WebUI Dokumentace](https://docs.openwebui.com/) - Pokroƒçil√° konfigurace

### Uk√°zkov√© soubory
- [`app.py`](../../../../../Module08/samples/04/app.py) - Produkƒçn√≠ aplikace Chainlit
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Edukaƒçn√≠ notebook
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - AI inference v prohl√≠≈æeƒçi
- [`open-webui-guide.md`](./open-webui-guide.md) - Kompletn√≠ nastaven√≠ Open WebUI

### Souvisej√≠c√≠ uk√°zky
- [Dokumentace k sezen√≠ 4](../../04.CuttingEdgeModels.md) - Kompletn√≠ pr≈Øvodce sezen√≠m
- [Uk√°zky Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Ofici√°ln√≠ uk√°zky

---

