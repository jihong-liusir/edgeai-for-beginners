<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1b09b5c867abbccfdbc826d857ae0c2",
  "translation_date": "2025-09-25T01:28:47+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "sk"
}
-->
# Session 3: Objavovanie a správa open-source modelov

## Prehľad

Táto lekcia sa zameriava na praktické objavovanie a správu modelov pomocou Foundry Local. Naučíte sa, ako zobraziť dostupné modely, testovať rôzne možnosti a pochopiť základné výkonnostné charakteristiky. Prístup kladie dôraz na praktické skúmanie pomocou nástroja foundry CLI, aby ste si mohli vybrať správne modely pre vaše potreby.

## Ciele učenia

- Ovládnuť príkazy foundry CLI na objavovanie a správu modelov
- Pochopiť vzory ukladania do vyrovnávacej pamäte a lokálneho úložiska modelov
- Naučiť sa rýchlo testovať a porovnávať rôzne modely
- Zaviesť praktické pracovné postupy pre výber a hodnotenie modelov
- Preskúmať rastúci ekosystém modelov dostupných cez Foundry Local

## Predpoklady

- Dokončená lekcia 1: Začíname s Foundry Local
- Nainštalovaný a dostupný Foundry Local CLI
- Dostatočný úložný priestor na sťahovanie modelov (modely môžu mať veľkosť od 1 GB do 20 GB+)
- Základné pochopenie typov modelov a ich využitia

## Časť 6: Praktické cvičenie

### Cvičenie: Objavovanie a porovnávanie modelov

Vytvorte si vlastný skript na hodnotenie modelov na základe Vzoru 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Vaša úloha

1. **Spustite skript Vzor 03**: `samples\03\list_and_bench.cmd`
2. **Vyskúšajte rôzne modely**: Otestujte aspoň 3 rôzne modely
3. **Porovnajte výkonnosť**: Zaznamenajte rozdiely v rýchlosti a kvalite odpovedí
4. **Zdokumentujte zistenia**: Vytvorte jednoduchý porovnávací graf

### Príklad formátu porovnania

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## Časť 7: Riešenie problémov a osvedčené postupy

### Bežné problémy a riešenia

**Model sa nespustí:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Nedostatok pamäte:**
- Začnite s menšími modelmi (`phi-4-mini`)
- Zatvorte ostatné aplikácie
- Ak často narážate na limity, zvážte upgrade RAM

**Pomalý výkon:**
- Uistite sa, že model je plne načítaný (skontrolujte podrobný výstup)
- Zatvorte nepotrebné aplikácie na pozadí
- Zvážte rýchlejšie úložisko (SSD)

### Osvedčené postupy

1. **Začnite s menšími modelmi**: Začnite s `phi-4-mini`, aby ste overili nastavenie
2. **Jeden model naraz**: Zastavte predchádzajúce modely pred spustením nových
3. **Monitorujte zdroje**: Sledujte využitie pamäte
4. **Testujte konzistentne**: Používajte rovnaké výzvy na spravodlivé porovnanie
5. **Dokumentujte výsledky**: Zaznamenávajte výkonnosť modelov pre vaše potreby

## Časť 8: Ďalšie kroky a zdroje

### Príprava na lekciu 4

- **Zameranie lekcie 4**: Nástroje a techniky optimalizácie
- **Predpoklady**: Pohodlná práca s prepínaním modelov a základným testovaním výkonnosti
- **Odporúčanie**: Identifikujte 2-3 obľúbené modely z tejto lekcie

### Ďalšie zdroje

- **[Dokumentácia Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Oficiálna dokumentácia
- **[CLI Referencia](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Kompletný zoznam príkazov
- **[Model Mondays](https://aka.ms/model-mondays)**: Týždenné predstavenie modelov
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Komunita a problémy
- **[Vzor 03: Objavovanie modelov](samples/03/README.md)**: Praktický príklad skriptu

### Kľúčové poznatky

✅ **Objavovanie modelov**: Použite `foundry model list` na preskúmanie dostupných modelov  
✅ **Rýchle testovanie**: Vzor `list_and_bench.cmd` na rýchle hodnotenie  
✅ **Monitorovanie výkonnosti**: Základné meranie využitia zdrojov a času odozvy  
✅ **Výber modelov**: Praktické pokyny na výber modelov podľa použitia  
✅ **Správa vyrovnávacej pamäte**: Pochopenie úložiska a postupov čistenia  

Teraz máte praktické zručnosti na objavovanie, testovanie a výber vhodných modelov pre vaše AI aplikácie pomocou jednoduchého prístupu Foundry Local CLI.

---

## Ciele učenia
- Objavovať a hodnotiť open-source modely pre lokálne inferencie
- Kompilovať a spúšťať vybrané Hugging Face modely vo Foundry Local
- Aplikovať stratégie výberu modelov pre presnosť, latenciu a potreby zdrojov
- Spravovať modely lokálne s vyrovnávacou pamäťou a verziami

## Časť 1: Objavovanie modelov s Foundry CLI

### Základné príkazy na správu modelov

Foundry CLI poskytuje jednoduché príkazy na objavovanie a správu modelov:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Spustenie vašich prvých modelov

Začnite s populárnymi, dobre otestovanými modelmi, aby ste pochopili ich výkonnostné charakteristiky:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b-instruct --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-distill-qwen-7b --verbose
```

**Poznámka:** Príznak `--verbose` poskytuje podrobné informácie o spustení, vrátane:
- Postupu sťahovania modelu (pri prvom spustení)
- Podrobností o alokácii pamäte
- Informácií o viazaní služby
- Úvodných výkonnostných metrík

### Pochopenie kategórií modelov

**Malé jazykové modely (SLMs):**
- `phi-4-mini`: Rýchly, efektívny, skvelý na všeobecný chat
- `phi-4`: Schopnejšia verzia s lepším uvažovaním

**Stredné modely:**
- `qwen2.5-7b-instruct`: Vynikajúce uvažovanie a dlhší kontext
- `deepseek-r1-distill-qwen-7b`: Optimalizovaný na generovanie kódu

**Väčšie modely:**
- `llama-3.2`: Najnovší open-source model od Meta
- `qwen2.5-14b-instruct`: Podniková úroveň uvažovania

## Časť 2: Rýchle testovanie a porovnávanie modelov

### Prístup Vzor 03: Jednoduchý zoznam a hodnotenie

Na základe nášho vzoru 03 je tu minimálny pracovný postup:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Testovanie výkonnosti modelov

Keď je model spustený, testujte ho s konzistentnými výzvami:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### Alternatíva testovania v PowerShell

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## Časť 3: Správa vyrovnávacej pamäte a úložiska modelov

### Pochopenie vyrovnávacej pamäte modelov

Foundry Local automaticky spravuje sťahovanie a vyrovnávaciu pamäť modelov:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Úvahy o úložisku modelov

**Typické veľkosti modelov:**
- `phi-4-mini`: ~2,5 GB
- `qwen2.5-7b-instruct`: ~4,1 GB  
- `deepseek-r1-distill-qwen-7b`: ~4,3 GB
- `llama-3.2`: ~4,9 GB
- `qwen2.5-14b-instruct`: ~8,2 GB

**Osvedčené postupy pre úložisko:**
- Uchovávajte 2-3 modely v pamäti pre rýchle prepínanie
- Odstráňte nepoužívané modely na uvoľnenie miesta: `foundry cache clean`
- Sledujte využitie disku, najmä na menších SSD
- Zvážte kompromisy medzi veľkosťou modelu a jeho schopnosťami

### Monitorovanie výkonnosti modelov

Počas spustenia modelov sledujte systémové zdroje:

**Správca úloh vo Windows:**
- Sledujte využitie pamäte (modely zostávajú načítané v RAM)
- Monitorujte využitie CPU počas inferencie
- Skontrolujte diskové I/O počas počiatočného načítania modelu

**Monitorovanie cez príkazový riadok:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## Časť 4: Praktické pokyny na výber modelov

### Výber modelov podľa použitia

**Pre všeobecný chat a Q&A:**
- Začnite s: `phi-4-mini` (rýchly, efektívny)
- Prejdite na: `phi-4` (lepšie uvažovanie)
- Pokročilé: `qwen2.5-7b-instruct` (dlhší kontext)

**Pre generovanie kódu:**
- Odporúčané: `deepseek-r1-distill-qwen-7b`
- Alternatíva: `qwen2.5-7b-instruct` (tiež dobrý na kód)

**Pre komplexné uvažovanie:**
- Najlepšie: `qwen2.5-7b-instruct` alebo `qwen2.5-14b-instruct`
- Cenovo dostupná možnosť: `phi-4`

### Sprievodca hardvérovými požiadavkami

**Minimálne systémové požiadavky:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Odporúčané pre najlepší výkon:**
- 32 GB+ RAM pre pohodlné prepínanie medzi modelmi
- SSD úložisko pre rýchlejšie načítanie modelov
- Moderný CPU s dobrým jednovláknovým výkonom
- Podpora NPU (Windows 11 Copilot+ PC) na akceleráciu

### Pracovný postup prepínania modelov

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b-instruct

REM Verify model is running
foundry service status
```

## Časť 5: Jednoduché hodnotenie modelov

### Základné testovanie výkonnosti

Tu je jednoduchý prístup na porovnanie výkonnosti modelov:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b-instruct", "deepseek-r1-distill-qwen-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Manuálne hodnotenie kvality

Pre každý model testujte s konzistentnými výzvami a manuálne hodnotte:

**Testovacie výzvy:**
1. "Vysvetlite kvantové počítanie jednoduchými slovami."
2. "Napíšte Python funkciu na zoradenie zoznamu."
3. "Aké sú výhody a nevýhody práce na diaľku?"
4. "Zhrňte výhody edge AI."

**Kritériá hodnotenia:**
- **Presnosť**: Sú informácie správne?
- **Jasnosť**: Je vysvetlenie ľahko pochopiteľné?
- **Kompletnosť**: Rieši to celú otázku?
- **Rýchlosť**: Ako rýchlo odpovedá?

### Monitorovanie využitia zdrojov

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## Časť 6: Ďalšie kroky
- Prihláste sa na Model Mondays pre nové modely a tipy: https://aka.ms/model-mondays
- Prispievajte zistenia do tímového súboru `models.json`
- Pripravte sa na lekciu 4: porovnávanie LLM vs SLM, lokálne vs cloudové inferencie a praktické ukážky

---

