<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-10-01T01:22:45+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "sk"
}
-->
# Session 3: Objavovanie a správa open-source modelov

## Prehľad

Táto lekcia sa zameriava na praktické objavovanie a správu modelov pomocou Foundry Local. Naučíte sa, ako zobraziť dostupné modely, testovať rôzne možnosti a pochopiť základné charakteristiky výkonu. Prístup kladie dôraz na praktické skúmanie pomocou príkazového riadku Foundry CLI, aby ste si mohli vybrať správne modely pre vaše potreby.

## Ciele učenia

- Ovládnuť príkazy Foundry CLI na objavovanie a správu modelov
- Pochopiť vzory ukladania modelov do cache a lokálneho úložiska
- Naučiť sa rýchlo testovať a porovnávať rôzne modely
- Vytvoriť praktické pracovné postupy na výber a benchmarking modelov
- Preskúmať rastúci ekosystém modelov dostupných cez Foundry Local

## Predpoklady

- Dokončená lekcia 1: Začíname s Foundry Local
- Nainštalovaný a dostupný Foundry Local CLI
- Dostatočný úložný priestor na sťahovanie modelov (modely môžu mať veľkosť od 1 GB do 20 GB+)
- Základné pochopenie typov modelov a ich využitia

## Prehľad

Táto lekcia skúma, ako priniesť open-source modely do Foundry Local.

## Časť 6: Praktické cvičenie

### Cvičenie: Objavovanie a porovnávanie modelov

Vytvorte vlastný skript na hodnotenie modelov na základe vzoru Sample 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Vaša úloha

1. **Spustite skript Sample 03**: `samples\03\list_and_bench.cmd`
2. **Vyskúšajte rôzne modely**: Otestujte aspoň 3 rôzne modely
3. **Porovnajte výkon**: Zaznamenajte rozdiely v rýchlosti a kvalite odpovedí
4. **Zdokumentujte zistenia**: Vytvorte jednoduchý porovnávací graf

### Príklad formátu porovnania

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## Časť 7: Riešenie problémov a osvedčené postupy

### Bežné problémy a riešenia

**Model sa nespustí:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Nedostatok pamäte:**
- Začnite s menšími modelmi (`phi-4-mini`)
- Zatvorte ostatné aplikácie
- Zvážte upgrade RAM, ak často narazíte na limity

**Pomalý výkon:**
- Uistite sa, že model je plne načítaný (skontrolujte podrobný výstup)
- Zatvorte nepotrebné aplikácie na pozadí
- Zvážte rýchlejšie úložisko (SSD)

### Osvedčené postupy

1. **Začnite s malými modelmi**: Použite `phi-4-mini` na overenie nastavenia
2. **Jeden model naraz**: Zastavte predchádzajúce modely pred spustením nových
3. **Monitorujte zdroje**: Sledujte využitie pamäte
4. **Testujte konzistentne**: Používajte rovnaké výzvy na spravodlivé porovnanie
5. **Dokumentujte výsledky**: Zaznamenávajte výkon modelov pre vaše potreby

## Časť 8: Ďalšie kroky a zdroje

### Príprava na lekciu 4

- **Zameranie lekcie 4**: Nástroje a techniky optimalizácie
- **Predpoklady**: Pohodlné prepínanie modelov a základné testovanie výkonu
- **Odporúčanie**: Identifikujte 2-3 obľúbené modely z tejto lekcie

### Dodatočné zdroje

- **[Foundry Local Dokumentácia](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Oficiálna dokumentácia
- **[CLI Referencia](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Kompletný zoznam príkazov
- **[Model Mondays](https://aka.ms/model-mondays)**: Týždenné predstavenie modelov
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Komunita a problémy
- **[Sample 03: Objavovanie modelov](samples/03/README.md)**: Praktický príklad skriptu

### Kľúčové poznatky

✅ **Objavovanie modelov**: Použite `foundry model list` na preskúmanie dostupných modelov  
✅ **Rýchle testovanie**: Vzor `list_and_bench.cmd` na rýchle hodnotenie  
✅ **Monitorovanie výkonu**: Základné meranie využitia zdrojov a času odozvy  
✅ **Výber modelov**: Praktické pokyny na výber modelov podľa využitia  
✅ **Správa cache**: Pochopenie úložiska a postupov čistenia  

Teraz máte praktické zručnosti na objavovanie, testovanie a výber vhodných modelov pre vaše AI aplikácie pomocou jednoduchého prístupu Foundry Local CLI: výber komunitných modelov, integrácia obsahu Hugging Face a prijatie stratégie „prineste si vlastný model“ (BYOM). Objavíte tiež sériu Model Mondays pre kontinuálne vzdelávanie a objavovanie modelov.

Referencie:
- Foundry Local dokumentácia: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Kompilácia modelov Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Model Mondays: https://aka.ms/model-mondays
- Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

## Ciele učenia
- Objaviť a hodnotiť open-source modely pre lokálnu inferenciu
- Kompilovať a spúšťať vybrané modely Hugging Face v rámci Foundry Local
- Použiť stratégie výberu modelov pre presnosť, latenciu a potreby zdrojov
- Spravovať modely lokálne pomocou cache a verzovania

## Časť 1: Objavovanie modelov pomocou Foundry CLI

### Základné príkazy na správu modelov

Foundry CLI poskytuje jednoduché príkazy na objavovanie a správu modelov:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Spustenie vašich prvých modelov

Začnite s populárnymi, dobre otestovanými modelmi na pochopenie charakteristík výkonu:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**Poznámka:** Príznak `--verbose` poskytuje podrobné informácie o spustení, vrátane:
- Postup sťahovania modelu (pri prvom spustení)
- Detaily alokácie pamäte
- Informácie o viazaní služby
- Metriky inicializácie výkonu

### Pochopenie kategórií modelov

**Malé jazykové modely (SLMs):**
- `phi-4-mini`: Rýchly, efektívny, skvelý na všeobecný chat
- `phi-4`: Schopnejšia verzia s lepším uvažovaním

**Stredné modely:**
- `qwen2.5-7b`: Výborné uvažovanie a dlhší kontext
- `deepseek-r1-7b`: Optimalizované na generovanie kódu

**Veľké modely:**
- `llama-3.2`: Najnovší open-source model od Meta
- `qwen2.5-14b`: Podnikové uvažovanie

## Časť 2: Rýchle testovanie a porovnávanie modelov

### Prístup Sample 03: Jednoduchý zoznam a benchmark

Na základe vzoru Sample 03 je tu minimálny pracovný postup:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Testovanie výkonu modelov

Keď je model spustený, testujte ho s konzistentnými výzvami:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### Alternatíva testovania v PowerShell

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## Časť 3: Správa cache a úložiska modelov

### Pochopenie cache modelov

Foundry Local automaticky spravuje sťahovanie a ukladanie modelov do cache:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Úvahy o úložisku modelov

**Typické veľkosti modelov:**
- `phi-4-mini`: ~2,5 GB
- `qwen2.5-7b`: ~4,1 GB  
- `deepseek-r1-7b`: ~4,3 GB
- `llama-3.2`: ~4,9 GB
- `qwen2.5-14b`: ~8,2 GB

**Najlepšie postupy pre úložisko:**
- Uchovávajte 2-3 modely v cache pre rýchle prepínanie
- Odstráňte nepoužívané modely na uvoľnenie miesta: `foundry cache clean`
- Sledujte využitie disku, najmä na menších SSD
- Zvážte kompromis medzi veľkosťou modelu a jeho schopnosťami

### Monitorovanie výkonu modelov

Počas spustenia modelov sledujte systémové zdroje:

**Správca úloh Windows:**
- Sledujte využitie pamäte (modely zostávajú načítané v RAM)
- Monitorujte využitie CPU počas inferencie
- Skontrolujte diskové I/O počas počiatočného načítania modelu

**Monitorovanie príkazového riadku:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## Časť 4: Praktické pokyny na výber modelov

### Výber modelov podľa využitia

**Pre všeobecný chat a otázky a odpovede:**
- Začnite s: `phi-4-mini` (rýchly, efektívny)
- Prejdite na: `phi-4` (lepšie uvažovanie)
- Pokročilé: `qwen2.5-7b` (dlhší kontext)

**Pre generovanie kódu:**
- Odporúčané: `deepseek-r1-7b`
- Alternatíva: `qwen2.5-7b` (tiež dobré na kód)

**Pre komplexné uvažovanie:**
- Najlepšie: `qwen2.5-7b` alebo `qwen2.5-14b`
- Možnosť s nižším rozpočtom: `phi-4`

### Sprievodca hardvérovými požiadavkami

**Minimálne systémové požiadavky:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Odporúčané pre najlepší výkon:**
- 32 GB+ RAM pre pohodlné prepínanie viacerých modelov
- SSD úložisko pre rýchlejšie načítanie modelov
- Moderný CPU s dobrým výkonom na jedno vlákno
- Podpora NPU (Windows 11 Copilot+ PC) na akceleráciu

### Pracovný postup prepínania modelov

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## Časť 5: Jednoduché benchmarkovanie modelov

### Základné testovanie výkonu

Tu je jednoduchý prístup na porovnanie výkonu modelov:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Manuálne hodnotenie kvality

Pre každý model testujte s konzistentnými výzvami a manuálne hodnotte:

**Testovacie výzvy:**
1. "Vysvetlite kvantové počítanie jednoduchými slovami."
2. "Napíšte funkciu v Pythone na zoradenie zoznamu."
3. "Aké sú výhody a nevýhody práce na diaľku?"
4. "Zhrňte výhody edge AI."

**Kritériá hodnotenia:**
- **Presnosť**: Sú informácie správne?
- **Jasnosť**: Je vysvetlenie ľahko pochopiteľné?
- **Kompletnosť**: Rieši to celú otázku?
- **Rýchlosť**: Ako rýchlo odpovedá?

### Monitorovanie využitia zdrojov

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## Časť 6: Ďalšie kroky
- Prihláste sa na Model Mondays pre nové modely a tipy: https://aka.ms/model-mondays
- Prispievajte zistenia do tímového `models.json`
- Pripravte sa na lekciu 4: porovnanie LLM vs SLM, lokálna vs cloudová inferencia a praktické ukážky

---

**Upozornenie**:  
Tento dokument bol preložený pomocou služby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa snažíme o presnosť, upozorňujeme, že automatizované preklady môžu obsahovať chyby alebo nepresnosti. Pôvodný dokument v jeho rodnom jazyku by mal byť považovaný za autoritatívny zdroj. Pre kritické informácie sa odporúča profesionálny ľudský preklad. Nenesieme zodpovednosť za akékoľvek nedorozumenia alebo nesprávne interpretácie vyplývajúce z použitia tohto prekladu.