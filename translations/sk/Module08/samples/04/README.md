<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-25T01:31:36+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "sk"
}
-->
# Uk√°≈æka 04: Produkƒçn√© chatovacie aplik√°cie s Chainlit

Komplexn√° uk√°≈æka, ktor√° demon≈°truje r√¥zne pr√≠stupy k vytv√°raniu produkƒçne pripraven√Ωch chatovac√≠ch aplik√°ci√≠ pomocou Microsoft Foundry Local, zah≈ï≈àaj√∫ca modern√© webov√© rozhrania, streamovanie odpoved√≠ a najnov≈°ie technol√≥gie prehliadaƒçov.

## ƒåo je zahrnut√©

- **üöÄ Chainlit Chat App** (`app.py`): Produkƒçne pripraven√° chatovacia aplik√°cia so streamovan√≠m
- **üåê WebGPU Demo** (`webgpu-demo/`): AI inferencia v prehliadaƒçi s hardv√©rovou akceler√°ciou
- **üé® Integr√°cia Open WebUI** (`open-webui-guide.md`): Profesion√°lne rozhranie podobn√© ChatGPT
- **üìö Edukaƒçn√Ω notebook** (`chainlit_app.ipynb`): Interakt√≠vne vzdel√°vacie materi√°ly

## R√Ωchly ≈°tart

### 1. Chainlit Chat Application

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Otv√°ra sa na: `http://localhost:8080`

### 2. WebGPU Browser Demo

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Otv√°ra sa na: `http://localhost:5173`

### 3. Open WebUI Setup

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Otv√°ra sa na: `http://localhost:3000`

## Architektonick√© vzory

### Matrica rozhodovania medzi lok√°lnym a cloudov√Ωm rie≈°en√≠m

| Scen√°r | Odpor√∫ƒçanie | D√¥vod |
|--------|-------------|-------|
| **Citliv√© √∫daje** | üè† Lok√°lne (Foundry) | D√°ta nikdy neopustia zariadenie |
| **Komplexn√© uva≈æovanie** | ‚òÅÔ∏è Cloud (Azure OpenAI) | Pr√≠stup k v√§ƒç≈°√≠m modelom |
| **Chat v re√°lnom ƒçase** | üè† Lok√°lne (Foundry) | Ni≈æ≈°ia latencia, r√Ωchlej≈°ie odpovede |
| **Anal√Ωza dokumentov** | üîÑ Hybrid | Lok√°lne na extrakciu, cloud na anal√Ωzu |
| **Generovanie k√≥du** | üè† Lok√°lne (Foundry) | Ochrana s√∫kromia + ≈°pecializovan√© modely |
| **V√Ωskumn√© √∫lohy** | ‚òÅÔ∏è Cloud (Azure OpenAI) | Potrebn√° ≈°irok√° datab√°za znalost√≠ |

### Porovnanie technol√≥gi√≠

| Technol√≥gia | Pou≈æitie | V√Ωhody | Nev√Ωhody |
|-------------|----------|--------|----------|
| **Chainlit** | Python v√Ωvoj√°ri, r√Ωchle prototypovanie | Jednoduch√© nastavenie, podpora streamovania | Len pre Python |
| **WebGPU** | Maxim√°lne s√∫kromie, offline scen√°re | Nativn√© prehliadaƒçe, bez potreby servera | Obmedzen√° veƒækos≈• modelu |
| **Open WebUI** | Produkƒçn√© nasadenie, t√≠my | Profesion√°lne UI, spr√°va pou≈æ√≠vateƒæov | Vy≈æaduje Docker |

## Predpoklady

- **Foundry Local**: Nain≈°talovan√© a spusten√© ([Stiahnu≈•](https://aka.ms/foundry-local-installer))
- **Python**: 3.10+ s virtu√°lnym prostred√≠m
- **Model**: Aspo≈à jeden naƒç√≠tan√Ω (`foundry model run phi-4-mini`)
- **Prehliadaƒç**: Chrome/Edge s podporou WebGPU pre demo
- **Docker**: Pre Open WebUI (voliteƒæn√©)

## In≈°tal√°cia a nastavenie

### 1. Nastavenie Python prostredia

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Nastavenie Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## Uk√°≈ækov√© aplik√°cie

### Chainlit Chat Application

**Funkcie:**
- üöÄ **Streamovanie v re√°lnom ƒçase**: Tokeny sa zobrazuj√∫ poƒças ich generovania
- üõ°Ô∏è **Robustn√© spracovanie ch√Ωb**: Elegantn√© zlyhanie a obnova
- üé® **Modern√© UI**: Profesion√°lne chatovacie rozhranie pripraven√© na pou≈æitie
- üîß **Flexibiln√° konfigur√°cia**: Premenn√© prostredia a automatick√° detekcia
- üì± **Responz√≠vny dizajn**: Funguje na desktopoch aj mobiln√Ωch zariadeniach

**R√Ωchly ≈°tart:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU Browser Demo

**Funkcie:**
- üåê **AI nativn√© prehliadaƒçu**: Bez potreby servera, funguje √∫plne v prehliadaƒçi
- ‚ö° **Akceler√°cia WebGPU**: Hardv√©rov√° akceler√°cia, ak je dostupn√°
- üîí **Maxim√°lne s√∫kromie**: D√°ta nikdy neopustia va≈°e zariadenie
- üéØ **Bez in≈°tal√°cie**: Funguje v akomkoƒævek kompatibilnom prehliadaƒçi
- üîÑ **Elegantn√© z√°lo≈æn√© rie≈°enie**: Automaticky prejde na CPU, ak WebGPU nie je dostupn√©

**Spustenie:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Integr√°cia Open WebUI

**Funkcie:**
- üé® **Rozhranie podobn√© ChatGPT**: Profesion√°lne, zn√°me UI
- üë• **Podpora viacer√Ωch pou≈æ√≠vateƒæov**: Pou≈æ√≠vateƒæsk√© √∫ƒçty a hist√≥ria konverz√°ci√≠
- üìÅ **Spracovanie s√∫borov**: Nahr√°vanie a anal√Ωza dokumentov
- üîÑ **Prep√≠nanie modelov**: Jednoduch√© prep√≠nanie medzi r√¥znymi modelmi
- üê≥ **Nasadenie cez Docker**: Produkƒçne pripraven√© kontajnerov√© nastavenie

**R√Ωchle nastavenie:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Referencia konfigur√°cie

### Premenn√© prostredia

| Premenn√° | Popis | Predvolen√° hodnota | Pr√≠klad |
|----------|-------|--------------------|---------|
| `MODEL` | Alias modelu na pou≈æitie | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Endpoint Foundry Local | Automaticky detekovan√Ω | `http://localhost:51211` |
| `API_KEY` | API kƒæ√∫ƒç (voliteƒæn√Ω pre lok√°lne) | `""` | `your-api-key` |

## Rie≈°enie probl√©mov

### Be≈æn√© probl√©my

**Chainlit Application:**

1. **Slu≈æba nie je dostupn√°:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Konflikty portov:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Probl√©my s Python prostred√≠m:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P ‚Üí Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU Demo:**

1. **WebGPU nie je podporovan√©:**
   - Aktualizujte na Chrome/Edge 113+
   - Aktivujte WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - Skontrolujte stav GPU: `chrome://gpu`
   - Demo automaticky prejde na CPU

2. **Chyby pri naƒç√≠tan√≠ modelu:**
   - Skontrolujte internetov√© pripojenie na stiahnutie modelu
   - Skontrolujte konzolu prehliadaƒça na chyby CORS
   - Overte, ≈æe pou≈æ√≠vate HTTP (nie file://)

**Open WebUI:**

1. **Spojenie odmietnut√©:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Modely sa nezobrazuj√∫:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Kontroln√Ω zoznam valid√°cie

```cmd
# ‚úÖ 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# ‚úÖ 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# ‚úÖ 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Pokroƒçil√© pou≈æitie

### Optimaliz√°cia v√Ωkonu

**Chainlit:**
- Pou≈æ√≠vajte streamovanie pre lep≈°√≠ vn√≠man√Ω v√Ωkon
- Implementujte pooling spojen√≠ pre vysok√∫ s√∫be≈ænos≈•
- Cache odpovede modelu pre opakovan√© dotazy
- Monitorujte vyu≈æitie pam√§te pri veƒæk√Ωch hist√≥ri√°ch konverz√°ci√≠

**WebGPU:**
- Pou≈æ√≠vajte WebGPU pre maxim√°lne s√∫kromie a r√Ωchlos≈•
- Implementujte kvantiz√°ciu modelu pre men≈°ie modely
- Pou≈æ√≠vajte Web Workers na spracovanie na pozad√≠
- Cache kompilovan√© modely v √∫lo≈æisku prehliadaƒça

**Open WebUI:**
- Pou≈æ√≠vajte perzistentn√© objemy pre hist√≥riu konverz√°ci√≠
- Konfigurujte limity zdrojov pre Docker kontajner
- Implementujte strat√©gie z√°lohovania pre pou≈æ√≠vateƒæsk√© d√°ta
- Nastavte reverzn√Ω proxy server pre SSL termin√°ciu

### Vzory integr√°cie

**Hybrid Lok√°lne/Cloud:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Multimod√°lna pipeline:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Produkƒçn√© nasadenie

### Bezpeƒçnostn√© √∫vahy

- **API kƒæ√∫ƒçe**: Pou≈æ√≠vajte premenn√© prostredia, nikdy ich nezapisujte priamo
- **Sie≈•**: Pou≈æ√≠vajte HTTPS v produkcii, zv√°≈æte VPN pre t√≠mov√Ω pr√≠stup
- **Kontrola pr√≠stupu**: Implementujte autentifik√°ciu pre Open WebUI
- **Ochrana √∫dajov**: Auditujte, ktor√© √∫daje zost√°vaj√∫ lok√°lne a ktor√© id√∫ do cloudu
- **Aktualiz√°cie**: Udr≈æujte Foundry Local a kontajnery aktualizovan√©

### Monitorovanie a √∫dr≈æba

- **Kontroly stavu**: Implementujte monitorovanie endpointov
- **Logovanie**: Centralizujte logy zo v≈°etk√Ωch komponentov
- **Metriky**: Sledujte ƒçasy odozvy, chybovos≈•, vyu≈æitie zdrojov
- **Z√°lohovanie**: Pravideln√© z√°lohovanie d√°t konverz√°ci√≠ a konfigur√°ci√≠

## Referencie a zdroje

### Dokument√°cia
- [Chainlit Dokument√°cia](https://docs.chainlit.io/) - Kompletn√Ω sprievodca frameworkom
- [Foundry Local Dokument√°cia](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Ofici√°lne Microsoft dokumenty
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - Integr√°cia WebGPU
- [Open WebUI Dokument√°cia](https://docs.openwebui.com/) - Pokroƒçil√° konfigur√°cia

### Uk√°≈ækov√© s√∫bory
- [`app.py`](../../../../../Module08/samples/04/app.py) - Produkƒçn√° aplik√°cia Chainlit
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Edukaƒçn√Ω notebook
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - AI inferencia v prehliadaƒçi
- [`open-webui-guide.md`](./open-webui-guide.md) - Kompletn√© nastavenie Open WebUI

### S√∫visiace uk√°≈æky
- [Dokument√°cia Session 4](../../04.CuttingEdgeModels.md) - Kompletn√Ω sprievodca session
- [Foundry Local Samples](https://github.com/microsoft/foundry-local/tree/main/samples) - Ofici√°lne uk√°≈æky

---

