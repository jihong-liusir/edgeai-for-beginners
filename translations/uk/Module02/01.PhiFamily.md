<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:50:17+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "uk"
}
-->
# Розділ 1: Основи сімейства моделей Microsoft Phi

Сімейство моделей Microsoft Phi представляє собою зміну парадигми в штучному інтелекті, демонструючи, що компактні, ефективні моделі можуть досягати вражаючих результатів, залишаючись значно більш ресурсоефективними, ніж традиційні великі мовні моделі. Важливо зрозуміти, як сімейство Phi забезпечує потужні можливості штучного інтелекту з меншими обчислювальними вимогами, зберігаючи високу продуктивність у різних завданнях.

## Ресурси для розробників

### Каталог моделей Azure AI Foundry
Сімейство моделей Phi (за винятком Phi-silica) доступне через [каталог моделей Azure AI Foundry](https://ai.azure.com/explore/models?q=phi), що дозволяє розробникам легко отримувати доступ, налаштовувати та впроваджувати ці моделі у своїх додатках. Каталог забезпечує зручний спосіб експериментувати з різними варіантами Phi та інтегрувати їх у ваші проєкти.

### Azure AI Foundry
Ви можете впроваджувати та експериментувати з моделями Phi за допомогою [Azure AI Foundry](https://ai.azure.com), який надає комплексне середовище для створення, тестування та впровадження рішень штучного інтелекту з мінімальними налаштуваннями.

### Foundry Local
Для локальної розробки та впровадження ознайомтеся з [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), який дозволяє запускати моделі Phi на вашій машині розробки з оптимізованими конфігураціями.

### Ресурси документації
- [Microsoft Research: Технічні звіти про моделі Phi](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Вступ

У цьому уроці ми дослідимо сімейство моделей Microsoft Phi та його основні концепції. Ми розглянемо еволюцію сімейства Phi, інноваційні методології навчання, які роблять моделі Phi ефективними, ключові варіанти в сімействі та практичні застосування в різних сценаріях.

## Цілі навчання

До кінця цього уроку ви зможете:

- Зрозуміти філософію дизайну та еволюцію сімейства моделей Microsoft Phi.
- Визначити ключові інновації, які дозволяють моделям Phi досягати високої продуктивності з меншою кількістю параметрів.
- Розпізнати переваги та обмеження різних варіантів моделей Phi.
- Застосувати знання про моделі Phi для вибору відповідних варіантів для реальних сценаріїв.

## Розуміння традиційної парадигми моделей штучного інтелекту

Традиційно, для досягнення високої продуктивності в обробці природної мови потрібні були масивні мовні моделі з мільярдами або сотнями мільярдів параметрів. Організації зазвичай впроваджують ці моделі на потужних GPU-кластерах, отримуючи доступ до їх можливостей через API-інтерфейси або спеціалізовану апаратну інфраструктуру.

Цей підхід добре працює для багатьох застосувань, але має вроджені обмеження щодо практичних сценаріїв впровадження. Традиційний метод передбачає використання моделей, які потребують значних обчислювальних ресурсів, великої кількості пам’яті та значного споживання енергії. Хоча цей підхід забезпечує доступ до передових можливостей, він створює залежність від дорогого обладнання, вводить високі операційні витрати та обмежує гнучкість впровадження.

## Виклик ефективного впровадження штучного інтелекту

Потреба в більш ефективному штучному інтелекті стає дедалі важливішою в різних сценаріях. Розглянемо застосування, які потребують локального впровадження з міркувань конфіденційності, чутливі до витрат реалізації, де витрати на API хмарних сервісів стають непомірними, сценарії обчислень на периферії з обмеженими апаратними ресурсами або реальні застосування, де критично важлива затримка.

### Основні обмеження впровадження

Традиційні впровадження великих моделей стикаються з кількома фундаментальними обмеженнями, які обмежують їх практичну застосовність:

- **Обмеження витрат**: Високі обчислювальні витрати роблять постійне впровадження дорогим для багатьох організацій.
- **Ресурсні обмеження**: Обмежений доступ до висококласної GPU-інфраструктури обмежує варіанти впровадження.
- **Вимоги конфіденційності**: Чутливі застосування потребують локальної обробки для збереження конфіденційності даних.
- **Чутливість до затримки**: Реальні застосування потребують негайних відповідей без затримок через хмару.

## Філософія моделей Microsoft Phi

Сімейство моделей Microsoft Phi представляє фундаментальну зміну в філософії дизайну моделей штучного інтелекту, надаючи пріоритет ефективності та практичному впровадженню, зберігаючи сильні характеристики продуктивності. Моделі Phi досягають цього завдяки інноваційним архітектурам, високоякісним методологіям навчання та спеціалізованим технікам оптимізації.

Сімейство Phi охоплює різні підходи, спрямовані на максимізацію продуктивності на параметр, дозволяючи впровадження на стандартному обладнанні, забезпечуючи при цьому значущі можливості штучного інтелекту. Мета полягає в тому, щоб зберігати конкурентну продуктивність, одночасно значно зменшуючи обчислювальні вимоги, використання пам’яті та операційні витрати.

### Основні принципи дизайну Phi

Моделі Phi побудовані на кількох основоположних принципах, які відрізняють їх від традиційних великих мовних моделей:

- **Ефективність перш за все**: Оптимізовані для максимальної продуктивності на параметр, а не абсолютного масштабу.
- **Якісне навчання**: Орієнтація на високоякісні, відфільтровані навчальні дані, а не на масивні набори даних.
- **Гнучкість впровадження**: Розроблені для ефективної роботи на різних апаратних конфігураціях.
- **Спеціалізовані можливості**: Часто оптимізовані для конкретних завдань або доменів для максимізації ефективності.

## Ключові технології, що забезпечують сімейство Phi

### Підхід "підручникового" навчання

Одним із найбільш революційних аспектів сімейства Phi є методологія навчання "підручникової якості". Замість навчання на масивних обсягах нефільтрованих даних з інтернету, моделі Phi використовують ретельно відібраний, високоякісний освітній контент, розроблений для ефективного навчання логіці, математиці, програмуванню та загальним знанням.

Цей підхід працює шляхом створення синтетичного освітнього контенту, який відображає високоякісні підручники та академічні матеріали. Навчальні дані спеціально розроблені для педагогічної ефективності, зосереджуючись на чітких поясненнях, покроковій логіці та структурованій презентації знань.

### Розширене навчання логіці

Останні моделі Phi включають складні методології навчання логіці, які дозволяють вирішувати багатокрокові проблеми. Ці техніки включають:

**Навчання "ланцюгом думок"**: Моделі навчаються розбивати складні проблеми на проміжні логічні кроки, роблячи процес їх вирішення більш прозорим і надійним.

**Масштабування під час генерації**: Моделі створюють детальні логічні ланцюги, використовуючи додаткові обчислювальні ресурси під час генерації відповідей для покращення точності.

**Навчання на межі можливостей**: Навчальні дані спеціально обираються для того, щоб кидати виклик моделі на межі її поточних можливостей, сприяючи засвоєнню складних логічних шаблонів.

### Архітектурні інновації

Сімейство Phi включає кілька архітектурних оптимізацій, спеціально розроблених для ефективності:

**Ефективність параметрів**: Ретельно продумані архітектурні рішення, які максимізують вплив кожного параметра моделі.

**Інтеграція мультимодальності**: Ефективна інтеграція тексту, зображень і мовних можливостей у компактних архітектурах.

**Оптимізація для обладнання**: Спеціалізовані варіанти, оптимізовані для конкретних апаратних платформ і сценаріїв впровадження.

## Оптимізація обладнання для моделей Phi

Сучасні середовища впровадження отримують вигоду від ефективності моделей Phi на різних апаратних конфігураціях:

### Оптимізоване впровадження на CPU

Моделі Phi розроблені для ефективної роботи на обладнанні лише з CPU, що робить їх доступними для впровадження на стандартній обчислювальній інфраструктурі без необхідності спеціалізованих AI-акселераторів.

### Прискорення на GPU

Хоча моделі Phi не потребують потужних GPU, вони можуть використовувати доступні GPU-ресурси для покращення продуктивності, забезпечуючи гнучкість у конфігураціях впровадження.

### Інтеграція з пристроями на периферії

Спеціалізовані варіанти, такі як Phi-3-Silica, оптимізовані для конкретних платформ обчислень на периферії, досягаючи вражаючих показників ефективності, таких як 650 токенів за секунду при споживанні лише 1.5 Вт потужності.

## Переваги сімейства моделей Phi

### Економічна ефективність

Моделі Phi значно знижують операційні витрати, потребуючи значно меншої обчислювальної інфраструктури, зберігаючи конкурентну продуктивність. Це робить штучний інтелект доступним для організацій з обмеженими бюджетами або для застосувань з високим обсягом, де важлива вартість одного запиту.

### Гнучкість впровадження

Ефективність моделей Phi дозволяє впровадження на широкому спектрі апаратних конфігурацій, від персональних ноутбуків до серверів підприємств, надаючи організаціям більшу гнучкість у виборі інфраструктури штучного інтелекту.

### Конфіденційність і безпека

Ефективність моделей Phi дозволяє локальне впровадження для застосувань, чутливих до конфіденційності, забезпечуючи, що чутливі дані ніколи не залишають контроль організації, при цьому надаючи потужні можливості штучного інтелекту.

### Продуктивність у реальному часі

Зменшені обчислювальні вимоги призводять до швидших часів генерації відповідей, дозволяючи реальні застосування, які потребують негайних відповідей, без компромісів щодо якості можливостей штучного інтелекту.

### Доступний штучний інтелект

Зменшуючи бар’єри для впровадження штучного інтелекту, моделі Phi роблять передові можливості штучного інтелекту доступними для організацій з обмеженими ресурсами, дозволяючи меншим командам і окремим розробникам використовувати складне розуміння мови.

## Практичні приклади та сценарії використання

Перед тим як заглибитися в технічну еволюцію, давайте розглянемо кілька конкретних прикладів того, що можуть досягти моделі Phi:

### Приклад математичного логічного мислення

Phi-4-mini-reasoning відмінно справляється з покроковим вирішенням математичних задач. Наприклад, на запит "Як розв’язати 3*x^2+4*x+5=1?" модель надає детальні кроки логічного мислення:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Приклад багатомовної підтримки

Phi-3.5-mini-instruct демонструє сильні багатомовні можливості в різних мовах. Ось приклад формату запиту:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Приклад мультимодальних можливостей

Phi-4-multimodal може одночасно обробляти текст, зображення та мовлення. Ось кілька практичних застосувань:

**Планування подорожі за допомогою аудіовходу:**
Phi-4 Multimodal аналізує усну мову, допомагаючи спланувати подорож до Сіетла, демонструючи свої розширені можливості обробки аудіо та рекомендацій.

**Розв’язання математичних задач із зображень:**
Phi-4 Multimodal вирішує складні математичні задачі через візуальні входи, демонструючи здатність обробляти та вирішувати рівняння, представлені в зображеннях.

**Приклад виклику функцій:**
За допомогою виклику функцій Phi-4-mini та Phi-4-multimodal можуть розширювати свої можливості обробки тексту, інтегруючи пошукові системи, підключаючи різні інструменти тощо. Як показано, модель може отримувати інформацію про матчі Прем’єр-ліги через Phi-4-mini, демонструючи здатність безперешкодно взаємодіяти з зовнішніми джерелами даних.

### Приклад генерації коду

Phi-4-multimodal може генерувати структурований код проєкту на основі як вмісту зображення, так і наданих запитів, як показано в цьому практичному робочому процесі:

1. Завантажте зображення каркасу або дизайну.
2. Надайте контекст про вимоги проєкту.
3. Модель генерує повні, функціональні структури коду.
4. Код може бути налаштований відповідно до конкретних фреймворків або мов.

### Приклад впровадження на периферії

Ми можемо впровадити квантизовану модель на пристроях периферії. Поєднуючи Microsoft Olive та ONNX GenAI Runtime, ми можемо впровадити Phi-4-mini на Windows, iPhone, Android та інших пристроях. Це приклад роботи на iPhone 12 Pro.

Процес впровадження включає:
- Квантизацію моделі для мобільної оптимізації.
- Інтеграцію ONNX Runtime для сумісності між платформами.
- Локальне виконання без підключення до інтернету.
- Продуктивність у реальному часі з мінімальним споживанням енергії.

## Еволюція сімейства Phi

### Phi-1 та Phi-2: Базові моделі

Ранні моделі Phi заклали основи принципів високоякісних навчальних даних та ефективних архітектур:

- **Phi-1 (1.3B параметрів)**: Ввела концепцію відфільтрованих навчальних даних для базового розуміння мови та генерації коду.
- **Phi-2 (2.7B параметрів)**: Покращила логічні можливості через синтетичні NLP-дані та ретельно відібраний веб-контент.

### Сімейство Phi-3: Масове впровадження

Серія Phi-3 стала проривом у можливостях SLM із кількома спеціалізованими варіантами:

- **Phi-3-mini (3.8B параметрів)**: Загальні мовні завдання з винятковою ефективністю, перевершуючи моделі вдвічі більші за розміром.
- **Phi-3-small (7B параметрів)**: Покращена продуктивність, перевершуючи GPT-3.5 Turbo у різних тестах.
- **Phi-3-medium (14B параметрів)**: Продуктивність корпоративного рівня, перевершуючи Gemini 1.0 Pro.
- **Phi-3-vision (4.2B параметрів)**: Мультимодальні
Сімейство Phi демонструє, що майбутнє впровадження штучного інтелекту полягає не лише у створенні більших моделей, але й у розробці розумніших, більш ефективних моделей, які можуть ефективно працювати в різноманітних апаратних середовищах, зберігаючи високі стандарти продуктивності.

## Приклади розробки та інтеграції

### Швидкий старт із Transformers

Ось як почати роботу з моделями Phi, використовуючи бібліотеку Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Приклад тонкого налаштування

Наступний приклад показує, як налаштувати Phi-4-mini-instruct для виконання конкретних завдань:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Спеціалізовані формати запитів

**Для завдань логічного мислення (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Для математичних завдань (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Мобільне впровадження з ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Оцінка продуктивності та досягнення

Сімейство моделей Phi досягло вражаючих результатів у різних тестах, часто перевершуючи набагато більші моделі:

### Основні досягнення продуктивності

**Відмінність у математичному мисленні:**
- Phi-4 досягає 82.5% точності на AIME 2025 (кваліфікація на математичну олімпіаду)
- Phi-4-reasoning (14B) перевершує DeepSeek-R1-Distill-70B (у 5 разів більшу) у тестах логічного мислення
- Phi-4-mini-reasoning (3.8B) конкурує з моделями, які вдвічі більші, у завданнях математичного мислення

**Досягнення ефективності:**
- Phi-3-Silica обробляє 650 токенів за секунду, споживаючи лише 1.5W потужності
- Phi-4-mini (3.8B) демонструє продуктивність, схожу на набагато більші моделі

**Результати тестів:**
- **MMLU (Масове багатозадачне розуміння мови)**: Конкурентна продуктивність у 57 академічних предметах
- **HumanEval**: Сильні можливості генерації коду, особливо в Python
- **MGSM**: Розв'язання багатомовних математичних задач початкового рівня
- **DROP**: Складні завдання з розуміння та логічного мислення
- **SimpleQA**: Точність відповідей на фактичні запити

### 📊 Матриця порівняння моделей

| Модель | Параметри | Довжина контексту | Основні сильні сторони | Найкращі випадки використання |
|--------|-----------|-------------------|------------------------|-------------------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Загальна ефективність | Мобільні додатки, базові чат-боти |
| **Phi-3.5-mini** | 3.8B | 128K | Підтримка багатомовності | Міжнародні застосування |
| **Phi-4-mini** | 3.8B | 128K | Покращене логічне мислення, виклик функцій | Автоматизація бізнесу |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Математичне мислення | Освітні платформи |
| **Phi-4** | 14B | 32K | Складне логічне мислення | Дослідження, розширений аналіз |
| **Phi-4-reasoning** | 14B | 32K/64K | Багатокрокове мислення | Наукові обчислення |
| **Phi-4-reasoning-plus** | 14B | 32K | Максимальна точність логічного мислення | Критичне прийняття рішень |
| **Phi-4-multimodal** | 5.6B | Змінна | Мова, зображення, текст | Мультимедійні застосування |

## Посібник з вибору моделі

### Для базових застосувань
- **Phi-3-mini**: Просте генерування тексту, базові запитання-відповіді, швидкі відповіді
- **Phi-4-mini**: Покращене логічне мислення з можливістю виклику функцій

### Для математичних і логічних завдань
- **Phi-4**: Складне розв'язання математичних задач і логічне мислення
- **Phi-4-reasoning**: Багатокрокове мислення з детальними поясненнями
- **Phi-4-reasoning-plus**: Максимальна точність для критичних завдань логічного мислення
- **Phi-4-mini-reasoning**: Ефективне математичне мислення для середовищ із обмеженими ресурсами

### Для мультимедійних застосувань
- **Phi-3-vision**: Комбінація обробки зображень і тексту
- **Phi-4-multimodal**: Комплексні можливості для мови, зображень і тексту

### Для корпоративного впровадження
- **Phi-3-medium**: Розширене розуміння мови для бізнес-застосувань
- **Phi-3-Silica**: Оптимізована для конкретних апаратних платформ

## Платформи впровадження та доступність

### Хмарні платформи
- **Azure AI Foundry**: Повнофункціональне впровадження з корпоративними інструментами
- **Hugging Face**: Репозиторій відкритих моделей і ресурси спільноти
- **NVIDIA API Catalog**: Варіанти впровадження мікросервісів

### Локальні фреймворки розробки
- **Ollama**: Легкий фреймворк для локального впровадження моделей
- **ONNX Runtime**: Оптимізований для різних апаратних конфігурацій  
- **DirectML**: Оптимізована продуктивність для Windows
- **llama.cpp**: Кросплатформний механізм інференції

### Навчальні ресурси
- **Phi Portal**: Офіційний центр документації Microsoft Phi
- **Phi Cookbook**: Комплексні приклади та навчальні матеріали
- **Technical Reports**: Детальні наукові статті на arxiv
- **Community Spaces**: Інтерактивні демо на Hugging Face

### Початок роботи з моделями Phi

#### Платформи розробки
1. **Azure AI Foundry**: Простий локальний CLI та управління моделями.
2. **Hugging Face Transformers**: Швидкі локальні експерименти
3. **Ollama**: Просте локальне впровадження для тестування

#### Шлях навчання
1. **Зрозумійте основні концепції**: Вивчіть фундаментальні принципи дизайну
2. **Експериментуйте з варіантами**: Спробуйте різні моделі Phi, щоб зрозуміти їхні можливості
3. **Практикуйте впровадження**: Впроваджуйте моделі в тестових середовищах
4. **Масштабуйте впровадження**: Поступово розширюйте використання на основі успішних пілотів

#### Найкращі практики
- **Починайте з малого**: Почніть із моделей Phi-mini для початкової розробки
- **Оптимізуйте запити**: Використовуйте правильне форматування чатів для найкращих результатів
- **Моніторте продуктивність**: Відстежуйте швидкість інференції та метрики точності
- **Враховуйте апаратне забезпечення**: Вибирайте розмір моделі відповідно до доступних обчислювальних ресурсів

## Висновок

Сімейство моделей Microsoft Phi представляє революційний підхід до дизайну моделей штучного інтелекту, демонструючи, що менші, більш ефективні моделі можуть досягати вражаючих результатів у різних завданнях. Завдяки акценту на високоякісних навчальних даних і архітектурних оптимізаціях, сімейство Phi забезпечує виняткові можливості зі значно зниженими вимогами до обчислювальних ресурсів порівняно з традиційними великими мовними моделями.

## Основні навчальні цілі

1. Зрозуміти філософію дизайну та еволюцію сімейства моделей Microsoft Phi від Phi-1 до Phi-4
2. Визначити ключові інновації, включаючи навчання "якісного рівня підручника" та архітектурні оптимізації
3. Розпізнати переваги та обмеження різних варіантів Phi у різних сценаріях впровадження
4. Застосувати знання для вибору відповідних моделей Phi для конкретних випадків використання та апаратних обмежень
5. Впроваджувати техніки оптимізації для використання моделей Phi на пристроях із обмеженими ресурсами
6. Пояснити архітектурні переваги сімейства моделей Phi над традиційними великими мовними моделями
7. Вибрати відповідний варіант Phi на основі конкретних вимог застосування та апаратних обмежень
8. Впроваджувати моделі Phi як у хмарних, так і в локальних сценаріях із оптимізованими конфігураціями
9. Застосовувати техніки квантування та оптимізації для покращення продуктивності моделей Phi на цільових пристроях
10. Оцінювати компроміси між розміром моделі, продуктивністю та можливостями в межах сімейства Phi

## Що далі

- [02: Основи сімейства Qwen](02.QwenFamily.md)

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.