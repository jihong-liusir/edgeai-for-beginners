<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-25T02:26:51+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "uk"
}
-->
# EdgeAI для початківців: Навчальні шляхи та графік навчання

### Інтенсивний навчальний шлях (1 тиждень)

| День | Фокус | Орієнтовні години |
|------|-------|------------------|
| День 1 | Модуль 1: Основи EdgeAI | 3 години |
| День 2 | Модуль 2: Основи SLM | 3 години |
| День 3 | Модуль 3: Розгортання SLM | 2 години |
| День 4-5 | Модуль 4: Оптимізація моделей (6 фреймворків) | 4 години |
| День 6 | Модуль 5: SLMOps | 3 години |
| День 7 | Модуль 6-7: AI-агенти та інструменти розробки | 4 години |
| День 8 | Модуль 8: Локальний інструментарій Foundry (сучасна реалізація) | 1 година |

### Інтенсивний навчальний шлях (2 тижні)

| День | Фокус | Орієнтовні години |
|------|-------|------------------|
| День 1-2 | Модуль 1: Основи EdgeAI | 3 години |
| День 3-4 | Модуль 2: Основи SLM | 3 години |
| День 5-6 | Модуль 3: Розгортання SLM | 2 години |
| День 7-8 | Модуль 4: Оптимізація моделей | 4 години |
| День 9-10 | Модуль 5: SLMOps | 3 години |
| День 11-12 | Модуль 6: AI-агенти | 2 години |
| День 13-14 | Модуль 7: Інструменти розробки | 3 години |

### Часткове навчання (4 тижні)

| Тиждень | Фокус | Орієнтовні години |
|------|-------|------------------|
| Тиждень 1 | Модуль 1-2: Основи та SLM | 6 годин |
| Тиждень 2 | Модуль 3-4: Розгортання та оптимізація | 6 годин |
| Тиждень 3 | Модуль 5-6: SLMOps та AI-агенти | 5 годин |
| Тиждень 4 | Модуль 7: Інструменти розробки та інтеграція | 3 години |

| День | Фокус | Орієнтовні години |
|------|-------|------------------|
| День 1-2 | Модуль 1: Основи EdgeAI | 3 години |
| День 3-4 | Модуль 2: Основи SLM | 3 години |
| День 5-6 | Модуль 3: Розгортання SLM | 2 години |
| День 7-8 | Модуль 4: Оптимізація моделей | 4 години |
| День 9-10 | Модуль 5: SLMOps | 3 години |
| День 11-12 | Модуль 6: Агентні системи SLM | 2 години |
| День 13-14 | Модуль 7: Приклади реалізації EdgeAI | 2 години |

| Модуль | Дата завершення | Витрачені години | Основні висновки |
|--------|----------------|-------------|--------------|
| Модуль 1: Основи EdgeAI | | | |
| Модуль 2: Основи SLM | | | |
| Модуль 3: Розгортання SLM | | | |
| Модуль 4: Оптимізація моделей (6 фреймворків) | | | |
| Модуль 5: SLMOps | | | |
| Модуль 6: Агентні системи SLM | | | |
| Модуль 7: Приклади реалізації EdgeAI | | | |
| Практичні вправи | | | |
| Міні-проєкт | | | |

### Часткове навчання (4 тижні)

| Тиждень | Фокус | Орієнтовні години |
|------|-------|------------------|
| Тиждень 1 | Модуль 1-2: Основи та SLM | 6 годин |
| Тиждень 2 | Модуль 3-4: Розгортання та оптимізація | 6 годин |
| Тиждень 3 | Модуль 5-6: SLMOps та AI-агенти | 5 годин |
| Тиждень 4 | Модуль 7: Інструменти розробки та інтеграція | 3 години |

## Вступ

Ласкаво просимо до навчального посібника "EdgeAI для початківців"! Цей документ допоможе вам ефективно освоїти матеріали курсу та максимально використати ваш навчальний досвід. Він пропонує структуровані навчальні шляхи, рекомендовані графіки навчання, ключові концепції та додаткові ресурси для глибшого розуміння технологій EdgeAI.

Це стислий курс тривалістю 20 годин, який надає основні знання про EdgeAI у форматі, що економить час, ідеально підходить для зайнятих професіоналів та студентів, які хочуть швидко отримати практичні навички в цій новій галузі.

## Огляд курсу

Курс організований у сім комплексних модулів:

1. **Основи EdgeAI та трансформація** - Розуміння основних концепцій та технологічних змін
2. **Основи малих мовних моделей (SLM)** - Дослідження різних сімейств SLM та їх архітектур
3. **Розгортання малих мовних моделей** - Реалізація практичних стратегій розгортання
4. **Конвертація формату моделей та квантування** - Розширена оптимізація з використанням 6 фреймворків, включаючи OpenVINO
5. **SLMOps - Операції з малими мовними моделями** - Управління життєвим циклом виробництва та розгортання
6. **Агентні системи SLM** - AI-агенти, виклик функцій та протокол контексту моделі
7. **Приклади реалізації EdgeAI** - AI Toolkit, розробка для Windows та специфічні для платформи реалізації
8. **Microsoft Foundry Local – Повний інструментарій розробника** - Локальна розробка з гібридною інтеграцією Azure (Модуль 08)

## Як використовувати цей навчальний посібник

- **Поступове навчання**: Дотримуйтесь модулів у порядку для найбільш логічного навчального досвіду
- **Контроль знань**: Використовуйте питання для самоперевірки після кожного розділу
- **Практичні вправи**: Виконуйте запропоновані завдання для закріплення теоретичних концепцій
- **Додаткові ресурси**: Досліджуйте додаткові матеріали для тем, які вас найбільше цікавлять

## Рекомендації щодо графіка навчання

### Інтенсивний навчальний шлях (1 тиждень)

| День | Фокус | Орієнтовні години |
|------|-------|-----------------|
| День 1-2 | Модуль 1: Основи EdgeAI | 6 годин |
| День 3-4 | Модуль 2: Основи SLM | 8 годин |
| День 5 | Модуль 3: Розгортання SLM | 3 години |
| День 6 | Модуль 8: Локальний інструментарій Foundry | 3 години |

### Часткове навчання (3 тижні)

| Тиждень | Фокус | Орієнтовні години |
|------|-------|-----------------|
| Тиждень 1 | Модуль 1: Основи EdgeAI | 6-7 годин |
| Тиждень 2 | Модуль 2: Основи SLM | 7-8 годин |
| Тиждень 3 | Модуль 3: Розгортання SLM (3 год) + Модуль 8: Локальний інструментарій Foundry (2-3 год) | 5-6 годин |

## Модуль 1: Основи EdgeAI та трансформація

### Основні навчальні цілі

- Розуміння відмінностей між хмарним та локальним AI
- Оволодіння основними техніками оптимізації для середовищ з обмеженими ресурсами
- Аналіз реальних застосувань технологій EdgeAI
- Налаштування середовища розробки для проєктів EdgeAI

### Основні області навчання

#### Розділ 1: Основи EdgeAI
- **Пріоритетні концепції**: 
  - Парадигми хмарних та локальних обчислень
  - Техніки квантування моделей
  - Варіанти апаратного прискорення (NPUs, GPUs, CPUs)
  - Переваги конфіденційності та безпеки

- **Додаткові матеріали**:
  - [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Documentation](https://docs.edgeimpulse.com)

#### Розділ 2: Реальні кейси
- **Пріоритетні концепції**: 
  - Екосистема моделей Microsoft Phi & Mu
  - Практичні реалізації в різних галузях
  - Міркування щодо розгортання

#### Розділ 3: Практичний посібник з реалізації
- **Пріоритетні концепції**: 
  - Налаштування середовища розробки
  - Інструменти квантування та оптимізації
  - Методи оцінки реалізацій EdgeAI

#### Розділ 4: Апаратне забезпечення для розгортання
- **Пріоритетні концепції**: 
  - Порівняння платформ апаратного забезпечення
  - Стратегії оптимізації для конкретного обладнання
  - Міркування щодо розгортання

### Питання для самоперевірки

1. Порівняйте та протиставте реалізації AI на основі хмари та локального середовища.
2. Поясніть три ключові техніки оптимізації моделей для локального розгортання.
3. Які основні переваги запуску AI моделей на локальному обладнанні?
4. Опишіть процес квантування моделі та як це впливає на продуктивність.
5. Поясніть, як різні апаратні прискорювачі (NPUs, GPUs, CPUs) впливають на розгортання EdgeAI.

### Практичні вправи

1. **Швидке налаштування середовища**: Налаштуйте мінімальне середовище розробки з необхідними пакетами (30 хвилин)
2. **Дослідження моделі**: Завантажте та вивчіть попередньо навчену малу мовну модель (1 година)
3. **Базове квантування**: Спробуйте просте квантування на невеликій моделі (1 година)

## Модуль 2: Основи малих мовних моделей (SLM)

### Основні навчальні цілі

- Розуміння архітектурних принципів різних сімейств SLM
- Порівняння можливостей моделей різних масштабів параметрів
- Оцінка моделей за ефективністю, можливостями та вимогами до розгортання
- Визначення відповідних сценаріїв використання для різних сімейств моделей

### Основні області навчання

#### Розділ 1: Сімейство моделей Microsoft Phi
- **Пріоритетні концепції**: 
  - Еволюція філософії дизайну
  - Архітектура з акцентом на ефективність
  - Спеціалізовані можливості

#### Розділ 2: Сімейство Qwen
- **Пріоритетні концепції**: 
  - Внесок у відкритий код
  - Масштабовані варіанти розгортання
  - Архітектура для розширеного логічного мислення

#### Розділ 3: Сімейство Gemma
- **Пріоритетні концепції**: 
  - Інновації, орієнтовані на дослідження
  - Мультимодальні можливості
  - Оптимізація для мобільних пристроїв

#### Розділ 4: Сімейство BitNET
- **Пріоритетні концепції**: 
  - Технологія квантування з точністю 1-біт
  - Фреймворк оптимізації для інференсу
  - Міркування щодо сталого розвитку

#### Розділ 5: Модель Microsoft Mu
- **Пріоритетні концепції**: 
  - Архітектура, орієнтована на пристрої
  - Інтеграція з Windows
  - Операція з збереженням конфіденційності

#### Розділ 6: Phi-Silica
- **Пріоритетні концепції**: 
  - Архітектура, оптимізована для NPU
  - Метрики продуктивності
  - Інтеграція для розробників

### Питання для самоперевірки

1. Порівняйте архітектурні підходи сімейств моделей Phi та Qwen.
2. Поясніть, чим технологія квантування BitNET відрізняється від традиційного квантування.
3. Які унікальні переваги моделі Mu для інтеграції з Windows?
4. Опишіть, як Phi-Silica використовує апаратне забезпечення NPU для оптимізації продуктивності.
5. Для мобільного додатку з обмеженим підключенням, яке сімейство моделей буде найбільш відповідним і чому?

### Практичні вправи

1. **Порівняння моделей**: Швидкий бенчмарк двох різних моделей SLM (1 година)
2. **Просте генерування тексту**: Базова реалізація генерування тексту за допомогою малої моделі (1 година)
3. **Швидка оптимізація**: Застосуйте одну техніку оптимізації для покращення швидкості інференсу (1 година)

## Модуль 3: Розгортання малих мовних моделей

### Основні навчальні цілі

- Вибір відповідних моделей залежно від обмежень розгортання
- Оволодіння техніками оптимізації для різних сценаріїв розгортання
- Реалізація SLM як у локальному, так і в хмарному середовищі
- Розробка конфігурацій, готових до виробництва, для застосувань EdgeAI

### Основні області навчання

#### Розділ 1: Розширене навчання SLM
- **Пріоритетні концепції**: 
  - Класифікація параметрів моделей
  - Розширені техніки оптимізації
  - Стратегії отримання моделей

#### Розділ 2: Розгортання в локальному середовищі
- **Пріоритетні концепції**: 
  - Розгортання на платформі Ollama
  - Локальні рішення Microsoft Foundry
  - Порівняльний аналіз фреймворків

#### Розділ 3: Контейнеризоване хмарне розгортання
- **Пріоритетні концепції**: 
  - Інференс високої продуктивності на vLLM
  - Оркестрація контейнерів
  - Реалізація ONNX Runtime

### Питання для самоперевірки

1. Які фактори слід враховувати при виборі між локальним розгортанням та хмарним?
2. Порівняйте Ollama та Microsoft Foundry Local як варіанти розгортання.
3. Поясніть переваги контейнеризації для розгортання SLM.
4. Які ключові метрики продуктивності слід моніторити для SLM, розгорнутого на локальному обладнанні?
5. Опишіть повний робочий процес розгортання від вибору моделі до реалізації у виробництві.

### Практичні вправи

1. **Базове локальне розгортання**: Розгорніть просту SLM за допомогою Ollama (1 година)
2. **Перевірка продуктивності**: Проведіть швидкий бенчмарк на розгорнутій моделі (30 хвилин)
3. **Проста інтеграція**: Створіть мінімальний додаток, який використовує вашу розгорнуту модель (1 година)

## Модуль 4: Конвертація формату моделей та квантування

### Основні навчальні цілі

- Оволодіння розширеними техніками квантування
- OpenVINO GenAI для розгортання LLM

#### Розділ 5: Apple MLX Framework
- **Пріоритетні концепції**: 
  - Оптимізація для Apple Silicon
  - Архітектура об'єднаної пам'яті
  - Можливості тонкого налаштування LoRA

#### Розділ 6: Синтез робочого процесу розробки Edge AI
- **Пріоритетні концепції**: 
  - Уніфікована архітектура робочого процесу
  - Дерева рішень для вибору фреймворків
  - Перевірка готовності до виробництва
  - Стратегії забезпечення майбутньої сумісності

### Питання для самоперевірки

1. Порівняйте стратегії квантування для різних рівнів точності (від 1-біт до 8-біт).
2. Поясніть переваги формату GGUF для розгортання на периферії.
3. Як апаратно-орієнтована оптимізація в Microsoft Olive покращує ефективність розгортання?
4. Які ключові переваги OpenVINO NNCF для стиснення моделей?
5. Опишіть, як Apple MLX використовує архітектуру об'єднаної пам'яті для оптимізації.
6. Як синтез робочого процесу допомагає у виборі оптимальних фреймворків для оптимізації?

### Практичні завдання

1. **Квантування моделі**: Застосуйте різні рівні квантування до моделі та порівняйте результати (1 година)
2. **Оптимізація OpenVINO**: Використовуйте NNCF для стиснення моделі для апаратного забезпечення Intel (1 година)
3. **Порівняння фреймворків**: Протестуйте одну й ту ж модель у трьох різних фреймворках оптимізації (1 година)
4. **Оцінка продуктивності**: Виміряйте вплив оптимізації на швидкість інференсу та використання пам'яті (1 година)

## Модуль 5: SLMOps - Операції з малими мовними моделями

### Основні навчальні цілі

- Зрозуміти принципи управління життєвим циклом SLMOps
- Опанувати техніки дистиляції та тонкого налаштування для розгортання на периферії
- Реалізувати стратегії розгортання у виробництві з моніторингом
- Створити робочі процеси для операцій і обслуговування SLM корпоративного рівня

### Основні області для вивчення

#### Розділ 1: Вступ до SLMOps
- **Пріоритетні концепції**: 
  - Зміна парадигми SLMOps в AI-операціях
  - Ефективність витрат і архітектура з пріоритетом конфіденційності
  - Стратегічний бізнес-ефект і конкурентні переваги

#### Розділ 2: Дистиляція моделі
- **Пріоритетні концепції**: 
  - Техніки передачі знань
  - Реалізація двоетапного процесу дистиляції
  - Робочі процеси дистиляції в Azure ML

#### Розділ 3: Стратегії тонкого налаштування
- **Пріоритетні концепції**: 
  - Ефективне налаштування параметрів (PEFT)
  - Розширені методи LoRA і QLoRA
  - Багатоадаптерне навчання та оптимізація гіперпараметрів

#### Розділ 4: Розгортання у виробництві
- **Пріоритетні концепції**: 
  - Конверсія моделі та квантування для виробництва
  - Конфігурація локального розгортання Foundry
  - Оцінка продуктивності та перевірка якості

### Питання для самоперевірки

1. Чим SLMOps відрізняється від традиційного MLOps?
2. Поясніть переваги дистиляції моделі для розгортання на периферії.
3. Які ключові аспекти слід враховувати при тонкому налаштуванні SLM у середовищах з обмеженими ресурсами?
4. Опишіть повний конвеєр розгортання у виробництві для застосунків Edge AI.

### Практичні завдання

1. **Основна дистиляція**: Створіть меншу модель на основі більшої моделі-вчителя (1 година)
2. **Експеримент з тонким налаштуванням**: Налаштуйте модель для конкретної галузі (1 година)
3. **Конвеєр розгортання**: Налаштуйте базовий конвеєр CI/CD для розгортання моделі (1 година)

## Модуль 6: Агентні системи SLM - AI-агенти та виклик функцій

### Основні навчальні цілі

- Створювати інтелектуальні AI-агенти для периферійних середовищ, використовуючи малі мовні моделі
- Реалізувати можливості виклику функцій за допомогою систематичних робочих процесів
- Опанувати інтеграцію Model Context Protocol (MCP) для стандартизованої взаємодії з інструментами
- Створювати складні агентні системи з мінімальним втручанням людини

### Основні області для вивчення

#### Розділ 1: AI-агенти та основи SLM
- **Пріоритетні концепції**: 
  - Класифікація агентів (рефлексивні, модельні, цілеспрямовані, навчальні агенти)
  - Аналіз компромісів між SLM і LLM
  - Шаблони дизайну агентів для периферії
  - Оптимізація ресурсів для агентів

#### Розділ 2: Виклик функцій у малих мовних моделях
- **Пріоритетні концепції**: 
  - Реалізація систематичних робочих процесів (виявлення намірів, JSON-вивід, зовнішнє виконання)
  - Реалізації для конкретних платформ (Phi-4-mini, вибрані моделі Qwen, Microsoft Foundry Local)
  - Розширені приклади (співпраця між агентами, динамічний вибір інструментів)
  - Виробничі аспекти (обмеження швидкості, аудит, заходи безпеки)

#### Розділ 3: Інтеграція Model Context Protocol (MCP)
- **Пріоритетні концепції**: 
  - Архітектура протоколу та багатошаровий дизайн системи
  - Підтримка багатьох бекендів (Ollama для розробки, vLLM для виробництва)
  - Протоколи з'єднання (режими STDIO і SSE)
  - Реальні застосування (автоматизація вебу, обробка даних, інтеграція API)

### Питання для самоперевірки

1. Які ключові архітектурні аспекти для агентів Edge AI?
2. Як виклик функцій покращує можливості агентів?
3. Поясніть роль Model Context Protocol у комунікації агентів.

### Практичні завдання

1. **Простий агент**: Створіть базового AI-агента з викликом функцій (1 година)
2. **Інтеграція MCP**: Реалізуйте MCP у застосунку агента (30 хвилин)

## Модуль 7: Зразки реалізації EdgeAI

### Основні навчальні цілі

- Опанувати AI Toolkit для Visual Studio Code для комплексних робочих процесів розробки EdgeAI
- Отримати експертизу у платформі Windows AI Foundry та стратегіях оптимізації NPU
- Реалізувати EdgeAI на різних апаратних платформах і сценаріях розгортання
- Створювати готові до виробництва застосунки EdgeAI з оптимізацією для конкретних платформ

### Основні області для вивчення

#### Розділ 1: AI Toolkit для Visual Studio Code
- **Пріоритетні концепції**: 
  - Комплексне середовище розробки Edge AI у VS Code
  - Каталог моделей і їх пошук для розгортання на периферії
  - Локальне тестування, оптимізація та розробка агентів
  - Моніторинг продуктивності та оцінка для сценаріїв периферії

#### Розділ 2: Посібник з розробки Windows EdgeAI
- **Пріоритетні концепції**: 
  - Комплексний огляд платформи Windows AI Foundry
  - API Phi Silica для ефективного інференсу на NPU
  - API комп'ютерного зору для обробки зображень і OCR
  - CLI Foundry Local для локальної розробки та тестування

#### Розділ 3: Реалізації для конкретних платформ
- **Пріоритетні концепції**: 
  - Розгортання NVIDIA Jetson Orin Nano (67 TOPS AI продуктивності)
  - Мобільні застосунки з .NET MAUI і ONNX Runtime GenAI
  - Рішення Azure EdgeAI з гібридною архітектурою хмара-периферія
  - Оптимізація Windows ML з універсальною підтримкою апаратного забезпечення
  - Застосунки Foundry Local з конфіденційно-орієнтованою реалізацією RAG

### Питання для самоперевірки

1. Як AI Toolkit спрощує робочий процес розробки EdgeAI?
2. Порівняйте стратегії розгортання на різних апаратних платформах.
3. Які переваги Windows AI Foundry для розробки на периферії?
4. Поясніть роль оптимізації NPU у сучасних застосунках Edge AI.
5. Як API Phi Silica використовує апаратне забезпечення NPU для оптимізації продуктивності?
6. Порівняйте переваги локального та хмарного розгортання для застосунків з високими вимогами до конфіденційності.

### Практичні завдання

1. **Налаштування AI Toolkit**: Налаштуйте AI Toolkit і оптимізуйте модель (1 година)
2. **Windows AI Foundry**: Створіть простий застосунок Windows AI, використовуючи API Phi Silica (1 година)
3. **Кросплатформне розгортання**: Розгорніть одну й ту ж модель на двох різних платформах (1 година)
4. **Оптимізація NPU**: Протестуйте продуктивність NPU за допомогою інструментів Windows AI Foundry (30 хвилин)

## Модуль 8: Microsoft Foundry Local – Повний набір інструментів для розробників (модернізований)

### Основні навчальні цілі

- Встановити та налаштувати Foundry Local з інтеграцією сучасного SDK
- Реалізувати розширені багатосистемні агентні системи з шаблонами координаторів
- Створювати інтелектуальні маршрутизатори моделей з автоматичним вибором на основі завдань
- Розгортати готові до виробництва AI-рішення з комплексним моніторингом
- Інтегрувати з Azure AI Foundry для гібридних сценаріїв розгортання
- Опанувати сучасні шаблони SDK з FoundryLocalManager і клієнтом OpenAI

### Основні області для вивчення

#### Розділ 1: Сучасна установка та конфігурація
- **Пріоритетні концепції**: 
  - Інтеграція SDK FoundryLocalManager
  - Автоматичне виявлення сервісів і моніторинг стану
  - Шаблони конфігурації на основі середовища
  - Аспекти розгортання у виробництві

#### Розділ 2: Розширені багатосистемні агентні системи
- **Пріоритетні концепції**: 
  - Шаблон координатора зі спеціалізованими агентами
  - Спеціалізація агентів для пошуку, аналізу та виконання
  - Механізми зворотного зв'язку для вдосконалення
  - Моніторинг продуктивності та відстеження статистики

#### Розділ 3: Інтелектуальне маршрутизування моделей
- **Пріоритетні концепції**: 
  - Алгоритми вибору моделей на основі ключових слів
  - Підтримка кількох моделей (загальні, аналітичні, кодові, творчі)
  - Конфігурація змінних середовища для гнучкості
  - Перевірка стану сервісів і обробка помилок

#### Розділ 4: Реалізація, готова до виробництва
- **Пріоритетні концепції**: 
  - Комплексна обробка помилок і механізми резервування
  - Моніторинг запитів і відстеження продуктивності
  - Інтерактивні приклади в Jupyter Notebook з оцінками
  - Шаблони інтеграції з існуючими застосунками

### Питання для самоперевірки

1. Чим сучасний підхід FoundryLocalManager відрізняється від ручних REST-викликів?
2. Поясніть шаблон координатора та як він організовує спеціалізованих агентів.
3. Як інтелектуальний маршрутизатор вибирає відповідні моделі на основі змісту запиту?
4. Які ключові компоненти системи AI-агентів, готової до виробництва?
5. Як реалізувати комплексний моніторинг стану сервісів Foundry Local?
6. Порівняйте переваги модернізованого підходу з традиційними шаблонами реалізації.

### Практичні завдання

1. **Налаштування сучасного SDK**: Налаштуйте FoundryLocalManager з автоматичним виявленням сервісів (30 хвилин)
2. **Багатосистемна агентна система**: Запустіть розширений координатор зі спеціалізованими агентами (30 хвилин)
3. **Інтелектуальне маршрутизування**: Протестуйте маршрутизатор моделей з різними типами запитів (30 хвилин)
4. **Інтерактивне дослідження**: Використовуйте Jupyter Notebook для дослідження розширених функцій (45 хвилин)
5. **Розгортання у виробництві**: Реалізуйте шаблони моніторингу та обробки помилок (30 хвилин)
6. **Гібридна інтеграція**: Налаштуйте сценарії резервування Azure AI Foundry (30 хвилин)

## Гід з розподілу часу

Щоб максимально використати 20-годинний курс, ось рекомендований розподіл часу:

| Діяльність | Розподіл часу | Опис |
|------------|--------------|------|
| Читання основних матеріалів | 9 годин | Зосередження на ключових концепціях кожного модуля |
| Практичні завдання | 6 годин | Практична реалізація основних технік |
| Самоперевірка | 2 години | Перевірка розуміння через питання та рефлексію |
| Міні-проєкт | 3 години | Застосування знань у невеликій практичній реалізації |

### Основні області фокусування за обмеженням часу

**Якщо у вас є лише 10 годин:**
- Завершіть модулі 1, 2 і 3 (основні концепції EdgeAI)
- Виконайте принаймні одне практичне завдання на кожен модуль
- Зосередьтеся на розумінні основних концепцій, а не на деталях реалізації

**Якщо ви можете присвятити повні 20 годин:**
- Завершіть усі сім модулів
- Виконайте ключові практичні завдання з кожного модуля
- Завершіть один міні-проєкт із модуля 7
- Ознайомтеся з принаймні 2-3 додатковими ресурсами

**Якщо у вас є більше ніж 20 годин:**
- Завершіть усі модулі з детальними завданнями
- Створіть кілька міні-проєктів
- Досліджуйте розширені техніки оптимізації в модулі 4
- Реалізуйте розгортання у виробництві з модуля 5

## Основні ресурси

Ці ретельно відібрані ресурси забезпечують максимальну цінність
| Практичні вправи | | | |
| Міні-проєкт | | | |

## Ідеї для міні-проєктів

Розгляньте можливість виконання одного з цих проєктів для практики концепцій EdgeAI (кожен розрахований на 2-4 години):

### Проєкти для початківців (2-3 години кожен)
1. **Edge Text Assistant**: Створіть простий офлайн-інструмент для завершення тексту, використовуючи невелику мовну модель.
2. **Model Comparison Dashboard**: Побудуйте базову візуалізацію метрик продуктивності для різних SLM.
3. **Optimization Experiment**: Виміряйте вплив різних рівнів квантування на одну базову модель.

### Проєкти середнього рівня (3-4 години кожен)
4. **AI Toolkit Workflow**: Використовуйте VS Code AI Toolkit для оптимізації та розгортання моделі від початку до кінця.
5. **Windows AI Foundry Application**: Створіть Windows-додаток, використовуючи Phi Silica API та оптимізацію NPU.
6. **Cross-Platform Deployment**: Розгорніть ту саму оптимізовану модель на Windows (OpenVINO) та мобільних пристроях (.NET MAUI).
7. **Function Calling Agent**: Побудуйте AI-агента з можливостями виклику функцій для сценаріїв на периферії.

### Проєкти з інтеграцією для просунутих (4-5 годин кожен)
8. **OpenVINO Optimization Pipeline**: Реалізуйте повну оптимізацію моделі, використовуючи NNCF та GenAI toolkit.
9. **SLMOps Pipeline**: Реалізуйте повний життєвий цикл моделі від навчання до розгортання на периферії.
10. **Multi-Model Edge System**: Розгорніть кілька спеціалізованих моделей, які працюють разом на периферійному обладнанні.
11. **MCP Integration System**: Побудуйте агентну систему, використовуючи Model Context Protocol для взаємодії з інструментами.

## Ресурси

- Microsoft Learn (Foundry Local)
  - Огляд: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Початок роботи: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Довідка CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Інтеграція з SDK для інференсу: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Як використовувати Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Компіляція моделей Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Огляд: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Агенти (огляд): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Інструменти оптимізації та інференсу
  - Microsoft Olive (документація): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (початок роботи): https://onnxruntime.ai/docs/get-started/with-python.html
  - Інтеграція ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (документація): https://docs.openvino.ai/2025/index.html
  - Apple MLX (документація): https://ml-explore.github.io/mlx/build/html/index.html
- Фреймворки розгортання та моделі
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (документація): https://docs.vllm.ai/
  - Ollama (швидкий старт): https://github.com/ollama/ollama#get-started
- Інструменти для розробників (Windows та VS Code)
  - AI Toolkit для VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (огляд): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Спільнота навчання

Приєднуйтесь до обговорень та спілкуйтеся з іншими учасниками:
- Обговорення на GitHub у [репозиторії EdgeAI для початківців](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Висновок

EdgeAI представляє передову технологію впровадження штучного інтелекту, яка забезпечує потужні можливості безпосередньо на пристроях, вирішуючи важливі питання конфіденційності, затримки та підключення. Цей 20-годинний курс надає вам основні знання та практичні навички для негайного початку роботи з технологіями EdgeAI.

Курс навмисно стислий і зосереджений на найважливіших концепціях, що дозволяє швидко отримати цінний досвід без надмірного витрачання часу. Пам’ятайте, що практичні вправи, навіть з простими прикладами, є ключем до закріплення отриманих знань.

Успіхів у навчанні!

---

