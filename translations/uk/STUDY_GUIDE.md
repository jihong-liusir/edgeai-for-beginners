<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-23T00:32:03+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "uk"
}
-->
# EdgeAI для початківців: Навчальні шляхи та графік навчання

### Інтенсивний навчальний шлях (1 тиждень)

| День | Фокус | Орієнтовні години |
|------|-------|------------------|
| День 1 | Модуль 1: Основи EdgeAI | 3 години |
| День 2 | Модуль 2: Основи SLM | 3 години |
| День 3 | Модуль 3: Розгортання SLM | 2 години |
| День 4-5 | Модуль 4: Оптимізація моделей (6 фреймворків) | 4 години |
| День 6 | Модуль 5: SLMOps | 3 години |
| День 7 | Модуль 6-7: AI-агенти та інструменти розробки | 5 годин |

### Інтенсивний навчальний шлях (2 тижні)

| День | Фокус | Орієнтовні години |
|------|-------|------------------|
| День 1-2 | Модуль 1: Основи EdgeAI | 3 години |
| День 3-4 | Модуль 2: Основи SLM | 3 години |
| День 5-6 | Модуль 3: Розгортання SLM | 2 години |
| День 7-8 | Модуль 4: Оптимізація моделей | 4 години |
| День 9-10 | Модуль 5: SLMOps | 3 години |
| День 11-12 | Модуль 6: AI-агенти | 2 години |
| День 13-14 | Модуль 7: Інструменти розробки | 3 години |

### Часткове навчання (4 тижні)

| Тиждень | Фокус | Орієнтовні години |
|------|-------|------------------|
| Тиждень 1 | Модуль 1-2: Основи та SLM | 6 годин |
| Тиждень 2 | Модуль 3-4: Розгортання та оптимізація | 6 годин |
| Тиждень 3 | Модуль 5-6: SLMOps та AI-агенти | 5 годин |
| Тиждень 4 | Модуль 7: Інструменти розробки та інтеграція | 3 години |

| День | Фокус | Орієнтовні години |
|------|-------|------------------|
| День 1-2 | Модуль 1: Основи EdgeAI | 3 години |
| День 3-4 | Модуль 2: Основи SLM | 3 години |
| День 5-6 | Модуль 3: Розгортання SLM | 2 години |
| День 7-8 | Модуль 4: Оптимізація моделей | 4 години |
| День 9-10 | Модуль 5: SLMOps | 3 години |
| День 11-12 | Модуль 6: Агентні системи SLM | 2 години |
| День 13-14 | Модуль 7: Приклади реалізації EdgeAI | 2 години |

| Модуль | Дата завершення | Витрачені години | Основні висновки |
|--------|----------------|-------------|--------------|
| Модуль 1: Основи EdgeAI | | | |
| Модуль 2: Основи SLM | | | |
| Модуль 3: Розгортання SLM | | | |
| Модуль 4: Оптимізація моделей (6 фреймворків) | | | |
| Модуль 5: SLMOps | | | |
| Модуль 6: Агентні системи SLM | | | |
| Модуль 7: Приклади реалізації EdgeAI | | | |
| Практичні вправи | | | |
| Міні-проєкт | | | |

### Часткове навчання (4 тижні)

| Тиждень | Фокус | Орієнтовні години |
|------|-------|------------------|
| Тиждень 1 | Модуль 1-2: Основи та SLM | 6 годин |
| Тиждень 2 | Модуль 3-4: Розгортання та оптимізація | 6 годин |
| Тиждень 3 | Модуль 5-6: SLMOps та AI-агенти | 5 годин |
| Тиждень 4 | Модуль 7: Інструменти розробки та інтеграція | 3 години |

## Вступ

Ласкаво просимо до навчального посібника "EdgeAI для початківців"! Цей документ створений, щоб допомогти вам ефективно освоїти матеріали курсу та максимально використати ваш навчальний досвід. Він пропонує структуровані навчальні шляхи, рекомендовані графіки навчання, ключові концепції та додаткові ресурси для поглиблення розуміння технологій EdgeAI.

Це стислий курс тривалістю 20 годин, який надає основні знання про EdgeAI у форматі, що економить час, ідеально підходить для зайнятих професіоналів та студентів, які хочуть швидко отримати практичні навички в цій новій галузі.

## Огляд курсу

Курс організований у сім комплексних модулів:

1. **Основи EdgeAI та трансформація** - Розуміння основних концепцій та технологічних змін
2. **Основи малих мовних моделей (SLM)** - Дослідження різних сімейств SLM та їх архітектур
3. **Розгортання малих мовних моделей (SLM)** - Реалізація практичних стратегій розгортання
4. **Конвертація формату моделей та квантування** - Розширена оптимізація за допомогою 6 фреймворків, включаючи OpenVINO
5. **SLMOps - Операції з малими мовними моделями** - Управління життєвим циклом виробництва та розгортання
6. **Агентні системи SLM** - AI-агенти, виклик функцій та протокол контексту моделі
7. **Приклади реалізації EdgeAI** - AI Toolkit, розробка для Windows та специфічні для платформи реалізації
8. **Microsoft Foundry Local – Повний набір інструментів для розробників** - Локальна розробка з гібридною інтеграцією Azure (Модуль 08)

## Як використовувати цей навчальний посібник

- **Поступове навчання**: Дотримуйтесь модулів у порядку для найбільш логічного навчального досвіду
- **Контроль знань**: Використовуйте питання для самоперевірки після кожного розділу
- **Практичні вправи**: Виконуйте запропоновані завдання для закріплення теоретичних концепцій
- **Додаткові ресурси**: Досліджуйте додаткові матеріали для тем, які вас найбільше цікавлять

## Рекомендації щодо графіка навчання

### Інтенсивний навчальний шлях (1 тиждень)

| День | Фокус | Орієнтовні години |
|------|-------|-----------------|
| День 1-2 | Модуль 1: Основи EdgeAI | 6 годин |
| День 3-4 | Модуль 2: Основи SLM | 8 годин |
| День 5 | Модуль 3: Розгортання SLM | 3 години |
| День 6 | Модуль 8: Набір інструментів Foundry Local | 3 години |

### Часткове навчання (3 тижні)

| Тиждень | Фокус | Орієнтовні години |
|------|-------|-----------------|
| Тиждень 1 | Модуль 1: Основи EdgeAI | 6-7 годин |
| Тиждень 2 | Модуль 2: Основи SLM | 7-8 годин |
| Тиждень 3 | Модуль 3: Розгортання SLM (3 год) + Модуль 8: Набір інструментів Foundry Local (2-3 год) | 5-6 годин |

## Модуль 1: Основи EdgeAI та трансформація

### Основні навчальні цілі

- Розуміння відмінностей між AI на основі хмари та AI на основі периферії
- Оволодіння основними техніками оптимізації для середовищ із обмеженими ресурсами
- Аналіз реальних застосувань технологій EdgeAI
- Налаштування середовища розробки для проєктів EdgeAI

### Основні області навчання

#### Розділ 1: Основи EdgeAI
- **Пріоритетні концепції**: 
  - Парадигми обчислень на периферії та в хмарі
  - Техніки квантування моделей
  - Опції апаратного прискорення (NPU, GPU, CPU)
  - Переваги конфіденційності та безпеки

- **Додаткові матеріали**:
  - [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Documentation](https://docs.edgeimpulse.com)

#### Розділ 2: Реальні кейси
- **Пріоритетні концепції**: 
  - Екосистема моделей Microsoft Phi & Mu
  - Практичні реалізації в різних галузях
  - Міркування щодо розгортання

#### Розділ 3: Практичний посібник з реалізації
- **Пріоритетні концепції**: 
  - Налаштування середовища розробки
  - Інструменти квантування та оптимізації
  - Методи оцінки реалізацій EdgeAI

#### Розділ 4: Апаратне забезпечення для розгортання на периферії
- **Пріоритетні концепції**: 
  - Порівняння платформ апаратного забезпечення
  - Стратегії оптимізації для конкретного апаратного забезпечення
  - Міркування щодо розгортання

### Питання для самоперевірки

1. Порівняйте та протиставте реалізації AI на основі хмари та на основі периферії.
2. Поясніть три ключові техніки оптимізації моделей для розгортання на периферії.
3. Які основні переваги запуску AI моделей на периферії?
4. Опишіть процес квантування моделі та як це впливає на продуктивність.
5. Поясніть, як різні апаратні прискорювачі (NPU, GPU, CPU) впливають на розгортання EdgeAI.

### Практичні вправи

1. **Швидке налаштування середовища**: Налаштуйте мінімальне середовище розробки з необхідними пакетами (30 хвилин)
2. **Дослідження моделі**: Завантажте та досліджуйте попередньо навчену малу мовну модель (1 година)
3. **Базове квантування**: Спробуйте просте квантування на малій моделі (1 година)

## Модуль 2: Основи малих мовних моделей

### Основні навчальні цілі

- Розуміння архітектурних принципів різних сімейств SLM
- Порівняння можливостей моделей різних масштабів параметрів
- Оцінка моделей за ефективністю, можливостями та вимогами до розгортання
- Визначення відповідних сценаріїв використання для різних сімейств моделей

### Основні області навчання

#### Розділ 1: Сімейство моделей Microsoft Phi
- **Пріоритетні концепції**: 
  - Еволюція філософії дизайну
  - Архітектура з акцентом на ефективність
  - Спеціалізовані можливості

#### Розділ 2: Сімейство Qwen
- **Пріоритетні концепції**: 
  - Внесок у відкритий код
  - Масштабовані варіанти розгортання
  - Архітектура для розширеного міркування

#### Розділ 3: Сімейство Gemma
- **Пріоритетні концепції**: 
  - Інновації, орієнтовані на дослідження
  - Мультимодальні можливості
  - Оптимізація для мобільних пристроїв

#### Розділ 4: Сімейство BitNET
- **Пріоритетні концепції**: 
  - Технологія квантування з точністю 1 біт
  - Фреймворк оптимізації для інференсу
  - Міркування щодо сталого розвитку

#### Розділ 5: Модель Microsoft Mu
- **Пріоритетні концепції**: 
  - Архітектура, орієнтована на пристрої
  - Інтеграція системи з Windows
  - Операція з збереженням конфіденційності

#### Розділ 6: Phi-Silica
- **Пріоритетні концепції**: 
  - Архітектура, оптимізована для NPU
  - Метрики продуктивності
  - Інтеграція для розробників

### Питання для самоперевірки

1. Порівняйте архітектурні підходи сімейств моделей Phi та Qwen.
2. Поясніть, чим технологія квантування BitNET відрізняється від традиційного квантування.
3. Які унікальні переваги моделі Mu для інтеграції з Windows?
4. Опишіть, як Phi-Silica використовує апаратне забезпечення NPU для оптимізації продуктивності.
5. Для мобільного застосунку з обмеженим підключенням, яке сімейство моделей буде найбільш відповідним і чому?

### Практичні вправи

1. **Порівняння моделей**: Швидкий бенчмарк двох різних моделей SLM (1 година)
2. **Просте генерування тексту**: Базова реалізація генерування тексту за допомогою малої моделі (1 година)
3. **Швидка оптимізація**: Застосуйте одну техніку оптимізації для покращення швидкості інференсу (1 година)

## Модуль 3: Розгортання малих мовних моделей

### Основні навчальні цілі

- Вибір відповідних моделей на основі обмежень розгортання
- Оволодіння техніками оптимізації для різних сценаріїв розгортання
- Реалізація SLM як у локальному, так і в хмарному середовищі
- Розробка конфігурацій, готових до виробництва, для застосувань EdgeAI

### Основні області навчання

#### Розділ 1: Розширене навчання SLM
- **Пріоритетні концепції**: 
  - Фреймворк класифікації параметрів
  - Розширені техніки оптимізації
  - Стратегії отримання моделей

#### Розділ 2: Розгортання в локальному середовищі
- **Пріоритетні концепції**: 
  - Розгортання на платформі Ollama
  - Локальні рішення Microsoft Foundry
  - Порівняльний аналіз фреймворків

#### Розділ 3: Контейнеризоване хмарне розгортання
- **Пріоритетні концепції**: 
  - Інференс високої продуктивності vLLM
  - Оркестрація контейнерів
  - Реалізація ONNX Runtime

### Питання для самоперевірки

1. Які фактори слід враховувати при виборі між локальним розгортанням та хмарним розгортанням?
2. Порівняйте Ollama та Microsoft Foundry Local як варіанти розгортання.
3. Поясніть переваги контейнеризації для розгортання SLM.
4. Які ключові метрики продуктивності слід моніторити для SLM, розгорнутого на периферії?
5. Опишіть повний робочий процес розгортання від вибору моделі до реалізації у виробництві.

### Практичні вправи

1. **Базове локальне розгортання**: Розгорніть просту SLM за допомогою Ollama (1 година)
2. **Перевірка продуктивності**: Проведіть швидкий бенчмарк на розгорнутій моделі (30 хвилин)
3. **Проста інтеграція**: Створіть мінімальний застосунок, який використовує вашу розгорнуту модель (1 година)

## Модуль 4: Конвертація формату моделей та квантування

### Основні навчальні цілі

- Оволодіння розширеними техніками квантування від точ
- **Пріоритетні концепти**:  
  - Оптимізація для Apple Silicon  
  - Архітектура об'єднаної пам'яті  
  - Можливості тонкого налаштування LoRA  

#### Розділ 6: Синтез робочого процесу розробки Edge AI  
- **Пріоритетні концепти**:  
  - Архітектура об'єднаного робочого процесу  
  - Дерева рішень для вибору фреймворків  
  - Перевірка готовності до виробництва  
  - Стратегії забезпечення майбутньої сумісності  

### Питання для самоперевірки  

1. Порівняйте стратегії квантування для різних рівнів точності (від 1-біт до 8-біт).  
2. Поясніть переваги формату GGUF для розгортання на периферії.  
3. Як апаратно-орієнтована оптимізація в Microsoft Olive покращує ефективність розгортання?  
4. Які ключові переваги OpenVINO NNCF для стиснення моделей?  
5. Опишіть, як Apple MLX використовує архітектуру об'єднаної пам'яті для оптимізації.  
6. Як синтез робочого процесу допомагає у виборі оптимальних фреймворків для оптимізації?  

### Практичні вправи  

1. **Квантування моделі**: Застосуйте різні рівні квантування до моделі та порівняйте результати (1 година).  
2. **Оптимізація OpenVINO**: Використовуйте NNCF для стиснення моделі для апаратного забезпечення Intel (1 година).  
3. **Порівняння фреймворків**: Протестуйте одну й ту ж модель у трьох різних фреймворках оптимізації (1 година).  
4. **Бенчмаркінг продуктивності**: Виміряйте вплив оптимізації на швидкість інференсу та використання пам'яті (1 година).  

## Модуль 5: SLMOps - Операції з малими мовними моделями  

### Основні навчальні цілі  

- Зрозуміти принципи управління життєвим циклом SLMOps  
- Опановувати техніки дистиляції та тонкого налаштування для розгортання на периферії  
- Реалізувати стратегії розгортання у виробництві з моніторингом  
- Створити робочі процеси для операцій та обслуговування SLM корпоративного рівня  

### Основні області для вивчення  

#### Розділ 1: Вступ до SLMOps  
- **Пріоритетні концепти**:  
  - Зміна парадигми SLMOps в операціях AI  
  - Ефективність витрат та архітектура з пріоритетом конфіденційності  
  - Стратегічний бізнес-ефект та конкурентні переваги  

#### Розділ 2: Дистиляція моделі  
- **Пріоритетні концепти**:  
  - Техніки передачі знань  
  - Реалізація двоетапного процесу дистиляції  
  - Робочі процеси дистиляції Azure ML  

#### Розділ 3: Стратегії тонкого налаштування  
- **Пріоритетні концепти**:  
  - Ефективне тонке налаштування параметрів (PEFT)  
  - Розширені методи LoRA та QLoRA  
  - Багатоадаптерне навчання та оптимізація гіперпараметрів  

#### Розділ 4: Розгортання у виробництві  
- **Пріоритетні концепти**:  
  - Конвертація та квантування моделі для виробництва  
  - Конфігурація локального розгортання Foundry  
  - Бенчмаркінг продуктивності та перевірка якості  

### Питання для самоперевірки  

1. Чим SLMOps відрізняється від традиційного MLOps?  
2. Поясніть переваги дистиляції моделі для розгортання на периферії.  
3. Які ключові аспекти слід враховувати при тонкому налаштуванні SLM у середовищах з обмеженими ресурсами?  
4. Опишіть повний конвеєр розгортання для додатків Edge AI.  

### Практичні вправи  

1. **Основна дистиляція**: Створіть меншу модель на основі більшої моделі-вчителя (1 година).  
2. **Експеримент з тонким налаштуванням**: Налаштуйте модель для конкретної галузі (1 година).  
3. **Конвеєр розгортання**: Налаштуйте базовий конвеєр CI/CD для розгортання моделі (1 година).  

## Модуль 6: Агентні системи SLM - AI-агенти та виклик функцій  

### Основні навчальні цілі  

- Створювати інтелектуальні AI-агенти для периферійних середовищ, використовуючи малі мовні моделі  
- Реалізовувати можливості виклику функцій за допомогою систематичних робочих процесів  
- Опановувати інтеграцію Model Context Protocol (MCP) для стандартизованої взаємодії з інструментами  
- Створювати складні агентні системи з мінімальним втручанням людини  

### Основні області для вивчення  

#### Розділ 1: AI-агенти та основи SLM  
- **Пріоритетні концепти**:  
  - Класифікація агентів (рефлекторні, модельні, цілеспрямовані, навчальні агенти)  
  - Аналіз компромісів між SLM та LLM  
  - Шаблони дизайну агентів для периферії  
  - Оптимізація ресурсів для агентів  

#### Розділ 2: Виклик функцій у малих мовних моделях  
- **Пріоритетні концепти**:  
  - Реалізація систематичного робочого процесу (виявлення намірів, JSON-вивід, зовнішнє виконання)  
  - Реалізації для конкретних платформ (Phi-4-mini, вибрані моделі Qwen, Microsoft Foundry Local)  
  - Розширені приклади (співпраця між агентами, динамічний вибір інструментів)  
  - Виробничі аспекти (обмеження швидкості, аудит, заходи безпеки)  

#### Розділ 3: Інтеграція Model Context Protocol (MCP)  
- **Пріоритетні концепти**:  
  - Архітектура протоколу та багатошаровий дизайн системи  
  - Підтримка багатьох бекендів (Ollama для розробки, vLLM для виробництва)  
  - Протоколи з'єднання (режими STDIO та SSE)  
  - Реальні застосування (автоматизація вебу, обробка даних, інтеграція API)  

### Питання для самоперевірки  

1. Які ключові архітектурні аспекти слід враховувати для агентів Edge AI?  
2. Як виклик функцій покращує можливості агентів?  
3. Поясніть роль Model Context Protocol у комунікації агентів.  

### Практичні вправи  

1. **Простий агент**: Створіть базового AI-агента з можливістю виклику функцій (1 година).  
2. **Інтеграція MCP**: Реалізуйте MCP у додатку агента (30 хвилин).  

## Модуль 7: Зразки реалізації EdgeAI  

### Основні навчальні цілі  

- Опановувати AI Toolkit для Visual Studio Code для комплексних робочих процесів розробки EdgeAI  
- Отримати експертизу у платформі Windows AI Foundry та стратегіях оптимізації NPU  
- Реалізовувати EdgeAI на різних апаратних платформах та сценаріях розгортання  
- Створювати готові до виробництва додатки EdgeAI з оптимізаціями для конкретних платформ  

### Основні області для вивчення  

#### Розділ 1: AI Toolkit для Visual Studio Code  
- **Пріоритетні концепти**:  
  - Комплексне середовище розробки Edge AI у VS Code  
  - Каталог моделей та їх пошук для розгортання на периферії  
  - Локальне тестування, оптимізація та розробка агентів  
  - Моніторинг продуктивності та оцінка для сценаріїв периферії  

#### Розділ 2: Посібник з розробки Windows EdgeAI  
- **Пріоритетні концепти**:  
  - Комплексний огляд платформи Windows AI Foundry  
  - API Phi Silica для ефективного інференсу на NPU  
  - API комп'ютерного зору для обробки зображень та OCR  
  - CLI Foundry Local для локальної розробки та тестування  

#### Розділ 3: Реалізації для конкретних платформ  
- **Пріоритетні концепти**:  
  - Розгортання NVIDIA Jetson Orin Nano (67 TOPS AI продуктивності)  
  - Мобільні додатки з .NET MAUI та ONNX Runtime GenAI  
  - Рішення Azure EdgeAI з гібридною архітектурою хмара-периферія  
  - Оптимізація Windows ML з універсальною підтримкою апаратного забезпечення  
  - Додатки Foundry Local з конфіденційною реалізацією RAG  

### Питання для самоперевірки  

1. Як AI Toolkit спрощує робочий процес розробки EdgeAI?  
2. Порівняйте стратегії розгортання на різних апаратних платформах.  
3. Які переваги Windows AI Foundry для розробки на периферії?  
4. Поясніть роль оптимізації NPU у сучасних додатках Edge AI.  
5. Як API Phi Silica використовує апаратне забезпечення NPU для оптимізації продуктивності?  
6. Порівняйте переваги локального та хмарного розгортання для додатків з пріоритетом конфіденційності.  

### Практичні вправи  

1. **Налаштування AI Toolkit**: Налаштуйте AI Toolkit та оптимізуйте модель (1 година).  
2. **Windows AI Foundry**: Створіть простий додаток Windows AI, використовуючи API Phi Silica (1 година).  
3. **Кросплатформне розгортання**: Розгорніть одну й ту ж модель на двох різних платформах (1 година).  
4. **Оптимізація NPU**: Протестуйте продуктивність NPU за допомогою інструментів Windows AI Foundry (30 хвилин).  

## Модуль 8: Microsoft Foundry Local – Повний набір інструментів для розробників  

### Основні навчальні цілі  

- Встановити та налаштувати Foundry Local на Windows  
- Запускати, знаходити та керувати моделями локально через Foundry CLI  
- Інтегрувати з REST та SDK-клієнтами, сумісними з OpenAI  
- Створювати практичні зразки: Chainlit chat, агенти та маршрутизатор моделей  
- Зрозуміти гібридні шаблони з Azure AI Foundry  

### Основні області для вивчення  

- Встановлення та основи CLI (модель, сервіс, кеш)  
- Інтеграція SDK (клієнти, сумісні з OpenAI, та Azure OpenAI)  
- Швидка перевірка Open WebUI  
- Шаблони агентів та виклику функцій  
- Моделі як інструменти (дизайн маршрутизатора та реєстру)  

### Питання для самоперевірки  

1. Як знайти локальну кінцеву точку та перелік доступних моделей?  
2. У чому різниця між використанням Foundry Local REST та Azure OpenAI?  
3. Як би ви спроєктували простий маршрутизатор для вибору моделей як інструментів?  
4. Які категорії CLI є найбільш актуальними для щоденної розробки?  
5. Як перевірити готовність Foundry Local перед запуском додатків?  

### Практичні вправи  

1. Встановіть/оновіть Foundry Local та запустіть `phi-4-mini` локально (30 хвилин).  
2. Викличте `/v1/models` та запустіть простий чат через REST (30 хвилин).  
3. Запустіть зразок додатку Chainlit та спілкуйтеся локально (30 хвилин).  
4. Запустіть координатор багатозадачного агента та перевірте результати (30 хвилин).  
5. Спробуйте маршрутизатор моделей як інструментів з перевизначеннями на основі середовища (30 хвилин).  

## Гід з розподілу часу  

Щоб максимально використати 20-годинний курс, ось рекомендований розподіл часу:  

| Діяльність | Розподіл часу | Опис |  
|------------|--------------|------|  
| Читання основних матеріалів | 9 годин | Зосередження на ключових концептах кожного модуля |  
| Практичні вправи | 6 годин | Практична реалізація ключових технік |  
| Самоперевірка | 2 години | Перевірка розуміння через питання та рефлексію |  
| Мініпроєкт | 3 години | Застосування знань у невеликій практичній реалізації |  

### Основні області фокусу за обмеженням часу  

**Якщо у вас є лише 10 годин:**  
- Завершіть модулі 1, 2 та 3 (основні концепти EdgeAI).  
- Виконайте принаймні одну практичну вправу з кожного модуля.  
- Зосередьтеся на розумінні основних концептів, а не на деталях реалізації.  

**Якщо ви можете присвятити повні 20 годин:**  
- Завершіть усі сім модулів.  
- Виконайте ключові практичні вправи з кожного модуля.  
- Завершіть один мініпроєкт із модуля 7.  
- Досліджуйте принаймні 2-3 додаткові ресурси.  

**Якщо у вас більше ніж 20 годин:**  
- Завершіть усі модулі з детальними вправами.  
- Створіть кілька мініпроєктів.  
- Досліджуйте розширені техніки оптимізації в модулі 4.  
- Реалізуйте розгортання у виробництві з модуля 5.  

## Основні ресурси  

Ці ретельно відібрані ресурси забезпечують максимальну цінність для вашого обмеженого часу навчання:  

### Обов'язкова документація  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Найефективніший інструмент оптимізації моделей  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Найшвидший спосіб локального розгортання SLM  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Довідник для провідної моделі, оптимізованої для периферії  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Комплексний інструментарій оптимізації від Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Інтегроване середовище розробки EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Платформа розробки EdgeAI для Windows  

### Інструменти для економії часу  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Швидкий доступ до моделей та їх розгортання  
- [Gradio](https://www.gradio.app/docs/interface) - Швидка розробка UI для демонстрації AI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Спрощена оптимізація моделей  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Ефективний інференс на CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Фреймворк для стиснення нейронних мереж  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Інструментарій для розгортання великих мовних моделей  

## Шаблон для відстеження прогресу  

Використовуйте цей спрощений шаблон для відстеження ваш
8. **Пайплайн оптимізації OpenVINO**: Реалізуйте повну оптимізацію моделі за допомогою NNCF та GenAI toolkit  
9. **Пайплайн SLMOps**: Реалізуйте повний життєвий цикл моделі від навчання до розгортання на пристроях  
10. **Система багатомодельного розгортання на пристроях**: Розгорніть кілька спеціалізованих моделей, які працюють разом на пристроях  
11. **Система інтеграції MCP**: Створіть агентну систему, використовуючи Model Context Protocol для взаємодії з інструментами  

## Посилання  

- Microsoft Learn (Foundry Local)  
  - Огляд: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Початок роботи: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Довідка CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Інтеграція з SDK для інференсу: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Як відкрити WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Компіляція моделей Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Огляд: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Агенти (огляд): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Інструменти оптимізації та інференсу  
  - Microsoft Olive (документація): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (початок роботи): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Інтеграція ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (документація): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (документація): https://ml-explore.github.io/mlx/build/html/index.html  
- Фреймворки розгортання та моделі  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (документація): https://docs.vllm.ai/  
  - Ollama (швидкий старт): https://github.com/ollama/ollama#get-started  
- Інструменти для розробників (Windows та VS Code)  
  - AI Toolkit для VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (огляд): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Спільнота навчання  

Приєднуйтесь до обговорень та спілкуйтеся з іншими учасниками:  
- Обговорення на GitHub у [репозиторії EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Висновок  

EdgeAI представляє передову технологію впровадження штучного інтелекту, яка забезпечує потужні можливості безпосередньо на пристроях, вирішуючи важливі питання конфіденційності, затримки та підключення. Цей 20-годинний курс надає вам необхідні знання та практичні навички для негайного початку роботи з технологіями EdgeAI.  

Курс спеціально розроблений, щоб бути стислим і зосередженим на найважливіших концепціях, дозволяючи вам швидко отримати цінний досвід без надмірного витрачання часу. Пам’ятайте, що практичні заняття, навіть із простими прикладами, є ключем до закріплення отриманих знань.  

Успіхів у навчанні!  

---

