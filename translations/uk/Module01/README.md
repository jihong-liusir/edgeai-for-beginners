<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-09-18T23:56:33+00:00",
  "source_file": "Module01/README.md",
  "language_code": "uk"
}
-->
# Розділ 01: Трансформація впровадження AI для периферійних пристроїв

EdgeAI представляє собою зміну парадигми у впровадженні штучного інтелекту, переміщуючи можливості AI з хмарної обробки на локальні периферійні пристрої. У цьому розділі розглядаються основні концепції, ключові технології та практичні застосування, які визначають цей трансформаційний підхід до реалізації AI.

## Структура модуля

### [Розділ 1: Основи EdgeAI](./01.EdgeAIFundamentals.md)
Цей розділ закладає основу, порівнюючи традиційні хмарні моделі AI з моделями впровадження EdgeAI. Ми досліджуємо критично важливі технології, такі як квантування моделей, оптимізація стиснення та Маленькі Мовні Моделі (SLMs), які долають обмеження обчислювальних ресурсів периферійних пристроїв. Увага приділяється тому, як ці інновації забезпечують покращений захист конфіденційності, наднизьку затримку та надійні можливості офлайн-обробки.

### [Розділ 2: Реальні приклади](./02.RealWorldCaseStudies.md)
На основі конкретних прикладів, таких як екосистеми моделей Phi і Mu від Microsoft та система звітності AI від Japan Airlines, цей розділ демонструє успішні впровадження EdgeAI у різних галузях. Ці кейси підтверджують виняткову продуктивність SLMs у спеціалізованих завданнях і ілюструють практичні переваги стратегій периферійного впровадження.

### [Розділ 3: Практичний посібник з впровадження](./03.PracticalImplementationGuide.md)
Цей розділ надає детальні рекомендації щодо підготовки середовища для практичного навчання, охоплюючи необхідні інструменти розробки, вимоги до апаратного забезпечення, основні ресурси моделей та оптимізаційні фреймворки. Він закладає технічну основу, необхідну для того, щоб учасники могли створювати та впроваджувати власні рішення EdgeAI.

### [Розділ 4: Апаратні платформи для впровадження Edge AI](./04.EdgeDeployment.md)
Цей розділ досліджує апаратну екосистему, яка дозволяє впровадження EdgeAI, охоплюючи платформи від Intel, Qualcomm, NVIDIA та Windows AI PCs. Він надає детальні порівняння можливостей апаратного забезпечення, платформно-специфічних технік оптимізації та практичних аспектів впровадження у різних сценаріях периферійних обчислень.

## Основні результати навчання

До кінця цього розділу читачі зрозуміють:
- Основні відмінності між архітектурами хмарного та периферійного AI
- Основні техніки оптимізації для впровадження на периферії
- Реальні приклади застосування та успішні кейси
- Практичні навички для реалізації рішень EdgeAI
- Вибір апаратних платформ та підходи до оптимізації для конкретних платформ
- Оцінку продуктивності та найкращі практики впровадження

## Майбутні перспективи

EdgeAI стає ключовою тенденцією, яка формує майбутнє впровадження AI, прокладаючи шлях до розподілених, ефективних та конфіденційних AI-систем, які можуть працювати незалежно від хмарного підключення, зберігаючи високі стандарти продуктивності.

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.