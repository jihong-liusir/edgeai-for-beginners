<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e9e31a2b5ff0f6a682a258fa859a8ff5",
  "translation_date": "2025-09-26T19:46:57+00:00",
  "source_file": "Module07/README.md",
  "language_code": "uk"
}
-->
# Розділ 07: Зразки EdgeAI

Edge AI об'єднує штучний інтелект із обчисленнями на периферії, дозволяючи здійснювати інтелектуальну обробку безпосередньо на пристроях без необхідності підключення до хмари. У цьому розділі розглядаються п'ять різних реалізацій EdgeAI на різних платформах і у фреймворках, демонструючи універсальність і потужність запуску моделей штучного інтелекту на периферії.

## 1. EdgeAI на NVIDIA Jetson Orin Nano

NVIDIA Jetson Orin Nano є проривом у доступних обчисленнях Edge AI, забезпечуючи до 67 TOPS продуктивності штучного інтелекту в компактному форм-факторі розміром із кредитну картку. Ця потужна платформа Edge AI демократизує розробку генеративного штучного інтелекту для ентузіастів, студентів і професійних розробників.

### Основні характеристики
- Забезпечує до 67 TOPS продуктивності штучного інтелекту — на 1.7X більше, ніж його попередник
- 1024 ядра CUDA і до 32 ядер Tensor для обробки штучного інтелекту
- 6-ядерний процесор Arm Cortex-A78AE v8.2 64-біт із максимальною частотою 1.5 ГГц
- Ціна всього $249, що робить платформу доступною для розробників, студентів і творців

### Застосування
Jetson Orin Nano чудово підходить для запуску сучасних генеративних моделей штучного інтелекту, включаючи Vision Transformers, великі мовні моделі (LLM) і моделі Vision-Language. Він спеціально розроблений для використання в GenAI, і тепер можна запускати кілька LLM на пристрої розміром із долоню. Популярні сценарії використання включають робототехніку з підтримкою штучного інтелекту, розумні дрони, інтелектуальні камери та автономні периферійні пристрої.

**Дізнатися більше**: [NVIDIA's Jetson Orin Nano SuperComputer: The Next Big Thing in EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI у мобільних додатках із .NET MAUI та ONNX Runtime GenAI

Це рішення демонструє, як інтегрувати генеративний штучний інтелект і великі мовні моделі (LLM) у кросплатформні мобільні додатки за допомогою .NET MAUI (Multi-platform App UI) та ONNX Runtime GenAI. Цей підхід дозволяє розробникам .NET створювати складні мобільні додатки з підтримкою штучного інтелекту, які працюють нативно на пристроях Android і iOS.

### Основні характеристики
- Побудовано на фреймворку .NET MAUI, що забезпечує єдину кодову базу для додатків Android і iOS
- Інтеграція ONNX Runtime GenAI дозволяє запускати генеративні моделі штучного інтелекту безпосередньо на мобільних пристроях
- Підтримує різні апаратні прискорювачі, адаптовані для мобільних пристроїв, включаючи CPU, GPU та спеціалізовані мобільні AI-процесори
- Оптимізації для конкретних платформ, такі як CoreML для iOS і NNAPI для Android через ONNX Runtime
- Реалізує повний цикл генеративного штучного інтелекту, включаючи попередню та постобробку, інференс, обробку логітів, пошук і вибір, а також управління KV-кешем

### Переваги розробки
Підхід .NET MAUI дозволяє розробникам використовувати свої існуючі навички C# і .NET, створюючи кросплатформні AI-додатки. Фреймворк ONNX Runtime GenAI підтримує кілька архітектур моделей, включаючи Llama, Mistral, Phi, Gemma та багато інших. Оптимізовані ядра ARM64 прискорюють INT4-квантизоване множення матриць, забезпечуючи ефективну продуктивність на мобільному обладнанні, зберігаючи при цьому знайомий досвід розробки в .NET.

### Сценарії використання
Це рішення ідеально підходить для розробників, які хочуть створювати мобільні додатки з підтримкою штучного інтелекту, використовуючи технології .NET, включаючи інтелектуальні чат-боти, додатки для розпізнавання зображень, інструменти перекладу мов і системи персоналізованих рекомендацій, які працюють повністю на пристрої для покращення конфіденційності та можливості роботи офлайн.

**Дізнатися більше**: [.NET MAUI ONNX Runtime GenAI Example](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI в Azure із Small Language Models Engine

Рішення EdgeAI від Microsoft на базі Azure зосереджене на ефективному розгортанні малих мовних моделей (SLM) у гібридних середовищах хмара-периферія. Цей підхід об'єднує масштабовані AI-сервіси хмари з вимогами до розгортання на периферії.

### Переваги архітектури
- Безшовна інтеграція з AI-сервісами Azure
- Запуск SLM/LLM і мультимодальних моделей на пристрої та в хмарі за допомогою ONNX Runtime
- Оптимізовано для розгортання в масштабах підприємства
- Підтримка безперервного оновлення та управління моделями

### Сценарії використання
Реалізація Azure EdgeAI чудово підходить для сценаріїв, які потребують розгортання AI корпоративного рівня з можливостями управління хмарою. Це включає інтелектуальну обробку документів, аналітику в реальному часі та гібридні AI-робочі процеси, які використовують як хмарні, так і периферійні обчислювальні ресурси.

**Дізнатися більше**: [Azure EdgeAI SLM Engine](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## [4. EdgeAI із Windows ML](./windowdeveloper.md)

Windows ML є передовим середовищем виконання від Microsoft, оптимізованим для продуктивного інференсу моделей на пристрої та спрощеного розгортання, слугуючи основою Windows AI Foundry. Ця платформа дозволяє розробникам створювати Windows-додатки з підтримкою штучного інтелекту, які використовують весь спектр апаратного забезпечення ПК.

### Можливості платформи
- Працює на всіх ПК із Windows 11 версії 24H2 (збірка 26100) або новішої
- Працює на всьому апаратному забезпеченні ПК x64 і ARM64, навіть на ПК без NPU або GPU
- Дозволяє розробникам використовувати власні моделі та ефективно розгортати їх у екосистемі партнерів із виробництва чипів, включаючи AMD, Intel, NVIDIA і Qualcomm, охоплюючи CPU, GPU, NPU
- Завдяки інфраструктурним API розробникам більше не потрібно створювати кілька збірок своїх додатків для різного апаратного забезпечення

### Переваги для розробників
Windows ML абстрагує апаратне забезпечення та провайдерів виконання, дозволяючи зосередитися на написанні коду. Крім того, Windows ML автоматично оновлюється для підтримки найновіших NPU, GPU і CPU після їх випуску. Платформа забезпечує єдиний фреймворк для розробки штучного інтелекту в різноманітній екосистемі апаратного забезпечення Windows.

**Дізнатися більше**: 
- [Огляд Windows ML](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Посібник із розробки Windows EdgeAI](./windowdeveloper.md) - Комплексний посібник із розробки Windows Edge AI

## [5. EdgeAI із Foundry Local Applications](./foundrylocal.md)

Foundry Local дозволяє розробникам Windows і Mac створювати додатки Retrieval Augmented Generation (RAG), використовуючи локальні ресурси в .NET, об'єднуючи локальні мовні моделі з можливостями семантичного пошуку. Цей підхід забезпечує рішення штучного інтелекту, орієнтовані на конфіденційність, які працюють виключно на локальній інфраструктурі.

### Технічна архітектура
- Об'єднує мовну модель Phi, локальні вбудовування та Semantic Kernel для створення сценарію RAG
- Використовує вбудовування як вектори (масиви) значень із плаваючою точкою, які представляють контент і його семантичне значення
- Semantic Kernel виступає основним оркестратором, інтегруючи Phi і Smart Components для створення безшовного RAG-пайплайну
- Підтримка локальних векторних баз даних, включаючи SQLite і Qdrant

### Переваги реалізації
RAG, або Retrieval Augmented Generation, — це просто складний спосіб сказати "знайти деяку інформацію та включити її в запит". Ця локальна реалізація забезпечує конфіденційність даних, надаючи інтелектуальні відповіді, засновані на власних базах знань. Підхід особливо цінний для корпоративних сценаріїв, які потребують суверенітету даних і можливостей роботи офлайн.

**Дізнатися більше**: 
- [Foundry Local](./foundrylocal.md)
- [Зразки Foundry Local RAG](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

### Windows Foundry Local

Microsoft Foundry Local надає REST-сервер, сумісний із OpenAI, на базі ONNX Runtime для запуску моделей локально на Windows. Нижче наведено короткий, перевірений огляд; дивіться офіційну документацію для отримання повної інформації.

- Початок роботи: https://learn.microsoft.com/azure/ai-foundry/foundry-local/get-started
- Архітектура: https://learn.microsoft.com/azure/ai-foundry/foundry-local/concepts/foundry-local-architecture
- Довідка CLI: https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli
- Повний посібник для Windows у цьому репозиторії: [foundrylocal.md](./foundrylocal.md)

Встановлення або оновлення на Windows (cmd.exe):
```cmd
winget install Microsoft.FoundryLocal
winget upgrade --id Microsoft.FoundryLocal
foundry --version
```

Дослідження категорій CLI:
```cmd
foundry model --help
foundry service --help
foundry cache --help
```

Запуск моделі та виявлення динамічної кінцевої точки:
```cmd
foundry model run gpt-oss-20b
foundry service status
```

Швидка перевірка REST для списку моделей (замініть PORT зі статусу):
```cmd
curl -s http://localhost:PORT/v1/models
```

Поради:
- Інтеграція SDK: https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Використання власної моделі (компіляція): https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## Ресурси для розробки Windows EdgeAI

Для розробників, які спеціально орієнтуються на платформу Windows, ми створили комплексний посібник, що охоплює всю екосистему Windows EdgeAI. Цей ресурс надає детальну інформацію про Windows AI Foundry, включаючи API, інструменти та найкращі практики для розробки EdgeAI на Windows.

### Платформа Windows AI Foundry
Платформа Windows AI Foundry надає комплексний набір інструментів і API, спеціально розроблених для розробки Edge AI на пристроях Windows. Це включає спеціалізовану підтримку апаратного забезпечення з прискоренням NPU, інтеграцію Windows ML і оптимізаційні техніки для конкретних платформ.

**Комплексний посібник**: [Посібник із розробки Windows EdgeAI](../windowdeveloper.md)

Цей посібник охоплює:
- Огляд платформи Windows AI Foundry і її компонентів
- API Phi Silica для ефективного інференсу на апаратному забезпеченні NPU
- API комп'ютерного зору для обробки зображень і OCR
- Інтеграцію та оптимізацію середовища виконання Windows ML
- CLI Foundry Local для локальної розробки та тестування
- Стратегії оптимізації апаратного забезпечення для пристроїв Windows
- Практичні приклади реалізації та найкращі практики

### [AI Toolkit для розробки Edge AI](./aitoolkit.md)
Для розробників, які використовують Visual Studio Code, розширення AI Toolkit надає комплексне середовище розробки, спеціально розроблене для створення, тестування та розгортання додатків Edge AI. Цей інструментарій спрощує весь робочий процес розробки Edge AI у VS Code.

**Посібник із розробки**: [AI Toolkit для розробки Edge AI](./aitoolkit.md)

Посібник AI Toolkit охоплює:
- Вибір і пошук моделей для розгортання на периферії
- Локальні робочі процеси тестування та оптимізації
- Інтеграцію ONNX і Ollama для моделей на периферії
- Техніки конвертації та квантизації моделей
- Розробку агентів для сценаріїв на периферії
- Оцінку продуктивності та моніторинг
- Підготовку до розгортання та найкращі практики

## Висновок

Ці п'ять реалізацій EdgeAI демонструють зрілість і різноманітність доступних сьогодні рішень Edge AI. Від пристроїв із апаратним прискоренням, таких як Jetson Orin Nano, до програмних фреймворків, таких як ONNX Runtime GenAI і Windows ML, розробники мають безпрецедентні можливості для розгортання інтелектуальних додатків на периферії.

Спільною рисою всіх цих платформ є демократизація можливостей штучного інтелекту, що робить складне машинне навчання доступним для розробників із різним рівнем навичок і сценаріями використання. Незалежно від того, чи створюєте ви мобільні додатки, настільне програмне забезпечення або вбудовані системи, ці рішення EdgeAI забезпечують основу для наступного покоління інтелектуальних додатків, які працюють ефективно та конфіденційно на периферії.

Кожна платформа пропонує унікальні переваги: Jetson Orin Nano для обчислень на периферії з апаратним прискоренням, ONNX Runtime GenAI для кросплатформної мобільної розробки, Azure EdgeAI для інтеграції хмара-периферія, Windows ML для нативних додатків Windows і Foundry Local для реалізацій RAG, орієнтованих на конфіденційність. Разом вони представляють комплексну екосистему для розробки EdgeAI.

---

