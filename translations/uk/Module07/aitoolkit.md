<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "65a22ed38b95f334dd8a893bf2c55806",
  "translation_date": "2025-10-02T15:05:58+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "uk"
}
-->
# AI Toolkit для Visual Studio Code - Посібник з розробки Edge AI

## Вступ

Ласкаво просимо до детального посібника з використання AI Toolkit для Visual Studio Code у розробці Edge AI. У той час як штучний інтелект переходить від централізованих хмарних обчислень до розподілених пристроїв на краю мережі, розробникам потрібні потужні інтегровані інструменти, які можуть впоратися з унікальними викликами розгортання на краю — від обмежених ресурсів до вимог роботи в автономному режимі.

AI Toolkit для Visual Studio Code заповнює цю прогалину, забезпечуючи повноцінне середовище розробки, спеціально створене для побудови, тестування та оптимізації AI-додатків, які ефективно працюють на пристроях краю. Незалежно від того, чи ви розробляєте для IoT сенсорів, мобільних пристроїв, вбудованих систем або серверів на краю, цей інструментарій спрощує весь процес розробки у знайомому середовищі VS Code.

Цей посібник проведе вас через основні концепції, інструменти та найкращі практики використання AI Toolkit у ваших проектах Edge AI — від вибору моделі до розгортання у виробництві.

## Огляд

AI Toolkit для Visual Studio Code — це потужне розширення, яке спрощує розробку агентів і створення AI-додатків. Інструментарій забезпечує широкі можливості для дослідження, оцінки та розгортання AI-моделей від різних постачальників, включаючи Anthropic, OpenAI, GitHub, Google, а також підтримує локальне виконання моделей за допомогою ONNX і Ollama.

Що відрізняє AI Toolkit — це його комплексний підхід до всього життєвого циклу розробки AI. На відміну від традиційних інструментів, які зосереджуються на окремих аспектах, AI Toolkit забезпечує інтегроване середовище, яке охоплює відкриття моделей, експерименти, розробку агентів, оцінку та розгортання — все у знайомому середовищі VS Code.

Платформа спеціально розроблена для швидкого прототипування та розгортання у виробництво, з такими функціями, як генерація підказок, швидкі стартери, безшовна інтеграція MCP (Model Context Protocol) та розширені можливості оцінки. Для розробки Edge AI це означає, що ви можете ефективно розробляти, тестувати та оптимізувати AI-додатки для сценаріїв розгортання на краю, зберігаючи весь процес розробки у VS Code.

## Навчальні цілі

До кінця цього посібника ви зможете:

### Основні компетенції
- **Встановлювати та налаштовувати** AI Toolkit для Visual Studio Code для робочих процесів розробки Edge AI
- **Орієнтуватися та використовувати** інтерфейс AI Toolkit, включаючи Model Catalog, Playground і Agent Builder
- **Вибирати та оцінювати** AI-моделі, придатні для розгортання на краю, з урахуванням продуктивності та обмежень ресурсів
- **Конвертувати та оптимізувати** моделі у формат ONNX та використовувати техніки квантування для пристроїв краю

### Навички розробки Edge AI
- **Проектувати та впроваджувати** Edge AI-додатки за допомогою інтегрованого середовища розробки
- **Проводити тестування моделей** в умовах, схожих на крайові, використовуючи локальне виконання та моніторинг ресурсів
- **Створювати та налаштовувати** AI-агентів, оптимізованих для сценаріїв розгортання на краю
- **Оцінювати продуктивність моделей** за допомогою метрик, релевантних для обчислень на краю (затримка, використання пам'яті, точність)

### Оптимізація та розгортання
- **Застосовувати техніки квантування та обрізання** для зменшення розміру моделі при збереженні прийнятної продуктивності
- **Оптимізувати моделі** для конкретних апаратних платформ краю, включаючи прискорення на CPU, GPU та NPU
- **Впроваджувати найкращі практики** для розробки Edge AI, включаючи управління ресурсами та стратегії резервного копіювання
- **Готувати моделі та додатки** для розгортання у виробництві на пристроях краю

### Розширені концепції Edge AI
- **Інтегрувати з фреймворками Edge AI**, такими як ONNX Runtime, Windows ML і TensorFlow Lite
- **Реалізовувати багатомодельні архітектури** та сценарії федеративного навчання для середовищ краю
- **Вирішувати поширені проблеми Edge AI**, включаючи обмеження пам'яті, швидкість виконання та сумісність апаратного забезпечення
- **Проектувати стратегії моніторингу та логування** для Edge AI-додатків у виробництві

### Практичне застосування
- **Створювати комплексні рішення Edge AI** від вибору моделі до розгортання
- **Демонструвати компетентність** у специфічних для краю робочих процесах розробки та техніках оптимізації
- **Застосовувати отримані знання** до реальних сценаріїв використання Edge AI, включаючи IoT, мобільні та вбудовані додатки
- **Оцінювати та порівнювати** різні стратегії розгортання Edge AI та їх компроміси

## Основні функції для розробки Edge AI

### 1. Каталог моделей і відкриття
- **Підтримка багатьох постачальників**: Перегляд і доступ до AI-моделей від Anthropic, OpenAI, GitHub, Google та інших постачальників
- **Інтеграція локальних моделей**: Спрощене відкриття моделей ONNX і Ollama для розгортання на краю
- **Моделі GitHub**: Пряма інтеграція з хостингом моделей GitHub для зручного доступу
- **Порівняння моделей**: Порівняння моделей для знаходження оптимального балансу для обмежень пристроїв краю

### 2. Інтерактивний Playground
- **Інтерактивне тестове середовище**: Швидке експериментування з можливостями моделі у контрольованому середовищі
- **Підтримка мультимодальності**: Тестування зображень, тексту та інших типових для краю входів
- **Експерименти в реальному часі**: Миттєвий зворотний зв'язок щодо відповідей моделі та продуктивності
- **Оптимізація параметрів**: Тонке налаштування параметрів моделі для вимог розгортання на краю

### 3. Конструктор підказок (Agent Builder)
- **Генерація природної мови**: Генерація стартових підказок за допомогою описів природною мовою
- **Ітеративне вдосконалення**: Покращення підказок на основі відповідей моделі та продуктивності
- **Розбиття завдань**: Розділення складних завдань за допомогою ланцюжка підказок і структурованих виходів
- **Підтримка змінних**: Використання змінних у підказках для динамічної поведінки агентів
- **Генерація виробничого коду**: Створення готового до виробництва коду для швидкої розробки додатків

### 4. Масове виконання та оцінка
- **Тестування багатьох моделей**: Виконання кількох підказок одночасно на вибраних моделях
- **Ефективне тестування у масштабі**: Тестування різних входів і конфігурацій ефективно
- **Користувацькі тестові випадки**: Запуск агентів із тестовими випадками для перевірки функціональності
- **Порівняння продуктивності**: Порівняння результатів між різними моделями та конфігураціями

### 5. Оцінка моделей за допомогою наборів даних
- **Стандартні метрики**: Тестування AI-моделей за допомогою вбудованих оцінювачів (F1 score, релевантність, схожість, узгодженість)
- **Користувацькі оцінювачі**: Створення власних метрик оцінки для конкретних випадків використання
- **Інтеграція наборів даних**: Тестування моделей на основі комплексних наборів даних
- **Вимірювання продуктивності**: Кількісна оцінка продуктивності моделі для рішень щодо розгортання на краю

### 6. Можливості тонкого налаштування
- **Налаштування моделей**: Адаптація моделей для конкретних випадків використання та доменів
- **Спеціалізована адаптація**: Адаптація моделей до спеціалізованих доменів і вимог
- **Оптимізація для краю**: Тонке налаштування моделей спеціально для обмежень розгортання на краю
- **Навчання для конкретного домену**: Створення моделей, адаптованих до специфічних випадків використання на краю

### 7. Інтеграція MCP Tool
- **Підключення зовнішніх інструментів**: Підключення агентів до зовнішніх інструментів через сервери Model Context Protocol
- **Дії у реальному світі**: Дозвіл агентам запитувати бази даних, отримувати доступ до API або виконувати користувацьку логіку
- **Існуючі сервери MCP**: Використання інструментів із командного (stdio) або HTTP (server-sent event) протоколів
- **Розробка користувацьких MCP**: Створення та тестування нових серверів MCP у Agent Builder

### 8. Розробка та тестування агентів
- **Підтримка виклику функцій**: Дозвіл агентам динамічно викликати зовнішні функції
- **Тестування інтеграції у реальному часі**: Тестування інтеграцій із реальними запусками та використанням інструментів
- **Версії агентів**: Контроль версій агентів із можливістю порівняння результатів оцінки
- **Налагодження та трасування**: Локальне трасування та можливості налагодження для розробки агентів

## Робочий процес розробки Edge AI

### Фаза 1: Відкриття та вибір моделі
1. **Дослідження каталогу моделей**: Використовуйте каталог моделей для пошуку моделей, придатних для розгортання на краю
2. **Порівняння продуктивності**: Оцінюйте моделі за розміром, точністю та швидкістю виконання
3. **Локальне тестування**: Використовуйте моделі Ollama або ONNX для локального тестування перед розгортанням на краю
4. **Оцінка вимог до ресурсів**: Визначте потреби у пам'яті та обчисленнях для цільових пристроїв краю

### Фаза 2: Оптимізація моделі
1. **Конвертація в ONNX**: Конвертуйте вибрані моделі у формат ONNX для сумісності з краєм
2. **Застосування квантування**: Зменшуйте розмір моделі через квантування INT8 або INT4
3. **Апаратна оптимізація**: Оптимізуйте для цільового апаратного забезпечення краю (ARM, x86, спеціалізовані прискорювачі)
4. **Перевірка продуктивності**: Переконайтеся, що оптимізовані моделі зберігають прийнятну точність

### Фаза 3: Розробка додатків
1. **Проектування агентів**: Використовуйте Agent Builder для створення AI-агентів, оптимізованих для краю
2. **Інженерія підказок**: Розробляйте підказки, які ефективно працюють із меншими моделями краю
3. **Тестування інтеграції**: Тестуйте агентів у симульованих умовах краю
4. **Генерація коду**: Створюйте виробничий код, оптимізований для розгортання на краю

### Фаза 4: Оцінка та тестування
1. **Масова оцінка**: Тестуйте кілька конфігурацій для пошуку оптимальних налаштувань краю
2. **Профілювання продуктивності**: Аналізуйте швидкість виконання, використання пам'яті та точність
3. **Симуляція краю**: Тестуйте в умовах, схожих на цільове середовище розгортання на краю
4. **Стрес-тестування**: Оцінюйте продуктивність за різних умов навантаження

### Фаза 5: Підготовка до розгортання
1. **Фінальна оптимізація**: Застосовуйте фінальні оптимізації на основі результатів тестування
2. **Пакування для розгортання**: Пакуйте моделі та код для розгортання на краю
3. **Документація**: Документуйте вимоги до розгортання та конфігурацію
4. **Налаштування моніторингу**: Готуйте моніторинг та логування для розгортання на краю

## Цільова аудиторія для розробки Edge AI

### Розробники Edge AI
- Розробники додатків, які створюють пристрої на краю з підтримкою AI та IoT-рішення
- Розробники вбудованих систем, які інтегрують AI-можливості у пристрої з обмеженими ресурсами
- Мобільні розробники, які створюють AI-додатки для смартфонів та планшетів

### Інженери Edge AI
- Інженери AI, які оптимізують моделі для розгортання на краю та управляють конвеєрами виконання
- Інженери DevOps, які розгортають та управляють AI-моделями у розподіленій інфраструктурі краю
- Інженери продуктивності, які оптимізують AI-навантаження для обмежень апаратного забезпечення краю

### Дослідники та викладачі
- Дослідники AI, які розробляють ефективні моделі та алгоритми для обчислень на краю
- Викладачі, які навчають концепціям Edge AI та демонструють техніки оптимізації
- Студенти, які вивчають виклики та рішення у розгортанні Edge AI

## Випадки використання Edge AI

### Розумні IoT-пристрої
- **Розпізнавання зображень у реальному часі**: Розгортання моделей комп'ютерного зору на IoT-камерах та сенсорах
- **Обробка голосу**: Реалізація розпізнавання мови та обробки природної мови на розумних колонках
- **Прогнозне обслуговування**: Виконання моделей виявлення аномалій на промислових пристроях краю
- **Моніторинг навколишнього середовища**: Розгортання моделей аналізу даних сенсорів для екологічних додатків

### Мобільні та вбудовані додатки
- **Переклад на пристрої**: Реалізація моделей перекладу мов, які працюють в автономному режимі
- **Доповнена реальність**: Розгортання моделей розпізнавання та відстеження об'єктів у реальному часі для AR-додатків
- **Моніторинг здоров'я**: Виконання моделей аналізу здоров'я на носимих пристроях та медичному обладнанні
- **Автономні системи**: Реалізація моделей прийняття рішень для дронів, роботів та транспортних засобів

### Інфраструктура обчислень на краю
- **Центри даних на краю**: Розгортання AI-моделей у центрах даних на краю для додатків із низькою затримкою
- **Інтеграція
2. Генерація початкових підказок за допомогою описів природною мовою  
3. Ітерація та вдосконалення підказок на основі відповідей моделі  
4. Інтеграція інструментів MCP для розширення можливостей агентів  

#### Крок 3: Тестування та оцінка  
1. Використовуйте **Bulk Run** для тестування кількох підказок на вибраних моделях  
2. Запускайте агентів із тестовими випадками для перевірки функціональності  
3. Оцінюйте точність і продуктивність за допомогою вбудованих або користувацьких метрик  
4. Порівнюйте різні моделі та конфігурації  

#### Крок 4: Тонке налаштування та оптимізація  
1. Налаштовуйте моделі для специфічних крайових сценаріїв  
2. Застосовуйте тонке налаштування для конкретних доменів  
3. Оптимізуйте для обмежень крайового розгортання  
4. Версіонуйте та порівнюйте різні конфігурації агентів  

#### Крок 5: Підготовка до розгортання  
1. Генеруйте готовий до виробництва код за допомогою Agent Builder  
2. Налаштуйте з'єднання серверів MCP для використання у виробництві  
3. Підготуйте пакети для розгортання на крайових пристроях  
4. Налаштуйте метрики моніторингу та оцінки  

## Найкращі практики розробки Edge AI  

### Вибір моделі  
- **Обмеження розміру**: Обирайте моделі, які відповідають обмеженням пам'яті цільових пристроїв  
- **Швидкість інференції**: Віддавайте перевагу моделям із швидкою інференцією для застосувань у реальному часі  
- **Компроміси точності**: Балансуйте точність моделі з обмеженнями ресурсів  
- **Сумісність формату**: Віддавайте перевагу форматам ONNX або оптимізованим для апаратного забезпечення для крайового розгортання  

### Техніки оптимізації  
- **Квантування**: Використовуйте квантування INT8 або INT4 для зменшення розміру моделі та покращення швидкості  
- **Обрізання**: Видаляйте непотрібні параметри моделі для зменшення вимог до обчислень  
- **Дистиляція знань**: Створюйте менші моделі, які зберігають продуктивність більших  
- **Апаратне прискорення**: Використовуйте NPUs, GPUs або спеціалізовані прискорювачі, якщо доступні  

### Робочий процес розробки  
- **Ітеративне тестування**: Часто тестуйте в умовах, схожих на крайові, під час розробки  
- **Моніторинг продуктивності**: Постійно відстежуйте використання ресурсів і швидкість інференції  
- **Контроль версій**: Відстежуйте версії моделей і налаштування оптимізації  
- **Документація**: Документуйте всі рішення щодо оптимізації та компроміси продуктивності  

### Міркування щодо розгортання  
- **Моніторинг ресурсів**: Відстежуйте використання пам'яті, CPU та енергії у виробництві  
- **Стратегії резервування**: Реалізуйте механізми резервування для збоїв моделі  
- **Механізми оновлення**: Плануйте оновлення моделей і управління версіями  
- **Безпека**: Реалізуйте відповідні заходи безпеки для застосувань Edge AI  

## Інтеграція з фреймворками Edge AI  

### ONNX Runtime  
- **Кросплатформне розгортання**: Розгортайте моделі ONNX на різних крайових платформах  
- **Оптимізація апаратного забезпечення**: Використовуйте апаратно-специфічні оптимізації ONNX Runtime  
- **Підтримка мобільних пристроїв**: Використовуйте ONNX Runtime Mobile для смартфонів і планшетів  
- **Інтеграція IoT**: Розгортайте на IoT-пристроях за допомогою легких дистрибутивів ONNX Runtime  

### Windows ML  
- **Пристрої Windows**: Оптимізуйте для крайових пристроїв і ПК на базі Windows  
- **Прискорення NPU**: Використовуйте нейронні процесори на пристроях Windows  
- **DirectML**: Використовуйте DirectML для прискорення GPU на платформах Windows  
- **Інтеграція UWP**: Інтегруйте з додатками Universal Windows Platform  

### TensorFlow Lite  
- **Оптимізація для мобільних пристроїв**: Розгортайте моделі TensorFlow Lite на мобільних і вбудованих пристроях  
- **Апаратні делегати**: Використовуйте спеціалізовані апаратні делегати для прискорення  
- **Мікроконтролери**: Розгортайте на мікроконтролерах за допомогою TensorFlow Lite Micro  
- **Кросплатформна підтримка**: Розгортайте на Android, iOS і вбудованих системах Linux  

### Azure IoT Edge  
- **Гібрид хмара-край**: Поєднуйте навчання в хмарі з інференцією на краю  
- **Розгортання модулів**: Розгортайте AI-моделі як модулі IoT Edge  
- **Управління пристроями**: Дистанційно керуйте крайовими пристроями та оновленнями моделей  
- **Телеметрія**: Збирайте дані про продуктивність і метрики моделей із крайових розгортань  

## Розширені сценарії Edge AI  

### Розгортання кількох моделей  
- **Енсамблі моделей**: Розгортайте кілька моделей для покращення точності або резервування  
- **A/B тестування**: Тестуйте різні моделі одночасно на крайових пристроях  
- **Динамічний вибір**: Обирайте моделі залежно від поточних умов пристрою  
- **Спільне використання ресурсів**: Оптимізуйте використання ресурсів між кількома розгорнутими моделями  

### Федеративне навчання  
- **Розподілене навчання**: Навчайте моделі на кількох крайових пристроях  
- **Збереження конфіденційності**: Залишайте дані навчання локальними, обмінюючись лише покращеннями моделі  
- **Спільне навчання**: Дозволяйте пристроям навчатися на основі колективного досвіду  
- **Координація край-хмара**: Координуйте навчання між крайовими пристроями та хмарною інфраструктурою  

### Обробка в реальному часі  
- **Обробка потоків**: Обробляйте безперервні потоки даних на крайових пристроях  
- **Інференція з низькою затримкою**: Оптимізуйте для мінімальної затримки інференції  
- **Пакетна обробка**: Ефективно обробляйте пакети даних на крайових пристроях  
- **Адаптивна обробка**: Коригуйте обробку залежно від поточних можливостей пристрою  

## Вирішення проблем у розробці Edge AI  

### Поширені проблеми  
- **Обмеження пам'яті**: Модель занадто велика для пам'яті цільового пристрою  
- **Швидкість інференції**: Інференція моделі занадто повільна для вимог реального часу  
- **Погіршення точності**: Оптимізація знижує точність моделі до неприйнятного рівня  
- **Сумісність апаратного забезпечення**: Модель несумісна з цільовим апаратним забезпеченням  

### Стратегії налагодження  
- **Профілювання продуктивності**: Використовуйте функції трасування AI Toolkit для виявлення вузьких місць  
- **Моніторинг ресурсів**: Відстежуйте використання пам'яті та CPU під час розробки  
- **Інкрементне тестування**: Тестуйте оптимізації поступово, щоб ізолювати проблеми  
- **Симуляція апаратного забезпечення**: Використовуйте інструменти розробки для симуляції цільового апаратного забезпечення  

### Рішення для оптимізації  
- **Додаткове квантування**: Застосовуйте більш агресивні техніки квантування  
- **Архітектура моделі**: Розгляньте різні архітектури моделей, оптимізовані для краю  
- **Оптимізація попередньої обробки**: Оптимізуйте попередню обробку даних для крайових обмежень  
- **Оптимізація інференції**: Використовуйте апаратно-специфічні оптимізації інференції  

## Ресурси та наступні кроки  

### Офіційна документація  
- [Документація для розробників AI Toolkit](https://aka.ms/AIToolkit/doc)  
- [Посібник із встановлення та налаштування](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [Документація VS Code Intelligent Apps](https://code.visualstudio.com/docs/intelligentapps)  
- [Документація Model Context Protocol (MCP)](https://modelcontextprotocol.io/)  

### Спільнота та підтримка  
- [Репозиторій AI Toolkit на GitHub](https://github.com/microsoft/vscode-ai-toolkit)  
- [Проблеми та запити на функції GitHub](https://aka.ms/AIToolkit/feedback)  
- [Спільнота Azure AI Foundry на Discord](https://aka.ms/azureaifoundry/discord)  
- [Ринок розширень VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### Технічні ресурси  
- [Документація ONNX Runtime](https://onnxruntime.ai/)  
- [Документація Ollama](https://ollama.ai/)  
- [Документація Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [Документація Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### Навчальні шляхи  
- [Курс основ Edge AI](../Module01/README.md)  
- [Посібник із малих мовних моделей](../Module02/README.md)  
- [Стратегії розгортання на краю](../Module03/README.md)  
- [Розробка Edge AI для Windows](./windowdeveloper.md)  

### Додаткові ресурси  
- **Статистика репозиторію**: 1.8k+ зірок, 150+ форків, 18+ учасників  
- **Ліцензія**: Ліцензія MIT  
- **Безпека**: Застосовуються політики безпеки Microsoft  
- **Телеметрія**: Відповідає налаштуванням телеметрії VS Code  

## Висновок  

AI Toolkit для Visual Studio Code є комплексною платформою для сучасної розробки AI, яка забезпечує спрощені можливості розробки агентів, особливо цінні для застосувань Edge AI. Завдяки широкому каталогу моделей, що підтримують постачальників, таких як Anthropic, OpenAI, GitHub і Google, у поєднанні з локальним виконанням через ONNX і Ollama, цей інструментарій пропонує гнучкість, необхідну для різноманітних сценаріїв розгортання на краю.

Сила інструментарію полягає в його інтегрованому підході — від пошуку моделей і експериментів у Playground до складної розробки агентів за допомогою Prompt Builder, комплексних можливостей оцінки та безшовної інтеграції інструментів MCP. Для розробників Edge AI це означає швидке створення прототипів і тестування AI-агентів перед розгортанням на краю з можливістю швидкої ітерації та оптимізації для середовищ із обмеженими ресурсами.

Основні переваги для розробки Edge AI включають:  
- **Швидке експериментування**: Швидко тестуйте моделі та агентів перед розгортанням на краю  
- **Гнучкість багатопостачальника**: Доступ до моделей із різних джерел для пошуку оптимальних рішень для краю  
- **Локальна розробка**: Тестуйте з ONNX і Ollama для автономної та конфіденційної розробки  
- **Готовність до виробництва**: Генеруйте готовий до виробництва код і інтегруйте з зовнішніми інструментами через MCP  
- **Комплексна оцінка**: Використовуйте вбудовані та користувацькі метрики для перевірки продуктивності Edge AI  

Оскільки AI продовжує рухатися до сценаріїв розгортання на краю, AI Toolkit для VS Code забезпечує середовище розробки та робочий процес, необхідні для створення, тестування та оптимізації інтелектуальних застосувань для середовищ із обмеженими ресурсами. Незалежно від того, чи розробляєте ви IoT-рішення, мобільні AI-додатки або вбудовані інтелектуальні системи, комплексний набір функцій і інтегрований робочий процес інструментарію підтримують весь життєвий цикл розробки Edge AI.

З постійним розвитком і активною спільнотою (1.8k+ зірок на GitHub) AI Toolkit залишається на передовій серед інструментів розробки AI, постійно еволюціонуючи, щоб задовольняти потреби сучасних розробників AI, які працюють над сценаріями розгортання на краю.

[Next Foundry Local](./foundrylocal.md)  

---

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.