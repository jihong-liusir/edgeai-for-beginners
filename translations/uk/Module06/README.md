<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-18T23:39:10+00:00",
  "source_file": "Module06/README.md",
  "language_code": "uk"
}
-->
# Розділ 06: Агентні системи SLM: Комплексний огляд

Ландшафт штучного інтелекту зазнає фундаментальних змін, переходячи від простих чат-ботів до складних AI-агентів, які працюють на основі Малих Мовних Моделей (SLM). Цей комплексний посібник досліджує три ключові аспекти сучасних агентних систем SLM: базові концепції та стратегії впровадження, можливості виклику функцій і революційну інтеграцію Протоколу Контексту Моделі (MCP).

## [Розділ 1: Основи AI-агентів і Малих Мовних Моделей](./01.IntroduceAgent.md)

Перший розділ закладає базове розуміння AI-агентів і Малих Мовних Моделей, визначаючи 2025 рік як рік AI-агентів після ери чат-ботів у 2023 році та буму копілотів у 2024 році. У цьому розділі представлені **агентні AI-системи**, які думають, розмірковують, планують, використовують інструменти та виконують завдання з мінімальним втручанням людини.

### Основні концепції:
- **Класифікаційна структура агентів**: Від простих рефлексивних агентів до агентів, що навчаються, з наданням повної таксономії для різних обчислювальних сценаріїв
- **Основи SLM**: Визначення Малих Мовних Моделей як моделей з менш ніж 10 мільярдами параметрів, які можуть виконувати практичні обчислення на споживчих пристроях
- **Стратегії вдосконаленої оптимізації**: Охоплення форматів розгортання GGUF, технік квантування (Q4_K_M, Q5_K_S, Q8_0) і оптимізованих для периферії фреймворків, таких як Llama.cpp і Apple MLX
- **Порівняння SLM і LLM**: Демонстрація зниження витрат у 10-30 разів із використанням SLM при збереженні ефективності для 70-80% типових завдань агентів

Розділ завершується практичними стратегіями впровадження за допомогою Ollama, VLLM і рішень Microsoft для периферії, встановлюючи SLM як майбутнє економічно вигідного та конфіденційного впровадження агентного AI.

## [Розділ 2: Виклик функцій у Малих Мовних Моделях](./02.FunctionCalling.md)

Другий розділ глибоко досліджує **можливості виклику функцій**, механізм, який перетворює статичні мовні моделі на динамічні AI-агенти, здатні до взаємодії з реальним світом. Цей технічний аналіз охоплює повний робочий процес від визначення намірів до інтеграції відповідей.

### Основні області впровадження:
- **Систематичний робочий процес**: Детальне дослідження інтеграції інструментів, визначення функцій, виявлення намірів, генерації JSON-виходу та зовнішнього виконання
- **Імплементації для конкретних платформ**: Комплексні посібники для Phi-4-mini з Ollama, виклику функцій Qwen3 і інтеграції Microsoft Foundry Local
- **Розширені приклади**: Системи співпраці між агентами, динамічний вибір інструментів і шаблони інтеграції для підприємств із комплексним обробленням помилок
- **Виробничі аспекти**: Обмеження швидкості, ведення журналів аудиту, заходи безпеки та стратегії оптимізації продуктивності

Цей розділ забезпечує як теоретичне розуміння, так і практичні шаблони впровадження, дозволяючи розробникам створювати надійні системи виклику функцій, які можуть обробляти все — від простих API-запитів до складних багатокрокових робочих процесів для підприємств.

## [Розділ 3: Інтеграція Протоколу Контексту Моделі (MCP)](./03.IntroduceMCP.md)

Останній розділ представляє **Протокол Контексту Моделі (MCP)**, революційну структуру, яка стандартизує взаємодію мовних моделей із зовнішніми інструментами та системами. У цьому розділі показано, як MCP створює міст між AI-моделями та реальним світом через чітко визначені протоколи.

### Основні аспекти інтеграції:
- **Архітектура протоколу**: Багатошаровий дизайн системи, що охоплює рівні застосунків, клієнтів LLM, клієнтів MCP і обробки інструментів
- **Підтримка багатьох бекендів**: Гнучка імплементація, яка підтримує як Ollama (локальна розробка), так і vLLM (виробничі бекенди)
- **Протоколи з'єднання**: Режим STDIO для прямої комунікації процесів і режим SSE для потокової передачі через HTTP
- **Реальні застосування**: Автоматизація вебу, обробка даних і приклади інтеграції API з комплексним обробленням помилок

Інтеграція MCP демонструє, як SLM можуть бути доповнені зовнішніми можливостями, компенсуючи їхню меншу кількість параметрів через розширену функціональність, зберігаючи при цьому переваги локального впровадження та ефективного використання ресурсів.

## Стратегічні наслідки

Разом ці три розділи представляють комплексну структуру для розуміння та впровадження агентних систем SLM. Еволюція від базових концепцій через виклик функцій до інтеграції MCP демонструє чіткий шлях до демократизованого впровадження AI, де:

- **Ефективність поєднується з можливостями** завдяки оптимізованим малим моделям
- **Економічність** сприяє широкому впровадженню
- **Стандартизовані протоколи** забезпечують сумісність
- **Локальне впровадження** зберігає конфіденційність і знижує затримки

Ця прогресія представляє не просто технологічний прорив, а зміну парадигми до більш доступних, ефективних і практичних AI-систем, які можуть ефективно працювати в умовах обмежених ресурсів, забезпечуючи при цьому складні агентні можливості.

Поєднання SLM із вдосконаленими стратегіями впровадження, надійним викликом функцій і стандартизованими протоколами інтеграції інструментів позиціонує ці системи як основу для наступного покоління AI-агентів, які змінять спосіб нашої взаємодії з штучним інтелектом і отримання користі від нього в різних галузях і застосуваннях.

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.