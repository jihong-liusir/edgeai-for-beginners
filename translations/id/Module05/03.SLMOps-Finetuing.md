<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T14:50:07+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "id"
}
-->
# Bagian 3: Fine-Tuning - Menyesuaikan Model untuk Tugas Spesifik

## Daftar Isi
1. [Pengantar Fine-Tuning](../../../Module05)
2. [Mengapa Fine-Tuning Penting](../../../Module05)
3. [Jenis Fine-Tuning](../../../Module05)
4. [Fine-Tuning dengan Microsoft Olive](../../../Module05)
5. [Contoh Praktis](../../../Module05)
6. [Praktik Terbaik dan Panduan](../../../Module05)
7. [Teknik Lanjutan](../../../Module05)
8. [Evaluasi dan Pemantauan](../../../Module05)
9. [Tantangan Umum dan Solusi](../../../Module05)
10. [Kesimpulan](../../../Module05)

## Pengantar Fine-Tuning

**Fine-tuning** adalah teknik pembelajaran mesin yang kuat, di mana model yang telah dilatih sebelumnya disesuaikan untuk melakukan tugas tertentu atau bekerja dengan dataset khusus. Alih-alih melatih model dari awal, fine-tuning memanfaatkan pengetahuan yang sudah dipelajari oleh model yang telah dilatih sebelumnya dan menyesuaikannya untuk kasus penggunaan tertentu.

### Apa itu Fine-Tuning?

Fine-tuning adalah bentuk **transfer learning** di mana Anda:
- Memulai dengan model yang telah dilatih sebelumnya yang telah mempelajari pola umum dari dataset besar
- Menyesuaikan parameter internal model menggunakan dataset spesifik Anda
- Mempertahankan pengetahuan yang berharga sambil mengkhususkan model untuk tugas Anda

Bayangkan seperti mengajari seorang koki berpengalaman untuk memasak masakan baru - mereka sudah memahami dasar-dasar memasak, tetapi perlu mempelajari teknik dan rasa khusus untuk gaya masakan baru.

### Manfaat Utama

- **Efisiensi Waktu**: Jauh lebih cepat dibandingkan melatih dari awal
- **Efisiensi Data**: Membutuhkan dataset yang lebih kecil untuk mencapai performa yang baik
- **Efektif Biaya**: Memerlukan sumber daya komputasi yang lebih rendah
- **Performa Lebih Baik**: Sering kali menghasilkan hasil yang lebih baik dibandingkan melatih dari awal
- **Optimalisasi Sumber Daya**: Membuat AI yang kuat dapat diakses oleh tim dan organisasi yang lebih kecil

## Mengapa Fine-Tuning Penting

### Aplikasi Dunia Nyata

Fine-tuning sangat penting dalam berbagai skenario:

**1. Adaptasi Domain**
- AI Medis: Menyesuaikan model bahasa umum untuk terminologi medis dan catatan klinis
- Teknologi Hukum: Mengkhususkan model untuk analisis dokumen hukum dan tinjauan kontrak
- Layanan Keuangan: Menyesuaikan model untuk analisis laporan keuangan dan penilaian risiko

**2. Spesialisasi Tugas**
- Pembuatan Konten: Fine-tuning untuk gaya penulisan atau nada tertentu
- Pembuatan Kode: Menyesuaikan model untuk bahasa pemrograman atau kerangka kerja tertentu
- Terjemahan: Meningkatkan performa untuk pasangan bahasa tertentu atau domain teknis

**3. Aplikasi Korporat**
- Layanan Pelanggan: Membuat chatbot yang memahami terminologi spesifik perusahaan
- Dokumentasi Internal: Membangun asisten AI yang akrab dengan proses organisasi
- Solusi Industri-Specific: Mengembangkan model yang memahami jargon dan alur kerja spesifik sektor

## Jenis Fine-Tuning

### 1. Full Fine-Tuning (Instruction Fine-Tuning)

Dalam full fine-tuning, semua parameter model diperbarui selama pelatihan. Pendekatan ini:
- Memberikan fleksibilitas maksimum dan potensi performa terbaik
- Membutuhkan sumber daya komputasi yang signifikan
- Menghasilkan versi model yang sepenuhnya baru
- Terbaik untuk skenario di mana Anda memiliki data pelatihan yang besar dan sumber daya komputasi yang memadai

### 2. Parameter-Efficient Fine-Tuning (PEFT)

Metode PEFT hanya memperbarui sebagian kecil parameter, membuat proses lebih efisien:

#### Low-Rank Adaptation (LoRA)
- Menambahkan matriks dekomposisi peringkat kecil yang dapat dilatih ke bobot yang ada
- Secara dramatis mengurangi jumlah parameter yang dapat dilatih
- Mempertahankan performa yang mendekati full fine-tuning
- Memungkinkan pergantian yang mudah antara adaptasi yang berbeda

#### QLoRA (Quantized LoRA)
- Menggabungkan LoRA dengan teknik kuantisasi
- Lebih mengurangi kebutuhan memori
- Memungkinkan fine-tuning model yang lebih besar pada perangkat keras konsumen
- Menyeimbangkan efisiensi dengan performa

#### Adapters
- Menyisipkan jaringan neural kecil di antara lapisan yang ada
- Memungkinkan fine-tuning yang terarah sambil menjaga model dasar tetap beku
- Memungkinkan pendekatan modular untuk kustomisasi model

### 3. Fine-Tuning Spesifik Tugas

Berfokus pada penyesuaian model untuk tugas-tugas downstream tertentu:
- **Klasifikasi**: Menyesuaikan model untuk tugas kategorisasi
- **Pembuatan**: Mengoptimalkan untuk pembuatan konten dan teks
- **Ekstraksi**: Fine-tuning untuk ekstraksi informasi dan pengenalan entitas bernama
- **Ringkasan**: Mengkhususkan model untuk ringkasan dokumen

## Fine-Tuning dengan Microsoft Olive

Microsoft Olive adalah toolkit optimasi model yang komprehensif yang menyederhanakan proses fine-tuning sambil menyediakan fitur kelas enterprise.

### Apa itu Microsoft Olive?

Microsoft Olive adalah alat optimasi model open-source yang:
- Merampingkan alur kerja fine-tuning untuk berbagai target perangkat keras
- Memberikan dukungan bawaan untuk arsitektur model populer (Llama, Phi, Qwen, Gemma)
- Menawarkan opsi penerapan cloud dan lokal
- Terintegrasi dengan mulus dengan Azure ML dan layanan AI Microsoft lainnya
- Mendukung optimasi dan kuantisasi otomatis

### Fitur Utama

- **Optimasi Berbasis Perangkat Keras**: Secara otomatis mengoptimalkan model untuk perangkat keras tertentu (CPU, GPU, NPU)
- **Dukungan Multi-Format**: Bekerja dengan model PyTorch, Hugging Face, dan ONNX
- **Alur Kerja Otomatis**: Mengurangi konfigurasi manual dan coba-coba
- **Integrasi Enterprise**: Dukungan bawaan untuk Azure ML dan penerapan cloud
- **Arsitektur yang Dapat Diperluas**: Memungkinkan teknik optimasi kustom

### Instalasi dan Pengaturan

#### Instalasi Dasar

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dependensi Opsional

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verifikasi Instalasi

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Contoh Praktis

### Contoh 1: Fine-Tuning Dasar dengan Olive CLI

Contoh ini menunjukkan fine-tuning model bahasa kecil untuk klasifikasi frasa:

#### Langkah 1: Siapkan Lingkungan Anda

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Langkah 2: Fine-Tune Model

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Langkah 3: Optimalkan untuk Penerapan

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Contoh 2: Konfigurasi Lanjutan dengan Dataset Kustom

#### Langkah 1: Siapkan Dataset Kustom

Buat file JSON dengan data pelatihan Anda:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Langkah 2: Buat File Konfigurasi

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Langkah 3: Eksekusi Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Contoh 3: Fine-Tuning QLoRA untuk Efisiensi Memori

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Praktik Terbaik dan Panduan

### Persiapan Data

**1. Kualitas Data Lebih Penting daripada Kuantitas**
- Prioritaskan contoh yang berkualitas tinggi dan beragam daripada volume besar data yang buruk
- Pastikan data mewakili kasus penggunaan target Anda
- Bersihkan dan lakukan pra-pemrosesan data secara konsisten

**2. Format Data dan Template**
- Gunakan format yang konsisten di semua contoh pelatihan
- Buat template input-output yang jelas yang sesuai dengan kasus penggunaan Anda
- Sertakan format instruksi yang sesuai untuk model yang disetel dengan instruksi

**3. Pemisahan Dataset**
- Sisihkan 10-20% data untuk validasi
- Pertahankan distribusi yang serupa di antara pembagian pelatihan/validasi
- Pertimbangkan pengambilan sampel terstratifikasi untuk tugas klasifikasi

### Konfigurasi Pelatihan

**1. Pemilihan Learning Rate**
- Mulailah dengan learning rate yang lebih kecil (1e-5 hingga 1e-4) untuk fine-tuning
- Gunakan penjadwalan learning rate untuk konvergensi yang lebih baik
- Pantau kurva loss untuk menyesuaikan learning rate sesuai kebutuhan

**2. Optimasi Ukuran Batch**
- Seimbangkan ukuran batch dengan memori yang tersedia
- Gunakan akumulasi gradien untuk ukuran batch efektif yang lebih besar
- Pertimbangkan hubungan antara ukuran batch dan learning rate

**3. Durasi Pelatihan**
- Pantau metrik validasi untuk menghindari overfitting
- Gunakan early stopping saat performa validasi mulai stagnan
- Simpan checkpoint secara teratur untuk pemulihan dan analisis

### Pemilihan Model

**1. Pilihan Model Dasar**
- Pilih model yang telah dilatih sebelumnya pada domain yang serupa jika memungkinkan
- Pertimbangkan ukuran model relatif terhadap batasan komputasi Anda
- Evaluasi persyaratan lisensi untuk penggunaan komersial

**2. Pemilihan Metode Fine-Tuning**
- Gunakan LoRA/QLoRA untuk lingkungan dengan sumber daya terbatas
- Pilih full fine-tuning saat performa maksimum sangat penting
- Pertimbangkan pendekatan berbasis adapter untuk skenario multi-tugas

### Manajemen Sumber Daya

**1. Optimasi Perangkat Keras**
- Pilih perangkat keras yang sesuai untuk ukuran model dan metode Anda
- Gunakan memori GPU secara efisien dengan checkpointing gradien
- Pertimbangkan solusi berbasis cloud untuk model yang lebih besar

**2. Manajemen Memori**
- Gunakan pelatihan presisi campuran jika tersedia
- Implementasikan akumulasi gradien untuk kendala memori
- Pantau penggunaan memori GPU selama pelatihan

## Teknik Lanjutan

### Pelatihan Multi-Adapter

Latih beberapa adapter untuk tugas yang berbeda sambil berbagi model dasar:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optimasi Hyperparameter

Implementasikan penyetelan hyperparameter secara sistematis:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Fungsi Loss Kustom

Implementasikan fungsi loss spesifik domain:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluasi dan Pemantauan

### Metrik dan Evaluasi

**1. Metrik Standar**
- **Akurasi**: Tingkat kebenaran keseluruhan untuk tugas klasifikasi
- **Perplexity**: Ukuran kualitas pemodelan bahasa
- **BLEU/ROUGE**: Kualitas pembuatan teks dan ringkasan
- **F1 Score**: Keseimbangan presisi dan recall untuk klasifikasi

**2. Metrik Spesifik Domain**
- **Benchmark Tugas-Specific**: Gunakan benchmark yang sudah mapan untuk domain Anda
- **Evaluasi Manusia**: Sertakan penilaian manusia untuk tugas subjektif
- **Metrik Bisnis**: Selaraskan dengan tujuan bisnis yang sebenarnya

**3. Pengaturan Evaluasi**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Pemantauan Kemajuan Pelatihan

**1. Pelacakan Loss**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Pemantauan Validasi**
- Pantau loss validasi bersamaan dengan loss pelatihan
- Pantau tanda-tanda overfitting (loss validasi meningkat sementara loss pelatihan menurun)
- Gunakan early stopping berdasarkan metrik validasi

**3. Pemantauan Sumber Daya**
- Pantau penggunaan GPU/CPU
- Lacak pola penggunaan memori
- Pantau kecepatan pelatihan dan throughput

## Tantangan Umum dan Solusi

### Tantangan 1: Overfitting

**Gejala:**
- Loss pelatihan terus menurun sementara loss validasi meningkat
- Kesenjangan besar antara performa pelatihan dan validasi
- Generalisasi yang buruk terhadap data baru

**Solusi:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Tantangan 2: Keterbatasan Memori

**Solusi:**
- Gunakan checkpointing gradien
- Implementasikan akumulasi gradien
- Pilih metode parameter-efficient (LoRA, QLoRA)
- Gunakan model paralelisme untuk model besar

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Tantangan 3: Pelatihan Lambat

**Solusi:**
- Optimalkan pipeline pemuatan data
- Gunakan pelatihan presisi campuran
- Implementasikan strategi batching yang efisien
- Pertimbangkan pelatihan terdistribusi untuk dataset besar

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Tantangan 4: Performa Buruk

**Langkah Diagnosa:**
1. Verifikasi kualitas dan format data
2. Periksa learning rate dan durasi pelatihan
3. Evaluasi pilihan model dasar
4. Tinjau pra-pemrosesan dan tokenisasi

**Solusi:**
- Tingkatkan keragaman data pelatihan
- Sesuaikan jadwal learning rate
- Coba model dasar yang berbeda
- Implementasikan teknik augmentasi data

## Kesimpulan

Fine-tuning adalah teknik yang kuat yang mendemokratisasi akses ke kemampuan AI mutakhir. Dengan memanfaatkan alat seperti Microsoft Olive, organisasi dapat dengan efisien menyesuaikan model yang telah dilatih sebelumnya untuk kebutuhan spesifik mereka sambil mengoptimalkan performa dan batasan sumber daya.

### Poin Penting

1. **Pilih Pendekatan yang Tepat**: Pilih metode fine-tuning berdasarkan sumber daya komputasi dan kebutuhan performa Anda
2. **Kualitas Data Penting**: Investasikan dalam data pelatihan yang berkualitas tinggi dan representatif
3. **Pantau dan Iterasi**: Evaluasi dan tingkatkan model Anda secara terus-menerus
4. **Manfaatkan Alat**: Gunakan kerangka kerja seperti Olive untuk menyederhanakan dan mengoptimalkan proses
5. **Pertimbangkan Penerapan**: Rencanakan optimasi dan penerapan model sejak awal

## ➡️ Langkah Selanjutnya

- [04: Deployment - Implementasi Model Siap Produksi](./04.SLMOps.Deployment.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan penerjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan hasil yang akurat, harap diketahui bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang otoritatif. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa penerjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.