<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T22:21:33+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "id"
}
-->
# EdgeAI untuk Pemula: Jalur Pembelajaran dan Jadwal Studi

### Jalur Pembelajaran Intensif (1 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 2 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 3 | Modul 3: Penerapan SLM | 2 jam |
| Hari 4-5 | Modul 4: Optimasi Model (6 kerangka kerja) | 4 jam |
| Hari 6 | Modul 5: SLMOps | 3 jam |
| Hari 7 | Modul 6-7: Agen AI & Alat Pengembangan | 5 jam |

### Jalur Pembelajaran Intensif (2 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 5-6 | Modul 3: Penerapan SLM | 2 jam |
| Hari 7-8 | Modul 4: Optimasi Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Agen AI | 2 jam |
| Hari 13-14 | Modul 7: Alat Pengembangan | 3 jam |

### Studi Paruh Waktu (4 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 1-2: Dasar-dasar & Dasar-dasar SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penerapan & Optimasi | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Agen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pengembangan & Integrasi | 3 jam |

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 5-6 | Modul 3: Penerapan SLM | 2 jam |
| Hari 7-8 | Modul 4: Optimasi Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Sistem Agen SLM | 2 jam |
| Hari 13-14 | Modul 7: Contoh Implementasi EdgeAI | 2 jam |

| Modul | Tanggal Selesai | Jam yang Dihabiskan | Poin Penting |
|--------|----------------|-------------|--------------|
| Modul 1: Dasar-dasar EdgeAI | | | |
| Modul 2: Dasar-dasar SLM | | | |
| Modul 3: Penerapan SLM | | | |
| Modul 4: Optimasi Model (6 kerangka kerja) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Sistem Agen SLM | | | |
| Modul 7: Contoh Implementasi EdgeAI | | | |
| Latihan Praktis | | | |
| Mini-Proyek | | | |

### Studi Paruh Waktu (4 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 1-2: Dasar-dasar & Dasar-dasar SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penerapan & Optimasi | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Agen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pengembangan & Integrasi | 3 jam |

## Pendahuluan

Selamat datang di panduan belajar EdgeAI untuk Pemula! Dokumen ini dirancang untuk membantu Anda memahami materi kursus secara efektif dan memaksimalkan pengalaman belajar Anda. Panduan ini menyediakan jalur pembelajaran yang terstruktur, jadwal studi yang disarankan, ringkasan konsep utama, dan sumber daya tambahan untuk memperdalam pemahaman Anda tentang teknologi EdgeAI.

Ini adalah kursus singkat selama 20 jam yang memberikan pengetahuan penting tentang EdgeAI dalam format yang efisien waktu, sehingga cocok untuk profesional sibuk dan pelajar yang ingin dengan cepat memperoleh keterampilan praktis di bidang yang sedang berkembang ini.

## Ikhtisar Kursus

Kursus ini terdiri dari tujuh modul komprehensif:

1. **Dasar-dasar dan Transformasi EdgeAI** - Memahami konsep inti dan perubahan teknologi
2. **Dasar-dasar Model Bahasa Kecil (SLM)** - Menjelajahi berbagai keluarga SLM dan arsitekturnya
3. **Penerapan Model Bahasa Kecil (SLM)** - Menerapkan strategi penerapan praktis
4. **Konversi Format Model dan Kuantisasi** - Optimasi lanjutan dengan 6 kerangka kerja termasuk OpenVINO
5. **SLMOps - Operasi Model Bahasa Kecil** - Manajemen siklus produksi dan penerapan
6. **Sistem Agen SLM** - Agen AI, pemanggilan fungsi, dan Protokol Konteks Model
7. **Contoh Implementasi EdgeAI** - Toolkit AI, pengembangan Windows, dan implementasi spesifik platform
8. **Microsoft Foundry Local â€“ Toolkit Pengembang Lengkap** - Pengembangan lokal dengan integrasi hybrid Azure (Modul 08)

## Cara Menggunakan Panduan Belajar Ini

- **Pembelajaran Bertahap**: Ikuti modul secara berurutan untuk pengalaman belajar yang paling koheren
- **Pemeriksaan Pengetahuan**: Gunakan pertanyaan penilaian diri setelah setiap bagian
- **Latihan Praktis**: Selesaikan latihan yang disarankan untuk memperkuat konsep teoritis
- **Sumber Daya Tambahan**: Jelajahi materi tambahan untuk topik yang paling menarik bagi Anda

## Rekomendasi Jadwal Studi

### Jalur Pembelajaran Intensif (1 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|-----------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 6 jam |
| Hari 3-4 | Modul 2: Dasar-dasar SLM | 8 jam |
| Hari 5 | Modul 3: Penerapan SLM | 3 jam |
| Hari 6 | Modul 8: Toolkit Foundry Local | 3 jam |

### Studi Paruh Waktu (3 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|-----------------|
| Minggu 1 | Modul 1: Dasar-dasar EdgeAI | 6-7 jam |
| Minggu 2 | Modul 2: Dasar-dasar SLM | 7-8 jam |
| Minggu 3 | Modul 3: Penerapan SLM (3 jam) + Modul 8: Toolkit Foundry Local (2-3 jam) | 5-6 jam |

## Modul 1: Dasar-dasar dan Transformasi EdgeAI

### Tujuan Pembelajaran Utama

- Memahami perbedaan antara AI berbasis cloud dan berbasis edge
- Menguasai teknik optimasi inti untuk lingkungan dengan sumber daya terbatas
- Menganalisis aplikasi dunia nyata dari teknologi EdgeAI
- Menyiapkan lingkungan pengembangan untuk proyek EdgeAI

### Area Fokus Studi

#### Bagian 1: Dasar-dasar EdgeAI
- **Konsep Prioritas**: 
  - Paradigma komputasi Edge vs. Cloud
  - Teknik kuantisasi model
  - Opsi akselerasi perangkat keras (NPU, GPU, CPU)
  - Keunggulan privasi dan keamanan

- **Materi Tambahan**:
  - [Dokumentasi TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Dokumentasi Edge Impulse](https://docs.edgeimpulse.com)

#### Bagian 2: Studi Kasus Dunia Nyata
- **Konsep Prioritas**: 
  - Ekosistem model Microsoft Phi & Mu
  - Implementasi praktis di berbagai industri
  - Pertimbangan penerapan

#### Bagian 3: Panduan Implementasi Praktis
- **Konsep Prioritas**: 
  - Penyiapan lingkungan pengembangan
  - Alat kuantisasi dan optimasi
  - Metode penilaian untuk implementasi EdgeAI

#### Bagian 4: Perangkat Keras Penerapan Edge
- **Konsep Prioritas**: 
  - Perbandingan platform perangkat keras
  - Strategi optimasi untuk perangkat keras tertentu
  - Pertimbangan penerapan

### Pertanyaan Penilaian Diri

1. Bandingkan dan kontraskan AI berbasis cloud dengan implementasi AI berbasis edge.
2. Jelaskan tiga teknik utama untuk mengoptimalkan model untuk penerapan edge.
3. Apa keunggulan utama menjalankan model AI di edge?
4. Deskripsikan proses kuantisasi model dan bagaimana hal itu memengaruhi kinerja.
5. Jelaskan bagaimana akselerator perangkat keras yang berbeda (NPU, GPU, CPU) memengaruhi penerapan EdgeAI.

### Latihan Praktis

1. **Penyiapan Lingkungan Cepat**: Konfigurasikan lingkungan pengembangan minimal dengan paket-paket penting (30 menit)
2. **Eksplorasi Model**: Unduh dan periksa model bahasa kecil yang sudah dilatih (1 jam)
3. **Kuantisasi Dasar**: Coba kuantisasi sederhana pada model kecil (1 jam)

## Modul 2: Dasar-dasar Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memahami prinsip arsitektur dari berbagai keluarga SLM
- Membandingkan kemampuan model berdasarkan skala parameter yang berbeda
- Mengevaluasi model berdasarkan efisiensi, kemampuan, dan kebutuhan penerapan
- Mengenali kasus penggunaan yang sesuai untuk berbagai keluarga model

### Area Fokus Studi

#### Bagian 1: Keluarga Model Microsoft Phi
- **Konsep Prioritas**: 
  - Evolusi filosofi desain
  - Arsitektur yang mengutamakan efisiensi
  - Kemampuan khusus

#### Bagian 2: Keluarga Qwen
- **Konsep Prioritas**: 
  - Kontribusi sumber terbuka
  - Opsi penerapan yang skalabel
  - Arsitektur penalaran lanjutan

#### Bagian 3: Keluarga Gemma
- **Konsep Prioritas**: 
  - Inovasi berbasis penelitian
  - Kemampuan multimodal
  - Optimasi untuk perangkat seluler

#### Bagian 4: Keluarga BitNET
- **Konsep Prioritas**: 
  - Teknologi kuantisasi 1-bit
  - Kerangka kerja optimasi inferensi
  - Pertimbangan keberlanjutan

#### Bagian 5: Model Microsoft Mu
- **Konsep Prioritas**: 
  - Arsitektur yang mengutamakan perangkat
  - Integrasi sistem dengan Windows
  - Operasi yang menjaga privasi

#### Bagian 6: Phi-Silica
- **Konsep Prioritas**: 
  - Arsitektur yang dioptimalkan untuk NPU
  - Metrik kinerja
  - Integrasi pengembang

### Pertanyaan Penilaian Diri

1. Bandingkan pendekatan arsitektur keluarga model Phi dan Qwen.
2. Jelaskan bagaimana teknologi kuantisasi BitNET berbeda dari kuantisasi tradisional.
3. Apa keunggulan unik model Mu untuk integrasi Windows?
4. Deskripsikan bagaimana Phi-Silica memanfaatkan perangkat keras NPU untuk optimasi kinerja.
5. Untuk aplikasi seluler dengan konektivitas terbatas, keluarga model mana yang paling sesuai dan mengapa?

### Latihan Praktis

1. **Perbandingan Model**: Benchmark cepat dua model SLM yang berbeda (1 jam)
2. **Generasi Teks Sederhana**: Implementasi dasar generasi teks dengan model kecil (1 jam)
3. **Optimasi Cepat**: Terapkan satu teknik optimasi untuk meningkatkan kecepatan inferensi (1 jam)

## Modul 3: Penerapan Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memilih model yang sesuai berdasarkan kendala penerapan
- Menguasai teknik optimasi untuk berbagai skenario penerapan
- Menerapkan SLM di lingkungan lokal dan cloud
- Merancang konfigurasi siap produksi untuk aplikasi EdgeAI

### Area Fokus Studi

#### Bagian 1: Pembelajaran Lanjutan SLM
- **Konsep Prioritas**: 
  - Kerangka klasifikasi parameter
  - Teknik optimasi lanjutan
  - Strategi akuisisi model

#### Bagian 2: Penerapan Lingkungan Lokal
- **Konsep Prioritas**: 
  - Penerapan platform Ollama
  - Solusi lokal Microsoft Foundry
  - Analisis perbandingan kerangka kerja

#### Bagian 3: Penerapan Cloud yang Terkontainerisasi
- **Konsep Prioritas**: 
  - Inferensi kinerja tinggi vLLM
  - Orkestrasi kontainer
  - Implementasi ONNX Runtime

### Pertanyaan Penilaian Diri

1. Faktor apa yang harus dipertimbangkan saat memilih antara penerapan lokal dan penerapan cloud?
2. Bandingkan Ollama dan Microsoft Foundry Local sebagai opsi penerapan.
3. Jelaskan manfaat kontainerisasi untuk penerapan SLM.
4. Apa metrik kinerja utama yang harus dipantau untuk SLM yang diterapkan di edge?
5. Deskripsikan alur kerja penerapan lengkap dari pemilihan model hingga implementasi produksi.

### Latihan Praktis

1. **Penerapan Lokal Dasar**: Terapkan SLM sederhana menggunakan Ollama (1 jam)
2. **Pemeriksaan Kinerja**: Jalankan benchmark cepat pada model yang diterapkan (30 menit)
3. **Integrasi Sederhana**: Buat aplikasi minimal yang menggunakan model yang diterapkan (1 jam)

## Modul 4: Konversi Format Model dan Kuantisasi

### Tujuan Pembelajaran Utama

- Menguasai teknik kuantisasi lanjutan dari presisi 1-bit hingga 8-bit
- Memahami strategi konversi format (GGUF, ONNX)
- Menerapkan optimasi di enam kerangka kerja (Llama.cpp, Olive, OpenVINO, MLX, sintesis alur kerja)
- Menerapkan model yang dioptimalkan untuk lingkungan produksi edge di perangkat keras Intel, Apple, dan lintas platform

### Area Fokus Studi

#### Bagian 1: Dasar-dasar Kuantisasi
- **Konsep Prioritas**: 
  - Kerangka klasifikasi presisi
  - Perdagangan antara kinerja dan akurasi
  - Optimasi jejak memori

#### Bagian 2: Implementasi Llama.cpp
- **Konsep Prioritas**: 
  - Penerapan lintas platform
  - Optimasi format GGUF
  - Teknik akselerasi perangkat keras

#### Bagian 3: Suite Microsoft Olive
- **Konsep Prioritas**: 
  - Optimasi yang sadar perangkat keras
  - Penerapan tingkat perusahaan
  - Alur kerja optimasi otomatis

#### Bagian 4: Toolkit OpenVINO
- **Konsep Prioritas**: 
  - Optimasi perangkat keras Intel
  - Kerangka Kompresi Jaringan Neural (NNCF)
  - Penerapan inferensi lintas platform
  - OpenVINO GenAI untuk penerapan LLM

#### Bagian 5: Kerangka Apple MLX
- **Konsep Prioritas**: 
  - Optimasi Apple Silicon
  - Arsitektur memori terpadu
  - Kemampuan fine-tuning LoRA

#### Bagian 6: Sintesis Alur Kerja Pengembangan Edge AI
- **Konsep Prioritas**: 
  - Arsitektur alur kerja terpadu
  - Pohon keputusan pemilihan kerangka kerja
  - Validasi kesiapan produksi
  - Strategi untuk masa depan

### Pertanyaan Penilaian Diri

1. Bandingkan strategi kuantisasi pada berbagai tingkat presisi (1-bit hingga 8-bit).
2. Jelaskan keuntungan format GGUF untuk penerapan di edge.
3. Bagaimana optimasi berbasis perangkat keras di Microsoft Olive meningkatkan efisiensi penerapan?
4. Apa manfaat utama dari NNCF OpenVINO untuk kompresi model?
5. Deskripsikan bagaimana Apple MLX memanfaatkan arsitektur memori terpadu untuk optimasi.
6. Bagaimana sintesis alur kerja membantu dalam memilih kerangka kerja optimasi yang optimal?

### Latihan Praktis

1. **Kuantisasi Model**: Terapkan berbagai tingkat kuantisasi pada model dan bandingkan hasilnya (1 jam)
2. **Optimasi OpenVINO**: Gunakan NNCF untuk mengompresi model untuk perangkat keras Intel (1 jam)
3. **Perbandingan Kerangka Kerja**: Uji model yang sama pada tiga kerangka kerja optimasi yang berbeda (1 jam)
4. **Benchmarking Kinerja**: Ukur dampak optimasi pada kecepatan inferensi dan penggunaan memori (1 jam)

## Modul 5: SLMOps - Operasi Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memahami prinsip manajemen siklus hidup SLMOps
- Menguasai teknik distilasi dan fine-tuning untuk penerapan di edge
- Menerapkan strategi penerapan produksi dengan pemantauan
- Membangun alur kerja operasi dan pemeliharaan SLM tingkat perusahaan

### Area Fokus Studi

#### Bagian 1: Pengantar SLMOps
- **Konsep Prioritas**: 
  - Pergeseran paradigma SLMOps dalam operasi AI
  - Arsitektur hemat biaya dan berorientasi privasi
  - Dampak strategis bisnis dan keunggulan kompetitif

#### Bagian 2: Distilasi Model
- **Konsep Prioritas**: 
  - Teknik transfer pengetahuan
  - Implementasi proses distilasi dua tahap
  - Alur kerja distilasi Azure ML

#### Bagian 3: Strategi Fine-tuning
- **Konsep Prioritas**: 
  - Fine-tuning yang efisien dalam parameter (PEFT)
  - Metode canggih LoRA dan QLoRA
  - Pelatihan multi-adapter dan optimasi hyperparameter

#### Bagian 4: Penerapan Produksi
- **Konsep Prioritas**: 
  - Konversi model dan kuantisasi untuk produksi
  - Konfigurasi penerapan Foundry Local
  - Benchmarking kinerja dan validasi kualitas

### Pertanyaan Penilaian Diri

1. Bagaimana SLMOps berbeda dari MLOps tradisional?
2. Jelaskan manfaat distilasi model untuk penerapan di edge.
3. Apa pertimbangan utama untuk fine-tuning SLM dalam lingkungan dengan sumber daya terbatas?
4. Deskripsikan pipeline penerapan produksi lengkap untuk aplikasi AI di edge.

### Latihan Praktis

1. **Distilasi Dasar**: Buat model yang lebih kecil dari model guru yang lebih besar (1 jam)
2. **Eksperimen Fine-tuning**: Fine-tuning model untuk domain tertentu (1 jam)
3. **Pipeline Penerapan**: Siapkan pipeline CI/CD dasar untuk penerapan model (1 jam)

## Modul 6: Sistem Agenik SLM - Agen AI dan Pemanggilan Fungsi

### Tujuan Pembelajaran Utama

- Membangun agen AI cerdas untuk lingkungan edge menggunakan Model Bahasa Kecil
- Menerapkan kemampuan pemanggilan fungsi dengan alur kerja sistematis
- Menguasai integrasi Model Context Protocol (MCP) untuk interaksi alat yang terstandarisasi
- Membuat sistem agenik yang canggih dengan intervensi manusia minimal

### Area Fokus Studi

#### Bagian 1: Agen AI dan Dasar SLM
- **Konsep Prioritas**: 
  - Kerangka klasifikasi agen (refleks, berbasis model, berbasis tujuan, agen pembelajaran)
  - Analisis trade-off SLM vs LLM
  - Pola desain agen khusus edge
  - Optimasi sumber daya untuk agen

#### Bagian 2: Pemanggilan Fungsi dalam Model Bahasa Kecil
- **Konsep Prioritas**: 
  - Implementasi alur kerja sistematis (deteksi intent, output JSON, eksekusi eksternal)
  - Implementasi spesifik platform (Phi-4-mini, model Qwen terpilih, Microsoft Foundry Local)
  - Contoh lanjutan (kolaborasi multi-agen, pemilihan alat dinamis)
  - Pertimbangan produksi (pembatasan tingkat, pencatatan audit, langkah keamanan)

#### Bagian 3: Integrasi Model Context Protocol (MCP)
- **Konsep Prioritas**: 
  - Arsitektur protokol dan desain sistem berlapis
  - Dukungan multi-backend (Ollama untuk pengembangan, vLLM untuk produksi)
  - Protokol koneksi (mode STDIO dan SSE)
  - Aplikasi dunia nyata (otomasi web, pemrosesan data, integrasi API)

### Pertanyaan Penilaian Diri

1. Apa pertimbangan arsitektur utama untuk agen AI di edge?
2. Bagaimana pemanggilan fungsi meningkatkan kemampuan agen?
3. Jelaskan peran Model Context Protocol dalam komunikasi agen.

### Latihan Praktis

1. **Agen Sederhana**: Bangun agen AI dasar dengan pemanggilan fungsi (1 jam)
2. **Integrasi MCP**: Terapkan MCP dalam aplikasi agen (30 menit)

## Modul 7: Contoh Implementasi EdgeAI

### Tujuan Pembelajaran Utama

- Menguasai AI Toolkit untuk Visual Studio Code untuk alur kerja pengembangan EdgeAI yang komprehensif
- Mendapatkan keahlian dalam platform Windows AI Foundry dan strategi optimasi NPU
- Menerapkan EdgeAI di berbagai platform perangkat keras dan skenario penerapan
- Membangun aplikasi EdgeAI siap produksi dengan optimasi spesifik platform

### Area Fokus Studi

#### Bagian 1: AI Toolkit untuk Visual Studio Code
- **Konsep Prioritas**: 
  - Lingkungan pengembangan Edge AI yang komprehensif dalam VS Code
  - Katalog model dan penemuan untuk penerapan di edge
  - Alur kerja pengujian lokal, optimasi, dan pengembangan agen
  - Pemantauan kinerja dan evaluasi untuk skenario edge

#### Bagian 2: Panduan Pengembangan Windows EdgeAI
- **Konsep Prioritas**: 
  - Gambaran komprehensif platform Windows AI Foundry
  - API Phi Silica untuk inferensi NPU yang efisien
  - API Computer Vision untuk pemrosesan gambar dan OCR
  - CLI Foundry Local untuk pengembangan dan pengujian lokal

#### Bagian 3: Implementasi Spesifik Platform
- **Konsep Prioritas**: 
  - Penerapan NVIDIA Jetson Orin Nano (67 TOPS kinerja AI)
  - Aplikasi seluler dengan .NET MAUI dan ONNX Runtime GenAI
  - Solusi Azure EdgeAI dengan arsitektur hybrid cloud-edge
  - Optimasi Windows ML dengan dukungan perangkat keras universal
  - Aplikasi Foundry Local dengan implementasi RAG berorientasi privasi

### Pertanyaan Penilaian Diri

1. Bagaimana AI Toolkit menyederhanakan alur kerja pengembangan EdgeAI?
2. Bandingkan strategi penerapan di berbagai platform perangkat keras.
3. Apa keuntungan Windows AI Foundry untuk pengembangan di edge?
4. Jelaskan peran optimasi NPU dalam aplikasi AI edge modern.
5. Bagaimana API Phi Silica memanfaatkan perangkat keras NPU untuk optimasi kinerja?
6. Bandingkan manfaat penerapan lokal vs cloud untuk aplikasi yang sensitif terhadap privasi.

### Latihan Praktis

1. **Pengaturan AI Toolkit**: Konfigurasikan AI Toolkit dan optimalkan model (1 jam)
2. **Windows AI Foundry**: Bangun aplikasi AI Windows sederhana menggunakan API Phi Silica (1 jam)
3. **Penerapan Lintas Platform**: Terapkan model yang sama di dua platform berbeda (1 jam)
4. **Optimasi NPU**: Uji kinerja NPU dengan alat Windows AI Foundry (30 menit)

## Modul 8: Microsoft Foundry Local â€“ Toolkit Pengembang Lengkap

### Tujuan Pembelajaran Utama

- Instal dan konfigurasikan Foundry Local di Windows
- Jalankan, temukan, dan kelola model secara lokal melalui Foundry CLI
- Integrasi dengan klien REST dan SDK yang kompatibel dengan OpenAI
- Bangun contoh praktis: obrolan Chainlit, agen, dan router model
- Memahami pola hybrid dengan Azure AI Foundry

### Area Fokus Studi

- Instalasi dan dasar-dasar CLI (model, layanan, cache)
- Integrasi SDK (klien yang kompatibel dengan OpenAI dan Azure OpenAI)
- Validasi cepat Open WebUI
- Pola agen dan pemanggilan fungsi
- Model sebagai alat (desain router dan registri)

### Pertanyaan Penilaian Diri

1. Bagaimana Anda menemukan endpoint lokal dan daftar model yang tersedia?
2. Apa perbedaan antara penggunaan REST Foundry Local dan Azure OpenAI?
3. Bagaimana Anda mendesain router sederhana untuk memilih model sebagai alat?
4. Kategori CLI mana yang paling relevan untuk pengembangan sehari-hari?
5. Bagaimana Anda memvalidasi kesiapan Foundry Local sebelum menjalankan aplikasi?

### Latihan Praktis

1. Instal/upgrade Foundry Local dan jalankan `phi-4-mini` secara lokal (30 menit)
2. Panggil `/v1/models` dan jalankan obrolan sederhana melalui REST (30 menit)
3. Luncurkan contoh aplikasi Chainlit dan obrolan secara lokal (30 menit)
4. Jalankan koordinator multi-agen dan inspeksi output (30 menit)
5. Coba router model sebagai alat dengan pengaturan berbasis lingkungan (30 menit)

## Panduan Alokasi Waktu

Untuk membantu Anda memanfaatkan waktu kursus 20 jam, berikut adalah pembagian waktu yang disarankan:

| Aktivitas | Alokasi Waktu | Deskripsi |
|----------|----------------|-------------|
| Membaca Materi Inti | 9 jam | Fokus pada konsep penting di setiap modul |
| Latihan Praktis | 6 jam | Implementasi teknik utama secara praktis |
| Penilaian Diri | 2 jam | Menguji pemahaman melalui pertanyaan dan refleksi |
| Proyek Mini | 3 jam | Menerapkan pengetahuan ke implementasi praktis kecil |

### Area Fokus Utama Berdasarkan Keterbatasan Waktu

**Jika Anda hanya memiliki 10 jam:**
- Selesaikan Modul 1, 2, dan 3 (konsep inti EdgeAI)
- Lakukan setidaknya satu latihan praktis per modul
- Fokus pada pemahaman konsep inti daripada detail implementasi

**Jika Anda dapat mendedikasikan waktu penuh 20 jam:**
- Selesaikan semua tujuh modul
- Lakukan latihan praktis utama dari setiap modul
- Selesaikan satu proyek mini dari Modul 7
- Jelajahi setidaknya 2-3 sumber tambahan

**Jika Anda memiliki lebih dari 20 jam:**
- Selesaikan semua modul dengan latihan terperinci
- Bangun beberapa proyek mini
- Jelajahi teknik optimasi lanjutan di Modul 4
- Terapkan penerapan produksi dari Modul 5

## Sumber Daya Penting

Sumber daya yang dipilih dengan cermat ini memberikan nilai terbaik untuk waktu belajar Anda yang terbatas:

### Dokumentasi Wajib Dibaca
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Alat optimasi model yang paling efisien
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cara tercepat untuk menerapkan SLM secara lokal
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referensi untuk model yang dioptimalkan untuk edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit optimasi komprehensif dari Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Lingkungan pengembangan EdgeAI terintegrasi
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platform pengembangan EdgeAI khusus Windows

### Alat Hemat Waktu
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Akses dan penerapan model dengan cepat
- [Gradio](https://www.gradio.app/docs/interface) - Pengembangan UI cepat untuk demo AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimasi model yang disederhanakan
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferensi CPU yang efisien
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Kerangka kerja kompresi jaringan saraf
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit penerapan model bahasa besar

## Template Pelacakan Kemajuan

Gunakan template sederhana ini untuk melacak kemajuan belajar Anda melalui kursus 20 jam:

| Modul | Tanggal Penyelesaian | Waktu yang Dihabiskan | Poin Penting |
|--------|----------------|-------------|---------------|
| Modul 1: Dasar EdgeAI | | | |
| Modul 2: Dasar SLM | | | |
| Modul 3: Penerapan SLM | | | |
| Modul 4: Optimasi Model | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Agen AI | | | |
| Modul 7: Alat Pengembangan | | | |
| Modul 8: Toolkit Foundry Local | | | |
| Latihan Praktis | | | |
| Proyek Mini | | | |

## Ide Proyek Mini

Pertimbangkan untuk menyelesaikan salah satu proyek ini untuk mempraktikkan konsep EdgeAI (masing-masing dirancang untuk memakan waktu 2-4 jam):

### Proyek Pemula (2-3 jam masing-masing)
1. **Asisten Teks Edge**: Buat alat penyelesaian teks offline sederhana menggunakan model bahasa kecil
2. **Dashboard Perbandingan Model**: Bangun visualisasi dasar metrik kinerja di berbagai SLM
3. **Eksperimen Optimasi**: Ukur dampak berbagai tingkat kuantisasi pada model dasar yang sama

### Proyek Menengah (3-4 jam masing-masing)
4. **Alur Kerja AI Toolkit**: Gunakan AI Toolkit VS Code untuk mengoptimalkan dan menerapkan model dari awal hingga akhir
5. **Aplikasi Windows AI Foundry**: Buat aplikasi Windows menggunakan API Phi Silica dan optimasi NPU
6. **Penerapan Lintas Platform**: Terapkan model yang sama yang dioptimalkan di Windows (OpenVINO) dan seluler (.NET MAUI)
7. **Agen Pemanggilan Fungsi**: Bangun agen AI dengan kemampuan pemanggilan fungsi untuk skenario edge

### Proyek Integrasi Lanjutan (4-5 jam masing-masing)
8. **OpenVINO Optimization Pipeline**: Implementasikan optimasi model lengkap menggunakan NNCF dan GenAI toolkit  
9. **SLMOps Pipeline**: Implementasikan siklus hidup model lengkap dari pelatihan hingga penerapan di perangkat edge  
10. **Multi-Model Edge System**: Terapkan beberapa model khusus yang bekerja bersama pada perangkat keras edge  
11. **MCP Integration System**: Bangun sistem agen menggunakan Model Context Protocol untuk interaksi alat  

## Referensi  

- Microsoft Learn (Foundry Local)  
  - Ikhtisar: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Memulai: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Referensi CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrasi dengan inference SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Cara menggunakan Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Kompilasi model Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Ikhtisar: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agen (ikhtisar): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Tooling Optimasi dan Inferensi  
  - Microsoft Olive (dokumen): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (memulai): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Integrasi ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (dokumen): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (dokumen): https://ml-explore.github.io/mlx/build/html/index.html  
- Framework dan Model Penerapan  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (dokumen): https://docs.vllm.ai/  
  - Ollama (memulai cepat): https://github.com/ollama/ollama#get-started  
- Alat Pengembang (Windows dan VS Code)  
  - AI Toolkit untuk VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (ikhtisar): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Komunitas Pembelajaran  

Bergabunglah dalam diskusi dan terhubung dengan sesama pembelajar:  
- Diskusi GitHub di [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Kesimpulan  

EdgeAI merupakan garis depan implementasi kecerdasan buatan, membawa kemampuan yang kuat langsung ke perangkat sambil mengatasi masalah penting seperti privasi, latensi, dan konektivitas. Kursus 20 jam ini memberikan Anda pengetahuan dasar dan keterampilan praktis untuk mulai bekerja dengan teknologi EdgeAI segera.  

Kursus ini sengaja dirancang ringkas dan fokus pada konsep-konsep paling penting, memungkinkan Anda dengan cepat mendapatkan keahlian yang berharga tanpa komitmen waktu yang berlebihan. Ingatlah bahwa praktik langsung, bahkan dengan contoh sederhana, adalah kunci untuk memperkuat apa yang telah Anda pelajari.  

Selamat belajar!  

---

