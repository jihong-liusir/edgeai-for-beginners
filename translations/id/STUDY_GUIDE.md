<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T09:19:44+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "id"
}
-->
# EdgeAI untuk Pemula: Jalur Pembelajaran dan Jadwal Studi

### Jalur Pembelajaran Intensif (1 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 0 | Modul 0: Pengantar EdgeAI | 1-2 jam |
| Hari 1 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 2 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 3 | Modul 3: Penerapan SLM | 2 jam |
| Hari 4-5 | Modul 4: Optimasi Model (6 kerangka kerja) | 4 jam |
| Hari 6 | Modul 5: SLMOps | 3 jam |
| Hari 7 | Modul 6-7: Agen AI & Alat Pengembangan | 4 jam |
| Hari 8 | Modul 8: Foundry Local Toolkit (Implementasi Modern) | 1 jam |

### Jalur Pembelajaran Intensif (2 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 5-6 | Modul 3: Penerapan SLM | 2 jam |
| Hari 7-8 | Modul 4: Optimasi Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Agen AI | 2 jam |
| Hari 13-14 | Modul 7: Alat Pengembangan | 3 jam |

### Studi Paruh Waktu (4 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 1-2: Dasar-dasar & Fondasi SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penerapan & Optimasi | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Agen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pengembangan & Integrasi | 3 jam |

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 0 | Modul 0: Pengantar EdgeAI | 1-2 jam |
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Fondasi SLM | 3 jam |
| Hari 5-6 | Modul 3: Penerapan SLM | 2 jam |
| Hari 7-8 | Modul 4: Optimasi Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Sistem Agen SLM | 2 jam |
| Hari 13-14 | Modul 7: Contoh Implementasi EdgeAI | 2 jam |

| Modul | Tanggal Selesai | Jam yang Dihabiskan | Poin Penting |
|--------|----------------|-------------|--------------|
| Modul 0: Pengantar EdgeAI | | | |
| Modul 1: Dasar-dasar EdgeAI | | | |
| Modul 2: Fondasi SLM | | | |
| Modul 3: Penerapan SLM | | | |
| Modul 4: Optimasi Model (6 kerangka kerja) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Sistem Agen SLM | | | |
| Modul 7: Contoh Implementasi EdgeAI | | | |
| Latihan Praktis | | | |
| Mini-Proyek | | | |

### Studi Paruh Waktu (4 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 1-2: Dasar-dasar & Fondasi SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penerapan & Optimasi | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Agen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pengembangan & Integrasi | 3 jam |

## Pengantar

Selamat datang di panduan belajar EdgeAI untuk Pemula! Dokumen ini dirancang untuk membantu Anda menavigasi materi kursus secara efektif dan memaksimalkan pengalaman belajar Anda. Panduan ini menyediakan jalur pembelajaran yang terstruktur, jadwal studi yang disarankan, ringkasan konsep utama, dan sumber daya tambahan untuk memperdalam pemahaman Anda tentang teknologi Edge AI.

Ini adalah kursus singkat selama 20 jam yang memberikan pengetahuan penting tentang EdgeAI dalam format yang efisien waktu, sehingga cocok untuk para profesional dan pelajar yang sibuk yang ingin dengan cepat memperoleh keterampilan praktis di bidang yang sedang berkembang ini.

## Ikhtisar Kursus

Kursus ini terdiri dari delapan modul komprehensif:

0. **Pengantar EdgeAI** - Dasar dan konteks dengan aplikasi industri serta tujuan pembelajaran
1. **Dasar-dasar dan Transformasi EdgeAI** - Memahami konsep inti dan pergeseran teknologi
2. **Fondasi Model Bahasa Kecil (SLM)** - Menjelajahi berbagai keluarga SLM dan arsitekturnya
3. **Penerapan Model Bahasa Kecil** - Menerapkan strategi penerapan praktis
4. **Konversi Format Model dan Kuantisasi** - Optimasi lanjutan dengan 6 kerangka kerja termasuk OpenVINO
5. **SLMOps - Operasi Model Bahasa Kecil** - Manajemen siklus produksi dan penerapan
6. **Sistem Agen SLM** - Agen AI, pemanggilan fungsi, dan Protokol Konteks Model
7. **Contoh Implementasi EdgeAI** - Toolkit AI, pengembangan Windows, dan implementasi spesifik platform
8. **Microsoft Foundry Local â€“ Toolkit Pengembang Lengkap** - Pengembangan lokal dengan integrasi hybrid Azure (Modul 08)

## Cara Menggunakan Panduan Studi Ini

- **Pembelajaran Bertahap**: Ikuti modul secara berurutan untuk pengalaman belajar yang paling koheren
- **Pemeriksaan Pengetahuan**: Gunakan pertanyaan penilaian diri setelah setiap bagian
- **Latihan Praktis**: Selesaikan latihan yang disarankan untuk memperkuat konsep teoritis
- **Sumber Daya Tambahan**: Jelajahi materi tambahan untuk topik yang paling menarik bagi Anda

## Rekomendasi Jadwal Studi

### Jalur Pembelajaran Intensif (1 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 0 | Modul 0: Pengantar EdgeAI | 1-2 jam |
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 6 jam |
| Hari 3-4 | Modul 2: Fondasi SLM | 8 jam |
| Hari 5 | Modul 3: Penerapan SLM | 3 jam |
| Hari 6 | Modul 8: Foundry Local Toolkit | 3 jam |

### Studi Paruh Waktu (3 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 0: Pengantar + Modul 1: Dasar-dasar EdgeAI | 7-9 jam |
| Minggu 2 | Modul 2: Fondasi SLM | 7-8 jam |
| Minggu 3 | Modul 3: Penerapan SLM (3 jam) + Modul 8: Foundry Local Toolkit (2-3 jam) | 5-6 jam |

## Modul 0: Pengantar EdgeAI

### Tujuan Pembelajaran Utama

- Memahami apa itu Edge AI dan mengapa penting dalam lanskap teknologi saat ini
- Mengidentifikasi industri utama yang diubah oleh Edge AI dan kasus penggunaannya
- Memahami keuntungan Model Bahasa Kecil (SLM) untuk penerapan di edge
- Menetapkan harapan dan hasil pembelajaran yang jelas untuk seluruh kursus
- Mengenali peluang karir dan persyaratan keterampilan di bidang Edge AI

### Area Fokus Studi

#### Bagian 1: Paradigma dan Definisi Edge AI
- **Konsep Prioritas**: 
  - Edge AI vs. pemrosesan AI berbasis cloud tradisional
  - Konvergensi perangkat keras, optimasi model, dan kebutuhan bisnis
  - Penerapan AI yang real-time, menjaga privasi, dan hemat biaya

#### Bagian 2: Aplikasi Industri
- **Konsep Prioritas**: 
  - Manufaktur & Industri 4.0: Pemeliharaan prediktif dan kontrol kualitas
  - Kesehatan: Pencitraan diagnostik dan pemantauan pasien
  - Sistem Otonom: Kendaraan tanpa pengemudi dan transportasi
  - Kota Pintar: Manajemen lalu lintas dan keselamatan publik
  - Teknologi Konsumen: Smartphone, perangkat wearable, dan rumah pintar

#### Bagian 3: Fondasi Model Bahasa Kecil
- **Konsep Prioritas**: 
  - Karakteristik SLM dan perbandingan kinerja
  - Efisiensi parameter vs. trade-off kemampuan
  - Kendala penerapan di edge dan strategi optimasi

#### Bagian 4: Kerangka Pembelajaran dan Jalur Karir
- **Konsep Prioritas**: 
  - Arsitektur kursus dan pendekatan penguasaan bertahap
  - Keterampilan teknis dan tujuan implementasi praktis
  - Peluang karir dan aplikasi industri

### Pertanyaan Penilaian Diri

1. Apa tiga tren teknologi utama yang memungkinkan Edge AI?
2. Bandingkan keuntungan dan tantangan Edge AI vs. AI berbasis cloud.
3. Sebutkan tiga industri di mana Edge AI memberikan nilai bisnis yang penting dan jelaskan alasannya.
4. Bagaimana Model Bahasa Kecil membuat Edge AI praktis untuk penerapan dunia nyata?
5. Apa keterampilan teknis utama yang akan Anda kembangkan sepanjang kursus ini?
6. Jelaskan pendekatan pembelajaran empat fase yang digunakan dalam kursus ini.

### Latihan Praktis

1. **Penelitian Industri**: Pilih satu aplikasi industri dan teliti implementasi Edge AI di dunia nyata (30 menit)
2. **Eksplorasi Model**: Jelajahi Model Bahasa Kecil yang tersedia di Hugging Face dan bandingkan jumlah parameter serta kemampuannya (30 menit)
3. **Perencanaan Pembelajaran**: Tinjau struktur kursus lengkap dan buat jadwal studi pribadi Anda (15 menit)

### Materi Tambahan

- [Ikhtisar Pasar Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [Ikhtisar Model Bahasa Kecil - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Fondasi Komputasi Edge](https://www.edgecomputing.org/)

## Modul 1: Dasar-dasar dan Transformasi EdgeAI

### Tujuan Pembelajaran Utama

- Memahami perbedaan antara AI berbasis cloud dan AI berbasis edge
- Menguasai teknik optimasi inti untuk lingkungan dengan sumber daya terbatas
- Menganalisis aplikasi dunia nyata dari teknologi EdgeAI
- Menyiapkan lingkungan pengembangan untuk proyek EdgeAI

### Area Fokus Studi

#### Bagian 1: Dasar-dasar EdgeAI
- **Konsep Prioritas**: 
  - Paradigma komputasi Edge vs. Cloud
  - Teknik kuantisasi model
  - Opsi akselerasi perangkat keras (NPU, GPU, CPU)
  - Keuntungan privasi dan keamanan

- **Materi Tambahan**:
  - [Dokumentasi TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Dokumentasi Edge Impulse](https://docs.edgeimpulse.com)

#### Bagian 2: Studi Kasus Dunia Nyata
- **Konsep Prioritas**: 
  - Ekosistem model Microsoft Phi & Mu
  - Implementasi praktis di berbagai industri
  - Pertimbangan penerapan

#### Bagian 3: Panduan Implementasi Praktis
- **Konsep Prioritas**: 
  - Pengaturan lingkungan pengembangan
  - Alat kuantisasi dan optimasi
  - Metode penilaian untuk implementasi EdgeAI

#### Bagian 4: Perangkat Keras Penerapan Edge
- **Konsep Prioritas**: 
  - Perbandingan platform perangkat keras
  - Strategi optimasi untuk perangkat keras tertentu
  - Pertimbangan penerapan

### Pertanyaan Penilaian Diri

1. Bandingkan dan kontraskan AI berbasis cloud dengan implementasi AI berbasis edge.
2. Jelaskan tiga teknik utama untuk mengoptimalkan model untuk penerapan di edge.
3. Apa keuntungan utama menjalankan model AI di edge?
4. Jelaskan proses kuantisasi model dan bagaimana hal itu memengaruhi kinerja.
5. Jelaskan bagaimana akselerator perangkat keras yang berbeda (NPU, GPU, CPU) memengaruhi penerapan EdgeAI.

### Latihan Praktis

1. **Pengaturan Lingkungan Cepat**: Konfigurasikan lingkungan pengembangan minimal dengan paket-paket penting (30 menit)
2. **Eksplorasi Model**: Unduh dan periksa model bahasa kecil yang sudah dilatih (1 jam)
3. **Kuantisasi Dasar**: Coba kuantisasi sederhana pada model kecil (1 jam)

## Modul 2: Fondasi Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memahami prinsip arsitektur dari berbagai keluarga SLM
- Membandingkan kemampuan model di berbagai skala parameter
- Mengevaluasi model berdasarkan efisiensi, kemampuan, dan kebutuhan penerapan
- Mengenali kasus penggunaan yang sesuai untuk berbagai keluarga model

### Area Fokus Studi

#### Bagian 1: Keluarga Model Microsoft Phi
- **Konsep Prioritas**: 
  - Evolusi filosofi desain
  - Arsitektur yang mengutamakan efisiensi
  - Kemampuan khusus

#### Bagian 2: Keluarga Qwen
- **Konsep Prioritas**: 
  - Kontribusi sumber terbuka
  - Opsi penerapan yang dapat diskalakan
  - Arsitektur penalaran lanjutan

#### Bagian 3: Keluarga Gemma
- **Konsep Prioritas**: 
  - Inovasi berbasis penelitian
  - Kemampuan multimodal
  - Optimasi untuk perangkat seluler

#### Bagian 4: Keluarga BitNET
- **Konsep Prioritas**: 
  - Teknologi kuantisasi 1-bit
  - Kerangka kerja optimasi inferensi
  - Pertimbangan keberlanjutan

#### Bagian 5: Model Microsoft Mu
- **Konsep Prioritas**: 
  - Arsitektur yang mengutamakan perangkat
  - Integrasi sistem dengan Windows
  - Operasi yang menjaga privasi

#### Bagian 6: Phi-Silica
- **Konsep Prioritas**: 
  - Arsitektur yang dioptimalkan untuk NPU
  - Metrik kinerja
  - Integrasi pengembang

### Pertanyaan Penilaian Diri

1. Bandingkan pendekatan arsitektur keluarga model Phi dan Qwen.
2. Jelaskan bagaimana teknologi kuantisasi BitNET berbeda dari kuantisasi tradisional.
3. Apa keunggulan unik model Mu untuk integrasi Windows?  
4. Jelaskan bagaimana Phi-Silica memanfaatkan perangkat keras NPU untuk optimasi kinerja.  
5. Untuk aplikasi mobile dengan konektivitas terbatas, keluarga model mana yang paling sesuai dan mengapa?  

### Latihan Praktis  

1. **Perbandingan Model**: Benchmark cepat dua model SLM yang berbeda (1 jam)  
2. **Generasi Teks Sederhana**: Implementasi dasar generasi teks dengan model kecil (1 jam)  
3. **Optimasi Cepat**: Terapkan satu teknik optimasi untuk meningkatkan kecepatan inferensi (1 jam)  

## Modul 3: Deployment Model Bahasa Kecil  

### Tujuan Pembelajaran Utama  

- Memilih model yang sesuai berdasarkan kendala deployment  
- Menguasai teknik optimasi untuk berbagai skenario deployment  
- Mengimplementasikan SLM di lingkungan lokal dan cloud  
- Merancang konfigurasi siap produksi untuk aplikasi EdgeAI  

### Fokus Studi  

#### Bagian 1: Pembelajaran Lanjutan SLM  
- **Konsep Prioritas**:  
  - Kerangka klasifikasi parameter  
  - Teknik optimasi lanjutan  
  - Strategi akuisisi model  

#### Bagian 2: Deployment Lingkungan Lokal  
- **Konsep Prioritas**:  
  - Deployment platform Ollama  
  - Solusi lokal Microsoft Foundry  
  - Analisis perbandingan framework  

#### Bagian 3: Deployment Cloud yang Terkontainerisasi  
- **Konsep Prioritas**:  
  - Inferensi kinerja tinggi vLLM  
  - Orkestrasi kontainer  
  - Implementasi ONNX Runtime  

### Pertanyaan Penilaian Diri  

1. Faktor apa saja yang harus dipertimbangkan saat memilih antara deployment lokal dan cloud?  
2. Bandingkan Ollama dan Microsoft Foundry Local sebagai opsi deployment.  
3. Jelaskan manfaat kontainerisasi untuk deployment SLM.  
4. Apa saja metrik kinerja utama yang harus dipantau untuk SLM yang dideploy di edge?  
5. Deskripsikan alur kerja deployment lengkap dari pemilihan model hingga implementasi produksi.  

### Latihan Praktis  

1. **Deployment Lokal Dasar**: Deploy SLM sederhana menggunakan Ollama (1 jam)  
2. **Pemeriksaan Kinerja**: Jalankan benchmark cepat pada model yang telah dideploy (30 menit)  
3. **Integrasi Sederhana**: Buat aplikasi minimal yang menggunakan model yang telah dideploy (1 jam)  

## Modul 4: Konversi Format Model dan Kuantisasi  

### Tujuan Pembelajaran Utama  

- Menguasai teknik kuantisasi lanjutan dari presisi 1-bit hingga 8-bit  
- Memahami strategi konversi format (GGUF, ONNX)  
- Mengimplementasikan optimasi di enam framework (Llama.cpp, Olive, OpenVINO, MLX, sintesis alur kerja)  
- Deploy model yang telah dioptimasi untuk lingkungan edge produksi di Intel, Apple, dan perangkat keras lintas platform  

### Fokus Studi  

#### Bagian 1: Dasar-Dasar Kuantisasi  
- **Konsep Prioritas**:  
  - Kerangka klasifikasi presisi  
  - Perbandingan kinerja vs akurasi  
  - Optimasi jejak memori  

#### Bagian 2: Implementasi Llama.cpp  
- **Konsep Prioritas**:  
  - Deployment lintas platform  
  - Optimasi format GGUF  
  - Teknik akselerasi perangkat keras  

#### Bagian 3: Microsoft Olive Suite  
- **Konsep Prioritas**:  
  - Optimasi berbasis perangkat keras  
  - Deployment kelas enterprise  
  - Alur kerja optimasi otomatis  

#### Bagian 4: Toolkit OpenVINO  
- **Konsep Prioritas**:  
  - Optimasi perangkat keras Intel  
  - Kerangka Kompresi Jaringan Neural (NNCF)  
  - Deployment inferensi lintas platform  
  - OpenVINO GenAI untuk deployment LLM  

#### Bagian 5: Framework Apple MLX  
- **Konsep Prioritas**:  
  - Optimasi Apple Silicon  
  - Arsitektur memori terpadu  
  - Kemampuan fine-tuning LoRA  

#### Bagian 6: Sintesis Alur Kerja Pengembangan Edge AI  
- **Konsep Prioritas**:  
  - Arsitektur alur kerja terpadu  
  - Pohon keputusan pemilihan framework  
  - Validasi kesiapan produksi  
  - Strategi untuk masa depan  

### Pertanyaan Penilaian Diri  

1. Bandingkan strategi kuantisasi di berbagai tingkat presisi (1-bit hingga 8-bit).  
2. Jelaskan keunggulan format GGUF untuk deployment di edge.  
3. Bagaimana optimasi berbasis perangkat keras di Microsoft Olive meningkatkan efisiensi deployment?  
4. Apa manfaat utama NNCF OpenVINO untuk kompresi model?  
5. Deskripsikan bagaimana Apple MLX memanfaatkan arsitektur memori terpadu untuk optimasi.  
6. Bagaimana sintesis alur kerja membantu dalam memilih framework optimasi yang optimal?  

### Latihan Praktis  

1. **Kuantisasi Model**: Terapkan berbagai tingkat kuantisasi pada model dan bandingkan hasilnya (1 jam)  
2. **Optimasi OpenVINO**: Gunakan NNCF untuk mengompresi model untuk perangkat keras Intel (1 jam)  
3. **Perbandingan Framework**: Uji model yang sama di tiga framework optimasi yang berbeda (1 jam)  
4. **Benchmark Kinerja**: Ukur dampak optimasi pada kecepatan inferensi dan penggunaan memori (1 jam)  

## Modul 5: SLMOps - Operasi Model Bahasa Kecil  

### Tujuan Pembelajaran Utama  

- Memahami prinsip manajemen siklus hidup SLMOps  
- Menguasai teknik distilasi dan fine-tuning untuk deployment di edge  
- Mengimplementasikan strategi deployment produksi dengan pemantauan  
- Membangun alur kerja operasi dan pemeliharaan SLM kelas enterprise  

### Fokus Studi  

#### Bagian 1: Pengantar SLMOps  
- **Konsep Prioritas**:  
  - Pergeseran paradigma SLMOps dalam operasi AI  
  - Arsitektur hemat biaya dan berorientasi privasi  
  - Dampak strategis bisnis dan keunggulan kompetitif  

#### Bagian 2: Distilasi Model  
- **Konsep Prioritas**:  
  - Teknik transfer pengetahuan  
  - Implementasi proses distilasi dua tahap  
  - Alur kerja distilasi Azure ML  

#### Bagian 3: Strategi Fine-Tuning  
- **Konsep Prioritas**:  
  - Fine-tuning yang efisien parameter (PEFT)  
  - Metode LoRA dan QLoRA lanjutan  
  - Pelatihan multi-adapter dan optimasi hyperparameter  

#### Bagian 4: Deployment Produksi  
- **Konsep Prioritas**:  
  - Konversi model dan kuantisasi untuk produksi  
  - Konfigurasi deployment Foundry Local  
  - Benchmarking kinerja dan validasi kualitas  

### Pertanyaan Penilaian Diri  

1. Bagaimana SLMOps berbeda dari MLOps tradisional?  
2. Jelaskan manfaat distilasi model untuk deployment di edge.  
3. Apa saja pertimbangan utama untuk fine-tuning SLM di lingkungan dengan sumber daya terbatas?  
4. Deskripsikan pipeline deployment produksi lengkap untuk aplikasi AI di edge.  

### Latihan Praktis  

1. **Distilasi Dasar**: Buat model yang lebih kecil dari model guru yang lebih besar (1 jam)  
2. **Eksperimen Fine-Tuning**: Fine-tuning model untuk domain tertentu (1 jam)  
3. **Pipeline Deployment**: Siapkan pipeline CI/CD dasar untuk deployment model (1 jam)  

## Modul 6: Sistem Agenik SLM - Agen AI dan Pemanggilan Fungsi  

### Tujuan Pembelajaran Utama  

- Membangun agen AI cerdas untuk lingkungan edge menggunakan Model Bahasa Kecil  
- Mengimplementasikan kemampuan pemanggilan fungsi dengan alur kerja sistematis  
- Menguasai integrasi Model Context Protocol (MCP) untuk interaksi alat yang terstandarisasi  
- Membuat sistem agenik yang canggih dengan intervensi manusia minimal  

### Fokus Studi  

#### Bagian 1: Agen AI dan Dasar-Dasar SLM  
- **Konsep Prioritas**:  
  - Kerangka klasifikasi agen (refleks, berbasis model, berbasis tujuan, agen pembelajaran)  
  - Analisis trade-off SLM vs LLM  
  - Pola desain agen khusus untuk edge  
  - Optimasi sumber daya untuk agen  

#### Bagian 2: Pemanggilan Fungsi dalam Model Bahasa Kecil  
- **Konsep Prioritas**:  
  - Implementasi alur kerja sistematis (deteksi intent, output JSON, eksekusi eksternal)  
  - Implementasi spesifik platform (Phi-4-mini, model Qwen terpilih, Microsoft Foundry Local)  
  - Contoh lanjutan (kolaborasi multi-agen, pemilihan alat dinamis)  
  - Pertimbangan produksi (pembatasan tingkat, pencatatan audit, langkah keamanan)  

#### Bagian 3: Integrasi Model Context Protocol (MCP)  
- **Konsep Prioritas**:  
  - Arsitektur protokol dan desain sistem berlapis  
  - Dukungan multi-backend (Ollama untuk pengembangan, vLLM untuk produksi)  
  - Protokol koneksi (mode STDIO dan SSE)  
  - Aplikasi dunia nyata (otomasi web, pemrosesan data, integrasi API)  

### Pertanyaan Penilaian Diri  

1. Apa saja pertimbangan arsitektur utama untuk agen AI di edge?  
2. Bagaimana pemanggilan fungsi meningkatkan kemampuan agen?  
3. Jelaskan peran Model Context Protocol dalam komunikasi agen.  

### Latihan Praktis  

1. **Agen Sederhana**: Bangun agen AI dasar dengan pemanggilan fungsi (1 jam)  
2. **Integrasi MCP**: Implementasikan MCP dalam aplikasi agen (30 menit)  

## Modul 7: Contoh Implementasi EdgeAI  

### Tujuan Pembelajaran Utama  

- Menguasai AI Toolkit untuk Visual Studio Code untuk alur kerja pengembangan EdgeAI yang komprehensif  
- Mendapatkan keahlian dalam platform Windows AI Foundry dan strategi optimasi NPU  
- Mengimplementasikan EdgeAI di berbagai platform perangkat keras dan skenario deployment  
- Membangun aplikasi EdgeAI siap produksi dengan optimasi spesifik platform  

### Fokus Studi  

#### Bagian 1: AI Toolkit untuk Visual Studio Code  
- **Konsep Prioritas**:  
  - Lingkungan pengembangan Edge AI yang komprehensif dalam VS Code  
  - Katalog model dan penemuan untuk deployment di edge  
  - Pengujian lokal, optimasi, dan alur kerja pengembangan agen  
  - Pemantauan kinerja dan evaluasi untuk skenario edge  

#### Bagian 2: Panduan Pengembangan Windows EdgeAI  
- **Konsep Prioritas**:  
  - Ikhtisar komprehensif platform Windows AI Foundry  
  - API Phi Silica untuk inferensi NPU yang efisien  
  - API Computer Vision untuk pemrosesan gambar dan OCR  
  - CLI Foundry Local untuk pengembangan dan pengujian lokal  

#### Bagian 3: Implementasi Spesifik Platform  
- **Konsep Prioritas**:  
  - Deployment NVIDIA Jetson Orin Nano (kinerja AI 67 TOPS)  
  - Aplikasi mobile dengan .NET MAUI dan ONNX Runtime GenAI  
  - Solusi Azure EdgeAI dengan arsitektur hybrid cloud-edge  
  - Optimasi Windows ML dengan dukungan perangkat keras universal  
  - Aplikasi Foundry Local dengan implementasi RAG berorientasi privasi  

### Pertanyaan Penilaian Diri  

1. Bagaimana AI Toolkit menyederhanakan alur kerja pengembangan EdgeAI?  
2. Bandingkan strategi deployment di berbagai platform perangkat keras.  
3. Apa keunggulan Windows AI Foundry untuk pengembangan di edge?  
4. Jelaskan peran optimasi NPU dalam aplikasi AI edge modern.  
5. Bagaimana API Phi Silica memanfaatkan perangkat keras NPU untuk optimasi kinerja?  
6. Bandingkan manfaat deployment lokal vs cloud untuk aplikasi yang sensitif terhadap privasi.  

### Latihan Praktis  

1. **Pengaturan AI Toolkit**: Konfigurasikan AI Toolkit dan optimasi model (1 jam)  
2. **Windows AI Foundry**: Bangun aplikasi AI Windows sederhana menggunakan API Phi Silica (1 jam)  
3. **Deployment Lintas Platform**: Deploy model yang sama di dua platform berbeda (1 jam)  
4. **Optimasi NPU**: Uji kinerja NPU dengan alat Windows AI Foundry (30 menit)  

## Modul 8: Microsoft Foundry Local â€“ Toolkit Pengembang Lengkap (Modernisasi)  

### Tujuan Pembelajaran Utama  

- Instalasi dan konfigurasi Foundry Local dengan integrasi SDK modern  
- Mengimplementasikan sistem multi-agen lanjutan dengan pola koordinator  
- Membangun router model cerdas dengan pemilihan tugas otomatis  
- Deploy solusi AI siap produksi dengan pemantauan komprehensif  
- Integrasi dengan Azure AI Foundry untuk skenario deployment hybrid  
- Menguasai pola SDK modern dengan FoundryLocalManager dan klien OpenAI  

### Fokus Studi  

#### Bagian 1: Instalasi dan Konfigurasi Modern  
- **Konsep Prioritas**:  
  - Integrasi SDK FoundryLocalManager  
  - Penemuan layanan otomatis dan pemantauan kesehatan  
  - Pola konfigurasi berbasis lingkungan  
  - Pertimbangan deployment produksi  

#### Bagian 2: Sistem Multi-Agen Lanjutan  
- **Konsep Prioritas**:  
  - Pola koordinator dengan agen spesialis  
  - Spesialisasi agen untuk pengambilan, penalaran, dan eksekusi  
  - Mekanisme umpan balik untuk penyempurnaan  
  - Pemantauan kinerja dan pelacakan statistik  

#### Bagian 3: Routing Model Cerdas  
- **Konsep Prioritas**:  
  - Algoritma pemilihan model berbasis kata kunci  
  - Dukungan multi-model (umum, penalaran, kode, kreatif)  
  - Konfigurasi variabel lingkungan untuk fleksibilitas  
  - Pemeriksaan kesehatan layanan dan penanganan kesalahan  

#### Bagian 4: Implementasi Siap Produksi  
- **Konsep Prioritas**:  
  - Penanganan kesalahan dan mekanisme fallback yang komprehensif  
  - Pemantauan permintaan dan pelacakan kinerja  
  - Contoh notebook Jupyter interaktif dengan benchmark  
  - Pola integrasi dengan aplikasi yang sudah ada  

### Pertanyaan Penilaian Diri  

1. Bagaimana pendekatan FoundryLocalManager modern berbeda dari panggilan REST manual?  
2. Jelaskan pola koordinator dan bagaimana ia mengatur agen spesialis.  
3. Bagaimana router cerdas memilih model yang sesuai berdasarkan konten kueri?  
4. Apa saja komponen utama sistem agen AI siap produksi?  
5. Bagaimana cara mengimplementasikan pemantauan kesehatan yang komprehensif untuk layanan Foundry Local?  
6. Bandingkan manfaat pendekatan yang dimodernisasi vs pola implementasi tradisional.  

### Latihan Praktis  

1. **Pengaturan SDK Modern**: Konfigurasikan FoundryLocalManager dengan penemuan layanan otomatis (30 menit)  
2. **Sistem Multi-Agen**: Jalankan koordinator lanjutan dengan agen spesialis (30 menit)  
3. **Routing Cerdas**: Uji router model dengan berbagai jenis kueri (30 menit)  
4. **Eksplorasi Interaktif**: Gunakan notebook Jupyter untuk mengeksplorasi fitur lanjutan (45 menit)  
5. **Deployment Produksi**: Implementasikan pola pemantauan dan penanganan kesalahan (30 menit)  
6. **Integrasi Hybrid**: Konfigurasikan skenario fallback Azure AI Foundry (30 menit)  

## Panduan Alokasi Waktu  

Untuk membantu Anda memanfaatkan waktu kursus 20 jam secara maksimal, berikut adalah pembagian waktu yang disarankan:  

| Aktivitas | Alokasi Waktu | Deskripsi |  
|----------|----------------|-------------|  
| Membaca Materi Inti | 9 jam | Fokus pada konsep penting di setiap modul |  
| Latihan Praktis | 6 jam | Implementasi teknik-teknik utama secara langsung |
| Penilaian Mandiri | 2 jam | Menguji pemahaman melalui pertanyaan dan refleksi |
| Proyek Mini | 3 jam | Menerapkan pengetahuan ke implementasi praktis kecil |

### Fokus Utama Berdasarkan Waktu yang Tersedia

**Jika Anda hanya memiliki 10 jam:**
- Selesaikan Modul 0 (Pengantar) dan Modul 1, 2, serta 3 (konsep inti EdgeAI)
- Lakukan setidaknya satu latihan praktis per modul
- Fokus pada pemahaman konsep inti daripada detail implementasi

**Jika Anda dapat mengalokasikan waktu penuh 20 jam:**
- Selesaikan semua delapan modul (termasuk Pengantar)
- Lakukan latihan praktis utama dari setiap modul
- Selesaikan satu proyek mini dari Modul 7
- Jelajahi setidaknya 2-3 sumber tambahan

**Jika Anda memiliki lebih dari 20 jam:**
- Selesaikan semua modul (termasuk Pengantar) dengan latihan mendetail
- Bangun beberapa proyek mini
- Jelajahi teknik optimasi lanjutan di Modul 4
- Implementasikan penerapan produksi dari Modul 5

## Sumber Daya Penting

Sumber daya yang dipilih dengan cermat ini memberikan nilai maksimal untuk waktu belajar Anda yang terbatas:

### Dokumentasi Wajib Dibaca
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Alat optimasi model yang paling efisien
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cara tercepat untuk menerapkan SLM secara lokal
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referensi untuk model yang dioptimalkan untuk edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit optimasi komprehensif dari Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Lingkungan pengembangan EdgeAI terintegrasi
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platform pengembangan EdgeAI khusus Windows

### Alat Penghemat Waktu
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Akses dan penerapan model dengan cepat
- [Gradio](https://www.gradio.app/docs/interface) - Pengembangan UI cepat untuk demo AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimasi model yang disederhanakan
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferensi CPU yang efisien
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Kerangka kompresi jaringan neural
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit penerapan model bahasa besar

## Template Pelacakan Kemajuan

Gunakan template sederhana ini untuk melacak kemajuan belajar Anda melalui kursus 20 jam:

| Modul | Tanggal Selesai | Waktu yang Dihabiskan | Poin Penting |
|-------|-----------------|-----------------------|--------------|
| Modul 0: Pengantar EdgeAI | | | |
| Modul 1: Dasar-dasar EdgeAI | | | |
| Modul 2: Dasar-dasar SLM | | | |
| Modul 3: Penerapan SLM | | | |
| Modul 4: Optimasi Model | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Agen AI | | | |
| Modul 7: Alat Pengembangan | | | |
| Modul 8: Toolkit Lokal Foundry | | | |
| Latihan Praktis | | | |
| Proyek Mini | | | |

## Ide Proyek Mini

Pertimbangkan untuk menyelesaikan salah satu proyek ini untuk mempraktikkan konsep EdgeAI (masing-masing dirancang untuk memakan waktu 2-4 jam):

### Proyek Pemula (2-3 jam masing-masing)
1. **Asisten Teks Edge**: Buat alat penyelesaian teks offline sederhana menggunakan model bahasa kecil
2. **Dasbor Perbandingan Model**: Bangun visualisasi dasar metrik kinerja dari berbagai SLM
3. **Eksperimen Optimasi**: Ukur dampak berbagai tingkat kuantisasi pada model dasar yang sama

### Proyek Menengah (3-4 jam masing-masing)
4. **Alur Kerja AI Toolkit**: Gunakan AI Toolkit di VS Code untuk mengoptimalkan dan menerapkan model dari awal hingga selesai
5. **Aplikasi Windows AI Foundry**: Buat aplikasi Windows menggunakan API Phi Silica dan optimasi NPU
6. **Penerapan Lintas Platform**: Terapkan model yang sama yang telah dioptimalkan di Windows (OpenVINO) dan perangkat seluler (.NET MAUI)
7. **Agen Pemanggilan Fungsi**: Bangun agen AI dengan kemampuan pemanggilan fungsi untuk skenario edge

### Proyek Integrasi Lanjutan (4-5 jam masing-masing)
8. **Pipeline Optimasi OpenVINO**: Implementasikan optimasi model lengkap menggunakan NNCF dan toolkit GenAI
9. **Pipeline SLMOps**: Implementasikan siklus hidup model lengkap dari pelatihan hingga penerapan di edge
10. **Sistem Edge Multi-Model**: Terapkan beberapa model khusus yang bekerja bersama di perangkat keras edge
11. **Sistem Integrasi MCP**: Bangun sistem agen menggunakan Model Context Protocol untuk interaksi alat

## Referensi

- Microsoft Learn (Foundry Lokal)
  - Ikhtisar: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Memulai: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referensi CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrasi dengan SDK inferensi: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Cara menggunakan Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompilasi model Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Ikhtisar: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agen (ikhtisar): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Alat Optimasi dan Inferensi
  - Microsoft Olive (dokumen): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (memulai): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integrasi ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokumen): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokumen): https://ml-explore.github.io/mlx/build/html/index.html
- Kerangka Penerapan dan Model
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokumen): https://docs.vllm.ai/
  - Ollama (memulai): https://github.com/ollama/ollama#get-started
- Alat Pengembang (Windows dan VS Code)
  - AI Toolkit untuk VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (ikhtisar): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Komunitas Pembelajaran

Bergabunglah dalam diskusi dan terhubung dengan sesama pembelajar:
- Diskusi GitHub di [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Kesimpulan

EdgeAI merupakan garis depan implementasi kecerdasan buatan, menghadirkan kemampuan yang kuat langsung ke perangkat sambil mengatasi masalah penting seperti privasi, latensi, dan konektivitas. Kursus 20 jam ini memberikan Anda pengetahuan penting dan keterampilan praktis untuk mulai bekerja dengan teknologi EdgeAI segera.

Kursus ini sengaja dirancang ringkas dan fokus pada konsep paling penting, memungkinkan Anda untuk dengan cepat mendapatkan keahlian berharga tanpa komitmen waktu yang berlebihan. Ingatlah bahwa praktik langsung, bahkan dengan contoh sederhana, adalah kunci untuk memperkuat apa yang telah Anda pelajari.

Selamat belajar!

---

