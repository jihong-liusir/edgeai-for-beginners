<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-25T00:38:14+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "id"
}
-->
# EdgeAI untuk Pemula: Jalur Pembelajaran dan Jadwal Studi

### Jalur Pembelajaran Intensif (1 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 2 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 3 | Modul 3: Penerapan SLM | 2 jam |
| Hari 4-5 | Modul 4: Optimasi Model (6 kerangka kerja) | 4 jam |
| Hari 6 | Modul 5: SLMOps | 3 jam |
| Hari 7 | Modul 6-7: Agen AI & Alat Pengembangan | 4 jam |
| Hari 8 | Modul 8: Foundry Local Toolkit (Implementasi Modern) | 1 jam |

### Jalur Pembelajaran Intensif (2 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Dasar-dasar SLM | 3 jam |
| Hari 5-6 | Modul 3: Penerapan SLM | 2 jam |
| Hari 7-8 | Modul 4: Optimasi Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Agen AI | 2 jam |
| Hari 13-14 | Modul 7: Alat Pengembangan | 3 jam |

### Studi Paruh Waktu (4 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 1-2: Dasar-dasar & Fondasi SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penerapan & Optimasi | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Agen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pengembangan & Integrasi | 3 jam |

| Hari | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Fondasi SLM | 3 jam |
| Hari 5-6 | Modul 3: Penerapan SLM | 2 jam |
| Hari 7-8 | Modul 4: Optimasi Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Sistem Agen SLM | 2 jam |
| Hari 13-14 | Modul 7: Contoh Implementasi EdgeAI | 2 jam |

| Modul | Tanggal Selesai | Jam yang Dihabiskan | Poin Penting |
|--------|----------------|-------------|--------------|
| Modul 1: Dasar-dasar EdgeAI | | | |
| Modul 2: Fondasi SLM | | | |
| Modul 3: Penerapan SLM | | | |
| Modul 4: Optimasi Model (6 kerangka kerja) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Sistem Agen SLM | | | |
| Modul 7: Contoh Implementasi EdgeAI | | | |
| Latihan Praktis | | | |
| Mini-Proyek | | | |

### Studi Paruh Waktu (4 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|------------------|
| Minggu 1 | Modul 1-2: Dasar-dasar & Fondasi SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penerapan & Optimasi | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Agen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pengembangan & Integrasi | 3 jam |

## Pendahuluan

Selamat datang di panduan belajar EdgeAI untuk Pemula! Dokumen ini dirancang untuk membantu Anda memahami materi kursus secara efektif dan memaksimalkan pengalaman belajar Anda. Panduan ini menyediakan jalur pembelajaran yang terstruktur, jadwal studi yang disarankan, ringkasan konsep utama, dan sumber daya tambahan untuk memperdalam pemahaman Anda tentang teknologi EdgeAI.

Ini adalah kursus singkat selama 20 jam yang memberikan pengetahuan penting tentang EdgeAI dalam format yang efisien waktu, sehingga cocok untuk para profesional dan pelajar yang sibuk yang ingin dengan cepat memperoleh keterampilan praktis di bidang yang sedang berkembang ini.

## Ikhtisar Kursus

Kursus ini terdiri dari tujuh modul komprehensif:

1. **Dasar-dasar dan Transformasi EdgeAI** - Memahami konsep inti dan perubahan teknologi
2. **Fondasi Model Bahasa Kecil (SLM)** - Menjelajahi berbagai keluarga SLM dan arsitekturnya
3. **Penerapan Model Bahasa Kecil** - Menerapkan strategi penerapan praktis
4. **Konversi Format Model dan Kuantisasi** - Optimasi lanjutan dengan 6 kerangka kerja termasuk OpenVINO
5. **SLMOps - Operasi Model Bahasa Kecil** - Manajemen siklus produksi dan penerapan
6. **Sistem Agen SLM** - Agen AI, pemanggilan fungsi, dan Protokol Konteks Model
7. **Contoh Implementasi EdgeAI** - Toolkit AI, pengembangan Windows, dan implementasi spesifik platform
8. **Microsoft Foundry Local â€“ Toolkit Pengembang Lengkap** - Pengembangan lokal dengan integrasi hybrid Azure (Modul 08)

## Cara Menggunakan Panduan Belajar Ini

- **Pembelajaran Bertahap**: Ikuti modul secara berurutan untuk pengalaman belajar yang paling koheren
- **Pemeriksaan Pengetahuan**: Gunakan pertanyaan penilaian diri setelah setiap bagian
- **Latihan Praktis**: Selesaikan latihan yang disarankan untuk memperkuat konsep teoritis
- **Sumber Daya Tambahan**: Jelajahi materi tambahan untuk topik yang paling menarik bagi Anda

## Rekomendasi Jadwal Studi

### Jalur Pembelajaran Intensif (1 minggu)

| Hari | Fokus | Perkiraan Jam |
|------|-------|-----------------|
| Hari 1-2 | Modul 1: Dasar-dasar EdgeAI | 6 jam |
| Hari 3-4 | Modul 2: Fondasi SLM | 8 jam |
| Hari 5 | Modul 3: Penerapan SLM | 3 jam |
| Hari 6 | Modul 8: Foundry Local Toolkit | 3 jam |

### Studi Paruh Waktu (3 minggu)

| Minggu | Fokus | Perkiraan Jam |
|------|-------|-----------------|
| Minggu 1 | Modul 1: Dasar-dasar EdgeAI | 6-7 jam |
| Minggu 2 | Modul 2: Fondasi SLM | 7-8 jam |
| Minggu 3 | Modul 3: Penerapan SLM (3 jam) + Modul 8: Foundry Local Toolkit (2-3 jam) | 5-6 jam |

## Modul 1: Dasar-dasar dan Transformasi EdgeAI

### Tujuan Pembelajaran Utama

- Memahami perbedaan antara AI berbasis cloud dan berbasis edge
- Menguasai teknik optimasi inti untuk lingkungan dengan sumber daya terbatas
- Menganalisis aplikasi nyata teknologi EdgeAI
- Menyiapkan lingkungan pengembangan untuk proyek EdgeAI

### Area Fokus Studi

#### Bagian 1: Dasar-dasar EdgeAI
- **Konsep Prioritas**: 
  - Paradigma komputasi Edge vs. Cloud
  - Teknik kuantisasi model
  - Opsi akselerasi perangkat keras (NPU, GPU, CPU)
  - Keunggulan privasi dan keamanan

- **Materi Tambahan**:
  - [Dokumentasi TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Dokumentasi Edge Impulse](https://docs.edgeimpulse.com)

#### Bagian 2: Studi Kasus Dunia Nyata
- **Konsep Prioritas**: 
  - Ekosistem model Microsoft Phi & Mu
  - Implementasi praktis di berbagai industri
  - Pertimbangan penerapan

#### Bagian 3: Panduan Implementasi Praktis
- **Konsep Prioritas**: 
  - Penyiapan lingkungan pengembangan
  - Alat kuantisasi dan optimasi
  - Metode penilaian untuk implementasi EdgeAI

#### Bagian 4: Perangkat Keras Penerapan Edge
- **Konsep Prioritas**: 
  - Perbandingan platform perangkat keras
  - Strategi optimasi untuk perangkat keras tertentu
  - Pertimbangan penerapan

### Pertanyaan Penilaian Diri

1. Bandingkan dan bedakan AI berbasis cloud dengan implementasi AI berbasis edge.
2. Jelaskan tiga teknik utama untuk mengoptimalkan model untuk penerapan edge.
3. Apa keuntungan utama menjalankan model AI di edge?
4. Deskripsikan proses kuantisasi model dan bagaimana hal itu memengaruhi kinerja.
5. Jelaskan bagaimana akselerator perangkat keras yang berbeda (NPU, GPU, CPU) memengaruhi penerapan EdgeAI.

### Latihan Praktis

1. **Penyiapan Lingkungan Cepat**: Konfigurasikan lingkungan pengembangan minimal dengan paket-paket penting (30 menit)
2. **Eksplorasi Model**: Unduh dan periksa model bahasa kecil yang sudah dilatih (1 jam)
3. **Kuantisasi Dasar**: Coba kuantisasi sederhana pada model kecil (1 jam)

## Modul 2: Fondasi Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memahami prinsip arsitektur dari berbagai keluarga SLM
- Membandingkan kemampuan model berdasarkan skala parameter
- Mengevaluasi model berdasarkan efisiensi, kemampuan, dan kebutuhan penerapan
- Mengenali kasus penggunaan yang sesuai untuk berbagai keluarga model

### Area Fokus Studi

#### Bagian 1: Keluarga Model Microsoft Phi
- **Konsep Prioritas**: 
  - Evolusi filosofi desain
  - Arsitektur efisiensi-pertama
  - Kemampuan khusus

#### Bagian 2: Keluarga Qwen
- **Konsep Prioritas**: 
  - Kontribusi sumber terbuka
  - Opsi penerapan yang skalabel
  - Arsitektur penalaran lanjutan

#### Bagian 3: Keluarga Gemma
- **Konsep Prioritas**: 
  - Inovasi berbasis penelitian
  - Kemampuan multimodal
  - Optimasi untuk perangkat seluler

#### Bagian 4: Keluarga BitNET
- **Konsep Prioritas**: 
  - Teknologi kuantisasi 1-bit
  - Kerangka kerja optimasi inferensi
  - Pertimbangan keberlanjutan

#### Bagian 5: Model Microsoft Mu
- **Konsep Prioritas**: 
  - Arsitektur perangkat-pertama
  - Integrasi sistem dengan Windows
  - Operasi yang menjaga privasi

#### Bagian 6: Phi-Silica
- **Konsep Prioritas**: 
  - Arsitektur yang dioptimalkan untuk NPU
  - Metrik kinerja
  - Integrasi pengembang

### Pertanyaan Penilaian Diri

1. Bandingkan pendekatan arsitektur keluarga model Phi dan Qwen.
2. Jelaskan bagaimana teknologi kuantisasi BitNET berbeda dari kuantisasi tradisional.
3. Apa keuntungan unik model Mu untuk integrasi Windows?
4. Deskripsikan bagaimana Phi-Silica memanfaatkan perangkat keras NPU untuk optimasi kinerja.
5. Untuk aplikasi seluler dengan konektivitas terbatas, keluarga model mana yang paling sesuai dan mengapa?

### Latihan Praktis

1. **Perbandingan Model**: Benchmark cepat dua model SLM yang berbeda (1 jam)
2. **Generasi Teks Sederhana**: Implementasi dasar generasi teks dengan model kecil (1 jam)
3. **Optimasi Cepat**: Terapkan satu teknik optimasi untuk meningkatkan kecepatan inferensi (1 jam)

## Modul 3: Penerapan Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memilih model yang sesuai berdasarkan kendala penerapan
- Menguasai teknik optimasi untuk berbagai skenario penerapan
- Menerapkan SLM di lingkungan lokal dan cloud
- Merancang konfigurasi siap produksi untuk aplikasi EdgeAI

### Area Fokus Studi

#### Bagian 1: Pembelajaran Lanjutan SLM
- **Konsep Prioritas**: 
  - Kerangka klasifikasi parameter
  - Teknik optimasi lanjutan
  - Strategi akuisisi model

#### Bagian 2: Penerapan Lingkungan Lokal
- **Konsep Prioritas**: 
  - Penerapan platform Ollama
  - Solusi lokal Microsoft Foundry
  - Analisis perbandingan kerangka kerja

#### Bagian 3: Penerapan Cloud yang Terkontainerisasi
- **Konsep Prioritas**: 
  - Inferensi kinerja tinggi vLLM
  - Orkestrasi kontainer
  - Implementasi ONNX Runtime

### Pertanyaan Penilaian Diri

1. Faktor apa yang harus dipertimbangkan saat memilih antara penerapan lokal dan penerapan cloud?
2. Bandingkan Ollama dan Microsoft Foundry Local sebagai opsi penerapan.
3. Jelaskan manfaat kontainerisasi untuk penerapan SLM.
4. Apa metrik kinerja utama yang harus dipantau untuk SLM yang diterapkan di edge?
5. Deskripsikan alur kerja penerapan lengkap dari pemilihan model hingga implementasi produksi.

### Latihan Praktis

1. **Penerapan Lokal Dasar**: Terapkan SLM sederhana menggunakan Ollama (1 jam)
2. **Pemeriksaan Kinerja**: Jalankan benchmark cepat pada model yang diterapkan (30 menit)
3. **Integrasi Sederhana**: Buat aplikasi minimal yang menggunakan model yang diterapkan (1 jam)

## Modul 4: Konversi Format Model dan Kuantisasi

### Tujuan Pembelajaran Utama

- Menguasai teknik kuantisasi lanjutan dari presisi 1-bit hingga 8-bit
- Memahami strategi konversi format (GGUF, ONNX)
- Menerapkan optimasi di enam kerangka kerja (Llama.cpp, Olive, OpenVINO, MLX, sintesis alur kerja)
- Menerapkan model yang dioptimalkan untuk lingkungan edge produksi di perangkat keras Intel, Apple, dan lintas platform

### Area Fokus Studi

#### Bagian 1: Fondasi Kuantisasi
- **Konsep Prioritas**: 
  - Kerangka klasifikasi presisi
  - Perbandingan kinerja vs. akurasi
  - Optimasi jejak memori

#### Bagian 2: Implementasi Llama.cpp
- **Konsep Prioritas**: 
  - Penerapan lintas platform
  - Optimasi format GGUF
  - Teknik akselerasi perangkat keras

#### Bagian 3: Suite Microsoft Olive
- **Konsep Prioritas**: 
  - Optimasi yang sadar perangkat keras
  - Penerapan tingkat perusahaan
  - Alur kerja optimasi otomatis

#### Bagian 4: Toolkit OpenVINO
- **Konsep Prioritas**: 
  - Optimasi perangkat keras Intel
  - Kerangka Kompresi Jaringan Neural (NNCF)
  - Penerapan inferensi lintas platform
- OpenVINO GenAI untuk penerapan LLM

#### Bagian 5: Kerangka Kerja Apple MLX
- **Konsep Prioritas**: 
  - Optimisasi Apple Silicon
  - Arsitektur memori terpadu
  - Kemampuan fine-tuning LoRA

#### Bagian 6: Sintesis Alur Kerja Pengembangan Edge AI
- **Konsep Prioritas**: 
  - Arsitektur alur kerja terpadu
  - Pohon keputusan pemilihan kerangka kerja
  - Validasi kesiapan produksi
  - Strategi untuk masa depan

### Pertanyaan Penilaian Diri

1. Bandingkan strategi kuantisasi pada berbagai tingkat presisi (1-bit hingga 8-bit).
2. Jelaskan keuntungan format GGUF untuk penerapan di edge.
3. Bagaimana optimisasi berbasis perangkat keras di Microsoft Olive meningkatkan efisiensi penerapan?
4. Apa manfaat utama dari NNCF OpenVINO untuk kompresi model?
5. Deskripsikan bagaimana Apple MLX memanfaatkan arsitektur memori terpadu untuk optimisasi.
6. Bagaimana sintesis alur kerja membantu dalam memilih kerangka kerja optimisasi yang optimal?

### Latihan Praktis

1. **Kuantisasi Model**: Terapkan berbagai tingkat kuantisasi pada model dan bandingkan hasilnya (1 jam)
2. **Optimisasi OpenVINO**: Gunakan NNCF untuk mengompresi model untuk perangkat keras Intel (1 jam)
3. **Perbandingan Kerangka Kerja**: Uji model yang sama pada tiga kerangka kerja optimisasi yang berbeda (1 jam)
4. **Benchmarking Kinerja**: Ukur dampak optimisasi pada kecepatan inferensi dan penggunaan memori (1 jam)

## Modul 5: SLMOps - Operasi Model Bahasa Kecil

### Tujuan Pembelajaran Utama

- Memahami prinsip manajemen siklus hidup SLMOps
- Menguasai teknik distilasi dan fine-tuning untuk penerapan di edge
- Menerapkan strategi penerapan produksi dengan pemantauan
- Membangun alur kerja operasi dan pemeliharaan SLM tingkat perusahaan

### Area Fokus Studi

#### Bagian 1: Pengantar SLMOps
- **Konsep Prioritas**: 
  - Pergeseran paradigma SLMOps dalam operasi AI
  - Arsitektur hemat biaya dan berorientasi privasi
  - Dampak strategis bisnis dan keuntungan kompetitif

#### Bagian 2: Distilasi Model
- **Konsep Prioritas**: 
  - Teknik transfer pengetahuan
  - Implementasi proses distilasi dua tahap
  - Alur kerja distilasi Azure ML

#### Bagian 3: Strategi Fine-tuning
- **Konsep Prioritas**: 
  - Fine-tuning yang efisien dalam parameter (PEFT)
  - Metode canggih LoRA dan QLoRA
  - Pelatihan multi-adapter dan optimisasi hyperparameter

#### Bagian 4: Penerapan Produksi
- **Konsep Prioritas**: 
  - Konversi model dan kuantisasi untuk produksi
  - Konfigurasi penerapan Foundry Local
  - Benchmarking kinerja dan validasi kualitas

### Pertanyaan Penilaian Diri

1. Bagaimana SLMOps berbeda dari MLOps tradisional?
2. Jelaskan manfaat distilasi model untuk penerapan di edge.
3. Apa pertimbangan utama untuk fine-tuning SLM dalam lingkungan dengan sumber daya terbatas?
4. Deskripsikan pipeline penerapan produksi lengkap untuk aplikasi AI di edge.

### Latihan Praktis

1. **Distilasi Dasar**: Buat model yang lebih kecil dari model guru yang lebih besar (1 jam)
2. **Eksperimen Fine-tuning**: Fine-tuning model untuk domain tertentu (1 jam)
3. **Pipeline Penerapan**: Siapkan pipeline CI/CD dasar untuk penerapan model (1 jam)

## Modul 6: Sistem SLM Agentic - Agen AI dan Pemanggilan Fungsi

### Tujuan Pembelajaran Utama

- Membangun agen AI cerdas untuk lingkungan edge menggunakan Model Bahasa Kecil
- Menerapkan kemampuan pemanggilan fungsi dengan alur kerja sistematis
- Menguasai integrasi Model Context Protocol (MCP) untuk interaksi alat yang terstandarisasi
- Membuat sistem agentic yang canggih dengan intervensi manusia minimal

### Area Fokus Studi

#### Bagian 1: Agen AI dan Dasar SLM
- **Konsep Prioritas**: 
  - Kerangka klasifikasi agen (refleks, berbasis model, berbasis tujuan, agen pembelajaran)
  - Analisis trade-off SLM vs LLM
  - Pola desain agen khusus untuk edge
  - Optimisasi sumber daya untuk agen

#### Bagian 2: Pemanggilan Fungsi dalam Model Bahasa Kecil
- **Konsep Prioritas**: 
  - Implementasi alur kerja sistematis (deteksi intent, output JSON, eksekusi eksternal)
  - Implementasi spesifik platform (Phi-4-mini, model Qwen terpilih, Microsoft Foundry Local)
  - Contoh lanjutan (kolaborasi multi-agen, pemilihan alat dinamis)
  - Pertimbangan produksi (pembatasan laju, pencatatan audit, langkah keamanan)

#### Bagian 3: Integrasi Model Context Protocol (MCP)
- **Konsep Prioritas**: 
  - Arsitektur protokol dan desain sistem berlapis
  - Dukungan multi-backend (Ollama untuk pengembangan, vLLM untuk produksi)
  - Protokol koneksi (mode STDIO dan SSE)
  - Aplikasi dunia nyata (otomasi web, pemrosesan data, integrasi API)

### Pertanyaan Penilaian Diri

1. Apa pertimbangan arsitektur utama untuk agen AI di edge?
2. Bagaimana pemanggilan fungsi meningkatkan kemampuan agen?
3. Jelaskan peran Model Context Protocol dalam komunikasi agen.

### Latihan Praktis

1. **Agen Sederhana**: Bangun agen AI dasar dengan pemanggilan fungsi (1 jam)
2. **Integrasi MCP**: Terapkan MCP dalam aplikasi agen (30 menit)

## Modul 7: Contoh Implementasi EdgeAI

### Tujuan Pembelajaran Utama

- Menguasai AI Toolkit untuk Visual Studio Code untuk alur kerja pengembangan EdgeAI yang komprehensif
- Mendapatkan keahlian dalam platform Windows AI Foundry dan strategi optimisasi NPU
- Menerapkan EdgeAI di berbagai platform perangkat keras dan skenario penerapan
- Membangun aplikasi EdgeAI siap produksi dengan optimisasi spesifik platform

### Area Fokus Studi

#### Bagian 1: AI Toolkit untuk Visual Studio Code
- **Konsep Prioritas**: 
  - Lingkungan pengembangan Edge AI yang komprehensif dalam VS Code
  - Katalog model dan penemuan untuk penerapan di edge
  - Pengujian lokal, optimisasi, dan alur kerja pengembangan agen
  - Pemantauan kinerja dan evaluasi untuk skenario edge

#### Bagian 2: Panduan Pengembangan Windows EdgeAI
- **Konsep Prioritas**: 
  - Ikhtisar komprehensif platform Windows AI Foundry
  - API Phi Silica untuk inferensi NPU yang efisien
  - API Computer Vision untuk pemrosesan gambar dan OCR
  - CLI Foundry Local untuk pengembangan dan pengujian lokal

#### Bagian 3: Implementasi Spesifik Platform
- **Konsep Prioritas**: 
  - Penerapan NVIDIA Jetson Orin Nano (67 TOPS kinerja AI)
  - Aplikasi seluler dengan .NET MAUI dan ONNX Runtime GenAI
  - Solusi Azure EdgeAI dengan arsitektur hybrid cloud-edge
  - Optimisasi Windows ML dengan dukungan perangkat keras universal
  - Aplikasi Foundry Local dengan implementasi RAG berorientasi privasi

### Pertanyaan Penilaian Diri

1. Bagaimana AI Toolkit menyederhanakan alur kerja pengembangan EdgeAI?
2. Bandingkan strategi penerapan di berbagai platform perangkat keras.
3. Apa keuntungan Windows AI Foundry untuk pengembangan di edge?
4. Jelaskan peran optimisasi NPU dalam aplikasi AI modern di edge.
5. Bagaimana API Phi Silica memanfaatkan perangkat keras NPU untuk optimisasi kinerja?
6. Bandingkan manfaat penerapan lokal vs cloud untuk aplikasi yang sensitif terhadap privasi.

### Latihan Praktis

1. **Pengaturan AI Toolkit**: Konfigurasikan AI Toolkit dan optimalkan model (1 jam)
2. **Windows AI Foundry**: Bangun aplikasi AI Windows sederhana menggunakan API Phi Silica (1 jam)
3. **Penerapan Lintas Platform**: Terapkan model yang sama di dua platform berbeda (1 jam)
4. **Optimisasi NPU**: Uji kinerja NPU dengan alat Windows AI Foundry (30 menit)

## Modul 8: Microsoft Foundry Local â€“ Toolkit Pengembang Lengkap (Modernisasi)

### Tujuan Pembelajaran Utama

- Instal dan konfigurasikan Foundry Local dengan integrasi SDK modern
- Menerapkan sistem multi-agen canggih dengan pola koordinator
- Membangun router model cerdas dengan pemilihan berbasis tugas otomatis
- Menerapkan solusi AI siap produksi dengan pemantauan komprehensif
- Mengintegrasikan dengan Azure AI Foundry untuk skenario penerapan hybrid
- Menguasai pola SDK modern dengan FoundryLocalManager dan klien OpenAI

### Area Fokus Studi

#### Bagian 1: Instalasi dan Konfigurasi Modern
- **Konsep Prioritas**: 
  - Integrasi SDK FoundryLocalManager
  - Penemuan layanan otomatis dan pemantauan kesehatan
  - Pola konfigurasi berbasis lingkungan
  - Pertimbangan penerapan produksi

#### Bagian 2: Sistem Multi-Agen Lanjutan
- **Konsep Prioritas**: 
  - Pola koordinator dengan agen spesialis
  - Spesialisasi agen untuk pengambilan, penalaran, dan eksekusi
  - Mekanisme umpan balik untuk penyempurnaan
  - Pemantauan kinerja dan pelacakan statistik

#### Bagian 3: Routing Model Cerdas
- **Konsep Prioritas**: 
  - Algoritma pemilihan model berbasis kata kunci
  - Dukungan multi-model (umum, penalaran, kode, kreatif)
  - Konfigurasi variabel lingkungan untuk fleksibilitas
  - Pemeriksaan kesehatan layanan dan penanganan kesalahan

#### Bagian 4: Implementasi Siap Produksi
- **Konsep Prioritas**: 
  - Penanganan kesalahan komprehensif dan mekanisme fallback
  - Pemantauan permintaan dan pelacakan kinerja
  - Contoh notebook Jupyter interaktif dengan benchmark
  - Pola integrasi dengan aplikasi yang ada

### Pertanyaan Penilaian Diri

1. Bagaimana pendekatan modern FoundryLocalManager berbeda dari panggilan REST manual?
2. Jelaskan pola koordinator dan bagaimana ia mengatur agen spesialis.
3. Bagaimana router cerdas memilih model yang sesuai berdasarkan konten kueri?
4. Apa komponen utama dari sistem agen AI siap produksi?
5. Bagaimana Anda menerapkan pemantauan kesehatan yang komprehensif untuk layanan Foundry Local?
6. Bandingkan manfaat pendekatan modernisasi vs pola implementasi tradisional.

### Latihan Praktis

1. **Pengaturan SDK Modern**: Konfigurasikan FoundryLocalManager dengan penemuan layanan otomatis (30 menit)
2. **Sistem Multi-Agen**: Jalankan koordinator lanjutan dengan agen spesialis (30 menit)
3. **Routing Cerdas**: Uji router model dengan berbagai jenis kueri (30 menit)
4. **Eksplorasi Interaktif**: Gunakan notebook Jupyter untuk menjelajahi fitur lanjutan (45 menit)
5. **Penerapan Produksi**: Terapkan pola pemantauan dan penanganan kesalahan (30 menit)
6. **Integrasi Hybrid**: Konfigurasikan skenario fallback Azure AI Foundry (30 menit)

## Panduan Alokasi Waktu

Untuk membantu Anda memanfaatkan waktu 20 jam kursus, berikut adalah pembagian waktu yang disarankan:

| Aktivitas | Alokasi Waktu | Deskripsi |
|-----------|---------------|-----------|
| Membaca Materi Inti | 9 jam | Fokus pada konsep penting di setiap modul |
| Latihan Praktis | 6 jam | Implementasi teknik utama secara praktis |
| Penilaian Diri | 2 jam | Menguji pemahaman melalui pertanyaan dan refleksi |
| Proyek Mini | 3 jam | Menerapkan pengetahuan ke implementasi praktis kecil |

### Area Fokus Utama Berdasarkan Keterbatasan Waktu

**Jika Anda hanya memiliki 10 jam:**
- Selesaikan Modul 1, 2, dan 3 (konsep inti EdgeAI)
- Lakukan setidaknya satu latihan praktis per modul
- Fokus pada pemahaman konsep inti daripada detail implementasi

**Jika Anda dapat mendedikasikan waktu penuh 20 jam:**
- Selesaikan semua tujuh modul
- Lakukan latihan praktis utama dari setiap modul
- Selesaikan satu proyek mini dari Modul 7
- Jelajahi setidaknya 2-3 sumber tambahan

**Jika Anda memiliki lebih dari 20 jam:**
- Selesaikan semua modul dengan latihan mendetail
- Bangun beberapa proyek mini
- Jelajahi teknik optimisasi lanjutan di Modul 4
- Terapkan penerapan produksi dari Modul 5

## Sumber Daya Penting

Sumber daya yang dipilih dengan cermat ini memberikan nilai maksimal untuk waktu belajar Anda yang terbatas:

### Dokumentasi Wajib Dibaca
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Alat optimisasi model yang paling efisien
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cara tercepat untuk menerapkan SLM secara lokal
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referensi untuk model yang dioptimalkan untuk edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit optimisasi komprehensif dari Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Lingkungan pengembangan EdgeAI yang terintegrasi
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platform pengembangan EdgeAI khusus Windows

### Alat Hemat Waktu
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Akses model cepat dan penerapan
- [Gradio](https://www.gradio.app/docs/interface) - Pengembangan UI cepat untuk demo AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimisasi model yang disederhanakan
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferensi CPU yang efisien
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Kerangka kerja kompresi jaringan saraf
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit penerapan model bahasa besar

## Template Pelacakan Kemajuan

Gunakan template sederhana ini untuk melacak kemajuan belajar Anda melalui kursus 20 jam:

| Modul | Tanggal Penyelesaian | Waktu yang Dihabiskan | Poin Penting |
|-------|----------------------|-----------------------|--------------|
| Modul 1: Dasar-dasar EdgeAI | | | |
| Modul 2: Dasar-dasar SLM | | | |
| Modul 3: Penerapan SLM | | | |
| Modul 4: Optimisasi Model | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Agen AI | | | |
| Modul 7: Alat Pengembangan | | | |
| Modul 8: Toolkit Foundry Local | | | |
| Latihan Praktis | | | |
| Proyek Mini | | | |

## Ide Proyek Mini

Pertimbangkan untuk menyelesaikan salah satu proyek berikut untuk mempraktikkan konsep EdgeAI (masing-masing dirancang untuk memakan waktu 2-4 jam):

### Proyek Pemula (2-3 jam masing-masing)
1. **Asisten Teks Edge**: Buat alat penyelesaian teks offline sederhana menggunakan model bahasa kecil
2. **Dashboard Perbandingan Model**: Bangun visualisasi dasar untuk metrik kinerja di berbagai SLM
3. **Eksperimen Optimasi**: Ukur dampak berbagai tingkat kuantisasi pada model dasar yang sama

### Proyek Menengah (3-4 jam masing-masing)
4. **Alur Kerja AI Toolkit**: Gunakan VS Code AI Toolkit untuk mengoptimalkan dan menerapkan model dari awal hingga akhir
5. **Aplikasi Windows AI Foundry**: Buat aplikasi Windows menggunakan API Phi Silica dan optimasi NPU
6. **Penerapan Lintas Platform**: Terapkan model yang sama yang telah dioptimalkan di Windows (OpenVINO) dan perangkat seluler (.NET MAUI)
7. **Agen Pemanggilan Fungsi**: Bangun agen AI dengan kemampuan pemanggilan fungsi untuk skenario edge

### Proyek Integrasi Lanjutan (4-5 jam masing-masing)
8. **Pipeline Optimasi OpenVINO**: Implementasikan optimasi model lengkap menggunakan NNCF dan toolkit GenAI
9. **Pipeline SLMOps**: Implementasikan siklus hidup model lengkap dari pelatihan hingga penerapan di edge
10. **Sistem Edge Multi-Model**: Terapkan beberapa model khusus yang bekerja bersama di perangkat keras edge
11. **Sistem Integrasi MCP**: Bangun sistem agen menggunakan Model Context Protocol untuk interaksi alat

## Referensi

- Microsoft Learn (Foundry Local)
  - Ikhtisar: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Memulai: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referensi CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrasi dengan SDK inferensi: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Cara menggunakan Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompilasi model Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Ikhtisar: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agen (ikhtisar): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Alat Optimasi dan Inferensi
  - Microsoft Olive (dokumen): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (memulai): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integrasi ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokumen): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokumen): https://ml-explore.github.io/mlx/build/html/index.html
- Kerangka Kerja Penerapan dan Model
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokumen): https://docs.vllm.ai/
  - Ollama (memulai cepat): https://github.com/ollama/ollama#get-started
- Alat Pengembang (Windows dan VS Code)
  - AI Toolkit untuk VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (ikhtisar): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Komunitas Pembelajaran

Bergabunglah dalam diskusi dan terhubung dengan sesama pembelajar:
- Diskusi GitHub di [repository EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Kesimpulan

EdgeAI merupakan garis depan implementasi kecerdasan buatan, menghadirkan kemampuan yang kuat langsung ke perangkat sambil mengatasi masalah penting seperti privasi, latensi, dan konektivitas. Kursus 20 jam ini memberikan Anda pengetahuan penting dan keterampilan praktis untuk mulai bekerja dengan teknologi EdgeAI segera.

Kursus ini sengaja dirancang ringkas dan fokus pada konsep paling penting, memungkinkan Anda dengan cepat mendapatkan keahlian berharga tanpa komitmen waktu yang berlebihan. Ingatlah bahwa latihan langsung, bahkan dengan contoh sederhana, adalah kunci untuk memperkuat apa yang telah Anda pelajari.

Selamat belajar!

---

