<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T14:51:28+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "tl"
}
-->
# Seksyon 3: Fine-Tuning - Pag-customize ng Mga Modelo para sa Partikular na Gawain

## Talaan ng Nilalaman
1. [Panimula sa Fine-Tuning](../../../Module05)
2. [Bakit Mahalaga ang Fine-Tuning](../../../Module05)
3. [Mga Uri ng Fine-Tuning](../../../Module05)
4. [Fine-Tuning gamit ang Microsoft Olive](../../../Module05)
5. [Mga Halimbawa ng Hands-On](../../../Module05)
6. [Mga Pinakamahusay na Praktika at Gabay](../../../Module05)
7. [Mga Advanced na Teknik](../../../Module05)
8. [Pagsusuri at Pag-monitor](../../../Module05)
9. [Karaniwang Hamon at Solusyon](../../../Module05)
10. [Konklusyon](../../../Module05)

## Panimula sa Fine-Tuning

**Ang Fine-tuning** ay isang makapangyarihang teknik sa machine learning na nag-aangkop ng isang pre-trained na modelo upang magsagawa ng partikular na gawain o magtrabaho gamit ang mga espesyal na dataset. Sa halip na magsimula sa pag-train ng modelo mula sa simula, ginagamit ng fine-tuning ang kaalaman na natutunan na ng pre-trained na modelo at ina-adjust ito para sa iyong partikular na layunin.

### Ano ang Fine-Tuning?

Ang Fine-tuning ay isang anyo ng **transfer learning** kung saan:
- Nagsisimula ka sa isang pre-trained na modelo na natutunan ang mga pangkalahatang pattern mula sa malalaking dataset
- Ina-adjust ang mga internal na parameter ng modelo gamit ang iyong partikular na dataset
- Pinapanatili ang mahalagang kaalaman habang ini-specialize ang modelo para sa iyong gawain

Isipin ito na parang pagtuturo sa isang bihasang chef na magluto ng bagong uri ng lutuin - naiintindihan na nila ang mga pangunahing kaalaman sa pagluluto, ngunit kailangan nilang matutunan ang mga partikular na teknik at lasa para sa bagong estilo.

### Pangunahing Benepisyo

- **Mabilis na Proseso**: Mas mabilis kaysa sa pag-train mula sa simula
- **Mas Kaunting Data**: Kailangan ng mas maliit na dataset para makamit ang magandang performance
- **Mas Mura**: Mas mababa ang computational requirements
- **Mas Magandang Resulta**: Madalas mas mahusay ang resulta kumpara sa pag-train mula sa simula
- **Pag-optimize ng Resources**: Ginagawang mas accessible ang makapangyarihang AI sa mas maliliit na team at organisasyon

## Bakit Mahalaga ang Fine-Tuning

### Mga Aplikasyon sa Tunay na Mundo

Ang Fine-tuning ay mahalaga sa maraming sitwasyon:

**1. Pag-aangkop sa Domain**
- Medical AI: Pag-aangkop ng mga general language model para sa medical terminology at clinical notes
- Legal Tech: Pag-specialize ng mga modelo para sa pagsusuri ng legal na dokumento at kontrata
- Financial Services: Pag-customize ng mga modelo para sa pagsusuri ng financial report at risk assessment

**2. Pag-specialize sa Gawain**
- Content Generation: Fine-tuning para sa partikular na estilo o tono ng pagsusulat
- Code Generation: Pag-aangkop ng mga modelo para sa partikular na programming language o framework
- Translation: Pagpapabuti ng performance para sa partikular na pares ng wika o teknikal na domain

**3. Mga Aplikasyon sa Korporasyon**
- Customer Service: Paglikha ng mga chatbot na nakakaintindi ng terminolohiyang pang-kumpanya
- Internal Documentation: Pagbuo ng AI assistants na pamilyar sa mga proseso ng organisasyon
- Solusyon sa Industriya: Pag-develop ng mga modelo na nakakaintindi ng jargon at workflow ng partikular na sektor

## Mga Uri ng Fine-Tuning

### 1. Full Fine-Tuning (Instruction Fine-Tuning)

Sa full fine-tuning, lahat ng parameter ng modelo ay ina-update sa panahon ng training. Ang approach na ito:
- Nagbibigay ng maximum na flexibility at potensyal na performance
- Nangangailangan ng malaking computational resources
- Nagreresulta sa isang ganap na bagong bersyon ng modelo
- Pinakamainam para sa mga sitwasyon kung saan may sapat na training data at computational resources

### 2. Parameter-Efficient Fine-Tuning (PEFT)

Ang mga PEFT method ay ina-update lamang ang maliit na subset ng mga parameter, na ginagawang mas efficient ang proseso:

#### Low-Rank Adaptation (LoRA)
- Nagdadagdag ng maliliit na trainable rank decomposition matrices sa mga umiiral na weights
- Malaking binabawasan ang bilang ng trainable parameters
- Pinapanatili ang performance na malapit sa full fine-tuning
- Pinapadali ang pag-switch sa pagitan ng iba't ibang adaptation

#### QLoRA (Quantized LoRA)
- Pinagsasama ang LoRA sa mga quantization technique
- Karagdagang binabawasan ang memory requirements
- Pinapahintulutan ang fine-tuning ng mas malalaking modelo gamit ang consumer hardware
- Binabalanse ang efficiency at performance

#### Adapters
- Naglalagay ng maliliit na neural networks sa pagitan ng mga umiiral na layer
- Pinapahintulutan ang targeted fine-tuning habang pinapanatili ang base model na frozen
- Nagbibigay ng modular na approach sa pag-customize ng modelo

### 3. Task-Specific Fine-Tuning

Nakatuon sa pag-aangkop ng mga modelo para sa partikular na downstream tasks:
- **Classification**: Pag-aadjust ng mga modelo para sa categorization tasks
- **Generation**: Pag-optimize para sa content creation at text generation
- **Extraction**: Fine-tuning para sa information extraction at named entity recognition
- **Summarization**: Pag-specialize ng mga modelo para sa document summarization

## Fine-Tuning gamit ang Microsoft Olive

Ang Microsoft Olive ay isang komprehensibong toolkit para sa model optimization na nagpapadali sa proseso ng fine-tuning habang nagbibigay ng enterprise-grade na mga feature.

### Ano ang Microsoft Olive?

Ang Microsoft Olive ay isang open-source na tool para sa model optimization na:
- Pinapasimple ang mga workflow ng fine-tuning para sa iba't ibang hardware targets
- Nagbibigay ng built-in na suporta para sa mga popular na model architecture (Llama, Phi, Qwen, Gemma)
- Nag-aalok ng parehong cloud at local deployment options
- Seamlessly na nag-iintegrate sa Azure ML at iba pang Microsoft AI services
- Sumusuporta sa automatic optimization at quantization

### Pangunahing Feature

- **Hardware-Aware Optimization**: Awtomatikong ina-optimize ang mga modelo para sa partikular na hardware (CPU, GPU, NPU)
- **Multi-Format Support**: Gumagana sa PyTorch, Hugging Face, at ONNX models
- **Automated Workflows**: Binabawasan ang manual configuration at trial-and-error
- **Enterprise Integration**: May built-in na suporta para sa Azure ML at cloud deployments
- **Extensible Architecture**: Pinapahintulutan ang custom optimization techniques

### Pag-install at Setup

#### Basic Installation

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Optional Dependencies

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verify Installation

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Mga Halimbawa ng Hands-On

### Halimbawa 1: Basic Fine-Tuning gamit ang Olive CLI

Ang halimbawang ito ay nagpapakita ng fine-tuning ng isang maliit na language model para sa phrase classification:

#### Hakbang 1: Ihanda ang Iyong Environment

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Hakbang 2: Fine-Tune ang Modelo

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Hakbang 3: I-optimize para sa Deployment

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Halimbawa 2: Advanced Configuration gamit ang Custom Dataset

#### Hakbang 1: Ihanda ang Custom Dataset

Gumawa ng JSON file gamit ang iyong training data:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Hakbang 2: Gumawa ng Configuration File

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Hakbang 3: I-execute ang Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Halimbawa 3: QLoRA Fine-Tuning para sa Memory Efficiency

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Mga Pinakamahusay na Praktika at Gabay

### Paghahanda ng Data

**1. Kalidad ng Data Higit sa Dami**
- Bigyang-priyoridad ang mataas na kalidad, iba't ibang halimbawa kaysa sa malaking dami ng mababang kalidad na data
- Siguraduhing ang data ay representatibo ng iyong target na use case
- Linisin at i-preprocess ang data nang pare-pareho

**2. Format ng Data at Templates**
- Gumamit ng pare-parehong formatting sa lahat ng training examples
- Gumawa ng malinaw na input-output templates na tumutugma sa iyong use case
- Isama ang tamang instruction formatting para sa instruction-tuned models

**3. Dataset Splitting**
- Magreserba ng 10-20% ng data para sa validation
- Panatilihin ang magkatulad na distribusyon sa train/validation splits
- Isaalang-alang ang stratified sampling para sa classification tasks

### Configuration ng Training

**1. Pagpili ng Learning Rate**
- Magsimula sa mas maliit na learning rates (1e-5 hanggang 1e-4) para sa fine-tuning
- Gumamit ng learning rate scheduling para sa mas magandang convergence
- I-monitor ang loss curves para ma-adjust ang rates nang naaayon

**2. Optimization ng Batch Size**
- Balansehin ang batch size sa available na memory
- Gumamit ng gradient accumulation para sa mas malaking effective batch sizes
- Isaalang-alang ang relasyon sa pagitan ng batch size at learning rate

**3. Tagal ng Training**
- I-monitor ang validation metrics upang maiwasan ang overfitting
- Gumamit ng early stopping kapag nag-plateau ang validation performance
- Mag-save ng checkpoints nang regular para sa recovery at analysis

### Pagpili ng Modelo

**1. Pagpili ng Base Model**
- Pumili ng mga modelong pre-trained sa magkatulad na domain kung maaari
- Isaalang-alang ang laki ng modelo kaugnay ng iyong computational constraints
- Suriin ang mga licensing requirements para sa commercial use

**2. Pagpili ng Fine-Tuning Method**
- Gumamit ng LoRA/QLoRA para sa resource-constrained environments
- Pumili ng full fine-tuning kapag kritikal ang maximum performance
- Isaalang-alang ang adapter-based na approaches para sa multiple task scenarios

### Pamamahala ng Resources

**1. Optimization ng Hardware**
- Pumili ng tamang hardware para sa laki ng modelo at method
- Gamitin ang GPU memory nang epektibo gamit ang gradient checkpointing
- Isaalang-alang ang cloud-based na solusyon para sa mas malalaking modelo

**2. Pamamahala ng Memory**
- Gumamit ng mixed precision training kung available
- Mag-implement ng gradient accumulation para sa memory constraints
- I-monitor ang GPU memory usage sa buong training

## Mga Advanced na Teknik

### Multi-Adapter Training

Mag-train ng maraming adapters para sa iba't ibang gawain habang ginagamit ang parehong base model:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparameter Optimization

Mag-implement ng systematic hyperparameter tuning:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Custom Loss Functions

Mag-implement ng domain-specific loss functions:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Pagsusuri at Pag-monitor

### Metrics at Evaluation

**1. Standard Metrics**
- **Accuracy**: Kabuuang tama para sa classification tasks
- **Perplexity**: Sukatan ng kalidad ng language modeling
- **BLEU/ROUGE**: Kalidad ng text generation at summarization
- **F1 Score**: Balanse ng precision at recall para sa classification

**2. Domain-Specific Metrics**
- **Task-Specific Benchmarks**: Gumamit ng mga established benchmarks para sa iyong domain
- **Human Evaluation**: Isama ang human assessment para sa subjective tasks
- **Business Metrics**: I-align sa aktwal na business objectives

**3. Evaluation Setup**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Pag-monitor ng Training Progress

**1. Loss Tracking**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validation Monitoring**
- I-track ang validation loss kasabay ng training loss
- I-monitor ang mga senyales ng overfitting (validation loss tumataas habang training loss bumababa)
- Gumamit ng early stopping base sa validation metrics

**3. Resource Monitoring**
- I-monitor ang GPU/CPU utilization
- I-track ang memory usage patterns
- I-monitor ang bilis ng training at throughput

## Karaniwang Hamon at Solusyon

### Hamon 1: Overfitting

**Mga Sintomas:**
- Patuloy na bumababa ang training loss habang tumataas ang validation loss
- Malaking agwat sa pagitan ng training at validation performance
- Mahinang generalization sa bagong data

**Mga Solusyon:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Hamon 2: Limitasyon sa Memory

**Mga Solusyon:**
- Gumamit ng gradient checkpointing
- Mag-implement ng gradient accumulation
- Pumili ng parameter-efficient methods (LoRA, QLoRA)
- Gumamit ng model parallelism para sa malalaking modelo

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Hamon 3: Mabagal na Training

**Mga Solusyon:**
- I-optimize ang data loading pipelines
- Gumamit ng mixed precision training
- Mag-implement ng efficient batching strategies
- Isaalang-alang ang distributed training para sa malalaking dataset

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Hamon 4: Mahinang Performance

**Mga Hakbang sa Diagnosis:**
1. Suriin ang kalidad at formatting ng data
2. I-check ang learning rate at tagal ng training
3. Suriin ang pagpili ng base model
4. I-review ang preprocessing at tokenization

**Mga Solusyon:**
- Palawakin ang diversity ng training data
- I-adjust ang learning rate schedule
- Subukan ang iba't ibang base models
- Mag-implement ng data augmentation techniques

## Konklusyon

Ang Fine-tuning ay isang makapangyarihang teknik na nagbibigay-daan sa mas malawak na access sa state-of-the-art na AI capabilities. Sa pamamagitan ng paggamit ng mga tool tulad ng Microsoft Olive, maaaring epektibong i-adapt ng mga organisasyon ang pre-trained na mga modelo sa kanilang partikular na pangangailangan habang ina-optimize ang performance at resource constraints.

### Pangunahing Takeaways

1. **Pumili ng Tamang Approach**: Pumili ng fine-tuning methods base sa iyong computational resources at performance requirements
2. **Mahalaga ang Kalidad ng Data**: Mag-invest sa mataas na kalidad, representatibong training data
3. **I-monitor at I-iterate**: Patuloy na suriin at pagbutihin ang iyong mga modelo
4. **Gamitin ang Mga Tool**: Gumamit ng mga framework tulad ng Olive para gawing simple at optimize ang proseso
5. **Isaalang-alang ang Deployment**: Magplano para sa model optimization at deployment mula sa simula

## ➡️ Ano ang susunod

- [04: Deployment - Production-Ready Model Implementation](./04.SLMOps.Deployment.md)

---

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama't sinisikap naming maging tumpak, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.