<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T09:25:06+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tl"
}
-->
# EdgeAI para sa mga Baguhan: Mga Landas ng Pag-aaral at Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 0 | Module 0: Panimula sa EdgeAI | 1-2 oras |
| Araw 1 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 2 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 3 | Module 3: Deployment ng SLM | 2 oras |
| Araw 4-5 | Module 4: Pag-optimize ng Modelo (6 na framework) | 4 oras |
| Araw 6 | Module 5: SLMOps | 3 oras |
| Araw 7 | Module 6-7: AI Agents at Mga Kagamitang Pang-develop | 4 oras |
| Araw 8 | Module 8: Foundry Local Toolkit (Modernong Implementasyon) | 1 oras |

### Konsentradong Landas ng Pag-aaral (2 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: AI Agents | 2 oras |
| Araw 13-14 | Module 7: Mga Kagamitang Pang-develop | 3 oras |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 0 | Module 0: Panimula sa EdgeAI | 1-2 oras |
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: Mga Sistemang Agentic ng SLM | 2 oras |
| Araw 13-14 | Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | 2 oras |

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mahahalagang Natutunan |
|--------|----------------|-------------|--------------|
| Module 0: Panimula sa EdgeAI | | | |
| Module 1: Mga Pangunahing Kaalaman sa EdgeAI | | | |
| Module 2: Mga Batayan ng SLM | | | |
| Module 3: Deployment ng SLM | | | |
| Module 4: Pag-optimize ng Modelo (6 na framework) | | | |
| Module 5: SLMOps | | | |
| Module 6: Mga Sistemang Agentic ng SLM | | | |
| Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | | | |
| Mga Hands-on na Ehersisyo | | | |
| Mini-Project | | | |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

## Panimula

Maligayang pagdating sa gabay sa pag-aaral ng EdgeAI para sa mga Baguhan! Ang dokumentong ito ay idinisenyo upang tulungan kang mag-navigate sa mga materyales ng kurso nang epektibo at mapakinabangan ang iyong karanasan sa pag-aaral. Nagbibigay ito ng mga nakabalangkas na landas ng pag-aaral, mga mungkahing iskedyul ng pag-aaral, mga buod ng mahahalagang konsepto, at mga karagdagang mapagkukunan upang palalimin ang iyong pag-unawa sa mga teknolohiya ng Edge AI.

Ito ay isang maikli ngunit komprehensibong kurso na tumatagal ng 20 oras, na nagbibigay ng mahahalagang kaalaman tungkol sa EdgeAI sa isang orasang format, na perpekto para sa mga abalang propesyonal at estudyante na nais mabilis na makakuha ng praktikal na kasanayan sa umuusbong na larangang ito.

## Pangkalahatang-ideya ng Kurso

Ang kurso na ito ay inayos sa walong komprehensibong module:

0. **Panimula sa EdgeAI** - Pundasyon at pagtatakda ng konteksto gamit ang mga aplikasyon sa industriya at mga layunin sa pag-aaral  
1. **Mga Pangunahing Kaalaman at Transformasyon ng EdgeAI** - Pag-unawa sa mga pangunahing konsepto at pagbabago sa teknolohiya  
2. **Mga Batayan ng Small Language Model (SLM)** - Paggalugad sa iba't ibang pamilya ng SLM at kanilang mga arkitektura  
3. **Deployment ng Small Language Model** - Pagpapatupad ng mga praktikal na estratehiya sa deployment  
4. **Pag-convert ng Format ng Modelo at Quantization** - Advanced na pag-optimize gamit ang 6 na framework kabilang ang OpenVINO  
5. **SLMOps - Mga Operasyon ng Small Language Model** - Pamamahala sa lifecycle ng produksyon at deployment  
6. **Mga Sistemang Agentic ng SLM** - AI agents, function calling, at Model Context Protocol  
7. **Mga Halimbawa ng Implementasyon ng EdgeAI** - AI Toolkit, Windows development, at mga implementasyon na partikular sa platform  
8. **Microsoft Foundry Local â€“ Kumpletong Toolkit ng Developer** - Lokal na unang development na may hybrid Azure integration (Module 08)

## Paano Gamitin ang Gabay sa Pag-aaral na Ito

- **Progressive Learning**: Sundin ang mga module nang sunod-sunod para sa pinakakohesibong karanasan sa pag-aaral  
- **Knowledge Checkpoints**: Gamitin ang mga tanong sa self-assessment pagkatapos ng bawat seksyon  
- **Hands-on Practice**: Kumpletuhin ang mga mungkahing ehersisyo upang mapalakas ang mga teoretikal na konsepto  
- **Supplementary Resources**: Galugarin ang mga karagdagang materyales para sa mga paksang pinaka-interesado ka  

## Mga Rekomendasyon sa Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 0 | Module 0: Panimula sa EdgeAI | 1-2 oras |
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 6 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 8 oras |
| Araw 5 | Module 3: Deployment ng SLM | 3 oras |
| Araw 6 | Module 8: Foundry Local Toolkit | 3 oras |

### Part-time na Pag-aaral (3 linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 0: Panimula + Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 7-9 oras |
| Linggo 2 | Module 2: Mga Batayan ng SLM | 7-8 oras |
| Linggo 3 | Module 3: Deployment ng SLM (3h) + Module 8: Foundry Local Toolkit (2-3h) | 5-6 oras |

## Module 0: Panimula sa EdgeAI

### Mga Layunin sa Pag-aaral

- Maunawaan kung ano ang Edge AI at bakit ito mahalaga sa kasalukuyang teknolohikal na landscape  
- Tukuyin ang mga pangunahing industriya na binago ng Edge AI at ang kanilang mga partikular na use case  
- Maunawaan ang mga benepisyo ng Small Language Models (SLMs) para sa edge deployment  
- Magtakda ng malinaw na mga inaasahan sa pag-aaral at mga resulta para sa buong kurso  
- Kilalanin ang mga oportunidad sa karera at mga kinakailangang kasanayan sa larangan ng Edge AI  

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Paradigm at Depinisyon ng Edge AI
- **Mga Prayoridad na Konsepto**:  
  - Edge AI vs. tradisyunal na cloud AI processing  
  - Ang pagsasanib ng hardware, pag-optimize ng modelo, at mga pangangailangan sa negosyo  
  - Real-time, privacy-preserving, at cost-efficient na AI deployment  

#### Seksyon 2: Mga Aplikasyon sa Industriya
- **Mga Prayoridad na Konsepto**:  
  - Manufacturing & Industry 4.0: Predictive maintenance at quality control  
  - Healthcare: Diagnostic imaging at patient monitoring  
  - Autonomous Systems: Mga self-driving na sasakyan at transportasyon  
  - Smart Cities: Pamamahala ng trapiko at pampublikong kaligtasan  
  - Consumer Technology: Mga smartphone, wearables, at smart homes  

#### Seksyon 3: Pundasyon ng Small Language Models
- **Mga Prayoridad na Konsepto**:  
  - Mga katangian ng SLM at mga paghahambing sa performance  
  - Trade-offs sa parameter efficiency vs. capability  
  - Mga limitasyon sa edge deployment at mga estratehiya sa pag-optimize  

#### Seksyon 4: Framework ng Pag-aaral at Landas ng Karera
- **Mga Prayoridad na Konsepto**:  
  - Arkitektura ng kurso at progresibong approach sa mastery  
  - Mga teknikal na kasanayan at layunin sa praktikal na implementasyon  
  - Mga oportunidad sa karera at aplikasyon sa industriya  

### Mga Tanong sa Self-Assessment

1. Ano ang tatlong pangunahing teknolohikal na trend na nagbigay-daan sa Edge AI?  
2. Ihambing ang mga benepisyo at hamon ng Edge AI vs. cloud-based AI.  
3. Magbigay ng tatlong industriya kung saan nagbibigay ang Edge AI ng mahalagang halaga sa negosyo at ipaliwanag kung bakit.  
4. Paano ginagawang praktikal ng Small Language Models ang Edge AI para sa deployment sa totoong mundo?  
5. Ano ang mga pangunahing teknikal na kasanayan na iyong ma-develop sa buong kurso?  
6. Ilarawan ang apat na yugto ng approach sa pag-aaral na ginamit sa kurso.  

### Mga Hands-on na Ehersisyo

1. **Pananaliksik sa Industriya**: Pumili ng isang aplikasyon sa industriya at magsaliksik ng isang totoong implementasyon ng Edge AI (30 minuto)  
2. **Paggalugad ng Modelo**: Mag-browse ng mga available na Small Language Models sa Hugging Face at ihambing ang kanilang parameter counts at capabilities (30 minuto)  
3. **Pagpaplano ng Pag-aaral**: Suriin ang buong istruktura ng kurso at gumawa ng iyong personal na iskedyul ng pag-aaral (15 minuto)  

### Mga Karagdagang Materyales

- [Edge AI Market Overview - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Small Language Models Overview - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Edge Computing Foundation](https://www.edgecomputing.org/)  

## Module 1: Mga Pangunahing Kaalaman at Transformasyon ng EdgeAI

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga pagkakaiba sa pagitan ng cloud-based at edge-based AI  
- Masterin ang mga pangunahing teknik sa pag-optimize para sa mga environment na may limitadong resources  
- Suriin ang mga totoong aplikasyon ng mga teknolohiya ng EdgeAI  
- Mag-set up ng development environment para sa mga proyekto ng EdgeAI  

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Mga Pangunahing Kaalaman sa EdgeAI
- **Mga Prayoridad na Konsepto**:  
  - Paradigm ng Edge vs. Cloud computing  
  - Mga teknik sa model quantization  
  - Mga opsyon sa hardware acceleration (NPUs, GPUs, CPUs)  
  - Mga benepisyo sa privacy at seguridad  

- **Mga Karagdagang Materyales**:  
  - [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)  
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)  
  - [Edge Impulse Documentation](https://docs.edgeimpulse.com)  

#### Seksyon 2: Mga Totoong Case Studies
- **Mga Prayoridad na Konsepto**:  
  - Microsoft Phi & Mu model ecosystem  
  - Mga praktikal na implementasyon sa iba't ibang industriya  
  - Mga konsiderasyon sa deployment  

#### Seksyon 3: Gabay sa Praktikal na Implementasyon
- **Mga Prayoridad na Konsepto**:  
  - Pag-set up ng development environment  
  - Mga tool sa quantization at optimization  
  - Mga pamamaraan sa pagsusuri para sa mga implementasyon ng EdgeAI  

#### Seksyon 4: Hardware para sa Edge Deployment
- **Mga Prayoridad na Konsepto**:  
  - Mga paghahambing ng platform ng hardware  
  - Mga estratehiya sa pag-optimize para sa partikular na hardware  
  - Mga konsiderasyon sa deployment  

### Mga Tanong sa Self-Assessment

1. Ihambing at kontrast ang cloud-based AI sa edge-based AI implementations.  
2. Ipaliwanag ang tatlong pangunahing teknik para sa pag-optimize ng mga modelo para sa edge deployment.  
3. Ano ang mga pangunahing benepisyo ng pagpapatakbo ng mga AI model sa edge?  
4. Ilarawan ang proseso ng pag-quantize ng modelo at kung paano ito nakakaapekto sa performance.  
5. Ipaliwanag kung paano nakakaapekto ang iba't ibang hardware accelerators (NPUs, GPUs, CPUs) sa deployment ng EdgeAI.  

### Mga Hands-on na Ehersisyo

1. **Quick Environment Setup**: Mag-configure ng minimal na development environment gamit ang mga essential na package (30 minuto)  
2. **Paggalugad ng Modelo**: Mag-download at suriin ang isang pre-trained na small language model (1 oras)  
3. **Basic Quantization**: Subukan ang simpleng quantization sa isang maliit na modelo (1 oras)  

## Module 2: Mga Batayan ng Small Language Model

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga prinsipyo ng arkitektura ng iba't ibang pamilya ng SLM  
- Ihambing ang kakayahan ng mga modelo sa iba't ibang parameter scale  
- Suriin ang mga modelo batay sa efficiency, capability, at mga kinakailangan sa deployment  
- Kilalanin ang mga angkop na use case para sa iba't ibang pamilya ng modelo  

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Microsoft Phi Model Family
- **Mga Prayoridad na Konsepto**:  
  - Ebolusyon ng design philosophy  
  - Efficiency-first na arkitektura  
  - Mga espesyal na kakayahan  

#### Seksyon 2: Qwen Family
- **Mga Prayoridad na Konsepto**:  
  - Mga kontribusyon sa open source  
  - Mga opsyon sa scalable deployment  
  - Advanced na arkitektura sa reasoning  

#### Seksyon 3: Gemma Family
- **Mga Prayoridad na Konsepto**:  
  - Innovation na pinangungunahan ng pananaliksik  
  - Multimodal na kakayahan  
  - Mobile optimization  

#### Seksyon 4: BitNET Family
- **Mga Prayoridad na Konsepto**:  
  - Teknolohiya ng 1-bit quantization  
  - Framework ng inference optimization  
  - Mga konsiderasyon sa sustainability  

#### Seksyon 5: Microsoft Mu Model
- **Mga Prayoridad na Konsepto**:  
  - Device-first na arkitektura  
  - System integration sa Windows  
  - Privacy-preserving na operasyon  

#### Seksyon 6: Phi-Silica
- **Mga Prayoridad na Konsepto**:  
  - NPU-optimized na arkitektura  
  - Mga performance metrics  
  - Integrasyon para sa mga developer  

### Mga Tanong sa Self-Assessment

1. Ihambing ang mga arkitektural na approach ng Phi at Qwen model families.  
2. Ipaliwanag kung paano naiiba ang teknolohiya ng quantization ng BitNET sa tradisyunal na quantization.  
3. Ano ang mga natatanging bentahe ng Mu model para sa Windows integration?  
4. Ilarawan kung paano ginagamit ng Phi-Silica ang NPU hardware para sa pag-optimize ng performance.  
5. Para sa isang mobile application na may limitadong koneksyon, aling pamilya ng modelo ang pinakaangkop at bakit?  

### Mga Gawain sa Praktikal  

1. **Paghahambing ng Modelo**: Mabilisang benchmark ng dalawang magkaibang SLM models (1 oras)  
2. **Simpleng Text Generation**: Pangunahing implementasyon ng text generation gamit ang maliit na modelo (1 oras)  
3. **Mabilisang Pag-optimize**: Mag-apply ng isang teknik sa pag-optimize upang mapabilis ang inference (1 oras)  

## Module 3: Deployment ng Small Language Model  

### Pangunahing Layunin ng Pag-aaral  

- Pumili ng angkop na mga modelo batay sa mga limitasyon ng deployment  
- Maging bihasa sa mga teknik sa pag-optimize para sa iba't ibang deployment scenarios  
- Mag-implement ng SLMs sa parehong lokal at cloud na kapaligiran  
- Magdisenyo ng mga production-ready na configuration para sa EdgeAI applications  

### Mga Pokus na Lugar ng Pag-aaral  

#### Seksyon 1: Advanced na Pag-aaral ng SLM  
- **Mga Prayoridad na Konsepto**:  
  - Framework para sa klasipikasyon ng parameter  
  - Mga advanced na teknik sa pag-optimize  
  - Mga estratehiya sa pagkuha ng modelo  

#### Seksyon 2: Deployment sa Lokal na Kapaligiran  
- **Mga Prayoridad na Konsepto**:  
  - Deployment sa Ollama platform  
  - Mga lokal na solusyon ng Microsoft Foundry  
  - Paghahambing ng mga framework  

#### Seksyon 3: Containerized Cloud Deployment  
- **Mga Prayoridad na Konsepto**:  
  - Mataas na performance na inference gamit ang vLLM  
  - Orkestrasyon ng container  
  - Implementasyon ng ONNX Runtime  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Anu-ano ang mga salik na dapat isaalang-alang kapag pumipili sa pagitan ng lokal at cloud deployment?  
2. Ihambing ang Ollama at Microsoft Foundry Local bilang mga opsyon sa deployment.  
3. Ipaliwanag ang mga benepisyo ng containerization para sa deployment ng SLM.  
4. Ano ang mga pangunahing performance metrics na dapat bantayan para sa edge-deployed na SLM?  
5. Ilarawan ang isang kumpletong workflow ng deployment mula sa pagpili ng modelo hanggang sa implementasyon sa produksyon.  

### Mga Gawain sa Praktikal  

1. **Pangunahing Lokal na Deployment**: Mag-deploy ng simpleng SLM gamit ang Ollama (1 oras)  
2. **Pagsusuri ng Performance**: Magpatakbo ng mabilisang benchmark sa iyong na-deploy na modelo (30 minuto)  
3. **Simpleng Integrasyon**: Gumawa ng minimal na application na gumagamit ng iyong na-deploy na modelo (1 oras)  

## Module 4: Pag-convert ng Format ng Modelo at Quantization  

### Pangunahing Layunin ng Pag-aaral  

- Maging bihasa sa mga advanced na teknik sa quantization mula 1-bit hanggang 8-bit precision  
- Maunawaan ang mga estratehiya sa pag-convert ng format (GGUF, ONNX)  
- Mag-implement ng pag-optimize sa anim na framework (Llama.cpp, Olive, OpenVINO, MLX, workflow synthesis)  
- Mag-deploy ng mga optimized na modelo para sa production edge environments sa Intel, Apple, at cross-platform hardware  

### Mga Pokus na Lugar ng Pag-aaral  

#### Seksyon 1: Mga Batayan ng Quantization  
- **Mga Prayoridad na Konsepto**:  
  - Framework para sa klasipikasyon ng precision  
  - Trade-offs sa performance at accuracy  
  - Pag-optimize ng memory footprint  

#### Seksyon 2: Implementasyon ng Llama.cpp  
- **Mga Prayoridad na Konsepto**:  
  - Deployment sa iba't ibang platform  
  - Pag-optimize ng GGUF format  
  - Mga teknik sa hardware acceleration  

#### Seksyon 3: Microsoft Olive Suite  
- **Mga Prayoridad na Konsepto**:  
  - Pag-optimize na aware sa hardware  
  - Deployment na pang-enterprise  
  - Mga automated na workflow sa pag-optimize  

#### Seksyon 4: OpenVINO Toolkit  
- **Mga Prayoridad na Konsepto**:  
  - Pag-optimize para sa Intel hardware  
  - Neural Network Compression Framework (NNCF)  
  - Deployment ng inference sa iba't ibang platform  
  - OpenVINO GenAI para sa deployment ng LLM  

#### Seksyon 5: Apple MLX Framework  
- **Mga Prayoridad na Konsepto**:  
  - Pag-optimize para sa Apple Silicon  
  - Unified memory architecture  
  - LoRA fine-tuning capabilities  

#### Seksyon 6: Workflow Synthesis para sa Edge AI Development  
- **Mga Prayoridad na Konsepto**:  
  - Unified workflow architecture  
  - Decision trees para sa pagpili ng framework  
  - Validation ng production readiness  
  - Mga estratehiya para sa future-proofing  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Ihambing ang mga estratehiya sa quantization sa iba't ibang precision levels (1-bit hanggang 8-bit).  
2. Ipaliwanag ang mga benepisyo ng GGUF format para sa edge deployment.  
3. Paano pinapahusay ng hardware-aware optimization sa Microsoft Olive ang deployment efficiency?  
4. Ano ang mga pangunahing benepisyo ng NNCF ng OpenVINO para sa compression ng modelo?  
5. Ilarawan kung paano ginagamit ng Apple MLX ang unified memory architecture para sa pag-optimize.  
6. Paano nakakatulong ang workflow synthesis sa pagpili ng optimal na mga framework sa pag-optimize?  

### Mga Gawain sa Praktikal  

1. **Quantization ng Modelo**: Mag-apply ng iba't ibang antas ng quantization sa isang modelo at ihambing ang mga resulta (1 oras)  
2. **Pag-optimize gamit ang OpenVINO**: Gamitin ang NNCF upang i-compress ang isang modelo para sa Intel hardware (1 oras)  
3. **Paghahambing ng Framework**: Subukan ang parehong modelo sa tatlong magkaibang optimization frameworks (1 oras)  
4. **Benchmarking ng Performance**: Sukatin ang epekto ng pag-optimize sa inference speed at memory usage (1 oras)  

## Module 5: SLMOps - Small Language Model Operations  

### Pangunahing Layunin ng Pag-aaral  

- Maunawaan ang mga prinsipyo ng lifecycle management ng SLMOps  
- Maging bihasa sa distillation at fine-tuning techniques para sa edge deployment  
- Mag-implement ng mga estratehiya sa production deployment na may monitoring  
- Bumuo ng mga workflow para sa enterprise-grade SLM operations at maintenance  

### Mga Pokus na Lugar ng Pag-aaral  

#### Seksyon 1: Panimula sa SLMOps  
- **Mga Prayoridad na Konsepto**:  
  - Paradigm shift ng SLMOps sa AI operations  
  - Arkitekturang cost-efficient at privacy-first  
  - Estratehikong epekto sa negosyo at mga competitive advantage  

#### Seksyon 2: Model Distillation  
- **Mga Prayoridad na Konsepto**:  
  - Mga teknik sa knowledge transfer  
  - Implementasyon ng two-stage distillation process  
  - Mga workflow ng distillation sa Azure ML  

#### Seksyon 3: Mga Estratehiya sa Fine-Tuning  
- **Mga Prayoridad na Konsepto**:  
  - Parameter-efficient fine-tuning (PEFT)  
  - Mga advanced na pamamaraan tulad ng LoRA at QLoRA  
  - Multi-adapter training at hyperparameter optimization  

#### Seksyon 4: Deployment sa Produksyon  
- **Mga Prayoridad na Konsepto**:  
  - Conversion at quantization ng modelo para sa produksyon  
  - Configuration ng Foundry Local deployment  
  - Benchmarking ng performance at validation ng kalidad  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Paano naiiba ang SLMOps sa tradisyunal na MLOps?  
2. Ipaliwanag ang mga benepisyo ng model distillation para sa edge deployment.  
3. Ano ang mga pangunahing konsiderasyon para sa fine-tuning ng SLMs sa mga kapaligirang may limitadong resources?  
4. Ilarawan ang isang kumpletong pipeline ng deployment para sa edge AI applications.  

### Mga Gawain sa Praktikal  

1. **Pangunahing Distillation**: Gumawa ng mas maliit na modelo mula sa mas malaking teacher model (1 oras)  
2. **Eksperimento sa Fine-Tuning**: I-fine-tune ang isang modelo para sa isang partikular na domain (1 oras)  
3. **Pipeline ng Deployment**: Mag-set up ng pangunahing CI/CD pipeline para sa deployment ng modelo (1 oras)  

## Module 6: SLM Agentic Systems - AI Agents at Function Calling  

### Pangunahing Layunin ng Pag-aaral  

- Bumuo ng matatalinong AI agents para sa edge environments gamit ang Small Language Models  
- Mag-implement ng function calling capabilities gamit ang systematic workflows  
- Maging bihasa sa Model Context Protocol (MCP) integration para sa standardized na interaksyon ng tool  
- Gumawa ng mga sopistikadong agentic systems na may minimal na interbensyon ng tao  

### Mga Pokus na Lugar ng Pag-aaral  

#### Seksyon 1: AI Agents at Mga Batayan ng SLM  
- **Mga Prayoridad na Konsepto**:  
  - Framework para sa klasipikasyon ng agent (reflex, model-based, goal-based, learning agents)  
  - Pagsusuri ng trade-offs sa pagitan ng SLM at LLM  
  - Mga disenyo ng pattern para sa edge-specific agents  
  - Pag-optimize ng resources para sa agents  

#### Seksyon 2: Function Calling sa Small Language Models  
- **Mga Prayoridad na Konsepto**:  
  - Implementasyon ng systematic workflow (intent detection, JSON output, external execution)  
  - Mga implementasyon na partikular sa platform (Phi-4-mini, napiling Qwen models, Microsoft Foundry Local)  
  - Mga advanced na halimbawa (multi-agent collaboration, dynamic tool selection)  
  - Mga konsiderasyon sa produksyon (rate limiting, audit logging, security measures)  

#### Seksyon 3: Model Context Protocol (MCP) Integration  
- **Mga Prayoridad na Konsepto**:  
  - Arkitektura ng protocol at layered system design  
  - Suporta sa multi-backend (Ollama para sa development, vLLM para sa produksyon)  
  - Mga koneksyon sa protocol (STDIO at SSE modes)  
  - Mga aplikasyon sa totoong mundo (web automation, data processing, API integration)  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Ano ang mga pangunahing konsiderasyon sa arkitektura para sa edge AI agents?  
2. Paano pinapahusay ng function calling ang kakayahan ng agents?  
3. Ipaliwanag ang papel ng Model Context Protocol sa komunikasyon ng agent.  

### Mga Gawain sa Praktikal  

1. **Simpleng Agent**: Bumuo ng pangunahing AI agent na may function calling (1 oras)  
2. **MCP Integration**: Mag-implement ng MCP sa isang agent application (30 minuto)  

## Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI  

### Pangunahing Layunin ng Pag-aaral  

- Maging bihasa sa AI Toolkit para sa Visual Studio Code para sa komprehensibong EdgeAI development workflows  
- Magkaroon ng kaalaman sa Windows AI Foundry platform at mga estratehiya sa NPU optimization  
- Mag-implement ng EdgeAI sa iba't ibang hardware platforms at deployment scenarios  
- Bumuo ng production-ready EdgeAI applications na may platform-specific optimizations  

### Mga Pokus na Lugar ng Pag-aaral  

#### Seksyon 1: AI Toolkit para sa Visual Studio Code  
- **Mga Prayoridad na Konsepto**:  
  - Komprehensibong Edge AI development environment sa loob ng VS Code  
  - Model catalog at discovery para sa edge deployment  
  - Lokal na testing, optimization, at agent development workflows  
  - Monitoring ng performance at pagsusuri para sa edge scenarios  

#### Seksyon 2: Gabay sa Windows EdgeAI Development  
- **Mga Prayoridad na Konsepto**:  
  - Komprehensibong overview ng Windows AI Foundry platform  
  - Phi Silica API para sa efficient NPU inference  
  - Computer Vision APIs para sa image processing at OCR  
  - Foundry Local CLI para sa lokal na development at testing  

#### Seksyon 3: Mga Implementasyon na Partikular sa Platform  
- **Mga Prayoridad na Konsepto**:  
  - Deployment sa NVIDIA Jetson Orin Nano (67 TOPS AI performance)  
  - Mga mobile application gamit ang .NET MAUI at ONNX Runtime GenAI  
  - Mga solusyon ng Azure EdgeAI na may cloud-edge hybrid architecture  
  - Windows ML optimization na may universal hardware support  
  - Mga aplikasyon ng Foundry Local na may privacy-focused RAG implementation  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Paano pinapasimple ng AI Toolkit ang EdgeAI development workflow?  
2. Ihambing ang mga estratehiya sa deployment sa iba't ibang hardware platforms.  
3. Ano ang mga benepisyo ng Windows AI Foundry para sa edge development?  
4. Ipaliwanag ang papel ng NPU optimization sa modernong edge AI applications.  
5. Paano ginagamit ng Phi Silica API ang NPU hardware para sa pag-optimize ng performance?  
6. Ihambing ang mga benepisyo ng lokal at cloud deployment para sa mga privacy-sensitive applications.  

### Mga Gawain sa Praktikal  

1. **AI Toolkit Setup**: I-configure ang AI Toolkit at i-optimize ang isang modelo (1 oras)  
2. **Windows AI Foundry**: Gumawa ng simpleng Windows AI application gamit ang Phi Silica API (1 oras)  
3. **Cross-Platform Deployment**: I-deploy ang parehong modelo sa dalawang magkaibang platform (1 oras)  
4. **NPU Optimization**: Subukan ang performance ng NPU gamit ang Windows AI Foundry tools (30 minuto)  

## Module 8: Microsoft Foundry Local â€“ Kompletong Toolkit para sa Developer (Modernized)  

### Pangunahing Layunin ng Pag-aaral  

- I-install at i-configure ang Foundry Local na may modern SDK integration  
- Mag-implement ng advanced multi-agent systems gamit ang coordinator patterns  
- Bumuo ng intelligent model routers na may automatic task-based selection  
- Mag-deploy ng production-ready AI solutions na may komprehensibong monitoring  
- Mag-integrate sa Azure AI Foundry para sa hybrid deployment scenarios  
- Maging bihasa sa modern SDK patterns gamit ang FoundryLocalManager at OpenAI client  

### Mga Pokus na Lugar ng Pag-aaral  

#### Seksyon 1: Modernong Pag-install at Pag-configure  
- **Mga Prayoridad na Konsepto**:  
  - Integration ng FoundryLocalManager SDK  
  - Automatic service discovery at health monitoring  
  - Mga pattern sa configuration batay sa environment  
  - Mga konsiderasyon sa deployment sa produksyon  

#### Seksyon 2: Advanced Multi-Agent Systems  
- **Mga Prayoridad na Konsepto**:  
  - Coordinator pattern gamit ang specialist agents  
  - Espesyalisasyon sa retrieval, reasoning, at execution agents  
  - Mga mekanismo ng feedback loop para sa refinement  
  - Monitoring ng performance at pagsubaybay sa statistics  

#### Seksyon 3: Intelligent Model Routing  
- **Mga Prayoridad na Konsepto**:  
  - Mga algorithm sa keyword-based model selection  
  - Suporta sa maraming modelo (general, reasoning, code, creative)  
  - Configuration ng environment variable para sa flexibility  
  - Health checking ng serbisyo at paghawak ng error  

#### Seksyon 4: Production-Ready Implementation  
- **Mga Prayoridad na Konsepto**:  
  - Komprehensibong paghawak ng error at fallback mechanisms  
  - Monitoring ng request at pagsubaybay sa performance  
  - Mga interactive na halimbawa gamit ang Jupyter notebook na may benchmarks  
  - Mga pattern ng integration sa umiiral na mga aplikasyon  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Paano naiiba ang modernong FoundryLocalManager approach sa manual REST calls?  
2. Ipaliwanag ang coordinator pattern at kung paano nito ino-orchestrate ang specialist agents.  
3. Paano pinipili ng intelligent router ang angkop na modelo batay sa nilalaman ng query?  
4. Ano ang mga pangunahing bahagi ng isang production-ready AI agent system?  
5. Paano mo ipapatupad ang komprehensibong health monitoring para sa Foundry Local services?  
6. Ihambing ang mga benepisyo ng modernized approach kumpara sa tradisyunal na mga pattern ng implementasyon.  

### Mga Gawain sa Praktikal  

1. **Modern SDK Setup**: I-configure ang FoundryLocalManager na may automatic service discovery (30 minuto)  
2. **Multi-Agent System**: Patakbuhin ang advanced coordinator na may specialist agents (30 minuto)  
3. **Intelligent Routing**: Subukan ang model router gamit ang iba't ibang uri ng query (30 minuto)  
4. **Interactive Exploration**: Gamitin ang Jupyter notebooks upang tuklasin ang mga advanced na feature (45 minuto)  
5. **Production Deployment**: Mag-implement ng monitoring at error handling patterns (30 minuto)  
6. **Hybrid Integration**: I-configure ang Azure AI Foundry fallback scenarios (30 minuto)  

## Gabay sa Alokasyon ng Oras  

Upang matulungan kang masulit ang 20-oras na timeline ng kurso, narito ang isang mungkahing breakdown kung paano i-allocate ang iyong oras:  

| Aktibidad | Alokasyon ng Oras | Deskripsyon |  
|----------|----------------|-------------|  
| Pagbabasa ng Core Materials | 9 oras | Pagtuon sa mahahalagang konsepto sa bawat module |  
| Mga Aktibidad na Praktikal | 6 na oras | Praktikal na pagpapatupad ng mahahalagang teknika |
| Pagsusuri sa Sarili | 2 oras | Pagsusuri ng iyong kaalaman sa pamamagitan ng mga tanong at pagninilay |
| Mini-Proyekto | 3 oras | Paglalapat ng kaalaman sa isang maliit na praktikal na proyekto |

### Mga Pangunahing Pokus Batay sa Oras na Magagamit

**Kung mayroon kang 10 oras lamang:**
- Kumpletuhin ang Module 0 (Introduksyon) at Modules 1, 2, at 3 (mga pangunahing konsepto ng EdgeAI)
- Gumawa ng kahit isang praktikal na aktibidad sa bawat module
- Magpokus sa pag-unawa sa mga pangunahing konsepto kaysa sa mga detalye ng pagpapatupad

**Kung maaari kang maglaan ng buong 20 oras:**
- Kumpletuhin ang lahat ng walong module (kasama ang Introduksyon)
- Gawin ang mahahalagang praktikal na aktibidad mula sa bawat module
- Kumpletuhin ang isang mini-proyekto mula sa Module 7
- Tuklasin ang hindi bababa sa 2-3 karagdagang mapagkukunan

**Kung mayroon kang higit sa 20 oras:**
- Kumpletuhin ang lahat ng module (kasama ang Introduksyon) na may detalyadong mga aktibidad
- Gumawa ng maraming mini-proyekto
- Tuklasin ang mga advanced na teknika ng pag-optimize sa Module 4
- Ipatupad ang deployment sa produksyon mula sa Module 5

## Mahahalagang Mapagkukunan

Ang mga maingat na piniling mapagkukunan na ito ay nagbibigay ng pinakamalaking halaga para sa iyong limitadong oras ng pag-aaral:

### Dokumentasyong Dapat Basahin
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Ang pinaka-epektibong tool para sa pag-optimize ng modelo
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Pinakamabilis na paraan para mag-deploy ng SLMs nang lokal
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Sanggunian para sa isang nangungunang edge-optimized na modelo
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Komprehensibong toolkit ng Intel para sa pag-optimize
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrated na EdgeAI development environment
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specific na EdgeAI development platform

### Mga Tool na Nakakatipid ng Oras
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Mabilis na pag-access at pag-deploy ng modelo
- [Gradio](https://www.gradio.app/docs/interface) - Mabilis na pagbuo ng UI para sa mga AI demo
- [Microsoft Olive](https://github.com/microsoft/Olive) - Pinadaling pag-optimize ng modelo
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Epektibong inference gamit ang CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework para sa compression ng neural network
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit para sa deployment ng malalaking language model

## Template para sa Pagsubaybay ng Pag-unlad

Gamitin ang simpleng template na ito upang subaybayan ang iyong pag-unlad sa 20-oras na kurso:

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mahahalagang Natutunan |
|--------|----------------|-------------|---------------|
| Module 0: Introduksyon sa EdgeAI | | | |
| Module 1: Mga Pangunahing Konsepto ng EdgeAI | | | |
| Module 2: Mga Batayan ng SLM | | | |
| Module 3: Deployment ng SLM | | | |
| Module 4: Pag-optimize ng Modelo | | | |
| Module 5: SLMOps | | | |
| Module 6: AI Agents | | | |
| Module 7: Mga Tool sa Pag-develop | | | |
| Module 8: Foundry Local Toolkit | | | |
| Mga Praktikal na Aktibidad | | | |
| Mini-Proyekto | | | |

## Mga Ideya para sa Mini-Proyekto

Isaalang-alang ang pagsasagawa ng isa sa mga proyektong ito upang maisagawa ang mga konsepto ng EdgeAI (bawat isa ay idinisenyo upang tumagal ng 2-4 na oras):

### Mga Proyekto para sa Baguhan (2-3 oras bawat isa)
1. **Edge Text Assistant**: Gumawa ng simpleng offline na tool para sa text completion gamit ang isang maliit na language model
2. **Dashboard para sa Paghahambing ng Modelo**: Bumuo ng basic na visualization ng mga performance metrics sa iba't ibang SLMs
3. **Eksperimento sa Pag-optimize**: Sukatin ang epekto ng iba't ibang antas ng quantization sa parehong base model

### Mga Proyekto para sa Intermediate (3-4 oras bawat isa)
4. **Workflow ng AI Toolkit**: Gamitin ang VS Code AI Toolkit upang i-optimize at i-deploy ang isang modelo mula simula hanggang matapos
5. **Application ng Windows AI Foundry**: Gumawa ng Windows app gamit ang Phi Silica API at NPU optimization
6. **Cross-Platform Deployment**: I-deploy ang parehong optimized na modelo sa Windows (OpenVINO) at mobile (.NET MAUI)
7. **Agent na Tumatawag ng Function**: Bumuo ng AI agent na may kakayahang tumawag ng function para sa edge scenarios

### Mga Proyekto para sa Advanced na Integrasyon (4-5 oras bawat isa)
8. **Pipeline para sa Pag-optimize ng OpenVINO**: Ipatupad ang kumpletong pag-optimize ng modelo gamit ang NNCF at GenAI toolkit
9. **SLMOps Pipeline**: Ipatupad ang kumpletong lifecycle ng modelo mula sa training hanggang sa edge deployment
10. **Multi-Model Edge System**: I-deploy ang maraming specialized na modelo na nagtutulungan sa edge hardware
11. **MCP Integration System**: Bumuo ng agentic system gamit ang Model Context Protocol para sa tool interaction

## Mga Sanggunian

- Microsoft Learn (Foundry Local)
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Get started: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI reference: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrate with inference SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI how-to: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compile Hugging Face models: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agents (overview): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimization and Inference Tooling
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (getting started): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html
- Deployment Frameworks and Models
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (docs): https://docs.vllm.ai/
  - Ollama (quick start): https://github.com/ollama/ollama#get-started
- Developer Tools (Windows and VS Code)
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (overview): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Komunidad ng Pag-aaral

Sumali sa talakayan at makipag-ugnayan sa kapwa mga nag-aaral:
- GitHub Discussions sa [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Konklusyon

Ang EdgeAI ay kumakatawan sa hangganan ng pagpapatupad ng artificial intelligence, na nagdadala ng makapangyarihang kakayahan nang direkta sa mga device habang tinutugunan ang mahahalagang isyu tulad ng privacy, latency, at connectivity. Ang 20-oras na kursong ito ay nagbibigay sa iyo ng mahahalagang kaalaman at praktikal na kasanayan upang agad na magsimula sa paggamit ng mga teknolohiya ng EdgeAI.

Ang kurso ay sadyang maikli at nakatuon sa pinakamahalagang konsepto, na nagbibigay-daan sa iyo upang mabilis na makakuha ng mahalagang kadalubhasaan nang hindi nangangailangan ng labis na oras. Tandaan na ang praktikal na pagsasanay, kahit na sa mga simpleng halimbawa, ang susi sa pagpapalakas ng iyong natutunan.

Masayang pag-aaral!

---

