<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ab6b3d55f53ea3d498b3c067b17f8816",
  "translation_date": "2025-09-18T15:08:22+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "tl"
}
-->
# AI Toolkit para sa Visual Studio Code - Gabay sa Pag-develop ng Edge AI

## Panimula

Maligayang pagdating sa komprehensibong gabay para sa paggamit ng AI Toolkit para sa Visual Studio Code sa pag-develop ng Edge AI. Habang ang artificial intelligence ay lumilipat mula sa centralized cloud computing patungo sa distributed edge devices, kailangan ng mga developer ng makapangyarihan at integrated na mga tool na kayang tugunan ang mga natatanging hamon ng edge deployment - mula sa limitadong resources hanggang sa mga pangangailangan para sa offline na operasyon.

Ang AI Toolkit para sa Visual Studio Code ay nagtataguyod ng tulay sa pagitan ng mga hamong ito sa pamamagitan ng pagbibigay ng kumpletong development environment na partikular na dinisenyo para sa pagbuo, pagsubok, at pag-optimize ng mga AI application na epektibong tumatakbo sa edge devices. Kung ikaw ay nagde-develop para sa IoT sensors, mobile devices, embedded systems, o edge servers, pinadadali ng toolkit na ito ang buong workflow ng pag-develop sa loob ng pamilyar na VS Code environment.

Ang gabay na ito ay magdadala sa iyo sa mahahalagang konsepto, mga tool, at pinakamahusay na mga kasanayan para sa paggamit ng AI Toolkit sa iyong mga Edge AI proyekto, mula sa pagpili ng modelo hanggang sa deployment sa produksyon.

## Pangkalahatang-ideya

Ang AI Toolkit ay nagbibigay ng integrated development environment para sa buong lifecycle ng Edge AI application sa loob ng VS Code. Nag-aalok ito ng seamless integration sa mga sikat na AI models mula sa mga provider tulad ng OpenAI, Anthropic, Google, at GitHub, habang sinusuportahan ang lokal na deployment ng modelo sa pamamagitan ng ONNX at Ollama - mga mahalagang kakayahan para sa Edge AI applications na nangangailangan ng on-device inference.

Ang natatanging aspeto ng AI Toolkit para sa Edge AI development ay ang pokus nito sa buong edge deployment pipeline. Hindi tulad ng tradisyunal na AI development tools na pangunahing nakatuon sa cloud deployment, ang AI Toolkit ay may mga espesyal na tampok para sa model optimization, resource-constrained testing, at edge-specific performance evaluation. Nauunawaan ng toolkit na ang Edge AI development ay nangangailangan ng iba't ibang konsiderasyon - mas maliit na laki ng modelo, mas mabilis na inference times, offline capability, at hardware-specific optimizations.

Sinusuportahan ng platform ang iba't ibang deployment scenarios, mula sa simpleng on-device inference hanggang sa masalimuot na multi-model edge architectures. Nagbibigay ito ng mga tool para sa model conversion, quantization, at optimization na mahalaga para sa matagumpay na edge deployment, habang pinapanatili ang produktibidad ng developer na kilala sa VS Code.

## Mga Layunin sa Pag-aaral

Sa pagtatapos ng gabay na ito, magagawa mo ang sumusunod:

### Pangunahing Kakayahan
- **I-install at i-configure** ang AI Toolkit para sa Visual Studio Code para sa Edge AI development workflows
- **Mag-navigate at gumamit** ng AI Toolkit interface, kabilang ang Model Catalog, Playground, at Agent Builder
- **Pumili at mag-evaluate** ng AI models na angkop para sa edge deployment batay sa performance at resource constraints
- **Mag-convert at mag-optimize** ng mga modelo gamit ang ONNX format at quantization techniques para sa edge devices

### Mga Kasanayan sa Edge AI Development
- **Magdisenyo at magpatupad** ng Edge AI applications gamit ang integrated development environment
- **Magsagawa ng model testing** sa edge-like conditions gamit ang local inference at resource monitoring
- **Lumikha at mag-customize** ng AI agents na optimized para sa edge deployment scenarios
- **Mag-evaluate ng model performance** gamit ang mga metrics na nauugnay sa edge computing (latency, memory usage, accuracy)

### Optimization at Deployment
- **Mag-apply ng quantization at pruning** techniques para mabawasan ang laki ng modelo habang pinapanatili ang katanggap-tanggap na performance
- **Mag-optimize ng mga modelo** para sa partikular na edge hardware platforms kabilang ang CPU, GPU, at NPU acceleration
- **Magpatupad ng pinakamahusay na kasanayan** para sa Edge AI development kabilang ang resource management at fallback strategies
- **Ihanda ang mga modelo at application** para sa production deployment sa edge devices

### Advanced Edge AI Concepts
- **Mag-integrate sa edge AI frameworks** kabilang ang ONNX Runtime, Windows ML, at TensorFlow Lite
- **Magpatupad ng multi-model architectures** at federated learning scenarios para sa edge environments
- **Mag-troubleshoot ng karaniwang edge AI issues** kabilang ang memory constraints, inference speed, at hardware compatibility
- **Magdisenyo ng monitoring at logging** strategies para sa Edge AI applications sa produksyon

### Praktikal na Aplikasyon
- **Magbuo ng end-to-end Edge AI solutions** mula sa pagpili ng modelo hanggang sa deployment
- **Magpakita ng kasanayan** sa edge-specific development workflows at optimization techniques
- **I-apply ang mga natutunang konsepto** sa mga real-world edge AI use cases kabilang ang IoT, mobile, at embedded applications
- **Mag-evaluate at magkumpara** ng iba't ibang edge AI deployment strategies at ang kanilang trade-offs

## Mga Pangunahing Tampok para sa Edge AI Development

### 1. Model Catalog at Discovery
- **Suporta sa Lokal na Modelo**: Tuklasin at i-access ang mga AI models na partikular na optimized para sa edge deployment
- **ONNX Integration**: I-access ang mga modelo sa ONNX format para sa efficient edge inference
- **Ollama Support**: Gamitin ang locally-running models sa pamamagitan ng Ollama para sa privacy at offline operation
- **Model Comparison**: Ikumpara ang mga modelo upang mahanap ang pinakamainam na balanse sa pagitan ng performance at resource consumption para sa edge devices

### 2. Interactive Playground
- **Lokal na Testing Environment**: Subukan ang mga modelo nang lokal bago ang edge deployment
- **Multi-modal Experimentation**: Subukan gamit ang mga imahe, teksto, at iba pang inputs na karaniwan sa edge scenarios
- **Parameter Tuning**: Mag-eksperimento sa iba't ibang model parameters para ma-optimize para sa edge constraints
- **Real-time Performance Monitoring**: Obserbahan ang inference speed at resource usage habang nagde-develop

### 3. Agent Builder para sa Edge Applications
- **Prompt Engineering**: Lumikha ng optimized prompts na epektibong gumagana sa mas maliit na edge models
- **MCP Tool Integration**: I-integrate ang Model Context Protocol tools para sa mas pinahusay na edge agent capabilities
- **Code Generation**: Bumuo ng production-ready code na optimized para sa edge deployment scenarios
- **Structured Outputs**: Magdisenyo ng agents na nagbibigay ng consistent, structured responses na angkop para sa edge applications

### 4. Model Evaluation at Testing
- **Performance Metrics**: I-evaluate ang mga modelo gamit ang metrics na nauugnay sa edge deployment (latency, memory usage, accuracy)
- **Batch Testing**: Subukan ang maraming model configurations nang sabay-sabay upang mahanap ang optimal edge settings
- **Custom Evaluation**: Lumikha ng custom evaluation criteria na partikular sa edge AI use cases
- **Resource Profiling**: Suriin ang memory at computational requirements para sa edge deployment planning

### 5. Model Conversion at Optimization
- **ONNX Conversion**: I-convert ang mga modelo mula sa iba't ibang format patungo sa ONNX para sa edge compatibility
- **Quantization**: Bawasan ang laki ng modelo at pagbutihin ang inference speed sa pamamagitan ng quantization techniques
- **Hardware Optimization**: I-optimize ang mga modelo para sa partikular na edge hardware (CPU, GPU, NPU)
- **Format Transformation**: I-transform ang mga modelo mula sa Hugging Face at iba pang sources para sa edge deployment

### 6. Fine-tuning para sa Edge Scenarios
- **Domain Adaptation**: I-customize ang mga modelo para sa partikular na edge use cases at environments
- **Local Training**: Mag-train ng mga modelo nang lokal gamit ang GPU support para sa edge-specific requirements
- **Azure Integration**: Gamitin ang Azure Container Apps para sa cloud-based fine-tuning bago ang edge deployment
- **Transfer Learning**: I-adapt ang pre-trained models para sa edge-specific tasks at constraints

### 7. Performance Monitoring at Tracing
- **Edge Performance Analysis**: I-monitor ang performance ng modelo sa edge-like conditions
- **Trace Collection**: Kolektahin ang detalyadong performance data para sa optimization
- **Bottleneck Identification**: Tukuyin ang mga performance issues bago ang deployment sa edge devices
- **Resource Usage Tracking**: I-monitor ang memory, CPU, at inference time para sa edge optimization

## Workflow ng Edge AI Development

### Phase 1: Model Discovery at Selection
1. **I-explore ang Model Catalog**: Gamitin ang model catalog upang mahanap ang mga modelo na angkop para sa edge deployment
2. **Ikumpara ang Performance**: I-evaluate ang mga modelo batay sa laki, accuracy, at inference speed
3. **Subukan nang Lokal**: Gamitin ang Ollama o ONNX models upang subukan nang lokal bago ang edge deployment
4. **Suriin ang Resource Requirements**: Tukuyin ang memory at computational needs para sa target edge devices

### Phase 2: Model Optimization
1. **I-convert sa ONNX**: I-convert ang napiling mga modelo sa ONNX format para sa edge compatibility
2. **Mag-apply ng Quantization**: Bawasan ang laki ng modelo sa pamamagitan ng INT8 o INT4 quantization
3. **Hardware Optimization**: I-optimize para sa target edge hardware (ARM, x86, specialized accelerators)
4. **Performance Validation**: Siguraduhing ang optimized models ay may katanggap-tanggap na accuracy

### Phase 3: Application Development
1. **Agent Design**: Gamitin ang Agent Builder upang lumikha ng edge-optimized AI agents
2. **Prompt Engineering**: Bumuo ng prompts na epektibong gumagana sa mas maliit na edge models
3. **Integration Testing**: Subukan ang agents sa simulated edge conditions
4. **Code Generation**: Bumuo ng production code na optimized para sa edge deployment

### Phase 4: Evaluation at Testing
1. **Batch Evaluation**: Subukan ang maraming configurations upang mahanap ang optimal edge settings
2. **Performance Profiling**: Suriin ang inference speed, memory usage, at accuracy
3. **Edge Simulation**: Subukan sa mga kondisyon na katulad ng target edge deployment environment
4. **Stress Testing**: I-evaluate ang performance sa ilalim ng iba't ibang load conditions

### Phase 5: Deployment Preparation
1. **Final Optimization**: Mag-apply ng huling optimizations batay sa testing results
2. **Deployment Packaging**: I-package ang mga modelo at code para sa edge deployment
3. **Documentation**: I-dokumenta ang deployment requirements at configuration
4. **Monitoring Setup**: Ihanda ang monitoring at logging para sa edge deployment

## Target Audience para sa Edge AI Development

### Edge AI Developers
- Mga application developers na gumagawa ng AI-powered edge devices at IoT solutions
- Mga embedded systems developers na nag-iintegrate ng AI capabilities sa resource-constrained devices
- Mga mobile developers na gumagawa ng on-device AI applications para sa smartphones at tablets

### Edge AI Engineers
- Mga AI engineers na nag-o-optimize ng mga modelo para sa edge deployment at nagma-manage ng inference pipelines
- Mga DevOps engineers na nagde-deploy at nagma-manage ng AI models sa distributed edge infrastructure
- Mga performance engineers na nag-o-optimize ng AI workloads para sa edge hardware constraints

### Researchers at Educators
- Mga AI researchers na gumagawa ng efficient models at algorithms para sa edge computing
- Mga educators na nagtuturo ng edge AI concepts at nagpapakita ng optimization techniques
- Mga estudyante na nag-aaral tungkol sa mga hamon at solusyon sa edge AI deployment

## Mga Edge AI Use Cases

### Smart IoT Devices
- **Real-time Image Recognition**: Mag-deploy ng computer vision models sa IoT cameras at sensors
- **Voice Processing**: Magpatupad ng speech recognition at natural language processing sa smart speakers
- **Predictive Maintenance**: Magpatakbo ng anomaly detection models sa industrial edge devices
- **Environmental Monitoring**: Mag-deploy ng sensor data analysis models para sa environmental applications

### Mobile at Embedded Applications
- **On-device Translation**: Magpatupad ng language translation models na gumagana offline
- **Augmented Reality**: Mag-deploy ng real-time object recognition at tracking para sa AR applications
- **Health Monitoring**: Magpatakbo ng health analysis models sa wearable devices at medical equipment
- **Autonomous Systems**: Magpatupad ng decision-making models para sa drones, robots, at vehicles

### Edge Computing Infrastructure
- **Edge Data Centers**: Mag-deploy ng AI models sa edge data centers para sa low-latency applications
- **CDN Integration**: Mag-integrate ng AI processing capabilities sa content delivery networks
- **5G Edge**: Gamitin ang 5G edge computing para sa AI-powered applications
- **Fog Computing**: Magpatupad ng AI processing sa fog computing environments

## Pag-install at Setup

### Mabilis na Pag-install
I-install ang AI Toolkit extension direkta mula sa Visual Studio Code Marketplace:

```
Install: AI Toolkit for Visual Studio Code (ms-windows-ai-studio.windows-ai-studio)
```

### Mga Kinakailangan para sa Edge AI Development
- **ONNX Runtime**: I-install ang ONNX Runtime para sa model inference
- **Ollama** (Opsyonal): I-install ang Ollama para sa lokal na model serving
- **Python Environment**: I-set up ang Python na may kinakailangang AI libraries
- **Edge Hardware Tools**: I-install ang hardware-specific development tools (CUDA, OpenVINO, atbp.)

### Paunang Configuration
1. Buksan ang VS Code at i-install ang AI Toolkit extension
2. I-configure ang model sources (ONNX, Ollama, cloud providers)
3. I-set up ang lokal na development environment para sa edge testing
4. I-configure ang hardware acceleration options para sa iyong development machine

## Pagsisimula sa Edge AI Development

### Hakbang 1: Model Selection
1. Buksan ang AI Toolkit view sa Activity Bar
2. I-browse ang Model Catalog para sa edge-compatible models
3. I-filter batay sa laki ng modelo, format (ONNX), at performance characteristics
4. Ikumpara ang mga modelo gamit ang built-in comparison tools

### Hakbang 2: Lokal na Pagsubok
1. Gamitin ang Playground upang subukan ang napiling mga modelo nang lokal
2. Mag-eksperimento sa iba't ibang prompts at parameters
3. I-monitor ang performance metrics habang nagte-test
4. I-evaluate ang model responses para sa edge use case requirements

### Hakbang 3: Model Optimization
1. Gamitin ang Model Conversion tools upang ma-optimize para sa edge deployment
2. Mag-apply ng quantization upang mabawasan ang laki ng modelo
3. Subukan ang optimized models upang matiyak ang katanggap-tanggap na performance
4. I-dokumenta ang optimization settings at performance trade-offs

### Hakbang 4: Agent Development
1. Gamitin ang Agent Builder upang lumikha ng edge-optimized AI agents
2. Bumuo ng prompts na epektibong gumagana sa mas maliit na mga modelo
3. I-integrate ang kinakailangang tools at APIs para sa edge scenarios
4. Subukan ang agents sa simulated edge conditions

### Hakbang 5: Evaluation at Deployment
1. Gamitin ang bulk evaluation upang subukan ang maraming configurations
2. I-profile ang performance sa ilalim ng iba't ibang kondisyon
3. Ihanda ang deployment packages para sa target edge devices
4. I-set up ang monitoring at logging para sa production deployment

## Mga Pinakamahusay na Kasanayan para sa Edge AI Development

### Model Selection
- **Size Constraints**: Pumili ng mga modelo na kasya sa memory limitations ng target devices
- **Inference Speed**: Bigyang-priyoridad ang mga modelo na may mabilis na inference times para sa real-time applications
- **Accuracy Trade-offs**: Balansehin ang model accuracy sa resource constraints
- **Format Compatibility**: Mas piliin ang ONNX o hardware-optimized formats para sa edge deployment

### Optimization Techniques
- **Quantization**: Gamitin ang INT8 o INT4 quantization upang mabawasan ang laki ng modelo at mapabilis ang speed
- **Pruning**: Alisin ang mga hindi kinakailangang model parameters upang mabawasan ang computational requirements
- **Knowledge Distillation**: Gumawa ng mas maliit na mga modelo na pinapanatili ang performance ng mas malalaking modelo
- **Hardware Acceleration**: Gamitin ang NPUs, GPUs, o specialized accelerators kung available

### Development Workflow
- **Iterative Testing**: Mag-test nang madalas sa edge-like conditions habang nagde-develop
- **Performance Monitoring**: Patuloy na i-monitor ang resource usage at inference speed
- **Version Control**: I-track ang model versions at optimization settings
- **Documentation**: I-dokumenta ang lahat ng optimization decisions at performance trade-offs

### Deployment Considerations
- **Resource Monitoring**: I-monitor ang memory, CPU, at power usage sa produksyon
- **Fallback Strategies**: Magpatupad ng fallback mechanisms para sa model failures
- **Update Mechanisms**: Magplano para sa model updates at version management
- **Seguridad**: Magpatupad ng angkop na mga hakbang sa seguridad para sa mga aplikasyon ng edge AI

## Integrasyon sa Edge AI Frameworks

### ONNX Runtime
- **Pag-deploy sa Iba't Ibang Platform**: I-deploy ang mga ONNX model sa iba't ibang edge platform
- **Pag-optimize ng Hardware**: Gamitin ang hardware-specific optimizations ng ONNX Runtime
- **Suporta sa Mobile**: Gamitin ang ONNX Runtime Mobile para sa mga smartphone at tablet na aplikasyon
- **Integrasyon sa IoT**: I-deploy sa mga IoT device gamit ang magaan na distribusyon ng ONNX Runtime

### Windows ML
- **Windows Devices**: I-optimize para sa mga Windows-based edge device at PC
- **NPU Acceleration**: Gamitin ang Neural Processing Units sa mga Windows device
- **DirectML**: Gamitin ang DirectML para sa GPU acceleration sa Windows platforms
- **Integrasyon sa UWP**: I-integrate sa mga Universal Windows Platform na aplikasyon

### TensorFlow Lite
- **Pag-optimize sa Mobile**: I-deploy ang TensorFlow Lite models sa mga mobile at embedded device
- **Hardware Delegates**: Gamitin ang mga espesyal na hardware delegates para sa acceleration
- **Micro Controllers**: I-deploy sa mga microcontroller gamit ang TensorFlow Lite Micro
- **Suporta sa Iba't Ibang Platform**: I-deploy sa Android, iOS, at embedded Linux systems

### Azure IoT Edge
- **Hybrid ng Cloud-Edge**: Pagsamahin ang cloud training sa edge inference
- **Pag-deploy ng Module**: I-deploy ang mga AI model bilang IoT Edge modules
- **Pamamahala ng Device**: Pamahalaan ang mga edge device at mga update ng model nang remote
- **Telemetry**: Kolektahin ang performance data at mga metric ng model mula sa edge deployments

## Mga Advanced na Edge AI Scenario

### Multi-Model Deployment
- **Model Ensembles**: I-deploy ang maraming model para sa mas mataas na accuracy o redundancy
- **A/B Testing**: Subukan ang iba't ibang model nang sabay-sabay sa mga edge device
- **Dynamic Selection**: Pumili ng model base sa kasalukuyang kondisyon ng device
- **Resource Sharing**: I-optimize ang paggamit ng resources sa maraming deployed na model

### Federated Learning
- **Distributed Training**: Mag-train ng mga model sa maraming edge device
- **Pagpapanatili ng Privacy**: Panatilihin ang training data sa lokal habang ibinabahagi ang mga improvement ng model
- **Collaborative Learning**: Pahintulutan ang mga device na matuto mula sa kolektibong karanasan
- **Koordinasyon ng Edge-Cloud**: I-coordinate ang learning sa pagitan ng edge devices at cloud infrastructure

### Real-time Processing
- **Stream Processing**: I-proseso ang tuloy-tuloy na data streams sa mga edge device
- **Low-latency Inference**: I-optimize para sa minimal na inference latency
- **Batch Processing**: Epektibong i-proseso ang mga batch ng data sa mga edge device
- **Adaptive Processing**: I-adjust ang processing base sa kasalukuyang kakayahan ng device

## Pag-troubleshoot ng Edge AI Development

### Karaniwang Problema
- **Memory Constraints**: Model na masyadong malaki para sa memory ng target device
- **Inference Speed**: Model inference na masyadong mabagal para sa real-time na pangangailangan
- **Pagbaba ng Accuracy**: Ang optimization ay nagdudulot ng hindi katanggap-tanggap na pagbaba ng accuracy ng model
- **Hardware Compatibility**: Model na hindi compatible sa target hardware

### Mga Diskarte sa Debugging
- **Performance Profiling**: Gamitin ang tracing features ng AI Toolkit para matukoy ang mga bottleneck
- **Resource Monitoring**: I-monitor ang memory at CPU usage habang nagde-develop
- **Incremental Testing**: Subukan ang mga optimization nang paunti-unti para ma-isolate ang mga problema
- **Hardware Simulation**: Gamitin ang mga development tool para i-simulate ang target hardware

### Mga Solusyon sa Optimization
- **Mas Agresibong Quantization**: Mag-apply ng mas agresibong quantization techniques
- **Arkitektura ng Model**: Isaalang-alang ang iba't ibang arkitektura ng model na na-optimize para sa edge
- **Pag-optimize ng Preprocessing**: I-optimize ang data preprocessing para sa mga limitasyon ng edge
- **Pag-optimize ng Inference**: Gamitin ang hardware-specific inference optimizations

## Mga Resources at Susunod na Hakbang

### Dokumentasyon
- [AI Toolkit Models Guide](https://code.visualstudio.com/docs/intelligentapps/models)
- [Model Playground Documentation](https://code.visualstudio.com/docs/intelligentapps/playground)
- [ONNX Runtime Documentation](https://onnxruntime.ai/)
- [Windows ML Documentation](https://docs.microsoft.com/en-us/windows/ai/)

### Komunidad at Suporta
- [VS Code AI Toolkit GitHub](https://github.com/microsoft/vscode-ai-toolkit)
- [ONNX Community](https://github.com/onnx/onnx)
- [Edge AI Developer Community](https://docs.microsoft.com/en-us/azure/iot-edge/community)
- [VS Code Extension Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### Mga Learning Resources
- [Edge AI Fundamentals Course](./Module01/README.md)
- [Small Language Models Guide](./Module02/README.md)
- [Edge Deployment Strategies](./Module03/README.md)
- [Windows Edge AI Development](./windowdeveloper.md)

## Konklusyon

Ang AI Toolkit para sa Visual Studio Code ay nagbibigay ng komprehensibong platform para sa Edge AI development, mula sa pagdiskubre at pag-optimize ng model hanggang sa pag-deploy at pag-monitor. Sa pamamagitan ng integrated tools at workflows nito, maaaring epektibong lumikha, mag-test, at mag-deploy ng mga AI application na mahusay na tumatakbo sa mga resource-constrained edge device.

Ang suporta ng toolkit para sa ONNX, Ollama, at iba't ibang cloud providers, kasama ang optimization at evaluation capabilities nito, ay ginagawa itong ideal na pagpipilian para sa Edge AI development. Kung ikaw ay gumagawa ng IoT applications, mobile AI features, o embedded intelligence systems, ang AI Toolkit ay nagbibigay ng mga tools at workflows na kinakailangan para sa matagumpay na Edge AI deployment.

Habang patuloy na umuunlad ang Edge AI, nananatiling nangunguna ang AI Toolkit para sa VS Code, na nagbibigay sa mga developer ng makabagong tools at kakayahan para sa pagbuo ng susunod na henerasyon ng mga intelligent edge application.

---

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama't sinisikap naming maging tumpak, pakitandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na dulot ng paggamit ng pagsasaling ito.