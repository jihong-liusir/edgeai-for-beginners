<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-18T14:15:54+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "tl"
}
-->
# Section02 : Pagtawag ng Function sa Maliit na Mga Modelong Pangwika (SLMs)

## Nilalaman ng Talahanayan
1. [Ano ang Pagtawag ng Function?](../../../Module06)
2. [Paano Gumagana ang Pagtawag ng Function](../../../Module06)
3. [Mga Senaryo ng Aplikasyon](../../../Module06)
4. [Pag-set up ng Pagtawag ng Function gamit ang Phi-4-mini at Ollama](../../../Module06)
5. [Paggamit ng Qwen3 Function Calling](../../../Module06)
6. [Foundry Local Integration](../../../Module06)
7. [Mga Pinakamahusay na Praktika at Pag-aayos ng Problema](../../../Module06)
8. [Mga Advanced na Halimbawa](../../../Module06)

## Ano ang Pagtawag ng Function?

Ang pagtawag ng function ay isang makapangyarihang kakayahan na nagbibigay-daan sa Maliit na Mga Modelong Pangwika (SLMs) na makipag-ugnayan sa mga panlabas na tool, API, at serbisyo. Sa halip na limitado sa kanilang training data, ang SLMs ay maaaring:

- **Kumonekta sa mga panlabas na API** (mga serbisyo ng panahon, database, search engine)
- **Magpatupad ng mga partikular na function** batay sa mga kahilingan ng user
- **Kumuha ng real-time na impormasyon** mula sa iba't ibang mapagkukunan
- **Gumawa ng mga computational na gawain** gamit ang mga espesyal na tool
- **Mag-chain ng maraming operasyon** para sa mas kumplikadong mga workflow

Binabago ng kakayahang ito ang SLMs mula sa pagiging static na mga text generator tungo sa pagiging dynamic na mga AI agent na maaaring magsagawa ng mga tunay na gawain.

## Paano Gumagana ang Pagtawag ng Function

Ang proseso ng pagtawag ng function ay sumusunod sa isang sistematikong workflow:

### 1. Pagsasama ng Tool
- **Mga Panlabas na Tool**: Ang SLMs ay maaaring kumonekta sa mga weather API, database, web services, at iba pang panlabas na sistema
- **Mga Kahulugan ng Function**: Ang bawat tool ay tinutukoy gamit ang mga partikular na parameter, input/output na format, at mga paglalarawan
- **API Compatibility**: Ang mga tool ay isinama sa pamamagitan ng mga standardized na interface (REST APIs, SDKs, atbp.)

### 2. Kahulugan ng Function
Ang mga function ay tinutukoy gamit ang tatlong pangunahing bahagi:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Pagtukoy ng Intent
- **Natural Language Processing**: Sinusuri ng SLM ang input ng user upang maunawaan ang layunin
- **Pag-match ng Function**: Tinutukoy kung aling function(s) ang kailangan upang matugunan ang kahilingan
- **Pagkuha ng Parameter**: Tinutukoy at kinukuha ang mga kinakailangang parameter mula sa mensahe ng user

### 4. Pagbuo ng JSON Output
Ang SLM ay bumubuo ng structured JSON na naglalaman ng:
- Pangalan ng function na tatawagin
- Mga kinakailangang parameter na may tamang halaga
- Konteksto ng pagpapatupad at metadata

### 5. Panlabas na Pagpapatupad
- **Pag-validate ng Parameter**: Tinitiyak na ang lahat ng kinakailangang parameter ay naroroon at tamang naka-format
- **Pagpapatupad ng Function**: Ang application ay nagpapatupad ng tinukoy na function gamit ang mga ibinigay na parameter
- **Pag-aayos ng Error**: Pinamamahalaan ang mga pagkabigo, timeout, at hindi wastong mga tugon

### 6. Pagsasama ng Tugon
- **Pagproseso ng Resulta**: Ang output ng function ay ibinabalik sa SLM
- **Pagsasama ng Konteksto**: Isinasama ng SLM ang mga resulta sa tugon nito
- **Komunikasyon sa User**: Ipinapakita ang impormasyon sa natural, conversational na format

## Mga Senaryo ng Aplikasyon

### Pagkuha ng Data
I-convert ang mga natural na query ng wika sa mga structured API call:
- **"Ipakita ang aking mga kamakailang order"** → Query sa database gamit ang user ID at mga filter ng petsa
- **"Ano ang panahon sa Tokyo?"** → Tawag sa weather API gamit ang parameter ng lokasyon
- **"Hanapin ang mga email mula kay John noong nakaraang linggo"** → Query sa email service gamit ang sender at mga filter ng petsa

### Pagpapatupad ng Operasyon
I-transform ang mga kahilingan ng user sa mga partikular na tawag ng function:
- **"Mag-iskedyul ng meeting bukas ng 2 PM"** → Integration sa Calendar API
- **"Magpadala ng mensahe sa team"** → API ng communication platform
- **"Gumawa ng backup ng aking mga file"** → Operasyon sa file system

### Mga Computational na Gawain
Pangasiwaan ang mga kumplikadong mathematical o logical na operasyon:
- **"Kalkulahin ang compound interest sa $10,000 sa 5% para sa 10 taon"** → Function ng financial calculation
- **"Suriin ang dataset na ito para sa mga trend"** → Mga tool sa statistical analysis
- **"I-optimize ang ruta na ito para sa delivery"** → Mga algorithm sa route optimization

### Mga Workflow sa Pagproseso ng Data
Mag-chain ng maraming tawag ng function para sa mas kumplikadong mga operasyon:
1. **Kumuha ng data** mula sa maraming mapagkukunan
2. **I-parse at i-validate** ang impormasyon
3. **I-transform** ang data sa kinakailangang format
4. **I-store ang mga resulta** sa naaangkop na mga sistema
5. **Gumawa ng mga ulat** o visualizations

### Pagsasama ng UI/UX
Mag-enable ng dynamic na pag-update ng interface:
- **"Ipakita ang data ng benta sa dashboard"** → Pagbuo at pagpapakita ng chart
- **"I-update ang mapa gamit ang mga bagong lokasyon"** → Integration ng geospatial data
- **"I-refresh ang display ng imbentaryo"** → Real-time na synchronization ng data

## Pag-set up ng Pagtawag ng Function gamit ang Phi-4-mini at Ollama

Sinusuportahan ng Phi-4-mini ng Microsoft ang parehong single at parallel na pagtawag ng function sa pamamagitan ng Ollama. Narito kung paano ito i-set up:

### Mga Kinakailangan
- Ollama bersyon 0.5.13 o mas mataas
- Phi-4-mini model (inirerekomenda: `phi4-mini:3.8b-fp16`)

### Mga Hakbang sa Pag-install

#### 1. I-install at Patakbuhin ang Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Gumawa ng Custom na ModelFile Template
Dahil sa kasalukuyang limitasyon sa default na mga template ng Ollama, kailangan mong gumawa ng custom na ModelFile gamit ang sumusunod na template:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Gumawa ng Custom na Model
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Halimbawa ng Single Function Calling

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Halimbawa ng Parallel Function Calling

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Paggamit ng Qwen3 Function Calling

Nag-aalok ang Qwen3 ng advanced na kakayahan sa pagtawag ng function na may mahusay na performance at flexibility. Narito kung paano ito ipatupad:

### Paggamit ng Qwen-Agent Framework

Ang Qwen-Agent ay nagbibigay ng high-level na framework na nagpapadali sa implementasyon ng pagtawag ng function:

#### Pag-install
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Basic Setup

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Custom na Implementasyon ng Function

Maaari ka ring magtukoy ng mga custom na function para sa Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Mga Advanced na Tampok ng Qwen3

#### Pagkontrol sa Thinking Mode
Sinusuportahan ng Qwen3 ang dynamic na switching sa pagitan ng thinking at non-thinking modes:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Multi-step Function Calling
Mahusay ang Qwen3 sa pag-chain ng maraming tawag ng function:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Foundry Local Integration

Ang Foundry Local ng Microsoft ay nagbibigay ng OpenAI-compatible na API para sa pagpapatakbo ng mga modelo nang lokal na may pinahusay na privacy at performance.

### Setup at Pag-install

#### Windows
I-download ang installer mula sa [Foundry Local releases page](https://github.com/microsoft/Foundry-Local/releases) at sundin ang mga tagubilin sa pag-install.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Basic Usage

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Mga Advanced na Tampok ng Foundry Local

#### Pamamahala ng Model
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Optimization ng Performance
Awtomatikong pinipili ng Foundry Local ang pinakamahusay na variant ng modelo para sa iyong hardware:
- **CUDA GPU**: Nagda-download ng GPU-optimized na mga modelo
- **Qualcomm NPU**: Gumagamit ng NPU-accelerated na mga variant
- **CPU-only**: Pinipili ang CPU-optimized na mga modelo

## Mga Pinakamahusay na Praktika at Pag-aayos ng Problema

### Mga Pinakamahusay na Praktika sa Kahulugan ng Function

#### 1. Malinaw at Deskriptibong Pangalan
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Komprehensibong Kahulugan ng Parameter
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Pag-validate ng Input at Pag-aayos ng Error
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Mga Karaniwang Isyu at Solusyon

#### Isyu 1: Hindi Tumatawag ng Function
**Sintomas**: Ang modelo ay tumutugon gamit ang text sa halip na tumawag ng function

**Solusyon**:
1. **Suriin ang paglalarawan ng function**: Tiyaking malinaw na tumutugma ito sa layunin ng user
2. **I-verify ang mga kahulugan ng parameter**: Siguraduhing ang lahat ng kinakailangang parameter ay maayos na tinukoy
3. **I-review ang system prompt**: Isama ang malinaw na mga tagubilin tungkol sa kung kailan gagamit ng mga function
4. **Subukan gamit ang explicit na mga kahilingan**: Halimbawa, "Gamitin ang weather function para makuha ang data para sa London"

#### Isyu 2: Mali ang mga Parameter
**Sintomas**: Tumatawag ng function gamit ang maling o nawawalang mga parameter

**Solusyon**:
1. **Magdagdag ng mga halimbawa ng parameter**: Isama ang mga sample na halaga sa mga paglalarawan ng parameter
2. **Gumamit ng enum constraints**: Limitahan ang mga halaga ng parameter sa mga partikular na opsyon kung maaari
3. **Magpatupad ng fallback values**: Magbigay ng mga default na halaga para sa mga opsyonal na parameter

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Isyu 3: Pagkabigo sa Parallel Function Calling
**Sintomas**: Isa lang ang function na nagpapatupad kapag dapat ay marami

**Solusyon**:
1. **Suriin ang suporta ng modelo**: Tiyaking sinusuportahan ng iyong modelo ang parallel function calling
2. **I-update ang system prompt**: Isama ang "ilang tool" o "maraming tool" sa system message
3. **Gumamit ng naaangkop na bersyon ng modelo**: Inirerekomenda ang Phi-4-mini:3.8b-fp16 para sa Ollama

#### Isyu 4: Mga Isyu sa Template gamit ang Ollama
**Sintomas**: Hindi gumagana ang pagtawag ng function gamit ang default na setup ng Ollama

**Solusyon**:
1. **Gumamit ng custom na ModelFile**: I-apply ang tamang template na ibinigay sa tutorial na ito
2. **I-update ang Ollama**: Siguraduhing gumagamit ka ng bersyon 0.5.13 o mas mataas
3. **Suriin ang model quantization**: Mas mahusay ang mas mataas na antas ng quantization (Q8_0, fp16) kaysa sa heavily quantized na mga bersyon

### Optimization ng Performance

#### 1. Mahusay na Disenyo ng Function
- **Panatilihing nakatuon ang mga function**: Ang bawat function ay dapat may isang malinaw na layunin
- **Bawasan ang mga panlabas na dependency**: Iwasan ang sobrang API calls at network requests
- **Cache ang mga resulta**: I-store ang madalas na hinihinging data para mapabilis ang tugon

#### 2. Batching at Async Operations
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Pamamahala ng Resource
- **Connection pooling**: Gamitin muli ang mga koneksyon sa database at API
- **Rate limiting**: Magpatupad ng tamang rate limiting para sa mga panlabas na API
- **Timeout handling**: Mag-set ng makatwirang timeout para sa lahat ng panlabas na tawag

## Mga Advanced na Halimbawa

### Sistema ng Multi-Agent Collaboration

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Sistema ng Dynamic Tool Selection

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Standard na format ng resulta para sa lahat ng tawag ng function"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Production-ready na AI agent na may komprehensibong kakayahan sa pagtawag ng function"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Irehistro ang mga core business function
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Irehistro ang lahat ng available na business function"""
        
        # CRM Functions
        self.register_function(
            name="get_customer_info",
            description="Kumuha ng impormasyon ng customer mula sa CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # tawag kada minuto
        )
        
        # Sales Functions
        self.register_function(
            name="create_sales_opportunity",
            description="Gumawa ng bagong sales opportunity",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Analytics Functions
        self.register_function(
            name="generate_sales_report",
            description="Gumawa ng ulat ng performance ng benta",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Notification Functions
        self.register_function(
            name="send_notification",
            description="Magpadala ng notification sa mga miyembro ng team",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Irehistro ang bagong function sa agent"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Paumanhin, maaari mo bang ibigay ang nilalaman ng markdown file na nais mong isalin?
"""Isagawa ang isang function na may komprehensibong error handling at pag-log"""
start_time = datetime.now()

try:
    # Siguraduhing umiiral ang function
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Function '{function_name}' hindi natagpuan",
            timestamp=start_time
        )
    
    # Suriin ang rate limits
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Rate limit lumampas para sa function '{function_name}'",
            timestamp=start_time
        )
    
    # Siguraduhin ang mga parameter
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Isagawa ang function
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # I-log ang matagumpay na pagtakbo
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # I-log ang nabigong pagtakbo
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Suriin kung ang tawag sa function ay nasa loob ng rate limits"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # I-reset ang counter kung lumipas na ang isang minuto
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Suriin kung nasa ilalim ng limit
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Siguraduhin ang mga parameter ng function"""
    func_params = self.functions[function_name]['parameters']
    
    # Suriin ang mga kinakailangang parameter
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Missing required parameter: {param_name}"
            )
    
    # Suriin ang mga uri ng parameter at mga limitasyon
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Pag-validate ng uri
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' dapat ay isang string"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' dapat ay isang numero"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' dapat ay isang boolean"
                )
            
            # Pag-validate ng enum
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' dapat ay isa sa: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """I-log ang tawag sa function para sa audit purposes"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Opsyonal na isulat sa external logging system
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Isulat ang log entry sa external logging system"""
    # Ang implementasyon ay depende sa iyong logging infrastructure
    # Halimbawa, magpadala sa ELK stack, CloudWatch, atbp.
    pass

# Mga Implementasyon ng Business Function
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Kunin ang impormasyon ng customer mula sa CRM system"""
    # Simulahin ang database/API call
    await asyncio.sleep(0.1)  # Simulahin ang network delay
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Product A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Product B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """Lumikha ng bagong sales opportunity"""
    # Simulahin ang CRM API call
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """Bumuo ng komprehensibong sales report"""
    # Simulahin ang data aggregation
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'medium', channel: str = 'email') -> Dict:
    """Magpadala ng notification sa tinukoy na channel"""
    # Simulahin ang notification service call
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Kunin ang mga OpenAI-compatible function definitions para sa lahat ng rehistradong function"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Halimbawa ng Paggamit para sa Enterprise Integration
async def enterprise_demo():
    """Ipakita ang kakayahan ng enterprise AI agent"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Halimbawa 1: Pagproseso ng customer inquiry
    print("=== Pagproseso ng Customer Inquiry ===")
    
    # Kunin ang impormasyon ng customer
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Impormasyon ng Customer Nakuha: {result.data['name']}")
        print(f"Execution Time: {result.execution_time:.3f}s")
    
    # Halimbawa 2: Paglikha ng sales opportunity
    print("\n=== Paglikha ng Sales Opportunity ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Opportunity Nilikha: {result.data['opportunity_id']}")
    
    # Halimbawa 3: Batch operations
    print("\n=== Batch Operations ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Bagong opportunity nilikha',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Task {i+1} matagumpay na natapos")
        else:
            print(f"Task {i+1} nabigo: {result.error}")
    
    # Ipakita ang audit log
    print(f"\n=== Audit Log ({len(agent.audit_log)} entries) ===")
    for entry in agent.audit_log[-3:]:  # Ipakita ang huling 3 entries
        print(f"{entry['timestamp']}: {entry['function_name']} - {'SUCCESS' if entry['success'] else 'FAILED'}")

# Patakbuhin ang enterprise demo
# asyncio.run(enterprise_demo())

## Konklusyon

Ang function calling sa Small Language Models ay kumakatawan sa isang pagbabago mula sa static AI assistants patungo sa dynamic, may kakayahang mga ahente na maaaring makipag-ugnayan sa totoong mundo. Ang tutorial na ito ay sumaklaw sa:

### Mga Pangunahing Puntos

1. **Pag-unawa sa Pundasyon**: Ang function calling ay nagbibigay-daan sa SLMs na lumampas sa kanilang training data sa pamamagitan ng pagkonekta sa mga external tools at services.

2. **Kakayahang Ipatupad**: Maraming paraan ang umiiral, mula sa low-level implementations gamit ang custom templates hanggang sa high-level frameworks tulad ng Qwen-Agent at Foundry Local.

3. **Mga Pagsasaalang-alang sa Produksyon**: Ang enterprise deployments ay nangangailangan ng pansin sa error handling, rate limiting, seguridad, at audit logging.

4. **Pag-optimize ng Performance**: Ang tamang disenyo ng function, mahusay na pagtakbo, at matalinong caching ay maaaring makapagpabuti ng response times.

### Mga Direksyon sa Hinaharap

Habang patuloy na umuunlad ang teknolohiya ng SLM, maaari nating asahan:

- **Mas Pinahusay na Function Calling Accuracy**: Mas mahusay na intent detection at parameter extraction
- **Mas Advanced na Parallel Processing**: Mas sopistikadong multi-function orchestration
- **Mas Mahusay na Integration Standards**: Mga standardized protocol para sa tool integration
- **Mas Advanced na Security Features**: Pinahusay na authentication at authorization mechanisms
- **Lumalagong Ecosystem**: Lumalaking library ng pre-built functions at integrations

### Pagsisimula

Upang simulan ang pag-implement ng function calling sa iyong mga proyekto:

1. **Magsimula ng Simple**: Simulan sa mga basic single-function scenarios
2. **Pumili ng Framework**: Pumili sa pagitan ng direct implementation (Ollama/Phi-4) o framework-assisted (Qwen-Agent)
3. **Disenyo ng Functions ng Maayos**: Mag-focus sa malinaw, mahusay na dokumentadong function definitions
4. **Ipatupad ang Error Handling**: Bumuo ng matibay na error handling mula sa simula
5. **Mag-scale ng Dahan-dahan**: Lumipat mula sa simple patungo sa mas kumplikadong scenarios habang nagkakaroon ng karanasan

Ang function calling ay nagbabago sa SLMs mula sa kahanga-hangang text generators patungo sa praktikal na AI agents na may kakayahang lutasin ang mga totoong problema. Sa pamamagitan ng pagsunod sa mga pattern at practices na nakabalangkas sa tutorial na ito, maaari kang bumuo ng makapangyarihan, maaasahang AI systems na lumalampas sa tradisyunal na chat interfaces.

### Mga Resources at Sanggunian
- **Phi-4 Models**: [Hugging Face Collection](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Qwen3 Documentation**: [Official Qwen Documentation](https://qwen.readthedocs.io/)
- **Ollama**: [Official Website](https://ollama.com/)
- **Foundry Local**: [GitHub Repository](https://github.com/microsoft/Foundry-Local)
- **Function Calling Best Practices**: [Hugging Face Guide](https://huggingface.co/docs/hugs/en/guides/function-calling)

Tandaan na ang function calling ay isang patuloy na umuunlad na larangan, at ang pagiging updated sa mga pinakabagong pagbabago sa mga napiling framework at modelo ay makakatulong sa iyo na makabuo ng mas epektibong AI agents.


## ➡️ Ano ang susunod

- [03: Model Context Protocol (MCP) Integration](./03.IntroduceMCP.md)

---

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama't sinisikap naming maging tumpak, tandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na dulot ng paggamit ng pagsasaling ito.