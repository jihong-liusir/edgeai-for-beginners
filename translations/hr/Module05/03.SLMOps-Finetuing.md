<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-19T01:15:02+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "hr"
}
-->
# Odjeljak 3: Fino podešavanje - Prilagodba modela za specifične zadatke

## Sadržaj
1. [Uvod u fino podešavanje](../../../Module05)
2. [Zašto je fino podešavanje važno](../../../Module05)
3. [Vrste finog podešavanja](../../../Module05)
4. [Fino podešavanje s Microsoft Olive](../../../Module05)
5. [Praktični primjeri](../../../Module05)
6. [Najbolje prakse i smjernice](../../../Module05)
7. [Napredne tehnike](../../../Module05)
8. [Evaluacija i praćenje](../../../Module05)
9. [Uobičajeni izazovi i rješenja](../../../Module05)
10. [Zaključak](../../../Module05)

## Uvod u fino podešavanje

**Fino podešavanje** je moćna tehnika strojnog učenja koja uključuje prilagodbu unaprijed treniranog modela za specifične zadatke ili rad s posebnim skupovima podataka. Umjesto treniranja modela od početka, fino podešavanje koristi već stečeno znanje unaprijed treniranog modela i prilagođava ga vašem konkretnom slučaju.

### Što je fino podešavanje?

Fino podešavanje je oblik **prijenosnog učenja** gdje:
- Započinjete s unaprijed treniranim modelom koji je naučio opće obrasce iz velikih skupova podataka
- Prilagođavate unutarnje parametre modela koristeći vaš specifični skup podataka
- Zadržavate vrijedno znanje dok model specijalizirate za vaš zadatak

Zamislite to kao podučavanje vještog kuhara da priprema novu kuhinju - već razumije osnove kuhanja, ali treba naučiti specifične tehnike i okuse za novi stil.

### Ključne prednosti

- **Ušteda vremena**: Znatno brže od treniranja od početka
- **Učinkovitost podataka**: Zahtijeva manje skupove podataka za postizanje dobrih rezultata
- **Isplativost**: Niži zahtjevi za računalnim resursima
- **Bolja izvedba**: Često postiže superiorne rezultate u usporedbi s treniranjem od početka
- **Optimizacija resursa**: Omogućuje pristup moćnoj AI tehnologiji manjim timovima i organizacijama

## Zašto je fino podešavanje važno

### Primjene u stvarnom svijetu

Fino podešavanje je ključno u brojnim scenarijima:

**1. Prilagodba domeni**
- Medicinska AI: Prilagodba općih jezičnih modela medicinskoj terminologiji i kliničkim bilješkama
- Pravna tehnologija: Specijalizacija modela za analizu pravnih dokumenata i pregled ugovora
- Financijske usluge: Prilagodba modela za analizu financijskih izvještaja i procjenu rizika

**2. Specijalizacija zadataka**
- Generiranje sadržaja: Fino podešavanje za specifične stilove pisanja ili tonove
- Generiranje koda: Prilagodba modela za određene programske jezike ili okvire
- Prevođenje: Poboljšanje izvedbe za specifične jezične parove ili tehničke domene

**3. Korporativne primjene**
- Korisnička podrška: Izrada chatbotova koji razumiju terminologiju specifičnu za tvrtku
- Interna dokumentacija: Izrada AI asistenata upoznatih s organizacijskim procesima
- Rješenja specifična za industriju: Razvoj modela koji razumiju žargon i tijekove rada specifične za sektor

## Vrste finog podešavanja

### 1. Potpuno fino podešavanje (Instrukcijsko fino podešavanje)

Kod potpunog finog podešavanja, svi parametri modela se ažuriraju tijekom treniranja. Ovaj pristup:
- Pruža maksimalnu fleksibilnost i potencijal izvedbe
- Zahtijeva značajne računalne resurse
- Rezultira potpuno novom verzijom modela
- Najbolji je za scenarije gdje imate obilje podataka za treniranje i računalne resurse

### 2. Učinkovito fino podešavanje parametara (PEFT)

PEFT metode ažuriraju samo mali podskup parametara, čineći proces učinkovitijim:

#### Low-Rank Adaptation (LoRA)
- Dodaje male trenabilne matrice niskog ranga postojećim težinama
- Znatno smanjuje broj trenabilnih parametara
- Održava izvedbu blizu potpunog finog podešavanja
- Omogućuje jednostavno prebacivanje između različitih prilagodbi

#### QLoRA (Quantized LoRA)
- Kombinira LoRA s tehnikama kvantizacije
- Dodatno smanjuje zahtjeve za memorijom
- Omogućuje fino podešavanje većih modela na potrošačkom hardveru
- Balansira učinkovitost s izvedbom

#### Adapteri
- Umeću male neuronske mreže između postojećih slojeva
- Omogućuju ciljno fino podešavanje dok osnovni model ostaje zamrznut
- Omogućuju modularni pristup prilagodbi modela

### 3. Fino podešavanje specifično za zadatak

Usmjereno na prilagodbu modela za specifične zadatke:
- **Klasifikacija**: Prilagodba modela za zadatke kategorizacije
- **Generiranje**: Optimizacija za stvaranje sadržaja i generiranje teksta
- **Ekstrakcija**: Fino podešavanje za ekstrakciju informacija i prepoznavanje naziva entiteta
- **Sažimanje**: Specijalizacija modela za sažimanje dokumenata

## Fino podešavanje s Microsoft Olive

Microsoft Olive je sveobuhvatan alat za optimizaciju modela koji pojednostavljuje proces finog podešavanja uz pružanje značajki na razini poduzeća.

### Što je Microsoft Olive?

Microsoft Olive je alat otvorenog koda za optimizaciju modela koji:
- Pojednostavljuje tijekove rada finog podešavanja za različite hardverske ciljeve
- Pruža ugrađenu podršku za popularne arhitekture modela (Llama, Phi, Qwen, Gemma)
- Nudi opcije za implementaciju u oblaku i lokalno
- Integrira se besprijekorno s Azure ML i drugim Microsoft AI uslugama
- Podržava automatsku optimizaciju i kvantizaciju

### Ključne značajke

- **Optimizacija prilagođena hardveru**: Automatski optimizira modele za specifični hardver (CPU, GPU, NPU)
- **Podrška za više formata**: Radi s PyTorch, Hugging Face i ONNX modelima
- **Automatizirani tijekovi rada**: Smanjuje ručnu konfiguraciju i pokušaje i pogreške
- **Integracija na razini poduzeća**: Ugrađena podrška za Azure ML i implementacije u oblaku
- **Proširiva arhitektura**: Omogućuje prilagođene tehnike optimizacije

### Instalacija i postavljanje

#### Osnovna instalacija

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Opcionalne ovisnosti

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Provjera instalacije

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Praktični primjeri

### Primjer 1: Osnovno fino podešavanje s Olive CLI

Ovaj primjer pokazuje fino podešavanje malog jezičnog modela za klasifikaciju fraza:

#### Korak 1: Pripremite svoje okruženje

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Korak 2: Fino podesite model

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Korak 3: Optimizirajte za implementaciju

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Primjer 2: Napredna konfiguracija s prilagođenim skupom podataka

#### Korak 1: Pripremite prilagođeni skup podataka

Izradite JSON datoteku sa svojim podacima za treniranje:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Korak 2: Izradite konfiguracijsku datoteku

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Korak 3: Izvršite fino podešavanje

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Primjer 3: QLoRA fino podešavanje za učinkovitost memorije

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Najbolje prakse i smjernice

### Priprema podataka

**1. Kvaliteta podataka iznad količine**
- Prioritet dajte visokokvalitetnim, raznolikim primjerima umjesto velikim količinama loših podataka
- Osigurajte da podaci predstavljaju vaš ciljni slučaj
- Dosljedno čistite i unaprijed obrađujte podatke

**2. Format podataka i predlošci**
- Koristite dosljedno formatiranje u svim primjerima za treniranje
- Izradite jasne predloške ulaz-izlaz koji odgovaraju vašem slučaju
- Uključite odgovarajuće formatiranje instrukcija za modele podešene na instrukcije

**3. Razdvajanje skupa podataka**
- Rezervirajte 10-20% podataka za validaciju
- Održavajte slične distribucije između skupova za treniranje i validaciju
- Razmotrite stratificirano uzorkovanje za zadatke klasifikacije

### Konfiguracija treniranja

**1. Odabir stope učenja**
- Započnite s manjim stopama učenja (1e-5 do 1e-4) za fino podešavanje
- Koristite rasporede stope učenja za bolju konvergenciju
- Pratite krivulje gubitka kako biste prilagodili stope

**2. Optimizacija veličine serije**
- Uravnotežite veličinu serije s dostupnom memorijom
- Koristite akumulaciju gradijenta za veće efektivne veličine serije
- Razmotrite odnos između veličine serije i stope učenja

**3. Trajanje treniranja**
- Pratite metrike validacije kako biste izbjegli pretreniranje
- Koristite rano zaustavljanje kada izvedba validacije stagnira
- Redovito spremajte kontrolne točke za oporavak i analizu

### Odabir modela

**1. Odabir osnovnog modela**
- Odaberite modele unaprijed trenirane na sličnim domenama kad je to moguće
- Razmotrite veličinu modela u odnosu na vaše računalne ograničenja
- Procijenite zahtjeve za licenciranjem za komercijalnu upotrebu

**2. Odabir metode finog podešavanja**
- Koristite LoRA/QLoRA za okruženja s ograničenim resursima
- Odaberite potpuno fino podešavanje kada je maksimalna izvedba ključna
- Razmotrite pristupe temeljene na adapterima za scenarije s više zadataka

### Upravljanje resursima

**1. Optimizacija hardvera**
- Odaberite odgovarajući hardver za veličinu modela i metodu
- Učinkovito koristite GPU memoriju s kontrolom gradijenta
- Razmotrite rješenja temeljena na oblaku za veće modele

**2. Upravljanje memorijom**
- Koristite treniranje s mješovitom preciznošću kad je dostupno
- Implementirajte akumulaciju gradijenta za ograničenja memorije
- Pratite korištenje GPU memorije tijekom treniranja

## Napredne tehnike

### Treniranje s više adaptera

Trenirajte više adaptera za različite zadatke dok dijelite osnovni model:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optimizacija hiperparametara

Implementirajte sustavno podešavanje hiperparametara:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Prilagođene funkcije gubitka

Implementirajte funkcije gubitka specifične za domenu:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluacija i praćenje

### Metrike i evaluacija

**1. Standardne metrike**
- **Točnost**: Ukupna ispravnost za zadatke klasifikacije
- **Perpleksnost**: Mjera kvalitete jezičnog modeliranja
- **BLEU/ROUGE**: Kvaliteta generiranja teksta i sažimanja
- **F1 rezultat**: Uravnotežena preciznost i odziv za klasifikaciju

**2. Metrike specifične za domenu**
- **Referentne vrijednosti specifične za zadatak**: Koristite utvrđene referentne vrijednosti za vašu domenu
- **Ljudska evaluacija**: Uključite procjenu od strane ljudi za subjektivne zadatke
- **Poslovne metrike**: Uskladite s stvarnim poslovnim ciljevima

**3. Postavljanje evaluacije**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Praćenje napretka treniranja

**1. Praćenje gubitka**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Praćenje validacije**
- Pratite gubitak validacije uz gubitak treniranja
- Pratite znakove pretreniranja (gubitak validacije raste dok gubitak treniranja opada)
- Koristite rano zaustavljanje na temelju metrika validacije

**3. Praćenje resursa**
- Pratite korištenje GPU/CPU
- Pratite obrasce korištenja memorije
- Pratite brzinu treniranja i propusnost

## Uobičajeni izazovi i rješenja

### Izazov 1: Pretreniranje

**Simptomi:**
- Gubitak treniranja nastavlja opadati dok gubitak validacije raste
- Velika razlika između izvedbe treniranja i validacije
- Loša generalizacija na nove podatke

**Rješenja:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Izazov 2: Ograničenja memorije

**Rješenja:**
- Koristite kontrolu gradijenta
- Implementirajte akumulaciju gradijenta
- Odaberite metode učinkovite za parametre (LoRA, QLoRA)
- Koristite paralelizam modela za velike modele

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Izazov 3: Sporo treniranje

**Rješenja:**
- Optimizirajte cjevovode za učitavanje podataka
- Koristite treniranje s mješovitom preciznošću
- Implementirajte učinkovite strategije grupiranja
- Razmotrite distribuirano treniranje za velike skupove podataka

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Izazov 4: Loša izvedba

**Koraci dijagnoze:**
1. Provjerite kvalitetu i format podataka
2. Provjerite stopu učenja i trajanje treniranja
3. Procijenite odabir osnovnog modela
4. Pregledajte unaprijed obradu i tokenizaciju

**Rješenja:**
- Povećajte raznolikost podataka za treniranje
- Prilagodite raspored stope učenja
- Isprobajte različite osnovne modele
- Implementirajte tehnike augmentacije podataka

## Zaključak

Fino podešavanje je moćna tehnika koja demokratizira pristup vrhunskim AI mogućnostima. Korištenjem alata poput Microsoft Olive, organizacije mogu učinkovito prilagoditi unaprijed trenirane modele svojim specifičnim potrebama uz optimizaciju za izvedbu i ograničenja resursa.

### Ključne točke

1. **Odaberite pravi pristup**: Odaberite metode finog podešavanja na temelju vaših računalnih resursa i zahtjeva za izvedbom
2. **Kvaliteta podataka je važna**: Uložite u visokokvalitetne, reprezentativne podatke za treniranje
3. **Pratite i iterirajte**: Kontinuirano evaluirajte i poboljšavajte svoje modele
4. **Iskoristite alate**: Koristite okvire poput Olive za pojednostavljenje i optimizaciju procesa
5. **Razmislite o implementaciji**: Planirajte optimizaciju i implementaciju modela od samog početka

## ➡️ Što slijedi

- [04: Implementacija - Model spreman za produkciju](./04.SLMOps.Deployment.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane čovjeka. Ne preuzimamo odgovornost za bilo kakva pogrešna tumačenja ili nesporazume koji proizlaze iz korištenja ovog prijevoda.