<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-19T01:20:00+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "hr"
}
-->
# Odjeljak 4: Implementacija modela spremnog za produkciju

## Pregled

Ovaj detaljni vodič provest će vas kroz cijeli proces implementacije fino podešenih kvantiziranih modela koristeći Foundry Local. Pokrit ćemo konverziju modela, optimizaciju kvantizacije i konfiguraciju implementacije od početka do kraja.

## Preduvjeti

Prije nego što započnete, osigurajte sljedeće:

- ✅ Fino podešen onnx model spreman za implementaciju
- ✅ Windows ili Mac računalo
- ✅ Python 3.10 ili noviji
- ✅ Najmanje 8GB dostupne RAM memorije
- ✅ Foundry Local instaliran na vašem sustavu

## Dio 1: Postavljanje okruženja

### Instalacija potrebnih alata

Otvorite svoj terminal (Command Prompt na Windowsu, Terminal na Macu) i pokrenite sljedeće naredbe redoslijedom:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

⚠️ **Važna napomena**: Također će vam trebati CMake verzija 3.31 ili novija, koju možete preuzeti s [cmake.org](https://cmake.org/download/).

## Dio 2: Konverzija modela i kvantizacija

### Odabir pravog formata

Za fino podešene male jezične modele preporučujemo korištenje **ONNX formata** jer nudi:

- 🚀 Bolju optimizaciju performansi
- 🔧 Hardverski neovisnu implementaciju
- 🏭 Mogućnosti spremne za produkciju
- 📱 Kompatibilnost na više platformi

### Metoda 1: Konverzija jednom naredbom (preporučeno)

Koristite sljedeću naredbu za direktnu konverziju vašeg fino podešenog modela:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**Objašnjenje parametara:**
- `--model_name_or_path`: Putanja do vašeg fino podešenog modela
- `--device cpu`: Koristite CPU za optimizaciju
- `--precision int4`: Koristite INT4 kvantizaciju (otprilike 75% smanjenje veličine)
- `--output_path`: Putanja za izlazni model

### Metoda 2: Pristup putem konfiguracijske datoteke (za napredne korisnike)

Kreirajte konfiguracijsku datoteku nazvanu `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

Zatim pokrenite:

```bash
olive run --config ./finetuned_conversion_config.json
```

### Usporedba opcija kvantizacije

| Preciznost | Veličina datoteke | Brzina inferencije | Kvaliteta modela | Preporučena upotreba |
|------------|-------------------|--------------------|------------------|----------------------|
| FP16       | Osnovna × 0.5     | Brza               | Najbolja         | Hardver visokih performansi |
| INT8       | Osnovna × 0.25    | Vrlo brza          | Dobra            | Uravnotežen izbor |
| INT4       | Osnovna × 0.125   | Najbrža            | Prihvatljiva     | Ograničeni resursi |

💡 **Preporuka**: Započnite s INT4 kvantizacijom za vašu prvu implementaciju. Ako kvaliteta nije zadovoljavajuća, pokušajte s INT8 ili FP16.

## Dio 3: Konfiguracija implementacije u Foundry Local

### Kreiranje konfiguracije modela

Navigirajte do direktorija modela u Foundry Local:

```bash
foundry cache cd ./models/
```

Kreirajte strukturu direktorija za vaš model:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

Kreirajte konfiguracijsku datoteku `inference_model.json` u direktoriju vašeg modela:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### Predlošci konfiguracija specifičnih za model

#### Za modele serije Qwen:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## Dio 4: Testiranje i optimizacija modela

### Provjera instalacije modela

Provjerite može li Foundry Local prepoznati vaš model:

```bash
foundry cache ls
```

Trebali biste vidjeti `your-finetuned-model-int4` na popisu.

### Pokretanje testiranja modela

```bash
foundry model run your-finetuned-model-int4
```

### Benchmarking performansi

Pratite ključne metrike tijekom testiranja:

1. **Vrijeme odgovora**: Mjerite prosječno vrijeme po odgovoru
2. **Potrošnja memorije**: Pratite korištenje RAM-a
3. **Iskorištenost CPU-a**: Provjerite opterećenje procesora
4. **Kvaliteta izlaza**: Procijenite relevantnost i koherentnost odgovora

### Lista za provjeru kvalitete

- ✅ Model odgovara prikladno na upite iz fino podešenog domena
- ✅ Format odgovora odgovara očekivanoj strukturi izlaza
- ✅ Nema curenja memorije tijekom duljeg korištenja
- ✅ Dosljedne performanse za različite duljine ulaza
- ✅ Ispravno rukovanje rubnim slučajevima i nevažećim unosima

## Sažetak

Čestitamo! Uspješno ste završili:

- ✅ Konverziju formata fino podešenog modela
- ✅ Optimizaciju kvantizacije modela
- ✅ Konfiguraciju implementacije u Foundry Local
- ✅ Podešavanje performansi i otklanjanje poteškoća

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane čovjeka. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.