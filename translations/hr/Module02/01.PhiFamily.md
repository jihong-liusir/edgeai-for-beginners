<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:44:59+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "hr"
}
-->
# Odjeljak 1: Osnove obitelji Microsoft Phi modela

Obitelj Microsoft Phi modela predstavlja promjenu paradigme u umjetnoj inteligenciji, pokazujući da kompaktni, učinkoviti modeli mogu postići izvanredne rezultate uz znatno manju potrošnju resursa u usporedbi s tradicionalnim velikim jezičnim modelima. Važno je razumjeti kako obitelj Phi omogućuje snažne AI mogućnosti uz smanjene računalne zahtjeve, istovremeno održavajući visoke performanse u raznim zadacima.

## Resursi za programere

### Azure AI Foundry Model Catalog
Obitelj Phi modela (osim Phi-silica) dostupna je putem [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), što programerima olakšava pristup, prilagodbu i implementaciju ovih modela u njihovim aplikacijama. Katalog pruža jednostavan način za eksperimentiranje s različitim varijantama Phi modela i njihovu integraciju u projekte.

### Azure AI Foundry
Možete implementirati i eksperimentirati s Phi modelima koristeći [Azure AI Foundry](https://ai.azure.com), koji pruža sveobuhvatno okruženje za izgradnju, testiranje i implementaciju AI rješenja uz minimalnu pripremu.

### Foundry Local
Za lokalni razvoj i implementaciju, pogledajte [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), koji omogućuje pokretanje Phi modela na vašem razvojnom računalu uz optimizirane konfiguracije.

### Dokumentacijski resursi
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Uvod

U ovoj lekciji istražit ćemo obitelj Microsoftovih Phi modela i njezine osnovne koncepte. Pokrit ćemo evoluciju obitelji Phi, inovativne metodologije treniranja koje čine Phi modele učinkovitim, ključne varijante u obitelji i praktične primjene u različitim scenarijima.

## Ciljevi učenja

Na kraju ove lekcije moći ćete:

- Razumjeti filozofiju dizajna i evoluciju obitelji Microsoftovih Phi modela.
- Identificirati ključne inovacije koje omogućuju Phi modelima postizanje visokih performansi s manje parametara.
- Prepoznati prednosti i ograničenja različitih varijanti Phi modela.
- Primijeniti znanje o Phi modelima za odabir odgovarajućih varijanti za stvarne scenarije.

## Razumijevanje tradicionalne paradigme AI modela

Tradicionalno, postizanje visokih performansi u obradi prirodnog jezika zahtijevalo je masivne jezične modele s milijardama ili stotinama milijardi parametara. Organizacije obično implementiraju ove modele na moćnim GPU klasterima, pristupajući njihovim mogućnostima putem API sučelja ili specijalizirane hardverske infrastrukture.

Ovaj pristup dobro funkcionira za mnoge aplikacije, ali ima inherentna ograničenja kada je riječ o praktičnim scenarijima implementacije. Konvencionalna metoda uključuje korištenje modela koji zahtijevaju značajne računalne resurse, velike količine memorije i značajnu potrošnju energije. Iako ovaj pristup pruža pristup najnaprednijim mogućnostima, stvara ovisnost o skupom hardveru, uvodi visoke operativne troškove i ograničava fleksibilnost implementacije.

## Izazov učinkovite implementacije AI-a

Potreba za učinkovitijim AI-jem postala je sve važnija u raznim scenarijima. Razmotrite aplikacije koje zahtijevaju lokalnu implementaciju zbog razloga privatnosti, osjetljive implementacije gdje troškovi API-ja u oblaku postaju prohibitivni, scenarije rubnog računalstva s ograničenim hardverskim resursima ili aplikacije u stvarnom vremenu gdje je kašnjenje kritično.

### Ključna ograničenja implementacije

Tradicionalne implementacije velikih modela suočavaju se s nekoliko temeljnih ograničenja koja ograničavaju njihovu praktičnu primjenjivost:

- **Ograničenja troškova**: Visoki računalni troškovi čine kontinuiranu implementaciju skupom za mnoge organizacije.
- **Ograničenja resursa**: Ograničen pristup vrhunskoj GPU infrastrukturi ograničava mogućnosti implementacije.
- **Zahtjevi privatnosti**: Osjetljive aplikacije zahtijevaju lokalnu obradu kako bi se održala privatnost podataka.
- **Osjetljivost na kašnjenje**: Aplikacije u stvarnom vremenu trebaju trenutne odgovore bez kašnjenja zbog povratnog putovanja u oblak.

## Filozofija Microsoftovih Phi modela

Obitelj Microsoftovih Phi modela predstavlja temeljnu promjenu u filozofiji dizajna AI modela, dajući prednost učinkovitosti i praktičnoj implementaciji uz održavanje snažnih performansi. Phi modeli to postižu inovativnim arhitekturama, visokokvalitetnim metodologijama treniranja i specijaliziranim tehnikama optimizacije.

Obitelj Phi obuhvaća različite pristupe dizajnirane za maksimiziranje performansi po parametru, omogućujući implementaciju na standardnom hardveru uz pružanje značajnih AI mogućnosti. Cilj je održati konkurentne performanse uz dramatično smanjenje računalnih zahtjeva, potrošnje memorije i operativnih troškova.

### Temeljna načela dizajna Phi modela

Phi modeli temelje se na nekoliko osnovnih načela koja ih razlikuju od tradicionalnih velikih jezičnih modela:

- **Učinkovitost na prvom mjestu**: Optimizirani za maksimalne performanse po parametru, a ne za apsolutnu veličinu.
- **Kvalitetno treniranje**: Fokus na visokokvalitetnim, kuriranim podacima za treniranje umjesto masivnih skupova podataka.
- **Fleksibilnost implementacije**: Dizajnirani za učinkovito funkcioniranje na raznim hardverskim konfiguracijama.
- **Specijalizirane mogućnosti**: Često optimizirani za specifične zadatke ili domene kako bi se maksimizirala učinkovitost.

## Ključne tehnologije koje omogućuju obitelj Phi modela

### Pristup "udžbeničkog" treniranja

Jedan od najrevolucionarnijih aspekata obitelji Phi je metodologija treniranja "kvalitete udžbenika". Umjesto treniranja na ogromnim količinama nefiltriranih podataka s interneta, Phi modeli koriste pažljivo kurirane, visokokvalitetne edukativne sadržaje dizajnirane za učinkovito podučavanje razmišljanja, matematike, kodiranja i općeg znanja.

Ovaj pristup funkcionira stvaranjem sintetičkih edukativnih sadržaja koji oponašaju visokokvalitetne udžbenike i akademske materijale. Podaci za treniranje posebno su dizajnirani da budu pedagoški zvučni, fokusirajući se na jasna objašnjenja, korak-po-korak razmišljanje i strukturirano predstavljanje znanja.

### Napredno treniranje razmišljanja

Nedavni Phi modeli uključuju sofisticirane metodologije treniranja razmišljanja koje omogućuju složeno višekorakovno rješavanje problema. Te tehnike uključuju:

**Treniranje lanca razmišljanja**: Modeli uče razbijati složene probleme na međukorake razmišljanja, čineći proces rješavanja problema transparentnijim i pouzdanijim.

**Skaliranje tijekom generiranja odgovora**: Modeli generiraju detaljne lance razmišljanja koji koriste dodatne računalne resurse tijekom generiranja odgovora za poboljšanu točnost.

**Treniranje na granici sposobnosti**: Podaci za treniranje pažljivo su odabrani kako bi izazvali model na granici njegovih trenutnih sposobnosti, potičući učenje složenih obrazaca razmišljanja.

### Inovacije u arhitekturi

Obitelj Phi uključuje nekoliko arhitektonskih optimizacija dizajniranih posebno za učinkovitost:

**Učinkovitost parametara**: Pažljivi arhitektonski izbori koji maksimiziraju utjecaj svakog parametra u modelu.

**Multimodalna integracija**: Učinkovita integracija obrade teksta, vizije i govora unutar kompaktnih arhitektura.

**Optimizacija hardvera**: Specijalizirane varijante optimizirane za specifične hardverske platforme i scenarije implementacije.

## Optimizacija hardvera za Phi modele

Moderni okruženja implementacije imaju koristi od učinkovitosti Phi modela na raznim hardverskim konfiguracijama:

### Implementacija optimizirana za CPU

Phi modeli dizajnirani su za učinkovito funkcioniranje na hardveru koji koristi samo CPU, čineći ih dostupnima za implementaciju na standardnoj računalnoj infrastrukturi bez potrebe za specijaliziranim AI akceleratorima.

### GPU ubrzanje

Iako ne zahtijevaju moćne GPU-ove, Phi modeli mogu koristiti dostupne GPU resurse za poboljšane performanse, pružajući fleksibilnost u konfiguracijama implementacije.

### Integracija na rubnim uređajima

Specijalizirane varijante poput Phi-3-Silica optimizirane su za specifične platforme rubnog računalstva, postižući izvanredne metrike učinkovitosti poput 650 tokena u sekundi uz samo 1,5W potrošnje energije.

## Prednosti obitelji Phi modela

### Učinkovitost troškova

Phi modeli dramatično smanjuju operativne troškove zahtijevajući znatno manje računalne infrastrukture uz održavanje konkurentnih performansi. To čini AI dostupnim organizacijama s ograničenim proračunima ili aplikacijama velikog obujma gdje je trošak po upitu važan.

### Fleksibilnost implementacije

Učinkovitost Phi modela omogućuje implementaciju na širokom rasponu hardverskih konfiguracija, od osobnih prijenosnih računala do poslovnih servera, pružajući organizacijama veću fleksibilnost u odabiru AI infrastrukture.

### Privatnost i sigurnost

Učinkovitost Phi modela omogućuje lokalnu implementaciju za aplikacije osjetljive na privatnost, osiguravajući da osjetljivi podaci nikada ne napuštaju kontrolu organizacije, a istovremeno pružaju snažne AI mogućnosti.

### Performanse u stvarnom vremenu

Smanjeni računalni zahtjevi omogućuju brže vrijeme obrade, omogućujući aplikacije u stvarnom vremenu koje zahtijevaju trenutne odgovore bez kompromisa u kvaliteti AI mogućnosti.

### Dostupnost AI-a

Smanjenjem prepreka za implementaciju AI-a, Phi modeli čine napredne AI mogućnosti dostupnima organizacijama s ograničenim resursima, omogućujući manjim timovima i pojedinačnim programerima korištenje sofisticiranog razumijevanja jezika.

## Praktični primjeri i slučajevi upotrebe

Prije nego što se upustimo u tehničku evoluciju, istražimo neke konkretne primjere onoga što Phi modeli mogu postići:

### Primjer matematičkog razmišljanja

Phi-4-mini-reasoning izvrsno rješava matematičke probleme korak po korak. Na primjer, kada se postavi pitanje "Kako riješiti 3*x^2+4*x+5=1?", model pruža detaljne korake razmišljanja:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Primjer podrške za više jezika

Phi-3.5-mini-instruct pokazuje snažne mogućnosti za više jezika u raznim jezicima. Evo primjera formata upita:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Primjer multimodalnih mogućnosti

Phi-4-multimodal može istovremeno obrađivati tekst, slike i govor. Evo nekoliko praktičnih primjena:

**Planiranje putovanja uz unos zvuka:**
Phi-4 Multimodal analizira govor kako bi pomogao u planiranju putovanja u Seattle, pokazujući svoje napredne mogućnosti obrade zvuka i preporuka.

**Rješavanje matematičkih problema iz slika:**
Phi-4 Multimodal rješava složene matematičke probleme putem vizualnih unosa, pokazujući svoju sposobnost obrade i rješavanja jednadžbi prikazanih na slikama.

**Primjer pozivanja funkcija:**
Uz pozivanje funkcija, Phi-4-mini i Phi-4-multimodal mogu proširiti svoje mogućnosti obrade teksta integracijom tražilica, povezivanjem raznih alata i više. Kao što je prikazano, model može dohvatiti informacije o utakmicama Premier lige putem Phi-4-mini, pokazujući svoju sposobnost besprijekorne interakcije s vanjskim izvorima podataka.

### Primjer generiranja koda

Phi-4-multimodal može generirati strukturirani projektni kod na temelju sadržaja slike i danih upita, kao što je prikazano u ovom praktičnom tijeku rada:

1. Prenesite sliku žičanog okvira ili dizajna
2. Pružite kontekst o zahtjevima projekta
3. Model generira kompletne, funkcionalne strukture koda
4. Kod se može prilagoditi na temelju specifičnih okvira ili jezika

### Primjer implementacije na rubnim uređajima

Možemo implementirati kvantizirani model na rubnim uređajima. Kombinacijom Microsoft Olive i ONNX GenAI Runtimea, možemo implementirati Phi-4-mini na Windows, iPhone, Android i drugim uređajima. Ovo je primjer pokretanja na iPhoneu 12 Pro.

Proces implementacije uključuje:
- Kvantizaciju modela za mobilnu optimizaciju
- Integraciju ONNX runtimea za kompatibilnost na više platformi
- Lokalnu obradu bez internetske povezanosti
- Performanse u stvarnom vremenu uz minimalnu potrošnju energije

## Evolucija obitelji Phi modela

### Phi-1 i Phi-2: Temeljni modeli

Rani Phi modeli uspostavili su temeljna načela visokokvalitetnih podataka za treniranje i učinkovitih arhitektura:

- **Phi-1 (1.3B parametara)**: Uveo koncept kuriranih podataka za treniranje za osnovno razumijevanje jezika i generiranje koda.
- **Phi-2 (2.7B parametara)**: Poboljšao sposobnosti razmišljanja putem sintetičkih NLP podataka i pažljivo filtriranog web sadržaja.

### Obitelj Phi-3: Glavna primjena

Serija Phi-3 označila je proboj u SLM mogućnostima s više specijaliziranih varijanti:

- **Phi-3-mini (3.8B parametara)**: Opći jezični zadaci s iznimnom učinkovitošću, nadmašujući modele dvostruko veće veličine.
- **Phi-3-small (7B parametara)**: Napredne performanse koje nadmašuju GPT-3.5 Turbo na raznim mjerilima.
- **Phi-3-medium (14B parametara)**: Performanse na razini poduzeća koje nadmašuju Gemini 1.0 Pro.
- **Phi-3-vision (4.2B parametara)**: Multimodalne mogućnosti za obradu slika i teksta.
- **Phi-3-Silica (3.3B parametara)**: Specijalizirana optimizacija za ugrađenu implementaciju u Windows 11.

### Obitelj Phi-4: Napredno razmišljanje

Najnovija generacija pomiče granice sposobnosti razmišljanja:

- **Phi-4 (14B parametara)**: Specijalizacija za složeno razmišljanje, posebno u matematici.
- **Phi-4-mini (3.8B parametara)**: Poboljšano razmišljanje uz pozivanje funkcija i podršku za dugi kontekst.
- **Phi-4-multimodal**: Istovremena obrada govora, vizije i teksta.
- **Phi-4-reasoning (14B parametara)**: Specijaliziran za složene višekorakovne zadatke razmišljanja.
- **Phi-4-reasoning-plus (14B parametara)**: Poboljšana točnost putem dodatnog učenja pojačanjem.
- **Phi-4-mini-reasoning (3.8B parametara)**: Matematičko razmišljanje optimizirano za ograničena okruženja.

## Primjene Phi modela

### Poslovne aplikacije

Organizacije koriste Phi modele za analizu dokumenata, automatizaciju korisničke podrške, pomoć pri generiranju koda i aplikacije poslovne inteligencije koje zahtijevaju lokalnu implementaciju radi usklađenosti i sigurnosti.

### Mobilno i rubno računalstvo

Mobilne aplikacije koriste Phi modele za prijevod u stvarnom vremenu, inteligentne asistente, generiranje sadržaja i personalizirane preporuke bez potrebe za stalnom internetskom povezanošću.

### Edukacijska tehnologija

Edukacijske platforme koriste Phi modele za personalizirano podučavanje, automatizirano ocjenjivanje, generiranje sadržaja i interaktivna iskustva učenja koja mogu funkcionirati offline ili u okruženjima s niskom povezanošću.

### Zdravstvo i usklađenost

Aplikacije u zdravstvu imaju koristi od sposobnosti Phi modela da lokalno obrađuju osjetljive medicinske podatke, istovremeno pružajući AI-podržanu dijagnostičku pomoć, pra
Obitelj Phi pokazuje da budućnost primjene umjetne inteligencije ne leži samo u izgradnji većih modela, već u razvoju pametnijih, učinkovitijih modela koji mogu učinkovito raditi na raznovrsnim hardverskim okruženjima uz održavanje visokih standarda performansi.

## Primjeri razvoja i integracije

### Brzi početak s Transformers knjižnicom

Evo kako započeti s Phi modelima koristeći Hugging Face Transformers knjižnicu:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Primjer fino podešavanja

Sljedeći primjer pokazuje kako fino podesiti Phi-4-mini-instruct za specifične zadatke:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specijalizirani formati upita

**Za zadatke zaključivanja (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Za matematičke zadatke (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobilna primjena s ONNX-om

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Mjerila performansi i postignuća

Obitelj Phi modela postigla je izvanredne rezultate na raznim mjerilima, često nadmašujući mnogo veće modele:

### Ključni naglasci performansi

**Izvrsnost u matematičkom zaključivanju:**
- Phi-4 postiže 82,5% točnosti na AIME 2025 (kvalifikacije za matematičku olimpijadu)
- Phi-4-reasoning (14B) nadmašuje DeepSeek-R1-Distill-70B (5x veći) na mjerilima zaključivanja
- Phi-4-mini-reasoning (3.8B) usporediv je s modelima dvostruko većim u zadacima matematičkog zaključivanja

**Postignuća u učinkovitosti:**
- Phi-3-Silica postiže 650 tokena u sekundi uz potrošnju od samo 1.5W
- Phi-4-mini (3.8B) postiže slične performanse kao mnogo veći modeli

**Performanse na mjerilima:**
- **MMLU (Masivno višezadaćno razumijevanje jezika)**: Konkurentne performanse u 57 akademskih predmeta
- **HumanEval**: Snažne sposobnosti generiranja koda, posebno u Pythonu
- **MGSM**: Višejezično rješavanje matematičkih problema osnovne škole
- **DROP**: Složeni zadaci razumijevanja i zaključivanja
- **SimpleQA**: Točnost odgovora na činjenična pitanja

### 📊 Matrica usporedbe modela

| Model | Parametri | Duljina konteksta | Ključne prednosti | Najbolje primjene |
|-------|-----------|-------------------|-------------------|-------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Opća učinkovitost | Mobilne aplikacije, osnovni chatbotovi |
| **Phi-3.5-mini** | 3.8B | 128K | Višejezična podrška | Međunarodne aplikacije |
| **Phi-4-mini** | 3.8B | 128K | Poboljšano zaključivanje, pozivanje funkcija | Automatizacija poslovanja |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matematičko zaključivanje | Obrazovne platforme |
| **Phi-4** | 14B | 32K | Složeno zaključivanje | Istraživanje, napredna analiza |
| **Phi-4-reasoning** | 14B | 32K/64K | Višekorak zaključivanje | Znanstveno računalstvo |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimalna točnost zaključivanja | Kritično donošenje odluka |
| **Phi-4-multimodal** | 5.6B | Varijabilno | Govor, vizija, tekst | Multimedijske aplikacije |

## Vodič za odabir modela

### Za osnovne aplikacije
- **Phi-3-mini**: Jednostavno generiranje teksta, osnovna pitanja i odgovori, brzi odgovori
- **Phi-4-mini**: Poboljšano zaključivanje s mogućnostima pozivanja funkcija

### Za matematičke i zadatke zaključivanja
- **Phi-4**: Složeno rješavanje matematičkih problema i zaključivanje
- **Phi-4-reasoning**: Višekorak zaključivanje s detaljnim objašnjenjima
- **Phi-4-reasoning-plus**: Maksimalna točnost za kritične aplikacije zaključivanja
- **Phi-4-mini-reasoning**: Učinkovito matematičko zaključivanje za okruženja s ograničenim resursima

### Za multimodalne aplikacije
- **Phi-3-vision**: Kombinacije obrade slike i teksta
- **Phi-4-multimodal**: Sveobuhvatne mogućnosti govora, vizije i teksta

### Za poslovnu primjenu
- **Phi-3-medium**: Napredno razumijevanje jezika za poslovne aplikacije
- **Phi-3-Silica**: Optimizirano za specifične hardverske platforme

## Platforme za primjenu i dostupnost

### Cloud platforme
- **Azure AI Foundry**: Potpuna primjena s poslovnim alatima
- **Hugging Face**: Repozitorij otvorenog koda i resursi zajednice
- **NVIDIA API Catalog**: Opcije za primjenu mikroservisa

### Okviri za lokalni razvoj
- **Ollama**: Lagani okvir za lokalnu primjenu modela
- **ONNX Runtime**: Optimizirano za razne hardverske konfiguracije  
- **DirectML**: Optimizirane performanse za Windows
- **llama.cpp**: Mehanizam za inferenciju na više platformi

### Resursi za učenje
- **Phi Portal**: Službeni Microsoft Phi dokumentacijski centar
- **Phi Cookbook**: Sveobuhvatni primjeri i vodiči
- **Tehnička izvješća**: Detaljni istraživački radovi na arxivu
- **Prostori zajednice**: Interaktivni demo sadržaji na Hugging Faceu

### Početak rada s Phi modelima

#### Platforme za razvoj
1. **Azure AI Foundry**: Jednostavan lokalni CLI i upravljanje modelima.
2. **Hugging Face Transformers**: Brza lokalna eksperimentacija
3. **Ollama**: Jednostavna lokalna primjena za testiranje

#### Put učenja
1. **Razumijevanje osnovnih pojmova**: Proučite temeljne principe dizajna
2. **Eksperimentiranje s varijantama**: Isprobajte različite Phi modele kako biste razumjeli njihove mogućnosti
3. **Praksa implementacije**: Primijenite modele u testnim okruženjima
4. **Širenje primjene**: Postupno proširite upotrebu na temelju uspješnih pilot projekata

#### Najbolje prakse
- **Započnite s manjim modelima**: Počnite s Phi-mini modelima za početni razvoj
- **Optimizirajte upite**: Koristite pravilno formatiranje razgovora za najbolje rezultate
- **Pratite performanse**: Pratite brzinu inferencije i metrike točnosti
- **Razmotrite hardver**: Prilagodite veličinu modela dostupnim računalnim resursima

## Zaključak

Obitelj Microsoft Phi modela predstavlja revolucionarni pristup dizajnu AI modela, pokazujući da manji, učinkovitiji modeli mogu postići izvanredne rezultate u raznim zadacima. Fokusirajući se na visokokvalitetne podatke za treniranje i optimizacije arhitekture, obitelj Phi pruža iznimne mogućnosti uz značajno smanjene računalne zahtjeve u usporedbi s tradicionalnim velikim jezičnim modelima.

## Ključni ciljevi učenja

1. Razumjeti filozofiju dizajna i evoluciju obitelji Microsoft Phi modela od Phi-1 do Phi-4
2. Identificirati ključne inovacije, uključujući "kvalitetu udžbenika" u treniranju i optimizacije arhitekture
3. Prepoznati prednosti i ograničenja različitih Phi varijanti u različitim scenarijima primjene
4. Primijeniti znanje za odabir odgovarajućih Phi modela za specifične slučajeve upotrebe i hardverska ograničenja
5. Implementirati tehnike optimizacije za primjenu Phi modela na uređajima s ograničenim resursima
6. Objasniti arhitektonske prednosti obitelji Phi modela u odnosu na tradicionalne velike jezične modele
7. Odabrati odgovarajuću Phi varijantu na temelju specifičnih zahtjeva aplikacije i hardverskih ograničenja
8. Primijeniti Phi modele u scenarijima primjene na oblaku i rubnim uređajima s optimiziranim konfiguracijama
9. Primijeniti tehnike kvantizacije i optimizacije za poboljšanje performansi Phi modela na ciljnim uređajima
10. Procijeniti kompromise između veličine modela, performansi i mogućnosti unutar obitelji Phi modela

## Što slijedi

- [02: Osnove obitelji Qwen](02.QwenFamily.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za bilo kakve nesporazume ili pogrešne interpretacije koje proizlaze iz korištenja ovog prijevoda.