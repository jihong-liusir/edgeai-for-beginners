<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1b09b5c867abbccfdbc826d857ae0c2",
  "translation_date": "2025-09-25T02:03:59+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "hr"
}
-->
# Sesija 3: Otkrivanje i upravljanje modelima otvorenog koda

## Pregled

Ova sesija usmjerena je na praktično otkrivanje i upravljanje modelima pomoću Foundry Local. Naučit ćete kako popisati dostupne modele, testirati različite opcije i razumjeti osnovne karakteristike performansi. Pristup naglašava praktično istraživanje pomoću foundry CLI-a kako biste odabrali prave modele za svoje potrebe.

## Ciljevi učenja

- Ovladati naredbama foundry CLI-a za otkrivanje i upravljanje modelima
- Razumjeti uzorke predmemorije modela i lokalnog pohranjivanja
- Naučiti brzo testirati i uspoređivati različite modele
- Uspostaviti praktične tijekove rada za odabir i usporedbu modela
- Istražiti rastući ekosustav modela dostupnih putem Foundry Local

## Preduvjeti

- Završena Sesija 1: Uvod u Foundry Local
- Instaliran i dostupan Foundry Local CLI
- Dovoljno prostora za pohranu za preuzimanje modela (modeli mogu biti veličine od 1GB do 20GB+)
- Osnovno razumijevanje vrsta modela i njihovih primjena

## Pregled

Ova sesija istražuje kako dovesti modele otvorenog koda u Foundry Local.

## Dio 6: Praktična vježba

### Vježba: Otkrivanje i usporedba modela

Izradite vlastiti skript za evaluaciju modela na temelju Primjera 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```


### Vaš zadatak

1. **Pokrenite skript Primjer 03**: `samples\03\list_and_bench.cmd`
2. **Isprobajte različite modele**: Testirajte najmanje 3 različita modela
3. **Usporedite performanse**: Zabilježite razlike u brzini i kvaliteti odgovora
4. **Dokumentirajte rezultate**: Izradite jednostavnu tablicu usporedbe

### Primjer formata usporedbe

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```


## Dio 7: Rješavanje problema i najbolje prakse

### Uobičajeni problemi i rješenja

**Model se ne pokreće:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```


**Nedovoljno memorije:**
- Započnite s manjim modelima (`phi-4-mini`)
- Zatvorite druge aplikacije
- Nadogradite RAM ako često dolazi do ograničenja

**Spori rad:**
- Provjerite je li model potpuno učitan (provjerite detaljan izlaz)
- Zatvorite nepotrebne aplikacije u pozadini
- Razmislite o bržoj pohrani (SSD)

### Najbolje prakse

1. **Započnite s manjim modelima**: Počnite s `phi-4-mini` kako biste provjerili postavke
2. **Jedan model odjednom**: Zaustavite prethodne modele prije pokretanja novih
3. **Pratite resurse**: Obratite pažnju na korištenje memorije
4. **Dosljedno testiranje**: Koristite iste upite za pravedne usporedbe
5. **Dokumentirajte rezultate**: Vodite bilješke o performansama modela za svoje potrebe

## Dio 8: Sljedeći koraci i reference

### Priprema za Sesiju 4

- **Fokus Sesije 4**: Alati i tehnike optimizacije
- **Preduvjeti**: Ugodno upravljanje modelima i osnovno testiranje performansi
- **Preporučeno**: Identificirajte 2-3 omiljena modela iz ove sesije

### Dodatni resursi

- **[Foundry Local Dokumentacija](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Službena dokumentacija
- **[CLI Referenca](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Kompletna referenca naredbi
- **[Model Mondays](https://aka.ms/model-mondays)**: Tjedni pregled modela
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Zajednica i problemi
- **[Primjer 03: Otkrivanje modela](samples/03/README.md)**: Praktični primjer skripta

### Ključne točke

✅ **Otkrivanje modela**: Koristite `foundry model list` za istraživanje dostupnih modela  
✅ **Brzo testiranje**: Uzorak `list_and_bench.cmd` za brzo ocjenjivanje  
✅ **Praćenje performansi**: Osnovno mjerenje korištenja resursa i vremena odgovora  
✅ **Odabir modela**: Praktične smjernice za odabir modela prema primjeni  
✅ **Upravljanje predmemorijom**: Razumijevanje pohrane i postupaka čišćenja  

Sada imate praktične vještine za otkrivanje, testiranje i odabir odgovarajućih modela za svoje AI aplikacije koristeći jednostavan CLI pristup Foundry Local-a.

## Ciljevi učenja

- Otkrivanje i evaluacija modela otvorenog koda za lokalnu inferenciju
- Kompilacija i pokretanje odabranih Hugging Face modela unutar Foundry Local-a
- Primjena strategija odabira modela za točnost, kašnjenje i potrebe resursa
- Upravljanje modelima lokalno uz predmemoriju i verzioniranje

## Dio 1: Otkrivanje modela pomoću Foundry CLI-a

### Osnovne naredbe za upravljanje modelima

Foundry CLI pruža jednostavne naredbe za otkrivanje i upravljanje modelima:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```


### Pokretanje prvih modela

Započnite s popularnim, dobro testiranim modelima kako biste razumjeli karakteristike performansi:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b-instruct --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-distill-qwen-7b --verbose
```


**Napomena:** Zastavica `--verbose` pruža detaljne informacije o pokretanju, uključujući:
- Napredak preuzimanja modela (pri prvom pokretanju)
- Detalje o dodjeli memorije
- Informacije o povezivanju usluga
- Metrike inicijalizacije performansi

### Razumijevanje kategorija modela

**Mali jezični modeli (SLM):**
- `phi-4-mini`: Brz, učinkovit, odličan za općeniti razgovor
- `phi-4`: Sposobnija verzija s boljim zaključivanjem

**Srednji modeli:**
- `qwen2.5-7b-instruct`: Izvrsno zaključivanje i duži kontekst
- `deepseek-r1-distill-qwen-7b`: Optimiziran za generiranje koda

**Veći modeli:**
- `llama-3.2`: Najnoviji otvoreni model od Mete
- `qwen2.5-14b-instruct`: Razina za poslovno zaključivanje

## Dio 2: Brzo testiranje i usporedba modela

### Pristup Primjeru 03: Jednostavan popis i usporedba

Na temelju našeg uzorka Primjer 03, evo minimalnog tijeka rada:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```


### Testiranje performansi modela

Kad je model pokrenut, testirajte ga s dosljednim upitima:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```


### Alternativa testiranju u PowerShell-u

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```


## Dio 3: Upravljanje predmemorijom i pohranom modela

### Razumijevanje predmemorije modela

Foundry Local automatski upravlja preuzimanjima i predmemorijom modela:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```


### Razmatranja o pohrani modela

**Tipične veličine modela:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b-instruct`: ~4.1 GB  
- `deepseek-r1-distill-qwen-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b-instruct`: ~8.2 GB

**Najbolje prakse za pohranu:**
- Držite 2-3 modela u predmemoriji za brzo prebacivanje
- Uklonite neiskorištene modele kako biste oslobodili prostor: `foundry cache clean`
- Pratite korištenje diska, posebno na manjim SSD-ovima
- Razmotrite kompromis između veličine modela i sposobnosti

### Praćenje performansi modela

Dok modeli rade, pratite resurse sustava:

**Windows Task Manager:**
- Pratite korištenje memorije (modeli ostaju učitani u RAM-u)
- Pratite korištenje CPU-a tijekom inferencije
- Provjerite diskovni I/O tijekom početnog učitavanja modela

**Praćenje putem naredbenog retka:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```


## Dio 4: Praktične smjernice za odabir modela

### Odabir modela prema primjeni

**Za općeniti razgovor i pitanja:**
- Započnite s: `phi-4-mini` (brz, učinkovit)
- Nadogradite na: `phi-4` (bolje zaključivanje)
- Napredno: `qwen2.5-7b-instruct` (duži kontekst)

**Za generiranje koda:**
- Preporučeno: `deepseek-r1-distill-qwen-7b`
- Alternativa: `qwen2.5-7b-instruct` (također dobar za kod)

**Za složeno zaključivanje:**
- Najbolje: `qwen2.5-7b-instruct` ili `qwen2.5-14b-instruct`
- Opcija za manji budžet: `phi-4`

### Vodič za hardverske zahtjeve

**Minimalni zahtjevi sustava:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```


**Preporučeno za najbolje performanse:**
- 32GB+ RAM-a za ugodno prebacivanje između modela
- SSD pohrana za brže učitavanje modela
- Moderni CPU s dobrim performansama po jezgri
- Podrška za NPU (Windows 11 Copilot+ PC-ovi) za ubrzanje

### Tijek rada za prebacivanje modela

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b-instruct

REM Verify model is running
foundry service status
```


## Dio 5: Jednostavno uspoređivanje modela

### Osnovno testiranje performansi

Evo jednostavnog pristupa za usporedbu performansi modela:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b-instruct", "deepseek-r1-distill-qwen-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```


### Ručna procjena kvalitete

Za svaki model testirajte s dosljednim upitima i ručno procijenite:

**Testni upiti:**
1. "Objasni kvantno računalstvo jednostavnim riječima."
2. "Napiši Python funkciju za sortiranje liste."
3. "Koje su prednosti i nedostaci rada na daljinu?"
4. "Sažmi prednosti edge AI-a."

**Kriteriji procjene:**
- **Točnost**: Jesu li informacije točne?
- **Jasnoća**: Je li objašnjenje lako razumljivo?
- **Potpunost**: Pokriva li cijelo pitanje?
- **Brzina**: Koliko brzo odgovara?

### Praćenje korištenja resursa

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```


## Dio 6: Sljedeći koraci

- Pretplatite se na Model Mondays za nove modele i savjete: https://aka.ms/model-mondays
- Podijelite rezultate sa svojim timom u `models.json`
- Pripremite se za Sesiju 4: usporedba LLM-ova i SLM-ova, lokalna vs cloud inferencija, i praktične demonstracije

---

