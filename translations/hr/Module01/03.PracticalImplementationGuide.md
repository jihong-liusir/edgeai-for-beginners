<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c37dfe660161e652077f6b7b23bb2167",
  "translation_date": "2025-10-11T14:46:13+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "hr"
}
-->
# Odjeljak 3: Praktični vodič za implementaciju

## Pregled

Ovaj sveobuhvatni vodič pomoći će vam da se pripremite za EdgeAI tečaj, koji se fokusira na izradu praktičnih AI rješenja koja učinkovito rade na rubnim uređajima. Tečaj naglašava praktičan razvoj koristeći moderne okvire i najnaprednije modele optimizirane za rubnu primjenu.

## 1. Postavljanje razvojnog okruženja

### Programski jezici i okviri

**Python okruženje**
- **Verzija**: Python 3.10 ili novija (preporučeno: Python 3.11)
- **Upravitelj paketa**: pip ili conda
- **Virtualno okruženje**: Koristite venv ili conda okruženja za izolaciju
- **Ključne biblioteke**: Specifične EdgeAI biblioteke instalirat ćemo tijekom tečaja

**Microsoft .NET okruženje**
- **Verzija**: .NET 8 ili novija
- **IDE**: Visual Studio 2022, Visual Studio Code ili JetBrains Rider
- **SDK**: Provjerite je li .NET SDK instaliran za razvoj na više platformi

### Razvojni alati

**Urednici koda i IDE-ovi**
- Visual Studio Code (preporučeno za razvoj na više platformi)
- PyCharm ili Visual Studio (za razvoj specifičan za jezik)
- Jupyter Notebooks za interaktivni razvoj i prototipiranje

**Kontrola verzija**
- Git (najnovija verzija)
- GitHub račun za pristup repozitorijima i suradnju

## 2. Hardverski zahtjevi i preporuke

### Minimalni sistemski zahtjevi
- **CPU**: Višejedreni procesor (Intel i5/AMD Ryzen 5 ili ekvivalent)
- **RAM**: Minimalno 8GB, preporučeno 16GB
- **Pohrana**: 50GB slobodnog prostora za modele i razvojne alate
- **OS**: Windows 10/11, macOS 10.15+ ili Linux (Ubuntu 20.04+)

### Strategija računalnih resursa
Tečaj je dizajniran da bude dostupan na različitim hardverskim konfiguracijama:

**Lokalni razvoj (fokus na CPU/NPU)**
- Primarni razvoj koristit će CPU i NPU akceleraciju
- Pogodno za većinu modernih prijenosnih i stolnih računala
- Fokus na učinkovitost i praktične scenarije primjene

**Cloud GPU resursi (opcionalno)**
- **Azure Machine Learning**: Za intenzivno treniranje i eksperimentiranje
- **Google Colab**: Dostupan besplatni plan za edukativne svrhe
- **Kaggle Notebooks**: Alternativna platforma za računalstvo u oblaku

### Razmatranja za rubne uređaje
- Razumijevanje procesora temeljenih na ARM arhitekturi
- Poznavanje ograničenja mobilnog i IoT hardvera
- Upoznavanje s optimizacijom potrošnje energije

## 3. Osnovne obitelji modela i resursi

### Primarne obitelji modela

**Microsoft Phi-4 obitelj**
- **Opis**: Kompaktni, učinkoviti modeli dizajnirani za rubnu primjenu
- **Prednosti**: Izvrsna izvedba u odnosu na veličinu, optimizirani za zadatke zaključivanja
- **Resurs**: [Phi-4 kolekcija na Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Primjene**: Generiranje koda, matematičko zaključivanje, opći razgovori

**Qwen-3 obitelj**
- **Opis**: Najnovija generacija Alibaba-ovih višejezičnih modela
- **Prednosti**: Snažne višejezične sposobnosti, učinkovita arhitektura
- **Resurs**: [Qwen-3 kolekcija na Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Primjene**: Višejezične aplikacije, AI rješenja za različite kulture

**Google Gemma-3n obitelj**
- **Opis**: Googleovi lagani modeli optimizirani za rubnu primjenu
- **Prednosti**: Brza inferencija, arhitektura prilagođena mobilnim uređajima
- **Resurs**: [Gemma-3n kolekcija na Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Primjene**: Mobilne aplikacije, obrada u stvarnom vremenu

### Kriteriji za odabir modela
- **Izvedba u odnosu na veličinu**: Razumijevanje kada odabrati manje ili veće modele
- **Optimizacija specifična za zadatke**: Usklađivanje modela s određenim primjenama
- **Ograničenja implementacije**: Memorija, kašnjenje i potrošnja energije

## 4. Alati za kvantizaciju i optimizaciju

### Llama.cpp okvir
- **Repozitorij**: [Llama.cpp na GitHubu](https://github.com/ggml-org/llama.cpp)
- **Svrha**: Inferencijski motor visokih performansi za LLM-ove
- **Ključne značajke**:
  - Optimizirana inferencija za CPU
  - Višestruki formati kvantizacije (Q4, Q5, Q8)
  - Kompatibilnost na više platformi
  - Memorijski učinkovito izvršavanje
- **Instalacija i osnovna upotreba**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Repozitorij**: [Microsoft Olive na GitHubu](https://github.com/microsoft/olive)
- **Svrha**: Alat za optimizaciju modela za rubnu primjenu
- **Ključne značajke**:
  - Automatizirani tijekovi rada za optimizaciju modela
  - Optimizacija prilagođena hardveru
  - Integracija s ONNX Runtime
  - Alati za usporedbu performansi
- **Instalacija i osnovna upotreba**:
  ```bash
  # Install Olive
  pip install olive-ai
  ```
  
  # Primjer Python skripte za optimizaciju modela
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (korisnici macOS-a)
- **Repozitorij**: [Apple MLX na GitHubu](https://github.com/ml-explore/mlx)
- **Svrha**: Okvir za strojno učenje za Apple Silicon
- **Ključne značajke**:
  - Optimizacija za Apple Silicon
  - Memorijski učinkovite operacije
  - API sličan PyTorch-u
  - Podrška za objedinjenu memorijsku arhitekturu
- **Instalacija i osnovna upotreba**:
  ```bash
  # Install MLX
  pip install mlx
  ```
  
  ```python
  # Example Python script for loading and optimizing a model
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Repozitorij**: [ONNX Runtime na GitHubu](https://github.com/microsoft/onnxruntime)
- **Svrha**: Akceleracija inferencije na više platformi za ONNX modele
- **Ključne značajke**:
  - Optimizacije specifične za hardver (CPU, GPU, NPU)
  - Optimizacija grafova za inferenciju
  - Podrška za kvantizaciju
  - Podrška za više jezika (Python, C++, C#, JavaScript)
- **Instalacija i osnovna upotreba**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. Preporučena literatura i resursi

### Osnovna dokumentacija
- **ONNX Runtime dokumentacija**: Razumijevanje inferencije na više platformi
- **Hugging Face Transformers vodič**: Učitavanje modela i inferencija
- **Edge AI dizajnerski obrasci**: Najbolje prakse za rubnu primjenu

### Tehnički radovi
- "Učinkoviti Edge AI: Pregled tehnika kvantizacije"
- "Kompresija modela za mobilne i rubne uređaje"
- "Optimizacija Transformer modela za rubno računalstvo"

### Zajednički resursi
- **EdgeAI Slack/Discord zajednice**: Podrška i rasprava među vršnjacima
- **GitHub repozitoriji**: Primjeri implementacija i vodiči
- **YouTube kanali**: Tehnički detalji i vodiči

## 6. Procjena i verifikacija

### Popis za provjeru prije tečaja
- [ ] Python 3.10+ instaliran i provjeren
- [ ] .NET 8+ instaliran i provjeren
- [ ] Razvojno okruženje konfigurirano
- [ ] Kreiran Hugging Face račun
- [ ] Osnovno poznavanje ciljanih obitelji modela
- [ ] Alati za kvantizaciju instalirani i testirani
- [ ] Zadovoljeni hardverski zahtjevi
- [ ] Postavljeni računi za računalstvo u oblaku (ako je potrebno)

## Ključni ciljevi učenja

Do kraja ovog vodiča moći ćete:

1. Postaviti potpuno razvojno okruženje za razvoj EdgeAI aplikacija
2. Instalirati i konfigurirati potrebne alate i okvire za optimizaciju modela
3. Odabrati odgovarajuće hardverske i softverske konfiguracije za svoje EdgeAI projekte
4. Razumjeti ključne aspekte implementacije AI modela na rubnim uređajima
5. Pripremiti svoj sustav za praktične vježbe u tečaju

## Dodatni resursi

### Službena dokumentacija
- **Python dokumentacija**: Službena dokumentacija za Python jezik
- **Microsoft .NET dokumentacija**: Službeni resursi za razvoj u .NET-u
- **ONNX Runtime dokumentacija**: Sveobuhvatan vodič za ONNX Runtime
- **TensorFlow Lite dokumentacija**: Službena dokumentacija za TensorFlow Lite

### Razvojni alati
- **Visual Studio Code**: Lagani urednik koda s proširenjima za AI razvoj
- **Jupyter Notebooks**: Interaktivno okruženje za eksperimentiranje s ML-om
- **Docker**: Platforma za kontejnerizaciju za dosljedna razvojna okruženja
- **Git**: Sustav za kontrolu verzija za upravljanje kodom

### Resursi za učenje
- **EdgeAI istraživački radovi**: Najnovija akademska istraživanja o učinkovitim modelima
- **Online tečajevi**: Dodatni materijali za učenje o optimizaciji AI-a
- **Zajednički forumi**: Platforme za pitanja i odgovore o izazovima u EdgeAI razvoju
- **Referentni skupovi podataka**: Standardni skupovi podataka za procjenu performansi modela

## Ishodi učenja

Nakon završetka ovog vodiča za pripremu, moći ćete:

1. Imati potpuno konfigurirano razvojno okruženje spremno za EdgeAI razvoj
2. Razumjeti hardverske i softverske zahtjeve za različite scenarije implementacije
3. Biti upoznati s ključnim okvirima i alatima koji se koriste tijekom tečaja
4. Odabrati odgovarajuće modele na temelju ograničenja uređaja i zahtjeva
5. Imati osnovno znanje o tehnikama optimizacije za rubnu primjenu

## ➡️ Što slijedi

- [04: EdgeAI hardver i implementacija](04.EdgeDeployment.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane čovjeka. Ne preuzimamo odgovornost za nesporazume ili pogrešna tumačenja koja mogu proizaći iz korištenja ovog prijevoda.