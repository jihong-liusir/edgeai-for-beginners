<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a35d3b47e6ae98ad9b3e89fb73917e90",
  "translation_date": "2025-09-19T00:10:26+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "hr"
}
-->
# Sekcija 1: Osnove EdgeAI-a

EdgeAI predstavlja promjenu paradigme u primjeni umjetne inteligencije, donoseći AI mogućnosti izravno na rubne uređaje umjesto da se oslanja isključivo na obradu u oblaku. Važno je razumjeti kako EdgeAI omogućuje lokalnu obradu AI-a na uređajima s ograničenim resursima, dok istovremeno održava razumnu izvedbu i rješava izazove poput privatnosti, kašnjenja i offline funkcionalnosti.

## Uvod

U ovoj lekciji istražit ćemo EdgeAI i njegove osnovne koncepte. Pokrit ćemo tradicionalnu paradigmu računalne obrade AI-a, izazove rubnog računalstva, ključne tehnologije koje omogućuju EdgeAI te praktične primjene u raznim industrijama.

## Ciljevi učenja

Na kraju ove lekcije moći ćete:

- Razumjeti razliku između tradicionalnog pristupa AI-u temeljenog na oblaku i EdgeAI-a.
- Identificirati ključne tehnologije koje omogućuju obradu AI-a na rubnim uređajima.
- Prepoznati prednosti i ograničenja implementacija EdgeAI-a.
- Primijeniti znanje o EdgeAI-u na stvarne scenarije i primjere upotrebe.

## Razumijevanje tradicionalne paradigme računalne obrade AI-a

Tradicionalno, generativne AI aplikacije oslanjaju se na infrastrukturu visokih performansi za učinkovito pokretanje velikih jezičnih modela (LLM-ova). Organizacije obično implementiraju ove modele na GPU klasterima u oblaku, pristupajući njihovim mogućnostima putem API sučelja.

Ovaj centralizirani model dobro funkcionira za mnoge aplikacije, ali ima inherentna ograničenja u scenarijima rubnog računalstva. Tradicionalni pristup uključuje slanje korisničkih upita na udaljene servere, obradu pomoću moćnog hardvera i vraćanje rezultata putem interneta. Iako ova metoda omogućuje pristup najnaprednijim modelima, stvara ovisnost o internetskoj povezanosti, uvodi probleme s kašnjenjem i postavlja pitanja privatnosti kada se osjetljivi podaci moraju prenijeti na vanjske servere.

Postoji nekoliko osnovnih koncepata koje trebamo razumjeti kada radimo s tradicionalnim paradigmama računalne obrade AI-a, a to su:

- **☁️ Obrada u oblaku**: AI modeli pokreću se na moćnoj server infrastrukturi s visokim računalnim resursima.
- **🔌 Pristup putem API-ja**: Aplikacije pristupaju AI mogućnostima putem udaljenih API poziva umjesto lokalne obrade.
- **🎛️ Centralizirano upravljanje modelima**: Modeli se održavaju i ažuriraju centralno, osiguravajući dosljednost, ali zahtijevajući mrežnu povezanost.
- **📈 Skalabilnost resursa**: Infrastruktura u oblaku može dinamički skalirati kako bi se nosila s promjenjivim zahtjevima za računalnim resursima.

## Izazovi rubnog računalstva

Rubni uređaji poput prijenosnih računala, mobilnih telefona i uređaja Interneta stvari (IoT) poput Raspberry Pi-a i NVIDIA Orin Nano-a predstavljaju jedinstvena ograničenja u računalnim resursima. Ovi uređaji obično imaju ograničenu procesorsku snagu, memoriju i energetske resurse u usporedbi s infrastrukturom podatkovnih centara.

Pokretanje tradicionalnih LLM-ova na takvim uređajima povijesno je bilo izazovno zbog ovih hardverskih ograničenja. Međutim, potreba za obradom AI-a na rubu postaje sve važnija u raznim scenarijima. Razmotrite situacije u kojima je internetska povezanost nepouzdana ili nedostupna, poput udaljenih industrijskih lokacija, vozila u tranzitu ili područja s lošom mrežnom pokrivenošću. Osim toga, aplikacije koje zahtijevaju visoke sigurnosne standarde, poput medicinskih uređaja, financijskih sustava ili vladinih aplikacija, možda trebaju lokalno obrađivati osjetljive podatke kako bi održale privatnost i usklađenost.

### Ključna ograničenja rubnog računalstva

Okruženja rubnog računalstva suočavaju se s nekoliko temeljnih ograničenja koja tradicionalna AI rješenja temeljena na oblaku ne susreću:

- **Ograničena procesorska snaga**: Rubni uređaji obično imaju manje CPU jezgri i niže brzine takta u usporedbi s hardverom za servere.
- **Ograničenja memorije**: Dostupna RAM memorija i kapacitet pohrane značajno su smanjeni na rubnim uređajima.
- **Ograničenja energije**: Uređaji na baterijski pogon moraju balansirati performanse s potrošnjom energije za produženi rad.
- **Upravljanje toplinom**: Kompaktni oblici uređaja ograničavaju mogućnosti hlađenja, što utječe na održive performanse pod opterećenjem.

## Što je EdgeAI?

### Koncept: Definicija EdgeAI-a

EdgeAI odnosi se na implementaciju i izvršavanje algoritama umjetne inteligencije izravno na rubnim uređajima—fizičkom hardveru koji postoji na "rubu" mreže, blizu mjesta gdje se podaci generiraju i prikupljaju. Ti uređaji uključuju pametne telefone, IoT senzore, pametne kamere, autonomna vozila, nosive uređaje i industrijsku opremu. Za razliku od tradicionalnih AI sustava koji se oslanjaju na servere u oblaku za obradu, EdgeAI donosi inteligenciju izravno na izvor podataka.

U svojoj srži, EdgeAI se odnosi na decentralizaciju obrade AI-a, premještajući je iz centraliziranih podatkovnih centara i distribuirajući je preko široke mreže uređaja koji čine naš digitalni ekosustav. Ovo predstavlja temeljnu promjenu u arhitekturi načina na koji se AI sustavi dizajniraju i implementiraju.

Ključni konceptualni stupovi EdgeAI-a uključuju:

- **Obrada u blizini**: Obrada se odvija fizički blizu mjesta gdje podaci nastaju.
- **Decentralizirana inteligencija**: Sposobnosti donošenja odluka distribuiraju se na više uređaja.
- **Suverenitet podataka**: Informacije ostaju pod lokalnom kontrolom, često nikada ne napuštajući uređaj.
- **Autonomno djelovanje**: Uređaji mogu inteligentno funkcionirati bez stalne povezanosti.
- **Ugrađeni AI**: Inteligencija postaje intrinzična sposobnost svakodnevnih uređaja.

### Vizualizacija arhitekture EdgeAI-a

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                  │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                      │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────────────────────────────────────────┐   Direct Response   ┌───────────┐
│              Edge Devices with Embedded AI        │───────────────────>│ End Users │
│  ┌─────────┐  ┌──────────────┐  ┌──────────────┐ │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │ │
│  └─────────┘  └──────────────┘  └──────────────┘ │
└──────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI predstavlja promjenu paradigme u primjeni umjetne inteligencije, donoseći AI mogućnosti izravno na rubne uređaje umjesto da se oslanja isključivo na obradu u oblaku. Ovaj pristup omogućuje pokretanje AI modela lokalno na uređajima s ograničenim računalnim resursima, pružajući mogućnosti inferencije u stvarnom vremenu bez potrebe za stalnom internetskom povezanošću.

EdgeAI obuhvaća razne tehnologije i tehnike osmišljene za učiniti AI modele učinkovitijima i prikladnijima za implementaciju na uređajima s ograničenim resursima. Cilj je održati razumnu izvedbu uz značajno smanjenje zahtjeva za računalnim i memorijskim resursima modela.

Pogledajmo osnovne pristupe koji omogućuju implementacije EdgeAI-a na različitim vrstama uređaja i primjenama.

### Osnovni principi EdgeAI-a

EdgeAI se temelji na nekoliko temeljnih principa koji ga razlikuju od tradicionalnog AI-a temeljenog na oblaku:

- **Lokalna obrada**: Inferencija AI-a odvija se izravno na rubnom uređaju bez potrebe za vanjskom povezanošću.
- **Optimizacija resursa**: Modeli su posebno optimizirani za hardverska ograničenja ciljanih uređaja.
- **Performanse u stvarnom vremenu**: Obrada se odvija s minimalnim kašnjenjem za aplikacije osjetljive na vrijeme.
- **Privatnost po dizajnu**: Osjetljivi podaci ostaju na uređaju, poboljšavajući sigurnost i usklađenost.

## Ključne tehnologije koje omogućuju EdgeAI

### Kvantizacija modela

Jedna od najvažnijih tehnika u EdgeAI-u je kvantizacija modela. Ovaj proces uključuje smanjenje preciznosti parametara modela, obično s 32-bitnih brojeva s pomičnim zarezom na 8-bitne cijele brojeve ili čak niže precizne formate. Iako ovo smanjenje preciznosti može izgledati zabrinjavajuće, istraživanja su pokazala da mnogi AI modeli mogu održati svoju izvedbu čak i uz značajno smanjenu preciznost.

Kvantizacija funkcionira mapiranjem raspona vrijednosti s pomičnim zarezom na manji skup diskretnih vrijednosti. Na primjer, umjesto korištenja 32 bita za predstavljanje svakog parametra, kvantizacija može koristiti samo 8 bita, što rezultira 4x smanjenjem zahtjeva za memorijom i često dovodi do bržih vremena inferencije.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Različite tehnike kvantizacije uključuju:

- **Post-trening kvantizacija (PTQ)**: Primjenjuje se nakon treninga modela bez potrebe za ponovnim treniranjem.
- **Kvantizacija svjesna treninga (QAT)**: Uključuje učinke kvantizacije tijekom treninga za bolju točnost.
- **Dinamička kvantizacija**: Kvantizira težine na int8, ali aktivacije izračunava dinamički.
- **Statistička kvantizacija**: Predračunava sve parametre kvantizacije za težine i aktivacije.

Za implementacije EdgeAI-a, odabir odgovarajuće strategije kvantizacije ovisi o specifičnoj arhitekturi modela, zahtjevima izvedbe i hardverskim mogućnostima ciljanog uređaja.

### Kompresija i optimizacija modela

Osim kvantizacije, razne tehnike kompresije pomažu smanjiti veličinu modela i zahtjeve za računalnim resursima. To uključuje:

**Pruning**: Ova tehnika uklanja nepotrebne veze ili neurone iz neuronskih mreža. Identificiranjem i eliminacijom parametara koji malo doprinose izvedbi modela, pruning može značajno smanjiti veličinu modela uz održavanje točnosti.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Destilacija znanja**: Ovaj pristup uključuje treniranje manjeg "studentskog" modela da oponaša ponašanje većeg "učiteljskog" modela. Studentski model uči približiti izlaze učitelja, često postižući sličnu izvedbu s značajno manje parametara.

**Optimizacija arhitekture modela**: Istraživači su razvili specijalizirane arhitekture dizajnirane posebno za implementaciju na rubu, poput MobileNets, EfficientNets i drugih laganih arhitektura koje balansiraju izvedbu s računalnom učinkovitošću.

### Mali jezični modeli (SLM-ovi)

Rastući trend u EdgeAI-u je razvoj malih jezičnih modela (SLM-ova). Ovi modeli su dizajnirani od temelja da budu kompaktni i učinkoviti, dok i dalje pružaju značajne mogućnosti obrade prirodnog jezika. SLM-ovi to postižu pažljivim odabirom arhitekture, učinkovitim tehnikama treninga i fokusiranim treningom na specifične domene ili zadatke.

Za razliku od tradicionalnih pristupa koji uključuju kompresiju velikih modela, SLM-ovi se često treniraju s manjim skupovima podataka i optimiziranim arhitekturama posebno dizajniranim za implementaciju na rubu. Ovaj pristup može rezultirati modelima koji su ne samo manji, već i učinkovitiji za specifične primjene.

## Hardverska akceleracija za EdgeAI

Moderni rubni uređaji sve više uključuju specijalizirani hardver dizajniran za ubrzanje AI radnih opterećenja:

### Neuronske procesorske jedinice (NPUs)

NPUs su specijalizirani procesori dizajnirani posebno za neuronske mrežne izračune. Ovi čipovi mogu obavljati zadatke inferencije AI-a mnogo učinkovitije od tradicionalnih CPU-a, često uz nižu potrošnju energije. Mnogi moderni pametni telefoni, prijenosna računala i IoT uređaji sada uključuju NPUs kako bi omogućili obradu AI-a na uređaju.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Uređaji s NPUs uključuju:

- **Apple**: A-serija i M-serija čipova s Neural Engine-om
- **Qualcomm**: Snapdragon procesori s Hexagon DSP/NPU
- **Samsung**: Exynos procesori s NPU
- **Intel**: Movidius VPUs i Habana Labs akceleratori
- **Microsoft**: Windows Copilot+ PC-ovi s NPUs

### 🎮 GPU akceleracija

Iako rubni uređaji možda nemaju moćne GPU-ove koji se nalaze u podatkovnim centrima, mnogi ipak uključuju integrirane ili diskretne GPU-ove koji mogu ubrzati AI radne opterećenja. Moderni mobilni GPU-ovi i integrirani grafički procesori mogu pružiti značajna poboljšanja performansi za zadatke inferencije AI-a.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optimizacija CPU-a

Čak i uređaji koji koriste samo CPU mogu imati koristi od EdgeAI-a putem optimiziranih implementacija. Moderni CPU-ovi uključuju specijalizirane instrukcije za AI radne opterećenja, a softverski okviri razvijeni su za maksimiziranje performansi CPU-a za inferenciju AI-a.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Za softverske inženjere koji rade s EdgeAI-om, razumijevanje kako iskoristiti ove opcije hardverske akceleracije ključno je za optimizaciju performansi inferencije i energetske učinkovitosti na ciljanom uređaju.

## Prednosti EdgeAI-a

### Privatnost i sigurnost

Jedna od najznačajnijih prednosti EdgeAI-a je poboljšana privatnost i sigurnost. Obradom podataka lokalno na uređaju, osjetljive informacije nikada ne napuštaju kontrolu korisnika. Ovo je posebno važno za aplikacije koje obrađuju osobne podatke, medicinske informacije ili povjerljive poslovne podatke.

### Smanjeno kašnjenje

EdgeAI eliminira potrebu za slanjem podataka na udaljene servere za obradu, značajno smanjujući kašnjenje. Ovo je ključno za aplikacije u stvarnom vremenu poput autonomnih vozila, industrijske automatizacije ili interaktivnih aplikacija gdje su potrebni trenutni odgovori.

### Offline funkcionalnost

EdgeAI omogućuje funkcionalnost AI-a čak i kada internetska povezanost nije dostupna. Ovo je vrijedno za aplikacije u udaljenim lokacijama, tijekom putovanja ili u situacijama gdje je pouzdanost mreže upitna.

### Troškovna učinkovitost

Smanjenjem oslanjanja na AI usluge temeljene na oblaku, EdgeAI može pomoći u smanjenju operativnih troškova, posebno za aplikacije s velikim volumenom korištenja. Organizacije mogu izbjeći stalne troškove API-ja i smanjiti zahtjeve za propusnošću.

### Skalabilnost

EdgeAI distribuira računalno opterećenje preko rubnih uređaja umjesto da ga centralizira u podatkovnim centrima. Ovo može pomoći u smanjenju troškova infrastrukture i poboljšanju ukupne skalabilnosti sustava.

## Primjene EdgeAI-a

### Pametni uređaji i IoT

EdgeAI pokreće mnoge značajke pametnih uređaja, od glasovnih asistenata koji mogu lokalno obrađivati naredbe do pametnih kamera koje mogu identificirati objekte i ljude bez slanja videozapisa u oblak. IoT uređaji koriste EdgeAI za prediktivno održavanje, praćenje okoliša i automatizirano donošenje odluka.

### Mobilne aplikacije

Pametni telefoni i tableti koriste EdgeAI za razne značajke, uključujući poboljšanje fotografija, prijevod u stvarnom vremenu, proširenu stvarnost i personalizirane preporuke. Ove aplikacije imaju koristi od niskog kašnjenja i prednosti privatnosti lokalne obrade.

### Industrijske primjene

Proizvodni i industrijski sektori koriste EdgeAI za kontrolu kvalitete, prediktivno održavanje i optimizaciju procesa. Ove aplikacije često zahtijevaju obradu u stvarnom vremenu i mogu raditi u okruženjima s ograničenom povezanošću.

### Zdravstvo

Medicinski uređaji i zdravstvene aplikacije koriste EdgeAI za praćenje pacijenata, pomoć u dijagnostici i preporuke za liječenje. Prednosti privatnosti i sigurnosti lokalne obrade posebno su važne u zdravstvenim aplikacijama.

## Izazovi i ograničenja

### Kompromisi u izvedbi

EdgeAI obično uključuje kompromise između veličine modela, računalne učinkovitosti i performansi. Iako tehnike poput kvant
## ➡️ Što slijedi

- [02: EdgeAI aplikacije](02.RealWorldCaseStudies.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.