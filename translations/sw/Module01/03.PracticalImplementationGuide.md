<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c37dfe660161e652077f6b7b23bb2167",
  "translation_date": "2025-10-11T14:39:43+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "sw"
}
-->
# Sehemu ya 3: Mwongozo wa Utekelezaji wa Kivitendo

## Muhtasari

Mwongozo huu wa kina utakusaidia kujiandaa kwa kozi ya EdgeAI, ambayo inalenga kujenga suluhisho za AI zinazofanya kazi kwa ufanisi kwenye vifaa vya pembezoni. Kozi inasisitiza maendeleo ya vitendo kwa kutumia mifumo ya kisasa na mifano ya hali ya juu iliyoboreshwa kwa ajili ya matumizi ya pembezoni.

## 1. Usanidi wa Mazingira ya Maendeleo

### Lugha za Programu na Mifumo

**Mazingira ya Python**
- **Toleo**: Python 3.10 au zaidi (inapendekezwa: Python 3.11)
- **Meneja wa Pakiti**: pip au conda
- **Mazingira ya Kipekee**: Tumia venv au mazingira ya conda kwa ajili ya kutenganisha
- **Maktaba Muhimu**: Tutasanidi maktaba maalum za EdgeAI wakati wa kozi

**Mazingira ya Microsoft .NET**
- **Toleo**: .NET 8 au zaidi
- **IDE**: Visual Studio 2022, Visual Studio Code, au JetBrains Rider
- **SDK**: Hakikisha .NET SDK imewekwa kwa maendeleo ya majukwaa mbalimbali

### Zana za Maendeleo

**Vihariri vya Kodi na IDE**
- Visual Studio Code (inapendekezwa kwa maendeleo ya majukwaa mbalimbali)
- PyCharm au Visual Studio (kwa maendeleo maalum ya lugha)
- Jupyter Notebooks kwa maendeleo ya maingiliano na majaribio

**Udhibiti wa Toleo**
- Git (toleo la hivi karibuni)
- Akaunti ya GitHub kwa ufikiaji wa hifadhi na ushirikiano

## 2. Mahitaji ya Vifaa na Mapendekezo

### Mahitaji ya Mfumo wa Kima cha Chini
- **CPU**: Kichakataji cha msingi nyingi (Intel i5/AMD Ryzen 5 au sawa)
- **RAM**: Angalau 8GB, inapendekezwa 16GB
- **Hifadhi**: Nafasi ya GB 50 inayopatikana kwa mifano na zana za maendeleo
- **OS**: Windows 10/11, macOS 10.15+, au Linux (Ubuntu 20.04+)

### Mkakati wa Rasilimali za Kompyuta
Kozi imeundwa kuwa rahisi kufikiwa kwenye usanidi tofauti wa vifaa:

**Maendeleo ya Ndani (Lengo la CPU/NPU)**
- Maendeleo ya msingi yatatumia CPU na kasi ya NPU
- Inafaa kwa kompyuta ndogo na kompyuta za mezani za kisasa
- Kuzingatia ufanisi na hali za matumizi ya vitendo

**Rasilimali za Wingu za GPU (Hiari)**
- **Azure Machine Learning**: Kwa mafunzo makubwa na majaribio
- **Google Colab**: Kiwango cha bure kinapatikana kwa madhumuni ya elimu
- **Kaggle Notebooks**: Jukwaa mbadala la kompyuta za wingu

### Mazingira ya Vifaa vya Pembezoni
- Uelewa wa vichakataji vya ARM
- Maarifa ya vifaa vya rununu na IoT
- Uzoefu wa kuboresha matumizi ya nishati

## 3. Familia za Mifano Muhimu na Rasilimali

### Familia za Mifano Muhimu

**Familia ya Microsoft Phi-4**
- **Maelezo**: Mifano ndogo, yenye ufanisi iliyoundwa kwa matumizi ya pembezoni
- **Nguvu**: Uwiano bora wa utendaji kwa ukubwa, imeboreshwa kwa kazi za kufikiri
- **Rasilimali**: [Phi-4 Collection on Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Matumizi**: Uzalishaji wa kodi, kufikiri kwa hesabu, mazungumzo ya jumla

**Familia ya Qwen-3**
- **Maelezo**: Kizazi kipya cha mifano ya lugha nyingi kutoka Alibaba
- **Nguvu**: Uwezo mkubwa wa lugha nyingi, usanifu wenye ufanisi
- **Rasilimali**: [Qwen-3 Collection on Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Matumizi**: Maombi ya lugha nyingi, suluhisho za AI za kitamaduni tofauti

**Familia ya Google Gemma-3n**
- **Maelezo**: Mifano nyepesi ya Google iliyoboreshwa kwa matumizi ya pembezoni
- **Nguvu**: Utoaji wa haraka, usanifu rafiki kwa rununu
- **Rasilimali**: [Gemma-3n Collection on Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Matumizi**: Maombi ya rununu, usindikaji wa wakati halisi

### Vigezo vya Uchaguzi wa Mfano
- **Uwiano wa Utendaji dhidi ya Ukubwa**: Kuelewa wakati wa kuchagua mifano midogo dhidi ya mikubwa
- **Uboreshaji Maalum wa Kazi**: Kulinganisha mifano na matumizi maalum
- **Vikwazo vya Utekelezaji**: Kumbukumbu, ucheleweshaji, na matumizi ya nishati

## 4. Zana za Uboreshaji na Upunguzaji

### Mfumo wa Llama.cpp
- **Hifadhi**: [Llama.cpp on GitHub](https://github.com/ggml-org/llama.cpp)
- **Madhumuni**: Injini ya utoaji wa utendaji wa juu kwa LLMs
- **Vipengele Muhimu**:
  - Utoaji ulioboreshwa kwa CPU
  - Miundo mbalimbali ya upunguzaji (Q4, Q5, Q8)
  - Utangamano wa majukwaa mbalimbali
  - Utekelezaji wa kumbukumbu kwa ufanisi
- **Usakinishaji na Matumizi ya Msingi**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Hifadhi**: [Microsoft Olive on GitHub](https://github.com/microsoft/olive)
- **Madhumuni**: Zana ya uboreshaji wa mifano kwa matumizi ya pembezoni
- **Vipengele Muhimu**:
  - Mifumo ya kazi ya uboreshaji wa mifano kiotomatiki
  - Uboreshaji unaozingatia vifaa
  - Muunganisho na ONNX Runtime
  - Zana za kupima utendaji
- **Usakinishaji na Matumizi ya Msingi**:
  ```bash
  # Install Olive
  pip install olive-ai
  ```
  
  # Mfano wa hati ya Python kwa uboreshaji wa mifano
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (Watumiaji wa macOS)
- **Hifadhi**: [Apple MLX on GitHub](https://github.com/ml-explore/mlx)
- **Madhumuni**: Mfumo wa kujifunza mashine kwa Apple Silicon
- **Vipengele Muhimu**:
  - Uboreshaji wa asili wa Apple Silicon
  - Operesheni za kumbukumbu kwa ufanisi
  - API inayofanana na PyTorch
  - Usaidizi wa usanifu wa kumbukumbu ya umoja
- **Usakinishaji na Matumizi ya Msingi**:
  ```bash
  # Install MLX
  pip install mlx
  ```
  
  ```python
  # Example Python script for loading and optimizing a model
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Hifadhi**: [ONNX Runtime on GitHub](https://github.com/microsoft/onnxruntime)
- **Madhumuni**: Utoaji wa kasi wa majukwaa mbalimbali kwa mifano ya ONNX
- **Vipengele Muhimu**:
  - Uboreshaji maalum wa vifaa (CPU, GPU, NPU)
  - Uboreshaji wa grafu kwa utoaji
  - Usaidizi wa upunguzaji
  - Usaidizi wa lugha mbalimbali (Python, C++, C#, JavaScript)
- **Usakinishaji na Matumizi ya Msingi**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. Usomaji na Rasilimali Zinazopendekezwa

### Nyaraka Muhimu
- **Nyaraka za ONNX Runtime**: Kuelewa utoaji wa majukwaa mbalimbali
- **Mwongozo wa Hugging Face Transformers**: Upakiaji wa mifano na utoaji
- **Mifumo ya Ubunifu ya Edge AI**: Mbinu bora za utekelezaji wa pembezoni

### Makala za Kiufundi
- "Edge AI yenye Ufanisi: Utafiti wa Mbinu za Upunguzaji"
- "Ukandamizaji wa Mfano kwa Vifaa vya Rununu na Pembezoni"
- "Kuboresha Mifano ya Transformer kwa Kompyuta ya Pembezoni"

### Rasilimali za Jamii
- **Jamii za Slack/Discord za EdgeAI**: Msaada wa wenzao na majadiliano
- **Hifadhi za GitHub**: Utekelezaji wa mifano na mafunzo
- **Mifumo ya YouTube**: Uchambuzi wa kina wa kiufundi na mafunzo

## 6. Ukaguzi na Uthibitishaji

### Orodha ya Kabla ya Kozi
- [ ] Python 3.10+ imewekwa na kuthibitishwa
- [ ] .NET 8+ imewekwa na kuthibitishwa
- [ ] Mazingira ya maendeleo yamewekwa
- [ ] Akaunti ya Hugging Face imeundwa
- [ ] Uelewa wa msingi wa familia za mifano lengwa
- [ ] Zana za upunguzaji zimewekwa na kujaribiwa
- [ ] Mahitaji ya vifaa yametimizwa
- [ ] Akaunti za kompyuta za wingu zimewekwa (ikiwa zinahitajika)

## Malengo Muhimu ya Kujifunza

Mwisho wa mwongozo huu, utaweza:

1. Kuseti mazingira kamili ya maendeleo kwa maendeleo ya programu za EdgeAI
2. Kusakinisha na kusanidi zana na mifumo muhimu kwa uboreshaji wa mifano
3. Kuchagua usanidi sahihi wa vifaa na programu kwa miradi yako ya EdgeAI
4. Kuelewa mambo muhimu ya kuzingatia kwa utekelezaji wa mifano ya AI kwenye vifaa vya pembezoni
5. Kuandaa mfumo wako kwa mazoezi ya vitendo katika kozi

## Rasilimali za Ziada

### Nyaraka Rasmi
- **Nyaraka za Python**: Nyaraka rasmi za lugha ya Python
- **Nyaraka za Microsoft .NET**: Rasilimali rasmi za maendeleo ya .NET
- **Nyaraka za ONNX Runtime**: Mwongozo wa kina wa ONNX Runtime
- **Nyaraka za TensorFlow Lite**: Nyaraka rasmi za TensorFlow Lite

### Zana za Maendeleo
- **Visual Studio Code**: Kihariri cha kodi chenye nyongeza za maendeleo ya AI
- **Jupyter Notebooks**: Mazingira ya maingiliano ya kompyuta kwa majaribio ya ML
- **Docker**: Jukwaa la kontena kwa mazingira ya maendeleo thabiti
- **Git**: Mfumo wa udhibiti wa toleo kwa usimamizi wa kodi

### Rasilimali za Kujifunza
- **Makala za Utafiti wa EdgeAI**: Utafiti wa kitaaluma wa hivi karibuni kuhusu mifano yenye ufanisi
- **Kozi za Mtandaoni**: Vifaa vya kujifunza vya ziada kuhusu uboreshaji wa AI
- **Mabaraza ya Jamii**: Mifumo ya maswali na majibu kwa changamoto za maendeleo ya EdgeAI
- **Seti za Takwimu za Kibenchi**: Seti za takwimu za kawaida kwa kutathmini utendaji wa mifano

## Matokeo ya Kujifunza

Baada ya kukamilisha mwongozo huu wa maandalizi, utaweza:

1. Kuwa na mazingira ya maendeleo yaliyosanidiwa kikamilifu kwa maendeleo ya EdgeAI
2. Kuelewa mahitaji ya vifaa na programu kwa hali tofauti za utekelezaji
3. Kufahamu mifumo na zana muhimu zinazotumika katika kozi
4. Kuchagua mifano sahihi kulingana na vikwazo na mahitaji ya kifaa
5. Kuwa na maarifa muhimu ya mbinu za uboreshaji kwa utekelezaji wa pembezoni

## ➡️ Nini kinachofuata

- [04: Vifaa vya EdgeAI na Utekelezaji](04.EdgeDeployment.md)

---

**Kanusho**:  
Hati hii imetafsiriwa kwa kutumia huduma ya tafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuhakikisha usahihi, tafadhali fahamu kuwa tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati ya asili katika lugha yake ya awali inapaswa kuzingatiwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa kutoelewana au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.