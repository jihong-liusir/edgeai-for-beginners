<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-23T01:04:14+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "sw"
}
-->
# Kipindi cha 1: Kuanza na Foundry Local

## Muhtasari

Microsoft Foundry Local inaleta uwezo wa Azure AI Foundry moja kwa moja kwenye mazingira yako ya maendeleo ya Windows 11, ikiruhusu maendeleo ya AI yenye faragha, kasi ya chini, na zana za kiwango cha biashara. Kipindi hiki kinashughulikia usakinishaji kamili, usanidi, na utekelezaji wa vitendo wa mifano maarufu ikiwemo phi, qwen, deepseek, na GPT-OSS-20B.

## Malengo ya Kujifunza

Mwisho wa kipindi hiki, utaweza:
- Kusakinisha na kusanidi Foundry Local kwenye Windows 11
- Kumudu amri za CLI na chaguo za usanidi
- Kuelewa mikakati ya kuhifadhi mifano kwa utendaji bora
- Kuendesha mifano ya phi, qwen, deepseek, na GPT-OSS-20B kwa mafanikio
- Kuunda programu yako ya kwanza ya AI kwa kutumia Foundry Local

## Mahitaji ya Awali

### Mahitaji ya Mfumo
- **Windows 11**: Toleo 22H2 au baadaye
- **RAM**: Angalau 16GB, inapendekezwa 32GB
- **Hifadhi**: Nafasi ya bure ya 50GB kwa mifano na cache
- **Vifaa**: Kifaa chenye NPU au GPU kinapendekezwa (Copilot+ PC au NVIDIA GPU)
- **Mtandao**: Intaneti ya kasi ya juu kwa kupakua mifano

### Mazingira ya Maendeleo
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## Sehemu ya 1: Usakinishaji na Usanidi

### Hatua ya 1: Kusakinisha Foundry Local

Sakinisha Foundry Local kwa kutumia Winget au pakua kisakinishi kutoka GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Hatua ya 2: Thibitisha Usakinishaji

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Sehemu ya 2: Kuelewa CLI

### Muundo wa Amri za Msingi

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Sehemu ya 3: Usimamizi wa Cache ya Mifano

Foundry Local hutumia cache ya mifano yenye akili ili kuboresha utendaji na hifadhi:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Sehemu ya 4: Utekelezaji wa Vitendo wa Mifano

### Kuendesha Mifano ya Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Kufanya Kazi na Mifano ya Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### Kuendesha Mifano ya DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### Kuendesha GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Sehemu ya 5: Kuunda Programu Yako ya Kwanza

### Kiolesura Rahisi cha Gumzo (API Inayolingana na OpenAI)

Unda programu ya msingi ya gumzo kwa kutumia API ya REST inayolingana na OpenAI ya Foundry Local. Hakikisha mfano unaendesha kwenye terminal nyingine.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Endesha Programu ya Gumzo

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## Sehemu ya 6: Utatuzi wa Matatizo na Mazoezi Bora

### Masuala ya Kawaida na Suluhisho

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Kufuatilia Rasilimali za Mfumo (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Mazoezi Bora

- Pendelea kutumia amri `foundry model ...`, `foundry cache ...`, na `foundry service ...` (tazama rejea ya CLI)
- Sasisha mara kwa mara ili kupata mifano mipya na marekebisho
- Anza na mifano midogo (Phi mini, Qwen 7B) na ongeza ukubwa polepole
- Fuata CPU/GPU/memory wakati wa kurekebisha maelekezo na mipangilio

## Sehemu ya 7: Mazoezi ya Vitendo

### Zoezi la 1: Uendeshaji wa Haraka wa Mifano Mingi

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Zoezi la 2: Upimaji wa Msingi wa Kasi ya Majibu

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Marejeleo

- Anza na Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- Rejea ya CLI na muhtasari wa amri: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Kusanya mifano ya Hugging Face kwa Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

