<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6a574846c3919c56f1d02bf1de2003ca",
  "translation_date": "2025-10-01T01:09:36+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "sw"
}
-->
# Kipindi cha 1: Kuanza na Foundry Local

## Muhtasari

Microsoft Foundry Local inaleta uwezo wa Azure AI Foundry moja kwa moja kwenye mazingira yako ya maendeleo ya Windows 11, ikiruhusu maendeleo ya AI yenye faragha, kasi ya chini, na zana za kiwango cha biashara. Kipindi hiki kinashughulikia usakinishaji kamili, usanidi, na utekelezaji wa mifano maarufu kama phi, qwen, deepseek, na GPT-OSS-20B.

## Malengo ya Kujifunza

Mwisho wa kipindi hiki, utaweza:
- Kusakinisha na kusanidi Foundry Local kwenye Windows 11
- Kumudu amri za CLI na chaguo za usanidi
- Kuelewa mikakati ya kuhifadhi mifano kwa utendaji bora
- Kuendesha kwa mafanikio mifano ya phi, qwen, deepseek, na GPT-OSS-20B
- Kuunda programu yako ya kwanza ya AI kwa kutumia Foundry Local

## Mahitaji ya Awali

### Mahitaji ya Mfumo
- **Windows 11**: Toleo 22H2 au jipya zaidi
- **RAM**: Angalau 16GB, inapendekezwa 32GB
- **Hifadhi**: Nafasi ya bure ya 50GB kwa mifano na cache
- **Vifaa**: Kifaa chenye NPU au GPU kinapendekezwa (Copilot+ PC au NVIDIA GPU)
- **Mtandao**: Intaneti ya kasi kwa kupakua mifano

### Mazingira ya Maendeleo
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## Sehemu ya 1: Usakinishaji na Usanidi

### Hatua ya 1: Kusakinisha Foundry Local

Sakinisha Foundry Local kwa kutumia Winget au pakua kisakinishi kutoka GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Hatua ya 2: Thibitisha Usakinishaji

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Sehemu ya 2: Kuelewa CLI

### Muundo wa Amri za Msingi

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Sehemu ya 3: Usimamizi wa Cache ya Mifano

Foundry Local hutumia uhifadhi wa akili wa mifano ili kuboresha utendaji na hifadhi:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Sehemu ya 4: Utekelezaji wa Mifano kwa Vitendo

### Kuendesha Mifano ya Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Kufanya Kazi na Mifano ya Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b
foundry model run qwen2.5-14b
```

### Kuendesha Mifano ya DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-7b
```

### Kuendesha GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Sehemu ya 5: Kuunda Programu Yako ya Kwanza

### Programu ya Kisasa ya Gumzo (OpenAI SDK + Foundry Local)

Unda programu ya gumzo ya kiwango cha uzalishaji kwa kutumia OpenAI SDK na ujumuishaji wa Foundry Local, ukifuata mifumo kutoka kwa Sampuli 01.

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("‚ö†Ô∏è Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"üåê Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"üè† Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"‚ö†Ô∏è Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"üîß Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### Endesha Programu ya Gumzo

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## Sehemu ya 6: Utatuzi wa Matatizo na Mbinu Bora

### Masuala ya Kawaida na Suluhisho

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### Kufuatilia Rasilimali za Mfumo (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Vigezo vya Mazingira

| Kigezo | Maelezo | Chaguo-msingi | Inahitajika |
|--------|---------|--------------|-------------|
| `MODEL` | Jina au alias ya mfano | `phi-4-mini` | Hapana |
| `BASE_URL` | URL ya msingi ya Foundry Local | `http://localhost:8000` | Hapana |
| `API_KEY` | API key (kwa kawaida haitahitajika kwa ndani) | `""` | Hapana |
| `AZURE_OPENAI_ENDPOINT` | Endpoint ya Azure OpenAI | - | Kwa Azure |
| `AZURE_OPENAI_API_KEY` | API key ya Azure OpenAI | - | Kwa Azure |
| `AZURE_OPENAI_API_VERSION` | Toleo la API ya Azure | `2024-08-01-preview` | Hapana |

### Mbinu Bora

- **Tumia OpenAI SDK**: Pendekeza OpenAI SDK badala ya maombi ya HTTP ya moja kwa moja kwa urahisi wa matengenezo
- **FoundryLocalManager**: Tumia SDK rasmi kwa usimamizi wa huduma inapopatikana
- **Utunzaji wa Makosa**: Tekeleza mikakati sahihi ya kurudi nyuma kwa programu za uzalishaji
- **Sasisha Mara kwa Mara**: Weka Foundry Local ikisasishwa ili kufikia mifano mipya na marekebisho
- **Anza Kidogo**: Anza na mifano midogo (Phi mini, Qwen 7B) na ongeza ukubwa
- **Fuatilia Rasilimali**: Fuata CPU/GPU/memory wakati wa kurekebisha maelezo na mipangilio

## Sehemu ya 7: Mazoezi ya Vitendo

### Zoezi la 1: Jaribio la Haraka la Mifano Mingi

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Zoezi la 2: Jaribio la Ujumuishaji wa OpenAI SDK

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"‚úÖ {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"‚ùå {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b"]
for model in models_to_test:
    test_model_integration(model)
```

### Zoezi la 3: Ukaguzi wa Kina wa Afya ya Huduma

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"‚úÖ Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"‚úÖ {model_id}: Working")
            except Exception as e:
                print(f"‚ùå {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"‚ùå Service check failed: {e}")
        return False

comprehensive_health_check()
```

## Marejeleo

- **Anza na Foundry Local**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **Marejeleo ya CLI na muhtasari wa amri**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **Ujumuishaji wa OpenAI SDK**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **Kusanya mifano ya Hugging Face**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **Sampuli 01: Gumzo la Haraka kupitia OpenAI SDK**: samples/01/README.md
- **Sampuli 02: Ujumuishaji wa SDK wa Juu**: samples/02/README.md

---

**Kanusho**:  
Hati hii imetafsiriwa kwa kutumia huduma ya tafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuhakikisha usahihi, tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati ya asili katika lugha yake ya awali inapaswa kuzingatiwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa kutoelewana au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.