<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49e18143f97a802a8647f4be28355348",
  "translation_date": "2025-09-19T00:57:50+00:00",
  "source_file": "Module04/01.Introduce.md",
  "language_code": "sl"
}
-->
# Poglavje 1: Osnove pretvorbe modelov in kvantizacije

Pretvorba formatov modelov in kvantizacija predstavljata ključne napredke v EdgeAI, saj omogočata napredne zmogljivosti strojnega učenja na napravah z omejenimi viri. Razumevanje, kako učinkovito pretvoriti, optimizirati in implementirati modele, je bistvenega pomena za gradnjo praktičnih rešitev umetne inteligence na robu.

## Uvod

V tem priročniku bomo raziskali tehnike pretvorbe formatov modelov in kvantizacije ter njihove napredne strategije implementacije. Pokrili bomo temeljne koncepte stiskanja modelov, meje in klasifikacije formatov, tehnike optimizacije ter praktične strategije implementacije za okolja robnega računalništva.

## Cilji učenja

Na koncu tega priročnika boste sposobni:

- 🔢 Razumeti meje kvantizacije in klasifikacije različnih ravni natančnosti.
- 🛠️ Prepoznati ključne tehnike pretvorbe formatov za implementacijo modelov na robnih napravah.
- 🚀 Naučiti se naprednih strategij kvantizacije in stiskanja za optimizirano sklepanje.

## Razumevanje meja in klasifikacij kvantizacije modelov

Kvantizacija modelov je tehnika, zasnovana za zmanjšanje natančnosti parametrov nevronskih mrež z bistveno manj bitov kot njihovi modeli s polno natančnostjo. Medtem ko modeli s polno natančnostjo uporabljajo 32-bitne predstavitve s plavajočo vejico, so kvantizirani modeli posebej zasnovani za učinkovitost in implementacijo na robu.

Okvir klasifikacije natančnosti nam pomaga razumeti različne kategorije ravni kvantizacije in njihove ustrezne primere uporabe. Ta klasifikacija je ključna za izbiro prave ravni natančnosti za specifične scenarije robnega računalništva.

### Okvir klasifikacije natančnosti

Razumevanje meja natančnosti pomaga pri izbiri ustreznih ravni kvantizacije za različne scenarije robnega računalništva:

- **🔬 Zelo nizka natančnost**: Kvantizacija od 1-bit do 2-bit (ekstremno stiskanje za specializirano strojno opremo)
- **📱 Nizka natančnost**: Kvantizacija od 3-bit do 4-bit (uravnotežena zmogljivost in učinkovitost)
- **⚖️ Srednja natančnost**: Kvantizacija od 5-bit do 8-bit (približevanje zmogljivostim modelov s polno natančnostjo ob ohranjanju učinkovitosti)

Natančne meje ostajajo fluidne v raziskovalni skupnosti, vendar večina praktikov obravnava 8-bitne in nižje kot "kvantizirane," pri čemer nekateri viri določajo specializirane pragove za različne cilje strojne opreme.

### Ključne prednosti kvantizacije modelov

Kvantizacija modelov ponuja več temeljnih prednosti, zaradi katerih je idealna za aplikacije robnega računalništva:

**Operativna učinkovitost**: Kvantizirani modeli omogočajo hitrejše čase sklepanja zaradi zmanjšane računske kompleksnosti, kar jih naredi idealne za aplikacije v realnem času. Zahtevajo manj računalniških virov, kar omogoča implementacijo na napravah z omejenimi viri, hkrati pa porabijo manj energije in ohranjajo zmanjšan ogljični odtis.

**Prilagodljivost implementacije**: Ti modeli omogočajo zmogljivosti umetne inteligence na napravi brez potrebe po internetni povezavi, izboljšujejo zasebnost in varnost z lokalno obdelavo, jih je mogoče prilagoditi za aplikacije specifične za določeno področje in so primerni za različna okolja robnega računalništva.

**Učinkovitost stroškov**: Kvantizirani modeli ponujajo stroškovno učinkovito usposabljanje in implementacijo v primerjavi z modeli s polno natančnostjo, z zmanjšanimi operativnimi stroški in nižjimi zahtevami po pasovni širini za aplikacije na robu.

## Napredne strategije pridobivanja formatov modelov

### GGUF (General GGML Universal Format)

GGUF služi kot primarni format za implementacijo kvantiziranih modelov na CPU in robnih napravah. Format ponuja obsežne vire za pretvorbo in implementacijo modelov:

**Funkcije odkrivanja formata**: Format ponuja napredno podporo za različne ravni kvantizacije, združljivost licenc in optimizacijo zmogljivosti. Uporabniki lahko dostopajo do združljivosti med platformami, realnočasovnih meril zmogljivosti in podpore za WebGPU za implementacijo v brskalniku.

**Zbirke ravni kvantizacije**: Priljubljeni formati kvantizacije vključujejo Q4_K_M za uravnoteženo stiskanje, serijo Q5_K_S za aplikacije, osredotočene na kakovost, Q8_0 za skoraj originalno natančnost in eksperimentalne formate, kot je Q2_K za implementacijo z zelo nizko natančnostjo. Format vključuje tudi različice, ki jih vodi skupnost, s specializiranimi konfiguracijami za specifična področja ter splošno uporabo in različice, prilagojene navodilom, optimizirane za različne primere uporabe.

### ONNX (Open Neural Network Exchange)

Format ONNX zagotavlja združljivost med okviri za kvantizirane modele z izboljšanimi integracijskimi zmogljivostmi:

**Integracija v podjetjih**: Format vključuje modele s podporo na ravni podjetja in zmogljivostmi optimizacije, ki vključujejo dinamično kvantizacijo za prilagodljivo natančnost in statično kvantizacijo za implementacijo v produkciji. Prav tako podpira modele iz različnih okvirov s standardiziranimi pristopi kvantizacije.

**Prednosti za podjetja**: Vgrajena orodja za optimizacijo, implementacijo med platformami in pospeševanje strojne opreme so integrirana v različne pogone za sklepanje. Neposredna podpora okvirov s standardiziranimi API-ji, integrirane funkcije optimizacije in celoviti delovni tokovi implementacije izboljšujejo izkušnjo v podjetjih.

## Napredne tehnike kvantizacije in optimizacije

### Llama.cpp okvir za optimizacijo

Llama.cpp ponuja najsodobnejše tehnike kvantizacije za maksimalno učinkovitost pri implementaciji na robu:

**Metode kvantizacije**: Okvir podpira različne ravni kvantizacije, vključno z Q4_0 (4-bitna kvantizacija z odlično redukcijo velikosti - idealna za mobilno implementacijo), Q5_1 (5-bitna kvantizacija, ki uravnoteži kakovost in stiskanje - primerna za sklepanje na robu) in Q8_0 (8-bitna kvantizacija za skoraj originalno kakovost - priporočljiva za uporabo v produkciji). Napredni formati, kot je Q2_K, predstavljajo najsodobnejše stiskanje za ekstremne scenarije.

**Prednosti implementacije**: Sklepanje, optimizirano za CPU, s pospeševanjem SIMD omogoča učinkovito nalaganje in izvajanje modelov. Združljivost med platformami na arhitekturah x86, ARM in Apple Silicon omogoča strojno neodvisne zmogljivosti implementacije.

**Primerjava pomnilniškega odtisa**: Različne ravni kvantizacije ponujajo različne kompromise med velikostjo modela in kakovostjo. Q4_0 zagotavlja približno 75 % redukcijo velikosti, Q5_1 ponuja 70 % redukcijo z boljšo ohranitvijo kakovosti, Q8_0 pa dosega 50 % redukcijo ob ohranjanju skoraj originalne zmogljivosti.

### Microsoft Olive optimizacijski paket

Microsoft Olive ponuja celovite delovne tokove optimizacije modelov, zasnovane za produkcijska okolja:

**Tehnike optimizacije**: Paket vključuje dinamično kvantizacijo za samodejno izbiro natančnosti, optimizacijo grafov in združevanje operaterjev za izboljšano učinkovitost, optimizacije, specifične za strojno opremo, za implementacijo na CPU, GPU in NPU ter večstopenjske optimizacijske procese. Specializirani delovni tokovi kvantizacije podpirajo različne ravni natančnosti od 8-bitne do eksperimentalne 1-bitne konfiguracije.

**Avtomatizacija delovnih tokov**: Avtomatizirano primerjanje med različicami optimizacije zagotavlja ohranjanje kakovostnih metrik med optimizacijo. Integracija s priljubljenimi okviri strojnega učenja, kot sta PyTorch in ONNX, omogoča optimizacijo za implementacijo v oblaku in na robu.

### Apple MLX okvir

Apple MLX zagotavlja nativno optimizacijo, posebej zasnovano za naprave Apple Silicon:

**Optimizacija za Apple Silicon**: Okvir uporablja arhitekturo združenega pomnilnika z integracijo Metal Performance Shaders, samodejno sklepanje z mešano natančnostjo in optimizirano uporabo pasovne širine pomnilnika. Modeli kažejo izjemno zmogljivost na čipih serije M z optimalnim ravnovesjem za različne implementacije na napravah Apple.

**Razvojne funkcije**: Podpora za API-je Python in Swift z operacijami polj, združljivimi z NumPy, zmogljivostmi samodejne diferenciacije in brezhibno integracijo z razvojnimi orodji Apple zagotavljajo celovito razvojno okolje.

## Strategije implementacije v produkciji in sklepanje

### Ollama: Poenostavljena lokalna implementacija

Ollama poenostavi implementacijo modelov z funkcijami, pripravljenimi za podjetja, za lokalna in robna okolja:

**Zmogljivosti implementacije**: Namestitev in izvajanje modelov z enim ukazom z avtomatskim pridobivanjem in predpomnjenjem modelov. Podpora za različne kvantizirane formate z REST API-jem za integracijo aplikacij ter zmogljivosti za upravljanje in preklapljanje med več modeli. Napredne ravni kvantizacije zahtevajo specifične konfiguracije za optimalno implementacijo.

**Napredne funkcije**: Podpora za prilagajanje modelov, generiranje datotek Dockerfile za implementacijo v kontejnerjih, pospeševanje GPU z avtomatskim zaznavanjem ter možnosti kvantizacije in optimizacije modelov zagotavljajo celovito prilagodljivost implementacije.

### VLLM: Sklepanje z visoko zmogljivostjo

VLLM zagotavlja optimizacijo sklepanja na ravni produkcije za scenarije z visoko prepustnostjo:

**Optimizacije zmogljivosti**: PagedAttention za učinkovito računsko obdelavo pozornosti, dinamično združevanje za optimizacijo prepustnosti, paralelizem tenzorjev za skaliranje na več GPU-jih in spekulativno dekodiranje za zmanjšanje zakasnitve. Napredni kvantizirani formati zahtevajo specializirane jedrne funkcije za sklepanje za optimalno zmogljivost.

**Integracija v podjetjih**: API končne točke, združljive z OpenAI, podpora za implementacijo v Kubernetesu, integracija za spremljanje in opazovanje ter zmogljivosti samodejnega skaliranja zagotavljajo rešitve za implementacijo na ravni podjetja.

### Microsoftove rešitve za rob

Microsoft zagotavlja celovite zmogljivosti implementacije na robu za okolja podjetij:

**Funkcije robnega računalništva**: Zasnova arhitekture "offline-first" z optimizacijo za omejene vire, upravljanje lokalnega registra modelov in zmogljivosti sinhronizacije med robom in oblakom zagotavljajo zanesljivo implementacijo na robu.

**Varnost in skladnost**: Lokalna obdelava podatkov za ohranjanje zasebnosti, varnostni nadzori na ravni podjetja, beleženje revizij in poročanje o skladnosti ter upravljanje dostopa na podlagi vlog zagotavljajo celovito varnost za implementacije na robu.

## Najboljše prakse za implementacijo kvantizacije modelov

### Smernice za izbiro ravni kvantizacije

Pri izbiri ravni kvantizacije za implementacijo na robu upoštevajte naslednje dejavnike:

**Premisleki o številu natančnosti**: Izberite zelo nizko natančnost, kot je Q2_K, za ekstremne mobilne aplikacije, nizko natančnost, kot je Q4_K_M, za uravnotežene scenarije zmogljivosti, in srednjo natančnost, kot je Q8_0, ko se približujete zmogljivostim modelov s polno natančnostjo ob ohranjanju učinkovitosti. Eksperimentalni formati ponujajo specializirano stiskanje za specifične raziskovalne aplikacije.

**Usklajenost s primerom uporabe**: Ujemajte zmogljivosti kvantizacije s specifičnimi zahtevami aplikacije, pri čemer upoštevajte dejavnike, kot so ohranjanje natančnosti, hitrost sklepanja, omejitve pomnilnika in zahteve za delovanje brez povezave.

### Izbira strategije optimizacije

**Pristop kvantizacije**: Izberite ustrezne ravni kvantizacije glede na zahteve glede kakovosti in omejitve strojne opreme. Upoštevajte Q4_0 za maksimalno stiskanje, Q5_1 za uravnotežene kompromise med kakovostjo in stiskanjem ter Q8_0 za ohranjanje skoraj originalne kakovosti. Eksperimentalni formati predstavljajo mejo ekstremnega stiskanja za specializirane aplikacije.

**Izbira okvira**: Izberite optimizacijske okvire glede na ciljno strojno opremo in zahteve implementacije. Uporabite Llama.cpp za implementacijo, optimizirano za CPU, Microsoft Olive za celovite delovne tokove optimizacije in Apple MLX za naprave Apple Silicon.

## Praktične pretvorbe formatov in primeri uporabe

### Scenariji implementacije v resničnem svetu

**Mobilne aplikacije**: Formati Q4_K odlično delujejo v aplikacijah za pametne telefone z minimalnim pomnilniškim odtisom, medtem ko Q8_0 zagotavlja uravnoteženo zmogljivost za aplikacije na tabličnih računalnikih. Formati Q5_K ponujajo vrhunsko kakovost za mobilne produktivne aplikacije.

**Namizno in robno računalništvo**: Q5_K zagotavlja optimalno zmogljivost za namizne aplikacije, Q8_0 ponuja visokokakovostno sklepanje za delovna okolja, Q4_K pa omogoča učinkovito obdelavo na robnih napravah.

**Raziskave in eksperimentalno**: Napredni formati kvantizacije omogočajo raziskovanje sklepanja z zelo nizko natančnostjo za akademske raziskave in aplikacije dokazovanja koncepta, ki zahtevajo ekstremne omejitve virov.

### Primerjalna merila zmogljivosti

**Hitrost sklepanja**: Q4_K dosega najhitrejše čase sklepanja na mobilnih CPU-jih, Q5_K zagotavlja uravnoteženo razmerje med hitrostjo in kakovostjo za splošne aplikacije, Q8_0 ponuja vrhunsko kakovost za kompleksne naloge, eksperimentalni formati pa zagotavljajo teoretično maksimalno prepustnost s specializirano strojno opremo.

**Zahteve po pomnilniku**: Ravni kvantizacije segajo od Q2_K (manj kot 500 MB za majhne modele) do Q8_0 (približno 50 % originalne velikosti), pri čemer eksperimentalne konfiguracije dosežejo maksimalna razmerja stiskanja.

## Izzivi in premisleki

### Kompromisi zmogljivosti

Implementacija kvantizacije zahteva skrbno razmislek o kompromisih med velikostjo modela, hitrostjo sklepanja in kakovostjo izhoda. Medtem ko Q4_K ponuja izjemno hitrost in učinkovitost, Q8_0 zagotavlja vrhunsko kakovost na račun povečanih zahtev po virih. Q5_K predstavlja srednjo pot, primerno za večino splošnih aplikacij.

### Združljivost strojne opreme

Različne robne naprave imajo različne zmogljivosti in omejitve. Q4_K deluje učinkovito na osnovnih procesorjih, Q5_K zahteva zmerne računske vire, Q8_0 pa koristi zmogljivejši strojni opremi. Eksperimentalni formati zahtevajo specializirano strojno ali programsko opremo za optimalno delovanje.

### Varnost in zasebnost

Medtem ko kvantizirani modeli omogočajo lokalno obdelavo za izboljšano zasebnost, je treba uvesti ustrezne varnostne ukrepe za zaščito modelov in podatkov v robnih okoljih. To je še posebej pomembno pri implementaciji

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitne nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.