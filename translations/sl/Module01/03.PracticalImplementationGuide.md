<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c37dfe660161e652077f6b7b23bb2167",
  "translation_date": "2025-10-11T14:47:13+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "sl"
}
-->
# Poglavje 3: Praktični vodič za implementacijo

## Pregled

Ta obsežen vodič vam bo pomagal pripraviti se na tečaj EdgeAI, ki se osredotoča na gradnjo praktičnih AI rešitev, ki učinkovito delujejo na robnih napravah. Tečaj poudarja praktični razvoj z uporabo sodobnih ogrodij in najsodobnejših modelov, optimiziranih za robno uporabo.

## 1. Nastavitev razvojnega okolja

### Programski jeziki in ogrodja

**Python okolje**
- **Različica**: Python 3.10 ali novejši (priporočeno: Python 3.11)
- **Upravitelj paketov**: pip ali conda
- **Virtualno okolje**: Uporabite venv ali conda okolja za izolacijo
- **Ključne knjižnice**: Specifične knjižnice za EdgeAI bomo namestili med tečajem

**Microsoft .NET okolje**
- **Različica**: .NET 8 ali novejši
- **IDE**: Visual Studio 2022, Visual Studio Code ali JetBrains Rider
- **SDK**: Poskrbite, da je .NET SDK nameščen za razvoj na več platformah

### Razvojna orodja

**Urejevalniki kode in IDE-ji**
- Visual Studio Code (priporočeno za razvoj na več platformah)
- PyCharm ali Visual Studio (za razvoj specifičen za jezik)
- Jupyter Notebooks za interaktivni razvoj in prototipiranje

**Nadzor različic**
- Git (najnovejša različica)
- GitHub račun za dostop do repozitorijev in sodelovanje

## 2. Zahteve glede strojne opreme in priporočila

### Minimalne sistemske zahteve
- **CPU**: Večjedrni procesor (Intel i5/AMD Ryzen 5 ali enakovreden)
- **RAM**: Minimalno 8GB, priporočeno 16GB
- **Shramba**: 50GB prostega prostora za modele in razvojna orodja
- **OS**: Windows 10/11, macOS 10.15+ ali Linux (Ubuntu 20.04+)

### Strategija računalniških virov
Tečaj je zasnovan tako, da je dostopen na različnih konfiguracijah strojne opreme:

**Lokalni razvoj (osredotočen na CPU/NPU)**
- Primarni razvoj bo uporabljal CPU in NPU pospeševanje
- Primerno za večino sodobnih prenosnikov in namiznih računalnikov
- Poudarek na učinkovitosti in praktičnih scenarijih uporabe

**Cloud GPU viri (neobvezno)**
- **Azure Machine Learning**: Za intenzivno učenje in eksperimentiranje
- **Google Colab**: Na voljo brezplačna različica za izobraževalne namene
- **Kaggle Notebooks**: Alternativna platforma za računalništvo v oblaku

### Razmisleki o robnih napravah
- Razumevanje procesorjev, ki temeljijo na ARM
- Poznavanje omejitev mobilne in IoT strojne opreme
- Seznanjenost z optimizacijo porabe energije

## 3. Osnovne družine modelov in viri

### Primarne družine modelov

**Microsoft Phi-4 družina**
- **Opis**: Kompaktni, učinkoviti modeli, zasnovani za robno uporabo
- **Prednosti**: Odlično razmerje med zmogljivostjo in velikostjo, optimizirani za naloge sklepanja
- **Vir**: [Phi-4 zbirka na Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Uporaba**: Generiranje kode, matematično sklepanje, splošni pogovori

**Qwen-3 družina**
- **Opis**: Najnovejša generacija večjezičnih modelov podjetja Alibaba
- **Prednosti**: Močne večjezične zmogljivosti, učinkovita arhitektura
- **Vir**: [Qwen-3 zbirka na Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Uporaba**: Večjezične aplikacije, medkulturne AI rešitve

**Google Gemma-3n družina**
- **Opis**: Googlov lahki modeli, optimizirani za robno uporabo
- **Prednosti**: Hitro sklepanje, arhitektura prijazna mobilnim napravam
- **Vir**: [Gemma-3n zbirka na Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Uporaba**: Mobilne aplikacije, obdelava v realnem času

### Merila za izbiro modelov
- **Razmerje med zmogljivostjo in velikostjo**: Razumevanje, kdaj izbrati manjše ali večje modele
- **Optimizacija za specifične naloge**: Ujemanje modelov s specifičnimi primeri uporabe
- **Omejitve pri uporabi**: Pomnilnik, zakasnitve in poraba energije

## 4. Orodja za kvantizacijo in optimizacijo

### Llama.cpp ogrodje
- **Repozitorij**: [Llama.cpp na GitHub](https://github.com/ggml-org/llama.cpp)
- **Namen**: Visoko zmogljiv pogonski mehanizem za LLM-je
- **Ključne funkcije**:
  - Optimizirano sklepanje na CPU
  - Več formatov kvantizacije (Q4, Q5, Q8)
  - Združljivost na več platformah
  - Učinkovito izvajanje glede na pomnilnik
- **Namestitev in osnovna uporaba**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Repozitorij**: [Microsoft Olive na GitHub](https://github.com/microsoft/olive)
- **Namen**: Orodje za optimizacijo modelov za robno uporabo
- **Ključne funkcije**:
  - Avtomatizirani delovni tokovi za optimizacijo modelov
  - Optimizacija glede na strojno opremo
  - Integracija z ONNX Runtime
  - Orodja za primerjalno analizo zmogljivosti
- **Namestitev in osnovna uporaba**:
  ```bash
  # Install Olive
  pip install olive-ai
  ```
  
  # Primer Python skripte za optimizacijo modela
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (macOS uporabniki)
- **Repozitorij**: [Apple MLX na GitHub](https://github.com/ml-explore/mlx)
- **Namen**: Ogrodje za strojno učenje za Apple Silicon
- **Ključne funkcije**:
  - Optimizacija za Apple Silicon
  - Učinkovite operacije glede na pomnilnik
  - API podoben PyTorch
  - Podpora za enotno arhitekturo pomnilnika
- **Namestitev in osnovna uporaba**:
  ```bash
  # Install MLX
  pip install mlx
  ```
  
  ```python
  # Example Python script for loading and optimizing a model
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Repozitorij**: [ONNX Runtime na GitHub](https://github.com/microsoft/onnxruntime)
- **Namen**: Pospeševanje sklepanja za ONNX modele na več platformah
- **Ključne funkcije**:
  - Optimizacije specifične za strojno opremo (CPU, GPU, NPU)
  - Optimizacije grafov za sklepanje
  - Podpora za kvantizacijo
  - Podpora za več jezikov (Python, C++, C#, JavaScript)
- **Namestitev in osnovna uporaba**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. Priporočeno branje in viri

### Ključna dokumentacija
- **ONNX Runtime dokumentacija**: Razumevanje sklepanja na več platformah
- **Hugging Face Transformers vodič**: Nalaganje modelov in sklepanje
- **Vzorci oblikovanja Edge AI**: Najboljše prakse za robno uporabo

### Tehnični članki
- "Učinkovit Edge AI: Pregled tehnik kvantizacije"
- "Kompresija modelov za mobilne in robne naprave"
- "Optimizacija Transformer modelov za robno računalništvo"

### Skupnostni viri
- **EdgeAI Slack/Discord skupnosti**: Podpora vrstnikov in razprave
- **GitHub repozitoriji**: Primeri implementacij in vodiči
- **YouTube kanali**: Tehnične poglobitve in vodiči

## 6. Ocena in preverjanje

### Predtečajni kontrolni seznam
- [ ] Nameščen in preverjen Python 3.10+
- [ ] Nameščen in preverjen .NET 8+
- [ ] Konfigurirano razvojno okolje
- [ ] Ustvarjen Hugging Face račun
- [ ] Osnovno poznavanje ciljnih družin modelov
- [ ] Nameščena in testirana orodja za kvantizacijo
- [ ] Izpolnjene zahteve glede strojne opreme
- [ ] Nastavljeni računi za računalništvo v oblaku (če je potrebno)

## Ključni cilji učenja

Do konca tega vodiča boste sposobni:

1. Nastaviti popolno razvojno okolje za razvoj EdgeAI aplikacij
2. Namestiti in konfigurirati potrebna orodja in ogrodja za optimizacijo modelov
3. Izbrati ustrezne konfiguracije strojne in programske opreme za vaše EdgeAI projekte
4. Razumeti ključne vidike pri uporabi AI modelov na robnih napravah
5. Pripraviti svoj sistem za praktične vaje v tečaju

## Dodatni viri

### Uradna dokumentacija
- **Python dokumentacija**: Uradna dokumentacija za programski jezik Python
- **Microsoft .NET dokumentacija**: Uradni viri za razvoj z .NET
- **ONNX Runtime dokumentacija**: Celovit vodič za ONNX Runtime
- **TensorFlow Lite dokumentacija**: Uradna dokumentacija za TensorFlow Lite

### Razvojna orodja
- **Visual Studio Code**: Lahek urejevalnik kode z razširitvami za AI razvoj
- **Jupyter Notebooks**: Interaktivno računalniško okolje za eksperimentiranje z ML
- **Docker**: Platforma za kontejnerizacijo za dosledna razvojna okolja
- **Git**: Sistem za nadzor različic za upravljanje kode

### Učni viri
- **EdgeAI raziskovalni članki**: Najnovejše akademske raziskave o učinkovitih modelih
- **Spletni tečaji**: Dodatni učni materiali o optimizaciji AI
- **Skupnostni forumi**: Platforme za vprašanja in odgovore o izzivih pri razvoju EdgeAI
- **Primerjalni podatkovni nabori**: Standardni podatkovni nabori za ocenjevanje zmogljivosti modelov

## Rezultati učenja

Po zaključku tega pripravljalnega vodiča boste:

1. Imeli popolnoma konfigurirano razvojno okolje, pripravljeno za razvoj EdgeAI
2. Razumeli zahteve glede strojne in programske opreme za različne scenarije uporabe
3. Seznanjeni s ključnimi ogrodji in orodji, ki se uporabljajo med tečajem
4. Sposobni izbrati ustrezne modele glede na omejitve naprav in zahteve
5. Imeli osnovno znanje o tehnikah optimizacije za robno uporabo

## ➡️ Kaj sledi

- [04: EdgeAI strojna oprema in uporaba](04.EdgeDeployment.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.