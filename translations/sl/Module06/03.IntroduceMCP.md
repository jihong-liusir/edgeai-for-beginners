<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bd5b920b610665fd0462f6b5c2e134",
  "translation_date": "2025-09-18T23:53:28+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "sl"
}
-->
# Poglavje 03 - Integracija protokola Model Context Protocol (MCP)

## Uvod v MCP (Model Context Protocol)

Model Context Protocol (MCP) je revolucionarni okvir, ki omogoča jezikovnim modelom interakcijo z zunanjimi orodji in sistemi na standardiziran način. Za razliko od tradicionalnih pristopov, kjer so modeli izolirani, MCP vzpostavi most med AI modeli in resničnim svetom prek jasno definiranega protokola.

### Kaj je MCP?

MCP deluje kot komunikacijski protokol, ki jezikovnim modelom omogoča:
- Povezovanje z zunanjimi viri podatkov
- Izvajanje orodij in funkcij
- Interakcijo z API-ji in storitvami
- Dostop do informacij v realnem času
- Izvajanje kompleksnih večstopenjskih operacij

Ta protokol spremeni statične jezikovne modele v dinamične agente, sposobne opravljati praktične naloge, ki presegajo generiranje besedila.

## Mali jezikovni modeli (SLM) v MCP

Mali jezikovni modeli predstavljajo učinkovit pristop k razvoju AI, ki ponuja številne prednosti:

### Prednosti SLM-jev
- **Učinkovitost virov**: Nižje zahteve po računalniški moči
- **Hitrejši odzivni časi**: Zmanjšana zakasnitev za aplikacije v realnem času  
- **Stroškovna učinkovitost**: Minimalne infrastrukturne potrebe
- **Zasebnost**: Lahko delujejo lokalno brez prenosa podatkov
- **Prilagodljivost**: Lažje prilagajanje za specifična področja

### Zakaj SLM-ji dobro delujejo z MCP

SLM-ji v kombinaciji z MCP ustvarijo močno povezavo, kjer so sposobnosti sklepanja modela okrepljene z zunanjimi orodji, kar kompenzira njihovo manjše število parametrov z izboljšano funkcionalnostjo.

## Pregled Python MCP SDK

Python MCP SDK zagotavlja osnovo za gradnjo aplikacij, ki podpirajo MCP. SDK vključuje:

- **Odjemalske knjižnice**: Za povezovanje z MCP strežniki
- **Okvir strežnika**: Za ustvarjanje prilagojenih MCP strežnikov
- **Upravljalnike protokola**: Za upravljanje komunikacije
- **Integracijo orodij**: Za izvajanje zunanjih funkcij

## Praktična implementacija: Phi-4 MCP odjemalec

Raziskali bomo praktično implementacijo z uporabo mini modela Phi-4 podjetja Microsoft, integriranega z zmogljivostmi MCP.

### Arhitektura sistema

Implementacija sledi slojeviti arhitekturi:

```
┌─────────────────────────────────────┐
│        Application Layer           │
│  ├── Interactive Loop              │
│  ├── CLI Interface                 │
│  └── Configuration Management      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│         LLM Client Layer           │
│  ├── OllamaClient                  │
│  ├── VLLMClient                    │
│  └── LLMClient (Abstract)          │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│        MCP Client Layer            │
│  ├── Phi4MiniMCPClient (STDIO)     │
│  ├── Phi4MiniSSEMCPClient (SSE)    │
│  └── BaseMCPClient (Abstract)      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│      Tool Processing Layer         │
│  ├── ToolCallHandler               │
│  ├── Function Format Transformer   │
│  └── Tool Schema Management        │
└─────────────────────────────────────┘
```

### Osnovne komponente

#### 1. Razredi MCP odjemalcev

**BaseMCPClient**: Abstraktna osnova, ki zagotavlja skupno funkcionalnost
- Protokol asinhronega upravljanja konteksta
- Standardna definicija vmesnika
- Upravljanje virov

**Phi4MiniMCPClient**: Implementacija na osnovi STDIO
- Lokalna komunikacija procesov
- Upravljanje standardnega vnosa/iznosa
- Upravljanje podprocesov

**Phi4MiniSSEMCPClient**: Implementacija na osnovi dogodkov, poslanih s strežnika
- HTTP komunikacija s pretakanjem
- Upravljanje dogodkov v realnem času
- Povezljivost s spletnimi strežniki

#### 2. Integracija LLM

**OllamaClient**: Gostovanje lokalnega modela
```python
class OllamaClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:11434/api/chat"
        self.model_id = "phi4-mini:3.8b-fp16"
```

**VLLMClient**: Visoko zmogljivo strežnikovanje
```python
class VLLMClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:8000/v1"
        self.model_id = "microsoft/Phi-4-mini-instruct"
```

#### 3. Cevovod za obdelavo orodij

Cevovod za obdelavo orodij pretvori MCP orodja v formate, združljive z jezikovnimi modeli:

```python
def transform_functions_format(input_data):
    """Convert MCP tool schemas to LLM-compatible formats"""
    # Maps OpenAPI schemas to function calling schemas
    # Handles parameter type conversion
    # Maintains required field information
```

## Začetek: Vodnik po korakih

### Korak 1: Nastavitev okolja

Namestite potrebne odvisnosti:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Korak 2: Osnovna konfiguracija

Nastavite spremenljivke okolja:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Korak 3: Zagon prvega MCP odjemalca

**Osnovna nastavitev Ollama:**
```bash
python ghmodel_mcp_demo.py
```

**Uporaba vLLM zaledja:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Povezava prek dogodkov, poslanih s strežnika:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Prilagojen MCP strežnik:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Korak 4: Programska uporaba

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Napredne funkcije

### Podpora za več zaledij

Implementacija podpira tako Ollama kot vLLM zaledja, kar omogoča izbiro glede na vaše zahteve:

- **Ollama**: Boljše za lokalni razvoj in testiranje
- **vLLM**: Optimizirano za produkcijo in scenarije z visokim pretokom

### Prilagodljivi komunikacijski protokoli

Podprta sta dva načina povezave:

**STDIO način**: Neposredna komunikacija procesov
- Nižja zakasnitev
- Primerno za lokalna orodja
- Enostavna nastavitev

**SSE način**: Pretakanje na osnovi HTTP
- Omogoča povezljivost v omrežju
- Boljše za porazdeljene sisteme
- Posodobitve v realnem času

### Zmožnosti integracije orodij

Sistem lahko integrira različna orodja:
- Spletna avtomatizacija (Playwright)
- Operacije z datotekami
- Interakcije z API-ji
- Sistemski ukazi
- Prilagojene funkcije

## Upravljanje napak in najboljše prakse

### Celovito upravljanje napak

Implementacija vključuje robustno upravljanje napak za:

**Napake povezave:**
- Okvare MCP strežnika
- Časovne omejitve omrežja
- Težave s povezljivostjo

**Napake pri izvajanju orodij:**
- Manjkajoča orodja
- Validacija parametrov
- Napake pri izvajanju

**Napake pri obdelavi odgovorov:**
- Težave pri razčlenjevanju JSON
- Neskladnosti formatov
- Anomalije v odgovorih LLM

### Najboljše prakse

1. **Upravljanje virov**: Uporabljajte asinhrone upravljalnike konteksta
2. **Upravljanje napak**: Implementirajte celovite try-catch bloke
3. **Beleženje**: Omogočite ustrezne ravni beleženja
4. **Varnost**: Validirajte vhodne podatke in sanirajte izhodne
5. **Zmogljivost**: Uporabljajte združevanje povezav in predpomnjenje

## Praktične aplikacije

### Spletna avtomatizacija
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Obdelava podatkov
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### Integracija API-jev
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Optimizacija zmogljivosti

### Upravljanje pomnilnika
- Učinkovito upravljanje zgodovine sporočil
- Pravilno čiščenje virov
- Združevanje povezav

### Optimizacija omrežja
- Asinhrone HTTP operacije
- Nastavljive časovne omejitve
- Graciozno okrevanje po napakah

### Sočasna obdelava
- Neblokirajoči vhod/izhod
- Vzporedno izvajanje orodij
- Učinkoviti asinhroni vzorci

## Varnostni vidiki

### Zaščita podatkov
- Varno upravljanje API ključev
- Validacija vhodnih podatkov
- Sanacija izhodnih podatkov

### Omrežna varnost
- Podpora za HTTPS
- Privzete lokalne končne točke
- Varno upravljanje žetonov

### Varnost izvajanja
- Filtriranje orodij
- Peskovana okolja
- Beleženje revizij

## Zaključek

SLM-ji, integrirani z MCP, predstavljajo premik paradigme v razvoju AI aplikacij. Z združevanjem učinkovitosti majhnih modelov in moči zunanjih orodij lahko razvijalci ustvarijo inteligentne sisteme, ki so hkrati učinkoviti z viri in zelo zmogljivi.

Implementacija Phi-4 MCP odjemalca prikazuje, kako je to integracijo mogoče doseči v praksi, ter zagotavlja trdno osnovo za gradnjo sofisticiranih aplikacij, ki temeljijo na AI.

Ključne točke:
- MCP vzpostavi povezavo med jezikovnimi modeli in zunanjimi sistemi
- SLM-ji ponujajo učinkovitost brez žrtvovanja zmogljivosti, ko so okrepljeni z orodji
- Modularna arhitektura omogoča enostavno razširitev in prilagoditev
- Pravilno upravljanje napak in varnostni ukrepi so ključni za uporabo v produkciji

Ta vadnica zagotavlja osnovo za gradnjo lastnih aplikacij, ki temeljijo na SLM in MCP, ter odpira možnosti za avtomatizacijo, obdelavo podatkov in integracijo inteligentnih sistemov.

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.