<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-19T01:20:15+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "sl"
}
-->
# Poglavje 4: Implementacija modela, pripravljenega za produkcijo

## Pregled

Ta obsežen vodič vas bo korak za korakom vodil skozi celoten proces nameščanja fino uglašenih kvantiziranih modelov z uporabo Foundry Local. Pokrili bomo pretvorbo modela, optimizacijo kvantizacije in konfiguracijo namestitve od začetka do konca.

## Predpogoji

Preden začnete, poskrbite, da imate naslednje:

- ✅ Fino uglašen onnx model, pripravljen za namestitev
- ✅ Računalnik z operacijskim sistemom Windows ali Mac
- ✅ Python 3.10 ali novejši
- ✅ Vsaj 8GB razpoložljivega RAM-a
- ✅ Foundry Local nameščen na vašem sistemu

## 1. del: Nastavitev okolja

### Namestitev potrebnih orodij

Odprite terminal (Command Prompt na Windowsu, Terminal na Macu) in zaporedoma zaženite naslednje ukaze:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

⚠️ **Pomembno obvestilo**: Potrebovali boste tudi CMake različice 3.31 ali novejše, ki ga lahko prenesete z [cmake.org](https://cmake.org/download/).

## 2. del: Pretvorba modela in kvantizacija

### Izbira pravega formata

Za fino uglašene manjše jezikovne modele priporočamo uporabo **ONNX formata**, ker ponuja:

- 🚀 Boljšo optimizacijo zmogljivosti
- 🔧 Neodvisnost od strojne opreme
- 🏭 Zmožnosti za produkcijo
- 📱 Združljivost med platformami

### Metoda 1: Pretvorba z enim ukazom (priporočeno)

Uporabite naslednji ukaz za neposredno pretvorbo vašega fino uglašenega modela:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**Pojasnilo parametrov:**
- `--model_name_or_path`: Pot do vašega fino uglašenega modela
- `--device cpu`: Uporaba CPU za optimizacijo
- `--precision int4`: Uporaba INT4 kvantizacije (približno 75% zmanjšanje velikosti)
- `--output_path`: Pot za shranjevanje pretvorjenega modela

### Metoda 2: Pristop z uporabo konfiguracijske datoteke (za napredne uporabnike)

Ustvarite konfiguracijsko datoteko z imenom `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

Nato zaženite:

```bash
olive run --config ./finetuned_conversion_config.json
```

### Primerjava možnosti kvantizacije

| Natančnost | Velikost datoteke | Hitrost sklepanja | Kakovost modela | Priporočena uporaba |
|------------|-------------------|-------------------|-----------------|---------------------|
| FP16       | Osnovna × 0.5     | Hitro             | Najboljša       | Napredna strojna oprema |
| INT8       | Osnovna × 0.25    | Zelo hitro        | Dobra           | Uravnotežena izbira |
| INT4       | Osnovna × 0.125   | Najhitrejša       | Sprejemljiva    | Omejeni viri |

💡 **Priporočilo**: Za prvo namestitev začnite z INT4 kvantizacijo. Če kakovost ni zadovoljiva, poskusite z INT8 ali FP16.

## 3. del: Konfiguracija namestitve Foundry Local

### Ustvarjanje konfiguracije modela

Pomaknite se do direktorija modelov Foundry Local:

```bash
foundry cache cd ./models/
```

Ustvarite strukturo direktorija za vaš model:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

Ustvarite konfiguracijsko datoteko `inference_model.json` v direktoriju vašega modela:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### Predloge konfiguracij za specifične modele

#### Za modele serije Qwen:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## 4. del: Testiranje in optimizacija modela

### Preverjanje namestitve modela

Preverite, ali Foundry Local prepozna vaš model:

```bash
foundry cache ls
```

Videti bi morali `your-finetuned-model-int4` na seznamu.

### Začetek testiranja modela

```bash
foundry model run your-finetuned-model-int4
```

### Primerjava zmogljivosti

Med testiranjem spremljajte ključne metrike:

1. **Čas odziva**: Merite povprečni čas na odziv
2. **Poraba pomnilnika**: Spremljajte porabo RAM-a
3. **Uporaba CPU**: Preverite obremenitev procesorja
4. **Kakovost izhoda**: Ocenite ustreznost in koherenco odzivov

### Kontrolni seznam za validacijo kakovosti

- ✅ Model ustrezno odgovarja na vprašanja iz fino uglašenega področja
- ✅ Format odziva ustreza pričakovani strukturi izhoda
- ✅ Brez uhajanja pomnilnika med daljšo uporabo
- ✅ Dosledna zmogljivost pri različnih dolžinah vhodnih podatkov
- ✅ Pravilno obravnavanje mejnih primerov in neveljavnih vhodov

## Povzetek

Čestitamo! Uspešno ste zaključili:

- ✅ Pretvorbo formata fino uglašenega modela
- ✅ Optimizacijo kvantizacije modela
- ✅ Konfiguracijo namestitve Foundry Local
- ✅ Prilagoditev zmogljivosti in odpravljanje težav

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.