<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-19T01:15:41+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "sl"
}
-->
# Poglavje 3: Fino prilagajanje - Prilagajanje modelov za specifične naloge

## Kazalo
1. [Uvod v fino prilagajanje](../../../Module05)
2. [Zakaj je fino prilagajanje pomembno](../../../Module05)
3. [Vrste finega prilagajanja](../../../Module05)
4. [Fino prilagajanje z Microsoft Olive](../../../Module05)
5. [Praktični primeri](../../../Module05)
6. [Najboljše prakse in smernice](../../../Module05)
7. [Napredne tehnike](../../../Module05)
8. [Vrednotenje in spremljanje](../../../Module05)
9. [Pogoste težave in rešitve](../../../Module05)
10. [Zaključek](../../../Module05)

## Uvod v fino prilagajanje

**Fino prilagajanje** je zmogljiva tehnika strojnega učenja, ki vključuje prilagajanje že izurjenega modela za izvajanje specifičnih nalog ali delo s specializiranimi podatkovnimi nabori. Namesto da bi model trenirali od začetka, fino prilagajanje izkoristi že pridobljeno znanje predhodno izurjenega modela in ga prilagodi za vaš specifični primer uporabe.

### Kaj je fino prilagajanje?

Fino prilagajanje je oblika **prenosnega učenja**, kjer:
- Začnete z že izurjenim modelom, ki je pridobil splošne vzorce iz velikih podatkovnih naborov
- Prilagodite notranje parametre modela z vašim specifičnim podatkovnim naborom
- Ohranite dragoceno znanje, medtem ko model specializirate za svojo nalogo

Pomislite na to kot na učenje izkušenega kuharja nove kuhinje – že razumejo osnove kuhanja, vendar se morajo naučiti specifičnih tehnik in okusov za nov slog.

### Ključne prednosti

- **Časovna učinkovitost**: Znatno hitrejše kot treniranje od začetka
- **Učinkovitost podatkov**: Zahteva manjše podatkovne nabore za dosego dobrih rezultatov
- **Stroškovna učinkovitost**: Nižje zahteve po računalniških virih
- **Boljša zmogljivost**: Pogosto doseže boljše rezultate v primerjavi s treniranjem od začetka
- **Optimizacija virov**: Omogoča dostop do zmogljive umetne inteligence manjšim ekipam in organizacijam

## Zakaj je fino prilagajanje pomembno

### Uporaba v resničnem svetu

Fino prilagajanje je ključno v številnih scenarijih:

**1. Prilagoditev domeni**
- Medicinska umetna inteligenca: Prilagajanje splošnih jezikovnih modelov za medicinsko terminologijo in klinične zapiske
- Pravna tehnologija: Specializacija modelov za analizo pravnih dokumentov in pregled pogodb
- Finančne storitve: Prilagajanje modelov za analizo finančnih poročil in oceno tveganja

**2. Specializacija nalog**
- Generiranje vsebine: Fino prilagajanje za specifične sloge pisanja ali tone
- Generiranje kode: Prilagajanje modelov za določene programske jezike ali ogrodja
- Prevajanje: Izboljšanje zmogljivosti za specifične jezikovne pare ali tehnične domene

**3. Korporativne aplikacije**
- Pomoč strankam: Ustvarjanje chatbotov, ki razumejo specifično terminologijo podjetja
- Interna dokumentacija: Gradnja AI asistentov, ki poznajo organizacijske procese
- Rešitve po industrijah: Razvoj modelov, ki razumejo specifičen žargon in delovne tokove v sektorju

## Vrste finega prilagajanja

### 1. Polno fino prilagajanje (Instruction Fine-Tuning)

Pri polnem finem prilagajanju se med treningom posodobijo vsi parametri modela. Ta pristop:
- Omogoča največjo prilagodljivost in potencial zmogljivosti
- Zahteva znatne računalniške vire
- Rezultira v popolnoma novi različici modela
- Najbolj primeren za scenarije, kjer imate obsežne podatke za trening in računalniške vire

### 2. Učinkovito fino prilagajanje parametrov (PEFT)

Metode PEFT posodobijo le majhen podnabor parametrov, kar proces naredi bolj učinkovit:

#### Low-Rank Adaptation (LoRA)
- Dodaja majhne matrike za razgradnjo rangov k obstoječim težam
- Znatno zmanjša število parametrov za trening
- Ohranja zmogljivost blizu polnega finega prilagajanja
- Omogoča enostavno preklapljanje med različnimi prilagoditvami

#### QLoRA (Quantized LoRA)
- Kombinira LoRA s kvantizacijskimi tehnikami
- Še dodatno zmanjša zahteve po pomnilniku
- Omogoča fino prilagajanje večjih modelov na potrošniški strojni opremi
- Uravnava učinkovitost z zmogljivostjo

#### Adapterji
- Vstavi majhne nevronske mreže med obstoječe sloje
- Omogoča ciljno fino prilagajanje, medtem ko osnovni model ostane zamrznjen
- Omogoča modularni pristop k prilagoditvi modela

### 3. Fino prilagajanje specifično za nalogo

Osredotoča se na prilagajanje modelov za specifične naloge:
- **Klasifikacija**: Prilagajanje modelov za naloge kategorizacije
- **Generiranje**: Optimizacija za ustvarjanje vsebine in generiranje besedila
- **Ekstrakcija**: Fino prilagajanje za ekstrakcijo informacij in prepoznavanje imenovanih entitet
- **Povzemanje**: Specializacija modelov za povzemanje dokumentov

## Fino prilagajanje z Microsoft Olive

Microsoft Olive je celovit komplet za optimizacijo modelov, ki poenostavi proces finega prilagajanja in ponuja funkcije na ravni podjetij.

### Kaj je Microsoft Olive?

Microsoft Olive je odprtokodno orodje za optimizacijo modelov, ki:
- Poenostavi delovne tokove finega prilagajanja za različne strojne cilje
- Ponuja vgrajeno podporo za priljubljene arhitekture modelov (Llama, Phi, Qwen, Gemma)
- Omogoča tako oblačne kot lokalne možnosti uvajanja
- Se brezhibno integrira z Azure ML in drugimi Microsoftovimi AI storitvami
- Podpira samodejno optimizacijo in kvantizacijo

### Ključne funkcije

- **Optimizacija glede na strojno opremo**: Samodejno optimizira modele za specifično strojno opremo (CPU, GPU, NPU)
- **Podpora za več formatov**: Deluje s PyTorch, Hugging Face in ONNX modeli
- **Samodejni delovni tokovi**: Zmanjša ročno konfiguracijo in poskuse
- **Integracija na ravni podjetja**: Vgrajena podpora za Azure ML in oblačne uvajanja
- **Razširljiva arhitektura**: Omogoča prilagojene tehnike optimizacije

### Namestitev in nastavitev

#### Osnovna namestitev

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Izbirne odvisnosti

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Preverjanje namestitve

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Praktični primeri

### Primer 1: Osnovno fino prilagajanje z Olive CLI

Ta primer prikazuje fino prilagajanje majhnega jezikovnega modela za klasifikacijo fraz:

#### Korak 1: Priprava okolja

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Korak 2: Fino prilagajanje modela

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Korak 3: Optimizacija za uvajanje

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Primer 2: Napredna konfiguracija s prilagojenim podatkovnim naborom

#### Korak 1: Priprava prilagojenega podatkovnega nabora

Ustvarite JSON datoteko s podatki za trening:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Korak 2: Ustvarjanje konfiguracijske datoteke

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Korak 3: Izvedba finega prilagajanja

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Primer 3: QLoRA fino prilagajanje za pomnilniško učinkovitost

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Najboljše prakse in smernice

### Priprava podatkov

**1. Kakovost podatkov pred količino**
- Dajte prednost visokokakovostnim, raznolikim primerom pred velikimi količinami slabih podatkov
- Poskrbite, da so podatki reprezentativni za vaš ciljni primer uporabe
- Dosledno čistite in predprocesirajte podatke

**2. Format podatkov in predloge**
- Uporabljajte dosledno formatiranje med vsemi primeri za trening
- Ustvarite jasne vhodno-izhodne predloge, ki ustrezajo vašemu primeru uporabe
- Vključite ustrezno formatiranje navodil za modele, prilagojene navodilom

**3. Razdelitev podatkov**
- Rezervirajte 10-20 % podatkov za validacijo
- Ohranite podobne porazdelitve med razdelitvami za trening/validacijo
- Razmislite o stratificiranem vzorčenju za naloge klasifikacije

### Konfiguracija treninga

**1. Izbira učne stopnje**
- Začnite z manjšimi učnimi stopnjami (1e-5 do 1e-4) za fino prilagajanje
- Uporabljajte načrtovanje učne stopnje za boljšo konvergenco
- Spremljajte krivulje izgube za prilagoditev stopenj

**2. Optimizacija velikosti serije**
- Uravnotežite velikost serije z razpoložljivim pomnilnikom
- Uporabljajte akumulacijo gradientov za večje efektivne velikosti serij
- Razmislite o razmerju med velikostjo serije in učno stopnjo

**3. Trajanje treninga**
- Spremljajte validacijske metrike, da se izognete prekomernemu prilagajanju
- Uporabljajte zgodnje ustavljanje, ko se validacijska zmogljivost ustali
- Redno shranjujte kontrolne točke za obnovitev in analizo

### Izbira modela

**1. Izbira osnovnega modela**
- Izberite modele, ki so predhodno izurjeni na podobnih domenah, kadar je to mogoče
- Razmislite o velikosti modela glede na vaše računalniške omejitve
- Ocenite zahteve glede licenciranja za komercialno uporabo

**2. Izbira metode finega prilagajanja**
- Uporabljajte LoRA/QLoRA za okolja z omejenimi viri
- Izberite polno fino prilagajanje, ko je ključna maksimalna zmogljivost
- Razmislite o pristopih, ki temeljijo na adapterjih, za scenarije z več nalogami

### Upravljanje virov

**1. Optimizacija strojne opreme**
- Izberite ustrezno strojno opremo glede na velikost modela in metodo
- Učinkovito uporabljajte pomnilnik GPU z kontrolnimi točkami gradientov
- Razmislite o rešitvah v oblaku za večje modele

**2. Upravljanje pomnilnika**
- Uporabljajte trening z mešano natančnostjo, kadar je na voljo
- Implementirajte akumulacijo gradientov za omejitve pomnilnika
- Spremljajte uporabo pomnilnika GPU med treningom

## Napredne tehnike

### Trening z več adapterji

Trenirajte več adapterjev za različne naloge, medtem ko delite osnovni model:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optimizacija hiperparametrov

Implementirajte sistematično prilagajanje hiperparametrov:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Prilagojene funkcije izgube

Implementirajte funkcije izgube, specifične za domeno:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Vrednotenje in spremljanje

### Metrike in vrednotenje

**1. Standardne metrike**
- **Natančnost**: Splošna pravilnost za naloge klasifikacije
- **Perpleksnost**: Merilo kakovosti jezikovnega modeliranja
- **BLEU/ROUGE**: Kakovost generiranja besedila in povzemanja
- **F1 rezultat**: Uravnotežena natančnost in priklic za klasifikacijo

**2. Metrike specifične za domeno**
- **Referenčne točke specifične za nalogo**: Uporabljajte uveljavljene referenčne točke za vašo domeno
- **Človeško vrednotenje**: Vključite oceno ljudi za subjektivne naloge
- **Poslovne metrike**: Uskladite z dejanskimi poslovnimi cilji

**3. Nastavitev vrednotenja**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Spremljanje napredka treninga

**1. Sledenje izgubi**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Spremljanje validacije**
- Spremljajte validacijsko izgubo skupaj z izgubo treninga
- Spremljajte znake prekomernega prilagajanja (validacijska izguba narašča, medtem ko izguba treninga upada)
- Uporabljajte zgodnje ustavljanje na podlagi validacijskih metrik

**3. Spremljanje virov**
- Spremljajte uporabo GPU/CPU
- Sledite vzorcem uporabe pomnilnika
- Spremljajte hitrost treninga in prepustnost

## Pogoste težave in rešitve

### Težava 1: Prekomerno prilagajanje

**Simptomi:**
- Izguba treninga se še naprej zmanjšuje, medtem ko se validacijska izguba povečuje
- Velika razlika med zmogljivostjo treninga in validacije
- Slaba generalizacija na nove podatke

**Rešitve:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Težava 2: Omejitve pomnilnika

**Rešitve:**
- Uporabljajte kontrolne točke gradientov
- Implementirajte akumulacijo gradientov
- Izberite metode, ki so učinkovite glede parametrov (LoRA, QLoRA)
- Uporabljajte paralelizacijo modela za velike modele

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Težava 3: Počasno treniranje

**Rešitve:**
- Optimizirajte podatkovne cevovode za nalaganje
- Uporabljajte trening z mešano natančnostjo
- Implementirajte učinkovite strategije serij
- Razmislite o porazdeljenem treningu za velike podatkovne nabore

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Težava 4: Slaba zmogljivost

**Koraki za diagnozo:**
1. Preverite kakovost in format podatkov
2. Preverite učno stopnjo in trajanje treninga
3. Ocenite izbiro osnovnega modela
4. Preglejte predprocesiranje in tokenizacijo

**Rešitve:**
- Povečajte raznolikost podatkov za trening
- Prilagodite načrt učne stopnje
- Preizkusite različne osnovne modele
- Implementirajte tehnike za povečanje podatkov

## Zaključek

Fino prilagajanje je zmogljiva tehnika, ki demokratizira dostop do najsodobnejših zmogljivosti umetne inteligence. Z uporabo orodij, kot je Microsoft Olive, lahko organizacije učinkovito prilagodijo predhodno izurjene modele svojim specifičnim potrebam, hkrati pa optimizirajo zmogljivost in omejitve virov.

### Ključne točke

1. **Izberite pravi pristop**: Izberite metode finega prilagajanja glede na vaše računalniške vire in zahteve glede zmogljivosti
2. **Kakovost podatkov je pomembna**: Vlagajte v visokokakovostne, reprezentativne podatke za trening
3. **Spremljajte in iterirajte**: Nenehno vrednotite in izboljšujte svoje modele
4. **Izkoristite orodja**: Uporabljajte ogrodja, kot je Olive, za poenostavitev in optimizacijo procesa
5. **Razmislite o uvajanju**: Načrtujte optimizacijo in uvajanje modela že od začetka

## ➡️ Kaj sledi

- [04: Uvajanje - Implementacija modela, pripravljena na produkcijo](./04.SLMOps

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitna napačna razumevanja ali napačne interpretacije, ki bi nastale zaradi uporabe tega prevoda.