<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:46:00+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "sl"
}
-->
# Poglavje 1: Osnove družine modelov Microsoft Phi

Družina modelov Microsoft Phi predstavlja prelomnico v umetni inteligenci, saj dokazuje, da lahko kompaktni in učinkoviti modeli dosežejo izjemno zmogljivost, hkrati pa so bistveno bolj varčni z viri kot tradicionalni veliki jezikovni modeli. Pomembno je razumeti, kako družina Phi omogoča zmogljive AI sposobnosti z zmanjšanimi računalniškimi zahtevami, pri tem pa ohranja visoko zmogljivost pri različnih nalogah.

## Viri za razvijalce

### Katalog modelov Azure AI Foundry
Družina modelov Phi (razen Phi-silica) je na voljo prek [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), kar razvijalcem omogoča enostaven dostop, prilagoditev in uporabo teh modelov v svojih aplikacijah. Katalog ponuja poenostavljen način za eksperimentiranje z različnimi različicami Phi in njihovo integracijo v projekte.

### Azure AI Foundry
Phi modele lahko namestite in preizkusite prek [Azure AI Foundry](https://ai.azure.com), ki zagotavlja celovito okolje za gradnjo, testiranje in uvajanje AI rešitev z minimalno pripravo.

### Foundry Local
Za lokalni razvoj in uvajanje si oglejte [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), ki omogoča izvajanje modelov Phi na vašem razvojnem računalniku z optimiziranimi konfiguracijami.

### Dokumentacija
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Uvod

V tej lekciji bomo raziskali družino modelov Microsoft Phi in njene temeljne koncepte. Pokrili bomo evolucijo družine Phi, inovativne metode učenja, ki omogočajo učinkovitost modelov Phi, ključne različice v družini ter praktične aplikacije v različnih scenarijih.

## Cilji učenja

Do konca te lekcije boste lahko:

- Razumeli filozofijo oblikovanja in evolucijo družine modelov Microsoft Phi.
- Prepoznali ključne inovacije, ki omogočajo modelom Phi doseganje visoke zmogljivosti z manj parametri.
- Spoznali prednosti in omejitve različnih različic modelov Phi.
- Uporabili znanje o modelih Phi za izbiro ustreznih različic v realnih scenarijih.

## Razumevanje tradicionalnega pristopa AI modelov

Tradicionalno je za doseganje visoke zmogljivosti pri obdelavi naravnega jezika potrebna uporaba velikih jezikovnih modelov z milijardami ali stotinami milijard parametrov. Organizacije običajno te modele izvajajo na zmogljivih GPU grozdih, dostopajo do njihovih sposobnosti prek API vmesnikov ali specializirane strojne infrastrukture.

Ta pristop dobro deluje za številne aplikacije, vendar ima inherentne omejitve pri praktičnih scenarijih uvajanja. Konvencionalna metoda vključuje uporabo modelov, ki zahtevajo velike računalniške vire, veliko količino pomnilnika in znatno porabo energije. Čeprav ta pristop omogoča dostop do najsodobnejših zmogljivosti, ustvarja odvisnost od drage strojne opreme, povečuje operativne stroške in omejuje fleksibilnost uvajanja.

## Izziv učinkovitega uvajanja AI

Potreba po bolj učinkoviti AI postaja vse bolj pomembna v različnih scenarijih. Upoštevajte aplikacije, ki zahtevajo lokalno uvajanje zaradi zasebnosti, stroškovno občutljive implementacije, kjer stroški API v oblaku postanejo previsoki, scenarije robnega računalništva z omejenimi strojno-tehničnimi viri ali aplikacije v realnem času, kjer je latenca ključna.

### Ključne omejitve uvajanja

Tradicionalna uvajanja velikih modelov se soočajo z več temeljnimi omejitvami, ki omejujejo njihovo praktično uporabnost:

- **Omejitve stroškov**: Visoki računalniški stroški otežujejo neprekinjeno uvajanje za številne organizacije.
- **Omejitve virov**: Omejen dostop do zmogljive GPU infrastrukture omejuje možnosti uvajanja.
- **Zahteve zasebnosti**: Občutljive aplikacije zahtevajo lokalno obdelavo za ohranjanje zasebnosti podatkov.
- **Občutljivost na latenco**: Aplikacije v realnem času potrebujejo takojšnje odzive brez zamud pri komunikaciji z oblakom.

## Filozofija modelov Microsoft Phi

Družina modelov Microsoft Phi predstavlja temeljni premik v filozofiji oblikovanja AI modelov, saj daje prednost učinkovitosti in praktičnemu uvajanju, hkrati pa ohranja močne zmogljivostne značilnosti. Modeli Phi to dosežejo z inovativnimi arhitekturami, visokokakovostnimi metodami učenja in specializiranimi tehnikami optimizacije.

Družina Phi vključuje različne pristope, zasnovane za maksimizacijo zmogljivosti na parameter, kar omogoča uvajanje na standardni strojni opremi, hkrati pa zagotavlja pomembne AI sposobnosti. Cilj je ohraniti konkurenčno zmogljivost ob drastičnem zmanjšanju računalniških zahtev, porabe pomnilnika in operativnih stroškov.

### Temeljna načela oblikovanja Phi

Modeli Phi temeljijo na več osnovnih načelih, ki jih ločujejo od tradicionalnih velikih jezikovnih modelov:

- **Učinkovitost na prvem mestu**: Optimizirani za največjo zmogljivost na parameter, ne pa za absolutno velikost.
- **Kakovostno učenje**: Osredotočeni na visokokakovostne, kurirane podatke za učenje namesto na obsežne podatkovne zbirke.
- **Fleksibilnost uvajanja**: Zasnovani za učinkovito delovanje na različnih strojnih konfiguracijah.
- **Specializirane sposobnosti**: Pogosto optimizirani za specifične naloge ali domene za maksimalno učinkovitost.

## Ključne tehnologije, ki omogočajo družino Phi

### Pristop "učbenik kakovosti" pri učenju

Ena najbolj revolucionarnih značilnosti družine Phi je metoda učenja "učbenik kakovosti". Namesto da bi se učili na ogromnih količinah nefiltriranih podatkov z interneta, modeli Phi uporabljajo skrbno kurirane, visokokakovostne izobraževalne vsebine, zasnovane za učinkovito poučevanje razmišljanja, matematike, kodiranja in splošnega znanja.

Ta pristop deluje tako, da ustvarja sintetične izobraževalne vsebine, ki posnemajo visokokakovostne učbenike in akademske materiale. Podatki za učenje so posebej zasnovani tako, da so pedagoško ustrezni, osredotočeni na jasne razlage, postopno razmišljanje in strukturirano predstavitev znanja.

### Napredno učenje razmišljanja

Novejši modeli Phi vključujejo sofisticirane metode učenja razmišljanja, ki omogočajo kompleksno večstopenjsko reševanje problemov. Te tehnike vključujejo:

**Učenje verige razmišljanja**: Modeli se naučijo razčleniti kompleksne probleme na vmesne korake razmišljanja, kar njihov proces reševanja naredi bolj transparenten in zanesljiv.

**Skaliranje med generiranjem**: Modeli ustvarjajo podrobne verige razmišljanja, ki med generiranjem odgovorov izkoristijo dodatne računalniške vire za izboljšano natančnost.

**Učenje na robu zmogljivosti**: Podatki za učenje so posebej izbrani, da izzovejo model na robu njegovih trenutnih zmogljivosti, kar spodbuja učenje kompleksnih vzorcev razmišljanja.

### Arhitekturne inovacije

Družina Phi vključuje več arhitekturnih optimizacij, zasnovanih posebej za učinkovitost:

**Učinkovitost parametrov**: Skrbne arhitekturne izbire, ki maksimizirajo vpliv vsakega parametra v modelu.

**Integracija več modalnosti**: Učinkovita integracija obdelave besedila, slike in govora v kompaktnih arhitekturah.

**Optimizacija strojne opreme**: Specializirane različice, optimizirane za specifične strojne platforme in scenarije uvajanja.

## Optimizacija strojne opreme za modele Phi

Sodobna okolja uvajanja koristijo učinkovitosti modelov Phi na različnih strojnih konfiguracijah:

### Optimizirano za CPU

Modeli Phi so zasnovani za učinkovito delovanje na strojni opremi, ki temelji samo na CPU, kar omogoča dostopnost za uvajanje na standardni računalniški infrastrukturi brez potrebe po specializiranih AI pospeševalnikih.

### Pospeševanje z GPU

Čeprav ne zahtevajo zmogljivih GPU-jev, modeli Phi lahko izkoristijo razpoložljive GPU vire za izboljšano zmogljivost, kar zagotavlja fleksibilnost pri konfiguracijah uvajanja.

### Integracija na robnih napravah

Specializirane različice, kot je Phi-3-Silica, so optimizirane za specifične platforme robnega računalništva, doseganje izjemnih učinkovitostnih metrik, kot je 650 tokenov na sekundo z le 1,5 W porabe energije.

## Prednosti družine modelov Phi

### Stroškovna učinkovitost

Modeli Phi drastično zmanjšajo operativne stroške, saj zahtevajo bistveno manj računalniške infrastrukture, hkrati pa ohranjajo konkurenčno zmogljivost. To omogoča dostopnost AI organizacijam z omejenimi proračuni ali aplikacijam z velikim obsegom, kjer so stroški na sklep pomembni.

### Fleksibilnost uvajanja

Učinkovitost modelov Phi omogoča uvajanje na širok spekter strojnih konfiguracij, od osebnih prenosnikov do strežnikov v podjetjih, kar organizacijam zagotavlja večjo fleksibilnost pri izbiri AI infrastrukture.

### Zasebnost in varnost

Učinkovitost modelov Phi omogoča lokalno uvajanje za aplikacije, občutljive na zasebnost, kar zagotavlja, da občutljivi podatki nikoli ne zapustijo nadzora organizacije, hkrati pa zagotavlja zmogljive AI sposobnosti.

### Zmogljivost v realnem času

Zmanjšane računalniške zahteve se prevedejo v hitrejše čase sklepanja, kar omogoča aplikacije v realnem času, ki zahtevajo takojšnje odzive brez kompromisov pri kakovosti AI sposobnosti.

### Dostopna AI

Z zmanjšanjem ovir za uvajanje AI modeli Phi omogočajo dostop do naprednih AI sposobnosti organizacijam z omejenimi viri, kar omogoča manjšim ekipam in posameznim razvijalcem uporabo sofisticiranega razumevanja jezika.

## Praktični primeri in uporabe

Preden se poglobimo v tehnično evolucijo, si oglejmo nekaj konkretnih primerov, kaj modeli Phi zmorejo:

### Primer matematičnega razmišljanja

Phi-4-mini-reasoning odlično obvlada postopno reševanje matematičnih problemov. Na primer, ko ga vprašamo "Kako rešiti 3*x^2+4*x+5=1?", model poda podrobne korake razmišljanja:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Primer večjezične podpore

Phi-3.5-mini-instruct izkazuje močne večjezične sposobnosti v različnih jezikih. Tukaj je primer oblike poziva:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Primer večmodalnih sposobnosti

Phi-4-multimodal lahko hkrati obdeluje besedilo, slike in govor. Tukaj so nekatere praktične uporabe:

**Načrtovanje potovanja z zvočnim vnosom:**
Oglejte si, kako Phi-4 Multimodal analizira govorjeni jezik za pomoč pri načrtovanju potovanja v Seattle, kar prikazuje njegove napredne sposobnosti obdelave zvoka in priporočanja.

**Reševanje matematičnih problemov iz slik:**
Oglejte si, kako Phi-4 Multimodal obravnava kompleksne matematične probleme prek vizualnih vnosov, kar prikazuje njegovo sposobnost obdelave in reševanja enačb, predstavljenih v slikah.

**Primer klicanja funkcij:**
S klicanjem funkcij lahko Phi-4-mini in Phi-4-multimodal razširita svoje sposobnosti obdelave besedila z integracijo iskalnikov, povezovanjem različnih orodij in več. Kot je prikazano, model lahko pridobi informacije o tekmah Premier League prek Phi-4-mini, kar prikazuje njegovo sposobnost brezhibne interakcije z zunanjimi viri podatkov.

### Primer generiranja kode

Phi-4-multimodal lahko generira strukturirano projektno kodo na podlagi vsebine slike in podanih pozivov, kot je prikazano v tem praktičnem poteku dela:

1. Naložite sliko žične mreže ali zasnove
2. Podajte kontekst o zahtevah projekta
3. Model generira popolne, funkcionalne strukture kode
4. Kodo je mogoče prilagoditi glede na specifične ogrodja ali jezike

### Primer uvajanja na robnih napravah

Model lahko kvantiziramo za optimizacijo mobilnih naprav. S kombinacijo Microsoft Olive in ONNX GenAI Runtime lahko Phi-4-mini uvedemo na Windows, iPhone, Android in druge naprave. Tukaj je primer, ki deluje na iPhone 12 Pro.

Postopek uvajanja vključuje:
- Kvantizacijo modela za mobilno optimizacijo
- Integracijo ONNX runtime za združljivost med platformami
- Lokalno sklepanje brez povezave z internetom
- Zmogljivost v realnem času z minimalno porabo energije

## Evolucija družine Phi

### Phi-1 in Phi-2: Temeljni modeli

Zgodnji modeli Phi so vzpostavili temeljna načela visokokakovostnih podatkov za učenje in učinkovitih arhitektur:

- **Phi-1 (1,3B parametrov)**: Uvedel koncept kuriranih podatkov za osnovno razumevanje jezika in generiranje kode.
- **Phi-2 (2,7B parametrov)**: Izboljšal sposobnosti razmišljanja prek sintetičnih NLP podatkov in skrbno filtrirane spletne vsebine.

### Družina Phi-3: Glavni sprejem

Serija Phi-3 je pomenila preboj v sposobnostih SLM z več specializiranimi različicami:

- **Phi-3-mini (3,8B parametrov)**: Splošne jezikovne naloge z izjemno učinkovitostjo, ki prekaša modele dvakratne velikosti.
- **Phi-3-small (7B parametrov)**: Napredna zmogljivost, ki premaga GPT-3.5 Turbo na različnih merilih.
- **Phi-3-medium (14B parametrov)**: Zmogljivost na ravni podjetij, ki premaga Gemini 1.0 Pro.
- **Phi-3-vision (4,2B parametrov)**: Večmodalne sposobnosti za obdelavo slik in besedila.
- **Phi-3-Silica (3,3B parametrov)**: Specializirana optimizacija za vgrajeno uvajanje v Windows 11.

### Družina Phi-4: Napredno razmišljanje

Najnovejša generacija premika meje sposobnosti razmišljanja:

- **Phi-4 (14B parametrov)**: Specializacija za kompleksno razmišljanje, zlasti v matematiki.
- **Phi-4-mini (3,8B parametrov)**: Izboljšano razmišljanje s klicanjem funkcij in podporo za dolge kontekste.
- **Phi-4-multimodal**: Hkratna obdelava govora, slike in besedila.
- **Phi-4-reasoning (14B parametrov)**: Specializiran za kompleksne večstopenjske naloge razmišljanja.
- **Phi-4-reasoning-plus (14B parametrov)**: Izboljšana natančnost prek dodatnega učenja z okrepitvijo.
- **Phi-4-mini-reasoning (3,8B parametrov)**: Matematično razmišljanje, optimizirano za omejena okolja.

## Uporabe modelov Phi

### Aplikacije v podjetjih

Organizacije uporabljajo modele Phi za analizo dokumentov, avtomatizacijo storitev za stranke, pomoč pri generiranju kode in aplikacije poslovne inteligence, ki zahtevajo lokalno uvajanje zaradi skladnosti in varnosti.

### Mobilno in robno računalništvo

Mobilne aplikacije izkoriščajo modele Phi za prevajanje v realnem času, inteligentne asistente, generiranje vsebine in personalizirana priporočila brez potrebe po stalni povezavi z internetom.

### Izobraževalna tehnologija

Izobraževalne platforme uporabljajo modele Phi za personalizirano tutorstvo, avtomatizirano ocenjevanje, generiranje vsebine in interaktivne učne izkušnje, ki lahko delujejo brez povezave ali v okoljih z nizko povezljivostjo.

### Zdravstvo in skladnost


Družina Phi dokazuje, da prihodnost uvajanja umetne inteligence ne temelji zgolj na gradnji večjih modelov, temveč na gradnji pametnejših, bolj učinkovitih modelov, ki lahko učinkovito delujejo v različnih strojnih okoljih, hkrati pa ohranjajo visoke standarde zmogljivosti.

## Primeri razvoja in integracije

### Hiter začetek z Transformers

Tukaj je prikazano, kako začeti z modeli Phi z uporabo knjižnice Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Primer prilagoditve

Naslednji primer prikazuje, kako prilagoditi Phi-4-mini-instruct za specifične naloge:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specializirani formati pozivov

**Za naloge sklepanja (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Za matematične naloge (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobilna uvedba z ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Merila zmogljivosti in dosežki

Družina modelov Phi je dosegla izjemne rezultate na različnih merilih, pogosto prekaša veliko večje modele:

### Ključni poudarki zmogljivosti

**Odličnost v matematičnem sklepanju:**
- Phi-4 doseže 82,5 % natančnost na AIME 2025 (kvalifikacija za matematično olimpijado)
- Phi-4-reasoning (14B) prekaša DeepSeek-R1-Distill-70B (5x večji) na merilih sklepanja
- Phi-4-mini-reasoning (3,8B) se kosa z modeli, ki so dvakrat večji, pri nalogah matematičnega sklepanja

**Dosežki učinkovitosti:**
- Phi-3-Silica doseže 650 tokenov na sekundo z le 1,5W porabe energije
- Phi-4-mini (3,8B) dosega podobno zmogljivost kot veliko večji modeli

**Uspešnost na merilih:**
- **MMLU (Massive Multitask Language Understanding)**: Konkurenčna zmogljivost v 57 akademskih predmetih
- **HumanEval**: Močne sposobnosti generiranja kode, zlasti v Pythonu
- **MGSM**: Večjezično reševanje matematičnih nalog osnovne šole
- **DROP**: Kompleksne naloge razumevanja in sklepanja
- **SimpleQA**: Natančnost pri odgovarjanju na dejanska vprašanja

### 📊 Primerjalna matrika modelov

| Model | Parametri | Dolžina konteksta | Ključne prednosti | Najboljši primeri uporabe |
|-------|-----------|-------------------|-------------------|---------------------------|
| **Phi-3-mini** | 3,8B | 4K/128K | Splošna učinkovitost | Mobilne aplikacije, osnovni klepetalniki |
| **Phi-3.5-mini** | 3,8B | 128K | Večjezična podpora | Mednarodne aplikacije |
| **Phi-4-mini** | 3,8B | 128K | Izboljšano sklepanje, klic funkcij | Poslovna avtomatizacija |
| **Phi-4-mini-reasoning** | 3,8B | 128K | Matematično sklepanje | Izobraževalne platforme |
| **Phi-4** | 14B | 32K | Kompleksno sklepanje | Raziskave, napredna analiza |
| **Phi-4-reasoning** | 14B | 32K/64K | Večstopenjsko sklepanje | Znanstveno računalništvo |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimalna natančnost sklepanja | Kritično odločanje |
| **Phi-4-multimodal** | 5,6B | Spremenljivo | Govor, vizija, besedilo | Multimedijske aplikacije |

## Vodnik za izbiro modela

### Za osnovne aplikacije
- **Phi-3-mini**: Enostavno generiranje besedila, osnovna vprašanja in odgovori, hitri odzivi
- **Phi-4-mini**: Izboljšano sklepanje z zmožnostmi klicanja funkcij

### Za matematične in sklepalne naloge
- **Phi-4**: Kompleksno reševanje matematičnih problemov in sklepanje
- **Phi-4-reasoning**: Večstopenjsko sklepanje z natančnimi razlagami
- **Phi-4-reasoning-plus**: Maksimalna natančnost za kritične naloge sklepanja
- **Phi-4-mini-reasoning**: Učinkovito matematično sklepanje za okolja z omejenimi viri

### Za multimodalne aplikacije
- **Phi-3-vision**: Kombinacije obdelave slik in besedila
- **Phi-4-multimodal**: Celovite zmožnosti govora, vizije in besedila

### Za poslovno uvedbo
- **Phi-3-medium**: Napredno razumevanje jezika za poslovne aplikacije
- **Phi-3-Silica**: Optimizirano za specifične strojne platforme

## Platforme za uvedbo in dostopnost

### Oblakovne platforme
- **Azure AI Foundry**: Celovita uvedba z orodji za podjetja
- **Hugging Face**: Odprtokodni repozitorij modelov in skupnostni viri
- **NVIDIA API Catalog**: Možnosti uvedbe mikrostoritev

### Okviri za lokalni razvoj
- **Ollama**: Lahek okvir za lokalno uvedbo modelov
- **ONNX Runtime**: Optimizirano za različne strojne konfiguracije  
- **DirectML**: Optimizirana zmogljivost za Windows
- **llama.cpp**: Večplatformni pogon za sklepanje

### Učni viri
- **Phi Portal**: Uradno Microsoftovo središče dokumentacije za Phi
- **Phi Cookbook**: Celoviti primeri in vadnice
- **Tehnična poročila**: Poglobljeni raziskovalni članki na arxiv
- **Skupnostni prostori**: Interaktivne predstavitve na Hugging Face

### Začetek z modeli Phi

#### Platforme za razvoj
1. **Azure AI Foundry**: Enostaven lokalni CLI in upravljanje modelov.
2. **Hugging Face Transformers**: Hitro lokalno eksperimentiranje
3. **Ollama**: Enostavna lokalna uvedba za testiranje

#### Učna pot
1. **Razumevanje osnovnih konceptov**: Preučite temeljna načela oblikovanja
2. **Eksperimentiranje z različicami**: Preizkusite različne modele Phi za razumevanje zmogljivosti
3. **Praktična implementacija**: Uvedite modele v testnih okoljih
4. **Razširitev uvedbe**: Postopno povečajte uporabo na podlagi uspešnih pilotov

#### Najboljše prakse
- **Začnite z majhnim**: Začetek z modeli Phi-mini za začetni razvoj
- **Optimizirajte pozive**: Uporabite pravilno oblikovanje klepeta za najboljše rezultate
- **Spremljajte zmogljivost**: Spremljajte hitrost sklepanja in metrike natančnosti
- **Upoštevajte strojno opremo**: Prilagodite velikost modela razpoložljivim računalniškim virom

## Zaključek

Družina modelov Microsoft Phi predstavlja revolucionaren pristop k oblikovanju modelov umetne inteligence, ki dokazuje, da lahko manjši, bolj učinkoviti modeli dosežejo izjemne rezultate pri različnih nalogah. Z osredotočanjem na visokokakovostne podatke za usposabljanje in optimizacije arhitekture družina Phi zagotavlja izjemne zmogljivosti z bistveno zmanjšanimi računalniškimi zahtevami v primerjavi s tradicionalnimi velikimi jezikovnimi modeli.

## Ključni učni cilji

1. Razumeti filozofijo oblikovanja in razvoj družine modelov Microsoft Phi od Phi-1 do Phi-4
2. Prepoznati ključne inovacije, vključno s "učbenik kakovostjo" usposabljanja in optimizacijami arhitekture
3. Prepoznati prednosti in omejitve različnih različic Phi v različnih scenarijih uvedbe
4. Uporabiti znanje za izbiro ustreznih modelov Phi za specifične primere uporabe in strojne omejitve
5. Izvesti tehnike optimizacije za uvedbo modelov Phi na napravah z omejenimi viri
6. Pojasniti arhitekturne prednosti družine modelov Phi v primerjavi s tradicionalnimi velikimi jezikovnimi modeli
7. Izbrati ustrezno različico Phi glede na specifične zahteve aplikacije in strojne omejitve
8. Uvesti modele Phi v oblačnih in robnih scenarijih z optimiziranimi konfiguracijami
9. Uporabiti tehnike kvantizacije in optimizacije za izboljšanje zmogljivosti modelov Phi na ciljnih napravah
10. Oceniti kompromise med velikostjo modela, zmogljivostjo in zmožnostmi v družini Phi

## Kaj sledi

- [02: Osnove družine Qwen](02.QwenFamily.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitne nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.