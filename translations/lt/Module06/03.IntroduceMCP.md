<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bd5b920b610665fd0462f6b5c2e134",
  "translation_date": "2025-09-18T23:54:47+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "lt"
}
-->
# 03 skyrius - Modelio konteksto protokolo (MCP) integracija

## Įvadas į MCP (Modelio konteksto protokolą)

Modelio konteksto protokolas (MCP) yra revoliucinis pagrindas, leidžiantis kalbos modeliams sąveikauti su išoriniais įrankiais ir sistemomis standartizuotu būdu. Skirtingai nuo tradicinių metodų, kur modeliai yra izoliuoti, MCP sukuria tiltą tarp AI modelių ir realaus pasaulio per aiškiai apibrėžtą protokolą.

### Kas yra MCP?

MCP veikia kaip komunikacijos protokolas, leidžiantis kalbos modeliams:
- Prisijungti prie išorinių duomenų šaltinių
- Vykdyti įrankius ir funkcijas
- Sąveikauti su API ir paslaugomis
- Pasiekti realaus laiko informaciją
- Atlikti sudėtingas daugiapakopes operacijas

Šis protokolas paverčia statinius kalbos modelius dinamiškais agentais, galinčiais atlikti praktines užduotis, kurios viršija teksto generavimą.

## Maži kalbos modeliai (SLM) MCP sistemoje

Maži kalbos modeliai yra efektyvus AI diegimo būdas, turintis keletą privalumų:

### SLM privalumai
- **Resursų efektyvumas**: Mažesni skaičiavimo reikalavimai
- **Greitesnis atsakas**: Sumažinta delsimo trukmė realaus laiko programoms  
- **Ekonomiškumas**: Minimalūs infrastruktūros poreikiai
- **Privatumas**: Gali veikti lokaliai, be duomenų perdavimo
- **Pritaikymas**: Lengviau pritaikyti specifinėms sritims

### Kodėl SLM gerai veikia su MCP

SLM kartu su MCP sudaro galingą derinį, kuriame modelio loginiai gebėjimai yra sustiprinami išoriniais įrankiais, kompensuojant mažesnį parametrų skaičių per padidintą funkcionalumą.

## Python MCP SDK apžvalga

Python MCP SDK suteikia pagrindą MCP palaikančių programų kūrimui. SDK apima:

- **Kliento bibliotekas**: Prisijungimui prie MCP serverių
- **Serverio pagrindą**: Individualių MCP serverių kūrimui
- **Protokolo tvarkytuvus**: Komunikacijos valdymui
- **Įrankių integraciją**: Išorinių funkcijų vykdymui

## Praktinis įgyvendinimas: Phi-4 MCP klientas

Pažvelkime į realaus pasaulio įgyvendinimą, naudojant Microsoft Phi-4 mini modelį su MCP galimybėmis.

### Sistemos architektūra

Įgyvendinimas remiasi sluoksniuota architektūra:

```
┌─────────────────────────────────────┐
│        Application Layer           │
│  ├── Interactive Loop              │
│  ├── CLI Interface                 │
│  └── Configuration Management      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│         LLM Client Layer           │
│  ├── OllamaClient                  │
│  ├── VLLMClient                    │
│  └── LLMClient (Abstract)          │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│        MCP Client Layer            │
│  ├── Phi4MiniMCPClient (STDIO)     │
│  ├── Phi4MiniSSEMCPClient (SSE)    │
│  └── BaseMCPClient (Abstract)      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│      Tool Processing Layer         │
│  ├── ToolCallHandler               │
│  ├── Function Format Transformer   │
│  └── Tool Schema Management        │
└─────────────────────────────────────┘
```

### Pagrindiniai komponentai

#### 1. MCP kliento klasės

**BaseMCPClient**: Abstraktus pagrindas, teikiantis bendrą funkcionalumą
- Asinchroninio konteksto valdymo protokolas
- Standartinė sąsajos apibrėžtis
- Resursų valdymas

**Phi4MiniMCPClient**: STDIO pagrindu veikiantis įgyvendinimas
- Lokali procesų komunikacija
- Standartinio įvesties/išvesties valdymas
- Subprocesų valdymas

**Phi4MiniSSEMCPClient**: Serverio siunčiamų įvykių įgyvendinimas
- HTTP srautinė komunikacija
- Realiojo laiko įvykių valdymas
- Internetinio serverio jungiamumas

#### 2. LLM integracija

**OllamaClient**: Lokalaus modelio talpinimas
```python
class OllamaClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:11434/api/chat"
        self.model_id = "phi4-mini:3.8b-fp16"
```

**VLLMClient**: Didelio našumo aptarnavimas
```python
class VLLMClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:8000/v1"
        self.model_id = "microsoft/Phi-4-mini-instruct"
```

#### 3. Įrankių apdorojimo procesas

Įrankių apdorojimo procesas transformuoja MCP įrankius į formatus, suderinamus su kalbos modeliais:

```python
def transform_functions_format(input_data):
    """Convert MCP tool schemas to LLM-compatible formats"""
    # Maps OpenAPI schemas to function calling schemas
    # Handles parameter type conversion
    # Maintains required field information
```

## Pradžia: žingsnis po žingsnio vadovas

### 1 žingsnis: aplinkos paruošimas

Įdiekite reikalingas priklausomybes:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### 2 žingsnis: pagrindinė konfigūracija

Nustatykite aplinkos kintamuosius:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### 3 žingsnis: pirmojo MCP kliento paleidimas

**Pagrindinis Ollama nustatymas:**
```bash
python ghmodel_mcp_demo.py
```

**Naudojant vLLM pagrindą:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Serverio siunčiamų įvykių jungtis:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Individualus MCP serveris:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### 4 žingsnis: programinis naudojimas

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Pažangios funkcijos

### Daugiapagrindė palaikymas

Įgyvendinimas palaiko tiek Ollama, tiek vLLM pagrindus, leidžiant pasirinkti pagal poreikius:

- **Ollama**: Geriau tinka lokaliam vystymui ir testavimui
- **vLLM**: Optimizuotas gamybai ir didelio našumo scenarijams

### Lankstūs jungties protokolai

Palaikomi du jungties režimai:

**STDIO režimas**: Tiesioginė procesų komunikacija
- Mažesnė delsimo trukmė
- Tinka lokaliems įrankiams
- Paprastas nustatymas

**SSE režimas**: HTTP pagrindu veikiantis srautas
- Tinklo galimybės
- Geriau tinka paskirstytoms sistemoms
- Realiojo laiko atnaujinimai

### Įrankių integracijos galimybės

Sistema gali integruotis su įvairiais įrankiais:
- Interneto automatizavimas (Playwright)
- Failų operacijos
- API sąveika
- Sistemos komandos
- Individualios funkcijos

## Klaidų valdymas ir geriausia praktika

### Išsamus klaidų valdymas

Įgyvendinimas apima patikimą klaidų valdymą:

**Jungties klaidos:**
- MCP serverio gedimai
- Tinklo laiko limitai
- Jungiamumo problemos

**Įrankių vykdymo klaidos:**
- Trūkstami įrankiai
- Parametrų validacija
- Vykdymo gedimai

**Atsakymo apdorojimo klaidos:**
- JSON analizės problemos
- Formatų neatitikimai
- LLM atsakymų anomalijos

### Geriausia praktika

1. **Resursų valdymas**: Naudokite asinchroninius konteksto valdytojus
2. **Klaidų valdymas**: Įgyvendinkite išsamius try-catch blokus
3. **Žurnalavimas**: Įjunkite tinkamus žurnalavimo lygius
4. **Saugumas**: Validuokite įvestis ir išvalykite išvestis
5. **Našumas**: Naudokite jungties kaupimą ir talpyklą

## Realūs pritaikymai

### Interneto automatizavimas
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Duomenų apdorojimas
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API integracija
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Našumo optimizavimas

### Atminties valdymas
- Efektyvus žinučių istorijos valdymas
- Tinkamas resursų išvalymas
- Jungties kaupimas

### Tinklo optimizavimas
- Asinchroninės HTTP operacijos
- Konfigūruojami laiko limitai
- Sklandus klaidų atkūrimas

### Lygiagretus apdorojimas
- Neužblokuojantis I/O
- Lygiagretus įrankių vykdymas
- Efektyvūs asinchroniniai modeliai

## Saugumo aspektai

### Duomenų apsauga
- Saugus API raktų valdymas
- Įvesties validacija
- Išvesties išvalymas

### Tinklo saugumas
- HTTPS palaikymas
- Lokalių galinių taškų numatytoji konfigūracija
- Saugus žetonų valdymas

### Vykdymo saugumas
- Įrankių filtravimas
- Smėlio dėžės aplinkos
- Audito žurnalavimas

## Išvada

SLM integracija su MCP atspindi paradigmos pokytį AI programų kūrime. Derinant mažų modelių efektyvumą su išorinių įrankių galia, kūrėjai gali kurti intelektualias sistemas, kurios yra ir resursų efektyvios, ir labai pajėgios.

Phi-4 MCP kliento įgyvendinimas parodo, kaip ši integracija gali būti pasiekta praktiškai, suteikiant tvirtą pagrindą sudėtingų AI palaikomų programų kūrimui.

Pagrindinės išvados:
- MCP sujungia kalbos modelius su išorinėmis sistemomis
- SLM siūlo efektyvumą, neprarandant galimybių, kai jie sustiprinami įrankiais
- Modulinė architektūra leidžia lengvai plėsti ir pritaikyti
- Tinkamas klaidų valdymas ir saugumo priemonės yra būtinos gamybos naudojimui

Šis vadovas suteikia pagrindą kurti savo SLM palaikomas MCP programas, atveriant galimybes automatizavimui, duomenų apdorojimui ir intelektualių sistemų integracijai.

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors stengiamės užtikrinti tikslumą, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus aiškinimus, atsiradusius dėl šio vertimo naudojimo.