<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "00583bdd288194f0c4e7d71363e4c48a",
  "translation_date": "2025-09-19T01:12:30+00:00",
  "source_file": "Module05/02.SLMOps-Distillation.md",
  "language_code": "lt"
}
-->
# 2 skyrius: Modelių distiliacija – nuo teorijos iki praktikos

## Turinys
1. [Įvadas į modelių distiliaciją](../../../Module05)
2. [Kodėl distiliacija yra svarbi](../../../Module05)
3. [Distiliacijos procesas](../../../Module05)
4. [Praktinis įgyvendinimas](../../../Module05)
5. [Azure ML distiliacijos pavyzdys](../../../Module05)
6. [Geriausios praktikos ir optimizavimas](../../../Module05)
7. [Praktiniai pritaikymai](../../../Module05)
8. [Išvados](../../../Module05)

## Įvadas į modelių distiliaciją {#introduction}

Modelių distiliacija yra efektyvi technika, leidžianti sukurti mažesnius ir efektyvesnius modelius, išlaikant didesnių ir sudėtingesnių modelių našumą. Šis procesas apima kompaktiško „studento“ modelio mokymą, kad jis imituotų didesnio „mokytojo“ modelio elgesį.

**Pagrindiniai privalumai:**
- **Mažesni skaičiavimo reikalavimai** prognozėms
- **Mažesnis atminties naudojimas** ir saugojimo poreikiai
- **Greitesnis prognozavimo laikas**, išlaikant tinkamą tikslumą
- **Ekonomiškas diegimas** ribotų išteklių aplinkose

## Kodėl distiliacija yra svarbi {#why-distillation-matters}

Dideli kalbos modeliai (LLM) tampa vis galingesni, tačiau kartu ir vis labiau reikalaujantys išteklių. Nors modelis su milijardais parametrų gali duoti puikius rezultatus, jis dažnai nėra praktiškas daugeliui realių pritaikymų dėl:

### Išteklių apribojimų
- **Skaičiavimo našta**: Dideli modeliai reikalauja daug GPU atminties ir apdorojimo galios
- **Prognozavimo delsos**: Sudėtingiems modeliams reikia daugiau laiko atsakymams generuoti
- **Energijos suvartojimas**: Didesni modeliai sunaudoja daugiau energijos, didindami eksploatavimo išlaidas
- **Infrastruktūros kaštai**: Didelių modelių talpinimui reikalinga brangi techninė įranga

### Praktiniai apribojimai
- **Mobilus diegimas**: Dideli modeliai neveikia efektyviai mobiliuosiuose įrenginiuose
- **Realaus laiko pritaikymai**: Programos, kurioms reikalinga maža delsos trukmė, negali toleruoti lėto prognozavimo
- **Edge kompiuterija**: IoT ir edge įrenginiai turi ribotus skaičiavimo išteklius
- **Kaštų svarstymai**: Daugelis organizacijų negali sau leisti infrastruktūros didelių modelių diegimui

## Distiliacijos procesas {#the-distillation-process}

Modelių distiliacija vyksta dviejų etapų procese, kuris perduoda žinias iš mokytojo modelio studentui:

### 1 etapas: Sintetinių duomenų generavimas

Mokytojo modelis generuoja atsakymus jūsų mokymo duomenų rinkiniui, sukuriant aukštos kokybės sintetinius duomenis, kurie atspindi mokytojo žinias ir sprendimų priėmimo modelius.

```python
# Conceptual example of synthetic data generation
def generate_synthetic_data(teacher_model, training_dataset):
    synthetic_data = []
    for input_sample in training_dataset:
        teacher_response = teacher_model.generate(input_sample)
        synthetic_data.append({
            'input': input_sample,
            'teacher_output': teacher_response
        })
    return synthetic_data
```

**Pagrindiniai šio etapo aspektai:**
- Mokytojo modelis apdoroja kiekvieną mokymo pavyzdį
- Generuoti atsakymai tampa „tikrąja tiesa“ studento mokymui
- Šis procesas užfiksuoja mokytojo sprendimų priėmimo modelius
- Sintetinių duomenų kokybė tiesiogiai veikia studento modelio našumą

### 2 etapas: Studentų modelio tobulinimas

Studento modelis mokomas naudojant sintetinį duomenų rinkinį, mokantis atkartoti mokytojo elgesį ir atsakymus.

```python
# Conceptual example of student training
def train_student_model(student_model, synthetic_data):
    for epoch in range(num_epochs):
        for batch in synthetic_data:
            student_output = student_model(batch['input'])
            loss = compute_loss(student_output, batch['teacher_output'])
            optimizer.step(loss.backward())
    return student_model
```

**Mokymo tikslai:**
- Minimizuoti skirtumą tarp studento ir mokytojo rezultatų
- Išlaikyti mokytojo žinias mažesnėje parametrų erdvėje
- Išlaikyti našumą, sumažinant modelio sudėtingumą

## Praktinis įgyvendinimas {#practical-implementation}

### Mokytojo ir studento modelių pasirinkimas

**Mokytojo modelio pasirinkimas:**
- Pasirinkite didelio masto LLM (100B+ parametrų), kurie įrodė savo našumą jūsų konkrečioje užduotyje
- Populiarūs mokytojo modeliai:
  - **DeepSeek V3** (671B parametrų) – puikus sprendimų priėmimui ir kodo generavimui
  - **Meta Llama 3.1 405B Instruct** – universalus bendros paskirties modelis
  - **GPT-4** – stiprus našumas įvairiose užduotyse
  - **Claude 3.5 Sonnet** – puikus sudėtingų sprendimų priėmimo užduotims
- Įsitikinkite, kad mokytojo modelis gerai veikia jūsų domeno duomenyse

**Studento modelio pasirinkimas:**
- Subalansuokite modelio dydį ir našumo reikalavimus
- Rinkitės efektyvius, mažesnius modelius, tokius kaip:
  - **Microsoft Phi-4-mini** – naujausias efektyvus modelis su stipriais sprendimų priėmimo gebėjimais
  - Meta Llama 3.1 8B Instruct
  - Microsoft Phi-3 Mini (4K ir 128K variantai)
  - Microsoft Phi-3.5 Mini Instruct

### Įgyvendinimo žingsniai

1. **Duomenų paruošimas**
   ```python
   # Prepare your training dataset
   training_data = load_dataset("your_training_data.jsonl")
   validation_data = load_dataset("your_validation_data.jsonl")
   ```

2. **Mokytojo modelio nustatymas**
   ```python
   # Initialize large-scale teacher model (100B+ parameters)
   teacher_model = load_model("deepseek-ai/DeepSeek-V3")
   # Alternative: teacher_model = load_model("meta-llama/Llama-3.1-405B-Instruct")
   ```

3. **Sintetinių duomenų generavimas**
   ```python
   # Generate responses from teacher model
   synthetic_training_data = generate_teacher_responses(
       teacher_model, 
       training_data
   )
   synthetic_validation_data = generate_teacher_responses(
       teacher_model, 
       validation_data
   )
   ```

4. **Studento modelio mokymas**
   ```python
   # Fine-tune Phi-4-mini as student model
   student_model = load_model("microsoft/Phi-4-mini")
   trained_student = fine_tune_student(
       student_model,
       synthetic_training_data,
       synthetic_validation_data
   )
   ```

## Azure ML distiliacijos pavyzdys {#azure-ml-example}

Azure Machine Learning siūlo išsamų platformą modelių distiliacijos įgyvendinimui. Štai kaip pasinaudoti Azure ML savo distiliacijos darbo eiga:

### Būtinos sąlygos

1. **Azure ML Workspace**: Sukurkite savo darbo erdvę tinkamame regione
   - Užtikrinkite prieigą prie didelio masto mokytojo modelių (DeepSeek V3, Llama 405B)
   - Konfigūruokite regionus pagal modelių prieinamumą

2. **Skaičiavimo ištekliai**: Konfigūruokite tinkamus skaičiavimo įrenginius mokymui
   - Didelės atminties įrenginiai mokytojo modelio prognozėms
   - GPU palaikomi įrenginiai studento modelio tobulinimui

### Palaikomos užduočių rūšys

Azure ML palaiko distiliaciją įvairioms užduotims:

- **Natūralios kalbos interpretacija (NLI)**
- **Pokalbių AI**
- **Klausimų ir atsakymų (QA)**
- **Matematinis sprendimų priėmimas**
- **Teksto santrauka**

### Pavyzdinis įgyvendinimas

```python
from azure.ai.ml import MLClient
from azure.ai.ml.entities import DistillationJob

# Initialize Azure ML client
ml_client = MLClient.from_config()

# Define distillation job with DeepSeek V3 as teacher and Phi-4-mini as student
distillation_job = DistillationJob(
    teacher_model="deepseek-v3",  # Large-scale teacher model (671B parameters)
    student_model="phi-4-mini",   # Efficient student model
    training_data="./training_data.jsonl",
    validation_data="./validation_data.jsonl",
    task_type="conversation",
    hyperparameters={
        "learning_rate": 2e-5,    # Lower learning rate for fine-tuning
        "batch_size": 2,          # Smaller batch size for memory efficiency
        "num_epochs": 3,
        "temperature": 0.7        # Teacher output softness
    }
)

# Submit distillation job
job = ml_client.jobs.create_or_update(distillation_job)
```

### Stebėjimas ir vertinimas

```python
# Monitor training progress
job_status = ml_client.jobs.get(job.name)
print(f"Job status: {job_status.status}")

# Evaluate distilled Phi-4-mini model
evaluation_results = ml_client.models.evaluate(
    model_name="phi-4-mini-distilled",
    test_data="./test_data.jsonl",
    metrics=["accuracy", "bleu_score", "inference_time"]
)

# Compare with original Phi-4-mini baseline
baseline_results = ml_client.models.evaluate(
    model_name="phi-4-mini-baseline",
    test_data="./test_data.jsonl"
)

print(f"Distilled model accuracy: {evaluation_results['accuracy']}")
print(f"Baseline model accuracy: {baseline_results['accuracy']}")
print(f"Performance improvement: {evaluation_results['accuracy'] - baseline_results['accuracy']}")
```

## Geriausios praktikos ir optimizavimas {#best-practices}

### Duomenų kokybė

**Aukštos kokybės mokymo duomenys yra būtini:**
- Užtikrinkite įvairius ir reprezentatyvius mokymo pavyzdžius
- Naudokite domeno specifinius duomenis, kai įmanoma
- Patikrinkite mokytojo modelio rezultatus prieš juos naudojant studento mokymui
- Subalansuokite duomenų rinkinį, kad išvengtumėte šališkumo studento modelio mokymesi

### Hiperparametrų derinimas

**Pagrindiniai parametrai optimizavimui:**
- **Mokymosi greitis**: Pradėkite nuo mažesnių greičių (1e-5 iki 5e-5) tobulinimui
- **Partijos dydis**: Subalansuokite atminties apribojimus ir mokymo stabilumą
- **Epochų skaičius**: Stebėkite per didelį pritaikymą; paprastai pakanka 2-5 epochų
- **Temperatūros skalavimas**: Koreguokite mokytojo rezultatų minkštumą geresniam žinių perdavimui

### Modelio architektūros svarstymai

**Mokytojo-studento suderinamumas:**
- Užtikrinkite architektūrinį suderinamumą tarp mokytojo ir studento modelių
- Apsvarstykite tarpinio sluoksnio suderinimą geresniam žinių perdavimui
- Naudokite dėmesio perdavimo technikas, kai tai taikoma

### Vertinimo strategijos

**Išsamus vertinimo požiūris:**
```python
# Multi-metric evaluation
evaluation_metrics = {
    'accuracy': evaluate_accuracy(student_model, test_data),
    'latency': measure_inference_time(student_model),
    'memory_usage': profile_memory_consumption(student_model),
    'task_specific_metrics': evaluate_task_performance(student_model, task_data)
}
```

## Praktiniai pritaikymai {#real-world-applications}

### Mobilus ir edge diegimas

Distiliuoti modeliai leidžia AI funkcijas ribotų išteklių įrenginiuose:
- **Išmaniojo telefono programos** su realaus laiko teksto apdorojimu
- **IoT įrenginiai** atliekantys vietinį prognozavimą
- **Įterptinės sistemos** su ribotais skaičiavimo ištekliais

### Ekonomiškos gamybos sistemos

Organizacijos naudoja distiliaciją, kad sumažintų eksploatavimo kaštus:
- **Klientų aptarnavimo pokalbių robotai** su greitesniais atsakymo laikais
- **Turinio moderavimo sistemos** efektyviai apdorojančios didelius kiekius
- **Realaus laiko vertimo paslaugos** su mažesne delsos trukme

### Domeno specifiniai pritaikymai

Distiliacija padeda sukurti specializuotus modelius:
- **Medicininės diagnostikos pagalba** su privatumo išsaugojimu vietiniame prognozavime
- **Teisinių dokumentų analizė** optimizuota specifiniams teisės domenams
- **Finansinės rizikos vertinimas** su greitu sprendimų priėmimu

### Atvejo analizė: Klientų aptarnavimas su DeepSeek V3 → Phi-4-mini

Technologijų įmonė įgyvendino distiliaciją savo klientų aptarnavimo sistemai:

**Įgyvendinimo detalės:**
- **Mokytojo modelis**: DeepSeek V3 (671B parametrų) – puikus sprendimų priėmimui sudėtingiems klientų klausimams
- **Studento modelis**: Phi-4-mini – optimizuotas greitam prognozavimui ir diegimui
- **Mokymo duomenys**: 50,000 klientų aptarnavimo pokalbių
- **Užduotis**: Daugiapakopė pokalbių pagalba su techninių problemų sprendimu

**Pasiekti rezultatai:**
- **85% sumažėjimas** prognozavimo laike (nuo 3.2s iki 0.48s per atsakymą)
- **95% sumažėjimas** atminties reikalavimuose (nuo 1.2TB iki 60GB)
- **92% išlaikymas** originalaus modelio tikslumo aptarnavimo užduotyse
- **60% sumažėjimas** eksploatavimo kaštuose
- **Pagerintas mastelio keitimas** – dabar galima aptarnauti 10 kartų daugiau vartotojų vienu metu

**Našumo suskirstymas:**
```python
# Comparison metrics
performance_comparison = {
    "DeepSeek V3 (Teacher)": {
        "parameters": "671B",
        "memory_usage": "1.2TB",
        "inference_time": "3.2s",
        "accuracy": "94.5%",
        "throughput": "50 queries/hour"
    },
    "Phi-4-mini (Distilled)": {
        "parameters": "14B",
        "memory_usage": "60GB", 
        "inference_time": "0.48s",
        "accuracy": "87.0%",
        "throughput": "500 queries/hour"
    }
}
```

## Išvados {#conclusion}

Modelių distiliacija yra esminė technika, leidžianti demokratizuoti prieigą prie pažangių AI galimybių. Sukuriant mažesnius, efektyvesnius modelius, kurie išlaiko didesnių modelių našumą, distiliacija sprendžia augantį poreikį praktiškam AI diegimui.

### Pagrindinės išvados

1. **Distiliacija užpildo spragą** tarp modelio našumo ir praktinių apribojimų
2. **Dviejų etapų procesas** užtikrina efektyvų žinių perdavimą iš mokytojo studentui
3. **Azure ML siūlo tvirtą infrastruktūrą** distiliacijos darbo eigoms įgyvendinti
4. **Tinkamas vertinimas ir optimizavimas** yra būtini sėkmingai distiliacijai
5. **Praktiniai pritaikymai** rodo reikšmingus privalumus kaštų, greičio ir prieinamumo srityse

### Ateities kryptys

Kadangi sritis toliau vystosi, galime tikėtis:
- **Pažangių distiliacijos technikų** su geresniais žinių perdavimo metodais
- **Daugelio mokytojų distiliacijos** studento modelio gebėjimų stiprinimui
- **Automatizuoto optimizavimo** distiliacijos procesui
- **Platesnės modelių palaikymo** įvairiose architektūrose ir domenuose

Modelių distiliacija suteikia organizacijoms galimybę pasinaudoti pažangiomis AI galimybėmis, išlaikant praktinius diegimo apribojimus, todėl pažangūs kalbos modeliai tampa prieinami įvairiems pritaikymams ir aplinkoms.

## ➡️ Kas toliau

- [03: Modelių tobulinimas – pritaikymas specifinėms užduotims](./03.SLMOps-Finetuing.md)

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus aiškinimus, kylančius dėl šio vertimo naudojimo.