<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-19T01:21:15+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "lt"
}
-->
# 4 skyrius: Diegimas - Paruošto modelio įgyvendinimas

## Apžvalga

Ši išsami pamoka padės jums pereiti visą procesą, kaip diegti pritaikytus kvantizuotus modelius naudojant Foundry Local. Apžvelgsime modelio konvertavimą, kvantizavimo optimizavimą ir diegimo konfigūraciją nuo pradžios iki pabaigos.

## Būtinos sąlygos

Prieš pradėdami, įsitikinkite, kad turite:

- ✅ Pritaikytą ONNX modelį, paruoštą diegimui
- ✅ Windows arba Mac kompiuterį
- ✅ Python 3.10 ar naujesnę versiją
- ✅ Bent 8GB laisvos RAM
- ✅ Įdiegtą Foundry Local jūsų sistemoje

## 1 dalis: Aplinkos paruošimas

### Reikalingų įrankių diegimas

Atidarykite terminalą (Command Prompt Windows sistemoje, Terminal Mac sistemoje) ir vykdykite šias komandas iš eilės:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

⚠️ **Svarbi pastaba**: Jums taip pat reikės CMake 3.31 ar naujesnės versijos, kurią galite atsisiųsti iš [cmake.org](https://cmake.org/download/).

## 2 dalis: Modelio konvertavimas ir kvantizavimas

### Tinkamo formato pasirinkimas

Pritaikytiems mažiems kalbos modeliams rekomenduojame naudoti **ONNX formatą**, nes jis siūlo:

- 🚀 Geresnę našumo optimizaciją
- 🔧 Aparatūros nepriklausomą diegimą
- 🏭 Paruoštumą gamybai
- 📱 Suderinamumą su įvairiomis platformomis

### 1 metodas: Konvertavimas viena komanda (Rekomenduojama)

Naudokite šią komandą, kad tiesiogiai konvertuotumėte pritaikytą modelį:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**Parametrų paaiškinimas:**
- `--model_name_or_path`: Kelias iki jūsų pritaikyto modelio
- `--device cpu`: Naudoti CPU optimizavimui
- `--precision int4`: Naudoti INT4 kvantizavimą (maždaug 75% dydžio sumažinimas)
- `--output_path`: Išvesties kelias konvertuotam modeliui

### 2 metodas: Konfigūracijos failo metodas (Patyrusiems vartotojams)

Sukurkite konfigūracijos failą pavadinimu `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

Tada vykdykite:

```bash
olive run --config ./finetuned_conversion_config.json
```

### Kvantizavimo parinkčių palyginimas

| Tikslumas | Failo dydis | Įžvalgos greitis | Modelio kokybė | Rekomenduojamas naudojimas |
|-----------|-------------|------------------|----------------|----------------------------|
| FP16      | Bazinis × 0.5 | Greitas | Geriausias | Aukštos klasės aparatinė įranga |
| INT8      | Bazinis × 0.25 | Labai greitas | Geras | Subalansuotas pasirinkimas |
| INT4      | Bazinis × 0.125 | Greičiausias | Priimtinas | Riboti resursai |

💡 **Rekomendacija**: Pirmam diegimui pradėkite nuo INT4 kvantizavimo. Jei kokybė nėra patenkinama, išbandykite INT8 arba FP16.

## 3 dalis: Foundry Local diegimo konfigūracija

### Modelio konfigūracijos kūrimas

Eikite į Foundry Local modelių katalogą:

```bash
foundry cache cd ./models/
```

Sukurkite modelio katalogo struktūrą:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

Sukurkite `inference_model.json` konfigūracijos failą savo modelio kataloge:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### Modelio šablonų konfigūracijos

#### Qwen serijos modeliams:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## 4 dalis: Modelio testavimas ir optimizavimas

### Modelio diegimo patikrinimas

Patikrinkite, ar Foundry Local atpažįsta jūsų modelį:

```bash
foundry cache ls
```

Turėtumėte matyti `your-finetuned-model-int4` sąraše.

### Modelio testavimo pradžia

```bash
foundry model run your-finetuned-model-int4
```

### Našumo vertinimas

Stebėkite pagrindinius rodiklius testavimo metu:

1. **Atsako laikas**: Vidutinio atsako laiko matavimas
2. **Atminties naudojimas**: RAM sunaudojimo stebėjimas
3. **CPU apkrova**: Procesoriaus apkrovos tikrinimas
4. **Išvesties kokybė**: Atsakymų aktualumo ir nuoseklumo vertinimas

### Kokybės patikrinimo kontrolinis sąrašas

- ✅ Modelis tinkamai reaguoja į pritaikytos srities užklausas
- ✅ Atsakymų formatas atitinka numatytą išvesties struktūrą
- ✅ Nėra atminties nutekėjimų ilgalaikio naudojimo metu
- ✅ Nuoseklus našumas skirtingo ilgio įvestims
- ✅ Tinkamas kraštutinių atvejų ir neteisingų įvestų duomenų apdorojimas

## Santrauka

Sveikiname! Jūs sėkmingai atlikote:

- ✅ Pritaikyto modelio formato konvertavimą
- ✅ Modelio kvantizavimo optimizavimą
- ✅ Foundry Local diegimo konfigūraciją
- ✅ Našumo derinimą ir problemų sprendimą

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama profesionali žmogaus vertimo paslauga. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.