<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-19T01:18:34+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "lt"
}
-->
# 3 skyrius: Modelių pritaikymas - pritaikymas specifinėms užduotims

## Turinys
1. [Įvadas į modelių pritaikymą](../../../Module05)
2. [Kodėl modelių pritaikymas yra svarbus](../../../Module05)
3. [Modelių pritaikymo tipai](../../../Module05)
4. [Modelių pritaikymas su Microsoft Olive](../../../Module05)
5. [Praktiniai pavyzdžiai](../../../Module05)
6. [Geriausios praktikos ir rekomendacijos](../../../Module05)
7. [Pažangios technikos](../../../Module05)
8. [Vertinimas ir stebėjimas](../../../Module05)
9. [Dažniausi iššūkiai ir sprendimai](../../../Module05)
10. [Išvada](../../../Module05)

## Įvadas į modelių pritaikymą

**Modelių pritaikymas** – tai galinga mašininio mokymosi technika, leidžianti pritaikyti iš anksto apmokytą modelį specifinėms užduotims ar specializuotiems duomenų rinkiniams. Vietoj modelio mokymo nuo nulio, pritaikymas pasinaudoja jau išmoktomis žiniomis ir pritaiko jas jūsų konkrečiam poreikiui.

### Kas yra modelių pritaikymas?

Modelių pritaikymas yra **perkėlimo mokymosi** forma, kur:
- Pradedate nuo iš anksto apmokyto modelio, kuris išmoko bendrus dėsningumus iš didelių duomenų rinkinių
- Koreguojate modelio vidinius parametrus naudodami savo specifinį duomenų rinkinį
- Išlaikote vertingas žinias, tuo pačiu specializuodami modelį savo užduočiai

Tai galima palyginti su patyrusio virėjo mokymu gaminti naują virtuvę – jis jau supranta pagrindinius maisto gaminimo principus, tačiau turi išmokti specifinių technikų ir skonių naujam stiliui.

### Pagrindiniai privalumai

- **Laiko efektyvumas**: Žymiai greitesnis nei mokymas nuo nulio
- **Duomenų efektyvumas**: Reikia mažesnių duomenų rinkinių, kad pasiektumėte gerus rezultatus
- **Ekonomiškumas**: Mažesni skaičiavimo reikalavimai
- **Geresni rezultatai**: Dažnai pasiekiami geresni rezultatai nei mokant nuo nulio
- **Resursų optimizavimas**: Galingas AI tampa prieinamas mažesnėms komandoms ir organizacijoms

## Kodėl modelių pritaikymas yra svarbus

### Realūs pritaikymo atvejai

Modelių pritaikymas yra būtinas daugelyje scenarijų:

**1. Prisitaikymas prie srities**
- Medicinos AI: Bendrų kalbos modelių pritaikymas medicinos terminologijai ir klinikinėms pastaboms
- Teisinės technologijos: Modelių specializavimas teisinių dokumentų analizei ir sutarčių peržiūrai
- Finansinės paslaugos: Modelių pritaikymas finansinių ataskaitų analizei ir rizikos vertinimui

**2. Užduočių specializavimas**
- Turinio kūrimas: Pritaikymas specifiniams rašymo stiliams ar tonams
- Kodo generavimas: Modelių pritaikymas tam tikroms programavimo kalboms ar sistemoms
- Vertimas: Rezultatų gerinimas specifinėms kalbų poroms ar techninėms sritims

**3. Įmonių pritaikymas**
- Klientų aptarnavimas: Pokalbių robotų kūrimas, suprantančių įmonės specifinę terminologiją
- Vidinė dokumentacija: AI asistentų kūrimas, susipažinusių su organizacijos procesais
- Pramonės sprendimai: Modelių kūrimas, suprantančių sektoriaus specifinį žargoną ir darbo eigą

## Modelių pritaikymo tipai

### 1. Pilnas pritaikymas (instrukcijų pritaikymas)

Pilno pritaikymo metu visi modelio parametrai yra atnaujinami mokymo metu. Šis metodas:
- Suteikia maksimalų lankstumą ir našumo potencialą
- Reikalauja daug skaičiavimo resursų
- Sukuria visiškai naują modelio versiją
- Geriausiai tinka, kai turite daug mokymo duomenų ir skaičiavimo resursų

### 2. Efektyvus parametrų pritaikymas (PEFT)

PEFT metodai atnaujina tik nedidelę parametrų dalį, todėl procesas tampa efektyvesnis:

#### Low-Rank Adaptation (LoRA)
- Prideda mažas treniruojamas matricas prie esamų svorių
- Žymiai sumažina treniruojamų parametrų skaičių
- Išlaiko našumą, artimą pilnam pritaikymui
- Leidžia lengvai perjungti skirtingus pritaikymus

#### QLoRA (Quantized LoRA)
- Derina LoRA su kvantavimo technikomis
- Dar labiau sumažina atminties reikalavimus
- Leidžia pritaikyti didesnius modelius vartotojų aparatinėje įrangoje
- Subalansuoja efektyvumą ir našumą

#### Adapteriai
- Įterpia mažus neuroninius tinklus tarp esamų sluoksnių
- Leidžia tikslinį pritaikymą, išlaikant bazinį modelį nepakitusį
- Leidžia modulinį modelio pritaikymo požiūrį

### 3. Užduočių specifinis pritaikymas

Fokusuojasi į modelių pritaikymą specifinėms užduotims:
- **Klasifikacija**: Modelių pritaikymas kategorijų užduotims
- **Generavimas**: Optimizavimas turinio kūrimui ir teksto generavimui
- **Ištraukimas**: Pritaikymas informacijos ištraukimo ir vardų atpažinimo užduotims
- **Santrauka**: Modelių specializavimas dokumentų santraukų kūrimui

## Modelių pritaikymas su Microsoft Olive

Microsoft Olive yra išsamus modelių optimizavimo įrankių rinkinys, kuris supaprastina pritaikymo procesą ir suteikia įmonės lygio funkcijas.

### Kas yra Microsoft Olive?

Microsoft Olive yra atvirojo kodo modelių optimizavimo įrankis, kuris:
- Supaprastina pritaikymo darbo eigą įvairioms aparatinės įrangos platformoms
- Suteikia integruotą palaikymą populiarioms modelių architektūroms (Llama, Phi, Qwen, Gemma)
- Siūlo tiek debesų, tiek vietinio diegimo galimybes
- Sklandžiai integruojasi su Azure ML ir kitomis Microsoft AI paslaugomis
- Palaiko automatinę optimizaciją ir kvantavimą

### Pagrindinės funkcijos

- **Optimizavimas pagal aparatinę įrangą**: Automatiškai optimizuoja modelius specifinei aparatinės įrangos platformai (CPU, GPU, NPU)
- **Daugiaplatformis palaikymas**: Veikia su PyTorch, Hugging Face ir ONNX modeliais
- **Automatizuotos darbo eigos**: Sumažina rankinio konfigūravimo ir bandymų poreikį
- **Įmonių integracija**: Integruotas palaikymas Azure ML ir debesų diegimams
- **Išplečiama architektūra**: Leidžia naudoti individualias optimizavimo technikas

### Įdiegimas ir nustatymas

#### Pagrindinis įdiegimas

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Papildomos priklausomybės

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Įdiegimo patikrinimas

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Praktiniai pavyzdžiai

### Pavyzdys 1: Pagrindinis pritaikymas naudojant Olive CLI

Šis pavyzdys demonstruoja mažo kalbos modelio pritaikymą frazių klasifikacijai:

#### 1 žingsnis: Paruoškite aplinką

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### 2 žingsnis: Pritaikykite modelį

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### 3 žingsnis: Optimizuokite diegimui

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Pavyzdys 2: Pažangi konfigūracija su individualiu duomenų rinkiniu

#### 1 žingsnis: Paruoškite individualų duomenų rinkinį

Sukurkite JSON failą su savo mokymo duomenimis:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### 2 žingsnis: Sukurkite konfigūracijos failą

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### 3 žingsnis: Vykdykite pritaikymą

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Pavyzdys 3: QLoRA pritaikymas efektyviai atminčiai

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Geriausios praktikos ir rekomendacijos

### Duomenų paruošimas

**1. Duomenų kokybė svarbiau už kiekį**
- Pirmenybę teikite aukštos kokybės, įvairiems pavyzdžiams, o ne dideliam kiekiui prastų duomenų
- Užtikrinkite, kad duomenys atspindėtų jūsų tikslinį naudojimo atvejį
- Nuosekliai valykite ir apdorokite duomenis

**2. Duomenų formatas ir šablonai**
- Naudokite nuoseklų formatavimą visiems mokymo pavyzdžiams
- Sukurkite aiškius įvesties-išvesties šablonus, atitinkančius jūsų naudojimo atvejį
- Įtraukite tinkamą instrukcijų formatavimą modeliams, pritaikytiems instrukcijoms

**3. Duomenų rinkinio skirstymas**
- Rezervuokite 10-20% duomenų validacijai
- Išlaikykite panašias distribucijas tarp mokymo/validacijos rinkinių
- Apsvarstykite stratifikavimą klasifikacijos užduotims

### Mokymo konfigūracija

**1. Mokymosi greičio pasirinkimas**
- Pradėkite nuo mažesnių mokymosi greičių (1e-5 iki 1e-4) pritaikymui
- Naudokite mokymosi greičio planavimą geresniam konvergavimui
- Stebėkite nuostolių kreives, kad atitinkamai koreguotumėte greitį

**2. Partijos dydžio optimizavimas**
- Subalansuokite partijos dydį su turima atmintimi
- Naudokite gradientų kaupimą didesniems efektyviems partijos dydžiams
- Apsvarstykite ryšį tarp partijos dydžio ir mokymosi greičio

**3. Mokymo trukmė**
- Stebėkite validacijos metrikas, kad išvengtumėte permokymo
- Naudokite ankstyvą sustabdymą, kai validacijos našumas stabilizuojasi
- Reguliariai išsaugokite kontrolinius taškus atkūrimui ir analizei

### Modelio pasirinkimas

**1. Bazinio modelio pasirinkimas**
- Pasirinkite modelius, iš anksto apmokytus panašiose srityse, kai įmanoma
- Apsvarstykite modelio dydį, atsižvelgdami į savo skaičiavimo apribojimus
- Įvertinkite licencijavimo reikalavimus komerciniam naudojimui

**2. Pritaikymo metodo pasirinkimas**
- Naudokite LoRA/QLoRA resursų apribotose aplinkose
- Pasirinkite pilną pritaikymą, kai svarbiausias maksimalus našumas
- Apsvarstykite adapterių metodus kelių užduočių scenarijams

### Resursų valdymas

**1. Aparatinės įrangos optimizavimas**
- Pasirinkite tinkamą aparatinę įrangą pagal modelio dydį ir metodą
- Efektyviai naudokite GPU atmintį su gradientų kontrolės taškais
- Apsvarstykite debesų sprendimus didesniems modeliams

**2. Atminties valdymas**
- Naudokite mišraus tikslumo mokymą, kai įmanoma
- Įgyvendinkite gradientų kaupimą atminties apribojimams
- Stebėkite GPU atminties naudojimą viso mokymo metu

## Pažangios technikos

### Daugiaadapterinis mokymas

Mokykite kelis adapterius skirtingoms užduotims, dalindamiesi baziniu modeliu:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hiperparametrų optimizavimas

Įgyvendinkite sisteminį hiperparametrų derinimą:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Individualios nuostolių funkcijos

Įgyvendinkite specifines nuostolių funkcijas:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Vertinimas ir stebėjimas

### Metrikos ir vertinimas

**1. Standartinės metrikos**
- **Tikslumas**: Bendras teisingumas klasifikacijos užduotims
- **Perpleksija**: Kalbos modelių kokybės matas
- **BLEU/ROUGE**: Teksto generavimo ir santraukų kokybės matas
- **F1 balas**: Subalansuotas tikslumas ir atšaukimas klasifikacijai

**2. Specifinės srities metrikos**
- **Užduočių specifiniai etalonai**: Naudokite nustatytus etalonus savo srityje
- **Žmogaus vertinimas**: Įtraukite žmogaus vertinimą subjektyvioms užduotims
- **Verslo metrikos**: Suderinkite su faktiniais verslo tikslais

**3. Vertinimo nustatymas**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Mokymo progreso stebėjimas

**1. Nuostolių stebėjimas**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validacijos stebėjimas**
- Stebėkite validacijos nuostolius kartu su mokymo nuostoliais
- Stebėkite permokymo požymius (validacijos nuostoliai didėja, kai mokymo nuostoliai mažėja)
- Naudokite ankstyvą sustabdymą, remdamiesi validacijos metrikomis

**3. Resursų stebėjimas**
- Stebėkite GPU/CPU naudojimą
- Sekite atminties naudojimo modelius
- Stebėkite mokymo greitį ir našumą

## Dažniausi iššūkiai ir sprendimai

### Iššūkis 1: Permokymas

**Simptomai:**
- Mokymo nuostoliai toliau mažėja, o validacijos nuostoliai didėja
- Didelis skirtumas tarp mokymo ir validacijos našumo
- Prastas generalizavimas naujiems duomenims

**Sprendimai:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Iššūkis 2: Atminties apribojimai

**Sprendimai:**
- Naudokite gradientų kontrolės taškus
- Įgyvendinkite gradientų kaupimą
- Pasirinkite efektyvius parametrų metodus (LoRA, QLoRA)
- Naudokite modelio paralelizmą dideliems modeliams

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Iššūkis 3: Lėtas mokymas

**Sprendimai:**
- Optimizuokite duomenų įkėlimo procesus
- Naudokite mišraus tikslumo mokymą
- Įgyvendinkite efektyvias partijos strategijas
- Apsvarstykite paskirstytą mokymą dideliems duomenų rinkiniams

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Iššūkis 4: Prastas našumas

**Diagnostikos žingsniai:**
1. Patikrinkite duomenų kokybę ir formatavimą
2. Patikrinkite mokymosi greitį ir mokymo trukmę
3. Įvertinkite bazinio modelio pasirinkimą
4. Peržiūrėkite išankstinį apdorojimą ir tokenizaciją

**Sprendimai:**
- Padidinkite mokymo duomenų įvairovę
- Koreguokite mokymosi greičio planavimą
- Išbandykite skirtingus bazinius modelius
- Įgyvendinkite duomenų papildymo technikas

## Išvada

Modelių pritaikymas yra galinga technika, kuri demokratizuoja prieigą prie pažangiausių AI galimybių. Naudodami tokius įrankius kaip Microsoft Olive, organizacijos gali efektyviai pritaikyti iš anksto apmokytus modelius savo specifiniams

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.