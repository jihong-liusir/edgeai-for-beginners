<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49e18143f97a802a8647f4be28355348",
  "translation_date": "2025-09-19T01:01:43+00:00",
  "source_file": "Module04/01.Introduce.md",
  "language_code": "lt"
}
-->
# 1 skyrius: Modelių formato konvertavimas ir kvantizavimo pagrindai

Modelių formato konvertavimas ir kvantizavimas yra svarbūs EdgeAI pažangos aspektai, leidžiantys įgyvendinti sudėtingas mašininio mokymosi galimybes ribotų resursų įrenginiuose. Supratimas, kaip efektyviai konvertuoti, optimizuoti ir diegti modelius, yra būtinas kuriant praktiškus AI sprendimus kraštiniuose įrenginiuose.

## Įvadas

Šiame vadove nagrinėsime modelių formato konvertavimo ir kvantizavimo technikas bei jų pažangias įgyvendinimo strategijas. Aptarsime pagrindines modelių suspaudimo sąvokas, formato konvertavimo ribas ir klasifikacijas, optimizavimo technikas bei praktines diegimo strategijas kraštiniuose kompiuterijos aplinkose.

## Mokymosi tikslai

Šio vadovo pabaigoje galėsite:

- 🔢 Suprasti kvantizavimo ribas ir skirtingų tikslumo lygių klasifikacijas.
- 🛠️ Identifikuoti pagrindines formato konvertavimo technikas modelių diegimui kraštiniuose įrenginiuose.
- 🚀 Išmokti pažangias kvantizavimo ir suspaudimo strategijas optimizuotai inferencijai.

## Modelių kvantizavimo ribų ir klasifikacijų supratimas

Modelių kvantizavimas yra technika, skirta sumažinti neuroninių tinklų parametrų tikslumą, naudojant žymiai mažiau bitų nei pilno tikslumo modeliai. Pilno tikslumo modeliai naudoja 32 bitų slankiojo kablelio reprezentacijas, o kvantizuoti modeliai yra specialiai sukurti efektyvumui ir diegimui kraštiniuose įrenginiuose.

Tikslumo klasifikavimo sistema padeda suprasti skirtingas kvantizavimo lygių kategorijas ir jų tinkamus naudojimo atvejus. Ši klasifikacija yra labai svarbi renkantis tinkamą tikslumo lygį konkretiems kraštinės kompiuterijos scenarijams.

### Tikslumo klasifikavimo sistema

Supratimas apie tikslumo ribas padeda pasirinkti tinkamus kvantizavimo lygius skirtingiems kraštinės kompiuterijos scenarijams:

- **🔬 Itin žemas tikslumas**: 1–2 bitų kvantizavimas (ekstremalus suspaudimas specializuotai aparatūrai)
- **📱 Žemas tikslumas**: 3–4 bitų kvantizavimas (subalansuotas našumas ir efektyvumas)
- **⚖️ Vidutinis tikslumas**: 5–8 bitų kvantizavimas (artėjantis prie pilno tikslumo galimybių, išlaikant efektyvumą)

Tikslumo ribos lieka lankstūs mokslinių tyrimų bendruomenėje, tačiau dauguma praktikų laiko 8 bitų ir mažesnius modelius „kvantizuotais“, kai kurie šaltiniai nustato specializuotas ribas skirtingiems aparatūros tikslams.

### Pagrindiniai modelių kvantizavimo privalumai

Modelių kvantizavimas siūlo keletą pagrindinių privalumų, kurie daro jį idealų kraštinės kompiuterijos taikymams:

**Operacinis efektyvumas**: Kvantizuoti modeliai užtikrina greitesnį inferencijos laiką dėl sumažėjusio skaičiavimo sudėtingumo, todėl jie yra idealūs realaus laiko taikymams. Jie reikalauja mažiau skaičiavimo resursų, leidžia diegti ribotų resursų įrenginiuose, sunaudoja mažiau energijos ir mažina anglies pėdsaką.

**Diegimo lankstumas**: Šie modeliai leidžia AI veikti įrenginyje be interneto ryšio, didina privatumą ir saugumą per vietinį apdorojimą, gali būti pritaikyti specifinėms sritims ir yra tinkami įvairioms kraštinės kompiuterijos aplinkoms.

**Ekonomiškumas**: Kvantizuoti modeliai siūlo ekonomišką mokymą ir diegimą, palyginti su pilno tikslumo modeliais, mažesnes eksploatavimo išlaidas ir mažesnius pralaidumo reikalavimus kraštiniuose taikymuose.

## Pažangios modelių formato įsigijimo strategijos

### GGUF (General GGML Universal Format)

GGUF yra pagrindinis formatas kvantizuotų modelių diegimui CPU ir kraštiniuose įrenginiuose. Formatui būdingi išsamūs resursai modelių konvertavimui ir diegimui:

**Formatų atradimo funkcijos**: Formatui būdinga pažangi įvairių kvantizavimo lygių, licencijų suderinamumo ir našumo optimizavimo palaikymas. Vartotojai gali pasinaudoti kryžminės platformos suderinamumu, realaus laiko našumo testais ir WebGPU palaikymu naršyklės pagrindu veikiančiam diegimui.

**Kvantizavimo lygių kolekcijos**: Populiarūs kvantizavimo formatai apima Q4_K_M subalansuotam suspaudimui, Q5_K_S seriją kokybei orientuotiems taikymams, Q8_0 beveik originaliam tikslumui ir eksperimentinius formatus, tokius kaip Q2_K itin žemo tikslumo diegimui. Formatui taip pat būdingi bendruomenės sukurti variantai su specializuotomis konfigūracijomis specifinėms sritims ir bendrojo naudojimo bei instrukcijoms pritaikyti variantai, optimizuoti skirtingiems naudojimo atvejams.

### ONNX (Open Neural Network Exchange)

ONNX formatas užtikrina kryžminės sistemos suderinamumą kvantizuotiems modeliams su patobulintomis integracijos galimybėmis:

**Įmonės integracija**: Formatui būdingi modeliai su įmonės lygio palaikymu ir optimizavimo galimybėmis, įskaitant dinaminį kvantizavimą adaptuojamam tikslumui ir statinį kvantizavimą gamybos diegimui. Jis taip pat palaiko modelius iš įvairių sistemų su standartizuotais kvantizavimo metodais.

**Įmonės privalumai**: Integruoti įrankiai optimizavimui, kryžminės platformos diegimui ir aparatūros pagreičiui yra suderinti su skirtingais inferencijos varikliais. Tiesioginis sistemos palaikymas su standartizuotais API, integruotos optimizavimo funkcijos ir išsamūs diegimo procesai pagerina įmonės patirtį.

## Pažangios kvantizavimo ir optimizavimo technikos

### Llama.cpp optimizavimo sistema

Llama.cpp siūlo pažangias kvantizavimo technikas, užtikrinančias maksimalų efektyvumą kraštiniuose diegimuose:

**Kvantizavimo metodai**: Sistema palaiko įvairius kvantizavimo lygius, įskaitant Q4_0 (4 bitų kvantizavimas su puikiu dydžio sumažinimu - idealus mobiliajam diegimui), Q5_1 (5 bitų kvantizavimas, subalansuojantis kokybę ir suspaudimą - tinkamas kraštinei inferencijai) ir Q8_0 (8 bitų kvantizavimas beveik originaliai kokybei - rekomenduojamas gamybos naudojimui). Pažangūs formatai, tokie kaip Q2_K, atspindi pažangų suspaudimą ekstremaliems scenarijams.

**Įgyvendinimo privalumai**: CPU optimizuota inferencija su SIMD pagreičiu užtikrina atminties efektyvų modelių įkrovimą ir vykdymą. Kryžminės platformos suderinamumas su x86, ARM ir Apple Silicon architektūromis leidžia aparatūros nepriklausomą diegimą.

**Atminties pėdsako palyginimas**: Skirtingi kvantizavimo lygiai siūlo įvairius kompromisus tarp modelio dydžio ir kokybės. Q4_0 užtikrina maždaug 75% dydžio sumažinimą, Q5_1 siūlo 70% sumažinimą su geresniu kokybės išlaikymu, o Q8_0 pasiekia 50% sumažinimą, išlaikant beveik originalų našumą.

### Microsoft Olive optimizavimo rinkinys

Microsoft Olive siūlo išsamias modelių optimizavimo darbo eigas, skirtas gamybos aplinkoms:

**Optimizavimo technikos**: Rinkinys apima dinaminį kvantizavimą automatiškam tikslumo pasirinkimui, grafų optimizavimą ir operatorių sujungimą efektyvumui pagerinti, aparatūros specifines optimizacijas CPU, GPU ir NPU diegimui bei daugiapakopius optimizavimo procesus. Specializuotos kvantizavimo darbo eigos palaiko įvairius tikslumo lygius nuo 8 bitų iki eksperimentinių 1 bitų konfigūracijų.

**Darbo eigos automatizavimas**: Automatinis testavimas per optimizavimo variantus užtikrina kokybės metrikų išsaugojimą optimizavimo metu. Integracija su populiariomis ML sistemomis, tokiomis kaip PyTorch ir ONNX, suteikia debesų ir kraštinio diegimo optimizavimo galimybes.

### Apple MLX sistema

Apple MLX siūlo natyvią optimizaciją, specialiai sukurtą Apple Silicon įrenginiams:

**Apple Silicon optimizacija**: Sistema naudoja vieningos atminties architektūrą su Metal Performance Shaders integracija, automatinį mišrų tikslumo inferenciją ir optimizuotą atminties pralaidumo naudojimą. Modeliai rodo išskirtinį našumą M serijos lustuose, užtikrinant optimalų balansą įvairiems Apple įrenginių diegimams.

**Kūrimo funkcijos**: Python ir Swift API palaikymas su NumPy suderinamais masyvo operacijomis, automatinio diferencijavimo galimybėmis ir sklandžia integracija su Apple kūrimo įrankiais suteikia išsamų kūrimo aplinką.

## Gamybos diegimo ir inferencijos strategijos

### Ollama: Supaprastintas vietinis diegimas

Ollama supaprastina modelių diegimą su įmonės paruoštomis funkcijomis vietinėms ir kraštinėms aplinkoms:

**Diegimo galimybės**: Vieno komandos modelio įdiegimas ir vykdymas su automatiniu modelio atsisiuntimu ir talpinimu. Palaikymas įvairiems kvantizuotiems formatams su REST API integracijai į programas ir daugiamodelių valdymo bei perjungimo galimybėmis. Pažangūs kvantizavimo lygiai reikalauja specifinės konfigūracijos optimaliam diegimui.

**Pažangios funkcijos**: Pritaikytų modelių derinimo palaikymas, Dockerfile generavimas konteinerizuotam diegimui, GPU pagreitis su automatiniu aptikimu ir modelių kvantizavimo bei optimizavimo galimybės suteikia išsamų diegimo lankstumą.

### VLLM: Aukštos kokybės inferencija

VLLM užtikrina gamybos lygio inferencijos optimizaciją didelio našumo scenarijams:

**Našumo optimizacijos**: PagedAttention atminties efektyviam dėmesio skaičiavimui, dinaminis paketavimas našumo optimizavimui, tensorų paralelizmas daugiagrafių masteliui ir spekuliatyvus dekodavimas latencijos mažinimui. Pažangūs kvantizavimo formatai reikalauja specializuotų inferencijos branduolių optimaliam našumui.

**Įmonės integracija**: OpenAI suderinami API galiniai taškai, Kubernetes diegimo palaikymas, stebėjimo ir stebėjimo integracija bei automatinio mastelio galimybės užtikrina įmonės lygio diegimo sprendimus.

### Microsoft kraštinės sprendimai

Microsoft siūlo išsamias kraštinės diegimo galimybes įmonės aplinkoms:

**Kraštinės kompiuterijos funkcijos**: Offline-first architektūros dizainas su resursų apribojimų optimizavimu, vietinis modelių registrų valdymas ir kraštinės-debesies sinchronizavimo galimybės užtikrina patikimą kraštinės diegimą.

**Saugumas ir atitiktis**: Vietinis duomenų apdorojimas privatumui išsaugoti, įmonės saugumo kontrolės, audito žurnalų ir atitikties ataskaitų teikimas bei prieigos valdymas pagal vaidmenis užtikrina išsamų saugumą kraštiniuose diegimuose.

## Geriausios praktikos modelių kvantizavimo įgyvendinimui

### Kvantizavimo lygių pasirinkimo gairės

Renkantis kvantizavimo lygius kraštiniam diegimui, atsižvelkite į šiuos veiksnius:

**Tikslumo skaičiaus svarstymai**: Pasirinkite itin žemą tikslumą, pvz., Q2_K, ekstremalioms mobiliosioms programoms, žemą tikslumą, pvz., Q4_K_M, subalansuotoms našumo situacijoms, ir vidutinį tikslumą, pvz., Q8_0, kai artėjama prie pilno tikslumo galimybių, išlaikant efektyvumą. Eksperimentiniai formatai siūlo specializuotą suspaudimą specifiniams mokslinių tyrimų taikymams.

**Naudojimo atvejų suderinimas**: Suderinkite kvantizavimo galimybes su specifiniais taikymo reikalavimais, atsižvelgdami į tokius veiksnius kaip tikslumo išsaugojimas, inferencijos greitis, atminties apribojimai ir neprisijungus veikimo reikalavimai.

### Optimizavimo strategijos pasirinkimas

**Kvantizavimo metodas**: Pasirinkite tinkamus kvantizavimo lygius pagal kokybės reikalavimus ir aparatūros apribojimus. Apsvarstykite Q4_0 maksimaliai suspaudimui, Q5_1 subalansuotam kokybės-suspaudimo kompromisui ir Q8_0 beveik originalios kokybės išsaugojimui. Eksperimentiniai formatai atspindi ekstremalaus suspaudimo ribas specializuotiems taikymams.

**Sistemos pasirinkimas**: Pasirinkite optimizavimo sistemas pagal tikslinę aparatūrą ir diegimo reikalavimus. Naudokite Llama.cpp CPU optimizuotam diegimui, Microsoft Olive išsamioms optimizavimo darbo eigoms ir Apple MLX Apple Silicon įrenginiams.

## Praktinis formato konvertavimas ir naudojimo atvejai

### Realūs diegimo scenarijai

**Mobiliosios programos**: Q4_K formatai puikiai tinka išmaniojo telefono programoms su minimaliu atminties pėdsaku, o Q8_0 užtikrina subalansuotą našumą planšetinių kompiuterių programoms. Q5_K formatai siūlo aukščiausios kokybės mobilias produktyvumo programas.

**Darbalaukio ir kraštinė kompiuterija**: Q5_K užtikrina optimalų našumą darbalaukio programoms, Q8_0 siūlo aukštos kokybės inferenciją darbo aplinkoms, o Q4_K leidžia efektyvų apdorojimą kraštiniuose įrenginiuose.

**Moksliniai tyrimai ir eksperimentai**: Pažangūs kvantizavimo formatai leidžia tyrinėti itin žemo tikslumo inferenciją akademiniams tyrimams ir koncepcijos įrodymo programoms, reikalaujančioms ekstremalių resursų apribojimų.

### Našumo testai ir palyginimai

**Inferencijos greitis**: Q4_K pasiekia greičiausią inferencijos laiką mobiliose CPU, Q5_K užtikrina subalansuotą greičio-kokybės santykį bendroms programoms, Q8_0 siūlo aukščiausios kokybės inferenciją sudėtingoms užduotims, o eksperimentiniai formatai užtikrina teorinį maksimalų pralaidumą su specializuota aparatūra.

**Atminties reikalavimai**: Kvantizavimo lygiai svyruoja nuo Q2_K (mažiau nei 500 MB mažiems modeliams) iki Q8_0 (maždaug 50% originalaus dydžio), o eksperimentinės konfigūracijos pasiekia maksimalias suspaudimo proporcijas.

## Iššūkiai ir svarstymai

### Našumo kompromisai



---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama profesionali žmogaus vertimo paslauga. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius naudojant šį vertimą.