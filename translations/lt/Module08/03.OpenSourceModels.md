<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-10-01T01:59:19+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "lt"
}
-->
# 3 sesija: Atvirojo kodo modelių atradimas ir valdymas

## Apžvalga

Ši sesija skirta praktiniam modelių atradimui ir valdymui naudojant Foundry Local. Sužinosite, kaip peržiūrėti galimus modelius, išbandyti skirtingas parinktis ir suprasti pagrindines našumo charakteristikas. Dėmesys skiriamas praktiniam tyrinėjimui naudojant foundry CLI, kad galėtumėte pasirinkti tinkamus modelius savo poreikiams.

## Mokymosi tikslai

- Įvaldyti foundry CLI komandas modelių atradimui ir valdymui
- Suprasti modelių talpyklos ir vietinio saugojimo principus
- Išmokti greitai išbandyti ir palyginti skirtingus modelius
- Sukurti praktinius darbo procesus modelių atrankai ir našumo testavimui
- Tyrinėti augančią modelių ekosistemą, prieinamą per Foundry Local

## Reikalavimai

- Baigta 1 sesija: Darbo pradžia su Foundry Local
- Įdiegtas ir pasiekiamas Foundry Local CLI
- Pakankamai vietos modelių atsisiuntimui (modelių dydis gali svyruoti nuo 1GB iki 20GB+)
- Pagrindinis modelių tipų ir jų naudojimo supratimas

## Apžvalga

Ši sesija nagrinėja, kaip integruoti atvirojo kodo modelius į Foundry Local, pasirinkti bendruomenės modelius, integruoti Hugging Face turinį ir taikyti „atsinešk savo modelį“ (BYOM) strategijas. Taip pat sužinosite apie „Model Mondays“ seriją, skirtą nuolatiniam mokymuisi ir modelių atradimui.

## 6 dalis: Praktinė užduotis

### Užduotis: Modelių atradimas ir palyginimas

Sukurkite savo modelio vertinimo scenarijų, remdamiesi 03 pavyzdžiu:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Jūsų užduotis

1. **Paleiskite 03 pavyzdžio scenarijų**: `samples\03\list_and_bench.cmd`
2. **Išbandykite skirtingus modelius**: Išbandykite bent 3 skirtingus modelius
3. **Palyginkite našumą**: Atkreipkite dėmesį į greičio ir atsakymo kokybės skirtumus
4. **Dokumentuokite rezultatus**: Sukurkite paprastą palyginimo lentelę

### Pavyzdinis palyginimo formatas

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## 7 dalis: Trikčių šalinimas ir geriausia praktika

### Dažnos problemos ir sprendimai

**Modelis neprasideda:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Nepakanka atminties:**
- Pradėkite nuo mažesnių modelių (`phi-4-mini`)
- Uždarykite kitas programas
- Atnaujinkite RAM, jei dažnai susiduriate su ribomis

**Lėtas našumas:**
- Įsitikinkite, kad modelis visiškai įkeltas (patikrinkite išsamų išvestį)
- Uždarykite nereikalingas fono programas
- Apsvarstykite greitesnį saugojimą (SSD)

### Geriausia praktika

1. **Pradėkite nuo mažų**: Pradėkite nuo `phi-4-mini`, kad patikrintumėte nustatymus
2. **Vienas modelis vienu metu**: Sustabdykite ankstesnius modelius prieš paleisdami naujus
3. **Stebėkite išteklius**: Stebėkite atminties naudojimą
4. **Testuokite nuosekliai**: Naudokite tuos pačius užklausų pavyzdžius sąžiningiems palyginimams
5. **Dokumentuokite rezultatus**: Užsirašykite modelių našumą pagal savo poreikius

## 8 dalis: Kiti žingsniai ir šaltiniai

### Pasiruošimas 4 sesijai

- **4 sesijos tema**: Optimizavimo įrankiai ir technikos
- **Reikalavimai**: Patogumas keičiant modelius ir atliekant pagrindinius našumo testus
- **Rekomenduojama**: Turėti 2-3 mėgstamus modelius, identifikuotus šios sesijos metu

### Papildomi šaltiniai

- **[Foundry Local dokumentacija](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Oficiali dokumentacija
- **[CLI nuoroda](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Pilna komandų nuoroda
- **[Model Mondays](https://aka.ms/model-mondays)**: Savaitiniai modelių pristatymai
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Bendruomenė ir problemų sprendimas
- **[03 pavyzdys: Modelių atradimas](samples/03/README.md)**: Praktinis pavyzdinis scenarijus

### Pagrindinės išvados

✅ **Modelių atradimas**: Naudokite `foundry model list`, kad peržiūrėtumėte galimus modelius  
✅ **Greitas testavimas**: Naudokite `list_and_bench.cmd` modelių greitam vertinimui  
✅ **Našumo stebėjimas**: Pagrindinis išteklių naudojimo ir atsakymo laiko matavimas  
✅ **Modelių atranka**: Praktinės gairės modelių pasirinkimui pagal naudojimo atvejus  
✅ **Talpyklos valdymas**: Saugojimo ir valymo procedūrų supratimas  

Dabar turite praktinių įgūdžių atrasti, testuoti ir pasirinkti tinkamus modelius savo AI programoms, naudodami Foundry Local paprastą CLI metodą.

## Mokymosi tikslai

- Atrasti ir įvertinti atvirojo kodo modelius vietinei analizei
- Kompiliuoti ir paleisti pasirinktus Hugging Face modelius Foundry Local aplinkoje
- Taikyti modelių atrankos strategijas pagal tikslumą, vėlavimą ir išteklių poreikius
- Valdyti modelius vietoje, naudojant talpyklą ir versijų kontrolę

## 1 dalis: Modelių atradimas su Foundry CLI

### Pagrindinės modelių valdymo komandos

Foundry CLI siūlo paprastas komandas modelių atradimui ir valdymui:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Pirmųjų modelių paleidimas

Pradėkite nuo populiarių, gerai išbandytų modelių, kad suprastumėte našumo charakteristikas:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**Pastaba:** `--verbose` vėliava pateikia išsamią paleidimo informaciją, įskaitant:
- Modelio atsisiuntimo eigą (pirmą kartą paleidžiant)
- Atminties paskirstymo detales
- Paslaugų susiejimo informaciją
- Našumo inicializavimo metrikas

### Modelių kategorijų supratimas

**Maži kalbos modeliai (SLMs):**
- `phi-4-mini`: Greitas, efektyvus, puikiai tinka bendram pokalbiui
- `phi-4`: Daugiau galimybių turinti versija su geresniu samprotavimu

**Vidutiniai modeliai:**
- `qwen2.5-7b`: Puikus samprotavimas ir ilgesnis kontekstas
- `deepseek-r1-7b`: Optimizuotas kodo generavimui

**Dideli modeliai:**
- `llama-3.2`: Naujausias Meta atvirojo kodo modelis
- `qwen2.5-14b`: Įmonės lygio samprotavimas

## 2 dalis: Greitas modelių testavimas ir palyginimas

### 03 pavyzdžio metodas: Paprastas sąrašas ir testavimas

Remiantis mūsų 03 pavyzdžio modeliu, pateikiamas minimalus darbo procesas:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Modelio našumo testavimas

Kai modelis veikia, testuokite jį naudodami nuoseklius užklausų pavyzdžius:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### PowerShell testavimo alternatyva

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## 3 dalis: Modelių talpyklos ir saugojimo valdymas

### Modelių talpyklos supratimas

Foundry Local automatiškai valdo modelių atsisiuntimus ir talpyklą:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Modelių saugojimo aspektai

**Tipiniai modelių dydžiai:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b`: ~4.1 GB  
- `deepseek-r1-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b`: ~8.2 GB

**Saugojimo geriausia praktika:**
- Laikykite 2-3 modelius talpykloje greitam perjungimui
- Pašalinkite nenaudojamus modelius, kad atlaisvintumėte vietą: `foundry cache clean`
- Stebėkite disko naudojimą, ypač mažesniuose SSD
- Apsvarstykite modelio dydžio ir galimybių kompromisus

### Modelio našumo stebėjimas

Kai modeliai veikia, stebėkite sistemos išteklius:

**Windows užduočių tvarkyklė:**
- Stebėkite atminties naudojimą (modeliai lieka įkelti į RAM)
- Stebėkite CPU naudojimą analizės metu
- Patikrinkite disko I/O pradinio modelio įkėlimo metu

**Komandinės eilutės stebėjimas:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## 4 dalis: Praktinės modelių atrankos gairės

### Modelių pasirinkimas pagal naudojimo atvejį

**Bendram pokalbiui ir klausimų-atsakymų sesijoms:**
- Pradėkite nuo: `phi-4-mini` (greitas, efektyvus)
- Atnaujinkite į: `phi-4` (geresnis samprotavimas)
- Pažangus pasirinkimas: `qwen2.5-7b` (ilgesnis kontekstas)

**Kodo generavimui:**
- Rekomenduojama: `deepseek-r1-7b`
- Alternatyva: `qwen2.5-7b` (taip pat geras kodo generavimui)

**Sudėtingam samprotavimui:**
- Geriausias: `qwen2.5-7b` arba `qwen2.5-14b`
- Biudžetinis pasirinkimas: `phi-4`

### Aparatūros reikalavimų vadovas

**Minimalūs sistemos reikalavimai:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Rekomenduojama geriausiam našumui:**
- 32GB+ RAM patogiam kelių modelių perjungimui
- SSD saugojimas greitesniam modelių įkėlimui
- Modernus CPU su geru vieno gijos našumu
- NPU palaikymas (Windows 11 Copilot+ kompiuteriai) spartinimui

### Modelių perjungimo darbo procesas

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## 5 dalis: Paprastas modelių našumo testavimas

### Pagrindinis našumo testavimas

Pateikiamas paprastas požiūris į modelių našumo palyginimą:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Rankinis kokybės vertinimas

Kiekvienam modeliui testuokite naudodami nuoseklius užklausų pavyzdžius ir vertinkite rankiniu būdu:

**Testo užklausos:**
1. "Paaiškinkite kvantinį skaičiavimą paprastais terminais."
2. "Parašykite Python funkciją sąrašo rūšiavimui."
3. "Kokie yra nuotolinio darbo privalumai ir trūkumai?"
4. "Apibendrinkite kraštinės AI privalumus."

**Vertinimo kriterijai:**
- **Tikslumas**: Ar informacija teisinga?
- **Aiškumas**: Ar paaiškinimas lengvai suprantamas?
- **Išsamumas**: Ar atsakymas apima visą klausimą?
- **Greitis**: Kaip greitai pateikiamas atsakymas?

### Išteklių naudojimo stebėjimas

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## 6 dalis: Kiti žingsniai

- Prenumeruokite „Model Mondays“ naujiems modeliams ir patarimams: https://aka.ms/model-mondays
- Prisidėkite prie savo komandos `models.json` failo
- Pasiruoškite 4 sesijai: LLM ir SLM palyginimas, vietinė ir debesų analizė, praktiniai demonstravimai

---

**Atsakomybės atsisakymas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar neteisingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.