<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-23T01:06:21+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "lt"
}
-->
# Sesija 1: Darbo pradžia su Foundry Local

## Apžvalga

Microsoft Foundry Local suteikia Azure AI Foundry galimybes tiesiai jūsų Windows 11 kūrimo aplinkoje, leidžiant kurti AI sprendimus su mažesne delsos trukme ir užtikrinant privatumo apsaugą, naudojant įmonės lygio įrankius. Šioje sesijoje aptarsime pilną diegimą, konfigūraciją ir praktinį populiarių modelių, tokių kaip phi, qwen, deepseek ir GPT-OSS-20B, diegimą.

## Mokymosi tikslai

Po šios sesijos jūs:
- Įdiegsite ir sukonfigūruosite Foundry Local Windows 11 aplinkoje
- Įvaldysite CLI komandas ir konfigūracijos parinktis
- Suprasite modelių talpyklos strategijas optimaliam našumui
- Sėkmingai paleisite phi, qwen, deepseek ir GPT-OSS-20B modelius
- Sukursite savo pirmąją AI programą naudodami Foundry Local

## Reikalavimai

### Sistemos reikalavimai
- **Windows 11**: Versija 22H2 arba naujesnė
- **RAM**: Mažiausiai 16GB, rekomenduojama 32GB
- **Saugykla**: 50GB laisvos vietos modeliams ir talpyklai
- **Aparatinė įranga**: Pageidautina įrenginys su NPU arba GPU (Copilot+ PC arba NVIDIA GPU)
- **Tinklas**: Greitas interneto ryšys modelių atsisiuntimui

### Kūrimo aplinka
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## 1 dalis: Diegimas ir nustatymas

### 1 žingsnis: Įdiegti Foundry Local

Įdiekite Foundry Local naudodami Winget arba atsisiųskite diegimo programą iš GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### 2 žingsnis: Patikrinti diegimą

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## 2 dalis: CLI supratimas

### Pagrindinė komandų struktūra

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## 3 dalis: Modelių talpykla ir valdymas

Foundry Local naudoja išmaniąją modelių talpyklą, kad optimizuotų našumą ir saugyklos naudojimą:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## 4 dalis: Praktinis modelių diegimas

### Microsoft Phi modelių paleidimas

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Darbas su Qwen modeliais

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### DeepSeek modelių paleidimas

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### GPT-OSS-20B paleidimas

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## 5 dalis: Pirmosios programos kūrimas

### Paprasta pokalbių sąsaja (OpenAI suderinama API)

Sukurkite pagrindinę pokalbių programą naudodami Foundry Local OpenAI suderinamą REST API. Įsitikinkite, kad modelis veikia kitame terminale.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Paleisti pokalbių programą

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## 6 dalis: Trikčių šalinimas ir geriausios praktikos

### Dažniausios problemos ir sprendimai

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Sistemos resursų stebėjimas (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Geriausios praktikos

- Naudokite `foundry model ...`, `foundry cache ...` ir `foundry service ...` komandas (žr. CLI nuorodą)
- Reguliariai atnaujinkite, kad gautumėte naujus modelius ir pataisas
- Pradėkite nuo mažesnių modelių (Phi mini, Qwen 7B) ir palaipsniui didinkite
- Stebėkite CPU/GPU/atminties naudojimą, kai koreguojate užklausas ir nustatymus

## 7 dalis: Praktinės užduotys

### Užduotis 1: Greitas kelių modelių paleidimas

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Užduotis 2: Pagrindinis delsos testas

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Nuorodos

- Darbo pradžia su Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- CLI nuoroda ir komandų apžvalga: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Hugging Face modelių kompiliavimas Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

