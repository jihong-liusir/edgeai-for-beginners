<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:52:30+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "lt"
}
-->
# 1 skyrius: Microsoft Phi modelių šeimos pagrindai

Microsoft Phi modelių šeima žymi paradigmos pokytį dirbtinio intelekto srityje, įrodydama, kad kompaktiški ir efektyvūs modeliai gali pasiekti įspūdingus rezultatus, tuo pačiu būdami žymiai mažiau resursų reikalaujantys nei tradiciniai dideli kalbos modeliai. Svarbu suprasti, kaip Phi šeima leidžia pasiekti galingas AI galimybes su mažesniais skaičiavimo reikalavimais, išlaikant aukštą našumą įvairiose užduotyse.

## Ištekliai kūrėjams

### Azure AI Foundry Model Catalog
Phi modelių šeima (išskyrus Phi-silica) yra pasiekiama per [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), leidžiant kūrėjams lengvai pasiekti, pritaikyti ir diegti šiuos modelius savo programose. Katalogas suteikia supaprastintą būdą eksperimentuoti su skirtingais Phi variantais ir integruoti juos į savo projektus.

### Azure AI Foundry
Phi modelius galite diegti ir eksperimentuoti su jais naudodami [Azure AI Foundry](https://ai.azure.com), kuris suteikia visapusišką aplinką AI sprendimų kūrimui, testavimui ir diegimui su minimaliu nustatymu.

### Foundry Local
Vietiniam kūrimui ir diegimui išbandykite [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), kuris leidžia paleisti Phi modelius jūsų kūrimo kompiuteryje su optimizuotomis konfigūracijomis.

### Dokumentacijos ištekliai
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Įvadas

Šioje pamokoje nagrinėsime Microsoft Phi modelių šeimą ir jos pagrindines koncepcijas. Aptarsime Phi šeimos evoliuciją, inovatyvius mokymo metodus, kurie daro Phi modelius efektyviais, pagrindinius šeimos variantus ir praktinius pritaikymus įvairiose situacijose.

## Mokymosi tikslai

Pamokos pabaigoje galėsite:

- Suprasti Microsoft Phi modelių šeimos dizaino filosofiją ir evoliuciją.
- Identifikuoti pagrindines inovacijas, leidžiančias Phi modeliams pasiekti aukštą našumą su mažesniu parametrų skaičiumi.
- Atpažinti skirtingų Phi modelių variantų privalumus ir trūkumus.
- Taikyti žinias apie Phi modelius, kad pasirinktumėte tinkamus variantus realioms situacijoms.

## Tradicinio AI modelio paradigma

Tradiciškai aukštas našumas natūralios kalbos apdorojime reikalavo masyvių kalbos modelių su milijardais ar šimtais milijardų parametrų. Organizacijos paprastai diegia šiuos modelius galinguose GPU klasteriuose, naudodamos jų galimybes per API sąsajas arba specializuotą techninę infrastruktūrą.

Šis metodas gerai veikia daugelyje programų, tačiau turi esminių apribojimų praktinio diegimo scenarijuose. Tradicinis metodas apima modelių naudojimą, kurie reikalauja didelių skaičiavimo resursų, daug atminties ir reikšmingo energijos suvartojimo. Nors šis metodas suteikia prieigą prie pažangiausių galimybių, jis sukuria priklausomybę nuo brangios techninės įrangos, didina eksploatavimo išlaidas ir riboja diegimo lankstumą.

## Efektyvaus AI diegimo iššūkis

Efektyvesnio AI poreikis tampa vis svarbesnis įvairiose situacijose. Pavyzdžiui, programos, reikalaujančios vietinio diegimo dėl privatumo priežasčių, sąnaudų jautrios įgyvendinimo, kur debesų API išlaidos tampa nepriimtinos, kraštinio skaičiavimo scenarijai su ribotais techninės įrangos resursais arba realaus laiko programos, kuriose svarbus atsako greitis.

### Pagrindiniai diegimo apribojimai

Tradiciniai didelių modelių diegimai susiduria su keliais esminiais apribojimais, kurie riboja jų praktinį pritaikymą:

- **Sąnaudų apribojimai**: Didelės skaičiavimo sąnaudos daro nuolatinį diegimą brangų daugeliui organizacijų.
- **Resursų apribojimai**: Ribota prieiga prie aukštos klasės GPU infrastruktūros riboja diegimo galimybes.
- **Privatumo reikalavimai**: Jautrios programos reikalauja vietinio apdorojimo, kad būtų išlaikytas duomenų privatumas.
- **Latencijos jautrumas**: Realaus laiko programos reikalauja greitų atsakymų be debesų ryšio vėlavimų.

## Microsoft Phi modelių filosofija

Microsoft Phi modelių šeima žymi esminį pokytį AI modelių dizaino filosofijoje, pirmenybę teikiant efektyvumui ir praktiniam diegimui, tuo pačiu išlaikant stiprias našumo charakteristikas. Phi modeliai tai pasiekia per inovatyvias architektūras, aukštos kokybės mokymo metodikas ir specializuotas optimizavimo technikas.

Phi šeima apima įvairius metodus, skirtus maksimaliai padidinti našumą per parametrą, leidžiant diegti standartinėje techninėje įrangoje, tuo pačiu suteikiant reikšmingas AI galimybes. Tikslas yra išlaikyti konkurencingą našumą, tuo pačiu drastiškai sumažinant skaičiavimo reikalavimus, atminties naudojimą ir eksploatavimo išlaidas.

### Pagrindiniai Phi dizaino principai

Phi modeliai yra sukurti remiantis keliais pagrindiniais principais, kurie juos išskiria iš tradicinių didelių kalbos modelių:

- **Efektyvumas pirmiausia**: Optimizuoti maksimaliai našumui per parametrą, o ne absoliučiam mastui.
- **Kokybiškas mokymas**: Dėmesys aukštos kokybės, kruopščiai atrinktiems mokymo duomenims, o ne masyviems duomenų rinkiniams.
- **Diegimo lankstumas**: Sukurti veikti efektyviai įvairiose techninės įrangos konfigūracijose.
- **Specializuotos galimybės**: Dažnai optimizuoti specifinėms užduotims ar sritims, kad būtų maksimaliai efektyvūs.

## Pagrindinės technologijos, leidžiančios Phi šeimą

### „Vadovėlio“ mokymo metodas

Vienas iš revoliucingiausių Phi šeimos aspektų yra „vadovėlio kokybės“ mokymo metodika. Vietoj mokymo su masyviu kiekiu nefiltruotų interneto duomenų, Phi modeliai naudoja kruopščiai atrinktą, aukštos kokybės edukacinį turinį, skirtą efektyviai mokyti logikos, matematikos, kodavimo ir bendrųjų žinių.

Šis metodas veikia kuriant sintetinį edukacinį turinį, kuris atspindi aukštos kokybės vadovėlius ir akademinę medžiagą. Mokymo duomenys yra specialiai sukurti, kad būtų pedagogiškai tinkami, orientuoti į aiškius paaiškinimus, žingsnis po žingsnio logiką ir struktūruotą žinių pateikimą.

### Pažangus logikos mokymas

Naujausi Phi modeliai įtraukia sudėtingas logikos mokymo metodikas, leidžiančias spręsti sudėtingas daugiapakopes problemas. Šios technikos apima:

**„Mąstymo grandinės“ mokymas**: Modeliai mokosi suskaidyti sudėtingas problemas į tarpinio logikos žingsnius, padarant jų problemų sprendimo procesą skaidresnį ir patikimesnį.

**Mastelio didinimas atsakymo metu**: Modeliai generuoja detalias logikos grandines, kurios atsakymo generavimo metu naudoja papildomus skaičiavimo resursus, kad pagerintų tikslumą.

**Mokymas ties galimybių riba**: Mokymo duomenys yra specialiai parinkti, kad iššauktų modelį ties jo dabartinių galimybių riba, skatinant mokytis sudėtingų logikos modelių.

### Architektūrinės inovacijos

Phi šeima įtraukia kelias architektūrines optimizacijas, specialiai sukurtas efektyvumui:

**Parametrų efektyvumas**: Kruopščiai parinktos architektūros, kurios maksimaliai išnaudoja kiekvieną modelio parametrą.

**Daugiarūšis integravimas**: Efektyvus teksto, vaizdų ir kalbos apdorojimo galimybių integravimas kompaktiškose architektūrose.

**Techninės įrangos optimizavimas**: Specializuoti variantai, optimizuoti specifinėms techninės įrangos platformoms ir diegimo scenarijams.

## Techninės įrangos optimizavimas Phi modeliams

Šiuolaikinės diegimo aplinkos naudoja Phi modelių efektyvumą įvairiose techninės įrangos konfigūracijose:

### CPU optimizuotas diegimas

Phi modeliai yra sukurti veikti efektyviai tik CPU pagrindu veikiančioje techninėje įrangoje, leidžiant juos diegti standartinėje kompiuterinėje infrastruktūroje be specializuotų AI akceleratorių.

### GPU pagreitinimas

Nors nereikalaujant galingų GPU, Phi modeliai gali pasinaudoti turimais GPU resursais, kad pagerintų našumą, suteikiant lankstumą diegimo konfigūracijose.

### Kraštinių įrenginių integracija

Specializuoti variantai, tokie kaip Phi-3-Silica, yra optimizuoti specifinėms kraštinio skaičiavimo platformoms, pasiekiant įspūdingus efektyvumo rodiklius, tokius kaip 650 žetonų per sekundę su tik 1.5W energijos suvartojimu.

## Phi modelių šeimos privalumai

### Sąnaudų efektyvumas

Phi modeliai žymiai sumažina eksploatavimo išlaidas, reikalaudami žymiai mažiau skaičiavimo infrastruktūros, tuo pačiu išlaikant konkurencingą našumą. Tai daro AI prieinamą organizacijoms su ribotais biudžetais arba didelės apimties programoms, kur svarbi kaina už vieną užklausą.

### Diegimo lankstumas

Phi modelių efektyvumas leidžia juos diegti įvairiose techninės įrangos konfigūracijose, nuo asmeninių nešiojamųjų kompiuterių iki įmonių serverių, suteikiant organizacijoms didesnį lankstumą jų AI infrastruktūros pasirinkimuose.

### Privatumas ir saugumas

Phi modelių efektyvumas leidžia vietinį diegimą privatumo jautrioms programoms, užtikrinant, kad jautrūs duomenys niekada nepaliks organizacijos kontrolės, tuo pačiu suteikiant galingas AI galimybes.

### Realaus laiko našumas

Sumažinti skaičiavimo reikalavimai reiškia greitesnį atsakymų generavimą, leidžiant realaus laiko programoms, kurios reikalauja greitų atsakymų, nekompromituojant AI galimybių kokybės.

### Prieinamas AI

Sumažindami AI diegimo barjerus, Phi modeliai daro pažangias AI galimybes prieinamas organizacijoms su ribotais resursais, leidžiant mažesnėms komandoms ir individualiems kūrėjams pasinaudoti sudėtingu kalbos supratimu.

## Praktiniai pavyzdžiai ir pritaikymo atvejai

Prieš gilindamiesi į techninę evoliuciją, pažvelkime į keletą konkrečių pavyzdžių, ką Phi modeliai gali pasiekti:

### Matematinės logikos pavyzdys

Phi-4-mini-reasoning puikiai sprendžia žingsnis po žingsnio matematines problemas. Pavyzdžiui, paklausus „Kaip išspręsti 3*x^2+4*x+5=1?“, modelis pateikia detalius logikos žingsnius:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Daugiakalbės palaikymo pavyzdys

Phi-3.5-mini-instruct demonstruoja stiprias daugiakalbes galimybes įvairiomis kalbomis. Štai pavyzdinis užklausos formatas:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Daugiarūšės galimybės pavyzdys

Phi-4-multimodal gali apdoroti tekstą, vaizdus ir kalbą vienu metu. Štai keletas praktinių pritaikymų:

**Kelionių planavimas naudojant garso įvestį:**
Phi-4 Multimodal analizuoja kalbą, kad padėtų suplanuoti kelionę į Sietlą, demonstruodamas pažangias garso apdorojimo ir rekomendacijų galimybes.

**Matematinės problemos sprendimas iš vaizdų:**
Phi-4 Multimodal sprendžia sudėtingas matematines problemas per vizualinę įvestį, demonstruodamas gebėjimą apdoroti ir spręsti lygtis, pateiktas vaizduose.

**Funkcijų kvietimo pavyzdys:**
Naudodami funkcijų kvietimą, Phi-4-mini ir Phi-4-multimodal gali išplėsti savo teksto apdorojimo galimybes, integruodami paieškos sistemas, jungdami įvairius įrankius ir daugiau. Kaip parodyta, modelis gali gauti „Premier League“ rungtynių informaciją per Phi-4-mini, demonstruodamas gebėjimą sklandžiai sąveikauti su išoriniais duomenų šaltiniais.

### Kodo generavimo pavyzdys

Phi-4-multimodal gali generuoti struktūrizuotą projekto kodą, remdamasis tiek vaizdo turiniu, tiek pateiktais užklausos duomenimis, kaip parodyta šiame praktiniame darbo procese:

1. Įkelkite vaizdą su karkasu ar dizainu
2. Pateikite kontekstą apie projekto reikalavimus
3. Modelis generuoja pilnas, funkcionalias kodo struktūras
4. Kodas gali būti pritaikytas pagal specifines sistemas ar kalbas

### Kraštinio diegimo pavyzdys

Galime diegti kvantizuotą modelį kraštiniuose įrenginiuose. Naudodami Microsoft Olive ir ONNX GenAI Runtime, galime diegti Phi-4-mini Windows, iPhone, Android ir kituose įrenginiuose. Štai pavyzdys, veikiantis iPhone 12 Pro.

Diegimo procesas apima:
- Modelio kvantizavimą mobiliajai optimizacijai
- ONNX vykdymo aplinkos integraciją kryžminės platformos suderinamumui
- Vietinį apdorojimą be interneto ryšio
- Realaus laiko našumą su minimaliu energijos suvartojimu

## Phi šeimos evoliucija

### Phi-1 ir Phi-2: Pagrindiniai modeliai

Ankstyvieji Phi modeliai nustatė pagrindinius principus, tokius kaip aukštos kokybės mokymo duomenys ir efektyvios architektūros:

- **Phi-1 (1.3B parametrai)**: Įvedė kruopščiai atrinktų mokymo duomenų koncepciją pagrindiniam kalbos supratimui ir kodo generavimui.
- **Phi-2 (2.7B parametrai)**: Pagerino logikos galimybes per sintetinę NLP duomenų ir kruopščiai filtruotą interneto turinį.

### Phi-3 šeima: Pagrindinis pritaikymas

Phi-3 serija žymėjo proveržį SLM galimybėse su keliais specializuotais variantais:

- **Phi-3-mini (3.8B parametrai)**: Bendros kalbos užduotys su išskirtiniu efektyvumu, pranokstant modelius dvigubai didesnius.
- **Phi-3-small (7B parametrai)**: Pažangus našumas, pranokstantis GPT-3.5 Turbo įvairiuose testuose.
- **Phi-3-medium (14B parametrai)**: Įmonės lygio našumas, pranokstantis Gemini 1.0 Pro.
- **Phi-3-vision (4.2B parametrai)**: Daugiarūšės galimybės vaizdų ir teksto apdoroj
Phi šeima parodo, kad dirbtinio intelekto ateitis slypi ne tik kuriant didesnius modelius, bet ir kuriant protingesnius, efektyvesnius modelius, kurie gali veikti įvairiose techninės įrangos aplinkose, išlaikydami aukštus našumo standartus.

## Kūrimo ir integravimo pavyzdžiai

### Greitas startas su Transformers

Štai kaip pradėti naudoti Phi modelius su Hugging Face Transformers biblioteka:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Pavyzdys, kaip pritaikyti modelį

Šis pavyzdys parodo, kaip pritaikyti Phi-4-mini-instruct konkrečioms užduotims:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specializuoti užduočių formatai

**Logikos užduotims (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Matematinėms užduotims (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobilus diegimas su ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Našumo rodikliai ir pasiekimai

Phi modelių šeima pasiekė įspūdingų rezultatų įvairiuose testuose, dažnai pranokdama daug didesnius modelius:

### Svarbiausi našumo pasiekimai

**Matematinio samprotavimo meistriškumas:**
- Phi-4 pasiekia 82,5% tikslumą AIME 2025 (Matematikos olimpiados kvalifikacija)
- Phi-4-reasoning (14B) pranoksta DeepSeek-R1-Distill-70B (5 kartus didesnį) logikos testuose
- Phi-4-mini-reasoning (3.8B) prilygsta modeliams, kurie yra dvigubai didesni matematinio samprotavimo užduotyse

**Efektyvumo pasiekimai:**
- Phi-3-Silica pasiekia 650 žetonų per sekundę, sunaudodamas tik 1,5W energijos
- Phi-4-mini (3.8B) pasiekia panašų našumą kaip daug didesni modeliai

**Testų rezultatai:**
- **MMLU (Masinis daugiatikslis kalbos supratimas)**: Konkurencingi rezultatai 57 akademinėse srityse
- **HumanEval**: Stiprios kodo generavimo galimybės, ypač Python kalboje
- **MGSM**: Daugiakalbis pradinės mokyklos matematikos problemų sprendimas
- **DROP**: Sudėtingos supratimo ir logikos užduotys
- **SimpleQA**: Faktų tikslumo atsakymai

### 📊 Modelių palyginimo matrica

| Modelis | Parametrai | Konteksto ilgis | Pagrindinės stiprybės | Geriausi naudojimo atvejai |
|---------|------------|-----------------|-----------------------|----------------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Bendras efektyvumas | Mobilios programėlės, paprasti pokalbių robotai |
| **Phi-3.5-mini** | 3.8B | 128K | Daugiakalbė parama | Tarptautinės programos |
| **Phi-4-mini** | 3.8B | 128K | Patobulintas samprotavimas, funkcijų iškvietimas | Verslo automatizavimas |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matematinis samprotavimas | Švietimo platformos |
| **Phi-4** | 14B | 32K | Sudėtingas samprotavimas | Tyrimai, pažangi analizė |
| **Phi-4-reasoning** | 14B | 32K/64K | Daugiapakopis samprotavimas | Mokslinis skaičiavimas |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimalus tikslumas samprotavime | Kritinių sprendimų priėmimas |
| **Phi-4-multimodal** | 5.6B | Kintamas | Kalba, vaizdas, tekstas | Multimedijos programos |

## Modelio pasirinkimo vadovas

### Paprastoms programoms
- **Phi-3-mini**: Paprastas teksto generavimas, pagrindiniai klausimai ir atsakymai, greiti atsakymai
- **Phi-4-mini**: Patobulintas samprotavimas su funkcijų iškvietimo galimybėmis

### Matematinėms ir logikos užduotims
- **Phi-4**: Sudėtingas matematikos problemų sprendimas ir samprotavimas
- **Phi-4-reasoning**: Daugiapakopis samprotavimas su išsamiais paaiškinimais
- **Phi-4-reasoning-plus**: Maksimalus tikslumas kritinėse logikos užduotyse
- **Phi-4-mini-reasoning**: Efektyvus matematinis samprotavimas ribotų resursų aplinkoje

### Multimodalinėms programoms
- **Phi-3-vision**: Vaizdo ir teksto apdorojimo deriniai
- **Phi-4-multimodal**: Išsamios kalbos, vaizdo ir teksto galimybės

### Įmonių diegimui
- **Phi-3-medium**: Pažangus kalbos supratimas verslo programoms
- **Phi-3-Silica**: Optimizuotas specifinėms techninės įrangos platformoms

## Diegimo platformos ir prieinamumas

### Debesų platformos
- **Azure AI Foundry**: Pilnai funkcionalus diegimas su verslo įrankiais
- **Hugging Face**: Atvirojo kodo modelių saugykla ir bendruomenės ištekliai
- **NVIDIA API Catalog**: Mikroservisų diegimo galimybės

### Vietinės kūrimo sistemos
- **Ollama**: Lengva sistema vietiniam modelių diegimui
- **ONNX Runtime**: Optimizuotas įvairioms techninės įrangos konfigūracijoms  
- **DirectML**: Optimizuotas Windows našumui
- **llama.cpp**: Kryžminės platformos inferencijos variklis

### Mokymosi ištekliai
- **Phi Portal**: Oficialus Microsoft Phi dokumentacijos centras
- **Phi Cookbook**: Išsamūs pavyzdžiai ir pamokos
- **Techninės ataskaitos**: Išsamūs moksliniai straipsniai arxiv
- **Bendruomenės erdvės**: Hugging Face interaktyvūs demonstraciniai pavyzdžiai

### Pradžia su Phi modeliais

#### Kūrimo platformos
1. **Azure AI Foundry**: Paprastas vietinis CLI ir modelių valdymas.
2. **Hugging Face Transformers**: Greitas vietinis eksperimentavimas
3. **Ollama**: Paprastas vietinis diegimas testavimui

#### Mokymosi kelias
1. **Suprasti pagrindines sąvokas**: Išstudijuoti pagrindinius dizaino principus
2. **Eksperimentuoti su variantais**: Išbandyti skirtingus Phi modelius, kad suprastumėte galimybes
3. **Praktikuoti įgyvendinimą**: Diegti modelius testavimo aplinkose
4. **Plėsti diegimą**: Palaipsniui didinti naudojimą, remiantis sėkmingais pilotais

#### Geriausios praktikos
- **Pradėkite nuo mažo**: Pradėkite nuo Phi-mini modelių pradiniam kūrimui
- **Optimizuokite užduotis**: Naudokite tinkamą pokalbių formatavimą geriausiems rezultatams
- **Stebėkite našumą**: Sekite inferencijos greitį ir tikslumo rodiklius
- **Apsvarstykite techninę įrangą**: Suderinkite modelio dydį su turimais skaičiavimo resursais

## Išvada

Microsoft Phi modelių šeima atspindi revoliucinį požiūrį į AI modelių dizainą, parodant, kad mažesni, efektyvesni modeliai gali pasiekti įspūdingų rezultatų įvairiose užduotyse. Dėmesys aukštos kokybės mokymo duomenims ir architektūrinėms optimizacijoms leidžia Phi šeimai pasiūlyti išskirtines galimybes, žymiai sumažinant skaičiavimo reikalavimus, palyginti su tradiciniais dideliais kalbos modeliais.

## Pagrindiniai mokymosi tikslai

1. Suprasti Microsoft Phi modelių šeimos dizaino filosofiją ir evoliuciją nuo Phi-1 iki Phi-4
2. Identifikuoti pagrindines inovacijas, įskaitant „vadovėlio kokybės“ mokymą ir architektūrines optimizacijas
3. Atpažinti skirtingų Phi variantų privalumus ir trūkumus įvairiose diegimo situacijose
4. Taikyti žinias, kad pasirinktumėte tinkamus Phi modelius konkretiems naudojimo atvejams ir techninės įrangos apribojimams
5. Įgyvendinti optimizavimo technikas, kad Phi modeliai būtų diegiami ribotų resursų įrenginiuose
6. Paaiškinti Phi modelių šeimos architektūrinius pranašumus, palyginti su tradiciniais dideliais kalbos modeliais
7. Pasirinkti tinkamą Phi variantą, remiantis specifiniais programos reikalavimais ir techninės įrangos apribojimais
8. Įgyvendinti Phi modelius tiek debesų, tiek kraštinių diegimo scenarijuose su optimizuotomis konfigūracijomis
9. Taikyti kvantavimo ir optimizavimo technikas, kad pagerintumėte Phi modelių našumą tiksliniuose įrenginiuose
10. Įvertinti kompromisus tarp modelio dydžio, našumo ir galimybių visoje Phi šeimoje

## Kas toliau

- [02: Qwen Family Fundamentals](02.QwenFamily.md)

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar neteisingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.