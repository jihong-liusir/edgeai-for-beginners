<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cf6b1cba2ead9fb7fdc55f77232db067",
  "translation_date": "2025-09-19T00:00:45+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "lt"
}
-->
# 3 skyrius: Praktinis įgyvendinimo vadovas

## Apžvalga

Šis išsamus vadovas padės pasiruošti EdgeAI kursui, kuris orientuotas į praktinių AI sprendimų kūrimą, efektyviai veikiančių kraštiniuose įrenginiuose. Kursas akcentuoja praktinį darbą naudojant modernias sistemas ir pažangiausius modelius, optimizuotus kraštiniam diegimui.

## 1. Kūrimo aplinkos paruošimas

### Programavimo kalbos ir sistemos

**Python aplinka**
- **Versija**: Python 3.10 ar naujesnė (rekomenduojama: Python 3.11)
- **Paketų tvarkyklė**: pip arba conda
- **Virtuali aplinka**: Naudokite venv arba conda aplinkas izoliacijai
- **Pagrindinės bibliotekos**: Kurso metu įdiegsime specifines EdgeAI bibliotekas

**Microsoft .NET aplinka**
- **Versija**: .NET 8 ar naujesnė
- **IDE**: Visual Studio 2022, Visual Studio Code arba JetBrains Rider
- **SDK**: Įsitikinkite, kad .NET SDK yra įdiegtas kryžminės platformos kūrimui

### Kūrimo įrankiai

**Kodo redaktoriai ir IDE**
- Visual Studio Code (rekomenduojama kryžminės platformos kūrimui)
- PyCharm arba Visual Studio (kalbai specifinis kūrimas)
- Jupyter Notebooks interaktyviam kūrimui ir prototipų kūrimui

**Versijų kontrolė**
- Git (naujausia versija)
- GitHub paskyra, skirta prieigai prie saugyklų ir bendradarbiavimui

## 2. Aparatinės įrangos reikalavimai ir rekomendacijos

### Minimalūs sistemos reikalavimai
- **CPU**: Daugiašerdis procesorius (Intel i5/AMD Ryzen 5 ar lygiavertis)
- **RAM**: Mažiausiai 8GB, rekomenduojama 16GB
- **Saugykla**: 50GB laisvos vietos modeliams ir kūrimo įrankiams
- **OS**: Windows 10/11, macOS 10.15+ arba Linux (Ubuntu 20.04+)

### Skaičiavimo resursų strategija
Kursas sukurtas taip, kad būtų prieinamas įvairioms aparatinės įrangos konfigūracijoms:

**Vietinis kūrimas (CPU/NPU akcentas)**
- Pagrindinis kūrimas vyks naudojant CPU ir NPU spartinimą
- Tinka daugumai modernių nešiojamųjų ir stalinių kompiuterių
- Dėmesys efektyvumui ir praktiniams diegimo scenarijams

**Debesų GPU resursai (pasirinktinai)**
- **Azure Machine Learning**: Intensyviam mokymui ir eksperimentams
- **Google Colab**: Nemokamas planas, skirtas edukaciniams tikslams
- **Kaggle Notebooks**: Alternatyvi debesų kompiuterijos platforma

### Kraštinių įrenginių aspektai
- ARM pagrindu veikiančių procesorių supratimas
- Žinios apie mobiliųjų ir IoT įrenginių apribojimus
- Susipažinimas su energijos suvartojimo optimizavimu

## 3. Pagrindinės modelių šeimos ir ištekliai

### Pagrindinės modelių šeimos

**Microsoft Phi-4 šeima**
- **Aprašymas**: Kompaktiški, efektyvūs modeliai, skirti kraštiniam diegimui
- **Stiprybės**: Puikus našumo ir dydžio santykis, optimizuoti loginėms užduotims
- **Išteklius**: [Phi-4 kolekcija Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Naudojimo atvejai**: Kodo generavimas, matematinis samprotavimas, bendras pokalbis

**Qwen-3 šeima**
- **Aprašymas**: Naujausia Alibaba daugiakalbių modelių karta
- **Stiprybės**: Stiprios daugiakalbės galimybės, efektyvi architektūra
- **Išteklius**: [Qwen-3 kolekcija Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Naudojimo atvejai**: Daugiakalbės aplikacijos, kultūriniai AI sprendimai

**Google Gemma-3n šeima**
- **Aprašymas**: Google lengvi modeliai, optimizuoti kraštiniam diegimui
- **Stiprybės**: Greitas įžvalgos, mobiliesiems pritaikyta architektūra
- **Išteklius**: [Gemma-3n kolekcija Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Naudojimo atvejai**: Mobiliosios aplikacijos, realaus laiko apdorojimas

### Modelių pasirinkimo kriterijai
- **Našumo ir dydžio kompromisai**: Supratimas, kada rinktis mažesnius ar didesnius modelius
- **Užduotims specifinė optimizacija**: Modelių pritaikymas specifiniams naudojimo atvejams
- **Diegimo apribojimai**: Atminties, vėlinimo ir energijos suvartojimo aspektai

## 4. Kvantizavimo ir optimizavimo įrankiai

### Llama.cpp sistema
- **Saugykla**: [Llama.cpp GitHub](https://github.com/ggml-org/llama.cpp)
- **Tikslas**: Aukšto našumo įžvalgos variklis LLM modeliams
- **Pagrindinės savybės**:
  - CPU optimizuota įžvalga
  - Įvairūs kvantizavimo formatai (Q4, Q5, Q8)
  - Kryžminės platformos suderinamumas
  - Atminties efektyvumas
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Saugykla**: [Microsoft Olive GitHub](https://github.com/microsoft/olive)
- **Tikslas**: Modelių optimizavimo įrankių rinkinys kraštiniam diegimui
- **Pagrindinės savybės**:
  - Automatiniai modelių optimizavimo procesai
  - Aparatinės įrangos optimizacija
  - Integracija su ONNX Runtime
  - Našumo vertinimo įrankiai
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Install Olive
  pip install olive-ai
  
  # Example Python script for model optimization
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Apibrėžkite modelį ir optimizavimo konfigūraciją
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Paleiskite optimizavimo procesą
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Išsaugokite optimizuotą modelį
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (macOS Users)
- **Repository**: [Apple MLX on GitHub](https://github.com/ml-explore/mlx)
- **Purpose**: Machine learning framework for Apple Silicon
- **Key Features**:
  - Native Apple Silicon optimization
  - Memory-efficient operations
  - PyTorch-like API
  - Unified memory architecture support
- **Installation and Basic Usage**:
  ```bash
  # Įdiekite MLX
  pip install mlx
  
  # Pavyzdinis Python scenarijus modelio įkėlimui ir optimizavimui
  ```python
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Saugykla**: [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
- **Tikslas**: Kryžminės platformos įžvalgos spartinimas ONNX modeliams
- **Pagrindinės savybės**:
  - Aparatinės įrangos optimizacijos (CPU, GPU, NPU)
  - Grafų optimizacijos įžvalgai
  - Kvantizavimo palaikymas
  - Kryžminės kalbos palaikymas (Python, C++, C#, JavaScript)
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```

## 5. Rekomenduojama literatūra ir ištekliai

### Esminė dokumentacija
- **ONNX Runtime dokumentacija**: Kryžminės platformos įžvalgos supratimas
- **Hugging Face Transformers vadovas**: Modelių įkėlimas ir įžvalga
- **Edge AI dizaino šablonai**: Geriausios praktikos kraštiniam diegimui

### Techniniai straipsniai
- "Efektyvus Edge AI: Kvantizavimo technikų apžvalga"
- "Modelių suspaudimas mobiliesiems ir kraštiniams įrenginiams"
- "Transformerių modelių optimizavimas kraštiniam kompiuteriui"

### Bendruomenės ištekliai
- **EdgeAI Slack/Discord bendruomenės**: Pagalba ir diskusijos
- **GitHub saugyklos**: Pavyzdinės implementacijos ir pamokos
- **YouTube kanalai**: Techninės analizės ir pamokos

## 6. Vertinimas ir patikrinimas

### Prieš kursą kontrolinis sąrašas
- [ ] Python 3.10+ įdiegtas ir patikrintas
- [ ] .NET 8+ įdiegtas ir patikrintas
- [ ] Kūrimo aplinka sukonfigūruota
- [ ] Hugging Face paskyra sukurta
- [ ] Pagrindinių modelių šeimų supratimas
- [ ] Kvantizavimo įrankiai įdiegti ir išbandyti
- [ ] Aparatinės įrangos reikalavimai atitikti
- [ ] Debesų kompiuterijos paskyros sukonfigūruotos (jei reikia)

## Pagrindiniai mokymosi tikslai

Pasibaigus šiam vadovui, jūs galėsite:

1. Paruošti pilną kūrimo aplinką EdgeAI aplikacijų kūrimui
2. Įdiegti ir sukonfigūruoti reikalingus įrankius ir sistemas modelių optimizavimui
3. Pasirinkti tinkamą aparatinę ir programinę įrangą savo EdgeAI projektams
4. Suprasti pagrindinius aspektus, susijusius su AI modelių diegimu kraštiniuose įrenginiuose
5. Paruošti savo sistemą praktinėms užduotims kurse

## Papildomi ištekliai

### Oficialios dokumentacijos
- **Python dokumentacija**: Oficialūs Python kalbos ištekliai
- **Microsoft .NET dokumentacija**: Oficialūs .NET kūrimo ištekliai
- **ONNX Runtime dokumentacija**: Išsamus ONNX Runtime vadovas
- **TensorFlow Lite dokumentacija**: Oficialūs TensorFlow Lite ištekliai

### Kūrimo įrankiai
- **Visual Studio Code**: Lengvas kodo redaktorius su AI kūrimo plėtiniais
- **Jupyter Notebooks**: Interaktyvi kompiuterinė aplinka ML eksperimentams
- **Docker**: Konteinerizacijos platforma nuoseklioms kūrimo aplinkoms
- **Git**: Versijų kontrolės sistema kodo valdymui

### Mokymosi ištekliai
- **EdgeAI moksliniai straipsniai**: Naujausi akademiniai tyrimai apie efektyvius modelius
- **Internetiniai kursai**: Papildomos mokymosi medžiagos apie AI optimizavimą
- **Bendruomenės forumai**: Klausimų ir atsakymų platformos EdgeAI kūrimo iššūkiams
- **Etaloniniai duomenų rinkiniai**: Standartiniai duomenų rinkiniai modelių našumo vertinimui

## Mokymosi rezultatai

Baigę šį pasiruošimo vadovą, jūs:

1. Turėsite pilnai sukonfigūruotą kūrimo aplinką EdgeAI kūrimui
2. Suprasite aparatinės ir programinės įrangos reikalavimus skirtingiems diegimo scenarijams
3. Būsite susipažinę su pagrindinėmis sistemomis ir įrankiais, naudojamais kurso metu
4. Galėsite pasirinkti tinkamus modelius pagal įrenginių apribojimus ir reikalavimus
5. Turėsite esminių žinių apie optimizavimo technikas kraštiniam diegimui

## ➡️ Kas toliau

- [04: EdgeAI aparatinė įranga ir diegimas](04.EdgeDeployment.md)

---

**Atsakomybės apribojimas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.