<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c37dfe660161e652077f6b7b23bb2167",
  "translation_date": "2025-10-11T14:50:08+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "lt"
}
-->
# 3 skyrius: Praktinis įgyvendinimo vadovas

## Apžvalga

Šis išsamus vadovas padės pasiruošti EdgeAI kursui, kuris orientuotas į praktinių AI sprendimų kūrimą, efektyviai veikiančių kraštiniuose įrenginiuose. Kursas akcentuoja praktinį darbą naudojant modernias sistemas ir pažangiausius modelius, optimizuotus kraštiniam diegimui.

## 1. Kūrimo aplinkos paruošimas

### Programavimo kalbos ir sistemos

**Python aplinka**
- **Versija**: Python 3.10 ar naujesnė (rekomenduojama: Python 3.11)
- **Paketų tvarkyklė**: pip arba conda
- **Virtuali aplinka**: Naudokite venv arba conda aplinkas izoliacijai
- **Pagrindinės bibliotekos**: Kurso metu įdiegsime specifines EdgeAI bibliotekas

**Microsoft .NET aplinka**
- **Versija**: .NET 8 ar naujesnė
- **IDE**: Visual Studio 2022, Visual Studio Code arba JetBrains Rider
- **SDK**: Įsitikinkite, kad .NET SDK yra įdiegtas kryžminės platformos kūrimui

### Kūrimo įrankiai

**Kodo redaktoriai ir IDE**
- Visual Studio Code (rekomenduojama kryžminės platformos kūrimui)
- PyCharm arba Visual Studio (specifiniam kalbos kūrimui)
- Jupyter Notebooks interaktyviam kūrimui ir prototipų kūrimui

**Versijų kontrolė**
- Git (naujausia versija)
- GitHub paskyra, skirta prieigai prie saugyklų ir bendradarbiavimui

## 2. Aparatinės įrangos reikalavimai ir rekomendacijos

### Minimalūs sistemos reikalavimai
- **CPU**: Daugiašerdis procesorius (Intel i5/AMD Ryzen 5 ar lygiavertis)
- **RAM**: Mažiausiai 8GB, rekomenduojama 16GB
- **Saugykla**: 50GB laisvos vietos modeliams ir kūrimo įrankiams
- **OS**: Windows 10/11, macOS 10.15+ arba Linux (Ubuntu 20.04+)

### Skaičiavimo išteklių strategija
Kursas pritaikytas įvairioms aparatinės įrangos konfigūracijoms:

**Vietinis kūrimas (CPU/NPU akcentas)**
- Pagrindinis kūrimas vyks naudojant CPU ir NPU spartinimą
- Tinka daugumai modernių nešiojamųjų ir stalinių kompiuterių
- Dėmesys efektyvumui ir praktiniams diegimo scenarijams

**Debesų GPU ištekliai (pasirinktinai)**
- **Azure Machine Learning**: Intensyviam mokymui ir eksperimentavimui
- **Google Colab**: Nemokamas planas edukaciniais tikslais
- **Kaggle Notebooks**: Alternatyvi debesų kompiuterijos platforma

### Kraštinių įrenginių aspektai
- ARM pagrindu veikiančių procesorių supratimas
- Žinios apie mobiliųjų ir IoT įrenginių apribojimus
- Susipažinimas su energijos suvartojimo optimizavimu

## 3. Pagrindinės modelių šeimos ir ištekliai

### Pagrindinės modelių šeimos

**Microsoft Phi-4 šeima**
- **Aprašymas**: Kompaktiški, efektyvūs modeliai, skirti kraštiniam diegimui
- **Stiprybės**: Puikus našumo ir dydžio santykis, optimizuoti loginėms užduotims
- **Išteklius**: [Phi-4 kolekcija Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Naudojimo atvejai**: Kodo generavimas, matematinis samprotavimas, bendras pokalbis

**Qwen-3 šeima**
- **Aprašymas**: Naujausia Alibaba daugiakalbių modelių karta
- **Stiprybės**: Stiprios daugiakalbės galimybės, efektyvi architektūra
- **Išteklius**: [Qwen-3 kolekcija Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Naudojimo atvejai**: Daugiakalbės programos, tarpkultūriniai AI sprendimai

**Google Gemma-3n šeima**
- **Aprašymas**: Google lengvi modeliai, optimizuoti kraštiniam diegimui
- **Stiprybės**: Greitas išvedimas, draugiška mobiliesiems architektūra
- **Išteklius**: [Gemma-3n kolekcija Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Naudojimo atvejai**: Mobiliosios programos, realaus laiko apdorojimas

### Modelių pasirinkimo kriterijai
- **Našumo ir dydžio kompromisai**: Supratimas, kada rinktis mažesnius ar didesnius modelius
- **Užduoties specifinė optimizacija**: Modelių pritaikymas specifiniams naudojimo atvejams
- **Diegimo apribojimai**: Atminties, vėlinimo ir energijos suvartojimo aspektai

## 4. Kvantizavimo ir optimizavimo įrankiai

### Llama.cpp sistema
- **Saugykla**: [Llama.cpp GitHub](https://github.com/ggml-org/llama.cpp)
- **Tikslas**: Didelio našumo išvedimo variklis LLM modeliams
- **Pagrindinės savybės**:
  - CPU optimizuotas išvedimas
  - Įvairūs kvantizavimo formatai (Q4, Q5, Q8)
  - Kryžminės platformos suderinamumas
  - Atminties efektyvumas
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Saugykla**: [Microsoft Olive GitHub](https://github.com/microsoft/olive)
- **Tikslas**: Modelių optimizavimo įrankių rinkinys kraštiniam diegimui
- **Pagrindinės savybės**:
  - Automatiniai modelių optimizavimo procesai
  - Aparatinės įrangos optimizacija
  - Integracija su ONNX Runtime
  - Našumo vertinimo įrankiai
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Install Olive
  pip install olive-ai
  ```
  
  # Pavyzdinis Python scenarijus modelio optimizavimui
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (macOS vartotojams)
- **Saugykla**: [Apple MLX GitHub](https://github.com/ml-explore/mlx)
- **Tikslas**: Mašininio mokymosi sistema Apple Silicon įrenginiams
- **Pagrindinės savybės**:
  - Natūrali Apple Silicon optimizacija
  - Atminties efektyvios operacijos
  - PyTorch panaši API
  - Vieningos atminties architektūros palaikymas
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Install MLX
  pip install mlx
  ```
  
  ```python
  # Example Python script for loading and optimizing a model
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Saugykla**: [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
- **Tikslas**: Kryžminės platformos išvedimo spartinimas ONNX modeliams
- **Pagrindinės savybės**:
  - Aparatinės įrangos specifinės optimizacijos (CPU, GPU, NPU)
  - Grafų optimizacijos išvedimui
  - Kvantizavimo palaikymas
  - Kryžminės kalbos palaikymas (Python, C++, C#, JavaScript)
- **Įdiegimas ir pagrindinis naudojimas**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. Rekomenduojama literatūra ir ištekliai

### Esminė dokumentacija
- **ONNX Runtime dokumentacija**: Kryžminės platformos išvedimo supratimas
- **Hugging Face Transformers vadovas**: Modelių įkėlimas ir išvedimas
- **Edge AI dizaino šablonai**: Geriausios praktikos kraštiniam diegimui

### Techniniai straipsniai
- "Efektyvus Edge AI: Kvantizavimo technikų apžvalga"
- "Modelių suspaudimas mobiliesiems ir kraštiniams įrenginiams"
- "Transformerių modelių optimizavimas kraštiniam kompiuteriui"

### Bendruomenės ištekliai
- **EdgeAI Slack/Discord bendruomenės**: Pagalba ir diskusijos su kolegomis
- **GitHub saugyklos**: Pavyzdiniai įgyvendinimai ir pamokos
- **YouTube kanalai**: Techninės analizės ir pamokos

## 6. Vertinimas ir patikrinimas

### Prieš kurso kontrolinis sąrašas
- [ ] Įdiegta ir patikrinta Python 3.10+
- [ ] Įdiegta ir patikrinta .NET 8+
- [ ] Suformuota kūrimo aplinka
- [ ] Sukurta Hugging Face paskyra
- [ ] Pagrindinių modelių šeimų susipažinimas
- [ ] Įdiegti ir išbandyti kvantizavimo įrankiai
- [ ] Atitinka aparatinės įrangos reikalavimus
- [ ] Sukurtos debesų kompiuterijos paskyros (jei reikia)

## Pagrindiniai mokymosi tikslai

Pasibaigus šiam vadovui, jūs galėsite:

1. Paruošti pilną kūrimo aplinką EdgeAI programų kūrimui
2. Įdiegti ir sukonfigūruoti reikalingus įrankius ir sistemas modelių optimizavimui
3. Pasirinkti tinkamas aparatinės ir programinės įrangos konfigūracijas savo EdgeAI projektams
4. Suprasti pagrindinius aspektus, susijusius su AI modelių diegimu kraštiniuose įrenginiuose
5. Paruošti savo sistemą praktinėms kurso užduotims

## Papildomi ištekliai

### Oficialios dokumentacijos
- **Python dokumentacija**: Oficialus Python kalbos dokumentas
- **Microsoft .NET dokumentacija**: Oficialūs .NET kūrimo ištekliai
- **ONNX Runtime dokumentacija**: Išsamus ONNX Runtime vadovas
- **TensorFlow Lite dokumentacija**: Oficialus TensorFlow Lite dokumentas

### Kūrimo įrankiai
- **Visual Studio Code**: Lengvas kodo redaktorius su AI kūrimo plėtiniais
- **Jupyter Notebooks**: Interaktyvi skaičiavimo aplinka ML eksperimentams
- **Docker**: Konteinerizacijos platforma nuoseklioms kūrimo aplinkoms
- **Git**: Versijų kontrolės sistema kodo valdymui

### Mokymosi ištekliai
- **EdgeAI moksliniai straipsniai**: Naujausi akademiniai tyrimai apie efektyvius modelius
- **Internetiniai kursai**: Papildomos mokymosi medžiagos apie AI optimizavimą
- **Bendruomenės forumai**: Klausimų ir atsakymų platformos EdgeAI kūrimo iššūkiams
- **Etaloniniai duomenų rinkiniai**: Standartiniai duomenų rinkiniai modelių našumo vertinimui

## Mokymosi rezultatai

Baigę šį pasiruošimo vadovą, jūs:

1. Turėsite pilnai sukonfigūruotą kūrimo aplinką EdgeAI kūrimui
2. Suprasite aparatinės ir programinės įrangos reikalavimus skirtingiems diegimo scenarijams
3. Būsite susipažinę su pagrindinėmis sistemomis ir įrankiais, naudojamais kurso metu
4. Galėsite pasirinkti tinkamus modelius pagal įrenginių apribojimus ir reikalavimus
5. Turėsite esminių žinių apie optimizavimo technikas kraštiniam diegimui

## ➡️ Kas toliau

- [04: EdgeAI aparatinė įranga ir diegimas](04.EdgeDeployment.md)

---

**Atsakomybės atsisakymas**:  
Šis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar neteisingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.