<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T14:50:21+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "fa"
}
-->
# بخش ۱: اصول اولیه خانواده مدل‌های Microsoft Phi

خانواده مدل‌های Microsoft Phi نشان‌دهنده یک تغییر بنیادین در هوش مصنوعی است که نشان می‌دهد مدل‌های کوچک و کارآمد می‌توانند عملکرد چشمگیری داشته باشند، در حالی که به طور قابل توجهی منابع کمتری نسبت به مدل‌های زبان بزرگ سنتی مصرف می‌کنند. مهم است که درک کنیم چگونه خانواده Phi قابلیت‌های قدرتمند هوش مصنوعی را با کاهش نیازهای محاسباتی فراهم می‌کند و در عین حال عملکرد بالایی در وظایف مختلف حفظ می‌کند.

## منابع برای توسعه‌دهندگان

### کاتالوگ مدل Azure AI Foundry
مدل‌های خانواده Phi (به جز Phi-silica) از طریق [کاتالوگ مدل Azure AI Foundry](https://ai.azure.com/explore/models?q=phi) در دسترس هستند، که دسترسی، تنظیم دقیق و استقرار این مدل‌ها را در برنامه‌های شما آسان می‌کند. این کاتالوگ راهی ساده برای آزمایش انواع مختلف Phi و ادغام آنها در پروژه‌های شما فراهم می‌کند.

### Azure AI Foundry
شما می‌توانید مدل‌های Phi را با استفاده از [Azure AI Foundry](https://ai.azure.com) مستقر کرده و آزمایش کنید، که محیطی جامع برای ساخت، آزمایش و استقرار راه‌حل‌های هوش مصنوعی با حداقل تنظیمات فراهم می‌کند.

### Foundry Local
برای توسعه و استقرار محلی، [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) را بررسی کنید که به شما امکان می‌دهد مدل‌های Phi را با تنظیمات بهینه روی ماشین توسعه خود اجرا کنید.

### منابع مستندات
- [تحقیقات مایکروسافت: گزارش‌های فنی مدل Phi](https://ai.azure.com/labs/projects/phi-4)
- [کتاب آشپزی Phi](https://aka.ms/phicookbook)

## مقدمه

در این درس، ما خانواده مدل‌های Phi مایکروسافت و مفاهیم اساسی آن را بررسی خواهیم کرد. ما به تکامل خانواده Phi، روش‌های نوآورانه آموزشی که مدل‌های Phi را کارآمد می‌سازند، انواع کلیدی در این خانواده و کاربردهای عملی در سناریوهای مختلف خواهیم پرداخت.

## اهداف یادگیری

تا پایان این درس، شما قادر خواهید بود:

- فلسفه طراحی و تکامل خانواده مدل‌های Phi مایکروسافت را درک کنید.
- نوآوری‌های کلیدی که به مدل‌های Phi امکان دستیابی به عملکرد بالا با پارامترهای کمتر را می‌دهند، شناسایی کنید.
- مزایا و محدودیت‌های انواع مختلف مدل‌های Phi را بشناسید.
- دانش مدل‌های Phi را برای انتخاب انواع مناسب در سناریوهای واقعی به کار ببرید.

## درک پارادایم سنتی مدل‌های هوش مصنوعی

به طور سنتی، دستیابی به عملکرد بالا در پردازش زبان طبیعی نیازمند مدل‌های زبان عظیم با میلیاردها یا صدها میلیارد پارامتر بود. سازمان‌ها معمولاً این مدل‌ها را روی خوشه‌های قدرتمند GPU مستقر می‌کنند و از طریق رابط‌های API یا زیرساخت‌های سخت‌افزاری تخصصی به قابلیت‌های آنها دسترسی پیدا می‌کنند.

این روش برای بسیاری از کاربردها خوب عمل می‌کند اما محدودیت‌های ذاتی در سناریوهای استقرار عملی دارد. روش معمول شامل استفاده از مدل‌هایی است که به منابع محاسباتی قابل توجه، حافظه زیاد و مصرف انرژی بالا نیاز دارند. در حالی که این روش دسترسی به قابلیت‌های پیشرفته را فراهم می‌کند، وابستگی به سخت‌افزار گران‌قیمت ایجاد می‌کند، هزینه‌های عملیاتی بالا را معرفی می‌کند و انعطاف‌پذیری استقرار را محدود می‌کند.

## چالش استقرار کارآمد هوش مصنوعی

نیاز به هوش مصنوعی کارآمدتر در سناریوهای مختلف به طور فزاینده‌ای مهم شده است. به کاربردهایی فکر کنید که نیاز به استقرار محلی برای دلایل حفظ حریم خصوصی دارند، پیاده‌سازی‌های حساس به هزینه که هزینه‌های API ابری غیرقابل تحمل می‌شوند، سناریوهای محاسبات لبه با منابع سخت‌افزاری محدود، یا کاربردهای بلادرنگ که حساسیت به تأخیر دارند.

### محدودیت‌های کلیدی استقرار

استقرار مدل‌های بزرگ سنتی با چندین محدودیت اساسی مواجه است که کاربرد عملی آنها را محدود می‌کند:

- **محدودیت‌های هزینه**: هزینه‌های محاسباتی بالا استقرار مداوم را برای بسیاری از سازمان‌ها گران می‌کند.
- **محدودیت‌های منابع**: دسترسی محدود به زیرساخت GPU پیشرفته گزینه‌های استقرار را محدود می‌کند.
- **نیازهای حفظ حریم خصوصی**: کاربردهای حساس نیاز به پردازش محلی دارند تا حریم خصوصی داده‌ها حفظ شود.
- **حساسیت به تأخیر**: کاربردهای بلادرنگ به پاسخ‌های فوری نیاز دارند بدون تأخیر ناشی از رفت و برگشت به ابر.

## فلسفه مدل Microsoft Phi

خانواده مدل‌های Microsoft Phi نشان‌دهنده یک تغییر بنیادین در فلسفه طراحی مدل‌های هوش مصنوعی است که کارایی و استقرار عملی را در اولویت قرار می‌دهد و در عین حال ویژگی‌های عملکرد قوی را حفظ می‌کند. مدل‌های Phi این هدف را از طریق معماری‌های نوآورانه، روش‌های آموزشی با کیفیت بالا و تکنیک‌های بهینه‌سازی تخصصی به دست می‌آورند.

خانواده Phi شامل رویکردهای مختلفی است که برای به حداکثر رساندن عملکرد به ازای هر پارامتر طراحی شده‌اند، امکان استقرار روی سخت‌افزار استاندارد را فراهم می‌کنند و در عین حال قابلیت‌های معنادار هوش مصنوعی ارائه می‌دهند. هدف حفظ عملکرد رقابتی در حالی است که نیازهای محاسباتی، استفاده از حافظه و هزینه‌های عملیاتی به طور چشمگیری کاهش می‌یابد.

### اصول طراحی اصلی Phi

مدل‌های Phi بر اساس چندین اصل بنیادی ساخته شده‌اند که آنها را از مدل‌های زبان بزرگ سنتی متمایز می‌کند:

- **اولویت کارایی**: بهینه‌سازی برای حداکثر عملکرد به ازای هر پارامتر به جای مقیاس مطلق.
- **آموزش با کیفیت**: تمرکز بر داده‌های آموزشی با کیفیت بالا و گزینش شده به جای مجموعه داده‌های عظیم.
- **انعطاف‌پذیری استقرار**: طراحی شده برای اجرا به طور مؤثر روی پیکربندی‌های سخت‌افزاری مختلف.
- **قابلیت‌های تخصصی**: اغلب برای وظایف یا حوزه‌های خاص بهینه‌سازی شده‌اند تا اثربخشی را به حداکثر برسانند.

## فناوری‌های کلیدی که خانواده Phi را ممکن می‌سازند

### روش آموزشی "کتاب درسی"

یکی از جنبه‌های انقلابی خانواده Phi روش آموزشی "کیفیت کتاب درسی" است. به جای آموزش بر روی مقادیر عظیم داده‌های اینترنتی بدون فیلتر، مدل‌های Phi از محتوای آموزشی گزینش شده و با کیفیت بالا استفاده می‌کنند که برای آموزش استدلال، ریاضیات، کدنویسی و دانش عمومی به طور مؤثر طراحی شده است.

این روش با ایجاد محتوای آموزشی مصنوعی که شبیه کتاب‌های درسی با کیفیت بالا و مواد آکادمیک است، کار می‌کند. داده‌های آموزشی به طور خاص طراحی شده‌اند تا از نظر آموزشی صحیح باشند، با تمرکز بر توضیحات واضح، استدلال گام به گام و ارائه دانش ساختاریافته.

### آموزش استدلال پیشرفته

مدل‌های اخیر Phi روش‌های آموزشی استدلال پیشرفته‌ای را شامل می‌شوند که امکان حل مسائل پیچیده چندمرحله‌ای را فراهم می‌کنند. این تکنیک‌ها شامل موارد زیر هستند:

**آموزش زنجیره‌ای تفکر**: مدل‌ها یاد می‌گیرند مسائل پیچیده را به مراحل استدلال میانی تقسیم کنند، که فرآیند حل مسئله آنها را شفاف‌تر و قابل اعتمادتر می‌کند.

**مقیاس‌بندی در زمان استنتاج**: مدل‌ها زنجیره‌های استدلال دقیق تولید می‌کنند که در طول تولید پاسخ از منابع محاسباتی اضافی برای دقت بهتر استفاده می‌کنند.

**آموزش در مرز قابلیت‌ها**: داده‌های آموزشی به طور خاص انتخاب می‌شوند تا مدل را در مرز قابلیت‌های فعلی خود به چالش بکشند و الگوهای استدلال پیچیده را یاد بگیرند.

### نوآوری‌های معماری

خانواده Phi شامل چندین بهینه‌سازی معماری است که به طور خاص برای کارایی طراحی شده‌اند:

**کارایی پارامتر**: انتخاب‌های معماری دقیق که تأثیر هر پارامتر در مدل را به حداکثر می‌رسانند.

**ادغام چندوجهی**: ادغام کارآمد قابلیت‌های پردازش متن، تصویر و گفتار در معماری‌های فشرده.

**بهینه‌سازی سخت‌افزار**: انواع تخصصی بهینه‌سازی شده برای پلتفرم‌های سخت‌افزاری خاص و سناریوهای استقرار.

## بهینه‌سازی سخت‌افزار برای مدل‌های Phi

محیط‌های استقرار مدرن از کارایی مدل‌های Phi در پیکربندی‌های سخت‌افزاری مختلف بهره‌مند می‌شوند:

### استقرار بهینه‌سازی شده برای CPU

مدل‌های Phi برای اجرا به طور مؤثر روی سخت‌افزار فقط CPU طراحی شده‌اند، که امکان استقرار روی زیرساخت محاسباتی استاندارد را بدون نیاز به شتاب‌دهنده‌های تخصصی هوش مصنوعی فراهم می‌کند.

### شتاب GPU

در حالی که نیاز به GPU‌های قدرتمند ندارند، مدل‌های Phi می‌توانند از منابع GPU موجود برای عملکرد بهتر استفاده کنند و انعطاف‌پذیری در پیکربندی‌های استقرار فراهم کنند.

### ادغام دستگاه‌های لبه

انواع تخصصی مانند Phi-3-Silica برای پلتفرم‌های محاسبات لبه خاص بهینه‌سازی شده‌اند و به معیارهای کارایی قابل توجهی مانند ۶۵۰ توکن در ثانیه با تنها ۱.۵ وات مصرف انرژی دست می‌یابند.

## مزایای خانواده مدل‌های Phi

### کارایی هزینه

مدل‌های Phi هزینه‌های عملیاتی را به طور چشمگیری کاهش می‌دهند زیرا به زیرساخت محاسباتی بسیار کمتری نیاز دارند و در عین حال عملکرد رقابتی را حفظ می‌کنند. این امر هوش مصنوعی را برای سازمان‌هایی با بودجه محدود یا کاربردهای حجیم که هزینه به ازای هر استنتاج اهمیت دارد، قابل دسترس می‌کند.

### انعطاف‌پذیری استقرار

کارایی مدل‌های Phi امکان استقرار در طیف گسترده‌ای از پیکربندی‌های سخت‌افزاری، از لپ‌تاپ‌های شخصی تا سرورهای سازمانی، را فراهم می‌کند و به سازمان‌ها انعطاف‌پذیری بیشتری در انتخاب زیرساخت هوش مصنوعی خود می‌دهد.

### حفظ حریم خصوصی و امنیت

کارایی مدل‌های Phi امکان استقرار محلی برای کاربردهای حساس به حریم خصوصی را فراهم می‌کند، که اطمینان می‌دهد داده‌های حساس هرگز از کنترل سازمان خارج نمی‌شوند و در عین حال قابلیت‌های قدرتمند هوش مصنوعی ارائه می‌دهند.

### عملکرد بلادرنگ

نیازهای محاسباتی کاهش‌یافته به زمان‌های استنتاج سریع‌تر ترجمه می‌شود، که امکان کاربردهای بلادرنگ را فراهم می‌کند که به پاسخ‌های فوری نیاز دارند بدون اینکه کیفیت قابلیت‌های هوش مصنوعی به خطر بیفتد.

### هوش مصنوعی قابل دسترس

با کاهش موانع استقرار هوش مصنوعی، مدل‌های Phi قابلیت‌های پیشرفته هوش مصنوعی را برای سازمان‌هایی با منابع محدود قابل دسترس می‌کنند و به تیم‌های کوچک‌تر و توسعه‌دهندگان فردی امکان استفاده از درک زبان پیچیده را می‌دهند.

## مثال‌ها و کاربردهای عملی

### مثال استدلال ریاضی

Phi-4-mini-reasoning در حل مسائل ریاضی گام به گام عالی عمل می‌کند. برای مثال، وقتی پرسیده می‌شود "چگونه ۳*x^۲+۴*x+۵=۱ را حل کنیم؟"، مدل مراحل استدلال دقیق ارائه می‌دهد:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### مثال پشتیبانی چندزبانه

Phi-3.5-mini-instruct قابلیت‌های چندزبانه قوی در زبان‌های مختلف نشان می‌دهد. اینجا یک قالب نمونه درخواست آورده شده است:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### مثال قابلیت‌های چندوجهی

Phi-4-multimodal می‌تواند متن، تصاویر و گفتار را به طور همزمان پردازش کند. در اینجا برخی کاربردهای عملی آورده شده است:

**برنامه‌ریزی سفر با ورودی صوتی:**
مشاهده کنید که چگونه Phi-4 Multimodal زبان گفتاری را تحلیل می‌کند تا به برنامه‌ریزی سفر به سیاتل کمک کند و قابلیت‌های پیشرفته پردازش صوتی و توصیه‌های خود را نشان دهد.

**حل مسائل ریاضی از تصاویر:**
ببینید که چگونه Phi-4 Multimodal مسائل ریاضی پیچیده را از طریق ورودی‌های تصویری حل می‌کند و توانایی آن در پردازش و حل معادلات ارائه شده در تصاویر را نشان می‌دهد.

**مثال فراخوانی تابع:**
با فراخوانی تابع، Phi-4-mini و Phi-4-multimodal می‌توانند قابلیت‌های پردازش متن خود را با موتورهای جستجو، اتصال ابزارهای مختلف و موارد دیگر گسترش دهند. همانطور که نشان داده شده است، مدل می‌تواند اطلاعات مسابقات لیگ برتر را از طریق Phi-4-mini بازیابی کند و توانایی آن در تعامل یکپارچه با منابع داده خارجی را نشان دهد.

### مثال تولید کد

Phi-4-multimodal می‌تواند کد پروژه ساختاریافته را بر اساس محتوای تصویری و درخواست‌های ارائه شده تولید کند، همانطور که در این جریان کاری عملی نشان داده شده است:

۱. آپلود یک تصویر از یک وایرفریم یا طراحی
۲. ارائه زمینه درباره نیازهای پروژه
۳. مدل ساختارهای کد کامل و کاربردی تولید می‌کند
۴. کد می‌تواند بر اساس چارچوب‌ها یا زبان‌های خاص سفارشی شود

### مثال استقرار لبه

ما می‌توانیم مدل کم‌حجم شده را روی دستگاه‌های لبه مستقر کنیم. با ترکیب Microsoft Olive و ONNX GenAI Runtime، می‌توانیم Phi-4-mini را روی ویندوز، آیفون، اندروید و سایر دستگاه‌ها مستقر کنیم. این یک مثال اجرا شده روی آیفون ۱۲ پرو است.

فرآیند استقرار شامل موارد زیر است:
- کم‌حجم‌سازی مدل برای بهینه‌سازی موبایل
- ادغام زمان اجرا ONNX برای سازگاری بین پلتفرم‌ها
- استنتاج محلی بدون اتصال به اینترنت
- عملکرد بلادرنگ با مصرف انرژی حداقلی

## تکامل خانواده Phi

### Phi-1 و Phi-2: مدل‌های پایه

مدل‌های اولیه Phi اصول بنیادی داده‌های آموزشی با کیفیت بالا و معماری‌های کارآمد را ایجاد کردند:

- **Phi-1 (1.3B پارامتر)**: مفهوم داده‌های آموزشی گزینش شده برای درک زبان پایه و تولید کد را معرفی کرد.
- **Phi-2 (2.7B پارامتر)**: قابلیت‌های استدلال را از طریق داده‌های مصنوعی NLP و محتوای وب به دقت فیلتر شده افزایش داد.

### خانواده Phi-3: پذیرش گسترده

سری Phi-3 یک پیشرفت در قابلیت‌های SLM با چندین انواع تخصصی بود:

- **Phi-3-mini (3.8B پارامتر)**: وظایف عمومی زبان با کارایی استثنایی، عملکرد بهتر از مدل‌هایی با دو برابر اندازه.
- **Phi-3-small (7B پارامتر)**: عملکرد پیشرفته که GPT-3.5 Turbo را در معیارهای مختلف شکست می‌دهد.
- **Phi-3-medium (14B پارامتر)**: عملکرد در سطح سازمانی که Gemini 1.0 Pro را شکست می‌دهد.
- **Phi-3-vision (4.2B پارامتر)**: قابلیت‌های چندوجهی برای پردازش تصویر و متن.
- **Phi-3-Silica (3.3B پارامتر)**: بهینه‌سازی تخصصی برای استقرار داخلی در ویندوز ۱۱.

### خانواده Phi-4: استدلال پیشرفته

نسل جدید مرزهای قابلیت‌های استدلال را گسترش می‌دهد:

- **Phi-4 (14B پارامتر)**: تخصص در استدلال پیچیده، به ویژه در ریاضیات.
- **Phi-4-mini (3.8B پارامتر)**: استدلال پیشرفته با فراخوانی تابع و پشتیبانی از زمینه طولانی.
- **Phi-4-multimodal**: قابلیت‌های پردازش همزمان گفتار، تصویر و متن.
- **Phi-4-reasoning (14B پارامتر)**: تخصص در وظایف استدلال چندمرحله‌ای پیچیده.
- **Phi-4-reasoning-plus (14B پارامتر)**: دقت افزایش یافته از طریق یادگیری تقویتی اضافی.
- **Phi-4-mini-reasoning (3.8B پارامتر)**: استدلال ریاضی بهینه‌سازی شده برای محیط‌های محدود.

## کاربردهای مدل‌های Phi

### کاربردهای سازمانی

سازمان‌ها از مدل‌های Phi برای تحلیل اسناد، خودکارسازی خدمات مشتری، کمک به تولید کد و کاربردهای هوش تجاری که نیاز به استقرار محلی برای رعایت قوانین و امنیت دارند، استفاده می‌کنند.

### محاسبات موبایل و لبه

برنامه‌های موبایل از مدل‌های Phi برای ترجمه بلادرنگ، دستیارهای هوشمند، تولید محتوا و توصیه‌های شخصی‌سازی شده بدون نیاز به اتصال دائمی به اینترنت استفاده می‌کنند.

### فناوری آموزشی

پلتفرم‌های آموزشی از مدل‌های Phi برای تدریس شخصی‌سازی شده، درجه‌بندی خودکار، تولید محتوا و تجربیات یادگیری تعاملی که می‌توانند به صورت آفلاین یا در محیط‌های با اتصال کم کار کنند، استفاده می‌کنند.

### مراقبت‌های بهداشتی و رعایت قوانین

کاربردهای مراقبت‌های بهداشتی از توانایی مدل‌های Phi در پردازش داده‌های پزشکی حساس به صورت محلی بهره‌مند می‌شوند، در حالی که کمک‌های تشخیصی مبتنی بر هوش مصنوعی، نظارت بر بیماران و توصیه‌های درمانی ارائه می‌دهند.

## چالش‌ها و محدودیت‌ها

### محدودیت‌های دانش

در حالی که کارآمد هستند، مدل‌های Phi ظرفیت دانش واقعی کمتری نسبت به مدل‌های بزرگ‌تر دارند، که ممکن است اثربخشی آنها را در کاربردهای دانش
خانواده Phi نشان می‌دهد که آینده استقرار هوش مصنوعی تنها در ساخت مدل‌های بزرگ‌تر نیست، بلکه در ساخت مدل‌های هوشمندتر و کارآمدتر است که بتوانند در محیط‌های سخت‌افزاری متنوع به طور مؤثر عمل کنند و استانداردهای عملکرد بالا را حفظ کنند.

## نمونه‌های توسعه و یکپارچه‌سازی

### شروع سریع با Transformers

در اینجا نحوه شروع کار با مدل‌های Phi با استفاده از کتابخانه Hugging Face Transformers آورده شده است:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### مثال تنظیم دقیق

مثال زیر نشان می‌دهد که چگونه می‌توان Phi-4-mini-instruct را برای وظایف خاص تنظیم دقیق کرد:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### قالب‌های تخصصی برای درخواست‌ها

**برای وظایف استدلالی (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**برای وظایف ریاضی (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### استقرار موبایل با ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## معیارهای عملکرد و دستاوردها

خانواده مدل Phi عملکرد قابل توجهی در معیارهای مختلف به دست آورده است و اغلب از مدل‌های بسیار بزرگ‌تر پیشی می‌گیرد:

### نکات برجسته عملکرد

**برتری در استدلال ریاضی:**
- Phi-4 به دقت 82.5٪ در AIME 2025 (مقدماتی المپیاد ریاضی) دست یافته است
- Phi-4-reasoning (14B) در معیارهای استدلالی از DeepSeek-R1-Distill-70B (5 برابر بزرگ‌تر) پیشی گرفته است
- Phi-4-mini-reasoning (3.8B) با مدل‌هایی که دو برابر اندازه آن هستند در وظایف استدلال ریاضی رقابت می‌کند

**دستاوردهای کارایی:**
- Phi-3-Silica با مصرف تنها 1.5 وات، 650 توکن در ثانیه پردازش می‌کند
- Phi-4-mini (3.8B) عملکرد مشابهی با مدل‌های بسیار بزرگ‌تر دارد

**عملکرد معیارها:**
- **MMLU (درک زبان چندوظیفه‌ای گسترده)**: عملکرد رقابتی در 57 موضوع علمی
- **HumanEval**: قابلیت‌های قوی تولید کد، به ویژه در پایتون
- **MGSM**: حل مسائل ریاضی در سطح مدرسه به صورت چندزبانه
- **DROP**: وظایف پیچیده درک و استدلال
- **SimpleQA**: دقت در پاسخ‌های واقعی

### 📊 ماتریس مقایسه مدل‌ها

| مدل | پارامترها | طول زمینه | نقاط قوت کلیدی | بهترین موارد استفاده |
|-----|-----------|-----------|----------------|-----------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | کارایی عمومی | اپلیکیشن‌های موبایل، چت‌بات‌های ساده |
| **Phi-3.5-mini** | 3.8B | 128K | پشتیبانی چندزبانه | کاربردهای بین‌المللی |
| **Phi-4-mini** | 3.8B | 128K | استدلال پیشرفته، فراخوانی توابع | اتوماسیون کسب‌وکار |
| **Phi-4-mini-reasoning** | 3.8B | 128K | استدلال ریاضی | پلتفرم‌های آموزشی |
| **Phi-4** | 14B | 32K | استدلال پیچیده | تحقیق، تحلیل پیشرفته |
| **Phi-4-reasoning** | 14B | 32K/64K | استدلال چندمرحله‌ای | محاسبات علمی |
| **Phi-4-reasoning-plus** | 14B | 32K | دقت حداکثری در استدلال | تصمیم‌گیری‌های حیاتی |
| **Phi-4-multimodal** | 5.6B | متغیر | گفتار، تصویر، متن | کاربردهای چندرسانه‌ای |

## راهنمای انتخاب مدل

### برای کاربردهای پایه
- **Phi-3-mini**: تولید متن ساده، پرسش و پاسخ پایه، پاسخ‌های سریع
- **Phi-4-mini**: استدلال پیشرفته با قابلیت فراخوانی توابع

### برای وظایف ریاضی و استدلالی
- **Phi-4**: حل مسائل ریاضی پیچیده و استدلال
- **Phi-4-reasoning**: استدلال چندمرحله‌ای با توضیحات دقیق
- **Phi-4-reasoning-plus**: دقت حداکثری برای کاربردهای استدلالی حیاتی
- **Phi-4-mini-reasoning**: استدلال ریاضی کارآمد برای محیط‌های با منابع محدود

### برای کاربردهای چندرسانه‌ای
- **Phi-3-vision**: ترکیب پردازش تصویر و متن
- **Phi-4-multimodal**: قابلیت‌های جامع گفتار، تصویر و متن

### برای استقرار سازمانی
- **Phi-3-medium**: درک زبان پیشرفته برای کاربردهای کسب‌وکار
- **Phi-3-Silica**: بهینه‌سازی شده برای پلتفرم‌های سخت‌افزاری خاص

## پلتفرم‌های استقرار و دسترسی

### پلتفرم‌های ابری
- **Azure AI Foundry**: استقرار کامل با ابزارهای سازمانی
- **Hugging Face**: مخزن مدل‌های متن‌باز و منابع جامعه
- **NVIDIA API Catalog**: گزینه‌های استقرار میکروسرویس

### چارچوب‌های توسعه محلی
- **Ollama**: چارچوب سبک برای استقرار مدل‌های محلی
- **ONNX Runtime**: بهینه‌سازی شده برای پیکربندی‌های سخت‌افزاری مختلف  
- **DirectML**: عملکرد بهینه برای ویندوز
- **llama.cpp**: موتور استنتاج چندپلتفرمی

### منابع آموزشی
- **Phi Portal**: مرکز مستندات رسمی Microsoft Phi
- **Phi Cookbook**: مثال‌ها و آموزش‌های جامع
- **گزارش‌های فنی**: مقالات تحقیقاتی عمیق در arxiv
- **فضاهای جامعه**: دموهای تعاملی Hugging Face

### شروع کار با مدل‌های Phi

#### پلتفرم‌های توسعه
1. **Azure AI Foundry**: CLI محلی ساده و مدیریت مدل.
2. **Hugging Face Transformers**: آزمایش سریع محلی
3. **Ollama**: استقرار محلی ساده برای آزمایش

#### مسیر یادگیری
1. **درک مفاهیم اصلی**: اصول طراحی بنیادی را مطالعه کنید
2. **آزمایش با انواع مختلف**: مدل‌های مختلف Phi را امتحان کنید تا قابلیت‌ها را درک کنید
3. **تمرین پیاده‌سازی**: مدل‌ها را در محیط‌های آزمایشی مستقر کنید
4. **گسترش استقرار**: استفاده را بر اساس آزمایش‌های موفق به تدریج گسترش دهید

#### بهترین شیوه‌ها
- **کوچک شروع کنید**: با مدل‌های Phi-mini برای توسعه اولیه شروع کنید
- **بهینه‌سازی درخواست‌ها**: از قالب‌بندی مناسب چت برای بهترین نتایج استفاده کنید
- **عملکرد را نظارت کنید**: سرعت استنتاج و معیارهای دقت را پیگیری کنید
- **سخت‌افزار را در نظر بگیرید**: اندازه مدل را با منابع محاسباتی موجود تطبیق دهید

## نتیجه‌گیری

خانواده مدل Microsoft Phi نمایانگر رویکردی انقلابی در طراحی مدل‌های هوش مصنوعی است که نشان می‌دهد مدل‌های کوچک‌تر و کارآمدتر می‌توانند عملکرد قابل توجهی در وظایف مختلف داشته باشند. با تمرکز بر داده‌های آموزشی با کیفیت بالا و بهینه‌سازی‌های معماری، خانواده Phi قابلیت‌های استثنایی را با نیازهای محاسباتی به طور قابل توجهی کاهش‌یافته نسبت به مدل‌های زبان بزرگ سنتی ارائه می‌دهد.

## اهداف کلیدی یادگیری

1. درک فلسفه طراحی و تکامل خانواده مدل‌های Phi از Phi-1 تا Phi-4
2. شناسایی نوآوری‌های کلیدی، از جمله آموزش با کیفیت "کتاب درسی" و بهینه‌سازی‌های معماری
3. شناخت مزایا و محدودیت‌های انواع مختلف Phi در سناریوهای استقرار مختلف
4. استفاده از دانش برای انتخاب مدل‌های مناسب Phi برای موارد استفاده خاص و محدودیت‌های سخت‌افزاری
5. پیاده‌سازی تکنیک‌های بهینه‌سازی برای استقرار مدل‌های Phi در دستگاه‌های با منابع محدود
6. توضیح مزایای معماری خانواده مدل‌های Phi نسبت به مدل‌های زبان بزرگ سنتی
7. انتخاب نوع مناسب Phi بر اساس نیازهای کاربردی خاص و محدودیت‌های سخت‌افزاری
8. پیاده‌سازی مدل‌های Phi در سناریوهای استقرار ابری و لبه با پیکربندی‌های بهینه
9. اعمال تکنیک‌های کمینه‌سازی و بهینه‌سازی برای بهبود عملکرد مدل‌های Phi در دستگاه‌های هدف
10. ارزیابی مبادلات بین اندازه مدل، عملکرد و قابلیت‌ها در سراسر خانواده Phi

## گام بعدی

- [02: اصول خانواده Qwen](02.QwenFamily.md)

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادقتی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.