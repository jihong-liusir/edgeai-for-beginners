{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d4d2e0",
   "metadata": {},
   "source": [
    "# جلسه ۶ – خط لوله چند مرحله‌ای (برنامه‌ریزی → اجرا → اصلاح)\n",
    "\n",
    "از توابع مسیریابی برای انتخاب مدل‌ها در هر مرحله استفاده می‌کند، سپس پاسخ نهایی را اصلاح می‌کند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959acb1",
   "metadata": {},
   "source": [
    "### توضیح: نصب وابستگی‌ها\n",
    "نصب `foundry-local-sdk` و `openai` که برای تماس‌های چت مرحله‌ای مورد نیاز هستند. اجرای مجدد آن بدون مشکل است.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58285936",
   "metadata": {},
   "source": [
    "# سناریو\n",
    "خط لوله مدل چندمرحله‌ای که: (1) یک وظیفه را به مراحل مجزا برنامه‌ریزی می‌کند، (2) هر مرحله را با انتخاب مدل مبتنی بر نیت اجرا می‌کند، (3) یک پاسخ نهایی ترکیبی را اصلاح می‌کند. زنجیره‌سازی قابلیت‌های ناهمگن SLM را برای کارایی در عین حفظ کیفیت نشان می‌دهد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0b10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q foundry-local-sdk openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220de1ac",
   "metadata": {},
   "source": [
    "### توضیح: وارد کردن‌های اصلی  \n",
    "وارد کردن regex برای تشخیص نیت، Foundry Local manager برای پیوست‌های مربوط به هر alias، و OpenAI client برای تکمیل‌های چت.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d63e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from foundry_local import FoundryLocalManager\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17da8d",
   "metadata": {},
   "source": [
    "### توضیح: کاتالوگ قابلیت‌ها و قوانین\n",
    "یک کاتالوگ مبتنی بر قابلیت و قوانین regex تعریف می‌کند که برای تطبیق متن مراحل با دسته‌های نیت (کد، خلاصه‌سازی، طبقه‌بندی، عمومی) استفاده می‌شود. مقادیر اولویت پایین‌تر در صورت وجود چندین مدل که از یک نیت پشتیبانی می‌کنند، برنده می‌شوند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee8e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = {\n",
    " 'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},\n",
    " 'qwen2.5-coder-7b': {'capabilities':['code','refactor'],'priority':1},\n",
    " 'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':3},\n",
    "}\n",
    "RULES = [\n",
    " (re.compile('code|refactor|function', re.I), 'code'),\n",
    " (re.compile('summari|abstract|tl;dr', re.I), 'summarize'),\n",
    " (re.compile('classif|category|label', re.I), 'classification'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d29a6",
   "metadata": {},
   "source": [
    "### توضیح: هدف، انتخاب مدل و کمک‌کننده چت\n",
    "ارائه می‌دهد:\n",
    "- `detect_intent` برای طبقه‌بندی مبتنی بر regex.\n",
    "- `pick_model` برای انتخاب بهترین نام مستعار بر اساس قابلیت + اولویت.\n",
    "- `chat` یک پوشش راحت که یک کلاینت برای هر نام مستعار ایجاد کرده و یک پاسخ تک‌مرحله‌ای بازمی‌گرداند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fe43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intent(text: str):\n",
    "    \"\"\"Return an intent label based on simple regex rules; falls back to 'general'.\"\"\"\n",
    "    for pat, intent in RULES:\n",
    "        if pat.search(text):\n",
    "            return intent\n",
    "    return 'general'\n",
    "\n",
    "def pick_model(intent: str) -> str:\n",
    "    \"\"\"Pick the best model for an intent using capability match first, then priority.\"\"\"\n",
    "    ranked = []\n",
    "    for name, meta in CATALOG.items():\n",
    "        ranked.append((name, intent in meta['capabilities'], meta['priority']))\n",
    "    # Sort: capability match (True first), then lower priority value\n",
    "    ranked.sort(key=lambda t: (not t[1], t[2]))\n",
    "    return ranked[0][0]\n",
    "\n",
    "def chat(alias: str, content: str, temp: float = 0.4) -> str:\n",
    "    \"\"\"Simple helper to send a single user message to a Foundry Local model via OpenAI client.\"\"\"\n",
    "    m = FoundryLocalManager(alias)\n",
    "    client = OpenAI(base_url=m.endpoint, api_key=m.api_key or 'not-needed')\n",
    "    mid = m.get_model_info(alias).id\n",
    "    resp = client.chat.completions.create(\n",
    "        model=mid,\n",
    "        messages=[{'role': 'user', 'content': content}],\n",
    "        max_tokens=180,\n",
    "        temperature=temp,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ba53d",
   "metadata": {},
   "source": [
    "### توضیح: عملکرد خط لوله چند مرحله‌ای\n",
    "خط لوله را اجرا می‌کند: برنامه‌ریزی → تجزیه مراحل → اجرای هر مرحله با مسیریابی مبتنی بر قصد → اصلاح خروجی‌های ترکیبی. یک دیکشنری ساختاریافته برای بررسی یا ارزیابی بازمی‌گرداند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22bf8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(task: str):\n",
    "    \"\"\"Multi-step pipeline: plan → execute steps → refine final answer.\n",
    "\n",
    "    Returns dict with keys: plan (raw plan text), steps (list of tuples), final (refined answer).\n",
    "    Each step tuple: (index, step_text, step_result, model_alias_used)\n",
    "    \"\"\"\n",
    "    # 1. Plan\n",
    "    plan_alias = pick_model('general')\n",
    "    plan_prompt = (\n",
    "        \"Break the task into 3 concise, actionable steps (no extra commentary).\\n\"\n",
    "        f\"Task: {task}\"\n",
    "    )\n",
    "    plan = chat(plan_alias, plan_prompt)\n",
    "\n",
    "    # 2. Parse steps (robust to numbering or bullet styles)\n",
    "    raw_lines = [l.strip() for l in plan.splitlines() if l.strip()]\n",
    "    steps = []\n",
    "    for line in raw_lines:\n",
    "        cleaned = re.sub(r'^\\d+[).:-]?\\s*', '', line)  # remove leading numbering\n",
    "        cleaned = re.sub(r'^[-*]\\s*', '', cleaned)      # remove bullet markers\n",
    "        if cleaned:\n",
    "            steps.append(cleaned)\n",
    "        if len(steps) == 3:\n",
    "            break\n",
    "    if not steps:\n",
    "        steps = [task]\n",
    "\n",
    "    # 3. Execute steps\n",
    "    outputs = []\n",
    "    for idx, step in enumerate(steps, 1):\n",
    "        intent = detect_intent(step)\n",
    "        exec_alias = pick_model(intent)\n",
    "        exec_prompt = (\n",
    "            f\"Execute step {idx} for the overall task.\\n\"\n",
    "            f\"Overall task: {task}\\n\"\n",
    "            f\"Step {idx}: {step}\\n\"\n",
    "            \"Return a concise result focusing only on the step objective.\"\n",
    "        )\n",
    "        result = chat(exec_alias, exec_prompt)\n",
    "        outputs.append((idx, step, result, exec_alias))\n",
    "\n",
    "    # 4. Refine final answer\n",
    "    refine_alias = pick_model('summarize')\n",
    "    combined = \"\\n\\n\".join(\n",
    "        f\"Step {idx} ({alias}) Output:\\n{res}\" for idx, _step, res, alias in outputs\n",
    "    )\n",
    "    refine_prompt = (\n",
    "        \"You are a senior assistant. Synthesize these step outputs into a cohesive final answer.\\n\"\n",
    "        \"Ensure clarity, avoid repetition, and highlight improvements or key insights if relevant.\\n\\n\"\n",
    "        f\"Task: {task}\\n\\n\"\n",
    "        f\"Step Outputs:\\n{combined}\"\n",
    "    )\n",
    "    final_ans = chat(refine_alias, refine_prompt)\n",
    "\n",
    "    return {\"plan\": plan, \"steps\": outputs, \"final\": final_ans}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282472b0",
   "metadata": {},
   "source": [
    "### توضیح: اجرای مثال وظیفه\n",
    "کل فرآیند را بر روی یک وظیفه با محوریت بازسازی اجرا می‌کند که نیت‌های ترکیبی (کد + خلاصه‌سازی) را نشان می‌دهد. دیکشنری نتیجه، طرح خام، خروجی‌های هر مرحله با نام‌های مستعار مدل انتخاب‌شده، و پاسخ نهایی ترکیب‌شده را نشان می‌دهد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac0f568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plan': '1. Profile the existing slow Python loop to identify bottlenecks.\\n2. Refactor the loop using optimized techniques (e.g., list comprehensions, map, or itertools).\\n3. Compare the performance of the refactored loop with the original using a benchmarking tool and summarize the gains.',\n",
       " 'steps': [(1,\n",
       "   'Profile the existing slow Python loop to identify bottlenecks.',\n",
       "   \"To execute step 1, you would use a profiling tool like `cProfile` in Python to analyze the performance of the existing slow loop. Here's an example of how you might do this:\\n\\n```python\\nimport cProfile\\n\\ndef slow_loop():\\n    # Example of a slow loop\\n    result = []\\n    for i in range(1000000):\\n        result.append(i * i)\\n    return result\\n\\n# Profile the slow loop\\ncProfile.run('slow_loop()', 'profile_stats')\\n\\n# To see the results, you can use pstats module\\nimport pstats\\np = pstats.Stats('profile_stats')\\np.sort_stats('cumulative').print_stats()\\n```\\n\\nThis code will run the `slow_loop` function and profile it, saving the results to 'profile_stats'. The `pstats` module can then be used to analyze the profiling data, which will show\",\n",
       "   'phi-4-mini'),\n",
       "  (2,\n",
       "   'Refactor the loop using optimized techniques (e.g., list comprehensions, map, or itertools).',\n",
       "   'To refactor a slow Python loop using optimized techniques such as list comprehensions, `map`, or `itertools`, follow these steps:\\n\\n1. **Identify the Loop**: Determine which loop in your code is causing the slowdown.\\n2. **Understand the Loop**: Analyze what the loop does, including any operations performed on each element.\\n3. **Choose an Optimization Technique**:\\n   - **List Comprehension**: If the loop constructs a new list, use a list comprehension.\\n   - **Map Function**: Use `map` if you need to apply a function to each item in an iterable.\\n   - **Itertools**: Utilize functions from the `itertools` module for more efficient looping patterns.\\n4. **Refactor the Loop**: Replace the original loop with the chosen optimization technique.\\n5. **Test the Code**: Ensure that the refactored code produces the same',\n",
       "   'qwen2.5-coder-7b'),\n",
       "  (3,\n",
       "   'Compare the performance of the refactored loop with the original using a benchmarking tool and summarize the gains.',\n",
       "   'To compare the performance of the refactored loop with the original using a benchmarking tool, follow these steps:\\n\\n1. **Choose a Benchmarking Tool**: Select an appropriate benchmarking tool such as `timeit`, `cProfile`, or `line_profiler` depending on your needs.\\n\\n2. **Set Up Your Environment**: Ensure that both the original and refactored code snippets are in separate functions or scripts so they can be easily compared.\\n\\n3. **Run Benchmarks**:\\n   - Use the chosen tool to measure the execution time of the original loop.\\n   - Repeat the process for the refactored loop.\\n\\n4. **Compare Results**: Analyze the results from both benchmarks to determine the performance gain achieved by the refactoring.\\n\\n5. **Summarize Gains**: Provide a concise summary of the performance improvements, including any specific metrics (e.g., speedup factor',\n",
       "   'qwen2.5-coder-7b')],\n",
       " 'final': 'To optimize a slow Python loop, you can use profiling tools like `cProfile` to identify the loop causing the slowdown. Once identified, you can refactor the loop using techniques such as list comprehensions, `map`, or `itertools` for more efficient looping patterns. After refactoring, you can use benchmarking tools like `timeit`, `cProfile`, or `line_profiler` to compare the performance of the original and refactored loops. The performance gains can be summarized in terms of speedup factor or other relevant metrics. This process can significantly improve the performance of your Python code.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline('Generate a refactored version of a slow Python loop and summarize performance gains.')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4251879",
   "metadata": {},
   "source": [
    "### توضیح: نمایش شیء نتیجه\n",
    "خروجی ساختاریافته‌ی پایپ‌لاین را برای بررسی سریع یا ارزیابی‌های بعدی (مثلاً اندازه‌گیری کیفیت گام یا اثربخشی بهبود) نشان می‌دهد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما هیچ مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "coopTranslator": {
   "original_hash": "4b16cb98e431df1b9f64f627bad7009c",
   "translation_date": "2025-10-08T22:12:40+00:00",
   "source_file": "Workshop/notebooks/session06_models_pipeline.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}