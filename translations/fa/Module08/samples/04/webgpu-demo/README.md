<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7a474b8e201d5316c0095cdbc3bf0555",
  "translation_date": "2025-09-24T12:49:12+00:00",
  "source_file": "Module08/samples/04/webgpu-demo/README.md",
  "language_code": "fa"
}
-->
# دموی WebGPU + ONNX Runtime

این دمو نشان می‌دهد که چگونه می‌توان مدل‌های هوش مصنوعی را مستقیماً در مرورگر اجرا کرد، با استفاده از WebGPU برای شتاب‌دهی سخت‌افزاری و ONNX Runtime Web.

## آنچه این دمو نشان می‌دهد

- **هوش مصنوعی مبتنی بر مرورگر**: اجرای مدل‌ها به طور کامل در مرورگر  
- **شتاب‌دهی WebGPU**: استنتاج سخت‌افزاری در صورت موجود بودن  
- **اولویت به حریم خصوصی**: هیچ داده‌ای دستگاه شما را ترک نمی‌کند  
- **بدون نیاز به نصب**: در هر مرورگر سازگار کار می‌کند  
- **بازگشت به حالت اولیه**: در صورت عدم دسترسی به WebGPU، به CPU بازمی‌گردد  

## الزامات

**سازگاری مرورگر:**
- Chrome/Edge نسخه 113+ با WebGPU فعال  
- بررسی وضعیت WebGPU: `chrome://gpu`  
- فعال کردن WebGPU: `chrome://flags/#enable-unsafe-webgpu`  

## اجرای دمو

### گزینه 1: سرور محلی (توصیه‌شده)

```cmd
# Navigate to the demo directory
cd Module08\samples\04\webgpu-demo

# Start a local server
python -m http.server 5173

# Open browser to http://localhost:5173
```


### گزینه 2: سرور زنده VS Code

1. افزونه "Live Server" را در VS Code نصب کنید  
2. روی `index.html` کلیک راست کنید → "Open with Live Server"  
3. دمو به طور خودکار در مرورگر باز می‌شود  

## آنچه خواهید دید

1. **تشخیص WebGPU**: بررسی سازگاری مرورگر  
2. **بارگذاری مدل**: دانلود و راه‌اندازی طبقه‌بند MNIST  
3. **اجرای استنتاج**: پیش‌بینی روی داده‌های نمونه  
4. **معیارهای عملکرد**: نمایش زمان بارگذاری و سرعت استنتاج  
5. **نمایش نتایج**: اعتماد به پیش‌بینی و خروجی‌های خام  

## عملکرد مورد انتظار

| ارائه‌دهنده اجرا | بارگذاری مدل | استنتاج | توضیحات |
|-------------------|--------------|----------|----------|
| **WebGPU** | ~2-5 ثانیه | ~10-50 میلی‌ثانیه | شتاب‌دهی سخت‌افزاری |
| **CPU (WASM)** | ~2-5 ثانیه | ~50-200 میلی‌ثانیه | بازگشت به نرم‌افزار |

## رفع مشکلات

**WebGPU در دسترس نیست:**
- به Chrome/Edge نسخه 113+ به‌روزرسانی کنید  
- WebGPU را در `chrome://flags` فعال کنید  
- بررسی کنید که درایورهای GPU به‌روز هستند  
- دمو به طور خودکار به CPU بازمی‌گردد  

**خطاهای بارگذاری:**
- مطمئن شوید که از طریق HTTP سرویس‌دهی می‌کنید (نه file://)  
- اتصال شبکه را برای دانلود مدل بررسی کنید  
- مطمئن شوید که CORS مانع دانلود مدل ONNX نمی‌شود  

**مشکلات عملکرد:**
- WebGPU سرعت قابل توجهی نسبت به CPU ارائه می‌دهد  
- اجرای اول ممکن است به دلیل دانلود مدل کندتر باشد  
- اجراهای بعدی از کش مرورگر استفاده می‌کنند  

## یکپارچگی با Foundry Local

این دمو WebGPU مکمل Foundry Local است و نشان می‌دهد:

- **استنتاج سمت کلاینت** برای حفظ حریم خصوصی کامل  
- **قابلیت‌های آفلاین** زمانی که اینترنت در دسترس نیست  
- **استقرار در لبه** برای محیط‌های محدود منابع  
- **معماری‌های ترکیبی** که استنتاج محلی و سروری را ترکیب می‌کنند  

برای برنامه‌های تولیدی، در نظر بگیرید:
- استفاده از Foundry Local برای استنتاج سمت سرور  
- استفاده از WebGPU برای پیش‌پردازش/پس‌پردازش سمت کلاینت  
- پیاده‌سازی مسیریابی هوشمند بین استنتاج محلی/راه دور  

## جزئیات فنی

**مدل استفاده‌شده:**
- طبقه‌بند ارقام MNIST (فرمت ONNX)  
- ورودی: تصاویر خاکستری 28x28  
- خروجی: توزیع احتمال 10 کلاس  
- اندازه: ~500KB (دانلود سریع)  

**ONNX Runtime Web:**
- ارائه‌دهنده اجرای WebGPU برای شتاب‌دهی GPU  
- ارائه‌دهنده اجرای WASM برای بازگشت به CPU  
- بهینه‌سازی خودکار و بهینه‌سازی گراف  

**API‌های مرورگر:**
- WebGPU برای دسترسی سخت‌افزاری  
- Web Workers برای پردازش پس‌زمینه (بهبود آینده)  
- WebAssembly برای محاسبات کارآمد  

## مراحل بعدی

- امتحان کردن با مدل‌های سفارشی ONNX  
- پیاده‌سازی آپلود تصویر واقعی و طبقه‌بندی  
- افزودن استنتاج جریانی برای مدل‌های بزرگ‌تر  
- یکپارچگی با ورودی دوربین/میکروفون  

---

