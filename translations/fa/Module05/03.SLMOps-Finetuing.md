<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T15:52:17+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "fa"
}
-->
# بخش ۳: تنظیم دقیق - سفارشی‌سازی مدل‌ها برای وظایف خاص

## فهرست مطالب
1. [مقدمه‌ای بر تنظیم دقیق](../../../Module05)
2. [چرا تنظیم دقیق اهمیت دارد](../../../Module05)
3. [انواع تنظیم دقیق](../../../Module05)
4. [تنظیم دقیق با Microsoft Olive](../../../Module05)
5. [مثال‌های عملی](../../../Module05)
6. [بهترین روش‌ها و راهنماها](../../../Module05)
7. [تکنیک‌های پیشرفته](../../../Module05)
8. [ارزیابی و نظارت](../../../Module05)
9. [چالش‌های رایج و راه‌حل‌ها](../../../Module05)
10. [نتیجه‌گیری](../../../Module05)

## مقدمه‌ای بر تنظیم دقیق

**تنظیم دقیق** یک تکنیک قدرتمند در یادگیری ماشین است که شامل تطبیق یک مدل از پیش آموزش‌دیده برای انجام وظایف خاص یا کار با مجموعه داده‌های تخصصی می‌شود. به جای آموزش مدل از ابتدا، تنظیم دقیق از دانش قبلاً آموخته شده توسط مدل از پیش آموزش‌دیده استفاده کرده و آن را برای کاربرد خاص شما تنظیم می‌کند.

### تنظیم دقیق چیست؟

تنظیم دقیق نوعی **یادگیری انتقالی** است که در آن:
- با یک مدل از پیش آموزش‌دیده که الگوهای عمومی را از مجموعه داده‌های بزرگ آموخته است شروع می‌کنید
- پارامترهای داخلی مدل را با استفاده از مجموعه داده خاص خود تنظیم می‌کنید
- دانش ارزشمند را حفظ کرده و مدل را برای وظیفه خود تخصصی می‌کنید

این را مانند آموزش یک آشپز ماهر برای پختن یک نوع غذای جدید تصور کنید - او اصول آشپزی را می‌داند، اما باید تکنیک‌ها و طعم‌های خاص سبک جدید را یاد بگیرد.

### مزایای کلیدی

- **صرفه‌جویی در زمان**: بسیار سریع‌تر از آموزش از ابتدا
- **کارایی داده**: نیاز به مجموعه داده‌های کوچکتر برای دستیابی به عملکرد خوب
- **مقرون‌به‌صرفه**: نیاز کمتر به منابع محاسباتی
- **عملکرد بهتر**: اغلب نتایج برتری نسبت به آموزش از ابتدا به دست می‌آورد
- **بهینه‌سازی منابع**: دسترسی به هوش مصنوعی قدرتمند را برای تیم‌ها و سازمان‌های کوچک فراهم می‌کند

## چرا تنظیم دقیق اهمیت دارد

### کاربردهای دنیای واقعی

تنظیم دقیق در بسیاری از سناریوها ضروری است:

**۱. تطبیق با حوزه**
- هوش مصنوعی پزشکی: تطبیق مدل‌های زبان عمومی برای اصطلاحات پزشکی و یادداشت‌های بالینی
- فناوری حقوقی: تخصصی کردن مدل‌ها برای تحلیل اسناد حقوقی و بررسی قراردادها
- خدمات مالی: سفارشی‌سازی مدل‌ها برای تحلیل گزارش‌های مالی و ارزیابی ریسک

**۲. تخصص وظیفه‌ای**
- تولید محتوا: تنظیم دقیق برای سبک‌های نوشتاری یا لحن‌های خاص
- تولید کد: تطبیق مدل‌ها برای زبان‌های برنامه‌نویسی یا چارچوب‌های خاص
- ترجمه: بهبود عملکرد برای جفت زبان‌های خاص یا حوزه‌های فنی

**۳. کاربردهای شرکتی**
- خدمات مشتری: ایجاد چت‌بات‌هایی که اصطلاحات خاص شرکت را درک می‌کنند
- مستندات داخلی: ساخت دستیارهای هوش مصنوعی آشنا با فرآیندهای سازمانی
- راه‌حل‌های صنعتی: توسعه مدل‌هایی که اصطلاحات و جریان‌های کاری خاص صنعت را درک می‌کنند

## انواع تنظیم دقیق

### ۱. تنظیم دقیق کامل (تنظیم دقیق دستوری)

در تنظیم دقیق کامل، تمام پارامترهای مدل در طول آموزش به‌روزرسانی می‌شوند. این روش:
- انعطاف‌پذیری و پتانسیل عملکردی حداکثری را فراهم می‌کند
- نیاز به منابع محاسباتی قابل توجه دارد
- منجر به ایجاد نسخه کاملاً جدیدی از مدل می‌شود
- بهترین گزینه برای سناریوهایی است که داده‌های آموزشی و منابع محاسباتی فراوان دارید

### ۲. تنظیم دقیق کارآمد پارامتر (PEFT)

روش‌های PEFT تنها زیرمجموعه کوچکی از پارامترها را به‌روزرسانی می‌کنند و فرآیند را کارآمدتر می‌سازند:

#### Low-Rank Adaptation (LoRA)
- ماتریس‌های تجزیه رتبه‌ای کوچک قابل آموزش را به وزن‌های موجود اضافه می‌کند
- تعداد پارامترهای قابل آموزش را به‌طور چشمگیری کاهش می‌دهد
- عملکردی نزدیک به تنظیم دقیق کامل را حفظ می‌کند
- امکان تغییر آسان بین تطبیق‌های مختلف را فراهم می‌کند

#### QLoRA (Quantized LoRA)
- LoRA را با تکنیک‌های کمینه‌سازی ترکیب می‌کند
- نیازهای حافظه را بیشتر کاهش می‌دهد
- امکان تنظیم دقیق مدل‌های بزرگ‌تر روی سخت‌افزار مصرف‌کننده را فراهم می‌کند
- تعادل بین کارایی و عملکرد را ایجاد می‌کند

#### Adapters
- شبکه‌های عصبی کوچک را بین لایه‌های موجود وارد می‌کند
- تنظیم دقیق هدفمند را در حالی که مدل پایه ثابت می‌ماند امکان‌پذیر می‌سازد
- رویکردی ماژولار برای سفارشی‌سازی مدل فراهم می‌کند

### ۳. تنظیم دقیق وظیفه‌محور

بر تطبیق مدل‌ها برای وظایف پایین‌دستی خاص تمرکز دارد:
- **دسته‌بندی**: تنظیم مدل‌ها برای وظایف دسته‌بندی
- **تولید**: بهینه‌سازی برای تولید محتوا و تولید متن
- **استخراج**: تنظیم دقیق برای استخراج اطلاعات و شناسایی موجودیت‌های نام‌دار
- **خلاصه‌سازی**: تخصصی کردن مدل‌ها برای خلاصه‌سازی اسناد

## تنظیم دقیق با Microsoft Olive

Microsoft Olive یک ابزار جامع برای بهینه‌سازی مدل است که فرآیند تنظیم دقیق را ساده کرده و ویژگی‌های سطح سازمانی ارائه می‌دهد.

### Microsoft Olive چیست؟

Microsoft Olive یک ابزار بهینه‌سازی مدل متن‌باز است که:
- جریان‌های کاری تنظیم دقیق را برای اهداف سخت‌افزاری مختلف ساده می‌کند
- پشتیبانی داخلی از معماری‌های مدل محبوب (Llama، Phi، Qwen، Gemma) ارائه می‌دهد
- گزینه‌های استقرار ابری و محلی را فراهم می‌کند
- به‌طور یکپارچه با Azure ML و سایر خدمات هوش مصنوعی مایکروسافت ادغام می‌شود
- از بهینه‌سازی و کمینه‌سازی خودکار پشتیبانی می‌کند

### ویژگی‌های کلیدی

- **بهینه‌سازی آگاه به سخت‌افزار**: مدل‌ها را به‌طور خودکار برای سخت‌افزار خاص (CPU، GPU، NPU) بهینه می‌کند
- **پشتیبانی چندفرمتی**: با مدل‌های PyTorch، Hugging Face و ONNX کار می‌کند
- **جریان‌های کاری خودکار**: پیکربندی دستی و آزمون و خطا را کاهش می‌دهد
- **ادغام سازمانی**: پشتیبانی داخلی از Azure ML و استقرار ابری
- **معماری قابل توسعه**: امکان استفاده از تکنیک‌های بهینه‌سازی سفارشی را فراهم می‌کند

### نصب و راه‌اندازی

#### نصب پایه

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### وابستگی‌های اختیاری

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### تأیید نصب

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## مثال‌های عملی

### مثال ۱: تنظیم دقیق پایه با Olive CLI

این مثال تنظیم دقیق یک مدل زبان کوچک برای دسته‌بندی عبارات را نشان می‌دهد:

#### مرحله ۱: آماده‌سازی محیط

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### مرحله ۲: تنظیم دقیق مدل

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### مرحله ۳: بهینه‌سازی برای استقرار

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### مثال ۲: پیکربندی پیشرفته با مجموعه داده سفارشی

#### مرحله ۱: آماده‌سازی مجموعه داده سفارشی

یک فایل JSON با داده‌های آموزشی خود ایجاد کنید:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### مرحله ۲: ایجاد فایل پیکربندی

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### مرحله ۳: اجرای تنظیم دقیق

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### مثال ۳: تنظیم دقیق QLoRA برای کارایی حافظه

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## بهترین روش‌ها و راهنماها

### آماده‌سازی داده

**۱. کیفیت داده بر کمیت داده**
- نمونه‌های متنوع و با کیفیت بالا را بر حجم زیاد داده‌های ضعیف ترجیح دهید
- اطمینان حاصل کنید که داده‌ها نماینده کاربرد هدف شما هستند
- داده‌ها را به‌طور مداوم پاک‌سازی و پیش‌پردازش کنید

**۲. قالب‌بندی داده و قالب‌ها**
- از قالب‌بندی ثابت در تمام نمونه‌های آموزشی استفاده کنید
- قالب‌های ورودی-خروجی واضحی ایجاد کنید که با کاربرد شما مطابقت داشته باشد
- قالب‌بندی دستورالعمل مناسب را برای مدل‌های تنظیم دقیق دستوری شامل کنید

**۳. تقسیم‌بندی مجموعه داده**
- ۱۰-۲۰٪ از داده‌ها را برای اعتبارسنجی رزرو کنید
- توزیع‌های مشابه را در تقسیم‌های آموزش/اعتبارسنجی حفظ کنید
- نمونه‌گیری طبقه‌بندی‌شده را برای وظایف دسته‌بندی در نظر بگیرید

### پیکربندی آموزش

**۱. انتخاب نرخ یادگیری**
- با نرخ‌های یادگیری کوچک‌تر (۱e-5 تا ۱e-4) برای تنظیم دقیق شروع کنید
- از زمان‌بندی نرخ یادگیری برای همگرایی بهتر استفاده کنید
- منحنی‌های خطا را برای تنظیم نرخ‌ها نظارت کنید

**۲. بهینه‌سازی اندازه دسته**
- اندازه دسته را با حافظه موجود متعادل کنید
- از تجمع گرادیان برای اندازه دسته مؤثر بزرگ‌تر استفاده کنید
- رابطه بین اندازه دسته و نرخ یادگیری را در نظر بگیرید

**۳. مدت زمان آموزش**
- معیارهای اعتبارسنجی را برای جلوگیری از بیش‌برازش نظارت کنید
- از توقف زودهنگام زمانی که عملکرد اعتبارسنجی ثابت می‌شود استفاده کنید
- به‌طور منظم نقاط بازیابی را برای بازیابی و تحلیل ذخیره کنید

### انتخاب مدل

**۱. انتخاب مدل پایه**
- مدل‌هایی را که از قبل در حوزه‌های مشابه آموزش دیده‌اند انتخاب کنید
- اندازه مدل را نسبت به محدودیت‌های محاسباتی خود در نظر بگیرید
- الزامات مجوز برای استفاده تجاری را ارزیابی کنید

**۲. انتخاب روش تنظیم دقیق**
- از LoRA/QLoRA برای محیط‌های محدود منابع استفاده کنید
- تنظیم دقیق کامل را زمانی که عملکرد حداکثری حیاتی است انتخاب کنید
- رویکردهای مبتنی بر آداپتور را برای سناریوهای چندوظیفه‌ای در نظر بگیرید

### مدیریت منابع

**۱. بهینه‌سازی سخت‌افزار**
- سخت‌افزار مناسب را برای اندازه مدل و روش خود انتخاب کنید
- از حافظه GPU به‌طور مؤثر با بررسی گرادیان استفاده کنید
- راه‌حل‌های مبتنی بر ابر را برای مدل‌های بزرگ‌تر در نظر بگیرید

**۲. مدیریت حافظه**
- از آموزش با دقت مختلط زمانی که در دسترس است استفاده کنید
- تجمع گرادیان را برای محدودیت‌های حافظه اجرا کنید
- استفاده از حافظه GPU را در طول آموزش نظارت کنید

## تکنیک‌های پیشرفته

### آموزش چند آداپتور

چندین آداپتور را برای وظایف مختلف آموزش دهید در حالی که مدل پایه مشترک است:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### بهینه‌سازی ابرپارامترها

بهینه‌سازی سیستماتیک ابرپارامترها را اجرا کنید:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### توابع خطای سفارشی

توابع خطای خاص حوزه را اجرا کنید:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## ارزیابی و نظارت

### معیارها و ارزیابی

**۱. معیارهای استاندارد**
- **دقت**: صحت کلی برای وظایف دسته‌بندی
- **Perplexity**: معیار کیفیت مدل‌سازی زبان
- **BLEU/ROUGE**: کیفیت تولید متن و خلاصه‌سازی
- **F1 Score**: تعادل دقت و بازخوانی برای دسته‌بندی

**۲. معیارهای خاص حوزه**
- **معیارهای وظیفه‌محور**: از معیارهای تثبیت‌شده برای حوزه خود استفاده کنید
- **ارزیابی انسانی**: ارزیابی انسانی را برای وظایف ذهنی شامل کنید
- **معیارهای کسب‌وکار**: با اهداف واقعی کسب‌وکار هماهنگ شوید

**۳. تنظیم ارزیابی**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### نظارت بر پیشرفت آموزش

**۱. ردیابی خطا**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**۲. نظارت بر اعتبارسنجی**
- خطای اعتبارسنجی را همراه با خطای آموزش ردیابی کنید
- علائم بیش‌برازش را نظارت کنید (افزایش خطای اعتبارسنجی در حالی که خطای آموزش کاهش می‌یابد)
- از توقف زودهنگام بر اساس معیارهای اعتبارسنجی استفاده کنید

**۳. نظارت بر منابع**
- استفاده از GPU/CPU را نظارت کنید
- الگوهای استفاده از حافظه را ردیابی کنید
- سرعت و توان عملیاتی آموزش را نظارت کنید

## چالش‌های رایج و راه‌حل‌ها

### چالش ۱: بیش‌برازش

**علائم:**
- خطای آموزش همچنان کاهش می‌یابد در حالی که خطای اعتبارسنجی افزایش می‌یابد
- شکاف بزرگ بین عملکرد آموزش و اعتبارسنجی
- عمومی‌سازی ضعیف به داده‌های جدید

**راه‌حل‌ها:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### چالش ۲: محدودیت‌های حافظه

**راه‌حل‌ها:**
- از بررسی گرادیان استفاده کنید
- تجمع گرادیان را اجرا کنید
- روش‌های کارآمد پارامتر (LoRA، QLoRA) را انتخاب کنید
- از موازی‌سازی مدل برای مدل‌های بزرگ استفاده کنید

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### چالش ۳: آموزش کند

**راه‌حل‌ها:**
- خطوط لوله بارگذاری داده را بهینه کنید
- از آموزش با دقت مختلط استفاده کنید
- استراتژی‌های دسته‌بندی کارآمد را اجرا کنید
- آموزش توزیع‌شده را برای مجموعه داده‌های بزرگ در نظر بگیرید

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### چالش ۴: عملکرد ضعیف

**مراحل تشخیص:**
1. کیفیت و قالب‌بندی داده را تأیید کنید
2. نرخ یادگیری و مدت زمان آموزش را بررسی کنید
3. انتخاب مدل پایه را ارزیابی کنید
4. پیش‌پردازش و توکن‌سازی را مرور کنید

**راه‌حل‌ها:**
- تنوع داده‌های آموزشی را افزایش دهید
- زمان‌بندی نرخ یادگیری را تنظیم کنید
- مدل‌های پایه مختلف را امتحان کنید
- تکنیک‌های افزایش داده را اجرا کنید

## نتیجه‌گیری

تنظیم دقیق یک تکنیک قدرتمند است که دسترسی به قابلیت‌های پیشرفته هوش مصنوعی را دموکراتیک می‌کند. با استفاده از ابزارهایی مانند Microsoft Olive، سازمان‌ها می‌توانند مدل‌های از پیش آموزش‌دیده را به‌طور مؤثر برای نیازهای خاص خود تطبیق داده و در عین حال عملکرد و محدودیت‌های منابع را بهینه کنند.

### نکات کلیدی

1. **رویکرد مناسب را انتخاب کنید**: روش‌های تنظیم دقیق را بر اساس منابع محاسباتی و نیازهای عملکردی خود انتخاب کنید
2. **کیفیت داده اهمیت دارد**: در داده‌های آموزشی با کیفیت بالا و نماینده سرمایه‌گذاری کنید
3. **نظارت و تکرار کنید**: مدل‌های خود را به‌طور مداوم ارزیابی و بهبود دهید
4. **از ابزارها استفاده کنید**: از چارچوب‌هایی مانند Olive برای ساده‌سازی و بهینه‌سازی فرآیند استفاده کنید
5. **استقرار را در نظر بگیرید**: از ابتدا برای بهینه‌سازی و استقرار مدل برنامه‌ریزی کنید

## ➡️ مرحله بعدی

- [04: استقرار - پیاده‌سازی مدل آماده تولید](./04.SLMOps.Deployment.md)

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.