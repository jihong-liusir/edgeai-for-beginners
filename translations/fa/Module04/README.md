<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c0cb9f7bcff2bc170532d8870a891f38",
  "translation_date": "2025-09-17T15:33:14+00:00",
  "source_file": "Module04/README.md",
  "language_code": "fa"
}
-->
# فصل ۰۴: تبدیل فرمت مدل و کوانتیزاسیون - مرور فصل

ظهور EdgeAI تبدیل فرمت مدل و کوانتیزاسیون را به فناوری‌های ضروری برای پیاده‌سازی قابلیت‌های پیشرفته یادگیری ماشین بر روی دستگاه‌های با منابع محدود تبدیل کرده است. این فصل جامع راهنمای کاملی برای درک، پیاده‌سازی و بهینه‌سازی مدل‌ها برای سناریوهای استقرار در لبه ارائه می‌دهد.

## 📚 ساختار فصل و مسیر یادگیری

این فصل به شش بخش پیشرفته تقسیم شده است که هر کدام بر اساس بخش قبلی بنا شده‌اند تا درک کاملی از بهینه‌سازی مدل برای محاسبات لبه ایجاد کنند:

---

## [بخش ۱: مبانی تبدیل فرمت مدل و کوانتیزاسیون](./01.Introduce.md)

### 🎯 مرور کلی
این بخش پایه‌ای چارچوب نظری برای بهینه‌سازی مدل در محیط‌های محاسبات لبه را ایجاد می‌کند و مرزهای کوانتیزاسیون از دقت ۱ بیت تا ۸ بیت و استراتژی‌های کلیدی تبدیل فرمت را پوشش می‌دهد.

**موضوعات کلیدی:**
- چارچوب طبقه‌بندی دقت (دقت فوق‌العاده پایین، پایین، متوسط)
- مزایا و موارد استفاده فرمت‌های GGUF و ONNX
- مزایای کوانتیزاسیون برای کارایی عملیاتی و انعطاف‌پذیری استقرار
- مقایسه‌های عملکرد و ردپای حافظه

**نتایج یادگیری:**
- درک مرزها و طبقه‌بندی‌های کوانتیزاسیون
- شناسایی تکنیک‌های مناسب تبدیل فرمت
- یادگیری استراتژی‌های پیشرفته بهینه‌سازی برای استقرار در لبه

---

## [بخش ۲: راهنمای پیاده‌سازی Llama.cpp](./02.Llamacpp.md)

### 🎯 مرور کلی
یک آموزش جامع برای پیاده‌سازی Llama.cpp، یک چارچوب قدرتمند C++ که امکان استنتاج مدل‌های زبان بزرگ را با حداقل تنظیمات در پیکربندی‌های سخت‌افزاری متنوع فراهم می‌کند.

**موضوعات کلیدی:**
- نصب در پلتفرم‌های ویندوز، macOS و لینوکس
- تبدیل فرمت GGUF و سطوح مختلف کوانتیزاسیون (Q2_K تا Q8_0)
- شتاب سخت‌افزاری با CUDA، Metal، OpenCL و Vulkan
- یکپارچه‌سازی با پایتون و استراتژی‌های استقرار تولید

**نتایج یادگیری:**
- تسلط بر نصب چندپلتفرمی و ساخت از منبع
- پیاده‌سازی تکنیک‌های کوانتیزاسیون و بهینه‌سازی مدل
- استقرار مدل‌ها در حالت سرور با یکپارچه‌سازی REST API

---

## [بخش ۳: مجموعه بهینه‌سازی Microsoft Olive](./03.MicrosoftOlive.md)

### 🎯 مرور کلی
بررسی Microsoft Olive، یک ابزار بهینه‌سازی مدل آگاه به سخت‌افزار با بیش از ۴۰ مؤلفه بهینه‌سازی داخلی، طراحی شده برای استقرار مدل‌های سطح سازمانی در پلتفرم‌های سخت‌افزاری متنوع.

**موضوعات کلیدی:**
- ویژگی‌های خودکار بهینه‌سازی با کوانتیزاسیون دینامیک و استاتیک
- هوش آگاه به سخت‌افزار برای استقرار در CPU، GPU و NPU
- پشتیبانی از مدل‌های محبوب (Llama، Phi، Qwen، Gemma) به صورت آماده
- یکپارچه‌سازی سازمانی با Azure ML و جریان‌های کاری تولید

**نتایج یادگیری:**
- استفاده از بهینه‌سازی خودکار برای معماری‌های مختلف مدل
- پیاده‌سازی استراتژی‌های استقرار چندپلتفرمی
- ایجاد خطوط لوله بهینه‌سازی آماده برای سازمان

---

## [بخش ۴: مجموعه بهینه‌سازی OpenVINO Toolkit](./04.openvino.md)

### 🎯 مرور کلی
بررسی جامع ابزار OpenVINO اینتل، یک پلتفرم متن‌باز برای استقرار راه‌حل‌های هوش مصنوعی با عملکرد بالا در محیط‌های ابری، محلی و لبه با قابلیت‌های پیشرفته فشرده‌سازی شبکه عصبی (NNCF).

**موضوعات کلیدی:**
- استقرار چندپلتفرمی با شتاب سخت‌افزاری (CPU، GPU، VPU، شتاب‌دهنده‌های هوش مصنوعی)
- چارچوب فشرده‌سازی شبکه عصبی (NNCF) برای کوانتیزاسیون و هرس پیشرفته
- OpenVINO GenAI برای بهینه‌سازی و استقرار مدل‌های زبان بزرگ
- قابلیت‌های سرور مدل سطح سازمانی و استراتژی‌های استقرار مقیاس‌پذیر

**نتایج یادگیری:**
- تسلط بر جریان‌های کاری تبدیل و بهینه‌سازی مدل OpenVINO
- پیاده‌سازی تکنیک‌های پیشرفته کوانتیزاسیون با NNCF
- استقرار مدل‌های بهینه‌سازی شده در پلتفرم‌های سخت‌افزاری متنوع با Model Server

---

## [بخش ۵: بررسی عمیق Apple MLX Framework](./05.AppleMLX.md)

### 🎯 مرور کلی
پوشش جامع Apple MLX، یک چارچوب انقلابی که به طور خاص برای یادگیری ماشین کارآمد بر روی Apple Silicon طراحی شده است، با تأکید بر قابلیت‌های مدل‌های زبان بزرگ و استقرار محلی.

**موضوعات کلیدی:**
- مزایای معماری حافظه یکپارچه و Metal Performance Shaders
- پشتیبانی از مدل‌های LLaMA، Mistral، Phi-3، Qwen و Code Llama
- تنظیم دقیق LoRA برای سفارشی‌سازی کارآمد مدل
- یکپارچه‌سازی Hugging Face و پشتیبانی از کوانتیزاسیون (۴ بیت و ۸ بیت)

**نتایج یادگیری:**
- تسلط بر بهینه‌سازی Apple Silicon برای استقرار مدل‌های زبان بزرگ
- پیاده‌سازی تکنیک‌های تنظیم دقیق و سفارشی‌سازی مدل
- ساخت برنامه‌های هوش مصنوعی سازمانی با ویژگی‌های پیشرفته حفظ حریم خصوصی

---

## [بخش ۶: ترکیب جریان کاری توسعه Edge AI](./06.workflow-synthesis.md)

### 🎯 مرور کلی
ترکیب جامع تمام چارچوب‌های بهینه‌سازی در جریان‌های کاری یکپارچه، ماتریس‌های تصمیم‌گیری و بهترین شیوه‌ها برای استقرار Edge AI آماده تولید در پلتفرم‌ها و موارد استفاده متنوع.

**موضوعات کلیدی:**
- معماری جریان کاری یکپارچه که چندین چارچوب بهینه‌سازی را ادغام می‌کند
- درخت‌های تصمیم‌گیری انتخاب چارچوب و تحلیل مصالحه‌های عملکرد
- اعتبارسنجی آمادگی تولید و استراتژی‌های استقرار جامع
- استراتژی‌های آینده‌نگر برای سخت‌افزار و معماری‌های مدل نوظهور

**نتایج یادگیری:**
- تسلط بر انتخاب سیستماتیک چارچوب بر اساس نیازها و محدودیت‌ها
- پیاده‌سازی خطوط لوله Edge AI آماده تولید با نظارت جامع
- طراحی جریان‌های کاری قابل تطبیق که با فناوری‌ها و نیازهای نوظهور تکامل می‌یابند

---

## 🎯 نتایج یادگیری فصل

با تکمیل این فصل جامع، خوانندگان به دستاوردهای زیر خواهند رسید:

### **تسلط فنی**
- درک عمیق مرزهای کوانتیزاسیون و کاربردهای عملی
- تجربه عملی با چندین چارچوب بهینه‌سازی
- مهارت‌های استقرار تولید برای محیط‌های محاسبات لبه

### **درک استراتژیک**
- توانایی انتخاب بهینه‌سازی آگاه به سخت‌افزار
- تصمیم‌گیری آگاهانه در مورد مصالحه‌های عملکرد
- استراتژی‌های استقرار و نظارت آماده سازمانی

### **معیارهای عملکرد**

| چارچوب | کوانتیزاسیون | استفاده از حافظه | بهبود سرعت | مورد استفاده |
|--------|--------------|------------------|------------|--------------|
| Llama.cpp | Q4_K_M | ~۴ گیگابایت | ۲-۳ برابر | استقرار چندپلتفرمی |
| Olive | INT4 | کاهش ۶۰-۷۵٪ | ۲-۶ برابر | جریان‌های کاری سازمانی |
| OpenVINO | INT8/INT4 | کاهش ۵۰-۷۵٪ | ۲-۵ برابر | بهینه‌سازی سخت‌افزار اینتل |
| MLX | ۴ بیت | ~۴ گیگابایت | ۲-۴ برابر | بهینه‌سازی Apple Silicon |

## 🚀 گام‌های بعدی و کاربردهای پیشرفته

این فصل پایه کاملی برای موارد زیر فراهم می‌کند:
- توسعه مدل‌های سفارشی برای حوزه‌های خاص
- تحقیق در بهینه‌سازی Edge AI
- توسعه برنامه‌های تجاری هوش مصنوعی
- استقرار Edge AI در مقیاس بزرگ سازمانی

دانش حاصل از این شش بخش یک جعبه‌ابزار جامع برای پیمایش در چشم‌انداز به سرعت در حال تحول بهینه‌سازی و استقرار مدل‌های Edge AI ارائه می‌دهد.

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.