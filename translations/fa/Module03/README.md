<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-17T15:55:36+00:00",
  "source_file": "Module03/README.md",
  "language_code": "fa"
}
-->
# فصل ۰۳: استقرار مدل‌های زبانی کوچک (SLMs)

این فصل جامع به چرخه کامل استقرار مدل‌های زبانی کوچک (SLMs) می‌پردازد و شامل مبانی نظری، استراتژی‌های عملی پیاده‌سازی و راه‌حل‌های آماده تولید مبتنی بر کانتینر است. فصل به سه بخش پیشرفته تقسیم شده است که خوانندگان را از مفاهیم پایه به سناریوهای استقرار پیشرفته هدایت می‌کند.

## ساختار فصل و مسیر یادگیری

### **[بخش ۱: یادگیری پیشرفته SLM - مبانی و بهینه‌سازی](./01.SLMAdvancedLearning.md)**
بخش ابتدایی، پایه‌های نظری برای درک مدل‌های زبانی کوچک و اهمیت استراتژیک آن‌ها در استقرار هوش مصنوعی در لبه را فراهم می‌کند. این بخش شامل موارد زیر است:

- **چارچوب طبقه‌بندی پارامترها**: بررسی دقیق دسته‌بندی‌های SLM از مدل‌های کوچک (۱۰۰M-1.4B پارامتر) تا مدل‌های متوسط (۱۴B-۳۰B پارامتر)، با تمرکز ویژه بر مدل‌هایی مانند Phi-4-mini-3.8B، سری Qwen3 و Google Gemma3، شامل تحلیل نیازهای سخت‌افزاری و حافظه برای هر سطح مدل
- **تکنیک‌های پیشرفته بهینه‌سازی**: پوشش جامع روش‌های کوانتیزاسیون با استفاده از چارچوب‌های Llama.cpp، Microsoft Olive و Apple MLX، شامل کوانتیزاسیون پیشرفته BitNET 1-bit با مثال‌های کدنویسی عملی که خطوط لوله کوانتیزاسیون و نتایج بنچمارک را نشان می‌دهد
- **استراتژی‌های دستیابی به مدل**: تحلیل عمیق اکوسیستم Hugging Face و کاتالوگ مدل Azure AI Foundry برای استقرار SLM در سطح سازمانی، همراه با نمونه‌های کد برای دانلود برنامه‌ریزی‌شده مدل، اعتبارسنجی و تبدیل فرمت
- **APIهای توسعه‌دهنده**: نمونه‌های کد در زبان‌های Python، C++ و C# که نشان می‌دهد چگونه مدل‌ها را بارگذاری کنید، استنتاج انجام دهید و با چارچوب‌های محبوب مانند PyTorch، TensorFlow و ONNX Runtime ادغام کنید

این بخش پایه‌ای بر تعادل بین کارایی عملیاتی، انعطاف‌پذیری استقرار و مقرون‌به‌صرفه بودن تأکید دارد که SLMها را برای سناریوهای محاسبات لبه ایده‌آل می‌کند، همراه با مثال‌های کدنویسی عملی که توسعه‌دهندگان می‌توانند مستقیماً در پروژه‌های خود پیاده‌سازی کنند.

### **[بخش ۲: استقرار در محیط محلی - راه‌حل‌های اولویت‌دار حریم خصوصی](./02.DeployingSLMinLocalEnv.md)**
بخش دوم از نظریه به پیاده‌سازی عملی منتقل می‌شود و بر استراتژی‌های استقرار محلی که حاکمیت داده و استقلال عملیاتی را در اولویت قرار می‌دهند، تمرکز دارد. موضوعات کلیدی شامل موارد زیر است:

- **پلتفرم جهانی Ollama**: بررسی جامع استقرار چندپلتفرمی با تأکید بر جریان‌های کاری دوستانه برای توسعه‌دهندگان، مدیریت چرخه عمر مدل و سفارشی‌سازی از طریق Modelfiles، شامل مثال‌های کامل ادغام REST API و اسکریپت‌های خودکار CLI
- **Microsoft Foundry Local**: راه‌حل‌های استقرار در سطح سازمانی با بهینه‌سازی مبتنی بر ONNX، ادغام Windows ML و ویژگی‌های امنیتی جامع، همراه با نمونه‌های کد C# و Python برای ادغام برنامه‌های بومی
- **تحلیل مقایسه‌ای**: مقایسه دقیق چارچوب‌ها شامل معماری فنی، ویژگی‌های عملکردی و دستورالعمل‌های بهینه‌سازی موارد استفاده، همراه با کد بنچمارک برای ارزیابی سرعت استنتاج و استفاده از حافظه در سخت‌افزارهای مختلف
- **ادغام API**: برنامه‌های نمونه که نشان می‌دهند چگونه خدمات وب، برنامه‌های چت و خطوط پردازش داده را با استقرار محلی SLM بسازید، همراه با نمونه‌های کد در Node.js، Python Flask/FastAPI و ASP.NET Core
- **چارچوب‌های تست**: رویکردهای تست خودکار برای تضمین کیفیت مدل، شامل مثال‌های تست واحد و تست یکپارچه برای پیاده‌سازی SLM

این بخش راهنمای عملی برای سازمان‌هایی ارائه می‌دهد که به دنبال پیاده‌سازی راه‌حل‌های هوش مصنوعی حفظ‌کننده حریم خصوصی هستند و در عین حال کنترل کامل بر محیط استقرار خود را حفظ می‌کنند، همراه با نمونه‌های کد آماده استفاده که توسعه‌دهندگان می‌توانند به نیازهای خاص خود تطبیق دهند.

### **[بخش ۳: استقرار کانتینری در فضای ابری - راه‌حل‌های در مقیاس تولید](./03.DeployingSLMinCloud.md)**
بخش نهایی به استراتژی‌های پیشرفته استقرار کانتینری می‌پردازد و مدل Phi-4-mini-instruct مایکروسافت را به عنوان مطالعه موردی اصلی معرفی می‌کند. این بخش شامل موارد زیر است:

- **استقرار vLLM**: بهینه‌سازی استنتاج با عملکرد بالا با APIهای سازگار با OpenAI، شتاب‌دهی پیشرفته GPU و پیکربندی آماده تولید، شامل Dockerfileهای کامل، مانیفست‌های Kubernetes و پارامترهای تنظیم عملکرد
- **ارکستراسیون کانتینری Ollama**: جریان‌های کاری ساده استقرار با Docker Compose، انواع بهینه‌سازی مدل و ادغام رابط کاربری وب، همراه با مثال‌های CI/CD برای استقرار و تست خودکار
- **پیاده‌سازی ONNX Runtime**: استقرار بهینه‌شده برای لبه با تبدیل جامع مدل، استراتژی‌های کوانتیزاسیون و سازگاری چندپلتفرمی، شامل نمونه‌های کد دقیق برای بهینه‌سازی و استقرار مدل
- **نظارت و مشاهده‌پذیری**: پیاده‌سازی داشبوردهای Prometheus/Grafana با معیارهای سفارشی برای نظارت بر عملکرد SLM، شامل تنظیمات هشدار و تجمیع لاگ‌ها
- **تعادل بار و مقیاس‌پذیری**: مثال‌های عملی از استراتژی‌های مقیاس‌پذیری افقی و عمودی با تنظیمات خودکار بر اساس استفاده از CPU/GPU و الگوهای درخواست
- **تقویت امنیت**: بهترین روش‌های امنیت کانتینر شامل کاهش امتیازات، سیاست‌های شبکه و مدیریت اسرار برای کلیدهای API و اعتبارنامه‌های دسترسی به مدل

هر رویکرد استقرار با مثال‌های کامل پیکربندی، روش‌های تست، چک‌لیست‌های آمادگی تولید و قالب‌های زیرساخت به‌عنوان کد ارائه شده است که توسعه‌دهندگان می‌توانند مستقیماً در جریان‌های کاری استقرار خود اعمال کنند.

## نتایج کلیدی یادگیری

با تکمیل این فصل، خوانندگان مهارت‌های زیر را کسب خواهند کرد:

1. **انتخاب استراتژیک مدل**: درک مرزهای پارامتر و انتخاب SLMهای مناسب بر اساس محدودیت‌های منابع و نیازهای عملکردی
2. **تسلط بر بهینه‌سازی**: پیاده‌سازی تکنیک‌های پیشرفته کوانتیزاسیون در چارچوب‌های مختلف برای دستیابی به تعادل بهینه بین عملکرد و کارایی
3. **انعطاف‌پذیری استقرار**: انتخاب بین راه‌حل‌های محلی حفظ‌کننده حریم خصوصی و استقرار کانتینری مقیاس‌پذیر بر اساس نیازهای سازمانی
4. **آمادگی تولید**: پیکربندی سیستم‌های نظارت، امنیت و مقیاس‌پذیری برای استقرار SLM در سطح سازمانی

## تمرکز عملی و کاربردهای دنیای واقعی

این فصل در سراسر خود بر جهت‌گیری عملی قوی تأکید دارد و شامل موارد زیر است:

- **مثال‌های عملی**: فایل‌های پیکربندی کامل، روش‌های تست API و اسکریپت‌های استقرار
- **بنچمارک عملکرد**: مقایسه‌های دقیق سرعت استنتاج، استفاده از حافظه و نیازهای منابع
- **ملاحظات امنیتی**: روش‌های امنیتی در سطح سازمانی، چارچوب‌های انطباق و استراتژی‌های حفاظت از داده
- **بهترین روش‌ها**: دستورالعمل‌های اثبات‌شده برای نظارت، مقیاس‌پذیری و نگهداری

## چشم‌انداز آینده‌نگر

فصل با بینش‌های آینده‌نگر درباره روندهای نوظهور به پایان می‌رسد، از جمله:

- معماری‌های پیشرفته مدل با نسبت‌های کارایی بهبود‌یافته
- ادغام عمیق‌تر سخت‌افزار با شتاب‌دهنده‌های تخصصی هوش مصنوعی
- تکامل اکوسیستم به سمت استانداردسازی و قابلیت همکاری
- الگوهای پذیرش سازمانی تحت تأثیر حریم خصوصی و الزامات انطباق

این رویکرد جامع تضمین می‌کند که خوانندگان برای مقابله با چالش‌های فعلی استقرار SLM و تحولات تکنولوژیکی آینده آماده هستند و تصمیمات آگاهانه‌ای می‌گیرند که با نیازها و محدودیت‌های خاص سازمانی آن‌ها همسو باشد.

این فصل به عنوان یک راهنمای عملی برای پیاده‌سازی فوری و یک منبع استراتژیک برای برنامه‌ریزی استقرار بلندمدت هوش مصنوعی عمل می‌کند و بر تعادل حیاتی بین قابلیت، کارایی و برتری عملیاتی که استقرار موفق SLM را تعریف می‌کند، تأکید دارد.

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.