<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T12:13:56+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "fa"
}
-->
# EdgeAI برای مبتدیان: مسیرهای یادگیری و برنامه مطالعه

### مسیر یادگیری فشرده (1 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 1 | ماژول 1: اصول EdgeAI | 3 ساعت |
| روز 2 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 3 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 4-5 | ماژول 4: بهینه‌سازی مدل (6 چارچوب) | 4 ساعت |
| روز 6 | ماژول 5: SLMOps | 3 ساعت |
| روز 7 | ماژول 6-7: عوامل هوش مصنوعی و ابزارهای توسعه | 4 ساعت |
| روز 8 | ماژول 8: ابزار محلی Foundry (پیاده‌سازی مدرن) | 1 ساعت |

### مسیر یادگیری فشرده (2 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 1-2 | ماژول 1: اصول EdgeAI | 3 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 5-6 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 7-8 | ماژول 4: بهینه‌سازی مدل | 4 ساعت |
| روز 9-10 | ماژول 5: SLMOps | 3 ساعت |
| روز 11-12 | ماژول 6: عوامل هوش مصنوعی | 2 ساعت |
| روز 13-14 | ماژول 7: ابزارهای توسعه | 3 ساعت |

### مطالعه نیمه‌وقت (4 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 1-2: اصول و مبانی SLM | 6 ساعت |
| هفته 2 | ماژول 3-4: استقرار و بهینه‌سازی | 6 ساعت |
| هفته 3 | ماژول 5-6: SLMOps و عوامل هوش مصنوعی | 5 ساعت |
| هفته 4 | ماژول 7: ابزارهای توسعه و یکپارچه‌سازی | 3 ساعت |

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 1-2 | ماژول 1: اصول EdgeAI | 3 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 5-6 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 7-8 | ماژول 4: بهینه‌سازی مدل | 4 ساعت |
| روز 9-10 | ماژول 5: SLMOps | 3 ساعت |
| روز 11-12 | ماژول 6: سیستم‌های عامل SLM | 2 ساعت |
| روز 13-14 | ماژول 7: نمونه‌های پیاده‌سازی EdgeAI | 2 ساعت |

| ماژول | تاریخ تکمیل | ساعات صرف شده | نکات کلیدی |
|--------|----------------|-------------|--------------|
| ماژول 1: اصول EdgeAI | | | |
| ماژول 2: مبانی SLM | | | |
| ماژول 3: استقرار SLM | | | |
| ماژول 4: بهینه‌سازی مدل (6 چارچوب) | | | |
| ماژول 5: SLMOps | | | |
| ماژول 6: سیستم‌های عامل SLM | | | |
| ماژول 7: نمونه‌های پیاده‌سازی EdgeAI | | | |
| تمرین‌های عملی | | | |
| پروژه کوچک | | | |

### مطالعه نیمه‌وقت (4 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 1-2: اصول و مبانی SLM | 6 ساعت |
| هفته 2 | ماژول 3-4: استقرار و بهینه‌سازی | 6 ساعت |
| هفته 3 | ماژول 5-6: SLMOps و عوامل هوش مصنوعی | 5 ساعت |
| هفته 4 | ماژول 7: ابزارهای توسعه و یکپارچه‌سازی | 3 ساعت |

## مقدمه

به راهنمای مطالعه EdgeAI برای مبتدیان خوش آمدید! این سند طراحی شده است تا به شما کمک کند مواد دوره را به طور مؤثر مرور کنید و تجربه یادگیری خود را به حداکثر برسانید. این راهنما مسیرهای یادگیری ساختاریافته، برنامه‌های مطالعه پیشنهادی، خلاصه مفاهیم کلیدی و منابع تکمیلی را برای درک عمیق‌تر فناوری‌های EdgeAI ارائه می‌دهد.

این دوره مختصر 20 ساعته، دانش ضروری درباره EdgeAI را در قالبی کارآمد ارائه می‌دهد و برای حرفه‌ای‌ها و دانشجویان پرمشغله‌ای که می‌خواهند به سرعت مهارت‌های عملی در این حوزه نوظهور کسب کنند، مناسب است.

## نمای کلی دوره

این دوره به هفت ماژول جامع تقسیم شده است:

1. **اصول و تحول EdgeAI** - درک مفاهیم اصلی و تغییرات فناوری
2. **مبانی مدل‌های کوچک زبانی (SLM)** - بررسی خانواده‌های مختلف SLM و معماری‌های آنها
3. **استقرار مدل‌های کوچک زبانی (SLM)** - پیاده‌سازی استراتژی‌های عملی استقرار
4. **تبدیل فرمت مدل و کوانتیزاسیون** - بهینه‌سازی پیشرفته با 6 چارچوب از جمله OpenVINO
5. **SLMOps - عملیات مدل‌های کوچک زبانی** - مدیریت چرخه تولید و استقرار
6. **سیستم‌های عامل SLM** - عوامل هوش مصنوعی، فراخوانی توابع و پروتکل زمینه مدل
7. **نمونه‌های پیاده‌سازی EdgeAI** - ابزارهای هوش مصنوعی، توسعه در ویندوز و پیاده‌سازی‌های خاص پلتفرم
8. **Microsoft Foundry Local – ابزار کامل توسعه‌دهنده** - توسعه محلی با یکپارچه‌سازی هیبریدی Azure (ماژول 08)

## نحوه استفاده از این راهنمای مطالعه

- **یادگیری تدریجی**: برای تجربه یادگیری منسجم‌تر، ماژول‌ها را به ترتیب دنبال کنید.
- **نقاط بررسی دانش**: از سوالات ارزیابی خود پس از هر بخش استفاده کنید.
- **تمرین عملی**: تمرین‌های پیشنهادی را برای تقویت مفاهیم نظری انجام دهید.
- **منابع تکمیلی**: مواد اضافی را برای موضوعاتی که بیشتر به آنها علاقه دارید، بررسی کنید.

## توصیه‌های برنامه مطالعه

### مسیر یادگیری فشرده (1 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|-----------------|
| روز 1-2 | ماژول 1: اصول EdgeAI | 6 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 8 ساعت |
| روز 5 | ماژول 3: استقرار SLM | 3 ساعت |
| روز 6 | ماژول 8: ابزار محلی Foundry | 3 ساعت |

### مطالعه نیمه‌وقت (3 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|-----------------|
| هفته 1 | ماژول 1: اصول EdgeAI | 6-7 ساعت |
| هفته 2 | ماژول 2: مبانی SLM | 7-8 ساعت |
| هفته 3 | ماژول 3: استقرار SLM (3 ساعت) + ماژول 8: ابزار محلی Foundry (2-3 ساعت) | 5-6 ساعت |

## ماژول 1: اصول و تحول EdgeAI

### اهداف کلیدی یادگیری

- تفاوت‌های بین هوش مصنوعی مبتنی بر ابر و مبتنی بر لبه را درک کنید.
- تکنیک‌های بهینه‌سازی اصلی برای محیط‌های محدود منابع را بیاموزید.
- کاربردهای واقعی فناوری‌های EdgeAI را تحلیل کنید.
- محیط توسعه برای پروژه‌های EdgeAI را راه‌اندازی کنید.

### حوزه‌های تمرکز مطالعه

#### بخش 1: اصول EdgeAI
- **مفاهیم اولویت‌دار**: 
  - پارادایم‌های محاسباتی لبه در مقابل ابر
  - تکنیک‌های کوانتیزاسیون مدل
  - گزینه‌های شتاب‌دهی سخت‌افزاری (NPUs، GPUs، CPUs)
  - مزایای حریم خصوصی و امنیت

- **مواد تکمیلی**:
  - [مستندات TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [مستندات Edge Impulse](https://docs.edgeimpulse.com)

#### بخش 2: مطالعات موردی واقعی
- **مفاهیم اولویت‌دار**: 
  - اکوسیستم مدل‌های Microsoft Phi & Mu
  - پیاده‌سازی‌های عملی در صنایع مختلف
  - ملاحظات استقرار

#### بخش 3: راهنمای پیاده‌سازی عملی
- **مفاهیم اولویت‌دار**: 
  - راه‌اندازی محیط توسعه
  - ابزارهای کوانتیزاسیون و بهینه‌سازی
  - روش‌های ارزیابی برای پیاده‌سازی‌های EdgeAI

#### بخش 4: سخت‌افزار استقرار لبه
- **مفاهیم اولویت‌دار**: 
  - مقایسه پلتفرم‌های سخت‌افزاری
  - استراتژی‌های بهینه‌سازی برای سخت‌افزار خاص
  - ملاحظات استقرار

### سوالات ارزیابی خود

1. تفاوت‌ها و شباهت‌های هوش مصنوعی مبتنی بر ابر و مبتنی بر لبه را مقایسه کنید.
2. سه تکنیک کلیدی برای بهینه‌سازی مدل‌ها برای استقرار لبه را توضیح دهید.
3. مزایای اصلی اجرای مدل‌های هوش مصنوعی در لبه چیست؟
4. فرآیند کوانتیزاسیون مدل را توضیح دهید و تأثیر آن بر عملکرد را شرح دهید.
5. توضیح دهید که چگونه شتاب‌دهنده‌های سخت‌افزاری مختلف (NPUs، GPUs، CPUs) بر استقرار EdgeAI تأثیر می‌گذارند.

### تمرین‌های عملی

1. **راه‌اندازی سریع محیط**: یک محیط توسعه حداقلی با بسته‌های ضروری پیکربندی کنید (30 دقیقه)
2. **بررسی مدل**: یک مدل کوچک زبانی پیش‌آموزش‌یافته را دانلود و بررسی کنید (1 ساعت)
3. **کوانتیزاسیون پایه**: کوانتیزاسیون ساده را روی یک مدل کوچک امتحان کنید (1 ساعت)

## ماژول 2: مبانی مدل‌های کوچک زبانی

### اهداف کلیدی یادگیری

- اصول معماری خانواده‌های مختلف SLM را درک کنید.
- قابلیت‌های مدل‌ها را در مقیاس‌های مختلف پارامتر مقایسه کنید.
- مدل‌ها را بر اساس کارایی، قابلیت و نیازهای استقرار ارزیابی کنید.
- موارد استفاده مناسب برای خانواده‌های مختلف مدل را شناسایی کنید.

### حوزه‌های تمرکز مطالعه

#### بخش 1: خانواده مدل Microsoft Phi
- **مفاهیم اولویت‌دار**: 
  - تکامل فلسفه طراحی
  - معماری کارایی‌محور
  - قابلیت‌های تخصصی

#### بخش 2: خانواده Qwen
- **مفاهیم اولویت‌دار**: 
  - مشارکت‌های متن‌باز
  - گزینه‌های استقرار مقیاس‌پذیر
  - معماری استدلال پیشرفته

#### بخش 3: خانواده Gemma
- **مفاهیم اولویت‌دار**: 
  - نوآوری مبتنی بر تحقیق
  - قابلیت‌های چندوجهی
  - بهینه‌سازی موبایل

#### بخش 4: خانواده BitNET
- **مفاهیم اولویت‌دار**: 
  - فناوری کوانتیزاسیون 1 بیتی
  - چارچوب بهینه‌سازی استنتاج
  - ملاحظات پایداری

#### بخش 5: مدل Microsoft Mu
- **مفاهیم اولویت‌دار**: 
  - معماری دستگاه‌محور
  - یکپارچه‌سازی سیستم با ویندوز
  - عملیات حفظ حریم خصوصی

#### بخش 6: Phi-Silica
- **مفاهیم اولویت‌دار**: 
  - معماری بهینه‌شده برای NPU
  - معیارهای عملکرد
  - یکپارچه‌سازی توسعه‌دهنده

### سوالات ارزیابی خود

1. رویکردهای معماری خانواده‌های مدل Phi و Qwen را مقایسه کنید.
2. توضیح دهید که فناوری کوانتیزاسیون BitNET چگونه با کوانتیزاسیون سنتی متفاوت است.
3. مزایای منحصر به فرد مدل Mu برای یکپارچه‌سازی ویندوز چیست؟
4. توضیح دهید که چگونه Phi-Silica از سخت‌افزار NPU برای بهینه‌سازی عملکرد استفاده می‌کند.
5. برای یک برنامه موبایل با اتصال محدود، کدام خانواده مدل مناسب‌تر است و چرا؟

### تمرین‌های عملی

1. **مقایسه مدل‌ها**: بنچمارک سریع دو مدل SLM مختلف (1 ساعت)
2. **تولید متن ساده**: پیاده‌سازی پایه تولید متن با یک مدل کوچک (1 ساعت)
3. **بهینه‌سازی سریع**: یک تکنیک بهینه‌سازی را برای بهبود سرعت استنتاج اعمال کنید (1 ساعت)

## ماژول 3: استقرار مدل‌های کوچک زبانی

### اهداف کلیدی یادگیری

- مدل‌های مناسب را بر اساس محدودیت‌های استقرار انتخاب کنید.
- تکنیک‌های بهینه‌سازی برای سناریوهای مختلف استقرار را بیاموزید.
- SLM‌ها را در محیط‌های محلی و ابری پیاده‌سازی کنید.
- پیکربندی‌های آماده تولید برای برنامه‌های EdgeAI طراحی کنید.

### حوزه‌های تمرکز مطالعه

#### بخش 1: یادگیری پیشرفته SLM
- **مفاهیم اولویت‌دار**: 
  - چارچوب طبقه‌بندی پارامترها
  - تکنیک‌های بهینه‌سازی پیشرفته
  - استراتژی‌های کسب مدل

#### بخش 2: استقرار محیط محلی
- **مفاهیم اولویت‌دار**: 
  - استقرار پلتفرم Ollama
  - راه‌حل‌های محلی Microsoft Foundry
  - تحلیل مقایسه‌ای چارچوب‌ها

#### بخش 3: استقرار ابری کانتینری‌شده
- **مفاهیم اولویت‌دار**: 
  - استنتاج با کارایی بالا vLLM
  - ارکستراسیون کانتینرها
  - پیاده‌سازی ONNX Runtime

### سوالات ارزیابی خود

1. چه عواملی باید هنگام انتخاب بین استقرار محلی و استقرار ابری در نظر گرفته شوند؟
2. Ollama و Microsoft Foundry Local را به عنوان گزینه‌های استقرار مقایسه کنید.
3. مزایای کانتینری‌شدن برای استقرار SLM چیست؟
4. معیارهای کلیدی عملکرد برای نظارت بر یک SLM مستقر در لبه چیست؟
5. یک جریان کاری کامل استقرار از انتخاب مدل تا پیاده‌سازی تولید را توضیح دهید.

### تمرین‌های عملی

1. **استقرار محلی پایه**: یک SLM ساده را با استفاده از Ollama مستقر کنید (1 ساعت)
2. **بررسی عملکرد**: یک بنچمارک سریع روی مدل مستقر شده خود اجرا کنید (30 دقیقه)
3. **یکپارچه‌سازی ساده**: یک برنامه حداقلی ایجاد کنید که از مدل مستقر شده شما استفاده کند (1 ساعت)

## ماژول 4: تبدیل فرمت مدل و کوانتیزاسیون

### اهداف کلیدی یادگیری

- تکنیک‌های پیشرفته کوانتیزاسیون از دقت 1 بیتی تا 8 بیتی را بیاموزید.
- استراتژی‌های تبدیل فرمت (GGUF، ONNX) را درک کنید.
- بهینه‌سازی را در شش چارچوب (Llama.cpp، Olive، OpenVINO، MLX، سنتز جریان کاری) پیاده‌سازی کنید.
- مدل‌های بهینه‌شده را برای محیط‌های تولید لبه در سخت‌افزارهای Intel، Apple و چندپلتفرمی مستقر کنید.

### حوزه‌های تمرکز مطالعه

#### بخش 1: مبانی کوانتیزاسیون
- **مفاهیم اولویت‌دار**: 
  - چارچوب طبقه‌بندی دقت
  - توازن عملکرد در مقابل دقت
  - بهینه‌سازی حافظه

#### بخش 2: پیاده‌سازی Llama.cpp
- **مفاهیم اولویت‌دار**: 
  - استقرار چندپلتفرمی
  - بهینه‌سازی فرمت GGUF
  - تکنیک‌های شتاب‌دهی سخت‌افزاری

#### بخش 3: مجموعه Microsoft Olive
- **مفاهیم اولویت‌دار**: 
  - بهینه‌سازی آگاه به سخت‌افزار
  - استقرار در سطح سازمانی
  - جریان‌های کاری بهینه‌سازی خودکار

#### بخش 4: ابزار OpenVINO
- **مفاهیم اولویت‌دار**: 
  - بهینه‌سازی سخت‌افزار Intel
  - چارچوب فشرده‌سازی شبکه عصبی (NNCF)
  - استقرار استنتاج چندپلتفرمی
- OpenVINO GenAI برای استقرار LLM

#### بخش ۵: چارچوب Apple MLX
- **مفاهیم اولویت‌دار**: 
  - بهینه‌سازی Apple Silicon
  - معماری حافظه یکپارچه
  - قابلیت‌های تنظیم دقیق LoRA

#### بخش ۶: ترکیب جریان کاری توسعه Edge AI
- **مفاهیم اولویت‌دار**: 
  - معماری جریان کاری یکپارچه
  - درخت‌های تصمیم‌گیری انتخاب چارچوب
  - اعتبارسنجی آمادگی تولید
  - استراتژی‌های آینده‌نگر

### سوالات ارزیابی خود

1. استراتژی‌های کم‌دقتی را در سطوح مختلف دقت (۱ بیت تا ۸ بیت) مقایسه کنید.
2. مزایای فرمت GGUF برای استقرار در لبه را توضیح دهید.
3. چگونه بهینه‌سازی مبتنی بر سخت‌افزار در Microsoft Olive کارایی استقرار را بهبود می‌بخشد؟
4. مزایای کلیدی NNCF در OpenVINO برای فشرده‌سازی مدل چیست؟
5. توضیح دهید که چگونه Apple MLX از معماری حافظه یکپارچه برای بهینه‌سازی استفاده می‌کند.
6. ترکیب جریان کاری چگونه به انتخاب چارچوب‌های بهینه‌سازی کمک می‌کند؟

### تمرین‌های عملی

1. **کم‌دقتی مدل**: سطوح مختلف کم‌دقتی را روی یک مدل اعمال کنید و نتایج را مقایسه کنید (۱ ساعت)
2. **بهینه‌سازی OpenVINO**: از NNCF برای فشرده‌سازی یک مدل برای سخت‌افزار Intel استفاده کنید (۱ ساعت)
3. **مقایسه چارچوب‌ها**: یک مدل را در سه چارچوب بهینه‌سازی مختلف آزمایش کنید (۱ ساعت)
4. **معیارهای عملکرد**: تاثیر بهینه‌سازی بر سرعت استنتاج و استفاده از حافظه را اندازه‌گیری کنید (۱ ساعت)

## ماژول ۵: SLMOps - عملیات مدل‌های زبان کوچک

### اهداف کلیدی یادگیری

- اصول مدیریت چرخه عمر SLMOps را درک کنید
- تکنیک‌های تقطیر و تنظیم دقیق برای استقرار در لبه را بیاموزید
- استراتژی‌های استقرار تولید با نظارت را اجرا کنید
- جریان‌های کاری عملیات و نگهداری SLM در سطح سازمانی بسازید

### حوزه‌های تمرکز مطالعه

#### بخش ۱: معرفی SLMOps
- **مفاهیم اولویت‌دار**: 
  - تغییر پارادایم SLMOps در عملیات هوش مصنوعی
  - معماری مقرون‌به‌صرفه و اولویت‌دار برای حفظ حریم خصوصی
  - تاثیر استراتژیک بر کسب‌وکار و مزایای رقابتی

#### بخش ۲: تقطیر مدل
- **مفاهیم اولویت‌دار**: 
  - تکنیک‌های انتقال دانش
  - اجرای فرآیند تقطیر دو مرحله‌ای
  - جریان‌های کاری تقطیر Azure ML

#### بخش ۳: استراتژی‌های تنظیم دقیق
- **مفاهیم اولویت‌دار**: 
  - تنظیم دقیق کارآمد پارامترها (PEFT)
  - روش‌های پیشرفته LoRA و QLoRA
  - آموزش چند آداپتری و بهینه‌سازی هایپرپارامترها

#### بخش ۴: استقرار تولید
- **مفاهیم اولویت‌دار**: 
  - تبدیل و کم‌دقتی مدل برای تولید
  - پیکربندی استقرار Foundry Local
  - معیارهای عملکرد و اعتبارسنجی کیفیت

### سوالات ارزیابی خود

1. SLMOps چگونه با MLOps سنتی تفاوت دارد؟
2. مزایای تقطیر مدل برای استقرار در لبه چیست؟
3. ملاحظات کلیدی برای تنظیم دقیق SLM‌ها در محیط‌های محدود منابع چیست؟
4. یک خط لوله کامل استقرار تولید برای برنامه‌های هوش مصنوعی لبه را توضیح دهید.

### تمرین‌های عملی

1. **تقطیر پایه**: یک مدل کوچک‌تر از یک مدل معلم بزرگ‌تر ایجاد کنید (۱ ساعت)
2. **آزمایش تنظیم دقیق**: یک مدل را برای یک حوزه خاص تنظیم دقیق کنید (۱ ساعت)
3. **خط لوله استقرار**: یک خط لوله CI/CD پایه برای استقرار مدل تنظیم کنید (۱ ساعت)

## ماژول ۶: سیستم‌های عامل SLM - عوامل هوش مصنوعی و فراخوانی توابع

### اهداف کلیدی یادگیری

- عوامل هوش مصنوعی هوشمند برای محیط‌های لبه با استفاده از مدل‌های زبان کوچک بسازید
- قابلیت‌های فراخوانی توابع را با جریان‌های کاری سیستماتیک اجرا کنید
- پروتکل زمینه مدل (MCP) را برای تعامل استاندارد ابزارها ادغام کنید
- سیستم‌های عامل پیچیده با حداقل مداخله انسانی ایجاد کنید

### حوزه‌های تمرکز مطالعه

#### بخش ۱: عوامل هوش مصنوعی و مبانی SLM
- **مفاهیم اولویت‌دار**: 
  - چارچوب طبقه‌بندی عوامل (بازتابی، مبتنی بر مدل، مبتنی بر هدف، عوامل یادگیری)
  - تحلیل مبادلات SLM در مقابل LLM
  - الگوهای طراحی عامل خاص لبه
  - بهینه‌سازی منابع برای عوامل

#### بخش ۲: فراخوانی توابع در مدل‌های زبان کوچک
- **مفاهیم اولویت‌دار**: 
  - اجرای جریان کاری سیستماتیک (تشخیص قصد، خروجی JSON، اجرای خارجی)
  - پیاده‌سازی‌های خاص پلتفرم (Phi-4-mini، مدل‌های منتخب Qwen، Microsoft Foundry Local)
  - مثال‌های پیشرفته (همکاری چند عامل، انتخاب ابزار پویا)
  - ملاحظات تولید (محدودیت نرخ، ثبت ممیزی، اقدامات امنیتی)

#### بخش ۳: ادغام پروتکل زمینه مدل (MCP)
- **مفاهیم اولویت‌دار**: 
  - معماری پروتکل و طراحی سیستم لایه‌ای
  - پشتیبانی چند بک‌اند (Ollama برای توسعه، vLLM برای تولید)
  - پروتکل‌های اتصال (حالت‌های STDIO و SSE)
  - کاربردهای واقعی (اتوماسیون وب، پردازش داده، ادغام API)

### سوالات ارزیابی خود

1. ملاحظات کلیدی معماری برای عوامل هوش مصنوعی لبه چیست؟
2. فراخوانی توابع چگونه قابلیت‌های عامل را افزایش می‌دهد؟
3. نقش پروتکل زمینه مدل در ارتباط عامل چیست؟

### تمرین‌های عملی

1. **عامل ساده**: یک عامل هوش مصنوعی پایه با فراخوانی توابع بسازید (۱ ساعت)
2. **ادغام MCP**: MCP را در یک برنامه عامل اجرا کنید (۳۰ دقیقه)

## ماژول ۷: نمونه‌های پیاده‌سازی EdgeAI

### اهداف کلیدی یادگیری

- ابزار هوش مصنوعی برای Visual Studio Code را برای جریان‌های کاری جامع توسعه EdgeAI بیاموزید
- تخصص در پلتفرم Windows AI Foundry و استراتژی‌های بهینه‌سازی NPU کسب کنید
- EdgeAI را در چندین پلتفرم سخت‌افزاری و سناریوهای استقرار پیاده‌سازی کنید
- برنامه‌های EdgeAI آماده تولید با بهینه‌سازی‌های خاص پلتفرم بسازید

### حوزه‌های تمرکز مطالعه

#### بخش ۱: ابزار هوش مصنوعی برای Visual Studio Code
- **مفاهیم اولویت‌دار**: 
  - محیط توسعه جامع Edge AI در VS Code
  - کاتالوگ مدل و کشف برای استقرار در لبه
  - جریان‌های کاری آزمایش محلی، بهینه‌سازی و توسعه عامل
  - نظارت بر عملکرد و ارزیابی برای سناریوهای لبه

#### بخش ۲: راهنمای توسعه Windows EdgeAI
- **مفاهیم اولویت‌دار**: 
  - نمای کلی جامع پلتفرم Windows AI Foundry
  - API Phi Silica برای استنتاج کارآمد NPU
  - API‌های بینایی کامپیوتری برای پردازش تصویر و OCR
  - CLI Foundry Local برای توسعه و آزمایش محلی

#### بخش ۳: پیاده‌سازی‌های خاص پلتفرم
- **مفاهیم اولویت‌دار**: 
  - استقرار NVIDIA Jetson Orin Nano (عملکرد هوش مصنوعی ۶۷ TOPS)
  - برنامه‌های موبایل با .NET MAUI و ONNX Runtime GenAI
  - راه‌حل‌های Azure EdgeAI با معماری ترکیبی ابر-لبه
  - بهینه‌سازی Windows ML با پشتیبانی سخت‌افزاری جهانی
  - برنامه‌های Foundry Local با پیاده‌سازی RAG متمرکز بر حفظ حریم خصوصی

### سوالات ارزیابی خود

1. ابزار هوش مصنوعی چگونه جریان کاری توسعه EdgeAI را ساده می‌کند؟
2. استراتژی‌های استقرار را در پلتفرم‌های سخت‌افزاری مختلف مقایسه کنید.
3. مزایای Windows AI Foundry برای توسعه لبه چیست؟
4. نقش بهینه‌سازی NPU در برنامه‌های هوش مصنوعی مدرن لبه چیست؟
5. API Phi Silica چگونه از سخت‌افزار NPU برای بهینه‌سازی عملکرد استفاده می‌کند؟
6. مزایای استقرار محلی در مقابل ابر برای برنامه‌های حساس به حفظ حریم خصوصی چیست؟

### تمرین‌های عملی

1. **تنظیم ابزار هوش مصنوعی**: ابزار هوش مصنوعی را پیکربندی کنید و یک مدل را بهینه کنید (۱ ساعت)
2. **Windows AI Foundry**: یک برنامه هوش مصنوعی ساده Windows با استفاده از API Phi Silica بسازید (۱ ساعت)
3. **استقرار چند پلتفرمی**: یک مدل را در دو پلتفرم مختلف مستقر کنید (۱ ساعت)
4. **بهینه‌سازی NPU**: عملکرد NPU را با ابزارهای Windows AI Foundry آزمایش کنید (۳۰ دقیقه)

## ماژول ۸: Microsoft Foundry Local – مجموعه ابزار کامل توسعه‌دهنده (مدرن شده)

### اهداف کلیدی یادگیری

- Foundry Local را با ادغام SDK مدرن نصب و پیکربندی کنید
- سیستم‌های چند عاملی پیشرفته با الگوهای هماهنگ‌کننده اجرا کنید
- مسیریاب‌های مدل هوشمند با انتخاب خودکار مبتنی بر وظیفه بسازید
- راه‌حل‌های هوش مصنوعی آماده تولید با نظارت جامع مستقر کنید
- با Azure AI Foundry برای سناریوهای استقرار ترکیبی ادغام کنید
- الگوهای SDK مدرن را با FoundryLocalManager و کلاینت OpenAI بیاموزید

### حوزه‌های تمرکز مطالعه

#### بخش ۱: نصب و پیکربندی مدرن
- **مفاهیم اولویت‌دار**: 
  - ادغام SDK FoundryLocalManager
  - کشف خودکار سرویس و نظارت بر سلامت
  - الگوهای پیکربندی مبتنی بر محیط
  - ملاحظات استقرار تولید

#### بخش ۲: سیستم‌های چند عاملی پیشرفته
- **مفاهیم اولویت‌دار**: 
  - الگوی هماهنگ‌کننده با عوامل متخصص
  - تخصص عوامل در بازیابی، استدلال و اجرا
  - مکانیسم‌های حلقه بازخورد برای اصلاح
  - نظارت بر عملکرد و ردیابی آمار

#### بخش ۳: مسیریابی مدل هوشمند
- **مفاهیم اولویت‌دار**: 
  - الگوریتم‌های انتخاب مدل مبتنی بر کلمات کلیدی
  - پشتیبانی از مدل‌های متعدد (عمومی، استدلال، کد، خلاقانه)
  - پیکربندی متغیرهای محیطی برای انعطاف‌پذیری
  - بررسی سلامت سرویس و مدیریت خطا

#### بخش ۴: پیاده‌سازی آماده تولید
- **مفاهیم اولویت‌دار**: 
  - مدیریت خطا و مکانیسم‌های بازگشت جامع
  - نظارت بر درخواست‌ها و ردیابی عملکرد
  - مثال‌های تعاملی Jupyter notebook با معیارها
  - الگوهای ادغام با برنامه‌های موجود

### سوالات ارزیابی خود

1. رویکرد مدرن FoundryLocalManager چگونه با فراخوانی دستی REST تفاوت دارد؟
2. الگوی هماهنگ‌کننده را توضیح دهید و چگونه عوامل متخصص را هماهنگ می‌کند؟
3. مسیریاب هوشمند چگونه مدل‌های مناسب را بر اساس محتوای پرسش انتخاب می‌کند؟
4. اجزای کلیدی یک سیستم عامل هوش مصنوعی آماده تولید چیست؟
5. چگونه نظارت جامع بر سلامت سرویس‌های Foundry Local را اجرا می‌کنید؟
6. مزایای رویکرد مدرن شده در مقابل الگوهای پیاده‌سازی سنتی چیست؟

### تمرین‌های عملی

1. **تنظیم SDK مدرن**: FoundryLocalManager را با کشف خودکار سرویس پیکربندی کنید (۳۰ دقیقه)
2. **سیستم چند عاملی**: هماهنگ‌کننده پیشرفته را با عوامل متخصص اجرا کنید (۳۰ دقیقه)
3. **مسیریابی هوشمند**: مسیریاب مدل را با انواع پرسش‌های مختلف آزمایش کنید (۳۰ دقیقه)
4. **اکتشاف تعاملی**: از Jupyter notebooks برای کشف ویژگی‌های پیشرفته استفاده کنید (۴۵ دقیقه)
5. **استقرار تولید**: الگوهای نظارت و مدیریت خطا را اجرا کنید (۳۰ دقیقه)
6. **ادغام ترکیبی**: سناریوهای بازگشت Azure AI Foundry را پیکربندی کنید (۳۰ دقیقه)

## راهنمای تخصیص زمان

برای کمک به شما در استفاده بهینه از زمان ۲۰ ساعته دوره، در اینجا یک تقسیم‌بندی پیشنهادی آمده است:

| فعالیت | تخصیص زمان | توضیحات |
|--------|------------|---------|
| مطالعه مواد اصلی | ۹ ساعت | تمرکز بر مفاهیم ضروری در هر ماژول |
| تمرین‌های عملی | ۶ ساعت | اجرای عملی تکنیک‌های کلیدی |
| ارزیابی خود | ۲ ساعت | آزمایش درک خود از طریق سوالات و بازتاب |
| پروژه کوچک | ۳ ساعت | اعمال دانش در یک پیاده‌سازی عملی کوچک |

### حوزه‌های تمرکز کلیدی بر اساس محدودیت زمانی

**اگر فقط ۱۰ ساعت دارید:**
- ماژول‌های ۱، ۲ و ۳ را کامل کنید (مفاهیم اصلی EdgeAI)
- حداقل یک تمرین عملی در هر ماژول انجام دهید
- بر درک مفاهیم اصلی به جای جزئیات پیاده‌سازی تمرکز کنید

**اگر می‌توانید ۲۰ ساعت کامل اختصاص دهید:**
- همه هفت ماژول را کامل کنید
- تمرین‌های عملی کلیدی از هر ماژول را انجام دهید
- یک پروژه کوچک از ماژول ۷ کامل کنید
- حداقل ۲-۳ منابع تکمیلی را بررسی کنید

**اگر بیش از ۲۰ ساعت دارید:**
- همه ماژول‌ها را با تمرین‌های دقیق کامل کنید
- چندین پروژه کوچک بسازید
- تکنیک‌های پیشرفته بهینه‌سازی در ماژول ۴ را بررسی کنید
- استقرار تولید را از ماژول ۵ اجرا کنید

## منابع ضروری

این منابع با دقت انتخاب شده‌اند تا بیشترین ارزش را برای زمان مطالعه محدود شما فراهم کنند:

### مستندات ضروری
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - کارآمدترین ابزار بهینه‌سازی مدل
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - سریع‌ترین راه برای استقرار SLM‌ها به صورت محلی
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - مرجع برای یک مدل بهینه‌سازی شده لبه پیشرو
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - ابزار جامع بهینه‌سازی Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - محیط توسعه EdgeAI یکپارچه
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - پلتفرم توسعه EdgeAI خاص Windows

### ابزارهای صرفه‌جویی در زمان
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - دسترسی سریع به مدل و استقرار
- [Gradio](https://www.gradio.app/docs/interface) - توسعه سریع رابط کاربری برای دموهای هوش مصنوعی
- [Microsoft Olive](https://github.com/microsoft/Olive) - بهینه‌سازی مدل ساده شده
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - استنتاج کارآمد CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - چارچوب فشرده‌سازی شبکه عصبی
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - ابزار استقرار مدل زبان بزرگ

## قالب ردیابی پیشرفت

از این قالب ساده برای ردیابی پیشرفت یادگیری خود در طول دوره ۲۰ ساعته استفاده کنید:

| ماژول | تاریخ تکمیل | ساعات صرف شده | نکات کلیدی |
|-------|------------|---------------|------------|
| ماژول ۱: اصول EdgeAI | | | |
| ماژول ۲: مبانی SLM | | | |
| ماژول ۳: استقرار SLM | | | |
| ماژول ۴: بهینه‌سازی مدل | | | |
| ماژول ۵: SLMOps | | | |
| ماژول ۶: عوامل هوش مصنوعی | | | |
| ماژول ۷: ابزارهای توسعه | | | |
| ماژول ۸: مجموعه ابزار Foundry Local | | | |
| تمرین‌های عملی | | | |
| پروژه‌های کوچک | | | |

## ایده‌های پروژه‌های کوچک

برای تمرین مفاهیم EdgeAI، یکی از این پروژه‌ها را انجام دهید (هر کدام طراحی شده‌اند تا ۲ تا ۴ ساعت زمان ببرند):

### پروژه‌های مبتدی (هر کدام ۲-۳ ساعت)
1. **دستیار متنی Edge**: یک ابزار ساده تکمیل متن آفلاین با استفاده از یک مدل زبان کوچک ایجاد کنید.
2. **داشبورد مقایسه مدل‌ها**: یک ابزار بصری ساده برای نمایش معیارهای عملکرد در مدل‌های زبان مختلف بسازید.
3. **آزمایش بهینه‌سازی**: تاثیر سطوح مختلف کوانتیزاسیون را بر روی یک مدل پایه اندازه‌گیری کنید.

### پروژه‌های متوسط (هر کدام ۳-۴ ساعت)
4. **جریان کاری ابزار AI**: از ابزار AI در VS Code برای بهینه‌سازی و استقرار یک مدل از ابتدا تا انتها استفاده کنید.
5. **اپلیکیشن Windows AI Foundry**: یک اپلیکیشن ویندوز با استفاده از API Phi Silica و بهینه‌سازی NPU ایجاد کنید.
6. **استقرار چند پلتفرمی**: همان مدل بهینه‌شده را در ویندوز (OpenVINO) و موبایل (.NET MAUI) مستقر کنید.
7. **عامل فراخوانی توابع**: یک عامل هوش مصنوعی با قابلیت فراخوانی توابع برای سناریوهای Edge بسازید.

### پروژه‌های پیشرفته (هر کدام ۴-۵ ساعت)
8. **خط لوله بهینه‌سازی OpenVINO**: بهینه‌سازی کامل مدل را با استفاده از NNCF و ابزار GenAI پیاده‌سازی کنید.
9. **خط لوله SLMOps**: چرخه کامل مدل از آموزش تا استقرار در Edge را پیاده‌سازی کنید.
10. **سیستم Edge چندمدلی**: چندین مدل تخصصی را که با هم روی سخت‌افزار Edge کار می‌کنند مستقر کنید.
11. **سیستم یکپارچه MCP**: یک سیستم عامل‌محور با استفاده از پروتکل Model Context برای تعامل ابزارها بسازید.

## منابع

- Microsoft Learn (Foundry Local)
  - نمای کلی: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - شروع به کار: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - مرجع CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - ادغام با SDKهای استنتاج: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - نحوه استفاده از Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - کامپایل مدل‌های Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - نمای کلی: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - عوامل (نمای کلی): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- ابزارهای بهینه‌سازی و استنتاج
  - Microsoft Olive (مستندات): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (شروع به کار): https://onnxruntime.ai/docs/get-started/with-python.html
  - ادغام ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (مستندات): https://docs.openvino.ai/2025/index.html
  - Apple MLX (مستندات): https://ml-explore.github.io/mlx/build/html/index.html
- چارچوب‌های استقرار و مدل‌ها
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (مستندات): https://docs.vllm.ai/
  - Ollama (شروع سریع): https://github.com/ollama/ollama#get-started
- ابزارهای توسعه‌دهنده (ویندوز و VS Code)
  - ابزار AI برای VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (نمای کلی): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## جامعه یادگیری

به بحث‌ها بپیوندید و با دیگر یادگیرندگان ارتباط برقرار کنید:
- بحث‌های GitHub در [مخزن EdgeAI برای مبتدیان](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [جامعه فناوری مایکروسافت](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## نتیجه‌گیری

EdgeAI نمایانگر مرزهای پیشرفته پیاده‌سازی هوش مصنوعی است که قابلیت‌های قدرتمند را مستقیماً به دستگاه‌ها می‌آورد و در عین حال نگرانی‌های مهمی مانند حریم خصوصی، تأخیر و اتصال را برطرف می‌کند. این دوره ۲۰ ساعته دانش ضروری و مهارت‌های عملی را برای شروع کار با فناوری‌های EdgeAI به شما ارائه می‌دهد.

این دوره به طور عمدی مختصر و بر مفاهیم مهم متمرکز است، به شما این امکان را می‌دهد که بدون تعهد زمانی زیاد، تخصص ارزشمندی کسب کنید. به یاد داشته باشید که تمرین عملی، حتی با مثال‌های ساده، کلید تقویت آنچه آموخته‌اید است.

یادگیری خوشایند!

---

