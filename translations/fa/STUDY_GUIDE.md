<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T21:20:00+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "fa"
}
-->
# EdgeAI برای مبتدیان: مسیرهای یادگیری و برنامه مطالعه

### مسیر یادگیری متمرکز (1 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 0 | ماژول 0: مقدمه‌ای بر EdgeAI | 1-2 ساعت |
| روز 1 | ماژول 1: اصول اولیه EdgeAI | 3 ساعت |
| روز 2 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 3 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 4-5 | ماژول 4: بهینه‌سازی مدل (6 چارچوب) | 4 ساعت |
| روز 6 | ماژول 5: SLMOps | 3 ساعت |
| روز 7 | ماژول 6-7: عوامل هوش مصنوعی و ابزارهای توسعه | 4 ساعت |
| روز 8 | ماژول 8: ابزار محلی Foundry (پیاده‌سازی مدرن) | 1 ساعت |

### مسیر یادگیری متمرکز (2 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 1-2 | ماژول 1: اصول اولیه EdgeAI | 3 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 5-6 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 7-8 | ماژول 4: بهینه‌سازی مدل | 4 ساعت |
| روز 9-10 | ماژول 5: SLMOps | 3 ساعت |
| روز 11-12 | ماژول 6: عوامل هوش مصنوعی | 2 ساعت |
| روز 13-14 | ماژول 7: ابزارهای توسعه | 3 ساعت |

### مطالعه پاره‌وقت (4 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 1-2: اصول اولیه و مبانی SLM | 6 ساعت |
| هفته 2 | ماژول 3-4: استقرار و بهینه‌سازی | 6 ساعت |
| هفته 3 | ماژول 5-6: SLMOps و عوامل هوش مصنوعی | 5 ساعت |
| هفته 4 | ماژول 7: ابزارهای توسعه و یکپارچه‌سازی | 3 ساعت |

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 0 | ماژول 0: مقدمه‌ای بر EdgeAI | 1-2 ساعت |
| روز 1-2 | ماژول 1: اصول اولیه EdgeAI | 3 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 5-6 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 7-8 | ماژول 4: بهینه‌سازی مدل | 4 ساعت |
| روز 9-10 | ماژول 5: SLMOps | 3 ساعت |
| روز 11-12 | ماژول 6: سیستم‌های عامل SLM | 2 ساعت |
| روز 13-14 | ماژول 7: نمونه‌های پیاده‌سازی EdgeAI | 2 ساعت |

| ماژول | تاریخ تکمیل | ساعات صرف شده | نکات کلیدی |
|--------|----------------|-------------|--------------|
| ماژول 0: مقدمه‌ای بر EdgeAI | | | |
| ماژول 1: اصول اولیه EdgeAI | | | |
| ماژول 2: مبانی SLM | | | |
| ماژول 3: استقرار SLM | | | |
| ماژول 4: بهینه‌سازی مدل (6 چارچوب) | | | |
| ماژول 5: SLMOps | | | |
| ماژول 6: سیستم‌های عامل SLM | | | |
| ماژول 7: نمونه‌های پیاده‌سازی EdgeAI | | | |
| تمرین‌های عملی | | | |
| پروژه کوچک | | | |

### مطالعه پاره‌وقت (4 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 1-2: اصول اولیه و مبانی SLM | 6 ساعت |
| هفته 2 | ماژول 3-4: استقرار و بهینه‌سازی | 6 ساعت |
| هفته 3 | ماژول 5-6: SLMOps و عوامل هوش مصنوعی | 5 ساعت |
| هفته 4 | ماژول 7: ابزارهای توسعه و یکپارچه‌سازی | 3 ساعت |

## مقدمه

به راهنمای مطالعه EdgeAI برای مبتدیان خوش آمدید! این سند طراحی شده است تا به شما کمک کند مواد دوره را به طور مؤثر مرور کنید و تجربه یادگیری خود را به حداکثر برسانید. این راهنما مسیرهای یادگیری ساختاریافته، برنامه‌های مطالعه پیشنهادی، خلاصه مفاهیم کلیدی و منابع تکمیلی را برای درک عمیق‌تر فناوری‌های Edge AI ارائه می‌دهد.

این دوره مختصر 20 ساعته دانش ضروری درباره EdgeAI را در قالبی کارآمد ارائه می‌دهد و برای حرفه‌ای‌های پرمشغله و دانشجویانی که می‌خواهند به سرعت مهارت‌های عملی در این حوزه نوظهور کسب کنند، مناسب است.

## نمای کلی دوره

این دوره به هشت ماژول جامع تقسیم شده است:

0. **مقدمه‌ای بر EdgeAI** - پایه‌گذاری و تنظیم زمینه با کاربردهای صنعتی و اهداف یادگیری  
1. **اصول اولیه و تحول EdgeAI** - درک مفاهیم اصلی و تغییرات فناوری  
2. **مبانی مدل‌های کوچک زبانی (SLM)** - بررسی خانواده‌های مختلف SLM و معماری‌های آن‌ها  
3. **استقرار مدل‌های کوچک زبانی (SLM)** - اجرای استراتژی‌های عملی استقرار  
4. **تبدیل فرمت مدل و کمینه‌سازی** - بهینه‌سازی پیشرفته با 6 چارچوب از جمله OpenVINO  
5. **SLMOps - عملیات مدل‌های کوچک زبانی** - مدیریت چرخه عمر تولید و استقرار  
6. **سیستم‌های عامل SLM** - عوامل هوش مصنوعی، فراخوانی توابع و پروتکل زمینه مدل  
7. **نمونه‌های پیاده‌سازی EdgeAI** - ابزارهای هوش مصنوعی، توسعه در ویندوز و پیاده‌سازی‌های خاص پلتفرم  
8. **Microsoft Foundry Local – ابزار کامل توسعه‌دهنده** - توسعه محلی با یکپارچه‌سازی هیبریدی Azure (ماژول 08)

## نحوه استفاده از این راهنمای مطالعه

- **یادگیری تدریجی**: برای تجربه یادگیری منسجم‌تر، ماژول‌ها را به ترتیب دنبال کنید  
- **نقاط بررسی دانش**: از سوالات ارزیابی خود پس از هر بخش استفاده کنید  
- **تمرین عملی**: تمرین‌های پیشنهادی را برای تقویت مفاهیم نظری کامل کنید  
- **منابع تکمیلی**: مواد اضافی را برای موضوعاتی که بیشتر به آن‌ها علاقه دارید، بررسی کنید  

## توصیه‌های برنامه مطالعه

### مسیر یادگیری متمرکز (1 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 0 | ماژول 0: مقدمه‌ای بر EdgeAI | 1-2 ساعت |
| روز 1-2 | ماژول 1: اصول اولیه EdgeAI | 6 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 8 ساعت |
| روز 5 | ماژول 3: استقرار SLM | 3 ساعت |
| روز 6 | ماژول 8: ابزار محلی Foundry | 3 ساعت |

### مطالعه پاره‌وقت (3 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 0: مقدمه + ماژول 1: اصول اولیه EdgeAI | 7-9 ساعت |
| هفته 2 | ماژول 2: مبانی SLM | 7-8 ساعت |
| هفته 3 | ماژول 3: استقرار SLM (3 ساعت) + ماژول 8: ابزار محلی Foundry (2-3 ساعت) | 5-6 ساعت |

## ماژول 0: مقدمه‌ای بر EdgeAI

### اهداف کلیدی یادگیری

- درک اینکه Edge AI چیست و چرا در چشم‌انداز فناوری امروز اهمیت دارد  
- شناسایی صنایع اصلی که توسط Edge AI تحول یافته‌اند و موارد استفاده خاص آن‌ها  
- درک مزایای مدل‌های کوچک زبانی (SLM) برای استقرار در لبه  
- تعیین انتظارات و نتایج یادگیری واضح برای کل دوره  
- شناخت فرصت‌های شغلی و الزامات مهارتی در حوزه Edge AI  

### حوزه‌های تمرکز مطالعه

#### بخش 1: پارادایم و تعریف Edge AI  
- **مفاهیم اولویت‌دار**:  
  - Edge AI در مقابل پردازش سنتی هوش مصنوعی ابری  
  - همگرایی سخت‌افزار، بهینه‌سازی مدل و نیازهای کسب‌وکار  
  - استقرار هوش مصنوعی بلادرنگ، حفظ حریم خصوصی و مقرون‌به‌صرفه  

#### بخش 2: کاربردهای صنعتی  
- **مفاهیم اولویت‌دار**:  
  - تولید و صنعت 4.0: نگهداری پیش‌بینی‌کننده و کنترل کیفیت  
  - مراقبت‌های بهداشتی: تصویربرداری تشخیصی و نظارت بر بیماران  
  - سیستم‌های خودمختار: وسایل نقلیه خودران و حمل‌ونقل  
  - شهرهای هوشمند: مدیریت ترافیک و ایمنی عمومی  
  - فناوری مصرف‌کننده: گوشی‌های هوشمند، پوشیدنی‌ها و خانه‌های هوشمند  

#### بخش 3: مبانی مدل‌های کوچک زبانی  
- **مفاهیم اولویت‌دار**:  
  - ویژگی‌ها و مقایسه عملکرد SLM  
  - کارایی پارامتر در مقابل مصالحه‌های قابلیت  
  - محدودیت‌های استقرار در لبه و استراتژی‌های بهینه‌سازی  

#### بخش 4: چارچوب یادگیری و مسیر شغلی  
- **مفاهیم اولویت‌دار**:  
  - معماری دوره و رویکرد تسلط تدریجی  
  - اهداف مهارتی فنی و پیاده‌سازی عملی  
  - فرصت‌های پیشرفت شغلی و کاربردهای صنعتی  

### سوالات ارزیابی خود

1. سه روند اصلی فناوری که Edge AI را ممکن کرده‌اند، چیست؟  
2. مزایا و چالش‌های Edge AI در مقابل هوش مصنوعی مبتنی بر ابر را مقایسه کنید.  
3. سه صنعتی که Edge AI ارزش تجاری حیاتی ارائه می‌دهد را نام ببرید و توضیح دهید چرا.  
4. چگونه مدل‌های کوچک زبانی Edge AI را برای استقرار در دنیای واقعی عملی می‌کنند؟  
5. مهارت‌های فنی کلیدی که در طول این دوره توسعه خواهید داد، چیست؟  
6. رویکرد یادگیری چهار مرحله‌ای استفاده شده در این دوره را توضیح دهید.  

### تمرین‌های عملی

1. **تحقیق صنعتی**: یک کاربرد صنعتی را انتخاب کنید و یک پیاده‌سازی واقعی Edge AI را تحقیق کنید (30 دقیقه)  
2. **بررسی مدل**: مدل‌های کوچک زبانی موجود در Hugging Face را مرور کنید و تعداد پارامترها و قابلیت‌های آن‌ها را مقایسه کنید (30 دقیقه)  
3. **برنامه‌ریزی یادگیری**: ساختار کامل دوره را مرور کنید و برنامه مطالعه شخصی خود را ایجاد کنید (15 دقیقه)  

### مواد تکمیلی

- [بررسی بازار Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [بررسی مدل‌های کوچک زبانی - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [بنیاد محاسبات لبه](https://www.edgecomputing.org/)  

## ماژول 1: اصول اولیه و تحول EdgeAI

### اهداف کلیدی یادگیری

- تفاوت‌های بین هوش مصنوعی مبتنی بر ابر و هوش مصنوعی مبتنی بر لبه را درک کنید  
- تکنیک‌های اصلی بهینه‌سازی برای محیط‌های محدود منابع را یاد بگیرید  
- کاربردهای واقعی فناوری‌های EdgeAI را تحلیل کنید  
- یک محیط توسعه برای پروژه‌های EdgeAI تنظیم کنید  

### حوزه‌های تمرکز مطالعه

#### بخش 1: اصول اولیه EdgeAI  
- **مفاهیم اولویت‌دار**:  
  - پارادایم‌های محاسبات لبه در مقابل ابر  
  - تکنیک‌های کمینه‌سازی مدل  
  - گزینه‌های شتاب‌دهنده سخت‌افزاری (NPU، GPU، CPU)  
  - مزایای حفظ حریم خصوصی و امنیت  

- **مواد تکمیلی**:  
  - [مستندات TensorFlow Lite](https://www.tensorflow.org/lite)  
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)  
  - [مستندات Edge Impulse](https://docs.edgeimpulse.com)  

#### بخش 2: مطالعات موردی واقعی  
- **مفاهیم اولویت‌دار**:  
  - اکوسیستم مدل‌های Microsoft Phi & Mu  
  - پیاده‌سازی‌های عملی در صنایع مختلف  
  - ملاحظات استقرار  

#### بخش 3: راهنمای پیاده‌سازی عملی  
- **مفاهیم اولویت‌دار**:  
  - تنظیم محیط توسعه  
  - ابزارهای کمینه‌سازی و بهینه‌سازی  
  - روش‌های ارزیابی برای پیاده‌سازی‌های EdgeAI  

#### بخش 4: سخت‌افزار استقرار لبه  
- **مفاهیم اولویت‌دار**:  
  - مقایسه پلتفرم‌های سخت‌افزاری  
  - استراتژی‌های بهینه‌سازی برای سخت‌افزار خاص  
  - ملاحظات استقرار  

### سوالات ارزیابی خود

1. هوش مصنوعی مبتنی بر ابر را با پیاده‌سازی‌های هوش مصنوعی مبتنی بر لبه مقایسه و تضاد دهید.  
2. سه تکنیک کلیدی برای بهینه‌سازی مدل‌ها برای استقرار در لبه را توضیح دهید.  
3. مزایای اصلی اجرای مدل‌های هوش مصنوعی در لبه چیست؟  
4. فرآیند کمینه‌سازی یک مدل را توضیح دهید و چگونه بر عملکرد تأثیر می‌گذارد.  
5. توضیح دهید که چگونه شتاب‌دهنده‌های سخت‌افزاری مختلف (NPU، GPU، CPU) بر استقرار EdgeAI تأثیر می‌گذارند.  

### تمرین‌های عملی

1. **تنظیم سریع محیط**: یک محیط توسعه حداقلی با بسته‌های ضروری تنظیم کنید (30 دقیقه)  
2. **بررسی مدل**: یک مدل کوچک زبانی پیش‌آموزش‌شده را دانلود و بررسی کنید (1 ساعت)  
3. **کمینه‌سازی پایه**: کمینه‌سازی ساده را روی یک مدل کوچک امتحان کنید (1 ساعت)  

## ماژول 2: مبانی مدل‌های کوچک زبانی

### اهداف کلیدی یادگیری

- اصول معماری خانواده‌های مختلف SLM را درک کنید  
- قابلیت‌های مدل‌ها را در مقیاس‌های مختلف پارامتر مقایسه کنید  
- مدل‌ها را بر اساس کارایی، قابلیت و نیازهای استقرار ارزیابی کنید  
- موارد استفاده مناسب برای خانواده‌های مختلف مدل را شناسایی کنید  

### حوزه‌های تمرکز مطالعه

#### بخش 1: خانواده مدل Microsoft Phi  
- **مفاهیم اولویت‌دار**:  
  - تکامل فلسفه طراحی  
  - معماری کارایی‌محور  
  - قابلیت‌های تخصصی  

#### بخش 2: خانواده Qwen  
- **مفاهیم اولویت‌دار**:  
  - مشارکت‌های متن‌باز  
  - گزینه‌های استقرار مقیاس‌پذیر  
  - معماری استدلال پیشرفته  

#### بخش 3: خانواده Gemma  
- **مفاهیم اولویت‌دار**:  
  - نوآوری مبتنی بر تحقیق  
  - قابلیت‌های چندوجهی  
  - بهینه‌سازی موبایل  

#### بخش 4: خانواده BitNET  
- **مفاهیم اولویت‌دار**:  
  - فناوری کمینه‌سازی 1 بیت  
  - چارچوب بهینه‌سازی استنتاج  
  - ملاحظات پایداری  

#### بخش 5: مدل Microsoft Mu  
- **مفاهیم اولویت‌دار**:  
  - معماری دستگاه‌محور  
  - یکپارچه‌سازی سیستم با ویندوز  
  - عملیات حفظ حریم خصوصی  

#### بخش 6: Phi-Silica  
- **مفاهیم اولویت‌دار**:  
  - معماری بهینه‌شده برای NPU  
  - معیارهای عملکرد  
  - یکپارچه‌سازی توسعه‌دهنده  

### سوالات ارزیابی خود

1. رویکردهای معماری خانواده‌های مدل Phi و Qwen را مقایسه کنید.  
2. توضیح دهید که چگونه فناوری کمینه‌سازی BitNET با کمینه‌سازی سنتی متفاوت است.  
3. مزایای منحصر به فرد مدل Mu برای یکپارچه‌سازی با ویندوز چیست؟
4. توضیح دهید که چگونه Phi-Silica از سخت‌افزار NPU برای بهینه‌سازی عملکرد استفاده می‌کند.
5. برای یک اپلیکیشن موبایل با اتصال محدود، کدام خانواده مدل مناسب‌تر است و چرا؟

### تمرین‌های عملی

1. **مقایسه مدل‌ها**: اجرای سریع بنچمارک دو مدل SLM مختلف (1 ساعت)
2. **تولید متن ساده**: پیاده‌سازی اولیه تولید متن با یک مدل کوچک (1 ساعت)
3. **بهینه‌سازی سریع**: اعمال یک تکنیک بهینه‌سازی برای افزایش سرعت استنتاج (1 ساعت)

## ماژول 3: استقرار مدل‌های کوچک زبانی (SLM)

### اهداف کلیدی یادگیری

- انتخاب مدل‌های مناسب بر اساس محدودیت‌های استقرار
- تسلط بر تکنیک‌های بهینه‌سازی برای سناریوهای مختلف استقرار
- پیاده‌سازی SLM‌ها در محیط‌های محلی و ابری
- طراحی تنظیمات آماده تولید برای اپلیکیشن‌های EdgeAI

### حوزه‌های تمرکز مطالعه

#### بخش 1: یادگیری پیشرفته SLM
- **مفاهیم اولویت‌دار**: 
  - چارچوب طبقه‌بندی پارامترها
  - تکنیک‌های پیشرفته بهینه‌سازی
  - استراتژی‌های دستیابی به مدل

#### بخش 2: استقرار در محیط محلی
- **مفاهیم اولویت‌دار**: 
  - استقرار پلتفرم Ollama
  - راه‌حل‌های محلی Microsoft Foundry
  - تحلیل مقایسه‌ای فریم‌ورک‌ها

#### بخش 3: استقرار ابری کانتینری‌شده
- **مفاهیم اولویت‌دار**: 
  - استنتاج با عملکرد بالا vLLM
  - ارکستراسیون کانتینرها
  - پیاده‌سازی ONNX Runtime

### سوالات ارزیابی خود

1. چه عواملی باید هنگام انتخاب بین استقرار محلی و استقرار ابری در نظر گرفته شوند؟
2. Ollama و Microsoft Foundry Local را به عنوان گزینه‌های استقرار مقایسه کنید.
3. مزایای کانتینری‌سازی برای استقرار SLM چیست؟
4. معیارهای کلیدی عملکرد برای یک SLM مستقر در Edge چیست؟
5. یک جریان کاری کامل استقرار از انتخاب مدل تا پیاده‌سازی تولید را توضیح دهید.

### تمرین‌های عملی

1. **استقرار محلی ساده**: استقرار یک SLM ساده با استفاده از Ollama (1 ساعت)
2. **بررسی عملکرد**: اجرای یک بنچمارک سریع روی مدل مستقر شده (30 دقیقه)
3. **یکپارچه‌سازی ساده**: ایجاد یک اپلیکیشن حداقلی که از مدل مستقر شده استفاده کند (1 ساعت)

## ماژول 4: تبدیل فرمت مدل و کوانتیزاسیون

### اهداف کلیدی یادگیری

- تسلط بر تکنیک‌های پیشرفته کوانتیزاسیون از دقت 1 بیت تا 8 بیت
- درک استراتژی‌های تبدیل فرمت (GGUF، ONNX)
- پیاده‌سازی بهینه‌سازی در شش فریم‌ورک (Llama.cpp، Olive، OpenVINO، MLX، سنتز جریان کاری)
- استقرار مدل‌های بهینه‌سازی شده برای محیط‌های تولیدی Edge در سخت‌افزارهای Intel، Apple و چند پلتفرمی

### حوزه‌های تمرکز مطالعه

#### بخش 1: مبانی کوانتیزاسیون
- **مفاهیم اولویت‌دار**: 
  - چارچوب طبقه‌بندی دقت
  - توازن عملکرد و دقت
  - بهینه‌سازی ردپای حافظه

#### بخش 2: پیاده‌سازی Llama.cpp
- **مفاهیم اولویت‌دار**: 
  - استقرار چند پلتفرمی
  - بهینه‌سازی فرمت GGUF
  - تکنیک‌های شتاب‌دهی سخت‌افزاری

#### بخش 3: مجموعه Microsoft Olive
- **مفاهیم اولویت‌دار**: 
  - بهینه‌سازی آگاه به سخت‌افزار
  - استقرار در سطح سازمانی
  - جریان‌های کاری بهینه‌سازی خودکار

#### بخش 4: ابزار OpenVINO
- **مفاهیم اولویت‌دار**: 
  - بهینه‌سازی سخت‌افزار Intel
  - چارچوب فشرده‌سازی شبکه عصبی (NNCF)
  - استقرار استنتاج چند پلتفرمی
  - OpenVINO GenAI برای استقرار LLM

#### بخش 5: فریم‌ورک Apple MLX
- **مفاهیم اولویت‌دار**: 
  - بهینه‌سازی Apple Silicon
  - معماری حافظه یکپارچه
  - قابلیت‌های تنظیم دقیق LoRA

#### بخش 6: سنتز جریان کاری توسعه Edge AI
- **مفاهیم اولویت‌دار**: 
  - معماری جریان کاری یکپارچه
  - درخت‌های تصمیم‌گیری انتخاب فریم‌ورک
  - اعتبارسنجی آمادگی تولید
  - استراتژی‌های آینده‌نگر

### سوالات ارزیابی خود

1. استراتژی‌های کوانتیزاسیون در سطوح دقت مختلف (1 بیت تا 8 بیت) را مقایسه کنید.
2. مزایای فرمت GGUF برای استقرار در Edge چیست؟
3. چگونه بهینه‌سازی آگاه به سخت‌افزار در Microsoft Olive کارایی استقرار را بهبود می‌بخشد؟
4. مزایای کلیدی NNCF در OpenVINO برای فشرده‌سازی مدل چیست؟
5. توضیح دهید که چگونه Apple MLX از معماری حافظه یکپارچه برای بهینه‌سازی استفاده می‌کند.
6. سنتز جریان کاری چگونه در انتخاب فریم‌ورک‌های بهینه‌سازی کمک می‌کند؟

### تمرین‌های عملی

1. **کوانتیزاسیون مدل**: اعمال سطوح مختلف کوانتیزاسیون به یک مدل و مقایسه نتایج (1 ساعت)
2. **بهینه‌سازی OpenVINO**: استفاده از NNCF برای فشرده‌سازی یک مدل برای سخت‌افزار Intel (1 ساعت)
3. **مقایسه فریم‌ورک‌ها**: آزمایش یک مدل مشابه در سه فریم‌ورک بهینه‌سازی مختلف (1 ساعت)
4. **بنچمارک عملکرد**: اندازه‌گیری تاثیر بهینه‌سازی بر سرعت استنتاج و استفاده از حافظه (1 ساعت)

## ماژول 5: SLMOps - عملیات مدل‌های کوچک زبانی

### اهداف کلیدی یادگیری

- درک اصول مدیریت چرخه عمر SLMOps
- تسلط بر تکنیک‌های تقطیر و تنظیم دقیق برای استقرار در Edge
- پیاده‌سازی استراتژی‌های استقرار تولید با نظارت
- ساخت جریان‌های کاری عملیات و نگهداری SLM در سطح سازمانی

### حوزه‌های تمرکز مطالعه

#### بخش 1: معرفی SLMOps
- **مفاهیم اولویت‌دار**: 
  - تغییر پارادایم SLMOps در عملیات هوش مصنوعی
  - معماری اولویت‌دار هزینه و حریم خصوصی
  - تاثیر استراتژیک بر کسب‌وکار و مزایای رقابتی

#### بخش 2: تقطیر مدل
- **مفاهیم اولویت‌دار**: 
  - تکنیک‌های انتقال دانش
  - پیاده‌سازی فرآیند تقطیر دو مرحله‌ای
  - جریان‌های کاری تقطیر Azure ML

#### بخش 3: استراتژی‌های تنظیم دقیق
- **مفاهیم اولویت‌دار**: 
  - تنظیم دقیق کارآمد پارامترها (PEFT)
  - روش‌های پیشرفته LoRA و QLoRA
  - آموزش چند آداپتری و بهینه‌سازی هایپرپارامترها

#### بخش 4: استقرار تولید
- **مفاهیم اولویت‌دار**: 
  - تبدیل مدل و کوانتیزاسیون برای تولید
  - پیکربندی استقرار Foundry Local
  - بنچمارک عملکرد و اعتبارسنجی کیفیت

### سوالات ارزیابی خود

1. SLMOps چگونه با MLOps سنتی تفاوت دارد؟
2. مزایای تقطیر مدل برای استقرار در Edge چیست؟
3. ملاحظات کلیدی برای تنظیم دقیق SLM‌ها در محیط‌های محدود منابع چیست؟
4. یک جریان کاری کامل استقرار تولید برای اپلیکیشن‌های Edge AI را توضیح دهید.

### تمرین‌های عملی

1. **تقطیر پایه**: ایجاد یک مدل کوچک‌تر از یک مدل معلم بزرگ‌تر (1 ساعت)
2. **آزمایش تنظیم دقیق**: تنظیم دقیق یک مدل برای یک حوزه خاص (1 ساعت)
3. **جریان کاری استقرار**: راه‌اندازی یک جریان کاری CI/CD پایه برای استقرار مدل (1 ساعت)

## ماژول 6: سیستم‌های عامل SLM - عوامل هوش مصنوعی و فراخوانی توابع

### اهداف کلیدی یادگیری

- ساخت عوامل هوش مصنوعی هوشمند برای محیط‌های Edge با استفاده از مدل‌های کوچک زبانی
- پیاده‌سازی قابلیت‌های فراخوانی توابع با جریان‌های کاری سیستماتیک
- تسلط بر ادغام پروتکل زمینه مدل (MCP) برای تعامل استاندارد ابزارها
- ایجاد سیستم‌های عامل پیچیده با حداقل مداخله انسانی

### حوزه‌های تمرکز مطالعه

#### بخش 1: عوامل هوش مصنوعی و مبانی SLM
- **مفاهیم اولویت‌دار**: 
  - چارچوب طبقه‌بندی عوامل (بازتابی، مبتنی بر مدل، مبتنی بر هدف، عوامل یادگیری)
  - تحلیل توازن SLM در مقابل LLM
  - الگوهای طراحی عامل خاص Edge
  - بهینه‌سازی منابع برای عوامل

#### بخش 2: فراخوانی توابع در مدل‌های کوچک زبانی
- **مفاهیم اولویت‌دار**: 
  - پیاده‌سازی جریان کاری سیستماتیک (تشخیص قصد، خروجی JSON، اجرای خارجی)
  - پیاده‌سازی‌های خاص پلتفرم (Phi-4-mini، مدل‌های منتخب Qwen، Microsoft Foundry Local)
  - مثال‌های پیشرفته (همکاری چند عامل، انتخاب ابزار پویا)
  - ملاحظات تولید (محدودیت نرخ، ثبت ممیزی، اقدامات امنیتی)

#### بخش 3: ادغام پروتکل زمینه مدل (MCP)
- **مفاهیم اولویت‌دار**: 
  - معماری پروتکل و طراحی سیستم لایه‌ای
  - پشتیبانی چند بک‌اند (Ollama برای توسعه، vLLM برای تولید)
  - پروتکل‌های اتصال (حالت‌های STDIO و SSE)
  - کاربردهای واقعی (اتوماسیون وب، پردازش داده، ادغام API)

### سوالات ارزیابی خود

1. ملاحظات کلیدی معماری برای عوامل هوش مصنوعی Edge چیست؟
2. فراخوانی توابع چگونه قابلیت‌های عامل را افزایش می‌دهد؟
3. نقش پروتکل زمینه مدل در ارتباطات عامل چیست؟

### تمرین‌های عملی

1. **عامل ساده**: ساخت یک عامل هوش مصنوعی پایه با فراخوانی توابع (1 ساعت)
2. **ادغام MCP**: پیاده‌سازی MCP در یک اپلیکیشن عامل (30 دقیقه)

## کارگاه: مسیر یادگیری عملی

### اهداف کلیدی یادگیری

- ساخت اپلیکیشن‌های هوش مصنوعی آماده تولید با استفاده از Foundry Local SDK و بهترین شیوه‌ها
- پیاده‌سازی الگوهای مدیریت خطا و بازخورد کاربر جامع
- ایجاد جریان‌های RAG با ارزیابی کیفیت و نظارت بر عملکرد
- توسعه سیستم‌های چند عاملی با الگوهای هماهنگ‌کننده
- تسلط بر مسیریابی مدل هوشمند برای انتخاب مدل مبتنی بر وظیفه
- استقرار راه‌حل‌های هوش مصنوعی محلی با معماری‌های حفظ حریم خصوصی

### حوزه‌های تمرکز مطالعه

#### جلسه 01: شروع به کار با Foundry Local
- **مفاهیم اولویت‌دار**:
  - ادغام SDK FoundryLocalManager و کشف سرویس خودکار
  - پیاده‌سازی‌های چت پایه و استریم
  - الگوهای مدیریت خطا و بازخورد کاربر
  - پیکربندی مبتنی بر محیط

#### جلسه 02: ساخت راه‌حل‌های هوش مصنوعی با RAG
- **مفاهیم اولویت‌دار**:
  - جاسازی‌های برداری در حافظه با sentence-transformers
  - پیاده‌سازی جریان RAG (بازیابی → تولید)
  - ارزیابی کیفیت با معیارهای RAGAS
  - ایمنی واردات برای وابستگی‌های اختیاری

#### جلسه 03: مدل‌های متن‌باز
- **مفاهیم اولویت‌دار**:
  - استراتژی‌های بنچمارک چند مدل
  - اندازه‌گیری تأخیر و توان عملیاتی
  - کاهش تدریجی و بازیابی خطا
  - مقایسه عملکرد در خانواده‌های مدل

#### جلسه 04: مدل‌های پیشرفته
- **مفاهیم اولویت‌دار**:
  - روش‌شناسی مقایسه SLM در مقابل LLM
  - نکات نوع و قالب‌بندی خروجی جامع
  - مدیریت خطا در هر مدل
  - نتایج ساختاریافته برای تحلیل

#### جلسه 05: عوامل هوش مصنوعی
- **مفاهیم اولویت‌دار**:
  - ارکستراسیون چند عامل با الگوی هماهنگ‌کننده
  - مدیریت حافظه عامل و ردیابی وضعیت
  - مدیریت خطا در جریان و ثبت مراحل
  - نظارت بر عملکرد و آمار

#### جلسه 06: مدل‌ها به عنوان ابزار
- **مفاهیم اولویت‌دار**:
  - تشخیص قصد و تطبیق الگو
  - الگوریتم‌های مسیریابی مدل مبتنی بر کلمات کلیدی
  - جریان‌های چند مرحله‌ای (برنامه‌ریزی → اجرا → اصلاح)
  - مستندسازی جامع توابع

### سوالات ارزیابی خود

1. FoundryLocalManager چگونه مدیریت سرویس را در مقایسه با فراخوانی‌های REST دستی ساده می‌کند؟
2. اهمیت محافظ‌های واردات برای وابستگی‌های اختیاری مانند sentence-transformers چیست؟
3. چه استراتژی‌هایی کاهش تدریجی در بنچمارک چند مدل را تضمین می‌کنند؟
4. الگوی هماهنگ‌کننده چگونه عوامل متخصص متعدد را ارکستراسیون می‌کند؟
5. اجزای یک مسیریاب مدل هوشمند چیست؟
6. عناصر کلیدی مدیریت خطای آماده تولید چیست؟

### تمرین‌های عملی

1. **اپلیکیشن چت**: پیاده‌سازی چت استریم با مدیریت خطا (45 دقیقه)
2. **جریان RAG**: ساخت RAG حداقلی با ارزیابی کیفیت (1 ساعت)
3. **بنچمارک مدل**: مقایسه عملکرد 3+ مدل (1 ساعت)
4. **سیستم چند عاملی**: ایجاد هماهنگ‌کننده با 2 عامل متخصص (1.5 ساعت)
5. **مسیریاب هوشمند**: ساخت انتخاب مدل مبتنی بر وظیفه (1 ساعت)
6. **استقرار تولید**: افزودن نظارت و مدیریت خطای جامع (45 دقیقه)

### تخصیص زمان

**یادگیری متمرکز (1 هفته)**:
- روز 1: جلسه 01-02 (چت + RAG) - 3 ساعت
- روز 2: جلسه 03-04 (بنچمارک + مقایسه) - 3 ساعت
- روز 3: جلسه 05-06 (عوامل + مسیریابی) - 3 ساعت
- روز 4: تمرین‌های عملی و اعتبارسنجی - 2 ساعت

**مطالعه پاره‌وقت (2 هفته)**:
- هفته 1: جلسات 01-03 (6 ساعت مجموع)
- هفته 2: جلسات 04-06 + تمرین‌ها (5 ساعت مجموع)

## ماژول 7: نمونه‌های پیاده‌سازی EdgeAI

### اهداف کلیدی یادگیری

- تسلط بر ابزار هوش مصنوعی برای Visual Studio Code برای جریان‌های کاری جامع توسعه EdgeAI
- کسب تخصص در پلتفرم Windows AI Foundry و استراتژی‌های بهینه‌سازی NPU
- پیاده‌سازی EdgeAI در چندین پلتفرم سخت‌افزاری و سناریوهای استقرار
- ساخت اپلیکیشن‌های EdgeAI آماده تولید با بهینه‌سازی‌های خاص پلتفرم

### حوزه‌های تمرکز مطالعه

#### بخش 1: ابزار هوش مصنوعی برای Visual Studio Code
- **مفاهیم اولویت‌دار**: 
  - محیط توسعه جامع Edge AI در VS Code
  - کاتالوگ مدل و کشف برای استقرار در Edge
  - آزمایش محلی، بهینه‌سازی و جریان‌های کاری توسعه عامل
  - نظارت بر عملکرد و ارزیابی برای سناریوهای Edge

#### بخش 2: راهنمای توسعه Windows EdgeAI
- **مفاهیم اولویت‌دار**: 
  - مرور جامع پلتفرم Windows AI Foundry
  - API Phi Silica برای استنتاج کارآمد NPU
  - API‌های بینایی کامپیوتری برای پردازش تصویر و OCR
  - CLI Foundry Local برای توسعه و آزمایش محلی

#### بخش 3: پیاده‌سازی‌های خاص پلتفرم
- **مفاهیم اولویت‌دار**: 
  - استقرار NVIDIA Jetson Orin Nano (عملکرد AI 67 TOPS)
  - اپلیکیشن‌های موبایل با .NET MAUI و ONNX Runtime GenAI
  - راه‌حل‌های Azure EdgeAI با معماری ترکیبی ابری-Edge
  - بهینه‌سازی Windows ML با پشتیبانی سخت‌افزار جهانی
  - اپلیکیشن‌های Foundry Local با پیاده‌سازی RAG متمرکز بر حریم خصوصی

### سوالات ارزیابی خود

1. ابزار هوش مصنوعی چگونه جریان کاری توسعه EdgeAI را ساده می‌کند؟
2. استراتژی‌های استقرار در پلتفرم‌های سخت‌افزاری مختلف را مقایسه کنید.
3. مزایای پلتفرم Windows AI Foundry برای توسعه در Edge چیست؟
4. نقش بهینه‌سازی NPU در برنامه‌های مدرن هوش مصنوعی لبه‌ای را توضیح دهید.  
5. API Phi Silica چگونه از سخت‌افزار NPU برای بهینه‌سازی عملکرد استفاده می‌کند؟  
6. مزایای استقرار محلی در مقابل استقرار ابری برای برنامه‌های حساس به حریم خصوصی را مقایسه کنید.  

### تمرین‌های عملی  

1. **راه‌اندازی ابزار هوش مصنوعی**: پیکربندی ابزار هوش مصنوعی و بهینه‌سازی یک مدل (1 ساعت)  
2. **Windows AI Foundry**: ساخت یک برنامه ساده هوش مصنوعی ویندوز با استفاده از API Phi Silica (1 ساعت)  
3. **استقرار چند پلتفرمی**: استقرار یک مدل مشابه در دو پلتفرم مختلف (1 ساعت)  
4. **بهینه‌سازی NPU**: آزمایش عملکرد NPU با ابزارهای Windows AI Foundry (30 دقیقه)  

## ماژول 8: Microsoft Foundry Local – جعبه‌ابزار کامل توسعه‌دهنده (مدرن‌سازی‌شده)  

### اهداف کلیدی یادگیری  

- نصب و پیکربندی Foundry Local با یکپارچه‌سازی SDK مدرن  
- پیاده‌سازی سیستم‌های پیشرفته چندعاملی با الگوهای هماهنگ‌کننده  
- ساخت مسیریاب‌های هوشمند مدل با انتخاب خودکار مبتنی بر وظیفه  
- استقرار راه‌حل‌های هوش مصنوعی آماده تولید با نظارت جامع  
- یکپارچه‌سازی با Azure AI Foundry برای سناریوهای استقرار ترکیبی  
- تسلط بر الگوهای SDK مدرن با FoundryLocalManager و OpenAI client  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: نصب و پیکربندی مدرن  
- **مفاهیم اولویت‌دار**:  
  - یکپارچه‌سازی SDK FoundryLocalManager  
  - کشف خودکار سرویس و نظارت بر سلامت  
  - الگوهای پیکربندی مبتنی بر محیط  
  - ملاحظات استقرار تولید  

#### بخش 2: سیستم‌های پیشرفته چندعاملی  
- **مفاهیم اولویت‌دار**:  
  - الگوی هماهنگ‌کننده با عوامل متخصص  
  - تخصص عوامل در بازیابی، استدلال و اجرا  
  - مکانیسم‌های حلقه بازخورد برای بهبود  
  - نظارت بر عملکرد و ردیابی آمار  

#### بخش 3: مسیریابی هوشمند مدل  
- **مفاهیم اولویت‌دار**:  
  - الگوریتم‌های انتخاب مدل مبتنی بر کلمات کلیدی  
  - پشتیبانی از چندین مدل (عمومی، استدلال، کدنویسی، خلاقانه)  
  - پیکربندی متغیرهای محیطی برای انعطاف‌پذیری  
  - بررسی سلامت سرویس و مدیریت خطا  

#### بخش 4: پیاده‌سازی آماده تولید  
- **مفاهیم اولویت‌دار**:  
  - مدیریت جامع خطاها و مکانیسم‌های جایگزین  
  - نظارت بر درخواست‌ها و ردیابی عملکرد  
  - مثال‌های تعاملی Jupyter notebook با بنچمارک‌ها  
  - الگوهای یکپارچه‌سازی با برنامه‌های موجود  

### سوالات خودارزیابی  

1. رویکرد مدرن FoundryLocalManager چه تفاوتی با فراخوانی‌های دستی REST دارد؟  
2. الگوی هماهنگ‌کننده را توضیح دهید و اینکه چگونه عوامل متخصص را هماهنگ می‌کند.  
3. مسیریاب هوشمند چگونه مدل‌های مناسب را بر اساس محتوای پرسش انتخاب می‌کند؟  
4. اجزای کلیدی یک سیستم عامل هوش مصنوعی آماده تولید چیست؟  
5. چگونه می‌توان نظارت جامع بر سلامت خدمات Foundry Local را پیاده‌سازی کرد؟  
6. مزایای رویکرد مدرن در مقایسه با الگوهای پیاده‌سازی سنتی چیست؟  

### تمرین‌های عملی  

1. **راه‌اندازی SDK مدرن**: پیکربندی FoundryLocalManager با کشف خودکار سرویس (30 دقیقه)  
2. **سیستم چندعاملی**: اجرای هماهنگ‌کننده پیشرفته با عوامل متخصص (30 دقیقه)  
3. **مسیریابی هوشمند**: آزمایش مسیریاب مدل با انواع مختلف پرسش‌ها (30 دقیقه)  
4. **کاوش تعاملی**: استفاده از Jupyter notebooks برای کاوش ویژگی‌های پیشرفته (45 دقیقه)  
5. **استقرار تولید**: پیاده‌سازی الگوهای نظارت و مدیریت خطا (30 دقیقه)  
6. **یکپارچه‌سازی ترکیبی**: پیکربندی سناریوهای جایگزین Azure AI Foundry (30 دقیقه)  

## راهنمای تخصیص زمان  

برای کمک به استفاده بهینه از زمان 30 ساعته دوره (شامل کارگاه)، در اینجا یک برنامه پیشنهادی برای تخصیص زمان ارائه شده است:  

| فعالیت | تخصیص زمان | توضیحات |  
|--------|------------|----------|  
| مطالعه مطالب اصلی | 12 ساعت | تمرکز بر مفاهیم اساسی در هر ماژول |  
| تمرین‌های عملی | 10 ساعت | پیاده‌سازی عملی تکنیک‌های کلیدی (شامل کارگاه) |  
| خودارزیابی | 3 ساعت | آزمون درک مفاهیم از طریق سوالات و تأمل |  
| پروژه کوچک | 5 ساعت | به‌کارگیری دانش در یک پیاده‌سازی کوچک عملی |  

### حوزه‌های کلیدی تمرکز بر اساس محدودیت زمانی  

**اگر فقط 10 ساعت زمان دارید:**  
- ماژول 0 (مقدمه) و ماژول‌های 1، 2 و 3 (مفاهیم اصلی EdgeAI) را کامل کنید  
- حداقل یک تمرین عملی در هر ماژول انجام دهید  
- بر درک مفاهیم اصلی به جای جزئیات پیاده‌سازی تمرکز کنید  

**اگر می‌توانید 20 ساعت کامل اختصاص دهید:**  
- تمام هشت ماژول (شامل مقدمه) را کامل کنید  
- تمرین‌های کلیدی هر ماژول را انجام دهید  
- یک پروژه کوچک از ماژول 7 را کامل کنید  
- حداقل 2-3 منبع تکمیلی را بررسی کنید  

**اگر بیش از 20 ساعت زمان دارید:**  
- تمام ماژول‌ها (شامل مقدمه) را با تمرین‌های دقیق کامل کنید  
- چندین پروژه کوچک بسازید  
- تکنیک‌های پیشرفته بهینه‌سازی در ماژول 4 را بررسی کنید  
- استقرار تولید را از ماژول 5 پیاده‌سازی کنید  

## منابع ضروری  

این منابع با دقت انتخاب شده‌اند تا بیشترین ارزش را برای زمان محدود مطالعه شما فراهم کنند:  

### مستندات ضروری برای مطالعه  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - کارآمدترین ابزار بهینه‌سازی مدل  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - سریع‌ترین راه برای استقرار SLMها به صورت محلی  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - مرجع برای یک مدل بهینه‌شده برای لبه  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - ابزار جامع بهینه‌سازی اینتل  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - محیط توسعه EdgeAI یکپارچه  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - پلتفرم توسعه EdgeAI مخصوص ویندوز  

### ابزارهای صرفه‌جویی در زمان  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - دسترسی سریع به مدل‌ها و استقرار  
- [Gradio](https://www.gradio.app/docs/interface) - توسعه سریع رابط کاربری برای دموهای هوش مصنوعی  
- [Microsoft Olive](https://github.com/microsoft/Olive) - بهینه‌سازی ساده مدل  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - استنتاج کارآمد CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - چارچوب فشرده‌سازی شبکه عصبی  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - ابزار استقرار مدل‌های زبان بزرگ  

## قالب پیگیری پیشرفت  

از این قالب ساده برای پیگیری پیشرفت یادگیری خود در طول دوره 20 ساعته استفاده کنید:  

| ماژول | تاریخ تکمیل | ساعات صرف‌شده | نکات کلیدی |  
|-------|-------------|---------------|-------------|  
| ماژول 0: مقدمه‌ای بر EdgeAI | | | |  
| ماژول 1: اصول EdgeAI | | | |  
| ماژول 2: مبانی SLM | | | |  
| ماژول 3: استقرار SLM | | | |  
| ماژول 4: بهینه‌سازی مدل | | | |  
| ماژول 5: SLMOps | | | |  
| ماژول 6: عوامل هوش مصنوعی | | | |  
| ماژول 7: ابزارهای توسعه | | | |  
| کارگاه: یادگیری عملی | | | |  
| ماژول 8: جعبه‌ابزار Foundry Local | | | |  
| تمرین‌های عملی | | | |  
| پروژه کوچک | | | |  

## ایده‌های پروژه کوچک  

یکی از این پروژه‌ها را برای تمرین مفاهیم EdgeAI تکمیل کنید (هر کدام طراحی شده‌اند تا 2-4 ساعت زمان ببرند):  

### پروژه‌های مبتدی (هر کدام 2-3 ساعت)  
1. **دستیار متنی لبه‌ای**: ایجاد یک ابزار ساده تکمیل متن آفلاین با استفاده از یک مدل زبان کوچک  
2. **داشبورد مقایسه مدل**: ساخت یک ابزار بصری برای مقایسه معیارهای عملکرد در مدل‌های مختلف SLM  
3. **آزمایش بهینه‌سازی**: اندازه‌گیری تأثیر سطوح مختلف کوانتیزاسیون بر روی یک مدل پایه مشابه  

### پروژه‌های متوسط (هر کدام 3-4 ساعت)  
4. **جریان کاری ابزار هوش مصنوعی**: استفاده از ابزار هوش مصنوعی VS Code برای بهینه‌سازی و استقرار یک مدل از ابتدا تا انتها  
5. **برنامه Windows AI Foundry**: ایجاد یک برنامه ویندوز با استفاده از API Phi Silica و بهینه‌سازی NPU  
6. **استقرار چند پلتفرمی**: استقرار یک مدل بهینه‌شده مشابه در ویندوز (OpenVINO) و موبایل (.NET MAUI)  
7. **عامل فراخوانی توابع**: ساخت یک عامل هوش مصنوعی با قابلیت فراخوانی توابع برای سناریوهای لبه‌ای  

### پروژه‌های پیشرفته یکپارچه‌سازی (هر کدام 4-5 ساعت)  
8. **خط لوله بهینه‌سازی OpenVINO**: پیاده‌سازی بهینه‌سازی کامل مدل با استفاده از NNCF و ابزار GenAI  
9. **خط لوله SLMOps**: پیاده‌سازی چرخه کامل مدل از آموزش تا استقرار لبه‌ای  
10. **سیستم چندمدلی لبه‌ای**: استقرار چندین مدل تخصصی که با هم روی سخت‌افزار لبه کار می‌کنند  
11. **سیستم یکپارچه MCP**: ساخت یک سیستم عامل با استفاده از پروتکل Model Context برای تعامل ابزارها  

## منابع  

- Microsoft Learn (Foundry Local)  
  - نمای کلی: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - شروع به کار: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - مرجع CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - یکپارچه‌سازی با SDKهای استنتاج: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - نحوه استفاده از Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - کامپایل مدل‌های Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - نمای کلی: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - عوامل (نمای کلی): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- ابزارهای بهینه‌سازی و استنتاج  
  - Microsoft Olive (مستندات): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (شروع به کار): https://onnxruntime.ai/docs/get-started/with-python.html  
  - یکپارچه‌سازی ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (مستندات): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (مستندات): https://ml-explore.github.io/mlx/build/html/index.html  
- چارچوب‌های استقرار و مدل‌ها  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (مستندات): https://docs.vllm.ai/  
  - Ollama (شروع سریع): https://github.com/ollama/ollama#get-started  
- ابزارهای توسعه (ویندوز و VS Code)  
  - ابزار هوش مصنوعی برای VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (نمای کلی): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## جامعه یادگیری  

به بحث بپیوندید و با دیگر یادگیرندگان ارتباط برقرار کنید:  
- بحث‌های GitHub در [مخزن EdgeAI برای مبتدیان](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [جامعه فنی مایکروسافت](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## نتیجه‌گیری  

هوش مصنوعی لبه‌ای نمایانگر مرزهای پیشرفته پیاده‌سازی هوش مصنوعی است که قابلیت‌های قدرتمندی را مستقیماً به دستگاه‌ها می‌آورد و در عین حال به نگرانی‌های مهمی مانند حریم خصوصی، تأخیر و اتصال پاسخ می‌دهد. این دوره 20 ساعته دانش ضروری و مهارت‌های عملی را برای شروع کار با فناوری‌های EdgeAI به شما ارائه می‌دهد.  

این دوره به‌طور عمدی مختصر و متمرکز بر مهم‌ترین مفاهیم طراحی شده است و به شما این امکان را می‌دهد که به سرعت تخصص ارزشمندی کسب کنید بدون اینکه زمان زیادی صرف کنید. به یاد داشته باشید که تمرین عملی، حتی با مثال‌های ساده، کلید تقویت آنچه آموخته‌اید است.  

موفق باشید!  

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.