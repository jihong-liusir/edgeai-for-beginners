<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T07:37:32+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "fa"
}
-->
# EdgeAI برای مبتدیان: مسیرهای یادگیری و برنامه مطالعه

### مسیر یادگیری متمرکز (1 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 0 | ماژول 0: مقدمه‌ای بر EdgeAI | 1-2 ساعت |
| روز 1 | ماژول 1: اصول اولیه EdgeAI | 3 ساعت |
| روز 2 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 3 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 4-5 | ماژول 4: بهینه‌سازی مدل (6 چارچوب) | 4 ساعت |
| روز 6 | ماژول 5: SLMOps | 3 ساعت |
| روز 7 | ماژول 6-7: عوامل هوش مصنوعی و ابزارهای توسعه | 4 ساعت |
| روز 8 | ماژول 8: ابزار محلی Foundry (پیاده‌سازی مدرن) | 1 ساعت |

### مسیر یادگیری متمرکز (2 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 1-2 | ماژول 1: اصول اولیه EdgeAI | 3 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 5-6 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 7-8 | ماژول 4: بهینه‌سازی مدل | 4 ساعت |
| روز 9-10 | ماژول 5: SLMOps | 3 ساعت |
| روز 11-12 | ماژول 6: عوامل هوش مصنوعی | 2 ساعت |
| روز 13-14 | ماژول 7: ابزارهای توسعه | 3 ساعت |

### مطالعه پاره‌وقت (4 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 1-2: اصول اولیه و مبانی SLM | 6 ساعت |
| هفته 2 | ماژول 3-4: استقرار و بهینه‌سازی | 6 ساعت |
| هفته 3 | ماژول 5-6: SLMOps و عوامل هوش مصنوعی | 5 ساعت |
| هفته 4 | ماژول 7: ابزارهای توسعه و یکپارچه‌سازی | 3 ساعت |

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 0 | ماژول 0: مقدمه‌ای بر EdgeAI | 1-2 ساعت |
| روز 1-2 | ماژول 1: اصول اولیه EdgeAI | 3 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 3 ساعت |
| روز 5-6 | ماژول 3: استقرار SLM | 2 ساعت |
| روز 7-8 | ماژول 4: بهینه‌سازی مدل | 4 ساعت |
| روز 9-10 | ماژول 5: SLMOps | 3 ساعت |
| روز 11-12 | ماژول 6: سیستم‌های عامل SLM | 2 ساعت |
| روز 13-14 | ماژول 7: نمونه‌های پیاده‌سازی EdgeAI | 2 ساعت |

| ماژول | تاریخ تکمیل | ساعات صرف شده | نکات کلیدی |
|--------|----------------|-------------|--------------|
| ماژول 0: مقدمه‌ای بر EdgeAI | | | |
| ماژول 1: اصول اولیه EdgeAI | | | |
| ماژول 2: مبانی SLM | | | |
| ماژول 3: استقرار SLM | | | |
| ماژول 4: بهینه‌سازی مدل (6 چارچوب) | | | |
| ماژول 5: SLMOps | | | |
| ماژول 6: سیستم‌های عامل SLM | | | |
| ماژول 7: نمونه‌های پیاده‌سازی EdgeAI | | | |
| تمرین‌های عملی | | | |
| پروژه کوچک | | | |

### مطالعه پاره‌وقت (4 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 1-2: اصول اولیه و مبانی SLM | 6 ساعت |
| هفته 2 | ماژول 3-4: استقرار و بهینه‌سازی | 6 ساعت |
| هفته 3 | ماژول 5-6: SLMOps و عوامل هوش مصنوعی | 5 ساعت |
| هفته 4 | ماژول 7: ابزارهای توسعه و یکپارچه‌سازی | 3 ساعت |

## مقدمه

به راهنمای مطالعه EdgeAI برای مبتدیان خوش آمدید! این سند طراحی شده است تا به شما کمک کند مواد دوره را به طور مؤثر مرور کنید و تجربه یادگیری خود را به حداکثر برسانید. این راهنما مسیرهای یادگیری ساختاریافته، برنامه‌های مطالعه پیشنهادی، خلاصه مفاهیم کلیدی و منابع تکمیلی را برای تعمیق درک شما از فناوری‌های EdgeAI ارائه می‌دهد.

این دوره مختصر 20 ساعته، دانش ضروری درباره EdgeAI را در قالبی کارآمد ارائه می‌دهد و برای حرفه‌ای‌ها و دانشجویان پرمشغله‌ای که می‌خواهند به سرعت مهارت‌های عملی در این حوزه نوظهور کسب کنند، مناسب است.

## نمای کلی دوره

این دوره به هشت ماژول جامع تقسیم شده است:

0. **مقدمه‌ای بر EdgeAI** - پایه‌گذاری و تنظیم زمینه با کاربردهای صنعتی و اهداف یادگیری  
1. **اصول اولیه و تحول EdgeAI** - درک مفاهیم اصلی و تغییرات فناوری  
2. **مبانی مدل‌های کوچک زبانی (SLM)** - بررسی خانواده‌های مختلف SLM و معماری‌های آنها  
3. **استقرار مدل‌های کوچک زبانی (SLM)** - اجرای استراتژی‌های عملی استقرار  
4. **تبدیل فرمت مدل و کمینه‌سازی** - بهینه‌سازی پیشرفته با 6 چارچوب از جمله OpenVINO  
5. **SLMOps - عملیات مدل‌های کوچک زبانی** - مدیریت چرخه عمر تولید و استقرار  
6. **سیستم‌های عامل SLM** - عوامل هوش مصنوعی، فراخوانی توابع و پروتکل زمینه مدل  
7. **نمونه‌های پیاده‌سازی EdgeAI** - ابزارهای هوش مصنوعی، توسعه در ویندوز و پیاده‌سازی‌های خاص پلتفرم  
8. **Microsoft Foundry Local – ابزار کامل توسعه‌دهنده** - توسعه محلی با یکپارچه‌سازی هیبریدی Azure (ماژول 08)

## نحوه استفاده از این راهنمای مطالعه

- **یادگیری تدریجی**: برای تجربه یادگیری منسجم‌تر، ماژول‌ها را به ترتیب دنبال کنید  
- **نقاط بررسی دانش**: از سوالات ارزیابی خود پس از هر بخش استفاده کنید  
- **تمرین عملی**: تمرین‌های پیشنهادی را برای تقویت مفاهیم نظری کامل کنید  
- **منابع تکمیلی**: برای موضوعاتی که بیشتر به آنها علاقه دارید، مواد اضافی را بررسی کنید  

## توصیه‌های برنامه مطالعه

### مسیر یادگیری متمرکز (1 هفته)

| روز | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| روز 0 | ماژول 0: مقدمه‌ای بر EdgeAI | 1-2 ساعت |
| روز 1-2 | ماژول 1: اصول اولیه EdgeAI | 6 ساعت |
| روز 3-4 | ماژول 2: مبانی SLM | 8 ساعت |
| روز 5 | ماژول 3: استقرار SLM | 3 ساعت |
| روز 6 | ماژول 8: ابزار محلی Foundry | 3 ساعت |

### مطالعه پاره‌وقت (3 هفته)

| هفته | تمرکز | ساعات تخمینی |
|------|-------|------------------|
| هفته 1 | ماژول 0: مقدمه + ماژول 1: اصول اولیه EdgeAI | 7-9 ساعت |
| هفته 2 | ماژول 2: مبانی SLM | 7-8 ساعت |
| هفته 3 | ماژول 3: استقرار SLM (3 ساعت) + ماژول 8: ابزار محلی Foundry (2-3 ساعت) | 5-6 ساعت |

## ماژول 0: مقدمه‌ای بر EdgeAI

### اهداف کلیدی یادگیری

- درک اینکه Edge AI چیست و چرا در چشم‌انداز فناوری امروز اهمیت دارد  
- شناسایی صنایع اصلی که توسط Edge AI تحول یافته‌اند و موارد استفاده خاص آنها  
- درک مزایای مدل‌های کوچک زبانی (SLM) برای استقرار در لبه  
- تعیین انتظارات و نتایج یادگیری واضح برای کل دوره  
- شناخت فرصت‌های شغلی و الزامات مهارتی در حوزه Edge AI  

### حوزه‌های تمرکز مطالعه

#### بخش 1: پارادایم و تعریف Edge AI
- **مفاهیم اولویت‌دار**:  
  - Edge AI در مقابل پردازش سنتی ابری  
  - همگرایی سخت‌افزار، بهینه‌سازی مدل و نیازهای کسب‌وکار  
  - استقرار هوش مصنوعی بلادرنگ، حفظ حریم خصوصی و مقرون‌به‌صرفه  

#### بخش 2: کاربردهای صنعتی
- **مفاهیم اولویت‌دار**:  
  - تولید و صنعت 4.0: نگهداری پیش‌بینی‌کننده و کنترل کیفیت  
  - مراقبت‌های بهداشتی: تصویربرداری تشخیصی و نظارت بر بیماران  
  - سیستم‌های خودمختار: وسایل نقلیه خودران و حمل‌ونقل  
  - شهرهای هوشمند: مدیریت ترافیک و ایمنی عمومی  
  - فناوری مصرف‌کننده: گوشی‌های هوشمند، پوشیدنی‌ها و خانه‌های هوشمند  

#### بخش 3: مبانی مدل‌های کوچک زبانی
- **مفاهیم اولویت‌دار**:  
  - ویژگی‌ها و مقایسه عملکرد SLM  
  - کارایی پارامترها در مقابل مصالحه‌های قابلیت  
  - محدودیت‌های استقرار در لبه و استراتژی‌های بهینه‌سازی  

#### بخش 4: چارچوب یادگیری و مسیر شغلی
- **مفاهیم اولویت‌دار**:  
  - معماری دوره و رویکرد تسلط تدریجی  
  - اهداف مهارت‌های فنی و پیاده‌سازی عملی  
  - فرصت‌های پیشرفت شغلی و کاربردهای صنعتی  

### سوالات ارزیابی خود

1. سه روند اصلی فناوری که Edge AI را ممکن کرده‌اند چیست؟  
2. مزایا و چالش‌های Edge AI در مقابل هوش مصنوعی مبتنی بر ابر را مقایسه کنید.  
3. سه صنعتی که Edge AI ارزش تجاری حیاتی ارائه می‌دهد را نام ببرید و توضیح دهید چرا.  
4. چگونه مدل‌های کوچک زبانی Edge AI را برای استقرار در دنیای واقعی عملی می‌کنند؟  
5. مهارت‌های فنی کلیدی که در طول این دوره توسعه خواهید داد چیست؟  
6. رویکرد یادگیری چهار مرحله‌ای استفاده شده در این دوره را توضیح دهید.  

### تمرین‌های عملی

1. **تحقیق صنعتی**: یک کاربرد صنعتی را انتخاب کنید و یک پیاده‌سازی واقعی Edge AI را تحقیق کنید (30 دقیقه)  
2. **بررسی مدل**: مدل‌های کوچک زبانی موجود در Hugging Face را مرور کنید و تعداد پارامترها و قابلیت‌های آنها را مقایسه کنید (30 دقیقه)  
3. **برنامه‌ریزی یادگیری**: ساختار کامل دوره را مرور کنید و برنامه مطالعه شخصی خود را ایجاد کنید (15 دقیقه)  

### مواد تکمیلی

- [بررسی بازار Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [بررسی مدل‌های کوچک زبانی - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [بنیاد محاسبات لبه](https://www.edgecomputing.org/)  

## ماژول 1: اصول اولیه و تحول EdgeAI

### اهداف کلیدی یادگیری

- تفاوت‌های بین هوش مصنوعی مبتنی بر ابر و مبتنی بر لبه را درک کنید  
- تکنیک‌های اصلی بهینه‌سازی برای محیط‌های محدود منابع را یاد بگیرید  
- کاربردهای واقعی فناوری‌های EdgeAI را تحلیل کنید  
- یک محیط توسعه برای پروژه‌های EdgeAI راه‌اندازی کنید  

### حوزه‌های تمرکز مطالعه

#### بخش 1: اصول اولیه EdgeAI
- **مفاهیم اولویت‌دار**:  
  - پارادایم‌های محاسبات لبه در مقابل ابر  
  - تکنیک‌های کمینه‌سازی مدل  
  - گزینه‌های شتاب‌دهنده سخت‌افزاری (NPUs، GPUs، CPUs)  
  - مزایای حفظ حریم خصوصی و امنیت  

- **مواد تکمیلی**:  
  - [مستندات TensorFlow Lite](https://www.tensorflow.org/lite)  
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)  
  - [مستندات Edge Impulse](https://docs.edgeimpulse.com)  

#### بخش 2: مطالعات موردی واقعی
- **مفاهیم اولویت‌دار**:  
  - اکوسیستم مدل‌های Microsoft Phi & Mu  
  - پیاده‌سازی‌های عملی در صنایع مختلف  
  - ملاحظات استقرار  

#### بخش 3: راهنمای پیاده‌سازی عملی
- **مفاهیم اولویت‌دار**:  
  - راه‌اندازی محیط توسعه  
  - ابزارهای کمینه‌سازی و بهینه‌سازی  
  - روش‌های ارزیابی برای پیاده‌سازی‌های EdgeAI  

#### بخش 4: سخت‌افزار استقرار لبه
- **مفاهیم اولویت‌دار**:  
  - مقایسه پلتفرم‌های سخت‌افزاری  
  - استراتژی‌های بهینه‌سازی برای سخت‌افزار خاص  
  - ملاحظات استقرار  

### سوالات ارزیابی خود

1. پیاده‌سازی‌های هوش مصنوعی مبتنی بر ابر را با هوش مصنوعی مبتنی بر لبه مقایسه و تضاد دهید.  
2. سه تکنیک کلیدی برای بهینه‌سازی مدل‌ها برای استقرار در لبه را توضیح دهید.  
3. مزایای اصلی اجرای مدل‌های هوش مصنوعی در لبه چیست؟  
4. فرآیند کمینه‌سازی یک مدل را توضیح دهید و چگونه بر عملکرد تأثیر می‌گذارد.  
5. توضیح دهید که چگونه شتاب‌دهنده‌های سخت‌افزاری مختلف (NPUs، GPUs، CPUs) بر استقرار EdgeAI تأثیر می‌گذارند.  

### تمرین‌های عملی

1. **راه‌اندازی سریع محیط**: یک محیط توسعه حداقلی با بسته‌های ضروری پیکربندی کنید (30 دقیقه)  
2. **بررسی مدل**: یک مدل کوچک زبانی از پیش آموزش‌دیده را دانلود و بررسی کنید (1 ساعت)  
3. **کمینه‌سازی پایه**: کمینه‌سازی ساده را روی یک مدل کوچک امتحان کنید (1 ساعت)  

## ماژول 2: مبانی مدل‌های کوچک زبانی

### اهداف کلیدی یادگیری

- اصول معماری خانواده‌های مختلف SLM را درک کنید  
- قابلیت‌های مدل‌ها را در مقیاس‌های مختلف پارامتر مقایسه کنید  
- مدل‌ها را بر اساس کارایی، قابلیت و نیازهای استقرار ارزیابی کنید  
- موارد استفاده مناسب برای خانواده‌های مختلف مدل را شناسایی کنید  

### حوزه‌های تمرکز مطالعه

#### بخش 1: خانواده مدل‌های Microsoft Phi
- **مفاهیم اولویت‌دار**:  
  - تکامل فلسفه طراحی  
  - معماری کارایی‌محور  
  - قابلیت‌های تخصصی  

#### بخش 2: خانواده Qwen
- **مفاهیم اولویت‌دار**:  
  - مشارکت‌های متن‌باز  
  - گزینه‌های استقرار مقیاس‌پذیر  
  - معماری استدلال پیشرفته  

#### بخش 3: خانواده Gemma
- **مفاهیم اولویت‌دار**:  
  - نوآوری مبتنی بر تحقیق  
  - قابلیت‌های چندوجهی  
  - بهینه‌سازی موبایل  

#### بخش 4: خانواده BitNET
- **مفاهیم اولویت‌دار**:  
  - فناوری کمینه‌سازی 1 بیت  
  - چارچوب بهینه‌سازی استنتاج  
  - ملاحظات پایداری  

#### بخش 5: مدل Microsoft Mu
- **مفاهیم اولویت‌دار**:  
  - معماری دستگاه‌محور  
  - یکپارچه‌سازی سیستم با ویندوز  
  - عملیات حفظ حریم خصوصی  

#### بخش 6: Phi-Silica
- **مفاهیم اولویت‌دار**:  
  - معماری بهینه‌شده برای NPU  
  - معیارهای عملکرد  
  - یکپارچه‌سازی توسعه‌دهنده  

### سوالات ارزیابی خود

1. رویکردهای معماری خانواده‌های مدل Phi و Qwen را مقایسه کنید.  
2. توضیح دهید که چگونه فناوری کمینه‌سازی BitNET با کمینه‌سازی سنتی تفاوت دارد.  
3. مزایای منحصر به فرد مدل Mu برای یکپارچگی با ویندوز چیست؟  
4. توضیح دهید که Phi-Silica چگونه از سخت‌افزار NPU برای بهینه‌سازی عملکرد استفاده می‌کند.  
5. برای یک اپلیکیشن موبایل با اتصال محدود، کدام خانواده مدل مناسب‌تر است و چرا؟  

### تمرین‌های عملی  

1. **مقایسه مدل‌ها**: اجرای سریع بنچمارک دو مدل SLM مختلف (1 ساعت)  
2. **تولید متن ساده**: پیاده‌سازی اولیه تولید متن با یک مدل کوچک (1 ساعت)  
3. **بهینه‌سازی سریع**: اعمال یک تکنیک بهینه‌سازی برای افزایش سرعت استنتاج (1 ساعت)  

## ماژول 3: استقرار مدل‌های کوچک زبان  

### اهداف کلیدی یادگیری  

- انتخاب مدل‌های مناسب بر اساس محدودیت‌های استقرار  
- تسلط بر تکنیک‌های بهینه‌سازی برای سناریوهای مختلف استقرار  
- پیاده‌سازی مدل‌های کوچک زبان در محیط‌های محلی و ابری  
- طراحی تنظیمات آماده تولید برای اپلیکیشن‌های EdgeAI  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: یادگیری پیشرفته مدل‌های کوچک زبان  
- **مفاهیم اولویت‌دار**:  
  - چارچوب طبقه‌بندی پارامترها  
  - تکنیک‌های پیشرفته بهینه‌سازی  
  - استراتژی‌های دستیابی به مدل  

#### بخش 2: استقرار در محیط محلی  
- **مفاهیم اولویت‌دار**:  
  - استقرار پلتفرم Ollama  
  - راه‌حل‌های محلی Microsoft Foundry  
  - تحلیل مقایسه‌ای فریم‌ورک‌ها  

#### بخش 3: استقرار ابری کانتینری‌شده  
- **مفاهیم اولویت‌دار**:  
  - استنتاج با عملکرد بالا vLLM  
  - ارکستراسیون کانتینر  
  - پیاده‌سازی ONNX Runtime  

### سوالات ارزیابی خود  

1. چه عواملی باید هنگام انتخاب بین استقرار محلی و استقرار ابری در نظر گرفته شوند؟  
2. Ollama و Microsoft Foundry Local را به عنوان گزینه‌های استقرار مقایسه کنید.  
3. مزایای کانتینری‌شدن برای استقرار مدل‌های کوچک زبان چیست؟  
4. معیارهای کلیدی عملکرد برای یک مدل کوچک زبان مستقر در Edge چیست؟  
5. یک جریان کاری کامل از انتخاب مدل تا پیاده‌سازی تولید را توضیح دهید.  

### تمرین‌های عملی  

1. **استقرار محلی ساده**: استقرار یک مدل کوچک زبان با استفاده از Ollama (1 ساعت)  
2. **بررسی عملکرد**: اجرای یک بنچمارک سریع روی مدل مستقر شده (30 دقیقه)  
3. **یکپارچه‌سازی ساده**: ایجاد یک اپلیکیشن کوچک که از مدل مستقر شده استفاده کند (1 ساعت)  

## ماژول 4: تبدیل فرمت مدل و کوانتیزاسیون  

### اهداف کلیدی یادگیری  

- تسلط بر تکنیک‌های پیشرفته کوانتیزاسیون از دقت 1 بیت تا 8 بیت  
- درک استراتژی‌های تبدیل فرمت (GGUF، ONNX)  
- پیاده‌سازی بهینه‌سازی در شش فریم‌ورک (Llama.cpp، Olive، OpenVINO، MLX، ترکیب جریان کاری)  
- استقرار مدل‌های بهینه‌سازی شده برای محیط‌های تولیدی Edge در سخت‌افزارهای Intel، Apple و چند پلتفرمی  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: مبانی کوانتیزاسیون  
- **مفاهیم اولویت‌دار**:  
  - چارچوب طبقه‌بندی دقت  
  - توازن عملکرد و دقت  
  - بهینه‌سازی حافظه  

#### بخش 2: پیاده‌سازی Llama.cpp  
- **مفاهیم اولویت‌دار**:  
  - استقرار چند پلتفرمی  
  - بهینه‌سازی فرمت GGUF  
  - تکنیک‌های شتاب‌دهی سخت‌افزاری  

#### بخش 3: مجموعه Microsoft Olive  
- **مفاهیم اولویت‌دار**:  
  - بهینه‌سازی مبتنی بر سخت‌افزار  
  - استقرار در سطح سازمانی  
  - جریان‌های کاری بهینه‌سازی خودکار  

#### بخش 4: ابزار OpenVINO  
- **مفاهیم اولویت‌دار**:  
  - بهینه‌سازی سخت‌افزار Intel  
  - چارچوب فشرده‌سازی شبکه عصبی (NNCF)  
  - استقرار استنتاج چند پلتفرمی  
  - OpenVINO GenAI برای استقرار مدل‌های زبان بزرگ  

#### بخش 5: فریم‌ورک Apple MLX  
- **مفاهیم اولویت‌دار**:  
  - بهینه‌سازی Apple Silicon  
  - معماری حافظه یکپارچه  
  - قابلیت‌های تنظیم دقیق LoRA  

#### بخش 6: ترکیب جریان کاری توسعه Edge AI  
- **مفاهیم اولویت‌دار**:  
  - معماری جریان کاری یکپارچه  
  - درخت‌های تصمیم‌گیری انتخاب فریم‌ورک  
  - اعتبارسنجی آمادگی تولید  
  - استراتژی‌های آینده‌نگر  

### سوالات ارزیابی خود  

1. استراتژی‌های کوانتیزاسیون در سطوح مختلف دقت (1 بیت تا 8 بیت) را مقایسه کنید.  
2. مزایای فرمت GGUF برای استقرار در Edge چیست؟  
3. چگونه بهینه‌سازی مبتنی بر سخت‌افزار در Microsoft Olive کارایی استقرار را بهبود می‌بخشد؟  
4. مزایای کلیدی NNCF در OpenVINO برای فشرده‌سازی مدل چیست؟  
5. توضیح دهید که Apple MLX چگونه از معماری حافظه یکپارچه برای بهینه‌سازی استفاده می‌کند.  
6. ترکیب جریان کاری چگونه در انتخاب فریم‌ورک‌های بهینه‌سازی کمک می‌کند؟  

### تمرین‌های عملی  

1. **کوانتیزاسیون مدل**: اعمال سطوح مختلف کوانتیزاسیون به یک مدل و مقایسه نتایج (1 ساعت)  
2. **بهینه‌سازی OpenVINO**: استفاده از NNCF برای فشرده‌سازی یک مدل برای سخت‌افزار Intel (1 ساعت)  
3. **مقایسه فریم‌ورک‌ها**: آزمایش یک مدل مشابه در سه فریم‌ورک بهینه‌سازی مختلف (1 ساعت)  
4. **بنچمارک عملکرد**: اندازه‌گیری تاثیر بهینه‌سازی بر سرعت استنتاج و استفاده از حافظه (1 ساعت)  

## ماژول 5: SLMOps - عملیات مدل‌های کوچک زبان  

### اهداف کلیدی یادگیری  

- درک اصول مدیریت چرخه عمر SLMOps  
- تسلط بر تکنیک‌های تقطیر و تنظیم دقیق برای استقرار در Edge  
- پیاده‌سازی استراتژی‌های استقرار تولید با نظارت  
- ساخت جریان‌های کاری عملیات و نگهداری مدل‌های کوچک زبان در سطح سازمانی  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: معرفی SLMOps  
- **مفاهیم اولویت‌دار**:  
  - تغییر پارادایم SLMOps در عملیات هوش مصنوعی  
  - معماری اولویت‌دار هزینه و حریم خصوصی  
  - تاثیر استراتژیک بر کسب‌وکار و مزایای رقابتی  

#### بخش 2: تقطیر مدل  
- **مفاهیم اولویت‌دار**:  
  - تکنیک‌های انتقال دانش  
  - پیاده‌سازی فرآیند تقطیر دو مرحله‌ای  
  - جریان‌های کاری تقطیر Azure ML  

#### بخش 3: استراتژی‌های تنظیم دقیق  
- **مفاهیم اولویت‌دار**:  
  - تنظیم دقیق پارامتر-کارآمد (PEFT)  
  - روش‌های پیشرفته LoRA و QLoRA  
  - آموزش چند آداپتری و بهینه‌سازی هایپرپارامتر  

#### بخش 4: استقرار تولید  
- **مفاهیم اولویت‌دار**:  
  - تبدیل مدل و کوانتیزاسیون برای تولید  
  - پیکربندی استقرار Foundry Local  
  - بنچمارک عملکرد و اعتبارسنجی کیفیت  

### سوالات ارزیابی خود  

1. SLMOps چگونه با MLOps سنتی تفاوت دارد؟  
2. مزایای تقطیر مدل برای استقرار در Edge چیست؟  
3. ملاحظات کلیدی برای تنظیم دقیق مدل‌های کوچک زبان در محیط‌های محدود منابع چیست؟  
4. یک جریان کاری کامل استقرار تولید برای اپلیکیشن‌های Edge AI را توضیح دهید.  

### تمرین‌های عملی  

1. **تقطیر ساده**: ایجاد یک مدل کوچک‌تر از یک مدل معلم بزرگ‌تر (1 ساعت)  
2. **آزمایش تنظیم دقیق**: تنظیم دقیق یک مدل برای یک حوزه خاص (1 ساعت)  
3. **جریان کاری استقرار**: راه‌اندازی یک جریان کاری CI/CD ساده برای استقرار مدل (1 ساعت)  

## ماژول 6: سیستم‌های عامل مدل‌های کوچک زبان - عوامل هوش مصنوعی و فراخوانی توابع  

### اهداف کلیدی یادگیری  

- ساخت عوامل هوش مصنوعی هوشمند برای محیط‌های Edge با استفاده از مدل‌های کوچک زبان  
- پیاده‌سازی قابلیت‌های فراخوانی توابع با جریان‌های کاری سیستماتیک  
- تسلط بر ادغام پروتکل زمینه مدل (MCP) برای تعامل استاندارد ابزارها  
- ایجاد سیستم‌های عامل پیچیده با حداقل مداخله انسانی  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: عوامل هوش مصنوعی و مبانی مدل‌های کوچک زبان  
- **مفاهیم اولویت‌دار**:  
  - چارچوب طبقه‌بندی عوامل (انعکاسی، مبتنی بر مدل، مبتنی بر هدف، عوامل یادگیری)  
  - تحلیل توازن مدل‌های کوچک زبان در مقابل مدل‌های بزرگ زبان  
  - الگوهای طراحی خاص برای عوامل Edge  
  - بهینه‌سازی منابع برای عوامل  

#### بخش 2: فراخوانی توابع در مدل‌های کوچک زبان  
- **مفاهیم اولویت‌دار**:  
  - پیاده‌سازی جریان کاری سیستماتیک (تشخیص قصد، خروجی JSON، اجرای خارجی)  
  - پیاده‌سازی‌های خاص پلتفرم (Phi-4-mini، مدل‌های منتخب Qwen، Microsoft Foundry Local)  
  - مثال‌های پیشرفته (همکاری چند عامل، انتخاب ابزار پویا)  
  - ملاحظات تولید (محدودیت نرخ، ثبت ممیزی، اقدامات امنیتی)  

#### بخش 3: ادغام پروتکل زمینه مدل (MCP)  
- **مفاهیم اولویت‌دار**:  
  - معماری پروتکل و طراحی سیستم لایه‌ای  
  - پشتیبانی چند بک‌اند (Ollama برای توسعه، vLLM برای تولید)  
  - پروتکل‌های اتصال (حالت‌های STDIO و SSE)  
  - کاربردهای واقعی (اتوماسیون وب، پردازش داده، ادغام API)  

### سوالات ارزیابی خود  

1. ملاحظات کلیدی معماری برای عوامل هوش مصنوعی Edge چیست؟  
2. فراخوانی توابع چگونه قابلیت‌های عوامل را افزایش می‌دهد؟  
3. نقش پروتکل زمینه مدل در ارتباط عوامل چیست؟  

### تمرین‌های عملی  

1. **عامل ساده**: ساخت یک عامل هوش مصنوعی ساده با فراخوانی توابع (1 ساعت)  
2. **ادغام MCP**: پیاده‌سازی MCP در یک اپلیکیشن عامل (30 دقیقه)  

## ماژول 7: نمونه‌های پیاده‌سازی EdgeAI  

### اهداف کلیدی یادگیری  

- تسلط بر ابزار هوش مصنوعی برای Visual Studio Code برای جریان‌های کاری جامع توسعه EdgeAI  
- کسب تخصص در پلتفرم Windows AI Foundry و استراتژی‌های بهینه‌سازی NPU  
- پیاده‌سازی EdgeAI در چندین پلتفرم سخت‌افزاری و سناریوهای استقرار  
- ساخت اپلیکیشن‌های EdgeAI آماده تولید با بهینه‌سازی‌های خاص پلتفرم  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: ابزار هوش مصنوعی برای Visual Studio Code  
- **مفاهیم اولویت‌دار**:  
  - محیط جامع توسعه Edge AI در VS Code  
  - کاتالوگ مدل و کشف برای استقرار Edge  
  - جریان‌های کاری تست محلی، بهینه‌سازی و توسعه عامل  
  - نظارت بر عملکرد و ارزیابی برای سناریوهای Edge  

#### بخش 2: راهنمای توسعه EdgeAI ویندوز  
- **مفاهیم اولویت‌دار**:  
  - نمای کلی جامع پلتفرم Windows AI Foundry  
  - API Phi Silica برای استنتاج کارآمد NPU  
  - API‌های بینایی کامپیوتری برای پردازش تصویر و OCR  
  - CLI Foundry Local برای توسعه و تست محلی  

#### بخش 3: پیاده‌سازی‌های خاص پلتفرم  
- **مفاهیم اولویت‌دار**:  
  - استقرار NVIDIA Jetson Orin Nano (عملکرد AI 67 TOPS)  
  - اپلیکیشن‌های موبایل با .NET MAUI و ONNX Runtime GenAI  
  - راه‌حل‌های Azure EdgeAI با معماری ترکیبی ابری-Edge  
  - بهینه‌سازی Windows ML با پشتیبانی سخت‌افزار جهانی  
  - اپلیکیشن‌های Foundry Local با پیاده‌سازی RAG متمرکز بر حریم خصوصی  

### سوالات ارزیابی خود  

1. ابزار هوش مصنوعی چگونه جریان کاری توسعه EdgeAI را ساده می‌کند؟  
2. استراتژی‌های استقرار در پلتفرم‌های سخت‌افزاری مختلف را مقایسه کنید.  
3. مزایای Windows AI Foundry برای توسعه Edge چیست؟  
4. نقش بهینه‌سازی NPU در اپلیکیشن‌های Edge AI مدرن چیست؟  
5. API Phi Silica چگونه از سخت‌افزار NPU برای بهینه‌سازی عملکرد استفاده می‌کند؟  
6. مزایای استقرار محلی در مقابل استقرار ابری برای اپلیکیشن‌های حساس به حریم خصوصی چیست؟  

### تمرین‌های عملی  

1. **راه‌اندازی ابزار هوش مصنوعی**: پیکربندی ابزار هوش مصنوعی و بهینه‌سازی یک مدل (1 ساعت)  
2. **Windows AI Foundry**: ساخت یک اپلیکیشن ساده هوش مصنوعی ویندوز با استفاده از API Phi Silica (1 ساعت)  
3. **استقرار چند پلتفرمی**: استقرار یک مدل مشابه در دو پلتفرم مختلف (1 ساعت)  
4. **بهینه‌سازی NPU**: تست عملکرد NPU با ابزارهای Windows AI Foundry (30 دقیقه)  

## ماژول 8: Microsoft Foundry Local – ابزار کامل توسعه‌دهنده (مدرن شده)  

### اهداف کلیدی یادگیری  

- نصب و پیکربندی Foundry Local با ادغام SDK مدرن  
- پیاده‌سازی سیستم‌های چند عاملی پیشرفته با الگوهای هماهنگ‌کننده  
- ساخت مسیریاب‌های مدل هوشمند با انتخاب خودکار مبتنی بر وظیفه  
- استقرار راه‌حل‌های هوش مصنوعی آماده تولید با نظارت جامع  
- ادغام با Azure AI Foundry برای سناریوهای استقرار ترکیبی  
- تسلط بر الگوهای SDK مدرن با FoundryLocalManager و کلاینت OpenAI  

### حوزه‌های تمرکز مطالعه  

#### بخش 1: نصب و پیکربندی مدرن  
- **مفاهیم اولویت‌دار**:  
  - ادغام SDK FoundryLocalManager  
  - کشف خودکار سرویس و نظارت بر سلامت  
  - الگوهای پیکربندی مبتنی بر محیط  
  - ملاحظات استقرار تولید  

#### بخش 2: سیستم‌های چند عاملی پیشرفته  
- **مفاهیم اولویت‌دار**:  
  - الگوی هماهنگ‌کننده با عوامل متخصص  
  - تخصص عوامل در بازیابی، استدلال و اجرا  
  - مکانیسم‌های حلقه بازخورد برای اصلاح  
  - نظارت بر عملکرد و ردیابی آمار  

#### بخش 3: مسیریابی مدل هوشمند  
- **مفاهیم اولویت‌دار**:  
  - الگوریتم‌های انتخاب مدل مبتنی بر کلمات کلیدی  
  - پشتیبانی از مدل‌های متعدد (عمومی، استدلال، کدنویسی، خلاقانه)  
  - پیکربندی متغیرهای محیطی برای انعطاف‌پذیری  
  - بررسی سلامت سرویس و مدیریت خطا  

#### بخش 4: پیاده‌سازی آماده تولید  
- **مفاهیم اولویت‌دار**:  
  - مدیریت جامع خطا و مکانیسم‌های جایگزین  
  - نظارت بر درخواست‌ها و ردیابی عملکرد  
  - مثال‌های تعاملی Jupyter notebook با بنچمارک‌ها  
  - الگوهای ادغام با اپلیکیشن‌های موجود  

### سوالات ارزیابی خود  

1. رویکرد مدرن FoundryLocalManager چگونه با فراخوانی دستی REST تفاوت دارد؟  
2. الگوی هماهنگ‌کننده چیست و چگونه عوامل متخصص را هماهنگ می‌کند؟  
3. مسیریاب هوشمند چگونه مدل‌های مناسب را بر اساس محتوای پرسش انتخاب می‌کند؟  
4. اجزای کلیدی یک سیستم عامل هوش مصنوعی آماده تولید چیست؟  
5. چگونه نظارت جامع بر سلامت سرویس‌های Foundry Local را پیاده‌سازی می‌کنید؟  
6. مزایای رویکرد مدرن شده در مقابل الگوهای پیاده‌سازی سنتی چیست؟  

### تمرین‌های عملی  

1. **راه‌اندازی SDK مدرن**: پیکربندی FoundryLocalManager با کشف خودکار سرویس (30 دقیقه)  
2. **سیستم چند عاملی**: اجرای هماهنگ‌کننده پیشرفته با عوامل متخصص (30 دقیقه)  
3. **مسیریابی هوشمند**: تست مسیریاب مدل با انواع پرسش‌های مختلف (30 دقیقه)  
4. **اکتشاف تعاملی**: استفاده از Jupyter notebooks برای کشف ویژگی‌های پیشرفته (45 دقیقه)  
5. **استقرار تولید**: پیاده‌سازی الگوهای نظارت و مدیریت خطا (30 دقیقه)  
6. **ادغام ترکیبی**: پیکربندی سناریوهای جایگزین Azure AI Foundry (30 دقیقه)  

## راهنمای تخصیص
| تمرین‌های عملی | ۶ ساعت | پیاده‌سازی عملی تکنیک‌های کلیدی |
| ارزیابی شخصی | ۲ ساعت | آزمون درک خود از طریق سوالات و بازتاب |
| پروژه کوچک | ۳ ساعت | به‌کارگیری دانش در یک پیاده‌سازی عملی کوچک |

### تمرکز‌های کلیدی بر اساس محدودیت زمانی

**اگر فقط ۱۰ ساعت وقت دارید:**
- ماژول ۰ (مقدمه) و ماژول‌های ۱، ۲ و ۳ (مفاهیم اصلی EdgeAI) را کامل کنید.
- حداقل یک تمرین عملی در هر ماژول انجام دهید.
- بر درک مفاهیم اصلی تمرکز کنید و جزئیات پیاده‌سازی را در اولویت قرار ندهید.

**اگر می‌توانید ۲۰ ساعت کامل اختصاص دهید:**
- تمام هشت ماژول (شامل مقدمه) را کامل کنید.
- تمرین‌های عملی کلیدی هر ماژول را انجام دهید.
- یک پروژه کوچک از ماژول ۷ را کامل کنید.
- حداقل ۲-۳ منابع تکمیلی را بررسی کنید.

**اگر بیش از ۲۰ ساعت وقت دارید:**
- تمام ماژول‌ها (شامل مقدمه) را با جزئیات تمرین‌ها کامل کنید.
- چندین پروژه کوچک بسازید.
- تکنیک‌های پیشرفته بهینه‌سازی در ماژول ۴ را بررسی کنید.
- پیاده‌سازی استقرار تولیدی از ماژول ۵ را انجام دهید.

## منابع ضروری

این منابع با دقت انتخاب شده‌اند تا بیشترین ارزش را برای زمان محدود مطالعه شما فراهم کنند:

### مستندات ضروری
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - کارآمدترین ابزار بهینه‌سازی مدل
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - سریع‌ترین راه برای استقرار SLM‌ها به صورت محلی
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - مرجع برای یک مدل بهینه‌سازی شده برای Edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - ابزار جامع بهینه‌سازی اینتل
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - محیط توسعه یکپارچه EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - پلتفرم توسعه EdgeAI مخصوص ویندوز

### ابزارهای صرفه‌جویی در زمان
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - دسترسی سریع به مدل‌ها و استقرار
- [Gradio](https://www.gradio.app/docs/interface) - توسعه سریع رابط کاربری برای دموهای AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - بهینه‌سازی ساده مدل
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - استنتاج کارآمد CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - چارچوب فشرده‌سازی شبکه عصبی
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - ابزار استقرار مدل‌های زبان بزرگ

## قالب پیگیری پیشرفت

از این قالب ساده برای پیگیری پیشرفت یادگیری خود در دوره ۲۰ ساعته استفاده کنید:

| ماژول | تاریخ تکمیل | ساعات صرف شده | نکات کلیدی |
|-------|------------|---------------|------------|
| ماژول ۰: مقدمه‌ای بر EdgeAI | | | |
| ماژول ۱: اصول EdgeAI | | | |
| ماژول ۲: مبانی SLM | | | |
| ماژول ۳: استقرار SLM | | | |
| ماژول ۴: بهینه‌سازی مدل | | | |
| ماژول ۵: SLMOps | | | |
| ماژول ۶: عوامل هوش مصنوعی | | | |
| ماژول ۷: ابزارهای توسعه | | | |
| ماژول ۸: ابزار محلی Foundry | | | |
| تمرین‌های عملی | | | |
| پروژه کوچک | | | |

## ایده‌های پروژه کوچک

یکی از این پروژه‌ها را برای تمرین مفاهیم EdgeAI در نظر بگیرید (هر کدام طراحی شده‌اند تا ۲-۴ ساعت زمان ببرند):

### پروژه‌های مبتدی (۲-۳ ساعت هر کدام)
1. **دستیار متنی Edge**: یک ابزار تکمیل متن ساده آفلاین با استفاده از یک مدل زبان کوچک ایجاد کنید.
2. **داشبورد مقایسه مدل**: یک بصری‌سازی ساده از معیارهای عملکرد در مدل‌های مختلف SLM بسازید.
3. **آزمایش بهینه‌سازی**: تاثیر سطوح مختلف کمیت‌سازی را بر یک مدل پایه اندازه‌گیری کنید.

### پروژه‌های متوسط (۳-۴ ساعت هر کدام)
4. **جریان کاری ابزار AI**: از ابزار AI در VS Code برای بهینه‌سازی و استقرار یک مدل از ابتدا تا انتها استفاده کنید.
5. **برنامه Foundry AI ویندوز**: یک برنامه ویندوز با استفاده از API Phi Silica و بهینه‌سازی NPU ایجاد کنید.
6. **استقرار چند پلتفرمی**: همان مدل بهینه‌سازی شده را در ویندوز (OpenVINO) و موبایل (.NET MAUI) مستقر کنید.
7. **عامل فراخوانی عملکرد**: یک عامل هوش مصنوعی با قابلیت فراخوانی عملکرد برای سناریوهای Edge بسازید.

### پروژه‌های پیشرفته یکپارچه‌سازی (۴-۵ ساعت هر کدام)
8. **خط لوله بهینه‌سازی OpenVINO**: بهینه‌سازی کامل مدل با استفاده از NNCF و ابزار GenAI را پیاده‌سازی کنید.
9. **خط لوله SLMOps**: چرخه کامل مدل از آموزش تا استقرار Edge را پیاده‌سازی کنید.
10. **سیستم Edge چند مدلی**: چندین مدل تخصصی را که با هم روی سخت‌افزار Edge کار می‌کنند مستقر کنید.
11. **سیستم یکپارچه MCP**: یک سیستم عامل‌محور با استفاده از پروتکل زمینه مدل برای تعامل ابزار بسازید.

## منابع

- Microsoft Learn (Foundry Local)
  - نمای کلی: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - شروع به کار: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - مرجع CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - یکپارچه‌سازی با SDK‌های استنتاج: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - نحوه استفاده از Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - کامپایل مدل‌های Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - نمای کلی: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - عوامل (نمای کلی): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- ابزارهای بهینه‌سازی و استنتاج
  - Microsoft Olive (مستندات): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (شروع به کار): https://onnxruntime.ai/docs/get-started/with-python.html
  - یکپارچه‌سازی ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (مستندات): https://docs.openvino.ai/2025/index.html
  - Apple MLX (مستندات): https://ml-explore.github.io/mlx/build/html/index.html
- چارچوب‌های استقرار و مدل‌ها
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (مستندات): https://docs.vllm.ai/
  - Ollama (شروع سریع): https://github.com/ollama/ollama#get-started
- ابزارهای توسعه (ویندوز و VS Code)
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (نمای کلی): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## جامعه یادگیری

به بحث بپیوندید و با دیگر یادگیرندگان ارتباط برقرار کنید:
- بحث‌های GitHub در [مخزن EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [جامعه فناوری مایکروسافت](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## نتیجه‌گیری

EdgeAI نمایانگر مرزهای پیشرفته پیاده‌سازی هوش مصنوعی است که قابلیت‌های قدرتمند را مستقیماً به دستگاه‌ها می‌آورد و در عین حال نگرانی‌های مهمی مانند حریم خصوصی، تأخیر و اتصال را برطرف می‌کند. این دوره ۲۰ ساعته دانش ضروری و مهارت‌های عملی را برای شروع کار با فناوری‌های EdgeAI فوراً در اختیار شما قرار می‌دهد.

این دوره به‌طور عمدی مختصر و متمرکز بر مهم‌ترین مفاهیم طراحی شده است تا به شما امکان دهد بدون تعهد زمانی بیش از حد، سریعاً تخصص ارزشمندی کسب کنید. به یاد داشته باشید که تمرین عملی، حتی با مثال‌های ساده، کلید تقویت آنچه یاد گرفته‌اید است.

یادگیری خوشایند!

---

