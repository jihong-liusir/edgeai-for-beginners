<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-17T15:13:35+00:00",
  "source_file": "Module06/README.md",
  "language_code": "fa"
}
-->
# فصل ۰۶: سیستم‌های عامل SLM: یک مرور جامع

چشم‌انداز هوش مصنوعی در حال تجربه یک تحول بنیادین است، زیرا از چت‌بات‌های ساده به سمت عوامل هوشمند پیشرفته‌ای که توسط مدل‌های کوچک زبانی (SLM) قدرت گرفته‌اند، حرکت می‌کنیم. این راهنمای جامع به سه جنبه حیاتی سیستم‌های عامل مدرن SLM می‌پردازد: مفاهیم پایه و استراتژی‌های پیاده‌سازی، قابلیت‌های فراخوانی توابع، و ادغام انقلابی پروتکل زمینه مدل (MCP).

## [بخش ۱: عوامل هوش مصنوعی و پایه مدل‌های کوچک زبانی](./01.IntroduceAgent.md)

بخش اول به درک پایه‌ای عوامل هوش مصنوعی و مدل‌های کوچک زبانی می‌پردازد و سال ۲۰۲۵ را به عنوان سال عوامل هوش مصنوعی پس از عصر چت‌بات‌ها در سال ۲۰۲۳ و رونق کوپایلوت‌ها در سال ۲۰۲۴ معرفی می‌کند. این بخش سیستم‌های هوش مصنوعی عامل‌محور را معرفی می‌کند که می‌توانند فکر کنند، استدلال کنند، برنامه‌ریزی کنند، از ابزارها استفاده کنند و وظایف را با کمترین دخالت انسانی اجرا کنند.

### مفاهیم کلیدی پوشش داده شده:
- **چارچوب طبقه‌بندی عوامل**: از عوامل بازتابی ساده تا عوامل یادگیرنده، ارائه یک طبقه‌بندی جامع برای سناریوهای مختلف محاسباتی
- **مبانی SLM**: تعریف مدل‌های کوچک زبانی به عنوان مدل‌هایی با کمتر از ۱۰ میلیارد پارامتر که می‌توانند استنتاج عملی را بر روی دستگاه‌های مصرف‌کننده انجام دهند
- **استراتژی‌های بهینه‌سازی پیشرفته**: پوشش فرمت GGUF برای پیاده‌سازی، تکنیک‌های کمینه‌سازی (Q4_K_M، Q5_K_S، Q8_0)، و چارچوب‌های بهینه‌سازی شده برای لبه مانند Llama.cpp و Apple MLX
- **مقایسه SLM و LLM**: نشان دادن کاهش هزینه ۱۰ تا ۳۰ برابر با SLM‌ها در حالی که برای ۷۰ تا ۸۰ درصد وظایف معمول عوامل موثر باقی می‌مانند

این بخش با استراتژی‌های عملی پیاده‌سازی با استفاده از Ollama، VLLM، و راه‌حل‌های لبه مایکروسافت به پایان می‌رسد و SLM‌ها را به عنوان آینده‌ای برای پیاده‌سازی هوش مصنوعی عامل‌محور مقرون‌به‌صرفه و حفظ حریم خصوصی معرفی می‌کند.

## [بخش ۲: فراخوانی توابع در مدل‌های کوچک زبانی](./02.FunctionCalling.md)

بخش دوم به طور عمیق به **قابلیت‌های فراخوانی توابع** می‌پردازد، مکانیزمی که مدل‌های زبانی ایستا را به عوامل هوش مصنوعی پویا تبدیل می‌کند که قادر به تعامل با دنیای واقعی هستند. این بررسی فنی کامل، جریان کاری از تشخیص قصد تا ادغام پاسخ را پوشش می‌دهد.

### حوزه‌های اصلی پیاده‌سازی:
- **جریان کاری سیستماتیک**: بررسی دقیق ادغام ابزارها، تعریف توابع، تشخیص قصد، تولید خروجی JSON، و اجرای خارجی
- **پیاده‌سازی‌های خاص پلتفرم**: راهنماهای جامع برای Phi-4-mini با Ollama، فراخوانی توابع Qwen3، و ادغام محلی Microsoft Foundry
- **نمونه‌های پیشرفته**: سیستم‌های همکاری چندعاملی، انتخاب ابزار پویا، و الگوهای ادغام سازمانی با مدیریت جامع خطا
- **ملاحظات تولید**: محدودیت نرخ، ثبت گزارش‌های حسابرسی، اقدامات امنیتی، و استراتژی‌های بهینه‌سازی عملکرد

این بخش هم درک نظری و هم الگوهای عملی پیاده‌سازی را ارائه می‌دهد و به توسعه‌دهندگان امکان می‌دهد سیستم‌های فراخوانی توابع قدرتمندی بسازند که بتوانند از فراخوانی‌های ساده API تا جریان‌های کاری پیچیده چندمرحله‌ای سازمانی را مدیریت کنند.

## [بخش ۳: ادغام پروتکل زمینه مدل (MCP)](./03.IntroduceMCP.md)

بخش نهایی **پروتکل زمینه مدل (MCP)** را معرفی می‌کند، یک چارچوب انقلابی که استانداردی برای تعامل مدل‌های زبانی با ابزارها و سیستم‌های خارجی ایجاد می‌کند. این بخش نشان می‌دهد که چگونه MCP از طریق پروتکل‌های تعریف‌شده، پلی بین مدل‌های هوش مصنوعی و دنیای واقعی ایجاد می‌کند.

### نکات برجسته ادغام:
- **معماری پروتکل**: طراحی سیستم لایه‌ای شامل لایه‌های کاربرد، مشتری LLM، مشتری MCP، و پردازش ابزار
- **پشتیبانی چندپشتیبان**: پیاده‌سازی انعطاف‌پذیر که از هر دو Ollama (توسعه محلی) و vLLM (تولید) پشتیبانی می‌کند
- **پروتکل‌های اتصال**: حالت STDIO برای ارتباط مستقیم فرآیند و حالت SSE برای جریان مبتنی بر HTTP
- **کاربردهای دنیای واقعی**: نمونه‌های اتوماسیون وب، پردازش داده‌ها، و ادغام API با مدیریت جامع خطا

ادغام MCP نشان می‌دهد که چگونه SLM‌ها می‌توانند با قابلیت‌های خارجی تقویت شوند، کمبود تعداد پارامترهای خود را با عملکردهای پیشرفته جبران کنند و در عین حال مزایای پیاده‌سازی محلی و بهره‌وری منابع را حفظ کنند.

## پیامدهای استراتژیک

این سه بخش با هم یک چارچوب جامع برای درک و پیاده‌سازی سیستم‌های عامل SLM ارائه می‌دهند. تکامل از مفاهیم پایه از طریق فراخوانی توابع تا ادغام MCP مسیر روشنی را به سمت پیاده‌سازی دموکراتیک هوش مصنوعی نشان می‌دهد که در آن:

- **بهره‌وری با قابلیت‌ها ترکیب می‌شود** از طریق مدل‌های کوچک بهینه‌شده
- **مقرون‌به‌صرفه بودن** پذیرش گسترده را ممکن می‌سازد
- **پروتکل‌های استاندارد** قابلیت همکاری را تضمین می‌کنند
- **پیاده‌سازی محلی** حریم خصوصی را حفظ کرده و تأخیر را کاهش می‌دهد

این پیشرفت نه تنها یک پیشرفت تکنولوژیکی بلکه یک تغییر پارادایم به سمت سیستم‌های هوش مصنوعی قابل دسترس‌تر، کارآمدتر و عملی‌تر است که می‌توانند به طور موثر در محیط‌های محدود منابع عمل کنند و در عین حال قابلیت‌های عامل‌محور پیشرفته‌ای ارائه دهند.

ترکیب SLM‌ها با استراتژی‌های پیشرفته پیاده‌سازی، فراخوانی توابع قدرتمند، و پروتکل‌های استاندارد ادغام ابزار، این سیستم‌ها را به عنوان پایه‌ای برای نسل بعدی عوامل هوش مصنوعی قرار می‌دهد که نحوه تعامل و بهره‌مندی ما از هوش مصنوعی در صنایع و کاربردهای مختلف را متحول خواهند کرد.

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادقتی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.