<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7256301d9d690c2054eabbf2bc5b10bf",
  "translation_date": "2025-09-22T17:44:42+00:00",
  "source_file": "Module08/06.ModelsAsTools.md",
  "language_code": "bn"
}
-->
# সেশন ৬: Foundry Local – টুল হিসেবে মডেল

## সংক্ষিপ্ত বিবরণ

Foundry Local-এর মাধ্যমে AI মডেলগুলোকে মডুলার, কাস্টমাইজযোগ্য টুল হিসেবে ব্যবহার করুন যা সরাসরি ডিভাইসে চলে। এই সেশনে গোপনীয়তা রক্ষা করে, কম লেটেন্সি ইনফারেন্সের জন্য ব্যবহারিক ওয়ার্কফ্লো এবং SDKs, APIs বা CLI-এর মাধ্যমে এই টুলগুলোকে কীভাবে ইন্টিগ্রেট করা যায় তা নিয়ে আলোচনা করা হয়েছে। এছাড়াও, প্রয়োজনে Azure AI Foundry-তে স্কেল করার পদ্ধতি শিখবেন।

রেফারেন্স:
- Foundry Local ডকুমেন্টেশন: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ইনফারেন্স SDKs-এর সাথে ইন্টিগ্রেশন: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face মডেল কম্পাইল করা: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## শেখার লক্ষ্য
- ডিভাইসে মডেল-হিসেবে-টুল প্যাটার্ন ডিজাইন করা
- OpenAI-সামঞ্জস্যপূর্ণ REST API বা SDKs-এর মাধ্যমে ইন্টিগ্রেট করা
- মডেলগুলোকে ডোমেইন-নির্দিষ্ট ব্যবহারের জন্য কাস্টমাইজ করা
- Azure AI Foundry-তে হাইব্রিড স্কেলিংয়ের পরিকল্পনা করা

## অংশ ১: টুল অ্যাবস্ট্রাকশন (ধাপে ধাপে)

লক্ষ্য: মডেলগুলোকে টুল হিসেবে উপস্থাপন করা, যেখানে স্পষ্ট কন্ট্রাক্ট এবং একটি সহজ রাউটার থাকবে।

ধাপ ১) টুল ইন্টারফেস এবং রেজিস্ট্রি সংজ্ঞায়িত করুন  
```python
# tools/registry.py
from dataclasses import dataclass
from typing import Callable, Dict

@dataclass
class Tool:
    name: str
    description: str
    input_schema: Dict
    output_schema: Dict
    handler: Callable[[Dict], Dict]

REGISTRY: Dict[str, Tool] = {}

def register(tool: Tool):
    REGISTRY[tool.name] = tool

def get_tool(name: str) -> Tool:
    return REGISTRY[name]
```
  
ধাপ ২) Foundry Local দ্বারা সমর্থিত দুটি টুল বাস্তবায়ন করুন  
```python
# tools/impl.py
import requests, os
from tools.registry import Tool, register

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}

# Chat tool (general assistant)

def chat_handler(payload: dict) -> dict:
    model = payload.get("model", "phi-4-mini")
    messages = payload.get("messages", [{"role":"user","content":"Hello"}])
    r = requests.post(f"{BASE_URL}/chat/completions", json={
        "model": model,
        "messages": messages,
        "max_tokens": payload.get("max_tokens", 300),
        "temperature": payload.get("temperature", 0.6)
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    msg = r.json()["choices"][0]["message"]["content"]
    return {"content": msg}

register(Tool(
    name="chat.assistant",
    description="General chat assistant",
    input_schema={"type":"object","properties":{"messages":{"type":"array"}}},
    output_schema={"type":"object","properties":{"content":{"type":"string"}}},
    handler=chat_handler
))

# Summarizer tool

def summarize_handler(payload: dict) -> dict:
    model = payload.get("model", "phi-4-mini")
    text = payload.get("text", "")
    messages = [
        {"role":"system","content":"You summarize text into 3 concise bullet points."},
        {"role":"user","content": f"Summarize:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
        "model": model,
        "messages": messages,
        "max_tokens": 200,
        "temperature": 0.2
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    return {"summary": r.json()["choices"][0]["message"]["content"]}

register(Tool(
    name="text.summarize",
    description="Summarize text into bullets",
    input_schema={"type":"object","properties":{"text":{"type":"string"}}},
    output_schema={"type":"object","properties":{"summary":{"type":"string"}}},
    handler=summarize_handler
))
```
  
ধাপ ৩) টাস্ক অনুযায়ী রাউটার  
```python
# tools/router.py
from tools.registry import get_tool

def route(task: str, payload: dict):
    mapping = {
        "general": "chat.assistant",
        "summarize": "text.summarize"
    }
    tool = get_tool(mapping[task])
    return tool.handler(payload)

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    print(route("general", {"messages":[{"role":"user","content":"Hi!"}]}))
    print(route("summarize", {"text":"Edge AI brings models to devices for privacy and low latency."}))
```
  

## অংশ ২: SDK এবং API ইন্টিগ্রেশন (ধাপে ধাপে)

লক্ষ্য: Foundry Local এন্ডপয়েন্টের বিরুদ্ধে OpenAI Python SDK ব্যবহার করা।

ধাপ ১) ইনস্টল করুন  
```cmd
cd Module08
.\.venv\Scripts\activate
pip install openai
```
  
ধাপ ২) পরিবেশ ভেরিয়েবল কনফিগার করুন  
```cmd
setx OPENAI_BASE_URL http://localhost:8000/v1
setx OPENAI_API_KEY local-key
```
  
ধাপ ৩) চ্যাট API কল করুন  
```python
# sdk_demo.py
from openai import OpenAI
import os

client = OpenAI(
    base_url=os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1"),
    api_key=os.getenv("OPENAI_API_KEY", "local-key")
)

resp = client.chat.completions.create(
    model="phi-4-mini",
    messages=[{"role": "user", "content": "Summarize edge AI in one sentence."}],
    max_tokens=64
)
print(resp.choices[0].message.content)
```
  

## অংশ ৩: ডোমেইন কাস্টমাইজেশন (ধাপে ধাপে)

লক্ষ্য: প্রম্পট টেমপ্লেট এবং JSON স্কিমা ব্যবহার করে ডোমেইনের জন্য আউটপুট কাস্টমাইজ করা।

ধাপ ১) একটি ডোমেইন প্রম্পট টেমপ্লেট তৈরি করুন  
```python
# domain/templates.py
BUSINESS_ANALYST_SYSTEM = """
You are a senior business analyst. Provide:
1) Key insights
2) Risks
3) Next steps
Respond in valid JSON with fields: insights, risks, next_steps.
"""
```
  
ধাপ ২) JSON আউটপুট নিশ্চিত করুন  
```python
# domain/analyst.py
import requests, os, json

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}

from domain.templates import BUSINESS_ANALYST_SYSTEM

def analyze(text: str) -> dict:
    messages = [
        {"role":"system","content": BUSINESS_ANALYST_SYSTEM},
        {"role":"user","content": f"Analyze this business text:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
    "model":"phi-4-mini",
        "messages": messages,
        "response_format": {"type":"json_object"},
        "temperature": 0.3
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    # Parse JSON content
    content = r.json()["choices"][0]["message"]["content"]
    return json.loads(content)

if __name__ == "__main__":
    print(analyze("Sales dipped 12% in Q3 due to supply constraints and marketing cuts."))
```
  

## অংশ ৪: অফলাইন এবং সিকিউরিটি পজিশন (ধাপে ধাপে)

লক্ষ্য: স্থানীয়ভাবে মডেলগুলো টুল হিসেবে চালানোর সময় গোপনীয়তা এবং স্থিতিশীলতা নিশ্চিত করা।

ধাপ ১) স্থানীয় এন্ডপয়েন্ট প্রি-ওয়ার্ম এবং যাচাই করুন  
```cmd
foundry model run phi-4-mini
curl http://localhost:8000/v1/models
```
  
ধাপ ২) ইনপুটগুলো স্যানিটাইজ করুন  
```python
# security/sanitize.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
ধাপ ৩) লোকাল-অনলি ফ্ল্যাগ এবং লগিং  
```python
# security/local_only.py
import os, json, time
LOG = os.getenv("MODELS_AS_TOOLS_LOG", "./tools_logs.jsonl")

def record(event: dict):
    with open(LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")

# Usage before each call
def before_call(tool_name, payload):
    record({"ts": time.time(), "tool": tool_name, "event": "before_call"})

# After each call
def after_call(tool_name, result):
    record({"ts": time.time(), "tool": tool_name, "event": "after_call"})
```
  

## অংশ ৫: Azure AI Foundry-তে স্কেলিং (ধাপে ধাপে)

লক্ষ্য: স্থানীয় মডেলগুলোকে Azure এন্ডপয়েন্টের সাথে মিরর করা, যাতে অতিরিক্ত ক্ষমতা পাওয়া যায়।

ধাপ ১) রাউটিং কৌশল নির্ধারণ করুন  
- গোপনীয়তা/লেটেন্সির জন্য স্থানীয়-প্রথম, ত্রুটি বা বড় প্রম্পটের ক্ষেত্রে Azure ব্যাকআপ  

ধাপ ২) একটি সহজ রাউটার স্টাব বাস্তবায়ন করুন  
```python
# hybrid/router.py
import os, requests

LOCAL_BASE = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
AZURE_BASE = os.getenv("AZURE_FOUNDRY_BASE_URL", "")  # set to your project endpoint
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
AZURE_KEY = os.getenv("AZURE_FOUNDRY_API_KEY", "")

HEADERS_LOCAL = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}
HEADERS_AZURE = {"Content-Type":"application/json","Authorization":f"Bearer {AZURE_KEY}"}

def chat_local(payload: dict):
    r = requests.post(f"{LOCAL_BASE}/chat/completions", json=payload, headers=HEADERS_LOCAL, timeout=60)
    r.raise_for_status()
    return r.json()

def chat_azure(payload: dict):
    if not AZURE_BASE:
        raise RuntimeError("Azure base URL not configured")
    r = requests.post(f"{AZURE_BASE}/chat/completions", json=payload, headers=HEADERS_AZURE, timeout=60)
    r.raise_for_status()
    return r.json()

def hybrid_chat(messages, prefer_local=True):
    payload = {"model":"phi-4-mini", "messages": messages, "max_tokens": 256}
    if prefer_local:
        try:
            return chat_local(payload)
        except Exception:
            return chat_azure(payload)
    else:
        try:
            return chat_azure(payload)
        except Exception:
            return chat_local(payload)

if __name__ == "__main__":
    # Ensure local model is running
    print(hybrid_chat([{"role":"user","content":"Hello from hybrid router!"}]))
```
  

## হাতে-কলমে চেকলিস্ট
- [ ] অন্তত দুটি টুল রেজিস্টার করুন এবং রিকোয়েস্ট রাউট করুন  
- [ ] OpenAI SDK এবং raw REST-এর মাধ্যমে Foundry Local কল করুন  
- [ ] ডোমেইন টেমপ্লেটের জন্য JSON আউটপুট নিশ্চিত করুন  
- [ ] স্থানীয়ভাবে কলগুলো স্যানিটাইজ এবং লগ করুন  
- [ ] Azure ব্যাকআপ সহ একটি সহজ হাইব্রিড রাউটার বাস্তবায়ন করুন  

## সমাপ্তি

Foundry Local শক্তিশালী অন-ডিভাইস AI সক্ষম করে, যেখানে মডেলগুলো কম্পোজেবল টুল হয়ে ওঠে। স্পষ্ট ইন্টারফেস, গভর্নেন্স এবং হাইব্রিড স্কেলিংয়ের মাধ্যমে, দলগুলো রিয়েল-টাইম, সুরক্ষিত AI অ্যাপ তৈরি করতে পারে যা ব্যবহারকারীর গোপনীয়তা রক্ষা করে এবং এন্টারপ্রাইজ-প্রস্তুত থাকে।

---

