<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T18:05:01+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "ar"
}
-->
# القسم 3: التخصيص - تعديل النماذج للمهام المحددة

## جدول المحتويات
1. [مقدمة عن التخصيص](../../../Module05)
2. [أهمية التخصيص](../../../Module05)
3. [أنواع التخصيص](../../../Module05)
4. [التخصيص باستخدام Microsoft Olive](../../../Module05)
5. [أمثلة عملية](../../../Module05)
6. [أفضل الممارسات والإرشادات](../../../Module05)
7. [تقنيات متقدمة](../../../Module05)
8. [التقييم والمراقبة](../../../Module05)
9. [التحديات الشائعة والحلول](../../../Module05)
10. [الخاتمة](../../../Module05)

## مقدمة عن التخصيص

**التخصيص** هو تقنية قوية في تعلم الآلة تهدف إلى تعديل نموذج مدرب مسبقًا ليقوم بمهام محددة أو يعمل مع مجموعات بيانات متخصصة. بدلاً من تدريب نموذج من البداية، يستفيد التخصيص من المعرفة المكتسبة بالفعل من النموذج المدرب مسبقًا ويقوم بتعديلها لتناسب حالتك الخاصة.

### ما هو التخصيص؟

التخصيص هو شكل من أشكال **التعلم الانتقالي** حيث تقوم بـ:
- البدء بنموذج مدرب مسبقًا تعلم أنماطًا عامة من مجموعات بيانات كبيرة
- تعديل المعلمات الداخلية للنموذج باستخدام مجموعة بياناتك الخاصة
- الاحتفاظ بالمعرفة القيمة مع تخصيص النموذج لمهمتك

فكر في الأمر كتعليم طاهٍ ماهر لطهي نوع جديد من المأكولات - فهو بالفعل يفهم أساسيات الطهي، لكنه يحتاج إلى تعلم تقنيات ونكهات محددة للطهي الجديد.

### الفوائد الرئيسية

- **كفاءة الوقت**: أسرع بكثير من التدريب من البداية
- **كفاءة البيانات**: يتطلب مجموعات بيانات أصغر لتحقيق أداء جيد
- **فعالية التكلفة**: احتياجات حسابية أقل
- **أداء أفضل**: غالبًا ما يحقق نتائج متفوقة مقارنة بالتدريب من البداية
- **تحسين الموارد**: يجعل الذكاء الاصطناعي القوي متاحًا للفرق والمؤسسات الصغيرة

## أهمية التخصيص

### التطبيقات الواقعية

التخصيص ضروري في العديد من السيناريوهات:

**1. التكيف مع المجال**
- الذكاء الاصطناعي الطبي: تعديل نماذج اللغة العامة لتناسب المصطلحات الطبية والملاحظات السريرية
- التكنولوجيا القانونية: تخصيص النماذج لتحليل الوثائق القانونية ومراجعة العقود
- الخدمات المالية: تخصيص النماذج لتحليل التقارير المالية وتقييم المخاطر

**2. التخصص في المهام**
- إنشاء المحتوى: تخصيص النماذج لأنماط كتابة أو نغمات محددة
- إنشاء الأكواد: تعديل النماذج للغات برمجة أو أطر عمل معينة
- الترجمة: تحسين الأداء لأزواج لغات محددة أو مجالات تقنية

**3. التطبيقات المؤسسية**
- خدمة العملاء: إنشاء روبوتات دردشة تفهم المصطلحات الخاصة بالشركة
- الوثائق الداخلية: بناء مساعدين ذكاء اصطناعي على دراية بعمليات المنظمة
- الحلول الخاصة بالصناعة: تطوير نماذج تفهم المصطلحات والجداول الزمنية الخاصة بالقطاع

## أنواع التخصيص

### 1. التخصيص الكامل (التخصيص التعليمي)

في التخصيص الكامل، يتم تحديث جميع معلمات النموذج أثناء التدريب. هذا النهج:
- يوفر أقصى قدر من المرونة وإمكانية الأداء
- يتطلب موارد حسابية كبيرة
- ينتج نسخة جديدة تمامًا من النموذج
- الأفضل في السيناريوهات التي تتوفر فيها بيانات تدريب كبيرة وموارد حسابية كافية

### 2. التخصيص الفعال للمعلمات (PEFT)

طرق PEFT تقوم بتحديث مجموعة صغيرة فقط من المعلمات، مما يجعل العملية أكثر كفاءة:

#### Low-Rank Adaptation (LoRA)
- يضيف مصفوفات صغيرة قابلة للتدريب إلى الأوزان الحالية
- يقلل بشكل كبير من عدد المعلمات القابلة للتدريب
- يحافظ على الأداء قريبًا من التخصيص الكامل
- يتيح التبديل السهل بين التعديلات المختلفة

#### QLoRA (Quantized LoRA)
- يجمع بين LoRA وتقنيات التكميم
- يقلل من متطلبات الذاكرة بشكل أكبر
- يتيح تخصيص نماذج أكبر على الأجهزة الاستهلاكية
- يوازن بين الكفاءة والأداء

#### Adapters
- إدخال شبكات عصبية صغيرة بين الطبقات الحالية
- يسمح بالتخصيص المستهدف مع الحفاظ على النموذج الأساسي ثابتًا
- يتيح نهجًا معياريًا لتخصيص النموذج

### 3. التخصيص الخاص بالمهمة

يركز على تعديل النماذج لمهام محددة:
- **التصنيف**: تعديل النماذج لمهام التصنيف
- **الإنشاء**: تحسين إنشاء المحتوى والنصوص
- **الاستخراج**: تخصيص لاستخراج المعلومات والتعرف على الكيانات المسماة
- **التلخيص**: تخصص النماذج لتلخيص الوثائق

## التخصيص باستخدام Microsoft Olive

Microsoft Olive هي مجموعة أدوات شاملة لتحسين النماذج تسهل عملية التخصيص مع توفير ميزات على مستوى المؤسسات.

### ما هي Microsoft Olive؟

Microsoft Olive هي أداة مفتوحة المصدر لتحسين النماذج التي:
- تبسط سير عمل التخصيص للأجهزة المختلفة
- توفر دعمًا مدمجًا للهياكل النموذجية الشهيرة (Llama، Phi، Qwen، Gemma)
- تقدم خيارات نشر سحابية ومحلية
- تتكامل بسلاسة مع Azure ML وخدمات الذكاء الاصطناعي الأخرى من Microsoft
- تدعم التحسين التلقائي والتكميم

### الميزات الرئيسية

- **التحسين الموجه للأجهزة**: تحسين النماذج تلقائيًا للأجهزة المحددة (CPU، GPU، NPU)
- **دعم متعدد الصيغ**: يعمل مع نماذج PyTorch، Hugging Face، وONNX
- **سير عمل تلقائي**: يقلل من التكوين اليدوي والتجربة والخطأ
- **تكامل المؤسسات**: دعم مدمج لـ Azure ML والنشر السحابي
- **هيكلية قابلة للتوسيع**: تسمح بتقنيات تحسين مخصصة

### التثبيت والإعداد

#### التثبيت الأساسي

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### التبعيات الاختيارية

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### التحقق من التثبيت

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## أمثلة عملية

### المثال 1: تخصيص أساسي باستخدام Olive CLI

هذا المثال يوضح تخصيص نموذج لغة صغير لتصنيف العبارات:

#### الخطوة 1: إعداد البيئة

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### الخطوة 2: تخصيص النموذج

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### الخطوة 3: تحسين للنشر

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### المثال 2: إعداد متقدم مع مجموعة بيانات مخصصة

#### الخطوة 1: إعداد مجموعة بيانات مخصصة

إنشاء ملف JSON يحتوي على بيانات التدريب:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### الخطوة 2: إنشاء ملف التكوين

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### الخطوة 3: تنفيذ التخصيص

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### المثال 3: تخصيص QLoRA لكفاءة الذاكرة

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## أفضل الممارسات والإرشادات

### إعداد البيانات

**1. جودة البيانات أهم من الكمية**
- ركز على أمثلة عالية الجودة ومتنوعة بدلاً من كميات كبيرة من البيانات الرديئة
- تأكد من أن البيانات تمثل حالتك المستهدفة
- قم بتنظيف البيانات ومعالجتها بشكل متسق

**2. تنسيق البيانات والقوالب**
- استخدم تنسيقًا متسقًا عبر جميع أمثلة التدريب
- أنشئ قوالب إدخال-إخراج واضحة تتناسب مع حالتك
- قم بتضمين تنسيق التعليمات المناسب للنماذج المخصصة للتعليمات

**3. تقسيم مجموعة البيانات**
- احتفظ بـ 10-20% من البيانات للتحقق
- حافظ على توزيعات مماثلة عبر تقسيمات التدريب/التحقق
- ضع في اعتبارك أخذ عينات طبقية لمهام التصنيف

### إعداد التدريب

**1. اختيار معدل التعلم**
- ابدأ بمعدلات تعلم صغيرة (1e-5 إلى 1e-4) للتخصيص
- استخدم جدولة معدل التعلم لتحسين التقارب
- راقب منحنيات الخسارة لتعديل المعدلات وفقًا لذلك

**2. تحسين حجم الدفعة**
- توازن بين حجم الدفعة والذاكرة المتاحة
- استخدم تراكم التدرج للحصول على أحجام دفعات فعالة أكبر
- ضع في اعتبارك العلاقة بين حجم الدفعة ومعدل التعلم

**3. مدة التدريب**
- راقب مقاييس التحقق لتجنب الإفراط في التخصيص
- استخدم الإيقاف المبكر عندما تستقر أداء التحقق
- احفظ نقاط التحقق بانتظام للاسترداد والتحليل

### اختيار النموذج

**1. اختيار النموذج الأساسي**
- اختر نماذج مدربة مسبقًا على مجالات مشابهة عندما يكون ذلك ممكنًا
- ضع في اعتبارك حجم النموذج بالنسبة لقيودك الحسابية
- قم بتقييم متطلبات الترخيص للاستخدام التجاري

**2. اختيار طريقة التخصيص**
- استخدم LoRA/QLoRA للبيئات ذات الموارد المحدودة
- اختر التخصيص الكامل عندما يكون الأداء الأقصى ضروريًا
- ضع في اعتبارك النهج القائم على المحولات للسيناريوهات متعددة المهام

### إدارة الموارد

**1. تحسين الأجهزة**
- اختر الأجهزة المناسبة لحجم النموذج والطريقة
- استخدم ذاكرة GPU بكفاءة مع نقاط التحقق التدرجية
- ضع في اعتبارك الحلول السحابية للنماذج الأكبر

**2. إدارة الذاكرة**
- استخدم تدريب الدقة المختلطة عندما يكون متاحًا
- قم بتنفيذ تراكم التدرج للقيود المتعلقة بالذاكرة
- راقب استخدام ذاكرة GPU أثناء التدريب

## تقنيات متقدمة

### تدريب متعدد المحولات

تدريب محولات متعددة لمهام مختلفة مع مشاركة النموذج الأساسي:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### تحسين المعلمات الفائقة

تنفيذ تحسين منهجي للمعلمات الفائقة:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### وظائف خسارة مخصصة

تنفيذ وظائف خسارة خاصة بالمجال:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## التقييم والمراقبة

### المقاييس والتقييم

**1. المقاييس القياسية**
- **الدقة**: صحة الإجمال لمهام التصنيف
- **Perplexity**: مقياس جودة نمذجة اللغة
- **BLEU/ROUGE**: جودة إنشاء النصوص والتلخيص
- **F1 Score**: توازن الدقة والاستدعاء لمهام التصنيف

**2. المقاييس الخاصة بالمجال**
- **معايير المهام الخاصة**: استخدم معايير معروفة لمجالك
- **التقييم البشري**: قم بتضمين تقييم بشري للمهام الذاتية
- **مقاييس الأعمال**: قم بالمواءمة مع الأهداف التجارية الفعلية

**3. إعداد التقييم**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### مراقبة تقدم التدريب

**1. تتبع الخسارة**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. مراقبة التحقق**
- تتبع خسارة التحقق بجانب خسارة التدريب
- راقب علامات الإفراط في التخصيص (زيادة خسارة التحقق بينما تقل خسارة التدريب)
- استخدم الإيقاف المبكر بناءً على مقاييس التحقق

**3. مراقبة الموارد**
- راقب استخدام GPU/CPU
- تتبع أنماط استخدام الذاكرة
- راقب سرعة التدريب ومعدل الإنتاجية

## التحديات الشائعة والحلول

### التحدي 1: الإفراط في التخصيص

**الأعراض:**
- تستمر خسارة التدريب في الانخفاض بينما تزيد خسارة التحقق
- فجوة كبيرة بين أداء التدريب والتحقق
- ضعف التعميم على البيانات الجديدة

**الحلول:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### التحدي 2: قيود الذاكرة

**الحلول:**
- استخدم نقاط التحقق التدرجية
- قم بتنفيذ تراكم التدرج
- اختر طرق تخصيص فعالة للمعلمات (LoRA، QLoRA)
- استخدم تقسيم النموذج للنماذج الكبيرة

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### التحدي 3: التدريب البطيء

**الحلول:**
- تحسين خطوط أنابيب تحميل البيانات
- استخدم تدريب الدقة المختلطة
- قم بتنفيذ استراتيجيات تجميع فعالة
- ضع في اعتبارك التدريب الموزع لمجموعات البيانات الكبيرة

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### التحدي 4: الأداء الضعيف

**خطوات التشخيص:**
1. تحقق من جودة البيانات وتنسيقها
2. تحقق من معدل التعلم ومدة التدريب
3. قم بتقييم اختيار النموذج الأساسي
4. راجع المعالجة المسبقة والتجزئة

**الحلول:**
- زيادة تنوع بيانات التدريب
- تعديل جدولة معدل التعلم
- تجربة نماذج أساسية مختلفة
- تنفيذ تقنيات زيادة البيانات

## الخاتمة

التخصيص هو تقنية قوية تتيح الوصول إلى قدرات الذكاء الاصطناعي المتقدمة. باستخدام أدوات مثل Microsoft Olive، يمكن للمؤسسات تعديل النماذج المدربة مسبقًا بكفاءة لتلبية احتياجاتها الخاصة مع تحسين الأداء والقيود المتعلقة بالموارد.

### النقاط الرئيسية

1. **اختر النهج المناسب**: اختر طرق التخصيص بناءً على مواردك الحسابية ومتطلبات الأداء
2. **جودة البيانات مهمة**: استثمر في بيانات تدريب عالية الجودة وممثلة
3. **راقب وكرر**: قم بتقييم وتحسين نماذجك باستمرار
4. **استخدم الأدوات**: استفد من الأطر مثل Olive لتبسيط وتحسين العملية
5. **ضع في اعتبارك النشر**: خطط لتحسين النموذج والنشر من البداية

## ➡️ ما التالي؟

- [04: النشر - تنفيذ النموذج الجاهز للإنتاج](./04.SLMOps.Deployment.md)

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة ناتجة عن استخدام هذه الترجمة.