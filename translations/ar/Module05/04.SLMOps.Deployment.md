<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-17T18:06:41+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "ar"
}
-->
# القسم 4: النشر - تنفيذ نموذج جاهز للإنتاج

## نظرة عامة

هذا الدليل الشامل سيرشدك خلال العملية الكاملة لنشر النماذج المحسّنة والمكمّمة باستخدام Foundry Local. سنغطي تحويل النموذج، تحسين التكميم، وتكوين النشر من البداية إلى النهاية.

## المتطلبات الأساسية

قبل البدء، تأكد من توفر ما يلي:

- ✅ نموذج ONNX محسّن وجاهز للنشر
- ✅ جهاز كمبيوتر يعمل بنظام Windows أو Mac
- ✅ Python 3.10 أو أعلى
- ✅ ذاكرة RAM متاحة لا تقل عن 8GB
- ✅ Foundry Local مثبت على نظامك

## الجزء 1: إعداد البيئة

### تثبيت الأدوات المطلوبة

افتح نافذة الأوامر (Command Prompt على Windows، Terminal على Mac) وقم بتشغيل الأوامر التالية بالتسلسل:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

⚠️ **ملاحظة مهمة**: ستحتاج أيضًا إلى إصدار CMake 3.31 أو أحدث، والذي يمكن تنزيله من [cmake.org](https://cmake.org/download/).

## الجزء 2: تحويل النموذج وتكميمه

### اختيار التنسيق المناسب

بالنسبة للنماذج الصغيرة المحسّنة للغات، نوصي باستخدام **تنسيق ONNX** لأنه يوفر:

- 🚀 تحسين الأداء بشكل أفضل
- 🔧 نشر مستقل عن الأجهزة
- 🏭 قدرات جاهزة للإنتاج
- 📱 توافق عبر الأنظمة المختلفة

### الطريقة الأولى: التحويل بأمر واحد (موصى به)

استخدم الأمر التالي لتحويل النموذج المحسّن مباشرة:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**شرح المعلمات:**
- `--model_name_or_path`: مسار النموذج المحسّن
- `--device cpu`: استخدام وحدة المعالجة المركزية للتحسين
- `--precision int4`: استخدام تكميم INT4 (تقليل الحجم بنسبة تقارب 75%)
- `--output_path`: مسار الإخراج للنموذج المحوّل

### الطريقة الثانية: نهج ملف التكوين (للمستخدمين المتقدمين)

قم بإنشاء ملف تكوين باسم `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

ثم قم بتشغيل:

```bash
olive run --config ./finetuned_conversion_config.json
```

### مقارنة خيارات التكميم

| الدقة       | حجم الملف       | سرعة الاستنتاج | جودة النموذج | الاستخدام الموصى به       |
|-------------|-----------------|-----------------|-------------|---------------------------|
| FP16        | الأساس × 0.5    | سريع           | الأفضل      | الأجهزة عالية الأداء      |
| INT8        | الأساس × 0.25   | سريع جدًا      | جيد         | خيار متوازن               |
| INT4        | الأساس × 0.125  | الأسرع         | مقبول       | الأجهزة محدودة الموارد    |

💡 **التوصية**: ابدأ بتكميم INT4 للنشر الأول. إذا لم تكن الجودة مرضية، جرب INT8 أو FP16.

## الجزء 3: تكوين نشر Foundry Local

### إنشاء تكوين النموذج

انتقل إلى دليل النماذج في Foundry Local:

```bash
foundry cache cd ./models/
```

قم بإنشاء هيكل دليل النموذج الخاص بك:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

قم بإنشاء ملف التكوين `inference_model.json` في دليل النموذج الخاص بك:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### تكوينات القوالب الخاصة بالنماذج

#### لنماذج سلسلة Qwen:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## الجزء 4: اختبار النموذج وتحسينه

### التحقق من تثبيت النموذج

تحقق مما إذا كان Foundry Local يمكنه التعرف على النموذج الخاص بك:

```bash
foundry cache ls
```

يجب أن ترى `your-finetuned-model-int4` في القائمة.

### بدء اختبار النموذج

```bash
foundry model run your-finetuned-model-int4
```

### قياس الأداء

راقب المقاييس الرئيسية أثناء الاختبار:

1. **وقت الاستجابة**: قياس متوسط الوقت لكل استجابة
2. **استهلاك الذاكرة**: مراقبة استخدام RAM
3. **استخدام وحدة المعالجة المركزية**: التحقق من تحميل المعالج
4. **جودة الإخراج**: تقييم مدى ملاءمة وتماسك الاستجابة

### قائمة التحقق من التحقق من الجودة

- ✅ النموذج يستجيب بشكل مناسب لاستفسارات المجال المحسّن
- ✅ تنسيق الاستجابة يتطابق مع هيكل الإخراج المتوقع
- ✅ لا توجد تسريبات ذاكرة أثناء الاستخدام المطول
- ✅ أداء متسق عبر أطوال المدخلات المختلفة
- ✅ التعامل بشكل صحيح مع الحالات الحافة والمدخلات غير الصالحة

## الملخص

تهانينا! لقد أكملت بنجاح:

- ✅ تحويل تنسيق النموذج المحسّن
- ✅ تحسين تكميم النموذج
- ✅ تكوين نشر Foundry Local
- ✅ ضبط الأداء وحل المشكلات

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.