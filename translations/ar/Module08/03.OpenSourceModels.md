<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-09-30T23:07:00+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "ar"
}
-->
# الجلسة 3: اكتشاف وإدارة النماذج مفتوحة المصدر

## نظرة عامة

تركز هذه الجلسة على اكتشاف النماذج وإدارتها عمليًا باستخدام Foundry Local. ستتعلم كيفية عرض النماذج المتاحة، اختبار الخيارات المختلفة، وفهم الخصائص الأساسية للأداء. يتم التركيز على الاستكشاف العملي باستخدام واجهة الأوامر (CLI) الخاصة بـ Foundry لمساعدتك في اختيار النماذج المناسبة لحالات الاستخدام الخاصة بك.

## أهداف التعلم

- إتقان أوامر CLI الخاصة بـ Foundry لاكتشاف وإدارة النماذج
- فهم أنماط التخزين المؤقت للنماذج والتخزين المحلي
- تعلم كيفية اختبار ومقارنة النماذج المختلفة بسرعة
- إنشاء تدفقات عمل عملية لاختيار النماذج وقياس الأداء
- استكشاف النظام البيئي المتنامي للنماذج المتاحة عبر Foundry Local

## المتطلبات الأساسية

- إكمال الجلسة 1: البدء مع Foundry Local
- تثبيت واجهة الأوامر الخاصة بـ Foundry Local وإمكانية الوصول إليها
- توفر مساحة تخزين كافية لتنزيل النماذج (قد تتراوح أحجام النماذج بين 1 جيجابايت إلى أكثر من 20 جيجابايت)
- فهم أساسي لأنواع النماذج وحالات الاستخدام

## نظرة عامة

تستكشف هذه الجلسة كيفية جلب النماذج مفتوحة المصدر إلى Foundry Local.

## الجزء 6: التمرين العملي

### التمرين: اكتشاف النماذج ومقارنتها

قم بإنشاء نص لتقييم النماذج بناءً على العينة 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```


### مهمتك

1. **تشغيل نص العينة 03**: `samples\03\list_and_bench.cmd`
2. **تجربة نماذج مختلفة**: اختبر على الأقل 3 نماذج مختلفة
3. **مقارنة الأداء**: لاحظ الفروقات في السرعة وجودة الاستجابة
4. **توثيق النتائج**: قم بإنشاء جدول مقارنة بسيط

### مثال على تنسيق المقارنة

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```


## الجزء 7: استكشاف الأخطاء وإصلاحها وأفضل الممارسات

### المشكلات الشائعة وحلولها

**النموذج لا يعمل:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```


**ذاكرة غير كافية:**
- ابدأ بنماذج أصغر (`phi-4-mini`)
- أغلق التطبيقات الأخرى
- قم بترقية ذاكرة الوصول العشوائي إذا كنت تواجه حدودًا بشكل متكرر

**أداء بطيء:**
- تأكد من تحميل النموذج بالكامل (تحقق من الإخراج التفصيلي)
- أغلق التطبيقات الخلفية غير الضرورية
- فكر في استخدام تخزين أسرع (SSD)

### أفضل الممارسات

1. **ابدأ صغيرًا**: ابدأ بـ `phi-4-mini` للتحقق من الإعداد
2. **نموذج واحد في كل مرة**: أوقف النماذج السابقة قبل بدء نماذج جديدة
3. **مراقبة الموارد**: راقب استخدام الذاكرة
4. **اختبار متسق**: استخدم نفس المطالبات للمقارنات العادلة
5. **توثيق النتائج**: احتفظ بملاحظات حول أداء النماذج لحالات الاستخدام الخاصة بك

## الجزء 8: الخطوات التالية والمراجع

### التحضير للجلسة 4

- **تركيز الجلسة 4**: أدوات وتقنيات تحسين الأداء
- **المتطلبات الأساسية**: الراحة مع تبديل النماذج واختبار الأداء الأساسي
- **الموصى به**: تحديد 2-3 نماذج مفضلة من هذه الجلسة

### موارد إضافية

- **[وثائق Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: الوثائق الرسمية
- **[مرجع CLI](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: مرجع الأوامر الكامل
- **[Model Mondays](https://aka.ms/model-mondays)**: تسليط الضوء الأسبوعي على النماذج
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: المجتمع والمشكلات
- **[العينة 03: اكتشاف النماذج](samples/03/README.md)**: نص عملي كمثال

### النقاط الرئيسية

✅ **اكتشاف النماذج**: استخدم `foundry model list` لاستكشاف النماذج المتاحة  
✅ **اختبار سريع**: نمط `list_and_bench.cmd` للتقييم السريع  
✅ **مراقبة الأداء**: قياس استخدام الموارد ووقت الاستجابة الأساسي  
✅ **اختيار النماذج**: إرشادات عملية لاختيار النماذج حسب حالة الاستخدام  
✅ **إدارة التخزين المؤقت**: فهم إجراءات التخزين والتنظيف  

لديك الآن المهارات العملية لاكتشاف واختبار واختيار النماذج المناسبة لتطبيقات الذكاء الاصطناعي الخاصة بك باستخدام واجهة الأوامر البسيطة لـ Foundry Local.

## أهداف التعلم

- اكتشاف وتقييم النماذج مفتوحة المصدر للاستدلال المحلي
- تجميع وتشغيل نماذج مختارة من Hugging Face داخل Foundry Local
- تطبيق استراتيجيات اختيار النماذج بناءً على الدقة، التأخير، واحتياجات الموارد
- إدارة النماذج محليًا باستخدام التخزين المؤقت وإصدارات النماذج

## الجزء 1: اكتشاف النماذج باستخدام واجهة الأوامر الخاصة بـ Foundry

### أوامر إدارة النماذج الأساسية

توفر واجهة الأوامر الخاصة بـ Foundry أوامر مباشرة لاكتشاف وإدارة النماذج:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```


### تشغيل النماذج الأولى

ابدأ بالنماذج الشائعة والمختبرة لفهم خصائص الأداء:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```


**ملاحظة:** يوفر العلم `--verbose` معلومات تفصيلية عند بدء التشغيل، بما في ذلك:
- تقدم تنزيل النموذج (في التشغيل الأول)
- تفاصيل تخصيص الذاكرة
- معلومات الربط بالخدمة
- مقاييس تهيئة الأداء

### فهم فئات النماذج

**نماذج اللغة الصغيرة (SLMs):**
- `phi-4-mini`: سريع، فعال، رائع للدردشة العامة
- `phi-4`: نسخة أكثر قدرة مع تحسين التفكير

**النماذج المتوسطة:**
- `qwen2.5-7b`: ممتاز في التفكير وسياق أطول
- `deepseek-r1-7b`: مُحسّن لتوليد الأكواد

**النماذج الأكبر:**
- `llama-3.2`: أحدث نموذج مفتوح المصدر من Meta
- `qwen2.5-14b`: التفكير على مستوى المؤسسات

## الجزء 2: اختبار سريع للنماذج ومقارنتها

### نهج العينة 03: قائمة بسيطة واختبار

استنادًا إلى نمط العينة 03، إليك سير العمل الأدنى:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```


### اختبار أداء النماذج

بمجرد تشغيل النموذج، اختبره باستخدام مطالبات متسقة:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```


### بديل اختبار PowerShell

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```


## الجزء 3: إدارة التخزين المؤقت والتخزين للنماذج

### فهم التخزين المؤقت للنماذج

يدير Foundry Local تلقائيًا تنزيل النماذج والتخزين المؤقت:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```


### اعتبارات تخزين النماذج

**أحجام النماذج النموذجية:**
- `phi-4-mini`: ~2.5 جيجابايت
- `qwen2.5-7b`: ~4.1 جيجابايت  
- `deepseek-r1-7b`: ~4.3 جيجابايت
- `llama-3.2`: ~4.9 جيجابايت
- `qwen2.5-14b`: ~8.2 جيجابايت

**أفضل ممارسات التخزين:**
- احتفظ بـ 2-3 نماذج مخزنة مؤقتًا للتبديل السريع
- قم بإزالة النماذج غير المستخدمة لتوفير المساحة: `foundry cache clean`
- راقب استخدام القرص، خاصةً على SSDs الصغيرة
- فكر في التوازن بين حجم النموذج وقدراته

### مراقبة أداء النماذج

أثناء تشغيل النماذج، راقب موارد النظام:

**مدير المهام في Windows:**
- راقب استخدام الذاكرة (تظل النماذج محملة في RAM)
- راقب استخدام وحدة المعالجة المركزية أثناء الاستدلال
- تحقق من إدخال/إخراج القرص أثناء تحميل النموذج الأولي

**مراقبة عبر سطر الأوامر:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```


## الجزء 4: إرشادات عملية لاختيار النماذج

### اختيار النماذج حسب حالة الاستخدام

**للدردشة العامة والأسئلة والأجوبة:**
- ابدأ بـ: `phi-4-mini` (سريع، فعال)
- قم بالترقية إلى: `phi-4` (تفكير أفضل)
- متقدم: `qwen2.5-7b` (سياق أطول)

**لتوليد الأكواد:**
- الموصى به: `deepseek-r1-7b`
- البديل: `qwen2.5-7b` (جيد أيضًا للأكواد)

**للتفكير المعقد:**
- الأفضل: `qwen2.5-7b` أو `qwen2.5-14b`
- الخيار الاقتصادي: `phi-4`

### دليل متطلبات الأجهزة

**متطلبات النظام الدنيا:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```


**الموصى به لأفضل أداء:**
- ذاكرة RAM بسعة 32 جيجابايت أو أكثر لتبديل النماذج بسهولة
- تخزين SSD لتحميل النماذج بشكل أسرع
- وحدة معالجة مركزية حديثة بأداء جيد في الخيوط الفردية
- دعم NPU (أجهزة Windows 11 Copilot+) للتسريع

### سير عمل تبديل النماذج

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```


## الجزء 5: قياس الأداء البسيط للنماذج

### اختبار الأداء الأساسي

إليك نهجًا بسيطًا لمقارنة أداء النماذج:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```


### تقييم الجودة يدويًا

لكل نموذج، اختبر باستخدام مطالبات متسقة وقيم يدويًا:

**مطالبات الاختبار:**
1. "اشرح الحوسبة الكمومية بطريقة بسيطة."
2. "اكتب وظيفة Python لترتيب قائمة."
3. "ما هي إيجابيات وسلبيات العمل عن بُعد؟"
4. "لخص فوائد الذكاء الاصطناعي الطرفي."

**معايير التقييم:**
- **الدقة**: هل المعلومات صحيحة؟
- **الوضوح**: هل الشرح سهل الفهم؟
- **الشمولية**: هل يعالج السؤال بالكامل؟
- **السرعة**: ما مدى سرعة الاستجابة؟

### مراقبة استخدام الموارد

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```


## الجزء 6: الخطوات التالية

- اشترك في Model Mondays للحصول على نماذج جديدة ونصائح: https://aka.ms/model-mondays
- ساهم بالنتائج في ملف `models.json` الخاص بفريقك
- التحضير للجلسة 4: مقارنة LLMs مقابل SLMs، الاستدلال المحلي مقابل السحابي، وعروض عملية

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة ناتجة عن استخدام هذه الترجمة.