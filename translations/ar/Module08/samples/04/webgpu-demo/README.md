<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7a474b8e201d5316c0095cdbc3bf0555",
  "translation_date": "2025-09-24T13:46:53+00:00",
  "source_file": "Module08/samples/04/webgpu-demo/README.md",
  "language_code": "ar"
}
-->
# عرض WebGPU + ONNX Runtime

هذا العرض يوضح كيفية تشغيل نماذج الذكاء الاصطناعي مباشرة في المتصفح باستخدام WebGPU لتسريع الأجهزة وONNX Runtime Web.

## ما الذي يوضحه هذا العرض

- **الذكاء الاصطناعي في المتصفح**: تشغيل النماذج بالكامل داخل المتصفح  
- **تسريع WebGPU**: تنفيذ يعتمد على تسريع الأجهزة عند توفره  
- **الخصوصية أولاً**: لا يتم إرسال أي بيانات خارج جهازك  
- **بدون تثبيت**: يعمل في أي متصفح متوافق  
- **الانتقال السلس**: يعتمد على وحدة المعالجة المركزية إذا لم يكن WebGPU متاحًا  

## المتطلبات

**توافق المتصفح:**
- Chrome/Edge 113+ مع تمكين WebGPU  
- تحقق من حالة WebGPU: `chrome://gpu`  
- تمكين WebGPU: `chrome://flags/#enable-unsafe-webgpu`  

## تشغيل العرض

### الخيار الأول: الخادم المحلي (موصى به)

```cmd
# Navigate to the demo directory
cd Module08\samples\04\webgpu-demo

# Start a local server
python -m http.server 5173

# Open browser to http://localhost:5173
```

### الخيار الثاني: خادم VS Code Live

1. قم بتثبيت إضافة "Live Server" في VS Code  
2. انقر بزر الماوس الأيمن على `index.html` → "Open with Live Server"  
3. يتم فتح العرض تلقائيًا في المتصفح  

## ما ستراه

1. **كشف WebGPU**: يتحقق من توافق المتصفح  
2. **تحميل النموذج**: تنزيل وتفعيل مصنف MNIST  
3. **تنفيذ التنبؤ**: تشغيل التنبؤ على بيانات نموذجية  
4. **مقاييس الأداء**: عرض وقت التحميل وسرعة التنبؤ  
5. **عرض النتائج**: ثقة التنبؤ والمخرجات الخام  

## الأداء المتوقع

| مزود التنفيذ | تحميل النموذج | التنبؤ | ملاحظات |
|--------------|--------------|--------|---------|
| **WebGPU**   | ~2-5 ثواني   | ~10-50 مللي ثانية | تسريع الأجهزة |
| **CPU (WASM)** | ~2-5 ثواني | ~50-200 مللي ثانية | اعتماد على البرمجيات |

## استكشاف الأخطاء وإصلاحها

**WebGPU غير متاح:**
- قم بالتحديث إلى Chrome/Edge 113+  
- تمكين WebGPU في `chrome://flags`  
- تحقق من تحديث برامج تشغيل GPU  
- العرض سيعتمد تلقائيًا على وحدة المعالجة المركزية  

**أخطاء التحميل:**
- تأكد من أنك تقدم عبر HTTP (وليس file://)  
- تحقق من اتصال الشبكة لتنزيل النموذج  
- تأكد من أن CORS لا يمنع تحميل نموذج ONNX  

**مشاكل الأداء:**
- يوفر WebGPU تسريعًا كبيرًا مقارنة بوحدة المعالجة المركزية  
- قد تكون أول عملية تشغيل أبطأ بسبب تنزيل النموذج  
- العمليات اللاحقة تستخدم ذاكرة التخزين المؤقت للمتصفح  

## التكامل مع Foundry Local

هذا العرض التوضيحي لـ WebGPU يكمل Foundry Local من خلال توضيح:  

- **التنبؤ على الجانب العميل** لتحقيق أقصى درجات الخصوصية  
- **القدرات غير المتصلة** عند عدم توفر الإنترنت  
- **النشر على الحافة** للبيئات ذات الموارد المحدودة  
- **الهياكل الهجينة** التي تجمع بين التنبؤ المحلي والخادم  

للتطبيقات الإنتاجية، ضع في اعتبارك:  
- استخدام Foundry Local للتنبؤ على الخادم  
- استخدام WebGPU للمعالجة المسبقة/اللاحقة على الجانب العميل  
- تنفيذ التوجيه الذكي بين التنبؤ المحلي/عن بعد  

## التفاصيل التقنية

**النموذج المستخدم:**
- مصنف أرقام MNIST (صيغة ONNX)  
- المدخلات: صور رمادية 28x28  
- المخرجات: توزيع احتمالي من 10 فئات  
- الحجم: ~500KB (تنزيل سريع)  

**ONNX Runtime Web:**
- مزود تنفيذ WebGPU لتسريع GPU  
- مزود تنفيذ WASM كبديل لوحدة المعالجة المركزية  
- تحسين تلقائي وتحسين الرسم البياني  

**واجهات برمجة التطبيقات للمتصفح:**
- WebGPU للوصول إلى الأجهزة  
- Web Workers للمعالجة الخلفية (تحسين مستقبلي)  
- WebAssembly للحساب الفعال  

## الخطوات التالية

- جرب مع نماذج ONNX مخصصة  
- قم بتنفيذ تحميل الصور الحقيقية والتصنيف  
- أضف التنبؤ المتدفق للنماذج الأكبر  
- دمج مع إدخال الكاميرا/الميكروفون  

---

