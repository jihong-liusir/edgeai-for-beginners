<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "142e0d1a5b794b8333cfd4895804ced5",
  "translation_date": "2025-09-17T18:16:06+00:00",
  "source_file": "Module07/README.md",
  "language_code": "ar"
}
-->
# الفصل السابع: أمثلة EdgeAI

يمثل Edge AI تقاطع الذكاء الاصطناعي مع الحوسبة الطرفية، مما يتيح معالجة ذكية مباشرة على الأجهزة دون الاعتماد على الاتصال بالسحابة. يستكشف هذا الفصل خمسة تطبيقات مختلفة لـ EdgeAI عبر منصات وأطر عمل متنوعة، مما يبرز تنوع وقوة تشغيل نماذج الذكاء الاصطناعي على الأطراف.

## 1. EdgeAI في NVIDIA Jetson Orin Nano

يمثل NVIDIA Jetson Orin Nano تقدمًا كبيرًا في الحوسبة الطرفية للذكاء الاصطناعي، حيث يوفر أداء يصل إلى 67 TOPS في شكل صغير بحجم بطاقة ائتمان. هذه المنصة القوية تجعل تطوير الذكاء الاصطناعي التوليدي متاحًا للهواة والطلاب والمطورين المحترفين على حد سواء.

### الميزات الرئيسية
- يوفر أداء يصل إلى 67 TOPS للذكاء الاصطناعي—تحسن بنسبة 1.7X مقارنة بسابقه
- 1024 نواة CUDA وما يصل إلى 32 نواة Tensor لمعالجة الذكاء الاصطناعي
- وحدة معالجة مركزية Arm Cortex-A78AE v8.2 64-bit ذات 6 أنوية بتردد أقصى 1.5 جيجاهرتز
- بسعر 249 دولار فقط، مما يوفر منصة ميسورة التكلفة ومتاحة للمطورين والطلاب والمبدعين

### التطبيقات
يتفوق Jetson Orin Nano في تشغيل نماذج الذكاء الاصطناعي التوليدي الحديثة بما في ذلك محولات الرؤية، نماذج اللغة الكبيرة، ونماذج الرؤية-اللغة. تم تصميمه خصيصًا لحالات استخدام الذكاء الاصطناعي التوليدي، ويمكن الآن تشغيل العديد من نماذج LLM على جهاز بحجم الكف. تشمل حالات الاستخدام الشائعة الروبوتات المدعومة بالذكاء الاصطناعي، الطائرات الذكية، الكاميرات الذكية، والأجهزة الطرفية المستقلة.

**تعرف على المزيد**: [NVIDIA's Jetson Orin Nano SuperComputer: The Next Big Thing in EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI في التطبيقات المحمولة باستخدام .NET MAUI و ONNX Runtime GenAI

توضح هذه الحلول كيفية دمج الذكاء الاصطناعي التوليدي ونماذج اللغة الكبيرة (LLMs) في التطبيقات المحمولة متعددة المنصات باستخدام .NET MAUI و ONNX Runtime GenAI. يتيح هذا النهج للمطورين بناء تطبيقات محمولة مدعومة بالذكاء الاصطناعي تعمل بشكل أصلي على أجهزة Android و iOS.

### الميزات الرئيسية
- يعتمد على إطار عمل .NET MAUI، مما يوفر قاعدة كود واحدة لتطبيقات Android و iOS
- تكامل ONNX Runtime GenAI يتيح تشغيل نماذج الذكاء الاصطناعي التوليدي مباشرة على الأجهزة المحمولة
- يدعم مختلف المسرعات المادية المصممة للأجهزة المحمولة، بما في ذلك CPU، GPU، ومعالجات الذكاء الاصطناعي المتخصصة
- تحسينات خاصة بالمنصة مثل CoreML لـ iOS و NNAPI لـ Android عبر ONNX Runtime
- تنفيذ دورة الذكاء الاصطناعي التوليدي بالكامل بما في ذلك المعالجة المسبقة واللاحقة، الاستدلال، معالجة logits، البحث والعينة، وإدارة ذاكرة التخزين المؤقت KV

### فوائد التطوير
يسمح نهج .NET MAUI للمطورين بالاستفادة من مهاراتهم الحالية في C# و .NET أثناء بناء تطبيقات الذكاء الاصطناعي متعددة المنصات. يدعم إطار عمل ONNX Runtime GenAI العديد من بنى النماذج بما في ذلك Llama، Mistral، Phi، Gemma، وغيرها. تسريع النوى ARM64 المحسنة عمليات ضرب المصفوفات INT4، مما يضمن أداءً فعالًا على الأجهزة المحمولة مع الحفاظ على تجربة تطوير .NET المألوفة.

### حالات الاستخدام
هذه الحلول مثالية للمطورين الذين يرغبون في بناء تطبيقات محمولة مدعومة بالذكاء الاصطناعي باستخدام تقنيات .NET، بما في ذلك روبوتات الدردشة الذكية، تطبيقات التعرف على الصور، أدوات ترجمة اللغة، وأنظمة التوصيات الشخصية التي تعمل بالكامل على الجهاز لتعزيز الخصوصية والقدرة على العمل دون اتصال.

**تعرف على المزيد**: [.NET MAUI ONNX Runtime GenAI Example](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI في Azure مع محرك نماذج اللغة الصغيرة

تركز حلول EdgeAI المستندة إلى Azure من Microsoft على نشر نماذج اللغة الصغيرة (SLMs) بكفاءة في بيئات هجينة تجمع بين السحابة والطرف. يربط هذا النهج بين خدمات الذكاء الاصطناعي على نطاق السحابة ومتطلبات النشر الطرفي.

### مزايا الهندسة
- تكامل سلس مع خدمات Azure AI
- تشغيل SLMs/LLMs والنماذج متعددة الوسائط على الجهاز وفي السحابة باستخدام ONNX Runtime
- تحسين للنشر على مستوى المؤسسات
- دعم تحديثات وإدارة النماذج المستمرة

### حالات الاستخدام
تتفوق حلول Azure EdgeAI في السيناريوهات التي تتطلب نشر الذكاء الاصطناعي على مستوى المؤسسات مع قدرات إدارة السحابة. يشمل ذلك معالجة المستندات الذكية، التحليلات في الوقت الحقيقي، وعمليات الذكاء الاصطناعي الهجينة التي تستفيد من موارد الحوسبة السحابية والطرفية.

**تعرف على المزيد**: [Azure EdgeAI SLM Engine](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## 4. EdgeAI مع Windows ML

يمثل Windows ML أحدث تقنيات Microsoft لتشغيل النماذج على الأجهزة بكفاءة وتبسيط النشر، ويعمل كأساس لـ Windows AI Foundry. تتيح هذه المنصة للمطورين إنشاء تطبيقات Windows مدعومة بالذكاء الاصطناعي تستفيد من كامل إمكانيات أجهزة الكمبيوتر.

### قدرات المنصة
- يعمل على جميع أجهزة Windows 11 التي تعمل بالإصدار 24H2 (البناء 26100) أو أعلى
- يعمل على جميع أجهزة الكمبيوتر x64 و ARM64، حتى تلك التي لا تحتوي على NPUs أو GPUs
- يتيح للمطورين جلب نماذجهم الخاصة ونشرها بكفاءة عبر نظام شركاء السيليكون بما في ذلك AMD، Intel، NVIDIA و Qualcomm
- باستخدام واجهات برمجة التطبيقات للبنية التحتية، لم يعد المطورون بحاجة إلى إنشاء نسخ متعددة من تطبيقاتهم لاستهداف أنواع مختلفة من السيليكون

### فوائد المطورين
يقوم Windows ML بتجريد الأجهزة ومزودي التنفيذ، مما يتيح لك التركيز على كتابة الكود الخاص بك. بالإضافة إلى ذلك، يتم تحديث Windows ML تلقائيًا لدعم أحدث NPUs و GPUs و CPUs عند إصدارها. توفر المنصة إطار عمل موحد لتطوير الذكاء الاصطناعي عبر نظام Windows للأجهزة المتنوعة.

**تعرف على المزيد**: 
- [Windows ML Overview](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Windows EdgeAI Development Guide](../windowdeveloper.md) - دليل شامل لتطوير Edge AI على Windows

## 5. EdgeAI مع تطبيقات Foundry Local

تمكن Foundry Local المطورين من بناء تطبيقات استرجاع معزز للتوليد (RAG) باستخدام الموارد المحلية في .NET، مما يجمع بين نماذج اللغة المحلية وقدرات البحث الدلالي. يوفر هذا النهج حلول ذكاء اصطناعي تركز على الخصوصية وتعمل بالكامل على البنية التحتية المحلية.

### الهندسة التقنية
- يجمع بين نموذج اللغة Phi-3، التضمينات المحلية، والنواة الدلالية لإنشاء سيناريو RAG
- يستخدم التضمينات كمتجهات (مصفوفات) من القيم العائمة التي تمثل المحتوى ومعناه الدلالي
- تعمل النواة الدلالية كمنسق رئيسي، حيث تدمج Phi-3 والمكونات الذكية لإنشاء خط أنابيب RAG سلس
- دعم قواعد بيانات المتجهات المحلية بما في ذلك SQLite و Qdrant

### فوائد التنفيذ
RAG، أو الاسترجاع المعزز للتوليد، هو ببساطة طريقة للبحث عن معلومات وإدخالها في النص. يضمن هذا التنفيذ المحلي خصوصية البيانات مع توفير استجابات ذكية تستند إلى قواعد معرفة مخصصة. يعتبر النهج ذا قيمة خاصة للسيناريوهات المؤسسية التي تتطلب سيادة البيانات وقدرات التشغيل دون اتصال.

**تعرف على المزيد**: [Foundry Local RAG Samples](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

## موارد تطوير Windows EdgeAI

للمطورين الذين يستهدفون منصة Windows بشكل خاص، قمنا بإنشاء دليل شامل يغطي نظام Windows EdgeAI بالكامل. يوفر هذا المورد معلومات تفصيلية حول Windows AI Foundry، بما في ذلك واجهات برمجة التطبيقات، الأدوات، وأفضل الممارسات لتطوير EdgeAI على Windows.

### منصة Windows AI Foundry
توفر منصة Windows AI Foundry مجموعة شاملة من الأدوات وواجهات برمجة التطبيقات المصممة خصيصًا لتطوير Edge AI على أجهزة Windows. يشمل ذلك دعمًا متخصصًا للأجهزة المسرعة بواسطة NPU، تكامل Windows ML، وتقنيات تحسين خاصة بالمنصة.

**الدليل الشامل**: [Windows EdgeAI Development Guide](../windowdeveloper.md)

يغطي هذا الدليل:
- نظرة عامة على منصة Windows AI Foundry ومكوناتها
- واجهة برمجة التطبيقات Phi Silica للاستدلال الفعال على أجهزة NPU
- واجهات برمجة التطبيقات للرؤية الحاسوبية لمعالجة الصور و OCR
- تكامل وتشغيل Windows ML
- واجهة CLI لـ Foundry Local للتطوير والاختبار المحلي
- استراتيجيات تحسين الأجهزة لأجهزة Windows
- أمثلة عملية وأفضل الممارسات للتنفيذ

### أدوات الذكاء الاصطناعي لتطوير Edge AI
للمطورين الذين يستخدمون Visual Studio Code، يوفر امتداد أدوات الذكاء الاصطناعي بيئة تطوير شاملة مصممة خصيصًا لبناء واختبار ونشر تطبيقات Edge AI. تعمل هذه الأدوات على تبسيط سير العمل الكامل لتطوير Edge AI داخل VS Code.

**دليل التطوير**: [AI Toolkit for Edge AI Development](../aitoolkit.md)

يغطي دليل أدوات الذكاء الاصطناعي:
- اكتشاف النماذج واختيارها للنشر الطرفي
- اختبارات وتحسينات محلية
- تكامل ONNX و Ollama للنماذج الطرفية
- تقنيات تحويل النماذج وتكميمها
- تطوير الوكلاء للسيناريوهات الطرفية
- تقييم الأداء والمراقبة
- إعداد النشر وأفضل الممارسات

## الخاتمة

تُظهر هذه التطبيقات الخمسة لـ EdgeAI نضج وتنوع حلول الذكاء الاصطناعي الطرفية المتاحة اليوم. من الأجهزة الطرفية المسرعة مثل Jetson Orin Nano إلى أطر العمل البرمجية مثل ONNX Runtime GenAI و Windows ML، يتمتع المطورون بخيارات غير مسبوقة لنشر التطبيقات الذكية على الأطراف.

الخيط المشترك بين جميع هذه المنصات هو ديمقراطية قدرات الذكاء الاصطناعي، مما يجعل التعلم الآلي المتقدم متاحًا للمطورين عبر مستويات مهارات وحالات استخدام مختلفة. سواء كنت تبني تطبيقات محمولة، برامج سطح المكتب، أو أنظمة مضمنة، توفر هذه الحلول أساسًا للجيل القادم من التطبيقات الذكية التي تعمل بكفاءة وخصوصية على الأطراف.

تقدم كل منصة مزايا فريدة: Jetson Orin Nano للحوسبة الطرفية المسرعة، ONNX Runtime GenAI لتطوير التطبيقات المحمولة متعددة المنصات، Azure EdgeAI للتكامل بين السحابة والطرف، Windows ML للتطبيقات الأصلية على Windows، و Foundry Local لتطبيقات RAG التي تركز على الخصوصية. معًا، يمثلون نظامًا بيئيًا شاملاً لتطوير EdgeAI.

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الرسمي. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة ناتجة عن استخدام هذه الترجمة.