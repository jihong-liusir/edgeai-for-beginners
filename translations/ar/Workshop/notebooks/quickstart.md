<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T07:09:28+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "ar"
}
-->
# ุฏููู ุงูุจุฏุก ุงูุณุฑูุน - ุฏูุงุชุฑ ูุฑุดุฉ ุงูุนูู

## ุฌุฏูู ุงููุญุชููุงุช

- [ุงููุชุทูุจุงุช ุงูุฃุณุงุณูุฉ](../../../../Workshop/notebooks)
- [ุงูุฅุนุฏุงุฏ ุงูุฃููู](../../../../Workshop/notebooks)
- [ุงูุฌูุณุฉ 04: ููุงุฑูุฉ ุงูููุงุฐุฌ](../../../../Workshop/notebooks)
- [ุงูุฌูุณุฉ 05: ููุณู ุงููููุงุก ุงููุชุนุฏุฏูู](../../../../Workshop/notebooks)
- [ุงูุฌูุณุฉ 06: ุชูุฌูู ุงูููุงุฐุฌ ุจูุงุกู ุนูู ุงูููุงูุง](../../../../Workshop/notebooks)
- [ูุชุบูุฑุงุช ุงูุจูุฆุฉ](../../../../Workshop/notebooks)
- [ุงูุฃูุงูุฑ ุงูุดุงุฆุนุฉ](../../../../Workshop/notebooks)

---

## ุงููุชุทูุจุงุช ุงูุฃุณุงุณูุฉ

### 1. ุชุซุจูุช Foundry Local

**Windows:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**ุงูุชุญูู ูู ุงูุชุซุจูุช:**
```bash
foundry --version
```

### 2. ุชุซุจูุช ุชุจุนูุงุช Python

```bash
cd Workshop
pip install -r requirements.txt
```

ุฃู ุชุซุจูุชูุง ุจุดูู ูุฑุฏู:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## ุงูุฅุนุฏุงุฏ ุงูุฃููู

### ุจุฏุก ุฎุฏูุฉ Foundry Local

**ูุทููุจ ูุจู ุชุดุบูู ุฃู ุฏูุชุฑ:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

ุงููุฎุฑุฌุงุช ุงููุชููุนุฉ:
```
โ Service started successfully
Endpoint: http://localhost:59959
```

### ุชูุฒูู ูุชุญููู ุงูููุงุฐุฌ

ุชุณุชุฎุฏู ุงูุฏูุงุชุฑ ูุฐู ุงูููุงุฐุฌ ุจุดูู ุงูุชุฑุงุถู:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### ุงูุชุญูู ูู ุงูุฅุนุฏุงุฏ

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## ุงูุฌูุณุฉ 04: ููุงุฑูุฉ ุงูููุงุฐุฌ

### ุงููุฏู
ููุงุฑูุฉ ุงูุฃุฏุงุก ุจูู ููุงุฐุฌ ุงููุบุฉ ุงูุตุบูุฑุฉ (SLM) ูููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLM).

### ุงูุฅุนุฏุงุฏ ุงูุณุฑูุน

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### ุชุดุบูู ุงูุฏูุชุฑ

1. **ุงูุชุญ** `session04_model_compare.ipynb` ูู VS Code ุฃู Jupyter  
2. **ุฃุนุฏ ุชุดุบูู ุงูููุงุฉ** (Kernel โ Restart Kernel)  
3. **ุดุบู ุฌููุน ุงูุฎูุงูุง** ุจุงูุชุฑุชูุจ  

### ุงูุชูููู ุงูุฑุฆูุณู

**ุงูููุงุฐุฌ ุงูุงูุชุฑุงุถูุฉ:**
- **SLM:** `phi-4-mini` (~4GB RAMุ ุฃุณุฑุน)
- **LLM:** `qwen2.5-3b` (~3GB RAMุ ูุญุณูู ููุฐุงูุฑุฉ)

**ูุชุบูุฑุงุช ุงูุจูุฆุฉ (ุงุฎุชูุงุฑู):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### ุงููุฎุฑุฌุงุช ุงููุชููุนุฉ

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

๐ก SLM is 1.99x faster than LLM for this prompt
```

### ุงูุชุฎุตูุต

**ุงุณุชุฎุฏุงู ููุงุฐุฌ ูุฎุชููุฉ:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**ููุฌู ูุฎุตุต:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### ูุงุฆูุฉ ุงูุชุญูู ูู ุงูุชุญูู

- [ ] ุชุนุฑุถ ุงูุฎููุฉ 12 ุงูููุงุฐุฌ ุงูุตุญูุญุฉ (phi-4-miniุ qwen2.5-3b)  
- [ ] ุชุนุฑุถ ุงูุฎููุฉ 12 ููุทุฉ ุงูููุงูุฉ ุงูุตุญูุญุฉ (ุงููููุฐ 59959)  
- [ ] ุชูุฑ ุงูุฎููุฉ 16 ุงูุชุดุฎูุต (โ ุงูุฎุฏูุฉ ุชุนูู)  
- [ ] ุชูุฑ ุงูุฎููุฉ 20 ูุญุต ูุง ูุจู ุงูุชุดุบูู (ููุง ุงููููุฐุฌูู ุฌูุฏุงู)  
- [ ] ุชูุชูู ุงูุฎููุฉ 22 ุจุงูููุงุฑูุฉ ูุน ููู ุฒูู ุงูุงุณุชุฌุงุจุฉ  
- [ ] ุชุนุฑุถ ุงูุฎููุฉ 24 ุงูุชุญูู ๐ ุฌููุน ุงููุญูุตุงุช ูุงุฌุญุฉ!  

### ุชูุฏูุฑ ุงูููุช
- **ุงูุชุดุบูู ุงูุฃูู:** 5-10 ุฏูุงุฆู (ุจูุง ูู ุฐูู ุชูุฒูู ุงูููุงุฐุฌ)  
- **ุงูุชุดุบููุงุช ุงููุงุญูุฉ:** 1-2 ุฏูููุฉ  

---

## ุงูุฌูุณุฉ 05: ููุณู ุงููููุงุก ุงููุชุนุฏุฏูู

### ุงููุฏู
ุนุฑุถ ุงูุชุนุงูู ุจูู ุงููููุงุก ุจุงุณุชุฎุฏุงู Foundry Local SDK - ูุนูู ุงููููุงุก ูุนูุง ูุฅูุชุงุฌ ูุฎุฑุฌุงุช ูุญุณููุฉ.

### ุงูุฅุนุฏุงุฏ ุงูุณุฑูุน

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### ุชุดุบูู ุงูุฏูุชุฑ

1. **ุงูุชุญ** `session05_agents_orchestrator.ipynb`  
2. **ุฃุนุฏ ุชุดุบูู ุงูููุงุฉ**  
3. **ุดุบู ุฌููุน ุงูุฎูุงูุง** ุจุงูุชุฑุชูุจ  

### ุงูุชูููู ุงูุฑุฆูุณู

**ุงูุฅุนุฏุงุฏ ุงูุงูุชุฑุงุถู (ููุณ ุงููููุฐุฌ ูููุง ุงููููููู):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**ุงูุฅุนุฏุงุฏ ุงููุชูุฏู (ููุงุฐุฌ ูุฎุชููุฉ):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### ุงููููููุฉ

```
User Question
    โ
Researcher Agent (phi-4-mini)
  โ Gathers bullet points
    โ
Editor Agent (phi-4-mini or qwen2.5-7b)
  โ Refines into executive summary
    โ
Final Output
```

### ุงููุฎุฑุฌุงุช ุงููุชููุนุฉ

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: โข Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### ุงูุชูุณุนุงุช

**ุฅุถุงูุฉ ุงููุฒูุฏ ูู ุงููููุงุก:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**ุงุฎุชุจุงุฑ ุงูุฏูุนุงุช:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### ุชูุฏูุฑ ุงูููุช
- **ุงูุชุดุบูู ุงูุฃูู:** 3-5 ุฏูุงุฆู  
- **ุงูุชุดุบููุงุช ุงููุงุญูุฉ:** 1-2 ุฏูููุฉ ููู ุณุคุงู  

---

## ุงูุฌูุณุฉ 06: ุชูุฌูู ุงูููุงุฐุฌ ุจูุงุกู ุนูู ุงูููุงูุง

### ุงููุฏู
ุชูุฌูู ุงูููุฌูุงุช ุจุฐูุงุก ุฅูู ุงูููุงุฐุฌ ุงููุชุฎุตุตุฉ ุจูุงุกู ุนูู ุงูููุงูุง ุงูููุชุดูุฉ.

### ุงูุฅุนุฏุงุฏ ุงูุณุฑูุน

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**ููุงุญุธุฉ:** ุชุณุชุฎุฏู ุงูุฌูุณุฉ 06 ููุงุฐุฌ CPU ุงูุชุฑุงุถููุง ูุชุญููู ุฃูุตู ูุฏุฑ ูู ุงูุชูุงูู.

### ุชุดุบูู ุงูุฏูุชุฑ

1. **ุงูุชุญ** `session06_models_router.ipynb`  
2. **ุฃุนุฏ ุชุดุบูู ุงูููุงุฉ**  
3. **ุดุบู ุฌููุน ุงูุฎูุงูุง** ุจุงูุชุฑุชูุจ  

### ุงูุชูููู ุงูุฑุฆูุณู

**ุงููุชุงููุฌ ุงูุงูุชุฑุงุถู (ููุงุฐุฌ CPU):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**ุงูุจุฏูู (ููุงุฐุฌ GPU):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### ุงูุชุดุงู ุงูููุงูุง

ูุณุชุฎุฏู ุงูููุฌู ุฃููุงุท regex ูุงูุชุดุงู ุงูููุงูุง:

| ุงูููุฉ | ุฃูุซูุฉ ุนูู ุงูุฃููุงุท | ูุชู ุชูุฌูููุง ุฅูู |
|-------|-------------------|-----------------|
| `code` | "refactor"ุ "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize"ุ "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize"ุ "tl;dr" | phi-4-mini-cpu |
| `general` | ูู ุดูุก ุขุฎุฑ | phi-4-mini-cpu |

### ุงููุฎุฑุฌุงุช ุงููุชููุนุฉ

```
โ Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

โ Success! All prompts routed correctly.
```

### ุงูุชุฎุตูุต

**ุฅุถุงูุฉ ููุฉ ูุฎุตุตุฉ:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|็ฟป่ฏ', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**ุชูููู ุชุชุจุน ุงูุฑููุฒ:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### ุงูุชุจุฏูู ุฅูู ููุงุฐุฌ GPU

ุฅุฐุง ูุงู ูุฏูู ุฐุงูุฑุฉ VRAM ุจุณุนุฉ 8GB+:

1. ูู **ุงูุฎููุฉ #6**ุ ูู ุจุชุนููู ูุชุงููุฌ CPU  
2. ูู ุจุฅูุบุงุก ุชุนููู ูุชุงููุฌ GPU  
3. ุชุญููู ููุงุฐุฌ GPU:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. ุฃุนุฏ ุชุดุบูู ุงูููุงุฉ ูุฃุนุฏ ุชุดุบูู ุงูุฏูุชุฑ  

### ุชูุฏูุฑ ุงูููุช
- **ุงูุชุดุบูู ุงูุฃูู:** 5-10 ุฏูุงุฆู (ุชุญููู ุงูููุงุฐุฌ)  
- **ุงูุชุดุบููุงุช ุงููุงุญูุฉ:** 30-60 ุซุงููุฉ ููู ุงุฎุชุจุงุฑ  

---

## ูุชุบูุฑุงุช ุงูุจูุฆุฉ

### ุงูุชูููู ุงูุนุงููู

ูู ุจุชุนูููู ูุจู ุจุฏุก Jupyter/VS Code:

**Windows (Command Prompt):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**Windows (PowerShell):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### ุงูุชูููู ุฏุงุฎู ุงูุฏูุชุฑ

ูู ุจุชุนูููู ูู ุจุฏุงูุฉ ุฃู ุฏูุชุฑ:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## ุงูุฃูุงูุฑ ุงูุดุงุฆุนุฉ

### ุฅุฏุงุฑุฉ ุงูุฎุฏูุฉ

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### ุฅุฏุงุฑุฉ ุงูููุงุฐุฌ

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### ุงุฎุชุจุงุฑ ููุงุท ุงูููุงูุฉ

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### ุฃูุงูุฑ ุงูุชุดุฎูุต

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## ุฃูุถู ุงูููุงุฑุณุงุช

### ูุจู ุจุฏุก ุฃู ุฏูุชุฑ

1. **ุชุญูู ูู ุชุดุบูู ุงูุฎุฏูุฉ:**
   ```bash
   foundry service status
   ```

2. **ุชุญูู ูู ุชุญููู ุงูููุงุฐุฌ:**
   ```bash
   foundry model ls
   ```

3. **ุฃุนุฏ ุชุดุบูู ููุงุฉ ุงูุฏูุชุฑ** ุฅุฐุง ููุช ุชุนูุฏ ุงูุชุดุบูู  

4. **ุงูุณุญ ุฌููุน ุงููุฎุฑุฌุงุช** ููุญุตูู ุนูู ุชุดุบูู ูุธูู  

### ุฅุฏุงุฑุฉ ุงูููุงุฑุฏ

1. **ุงุณุชุฎุฏู ููุงุฐุฌ CPU ุงูุชุฑุงุถููุง** ูุชุญููู ุงูุชูุงูู  
2. **ูู ุจุงูุชุจุฏูู ุฅูู ููุงุฐุฌ GPU** ููุท ุฅุฐุง ูุงู ูุฏูู ุฐุงูุฑุฉ VRAM ุจุณุนุฉ 8GB+  
3. **ุฃุบูู ุงูุชุทุจููุงุช ุงูุฃุฎุฑู ุงูุชู ุชุณุชุฎุฏู GPU** ูุจู ุงูุชุดุบูู  
4. **ุงุญุชูุธ ุจุงูุฎุฏูุฉ ููุฏ ุงูุชุดุบูู** ุจูู ุฌูุณุงุช ุงูุฏูุชุฑ  
5. **ุฑุงูุจ ุงุณุชุฎุฏุงู ุงูููุงุฑุฏ** ุจุงุณุชุฎุฏุงู Task Manager / nvidia-smi  

### ุงุณุชูุดุงู ุงูุฃุฎุทุงุก ูุฅุตูุงุญูุง

1. **ุชุญูู ุฏุงุฆููุง ูู ุงูุฎุฏูุฉ ุฃููุงู** ูุจู ุชุตุญูุญ ุงูุฃุฎุทุงุก ูู ุงูููุฏ  
2. **ุฃุนุฏ ุชุดุบูู ุงูููุงุฉ** ุฅุฐุง ุฑุฃูุช ุชูููููุง ูุฏูููุง  
3. **ุฃุนุฏ ุชุดุบูู ุฎูุงูุง ุงูุชุดุฎูุต** ุจุนุฏ ุฃู ุชุบููุฑุงุช  
4. **ุชุญูู ูู ุฃุณูุงุก ุงูููุงุฐุฌ** ูุชุชุทุงุจู ูุน ูุง ุชู ุชุญูููู  
5. **ุชุญูู ูู ูููุฐ ููุทุฉ ุงูููุงูุฉ** ูุชุชุทุงุจู ูุน ุญุงูุฉ ุงูุฎุฏูุฉ  

---

## ุงููุฑุฌุน ุงูุณุฑูุน: ุฃุณูุงุก ุงูููุงุฐุฌ

### ุงูููุงุฐุฌ ุงูุดุงุฆุนุฉ

| ุงูุงุณู ุงููุณุชุนุงุฑ | ุงูุญุฌู | ุงูุฃูุถู ูู | RAM/VRAM | ุงููุชุบูุฑุงุช |
|----------------|-------|-----------|----------|-----------|
| `phi-4-mini` | ~4B | ุงูุฏุฑุฏุดุฉ ุงูุนุงูุฉุ ุงูุชูุฎูุต | 4-6GB | `-cpu`ุ `-cuda-gpu`ุ `-npu` |
| `phi-3.5-mini` | ~3.5B | ุฅูุดุงุก ุงูุฃููุงุฏุ ุฅุนุงุฏุฉ ุงูููููุฉ | 3-5GB | `-cpu`ุ `-cuda-gpu`ุ `-npu` |
| `qwen2.5-3b` | ~3B | ุงูููุงู ุงูุนุงูุฉุ ุงูููุงุกุฉ | 3-4GB | `-cpu`ุ `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | ุณุฑูุนุ ููุงุฑุฏ ููุฎูุถุฉ | 2-3GB | `-cpu`ุ `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | ุงูุชุตูููุ ููุงุฑุฏ ููููุฉ ุฌุฏูุง | 1-2GB | `-cpu`ุ `-cuda-gpu` |

### ุชุณููุฉ ุงููุชุบูุฑุงุช

- **ุงูุงุณู ุงูุฃุณุงุณู** (ูุซู `phi-4-mini`): ูุฎุชุงุฑ ุชููุงุฆููุง ุฃูุถู ูุชุบูุฑ ูุฌูุงุฒู  
- **`-cpu`**: ูุญุณูู ูู CPUุ ูุนูู ูู ูู ููุงู  
- **`-cuda-gpu`**: ูุญุณูู ูู NVIDIA GPUุ ูุชุทูุจ ุฐุงูุฑุฉ VRAM ุจุณุนุฉ 8GB+  
- **`-npu`**: ูุญุณูู ูู Qualcomm NPUุ ูุชุทูุจ ุจุฑุงูุฌ ุชุดุบูู NPU  

**ุงูุชูุตูุฉ:** ุงุณุชุฎุฏู ุงูุฃุณูุงุก ุงูุฃุณุงุณูุฉ (ุจุฏูู ูุงุญูุฉ) ูุฏุน Foundry Local ูุฎุชุงุฑ ุฃูุถู ูุชุบูุฑ ุชููุงุฆููุง.

---

## ูุคุดุฑุงุช ุงููุฌุงุญ

ุฃูุช ุฌุงูุฒ ุนูุฏูุง ุชุฑู:

โ `foundry service status` ูุธูุฑ "running"  
โ `foundry model ls` ูุธูุฑ ุงูููุงุฐุฌ ุงููุทููุจุฉ  
โ ุงูุฎุฏูุฉ ูุชุงุญุฉ ุนูุฏ ููุทุฉ ุงูููุงูุฉ ุงูุตุญูุญุฉ  
โ ูุญุต ุงูุตุญุฉ ูุนูุฏ 200 OK  
โ ุฎูุงูุง ุงูุชุดุฎูุต ูู ุงูุฏูุชุฑ ุชูุฑ  
โ ูุง ุชูุฌุฏ ุฃุฎุทุงุก ุงุชุตุงู ูู ุงููุฎุฑุฌุงุช  

---

## ุงูุญุตูู ุนูู ุงููุณุงุนุฏุฉ

### ุงููุซุงุฆู
- **ุงููุณุชูุฏุน ุงูุฑุฆูุณู**: https://github.com/microsoft/Foundry-Local  
- **Python SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python  
- **ูุฑุฌุน CLI**: https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md  
- **ุงุณุชูุดุงู ุงูุฃุฎุทุงุก ูุฅุตูุงุญูุง**: ุฑุงุฌุน `troubleshooting.md` ูู ูุฐุง ุงูุฏููู  

### ูุดุงูู GitHub
- https://github.com/microsoft/Foundry-Local/issues  
- https://github.com/microsoft/edgeai-for-beginners/issues  

---

**ุขุฎุฑ ุชุญุฏูุซ:** 8 ุฃูุชูุจุฑ 2025  
**ุงูุฅุตุฏุงุฑ:** ุฏูุงุชุฑ ูุฑุดุฉ ุงูุนูู 2.0  

---

**ุฅุฎูุงุก ุงููุณุคูููุฉ**:  
ุชู ุชุฑุฌูุฉ ูุฐุง ุงููุณุชูุฏ ุจุงุณุชุฎุฏุงู ุฎุฏูุฉ ุงูุชุฑุฌูุฉ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู [Co-op Translator](https://github.com/Azure/co-op-translator). ุจูููุง ูุณุนู ูุชุญููู ุงูุฏูุฉุ ูุฑุฌู ุงูุนูู ุฃู ุงูุชุฑุฌูุงุช ุงูุขููุฉ ูุฏ ุชุญุชูู ุนูู ุฃุฎุทุงุก ุฃู ูุนูููุงุช ุบูุฑ ุฏูููุฉ. ูุฌุจ ุงุนุชุจุงุฑ ุงููุณุชูุฏ ุงูุฃุตูู ุจูุบุชู ุงูุฃุตููุฉ ุงููุตุฏุฑ ุงูุฑุณูู. ููุญุตูู ุนูู ูุนูููุงุช ุญุงุณูุฉุ ูููุตู ุจุงูุงุณุชุนุงูุฉ ุจุชุฑุฌูุฉ ุจุดุฑูุฉ ุงุญุชุฑุงููุฉ. ูุญู ุบูุฑ ูุณุคูููู ุนู ุฃู ุณูุก ููู ุฃู ุชูุณูุฑุงุช ุฎุงุทุฆุฉ ูุงุชุฌุฉ ุนู ุงุณุชุฎุฏุงู ูุฐู ุงูุชุฑุฌูุฉ.