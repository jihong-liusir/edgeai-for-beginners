<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1f5ed7b55962c3dccafd3da6f9ec252",
  "translation_date": "2025-09-17T17:45:43+00:00",
  "source_file": "Module01/04.EdgeDeployment.md",
  "language_code": "ar"
}
-->
# القسم 4: منصات الأجهزة لنشر الذكاء الاصطناعي على الحافة

يمثل نشر الذكاء الاصطناعي على الحافة تتويجًا لعملية تحسين النماذج واختيار الأجهزة، حيث يتم جلب القدرات الذكية مباشرة إلى الأجهزة التي يتم فيها توليد البيانات. يستكشف هذا القسم الاعتبارات العملية، متطلبات الأجهزة، والفوائد الاستراتيجية لنشر الذكاء الاصطناعي على الحافة عبر منصات مختلفة، مع التركيز على الحلول الرائدة من Intel، Qualcomm، NVIDIA، وأجهزة Windows AI PCs.

## الموارد للمطورين

### الوثائق وموارد التعلم
- [Microsoft Learn: تطوير الذكاء الاصطناعي على الحافة](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)
- [موارد Intel للذكاء الاصطناعي على الحافة](https://www.intel.com/content/www/us/en/developer/topic-technology/edge-5g/edge-ai.html)
- [موارد Qualcomm للمطورين](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk)
- [وثائق NVIDIA Jetson](https://developer.nvidia.com/embedded/learn/getting-started-jetson)
- [وثائق Windows AI](https://learn.microsoft.com/windows/ai/)

### الأدوات وSDKs
- [ONNX Runtime](https://onnxruntime.ai/) - إطار عمل للتنفيذ عبر المنصات
- [OpenVINO Toolkit](https://docs.openvino.ai/) - مجموعة أدوات التحسين من Intel
- [TensorRT](https://developer.nvidia.com/tensorrt) - SDK للتنفيذ عالي الأداء من NVIDIA
- [DirectML](https://learn.microsoft.com/windows/ai/directml/dml-intro) - واجهة برمجية للتعلم الآلي المسرّع من Microsoft

## المقدمة

في هذا القسم، سنستكشف الجوانب العملية لنشر نماذج الذكاء الاصطناعي على الأجهزة الطرفية. سنغطي الاعتبارات الأساسية للنشر الناجح، اختيار منصات الأجهزة، واستراتيجيات التحسين الخاصة بمختلف سيناريوهات الحوسبة الطرفية.

## أهداف التعلم

بنهاية هذا القسم، ستكون قادرًا على:

- فهم الاعتبارات الرئيسية لنشر الذكاء الاصطناعي على الحافة بنجاح
- تحديد منصات الأجهزة المناسبة لمختلف أعباء العمل للذكاء الاصطناعي على الحافة
- التعرف على الموازنة بين الحلول المختلفة للأجهزة الطرفية
- تطبيق تقنيات التحسين الخاصة بمنصات الأجهزة المختلفة للذكاء الاصطناعي على الحافة

## اعتبارات نشر الذكاء الاصطناعي على الحافة

يقدم نشر الذكاء الاصطناعي على الأجهزة الطرفية تحديات ومتطلبات فريدة مقارنة بالنشر السحابي. يتطلب التنفيذ الناجح للذكاء الاصطناعي على الحافة مراعاة دقيقة لعدة عوامل:

### قيود موارد الأجهزة

عادةً ما تكون الأجهزة الطرفية محدودة الموارد مقارنة بالبنية التحتية السحابية:

- **قيود الذاكرة**: العديد من الأجهزة الطرفية تحتوي على ذاكرة RAM محدودة (من بضعة ميغابايت إلى بضعة غيغابايت)
- **قيود التخزين**: التخزين الدائم المحدود يؤثر على حجم النموذج وإدارة البيانات
- **قدرات المعالجة**: قدرات CPU/GPU/NPU المحدودة تؤثر على سرعة التنفيذ
- **استهلاك الطاقة**: العديد من الأجهزة الطرفية تعمل على طاقة البطارية أو لديها قيود حرارية

### اعتبارات الاتصال

يجب أن يعمل الذكاء الاصطناعي على الحافة بشكل فعال مع اتصال متغير:

- **الاتصال المتقطع**: يجب أن تستمر العمليات أثناء انقطاع الشبكة
- **قيود النطاق الترددي**: قدرات نقل البيانات أقل مقارنة بمراكز البيانات
- **متطلبات زمن الاستجابة**: العديد من التطبيقات تتطلب معالجة في الوقت الفعلي أو شبه الفعلي
- **مزامنة البيانات**: إدارة المعالجة المحلية مع المزامنة الدورية مع السحابة

### متطلبات الأمان والخصوصية

يقدم الذكاء الاصطناعي على الحافة تحديات أمان محددة:

- **الأمان الفيزيائي**: قد يتم نشر الأجهزة في مواقع يمكن الوصول إليها ماديًا
- **حماية البيانات**: معالجة البيانات الحساسة على أجهزة قد تكون عرضة للخطر
- **المصادقة**: التحكم الآمن في الوصول لوظائف الأجهزة الطرفية
- **إدارة التحديثات**: آليات آمنة لتحديث النماذج والبرامج

### النشر والإدارة

تشمل الاعتبارات العملية للنشر:

- **إدارة الأسطول**: العديد من عمليات النشر الطرفية تشمل أجهزة موزعة عديدة
- **إدارة الإصدارات**: إدارة إصدارات النماذج عبر الأجهزة الموزعة
- **المراقبة**: تتبع الأداء واكتشاف الشذوذ على الحافة
- **إدارة دورة الحياة**: من النشر الأولي إلى التحديثات وحتى التقاعد

## خيارات منصات الأجهزة للذكاء الاصطناعي على الحافة

### حلول Intel للذكاء الاصطناعي على الحافة

تقدم Intel عدة منصات أجهزة محسّنة لنشر الذكاء الاصطناعي على الحافة:

#### Intel NUC

يوفر Intel NUC (وحدة الحوسبة التالية) أداءً على مستوى سطح المكتب في شكل صغير الحجم:

- **معالجات Intel Core** مع رسومات Iris Xe المدمجة
- **RAM**: يدعم حتى 64GB DDR4
- **التوافق مع Neural Compute Stick 2** لتسريع إضافي للذكاء الاصطناعي
- **الأفضل لـ**: أعباء العمل الطرفية المعتدلة إلى المعقدة في المواقع الثابتة مع توفر الطاقة

[Intel NUC للذكاء الاصطناعي على الحافة](https://www.intel.com/content/www/us/en/products/details/nuc.html)

#### وحدات معالجة الرؤية Intel Movidius (VPUs)

أجهزة متخصصة للرؤية الحاسوبية وتسريع الشبكات العصبية:

- **استهلاك طاقة منخفض للغاية** (1-3W نموذجي)
- **تسريع مخصص للشبكات العصبية**
- **شكل صغير الحجم** للتكامل مع الكاميرات وأجهزة الاستشعار
- **الأفضل لـ**: تطبيقات الرؤية الحاسوبية مع قيود صارمة على الطاقة

[Intel Movidius VPU](https://www.intel.com/content/www/us/en/products/details/processors/movidius-vpu.html)

#### Intel Neural Compute Stick 2

مسرّع شبكات عصبية يعمل عبر USB:

- **Intel Movidius Myriad X VPU**
- **أداء يصل إلى 4 TOPS**
- **واجهة USB 3.0** للتكامل السهل
- **الأفضل لـ**: النماذج الأولية السريعة وإضافة قدرات الذكاء الاصطناعي إلى الأنظمة الحالية

[Intel Neural Compute Stick 2](https://www.intel.com/content/www/us/en/developer/tools/neural-compute-stick/overview.html)

#### نهج التطوير

توفر Intel مجموعة أدوات OpenVINO لتحسين النماذج ونشرها:

```python
# Example: Using OpenVINO for edge deployment
from openvino.inference_engine import IECore

# Initialize the Inference Engine
ie = IECore()

# Read the network from IR files
net = ie.read_network(model="optimized_model.xml", weights="optimized_model.bin")

# Prepare input and output blobs
input_blob = next(iter(net.input_info))
output_blob = next(iter(net.outputs))

# Load the network to the device (CPU, GPU, MYRIAD, etc.)
exec_net = ie.load_network(network=net, device_name="CPU")

# Prepare input
input_data = preprocess_image("sample.jpg")

# Run inference
result = exec_net.infer(inputs={input_blob: input_data})

# Process output
output = result[output_blob]
```

### حلول Qualcomm للذكاء الاصطناعي

تركز منصات Qualcomm على التطبيقات المحمولة والمضمنة:

#### Qualcomm Snapdragon

أنظمة Snapdragon على الشريحة (SoCs) تتضمن:

- **محرك الذكاء الاصطناعي Qualcomm** مع Hexagon DSP
- **Adreno GPU** للرسومات والحوسبة المتوازية
- **أنوية Kryo CPU** للمعالجة العامة
- **الأفضل لـ**: الهواتف الذكية، الأجهزة اللوحية، سماعات XR، والكاميرات الذكية

[Qualcomm Snapdragon للذكاء الاصطناعي على الحافة](https://www.qualcomm.com/products/mobile/snapdragon/pcs/product-list)

#### Qualcomm Cloud AI 100

مسرّع استنتاج الذكاء الاصطناعي الطرفي المخصص:

- **أداء يصل إلى 400 TOPS**
- **كفاءة الطاقة** محسّنة لمراكز البيانات والنشر الطرفي
- **هندسة قابلة للتوسع** لسيناريوهات النشر المختلفة
- **الأفضل لـ**: تطبيقات الذكاء الاصطناعي الطرفية عالية الإنتاجية في البيئات المسيطر عليها

[Qualcomm Cloud AI 100](https://www.qualcomm.com/products/technology/processors/cloud-artificial-intelligence)

#### منصة Qualcomm RB5/RB6 للروبوتات

مصممة خصيصًا للروبوتات والحوسبة الطرفية المتقدمة:

- **اتصال 5G مدمج**
- **قدرات متقدمة للذكاء الاصطناعي والرؤية الحاسوبية**
- **دعم شامل لأجهزة الاستشعار**
- **الأفضل لـ**: الروبوتات الذاتية، الطائرات بدون طيار، والأنظمة الصناعية الذكية

[منصة Qualcomm للروبوتات](https://www.qualcomm.com/products/application/robotics/qualcomm-robotics-rb6-platform)

#### نهج التطوير

توفر Qualcomm Neural Processing SDK وAI Model Efficiency Toolkit:

```python
# Example: Using Qualcomm Neural Processing SDK
from qti.aisw.dlc_utils import modeltools

# Convert your model to DLC format
converter = modeltools.DlcConverter()
converter.convert(
    input_network="model.tflite",
    input_dim=[1, 224, 224, 3],
    output_path="optimized_model.dlc"
)

# Use SNPE runtime for inference
from qti.aisw.snpe_runtime import SnpeRuntime

# Initialize runtime
runtime = SnpeRuntime()
runtime.load("optimized_model.dlc")

# Prepare input
input_tensor = preprocess_image("sample.jpg")

# Run inference
outputs = runtime.execute(input_tensor)

# Process results
predictions = postprocess_output(outputs)
```

### 🎮 حلول NVIDIA للذكاء الاصطناعي على الحافة

تقدم NVIDIA منصات قوية مع تسريع GPU للنشر الطرفي:

#### عائلة NVIDIA Jetson

منصات حوسبة الذكاء الاصطناعي الطرفية المصممة خصيصًا:

##### سلسلة Jetson Orin
- **أداء يصل إلى 275 TOPS**
- **معمارية NVIDIA Ampere GPU**
- **تكوينات الطاقة** من 5W إلى 60W
- **الأفضل لـ**: الروبوتات المتقدمة، تحليلات الفيديو الذكية، والأجهزة الطبية

##### Jetson Nano
- **حوسبة الذكاء الاصطناعي للمبتدئين** (472 GFLOPS)
- **GPU Maxwell بـ 128 نواة**
- **كفاءة الطاقة** (5-10W)
- **الأفضل لـ**: المشاريع الهواة، التطبيقات التعليمية، والنشر البسيط للذكاء الاصطناعي

[منصة NVIDIA Jetson](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/)

#### NVIDIA Clara Guardian

منصة لتطبيقات الذكاء الاصطناعي في الرعاية الصحية:

- **الاستشعار في الوقت الفعلي** لمراقبة المرضى
- **مبنية على Jetson** أو خوادم مسرّعة GPU
- **تحسينات خاصة بالرعاية الصحية**
- **الأفضل لـ**: المستشفيات الذكية، مراقبة المرضى، وتصوير الطبي

[NVIDIA Clara Guardian](https://developer.nvidia.com/clara)

#### منصة NVIDIA EGX

حلول الحوسبة الطرفية على مستوى المؤسسات:

- **قابلة للتوسع من NVIDIA A100 إلى T4 GPUs**
- **حلول خوادم معتمدة** من شركاء OEM
- **مجموعة برامج NVIDIA AI Enterprise** مضمنة
- **الأفضل لـ**: عمليات نشر الذكاء الاصطناعي الطرفية واسعة النطاق في البيئات الصناعية والمؤسساتية

[منصة NVIDIA EGX](https://www.nvidia.com/en-us/data-center/products/egx-edge-computing/)

#### نهج التطوير

توفر NVIDIA TensorRT لنشر النماذج المحسّنة:

```python
# Example: Using TensorRT for optimized inference
import tensorrt as trt
import numpy as np

# Create builder and network
logger = trt.Logger(trt.Logger.INFO)
builder = trt.Builder(logger)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))

# Parse ONNX model
parser = trt.OnnxParser(network, logger)
with open("model.onnx", "rb") as f:
    parser.parse(f.read())

# Create optimization config
config = builder.create_builder_config()
config.max_workspace_size = 1 << 30  # 1GB
config.set_flag(trt.BuilderFlag.FP16)

# Build and serialize engine
engine = builder.build_engine(network, config)
with open("model.trt", "wb") as f:
    f.write(engine.serialize())

# Create runtime and execute
runtime = trt.Runtime(logger)
engine = runtime.deserialize_cuda_engine(open("model.trt", "rb").read())
context = engine.create_execution_context()

# Run inference
input_data = preprocess_image("sample.jpg")
output = run_inference(context, input_data, engine)
```

### أجهزة Windows AI PCs

تمثل أجهزة Windows AI PCs فئة جديدة من أجهزة الذكاء الاصطناعي الطرفية، مع وحدات معالجة عصبية (NPUs) متخصصة:

#### Qualcomm Snapdragon X Elite/Plus

الجيل الأول من أجهزة Windows Copilot+ PCs يتميز بـ:

- **Hexagon NPU** مع أداء يزيد عن 45 TOPS
- **معالج Qualcomm Oryon** مع ما يصل إلى 12 نواة
- **Adreno GPU** للرسومات وتسريع إضافي للذكاء الاصطناعي
- **الأفضل لـ**: الإنتاجية المعززة بالذكاء الاصطناعي، إنشاء المحتوى، وتطوير البرمجيات

[Qualcomm Snapdragon X Elite](https://www.qualcomm.com/snapdragon/laptops)

#### Intel Core Ultra (Meteor Lake وما بعده)

معالجات Intel لأجهزة الذكاء الاصطناعي تتميز بـ:

- **Intel AI Boost (NPU)** يوفر أداء يصل إلى 10 TOPS
- **Intel Arc GPU** يقدم تسريع إضافي للذكاء الاصطناعي
- **أنوية CPU للأداء والكفاءة**
- **الأفضل لـ**: أجهزة الكمبيوتر المحمولة للأعمال، محطات العمل الإبداعية، والحوسبة اليومية المعززة بالذكاء الاصطناعي

[معالجات Intel Core Ultra](https://www.intel.com/content/www/us/en/products/details/processors/core/ultra.html)

#### سلسلة AMD Ryzen AI

معالجات AMD الموجهة للذكاء الاصطناعي تشمل:

- **NPU قائم على XDNA** يوفر أداء يصل إلى 16 TOPS
- **أنوية Zen 4 CPU** للمعالجة العامة
- **رسومات RDNA 3** لقدرات الحوسبة الإضافية
- **الأفضل لـ**: المحترفين المبدعين، المطورين، والمستخدمين المتقدمين

[معالجات AMD Ryzen AI](https://www.amd.com/en/processors/ryzen-ai.html)

#### نهج التطوير

تستفيد أجهزة Windows AI PCs من منصة Windows Developer وDirectML:

```csharp
// Example: Using Windows App SDK and DirectML
using Microsoft.AI.DirectML;
using Microsoft.Windows.AI;

// Load model
var modelPath = "optimized_model.onnx";
var modelOptions = new OnnxModelOptions
{
    InterOpNumThreads = 4,
    IntraOpNumThreads = 4
};

// Create model
var model = await OnnxModel.CreateFromFileAsync(modelPath, modelOptions);

// Prepare input
var inputFeatures = new List<InputFeature>
{
    new InputFeature
    {
        Name = "input",
        Value = imageData
    }
};

// Run inference
var results = await model.EvaluateAsync(inputFeatures);

// Process output
var output = results.First().Value;
```

## ⚡ تقنيات التحسين الخاصة بالأجهزة

### 🔍 نهج التكميم

تستفيد منصات الأجهزة المختلفة من تقنيات تكميم محددة:

#### تحسينات Intel OpenVINO
- **تكميم INT8** للمعالج المركزي ووحدة الرسومات المدمجة
- **دقة FP16** لتحسين الأداء مع خسارة دقة قليلة
- **تكميم غير متماثل** للتعامل مع توزيعات التنشيط

#### تحسينات محرك الذكاء الاصطناعي Qualcomm
- **تكميم UINT8** لـ Hexagon DSP
- **دقة مختلطة** تستفيد من جميع وحدات الحوسبة المتاحة
- **تكميم لكل قناة** لتحسين الدقة

#### تحسينات NVIDIA TensorRT
- **دقة INT8 وFP16** لتسريع GPU
- **دمج الطبقات** لتقليل نقل البيانات
- **ضبط تلقائي للنواة** لهندسات GPU محددة

#### تحسينات NPU في Windows
- **تكميم INT8/INT4** لتنفيذ NPU
- **تحسينات الرسم البياني DirectML**
- **تسريع وقت تشغيل Windows ML**

### التكيفات الخاصة بالهندسة المعمارية

تتطلب الأجهزة المختلفة اعتبارات هندسية محددة:

- **Intel**: تحسين لتعليمات AVX-512 ومتسارع التعلم العميق من Intel
- **Qualcomm**: الاستفادة من الحوسبة غير المتجانسة عبر Hexagon DSP، Adreno GPU، وKryo CPU
- **NVIDIA**: تحقيق أقصى استفادة من التوازي GPU واستخدام أنوية CUDA
- **Windows NPU**: التصميم لمعالجة تعاونية بين NPU-CPU-GPU

### استراتيجيات إدارة الذاكرة

تختلف إدارة الذاكرة الفعالة حسب المنصة:

- **Intel**: تحسين لاستخدام ذاكرة التخزين المؤقت وأنماط الوصول إلى الذاكرة
- **Qualcomm**: إدارة الذاكرة المشتركة عبر المعالجات غير المتجانسة
- **NVIDIA**: استخدام ذاكرة موحدة CUDA وتحسين استخدام VRAM
- **Windows NPU**: موازنة أعباء العمل بين ذاكرة NPU المخصصة وRAM النظام

## قياس الأداء والمعايير

عند تقييم نشر الذكاء الاصطناعي على الحافة، ضع في اعتبارك هذه المقاييس الرئيسية:

### مقاييس الأداء

- **وقت التنفيذ**: ميلي ثانية لكل تنفيذ (الأقل هو الأفضل)
- **الإنتاجية**: عدد التنفيذات في الثانية (الأعلى هو الأفضل)
- **زمن الاستجابة**: وقت الاستجابة من البداية إلى النهاية (الأقل هو الأفضل)
- **FPS**: الإطارات في الثانية لتطبيقات الرؤية (الأعلى هو الأفضل)

### مقاييس الكفاءة

- **الأداء لكل واط**: TOPS/W أو تنفيذات/ثانية/واط
- **الطاقة لكل تنفيذ**: الجول المستهلك لكل تنفيذ
- **تأثير البطارية**: تقليل وقت التشغيل عند تشغيل أعباء العمل للذكاء الاصطناعي
- **الكفاءة الحرارية**: زيادة درجة الحرارة أثناء التشغيل المستمر

### مقاييس الدقة

- **دقة Top-1/Top-5**: نسبة صحة التصنيف
- **mAP**: متوسط الدقة للأغراض الكشف
- **درجة F1**: توازن بين الدقة والاسترجاع
- **تأثير التكميم**: الفرق في الدقة بين النماذج ذات الدقة الكاملة والمكممة

## أنماط النشر وأفضل الممارسات

### استراتيجيات النشر للمؤسسات

- **الحاويات**: استخدام Docker أو ما شابه للنشر المتسق
- **إدارة الأسطول**: حلول مثل Azure IoT Edge لإدارة الأجهزة
- **المراقبة**: جمع البيانات التليمترية وتتبع الأداء
- **إدارة التحديثات**: آليات تحديث OTA للنماذج والبرمجيات

### أنماط السحابة الهجينة والحافة

- **التدريب في السحابة، الاستنتاج في الحافة**: التدريب في السحابة، النشر في الحافة
- **المعالجة الأولية في الحافة، التحليل في السحابة**: معالجة أساسية في الحافة، تحليل معقد في السحابة
- **التعلم الفيدرالي**: تحسين النموذج الموزع دون مركزية البيانات
- **التعلم التدريجي**: تحسين النموذج بشكل مستمر من بيانات الحافة

### أنماط التكامل

- **تكامل المستشعرات**: الاتصال المباشر بالكاميرات، الميكروفونات، والمستشعرات الأخرى
- **التحكم في المشغلات**: التحكم الفوري في المحركات، الشاشات، والمخرجات الأخرى
- **تكامل الأنظمة**: التواصل مع أنظمة المؤسسات الحالية
- **تكامل إنترنت الأشياء**: الاتصال مع أنظمة إنترنت الأشياء الأوسع

## اعتبارات النشر الخاصة بالصناعة

### الرعاية الصحية

- **خصوصية المرضى**: الامتثال لـ HIPAA لحماية البيانات الطبية
- **لوائح الأجهزة الطبية**: متطلبات FDA والجهات التنظيمية الأخرى
- **متطلبات الموثوقية**: تحمل الأخطاء للتطبيقات الحرجة
- **معايير التكامل**: FHIR، HL7، ومعايير التوافق الأخرى في الرعاية الصحية

### التصنيع

- **البيئة الصناعية**: التكيف مع الظروف القاسية
- **متطلبات الوقت الحقيقي**: الأداء الحتمي لأنظمة التحكم
- **أنظمة السلامة**: التكامل مع بروتوكولات السلامة الصناعية
- **تكامل الأنظمة القديمة**: الاتصال بالبنية التحتية الحالية لـ OT

### السيارات

- **السلامة الوظيفية**: الامتثال لـ ISO 26262
- **التكيف البيئي**: التشغيل عبر درجات حرارة متطرفة
- **إدارة الطاقة**: التشغيل بكفاءة في استهلاك البطارية
- **إدارة دورة الحياة**: الدعم طويل الأمد لعمر المركبة

### المدن الذكية

- **النشر الخارجي**: مقاومة الطقس والأمان الفيزيائي
- **إدارة النطاق**: التعامل مع آلاف إلى ملايين الأجهزة الموزعة
- **تفاوت الشبكة**: التشغيل مع اتصال غير مستقر
- **اعتبارات الخصوصية**: التعامل المسؤول مع بيانات الأماكن العامة

## الاتجاهات المستقبلية في أجهزة الذكاء الاصطناعي على الحافة

### التطورات الناشئة في الأجهزة

- **رقائق مخصصة للذكاء الاصطناعي**: المزيد من وحدات المعالجة العصبية والمسرعات المخصصة للذكاء الاصطناعي
- **الحوسبة العصبية**: معماريات مستوحاة من الدماغ لتحسين الكفاءة
- **الحوسبة داخل الذاكرة**: تقليل حركة البيانات لعمليات الذكاء الاصطناعي
- **التغليف متعدد الشرائح**: دمج متنوع لمعالجات الذكاء الاصطناعي المتخصصة

### التطور المشترك بين البرمجيات والأجهزة

- **البحث عن بنية الشبكات العصبية الموجهة للأجهزة**: نماذج محسنة للأجهزة المحددة
- **تقدم المترجمات**: تحسين ترجمة النماذج إلى تعليمات الأجهزة
- **تحسينات الرسوم البيانية المتخصصة**: تحويلات الشبكات الموجهة للأجهزة
- **التكيف الديناميكي**: تحسين وقت التشغيل بناءً على الموارد المتاحة

### جهود التوحيد القياسي

- **ONNX و ONNX Runtime**: توافق النماذج عبر المنصات
- **MLIR**: تمثيل وسيط متعدد المستويات للتعلم الآلي
- **OpenXLA**: ترجمة الجبر الخطي المتسارعة
- **TMUL**: طبقات تجريد معالجات التنسور

## البدء في نشر الذكاء الاصطناعي على الحافة

### إعداد بيئة التطوير

1. **اختيار الأجهزة المستهدفة**: اختيار المنصة المناسبة لحالتك
2. **تثبيت SDKs والأدوات**: إعداد مجموعة أدوات التطوير الخاصة بالمصنع
3. **تكوين أدوات التحسين**: تثبيت برامج التكميم والتجميع
4. **إعداد خط أنابيب CI/CD**: إنشاء سير عمل الاختبار والنشر الآلي

### قائمة التحقق للنشر

- **تحسين النموذج**: التكميم، التشذيب، وتحسين البنية
- **اختبار الأداء**: قياس الأداء على الأجهزة المستهدفة في ظروف واقعية
- **تحليل الطاقة**: قياس أنماط استهلاك الطاقة
- **تدقيق الأمان**: التحقق من حماية البيانات وضوابط الوصول
- **آلية التحديث**: تنفيذ قدرات التحديث الآمن
- **إعداد المراقبة**: نشر جمع البيانات التنبيهية

## ➡️ ما التالي

- مراجعة [نظرة عامة على الوحدة الأولى](./README.md)
- استكشاف [الوحدة الثانية: أساسيات نماذج اللغة الصغيرة](../Module02/README.md)
- الانتقال إلى [الوحدة الثالثة: استراتيجيات نشر نماذج اللغة الصغيرة](../Module03/README.md)

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الرسمي. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.