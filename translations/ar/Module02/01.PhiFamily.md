<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T17:10:16+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "ar"
}
-->
# القسم 1: أساسيات عائلة نماذج Microsoft Phi

تمثل عائلة نماذج Microsoft Phi تحولًا جذريًا في الذكاء الاصطناعي، حيث تثبت أن النماذج المدمجة والكفؤة يمكن أن تحقق أداءً مذهلًا مع كونها أكثر كفاءة في استخدام الموارد مقارنة بالنماذج التقليدية الكبيرة. من المهم فهم كيف تمكن عائلة Phi من تحقيق قدرات ذكاء اصطناعي قوية مع تقليل المتطلبات الحسابية مع الحفاظ على أداء عالٍ عبر مهام متنوعة.

## الموارد للمطورين

### كتالوج نماذج Azure AI Foundry
تتوفر نماذج عائلة Phi (باستثناء Phi-silica) من خلال [كتالوج نماذج Azure AI Foundry](https://ai.azure.com/explore/models?q=phi)، مما يسهل على المطورين الوصول إلى هذه النماذج وتخصيصها ونشرها في تطبيقاتهم. يوفر الكتالوج طريقة مبسطة لتجربة مختلف أنواع Phi ودمجها في مشاريعك.

### Azure AI Foundry
يمكنك نشر وتجربة نماذج Phi باستخدام [Azure AI Foundry](https://ai.azure.com)، الذي يوفر بيئة شاملة لبناء واختبار ونشر حلول الذكاء الاصطناعي بأقل إعداد.

### Foundry Local
للتطوير والنشر المحلي، يمكنك الاطلاع على [Microsoft Foundry Local](https://github.com/microsoft/foundry-local)، الذي يتيح لك تشغيل نماذج Phi على جهاز التطوير الخاص بك مع تكوينات محسّنة.

### موارد الوثائق
- [Microsoft Research: تقارير تقنية نماذج Phi](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## المقدمة

في هذه الدرس، سنستكشف عائلة نماذج Microsoft Phi ومفاهيمها الأساسية. سنغطي تطور عائلة Phi، منهجيات التدريب المبتكرة التي تجعل نماذج Phi فعالة، الأنواع الرئيسية في العائلة، والتطبيقات العملية عبر سيناريوهات مختلفة.

## أهداف التعلم

بنهاية هذا الدرس، ستكون قادرًا على:

- فهم فلسفة التصميم وتطور عائلة نماذج Microsoft Phi.
- التعرف على الابتكارات الرئيسية التي تمكن نماذج Phi من تحقيق أداء عالٍ مع عدد أقل من المعلمات.
- التعرف على فوائد وقيود الأنواع المختلفة من نماذج Phi.
- تطبيق المعرفة بنماذج Phi لاختيار الأنواع المناسبة لسيناريوهات العالم الحقيقي.

## فهم نموذج الذكاء الاصطناعي التقليدي

تقليديًا، كان تحقيق أداء عالٍ في معالجة اللغة الطبيعية يتطلب نماذج لغوية ضخمة تحتوي على مليارات أو مئات المليارات من المعلمات. عادةً ما تقوم المؤسسات بنشر هذه النماذج على مجموعات GPU قوية، وتصل إلى قدراتها من خلال واجهات API أو بنية تحتية مخصصة.

هذا النهج يعمل بشكل جيد للعديد من التطبيقات ولكنه يحتوي على قيود جوهرية عندما يتعلق الأمر بسيناريوهات النشر العملية. الطريقة التقليدية تتضمن استخدام نماذج تتطلب موارد حسابية كبيرة، كميات كبيرة من الذاكرة، واستهلاك كبير للطاقة. بينما يوفر هذا النهج الوصول إلى قدرات متقدمة، فإنه يخلق اعتمادًا على أجهزة باهظة الثمن، ويزيد من تكاليف التشغيل، ويحد من مرونة النشر.

## تحدي نشر الذكاء الاصطناعي بكفاءة

أصبح الحاجة إلى ذكاء اصطناعي أكثر كفاءة أمرًا بالغ الأهمية عبر سيناريوهات مختلفة. فكر في التطبيقات التي تتطلب النشر المحلي لأسباب الخصوصية، أو التطبيقات الحساسة للتكلفة حيث تصبح تكاليف API السحابية باهظة، أو سيناريوهات الحوسبة الطرفية ذات الموارد المحدودة، أو التطبيقات الفورية حيث تكون الاستجابة الفورية ضرورية.

### قيود النشر الرئيسية

تواجه عمليات نشر النماذج الكبيرة التقليدية عدة قيود أساسية تحد من قابليتها للتطبيق العملي:

- **قيود التكلفة**: التكاليف الحسابية العالية تجعل النشر المستمر مكلفًا للعديد من المؤسسات.
- **قيود الموارد**: الوصول المحدود إلى بنية GPU عالية الأداء يقيّد خيارات النشر.
- **متطلبات الخصوصية**: التطبيقات الحساسة تتطلب معالجة محلية للحفاظ على خصوصية البيانات.
- **حساسية التأخير**: التطبيقات الفورية تحتاج إلى استجابات فورية دون تأخير جولة السحابة.

## فلسفة نماذج Microsoft Phi

تمثل عائلة نماذج Microsoft Phi تحولًا أساسيًا في فلسفة تصميم نماذج الذكاء الاصطناعي، حيث تركز على الكفاءة والنشر العملي مع الحفاظ على خصائص الأداء القوية. تحقق نماذج Phi ذلك من خلال هياكل مبتكرة، منهجيات تدريب عالية الجودة، وتقنيات تحسين متخصصة.

تشمل عائلة Phi نهجًا مختلفًا مصممًا لتعظيم الأداء لكل معلمة، مما يتيح النشر على الأجهزة القياسية مع توفير قدرات ذكاء اصطناعي ذات مغزى. الهدف هو الحفاظ على أداء تنافسي مع تقليل المتطلبات الحسابية، استخدام الذاكرة، وتكاليف التشغيل بشكل كبير.

### مبادئ تصميم Phi الأساسية

تم بناء نماذج Phi على عدة مبادئ أساسية تميزها عن النماذج اللغوية الكبيرة التقليدية:

- **الكفاءة أولًا**: مصممة لتحقيق أقصى أداء لكل معلمة بدلاً من الحجم المطلق.
- **تدريب عالي الجودة**: التركيز على بيانات تدريب عالية الجودة ومنسقة بدلاً من مجموعات البيانات الضخمة.
- **مرونة النشر**: مصممة للعمل بفعالية على تكوينات الأجهزة المختلفة.
- **قدرات متخصصة**: غالبًا ما تكون محسّنة لمهام أو مجالات محددة لتحقيق أقصى فعالية.

## التقنيات الرئيسية التي تمكن عائلة Phi

### نهج التدريب "الكتاب المدرسي"

أحد الجوانب الثورية لعائلة Phi هو منهجية التدريب "جودة الكتاب المدرسي". بدلاً من التدريب على كميات ضخمة من بيانات الإنترنت غير المفلترة، تستخدم نماذج Phi محتوى تعليميًا عالي الجودة ومنسقًا مصممًا لتعليم التفكير، الرياضيات، البرمجة، والمعرفة العامة بشكل فعال.

### تدريب التفكير المتقدم

تتضمن نماذج Phi الحديثة منهجيات تدريب التفكير المتقدمة التي تمكن من حل المشكلات المعقدة متعددة الخطوات. تشمل هذه التقنيات:

**تدريب سلسلة التفكير**: تعلم النماذج كيفية تقسيم المشكلات المعقدة إلى خطوات تفكير وسيطة، مما يجعل عملية حل المشكلات أكثر شفافية وموثوقية.

**التوسع أثناء وقت الاستنتاج**: تولد النماذج سلاسل تفكير مفصلة تستفيد من موارد حسابية إضافية أثناء توليد الاستجابات لتحسين الدقة.

**تدريب حافة القدرات**: يتم اختيار بيانات التدريب خصيصًا لتحدي النموذج عند حافة قدراته الحالية، مما يعزز تعلم أنماط التفكير المعقدة.

### الابتكارات المعمارية

تتضمن عائلة Phi العديد من التحسينات المعمارية المصممة خصيصًا للكفاءة:

**كفاءة المعلمات**: اختيارات معمارية دقيقة تزيد من تأثير كل معلمة في النموذج.

**التكامل متعدد الوسائط**: دمج فعال لقدرات معالجة النصوص، الرؤية، والصوت داخل هياكل مدمجة.

**تحسين الأجهزة**: أنواع متخصصة محسّنة لمنصات الأجهزة المحددة وسيناريوهات النشر.

## تحسين الأجهزة لنماذج Phi

تستفيد بيئات النشر الحديثة من كفاءة نماذج Phi عبر تكوينات الأجهزة المختلفة:

### النشر المحسن للمعالجات

تم تصميم نماذج Phi للعمل بفعالية على الأجهزة التي تعتمد فقط على المعالجات، مما يجعلها متاحة للنشر على بنية الحوسبة القياسية دون الحاجة إلى مسرعات ذكاء اصطناعي متخصصة.

### تسريع GPU

على الرغم من عدم الحاجة إلى وحدات GPU قوية، يمكن لنماذج Phi الاستفادة من موارد GPU المتاحة لتحسين الأداء، مما يوفر مرونة في تكوينات النشر.

### التكامل مع الأجهزة الطرفية

تم تحسين أنواع متخصصة مثل Phi-3-Silica لمنصات الحوسبة الطرفية المحددة، مما يحقق مقاييس كفاءة مذهلة مثل 650 رمزًا في الثانية مع استهلاك طاقة يبلغ 1.5 واط فقط.

## فوائد عائلة نماذج Phi

### الكفاءة في التكلفة

تقلل نماذج Phi بشكل كبير من تكاليف التشغيل من خلال تقليل الحاجة إلى بنية تحتية حسابية كبيرة مع الحفاظ على أداء تنافسي. يجعل هذا الذكاء الاصطناعي متاحًا للمؤسسات ذات الميزانيات المحدودة أو التطبيقات ذات الحجم الكبير حيث تكون تكلفة الاستنتاج مهمة.

### مرونة النشر

تتيح كفاءة نماذج Phi النشر عبر مجموعة واسعة من تكوينات الأجهزة، من أجهزة الكمبيوتر المحمولة الشخصية إلى خوادم المؤسسات، مما يوفر للمؤسسات مرونة أكبر في خيارات البنية التحتية للذكاء الاصطناعي.

### الخصوصية والأمان

تتيح كفاءة نماذج Phi النشر المحلي للتطبيقات الحساسة للخصوصية، مما يضمن أن البيانات الحساسة لا تغادر سيطرة المؤسسة مع توفير قدرات ذكاء اصطناعي قوية.

### الأداء الفوري

تترجم المتطلبات الحسابية المنخفضة إلى أوقات استنتاج أسرع، مما يتيح التطبيقات الفورية التي تتطلب استجابات فورية دون المساومة على جودة قدرات الذكاء الاصطناعي.

### الذكاء الاصطناعي المتاح

من خلال تقليل الحواجز أمام نشر الذكاء الاصطناعي، تجعل نماذج Phi قدرات الذكاء الاصطناعي المتقدمة متاحة للمؤسسات ذات الموارد المحدودة، مما يمكن الفرق الصغيرة والمطورين الفرديين من الاستفادة من فهم اللغة المتقدم.

## أمثلة عملية وحالات استخدام

### مثال على التفكير الرياضي

Phi-4-mini-reasoning يتفوق في حل المشكلات الرياضية خطوة بخطوة. على سبيل المثال، عند سؤاله "كيف يمكن حل 3*x^2+4*x+5=1؟"، يقدم النموذج خطوات تفكير مفصلة:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### مثال على الدعم متعدد اللغات

Phi-3.5-mini-instruct يظهر قدرات متعددة اللغات قوية عبر لغات مختلفة. إليك مثال على تنسيق الطلب:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### مثال على القدرات متعددة الوسائط

Phi-4-multimodal يمكنه معالجة النصوص والصور والصوت في وقت واحد. إليك بعض التطبيقات العملية:

**تخطيط السفر باستخدام إدخال صوتي:**
شاهد كيف يحلل Phi-4 Multimodal اللغة المنطوقة للمساعدة في تخطيط رحلة إلى سياتل، مما يظهر قدراته المتقدمة في معالجة الصوت والتوصيات.

**حل المشكلات الرياضية من الصور:**
شاهد كيف يتعامل Phi-4 Multimodal مع المشكلات الرياضية المعقدة من خلال المدخلات البصرية، مما يظهر قدرته على معالجة وحل المعادلات المقدمة في الصور.

**مثال على استدعاء الوظائف:**
مع استدعاء الوظائف، يمكن لـ Phi-4-mini وPhi-4-multimodal توسيع قدرات معالجة النصوص من خلال دمج محركات البحث، وربط أدوات مختلفة، والمزيد. كما هو موضح، يمكن للنموذج استرداد معلومات مباريات الدوري الإنجليزي الممتاز عبر Phi-4-mini، مما يظهر قدرته على التفاعل مع مصادر البيانات الخارجية بسلاسة.

### مثال على توليد الكود

Phi-4-multimodal يمكنه توليد كود مشروع منظم بناءً على محتوى الصور والمطالبات المقدمة، كما هو موضح في سير العمل العملي:

1. تحميل صورة لهيكل أو تصميم
2. تقديم سياق حول متطلبات المشروع
3. يقوم النموذج بتوليد هياكل كود كاملة وظيفية
4. يمكن تخصيص الكود بناءً على أطر العمل أو اللغات المحددة

### مثال على النشر الطرفي

يمكننا نشر النموذج الكمي على الأجهزة الطرفية. من خلال الجمع بين Microsoft Olive وONNX GenAI Runtime، يمكننا نشر Phi-4-mini على Windows، iPhone، Android وأجهزة أخرى. هذا مثال يعمل على iPhone 12 Pro.

تشمل عملية النشر:
- تكميم النموذج لتحسينه على الأجهزة المحمولة
- تكامل ONNX runtime للتوافق عبر الأنظمة الأساسية
- الاستنتاج المحلي دون اتصال بالإنترنت
- الأداء الفوري مع استهلاك طاقة منخفض

## تطور عائلة Phi

### Phi-1 وPhi-2: نماذج الأساس

النماذج الأولى من Phi وضعت المبادئ الأساسية للبيانات التدريبية عالية الجودة والهياكل الفعالة:

- **Phi-1 (1.3 مليار معلمة)**: قدمت مفهوم البيانات التدريبية المنسقة لفهم اللغة الأساسي وتوليد الكود.
- **Phi-2 (2.7 مليار معلمة)**: عززت قدرات التفكير من خلال بيانات NLP الاصطناعية ومحتوى الويب المصفى بعناية.

### عائلة Phi-3: التبني السائد

سلسلة Phi-3 حققت تقدمًا كبيرًا في قدرات SLM مع العديد من الأنواع المتخصصة:

- **Phi-3-mini (3.8 مليار معلمة)**: مهام اللغة العامة بكفاءة استثنائية، تتفوق على نماذج ضعف حجمها.
- **Phi-3-small (7 مليار معلمة)**: أداء متقدم يتفوق على GPT-3.5 Turbo في معايير مختلفة.
- **Phi-3-medium (14 مليار معلمة)**: أداء على مستوى المؤسسات يتفوق على Gemini 1.0 Pro.
- **Phi-3-vision (4.2 مليار معلمة)**: قدرات متعددة الوسائط لمعالجة النصوص والصور.
- **Phi-3-Silica (3.3 مليار معلمة)**: تحسين متخصص للنشر المدمج في Windows 11.

### عائلة Phi-4: التفكير المتقدم

الجيل الأحدث يدفع حدود قدرات التفكير:

- **Phi-4 (14 مليار معلمة)**: تخصص في التفكير المعقد، خاصة في الرياضيات.
- **Phi-4-mini (3.8 مليار معلمة)**: تحسين التفكير مع استدعاء الوظائف ودعم السياق الطويل.
- **Phi-4-multimodal**: معالجة النصوص والرؤية والصوت في وقت واحد.
- **Phi-4-reasoning (14 مليار معلمة)**: متخصص في مهام التفكير المعقدة متعددة الخطوات.
- **Phi-4-reasoning-plus (14 مليار معلمة)**: تحسين الدقة من خلال التعلم المعزز الإضافي.
- **Phi-4-mini-reasoning (3.8 مليار معلمة)**: التفكير الرياضي محسّن للبيئات المقيدة.

## تطبيقات نماذج Phi

### التطبيقات المؤسسية

تستخدم المؤسسات نماذج Phi لتحليل المستندات، أتمتة خدمة العملاء، مساعدة توليد الكود، وتطبيقات ذكاء الأعمال التي تتطلب النشر المحلي للامتثال والأمان.

### الحوسبة المحمولة والطرفية

تستفيد التطبيقات المحمولة من نماذج Phi للترجمة الفورية، المساعدين الذكيين، توليد المحتوى، والتوصيات الشخصية دون الحاجة إلى اتصال دائم بالإنترنت.

### التكنولوجيا التعليمية

تستخدم المنصات التعليمية نماذج Phi للتدريس الشخصي، التقييم الآلي، توليد المحتوى، وتجارب التعلم التفاعلية التي يمكن أن تعمل دون اتصال أو في بيئات منخفضة الاتصال.

### الرعاية الصحية والامتثال

تستفيد تطبيقات الرعاية الصحية من قدرة نماذج Phi على معالجة البيانات الطبية الحساسة محليًا مع توفير المساعدة التشخيصية المدعومة بالذكاء الاصطناعي، مراقبة المرضى، وتوصيات العلاج.

## التحديات والقيود

### قيود المعرفة

على الرغم من كفاءتها، فإن نماذج Phi لديها قدرة معرفة واقعية أقل مقارنة بالنماذج الأكبر، مما قد يحد من فعاليتها في التطبيقات التي تتطلب خبرة واسعة في المجال.

### دعم اللغة

تم تحسين نماذج Phi بشكل أساسي للغة الإنجليزية، على الرغم من أن الأنواع الأحدث تشمل قدرات متعددة اللغات. قد تواجه التطبيقات التي تتطلب دعمًا واسعًا للغات غير الإنجليزية قيودًا.

### مهام التخطيط المعقدة

التخطيط متعدد الخطوات والمهام المعقدة التي تتطلب التفكير المطول قد تشكل تحديًا للنماذج الأصغر، على الرغم من أن الأنواع المتخصصة في التفكير تعالج العديد من هذه القيود.

### أداء المجال المتخصص

المجالات المتخصصة التي تتطلب معرفة واسعة بالمجال قد تستفيد من نماذج أكبر وأكثر تخصصًا بدلاً من SLMs العامة.

## مستقبل عائلة نماذج Phi

تمثل عائلة نماذج Phi بداية اتجاه أوسع نحو نشر الذكاء الاصطناعي بكفاءة وعملية. تشمل التطورات المستقبلية تحسين مقاييس الكفاءة، تعزيز القدرات متعددة الوسائط، أنواع متخصصة للصناعات المحددة، وتحسين التكامل مع بنية الحوسبة الطرفية.

مع استمرار تطور التكنولوجيا، يمكننا توقع أن تصبح نماذج Phi أكثر قدرة مع الحفاظ على مزايا الكفاءة الخاصة بها، مما يتيح نشر الذكاء الاصطناعي في سيناريوهات كانت مقيدة سابقًا بسبب المتطلبات الحسابية.
تُظهر عائلة Phi أن مستقبل نشر الذكاء الاصطناعي لا يكمن فقط في بناء نماذج أكبر، بل في بناء نماذج أكثر ذكاءً وكفاءةً يمكنها العمل بفعالية عبر بيئات أجهزة متنوعة مع الحفاظ على معايير أداء عالية.

## أمثلة على التطوير والتكامل

### البداية السريعة مع Transformers

إليك كيفية البدء مع نماذج Phi باستخدام مكتبة Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### مثال على التخصيص

المثال التالي يوضح كيفية تخصيص Phi-4-mini-instruct لمهام محددة:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### تنسيقات مخصصة للمطالبات

**للمهام الاستدلالية (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**للمهام الرياضية (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### النشر على الأجهزة المحمولة باستخدام ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## معايير الأداء والإنجازات

حققت عائلة نماذج Phi أداءً مذهلاً عبر معايير مختلفة، وغالبًا ما تفوقت على نماذج أكبر بكثير:

### أبرز الإنجازات في الأداء

**التفوق في الاستدلال الرياضي:**
- Phi-4 تحقق دقة بنسبة 82.5% في AIME 2025 (تصفيات أولمبياد الرياضيات)
- Phi-4-reasoning (14B) تتفوق على DeepSeek-R1-Distill-70B (أكبر بخمس مرات) في معايير الاستدلال
- Phi-4-mini-reasoning (3.8B) تنافس نماذج ضعف حجمها في مهام الاستدلال الرياضي

**إنجازات الكفاءة:**
- Phi-3-Silica تحقق 650 رمزًا في الثانية مع استهلاك طاقة يبلغ 1.5 واط فقط
- Phi-4-mini (3.8B) تحقق أداءً مشابهًا لنماذج أكبر بكثير

**أداء المعايير:**
- **MMLU (فهم اللغة متعدد المهام)**: أداء تنافسي عبر 57 موضوعًا أكاديميًا
- **HumanEval**: قدرات قوية في توليد الأكواد، خاصةً في Python
- **MGSM**: حل مسائل الرياضيات المدرسية متعددة اللغات
- **DROP**: مهام الفهم والاستدلال المعقدة
- **SimpleQA**: دقة في الردود الواقعية

### 📊 مصفوفة مقارنة النماذج

| النموذج | المعلمات | طول السياق | نقاط القوة الرئيسية | أفضل حالات الاستخدام |
|---------|----------|------------|---------------------|-----------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | الكفاءة العامة | التطبيقات المحمولة، روبوتات الدردشة الأساسية |
| **Phi-3.5-mini** | 3.8B | 128K | دعم متعدد اللغات | التطبيقات الدولية |
| **Phi-4-mini** | 3.8B | 128K | استدلال معزز، استدعاء الوظائف | أتمتة الأعمال |
| **Phi-4-mini-reasoning** | 3.8B | 128K | استدلال رياضي | المنصات التعليمية |
| **Phi-4** | 14B | 32K | استدلال معقد | البحث، التحليل المتقدم |
| **Phi-4-reasoning** | 14B | 32K/64K | استدلال متعدد الخطوات | الحوسبة العلمية |
| **Phi-4-reasoning-plus** | 14B | 32K | دقة استدلال قصوى | اتخاذ القرارات الحرجة |
| **Phi-4-multimodal** | 5.6B | متغير | الصوت، الرؤية، النص | التطبيقات متعددة الوسائط |

## دليل اختيار النموذج

### للتطبيقات الأساسية
- **Phi-3-mini**: توليد النصوص البسيطة، الأسئلة والأجوبة الأساسية، الردود السريعة
- **Phi-4-mini**: استدلال معزز مع قدرات استدعاء الوظائف

### للمهام الرياضية والاستدلالية
- **Phi-4**: حل المشكلات الرياضية المعقدة والاستدلال
- **Phi-4-reasoning**: استدلال متعدد الخطوات مع تفسيرات مفصلة
- **Phi-4-reasoning-plus**: دقة قصوى لتطبيقات الاستدلال الحرجة
- **Phi-4-mini-reasoning**: استدلال رياضي فعال للبيئات ذات الموارد المحدودة

### للتطبيقات متعددة الوسائط
- **Phi-3-vision**: معالجة الصور والنصوص معًا
- **Phi-4-multimodal**: قدرات شاملة للصوت والرؤية والنصوص

### للنشر المؤسسي
- **Phi-3-medium**: فهم لغوي متقدم لتطبيقات الأعمال
- **Phi-3-Silica**: مُحسّن لمنصات الأجهزة المحددة

## منصات النشر وإمكانية الوصول

### منصات السحابة
- **Azure AI Foundry**: نشر كامل الميزات مع أدوات المؤسسات
- **Hugging Face**: مستودع نماذج مفتوح المصدر وموارد المجتمع
- **NVIDIA API Catalog**: خيارات نشر الخدمات المصغرة

### أطر التطوير المحلية
- **Ollama**: إطار عمل خفيف للنشر المحلي للنماذج
- **ONNX Runtime**: مُحسّن لتكوينات الأجهزة المختلفة  
- **DirectML**: أداء مُحسّن لنظام Windows
- **llama.cpp**: محرك استنتاج متعدد المنصات

### موارد التعلم
- **Phi Portal**: مركز وثائق Microsoft Phi الرسمي
- **Phi Cookbook**: أمثلة ودروس شاملة
- **التقارير التقنية**: أوراق بحثية متعمقة على arxiv
- **مساحات المجتمع**: عروض تفاعلية على Hugging Face

### البدء مع نماذج Phi

#### منصات التطوير
1. **Azure AI Foundry**: واجهة سطر أوامر محلية بسيطة وإدارة النماذج.
2. **Hugging Face Transformers**: تجربة محلية سريعة
3. **Ollama**: نشر محلي بسيط للاختبار

#### مسار التعلم
1. **فهم المفاهيم الأساسية**: دراسة مبادئ التصميم الأساسية
2. **تجربة المتغيرات**: تجربة نماذج Phi المختلفة لفهم القدرات
3. **ممارسة التنفيذ**: نشر النماذج في بيئات الاختبار
4. **توسيع النشر**: التوسع التدريجي بناءً على التجارب الناجحة

#### أفضل الممارسات
- **ابدأ صغيرًا**: ابدأ بنماذج Phi-mini للتطوير الأولي
- **تحسين المطالبات**: استخدم تنسيقات الدردشة المناسبة للحصول على أفضل النتائج
- **مراقبة الأداء**: تتبع سرعة الاستنتاج ومقاييس الدقة
- **مراعاة الأجهزة**: مطابقة حجم النموذج مع الموارد الحاسوبية المتاحة

## الخاتمة

تمثل عائلة نماذج Microsoft Phi نهجًا ثوريًا في تصميم نماذج الذكاء الاصطناعي، حيث تُظهر أن النماذج الأصغر والأكثر كفاءة يمكنها تحقيق أداء مذهل عبر مهام متنوعة. من خلال التركيز على بيانات تدريب عالية الجودة وتحسينات معمارية، تقدم عائلة Phi قدرات استثنائية مع متطلبات حسابية أقل بكثير مقارنةً بالنماذج التقليدية الكبيرة.

## أهداف التعلم الرئيسية

1. فهم فلسفة التصميم وتطور عائلة نماذج Microsoft Phi من Phi-1 إلى Phi-4
2. تحديد الابتكارات الرئيسية، بما في ذلك تدريب "بجودة الكتب الدراسية" والتحسينات المعمارية
3. التعرف على فوائد وقيود المتغيرات المختلفة لعائلة Phi عبر سيناريوهات النشر المختلفة
4. تطبيق المعرفة لاختيار نماذج Phi المناسبة لحالات الاستخدام والقيود الحاسوبية
5. تنفيذ تقنيات تحسين لنشر نماذج Phi على الأجهزة ذات الموارد المحدودة
6. شرح المزايا المعمارية لعائلة نماذج Phi مقارنةً بالنماذج التقليدية الكبيرة
7. اختيار المتغير المناسب من Phi بناءً على متطلبات التطبيق والقيود الحاسوبية
8. تنفيذ نماذج Phi في سيناريوهات النشر السحابية والطرفية مع تكوينات مُحسّنة
9. تطبيق تقنيات التكميم والتحسين لتحسين أداء نماذج Phi على الأجهزة المستهدفة
10. تقييم التوازن بين حجم النموذج والأداء والقدرات عبر عائلة Phi

## ما التالي

- [02: أساسيات عائلة Qwen](02.QwenFamily.md)

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الرسمي. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.