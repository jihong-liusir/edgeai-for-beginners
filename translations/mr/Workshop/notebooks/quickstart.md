<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T09:51:25+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "mr"
}
-->
# рд╡рд░реНрдХрд╢реЙрдк рдиреЛрдЯрдмреБрдХреНрд╕ - рдЬрд▓рдж рдкреНрд░рд╛рд░рдВрдн рдорд╛рд░реНрдЧрджрд░реНрд╢рд┐рдХрд╛

## рд╡рд┐рд╖рдп рд╕реВрдЪреА

- [рдкреВрд░реНрд╡рддрдпрд╛рд░реА](../../../../Workshop/notebooks)
- [рдкреНрд░рд╛рд░рдВрднрд┐рдХ рд╕реЗрдЯрдЕрдк](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ 04: рдореЙрдбреЗрд▓ рддреБрд▓рдирд╛](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ 05: рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрдЯрд░](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ 06: рд╣реЗрддреВрдиреБрд╕рд╛рд░ рдореЙрдбреЗрд▓ рд░реВрдЯрд┐рдВрдЧ](../../../../Workshop/notebooks)
- [рдкрд░реНрдпрд╛рд╡рд░рдгреАрдп рд╡реНрд╣реЗрд░рд┐рдПрдмрд▓реНрд╕](../../../../Workshop/notebooks)
- [рд╕рд╛рдорд╛рдиреНрдп рдХрдорд╛рдВрдбреНрд╕](../../../../Workshop/notebooks)

---

## рдкреВрд░реНрд╡рддрдпрд╛рд░реА

### 1. рдлрд╛рдЙрдВрдбреНрд░реА рд▓реЛрдХрд▓ рд╕реНрдерд╛рдкрд┐рдд рдХрд░рд╛

**Windows:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**рд╕реНрдерд╛рдкрдирд╛ рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░рд╛:**
```bash
foundry --version
```

### 2. Python рдбрд┐рдкреЗрдВрдбрдиреНрд╕реА рд╕реНрдерд╛рдкрд┐рдд рдХрд░рд╛

```bash
cd Workshop
pip install -r requirements.txt
```

рдХрд┐рдВрд╡рд╛ рд╕реНрд╡рддрдВрддреНрд░рдкрдгреЗ рд╕реНрдерд╛рдкрд┐рдд рдХрд░рд╛:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## рдкреНрд░рд╛рд░рдВрднрд┐рдХ рд╕реЗрдЯрдЕрдк

### рдлрд╛рдЙрдВрдбреНрд░реА рд▓реЛрдХрд▓ рд╕реЗрд╡рд╛ рд╕реБрд░реВ рдХрд░рд╛

**рдХреЛрдгрддреНрдпрд╛рд╣реА рдиреЛрдЯрдмреБрдХ рдЪрд╛рд▓рд╡рдгреНрдпрд╛рдкреВрд░реНрд╡реА рдЖрд╡рд╢реНрдпрдХ:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ:
```
тЬЕ Service started successfully
Endpoint: http://localhost:59959
```

### рдореЙрдбреЗрд▓реНрд╕ рдбрд╛рдЙрдирд▓реЛрдб рдЖрдгрд┐ рд▓реЛрдб рдХрд░рд╛

рдиреЛрдЯрдмреБрдХреНрд╕ рдЦрд╛рд▓реАрд▓ рдореЙрдбреЗрд▓реНрд╕ рд╡рд╛рдкрд░рддрд╛рдд:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### рд╕реЗрдЯрдЕрдк рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░рд╛

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## рд╕рддреНрд░ 04: рдореЙрдбреЗрд▓ рддреБрд▓рдирд╛

### рдЙрджреНрджреЗрд╢
рд▓рд╣рд╛рди рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕ (SLM) рдЖрдгрд┐ рдореЛрдареНрдпрд╛ рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕ (LLM) рдпрд╛рдВрдЪреНрдпрд╛рддреАрд▓ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рддреБрд▓рдирд╛ рдХрд░рд╛.

### рдЬрд▓рдж рд╕реЗрдЯрдЕрдк

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### рдиреЛрдЯрдмреБрдХ рдЪрд╛рд▓рд╡рдгреЗ

1. **рдЙрдШрдбрд╛** `session04_model_compare.ipynb` VS Code рдХрд┐рдВрд╡рд╛ Jupyter рдордзреНрдпреЗ
2. **рдХрд░реНрдирд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░рд╛** (Kernel тЖТ Restart Kernel)
3. **рд╕рд░реНрд╡ рд╕реЗрд▓реНрд╕ рдЪрд╛рд▓рд╡рд╛** рдХреНрд░рдорд╛рдиреЗ

### рдореБрдЦреНрдп рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди

**рдбрд┐рдлреЙрд▓реНрдЯ рдореЙрдбреЗрд▓реНрд╕:**
- **SLM:** `phi-4-mini` (~4GB RAM, рдЬрд▓рдж)
- **LLM:** `qwen2.5-3b` (~3GB RAM, рдореЗрдорд░реА-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭреНрдб)

**рдкрд░реНрдпрд╛рд╡рд░рдгреАрдп рд╡реНрд╣реЗрд░рд┐рдПрдмрд▓реНрд╕ (рдкрд░реНрдпрд╛рдпреА):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

ЁЯТб SLM is 1.99x faster than LLM for this prompt
```

### рд╕рд╛рдиреБрдХреВрд▓рди

**рд╡реЗрдЧрд│реЗ рдореЙрдбреЗрд▓реНрд╕ рд╡рд╛рдкрд░рд╛:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**рд╕рд╛рдиреБрдХреВрд▓ рдкреНрд░реЙрдореНрдкреНрдЯ:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### рд╕рддреНрдпрд╛рдкрди рдЪреЗрдХрд▓рд┐рд╕реНрдЯ

- [ ] рд╕реЗрд▓ 12 рдпреЛрдЧреНрдп рдореЙрдбреЗрд▓реНрд╕ рджрд░реНрд╢рд╡рддреЗ (phi-4-mini, qwen2.5-3b)
- [ ] рд╕реЗрд▓ 12 рдпреЛрдЧреНрдп рдПрдВрдбрдкреЙрдЗрдВрдЯ рджрд░реНрд╢рд╡рддреЗ (рдкреЛрд░реНрдЯ 59959)
- [ ] рд╕реЗрд▓ 16 рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рдкрд╛рд╕ рд╣реЛрддреЗ (тЬЕ рд╕реЗрд╡рд╛ рдЪрд╛рд▓реВ рдЖрд╣реЗ)
- [ ] рд╕реЗрд▓ 20 рдкреНрд░реА-рдлреНрд▓рд╛рдЗрдЯ рдЪреЗрдХ рдкрд╛рд╕ рд╣реЛрддреЗ (рджреЛрдиреНрд╣реА рдореЙрдбреЗрд▓реНрд╕ рдареАрдХ)
- [ ] рд╕реЗрд▓ 22 рддреБрд▓рдирд╛ рдкреВрд░реНрдг рд╣реЛрддреЗ рд▓реЗрдЯрдиреНрд╕реА рд╡реНрд╣реЕрд▓реНрдпреВрд╕рд╕рд╣
- [ ] рд╕реЗрд▓ 24 рд╕рддреНрдпрд╛рдкрди рджрд░реНрд╢рд╡рддреЗ ЁЯОЙ рд╕рд░реНрд╡ рдЪреЗрдХреНрд╕ рдкрд╛рд╕ рдЭрд╛рд▓реЗ!

### рд╡реЗрд│ рдЕрдВрджрд╛рдЬ
- **рдкрд╣рд┐рд▓рд╛ рд░рди:** 5-10 рдорд┐рдирд┐рдЯреЗ (рдореЙрдбреЗрд▓ рдбрд╛рдЙрдирд▓реЛрдбрд╕рд╣)
- **рдкреБрдвреАрд▓ рд░рди:** 1-2 рдорд┐рдирд┐рдЯреЗ

---

## рд╕рддреНрд░ 05: рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрдЯрд░

### рдЙрджреНрджреЗрд╢
рдлрд╛рдЙрдВрдбреНрд░реА рд▓реЛрдХрд▓ SDK рд╡рд╛рдкрд░реВрди рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рд╕рд╣рдХрд╛рд░реНрдпрд╛рдЪреЗ рдкреНрд░рджрд░реНрд╢рди - рдПрдЬрдВрдЯреНрд╕ рдПрдХрддреНрд░рд┐рддрдкрдгреЗ рдкрд░рд┐рд╖реНрдХреГрдд рдЖрдЙрдЯрдкреБрдЯ рддрдпрд╛рд░ рдХрд░рддрд╛рдд.

### рдЬрд▓рдж рд╕реЗрдЯрдЕрдк

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### рдиреЛрдЯрдмреБрдХ рдЪрд╛рд▓рд╡рдгреЗ

1. **рдЙрдШрдбрд╛** `session05_agents_orchestrator.ipynb`
2. **рдХрд░реНрдирд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░рд╛**
3. **рд╕рд░реНрд╡ рд╕реЗрд▓реНрд╕ рдЪрд╛рд▓рд╡рд╛** рдХреНрд░рдорд╛рдиреЗ

### рдореБрдЦреНрдп рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди

**рдбрд┐рдлреЙрд▓реНрдЯ рд╕реЗрдЯрдЕрдк (рджреЛрдиреНрд╣реА рдПрдЬрдВрдЯреНрд╕рд╕рд╛рдареА рд╕рдорд╛рди рдореЙрдбреЗрд▓):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**рдкреНрд░рдЧрдд рд╕реЗрдЯрдЕрдк (рд╡реЗрдЧрд│реЗ рдореЙрдбреЗрд▓реНрд╕):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░

```
User Question
    тЖУ
Researcher Agent (phi-4-mini)
  тЖТ Gathers bullet points
    тЖУ
Editor Agent (phi-4-mini or qwen2.5-7b)
  тЖТ Refines into executive summary
    тЖУ
Final Output
```

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: тАв Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### рд╡рд┐рд╕реНрддрд╛рд░

**рдЕрдзрд┐рдХ рдПрдЬрдВрдЯреНрд╕ рдЬреЛрдбрд╛:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**рдмреЕрдЪ рдЯреЗрд╕реНрдЯрд┐рдВрдЧ:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### рд╡реЗрд│ рдЕрдВрджрд╛рдЬ
- **рдкрд╣рд┐рд▓рд╛ рд░рди:** 3-5 рдорд┐рдирд┐рдЯреЗ
- **рдкреБрдвреАрд▓ рд░рди:** рдкреНрд░рддрд┐ рдкреНрд░рд╢реНрди 1-2 рдорд┐рдирд┐рдЯреЗ

---

## рд╕рддреНрд░ 06: рд╣реЗрддреВрдиреБрд╕рд╛рд░ рдореЙрдбреЗрд▓ рд░реВрдЯрд┐рдВрдЧ

### рдЙрджреНрджреЗрд╢
рдЖрдврд│рд▓реЗрд▓реНрдпрд╛ рд╣реЗрддреВрдиреБрд╕рд╛рд░ рдкреНрд░реЙрдореНрдкреНрдЯреНрд╕ рд╡рд┐рд╢реЗрд╖ рдореЙрдбреЗрд▓реНрд╕рдХрдбреЗ рдмреБрджреНрдзрд┐рдорддреНрддреЗрдиреЗ рд░реВрдЯ рдХрд░рд╛.

### рдЬрд▓рдж рд╕реЗрдЯрдЕрдк

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**рдЯреАрдк:** рд╕рддреНрд░ 06 CPU рдореЙрдбреЗрд▓реНрд╕рд╡рд░ рдбрд┐рдлреЙрд▓реНрдЯ рдЖрд╣реЗ рдЬрд╛рд╕реНрддреАрдд рдЬрд╛рд╕реНрдд рд╕реБрд╕рдВрдЧрддрддреЗрд╕рд╛рдареА.

### рдиреЛрдЯрдмреБрдХ рдЪрд╛рд▓рд╡рдгреЗ

1. **рдЙрдШрдбрд╛** `session06_models_router.ipynb`
2. **рдХрд░реНрдирд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░рд╛**
3. **рд╕рд░реНрд╡ рд╕реЗрд▓реНрд╕ рдЪрд╛рд▓рд╡рд╛** рдХреНрд░рдорд╛рдиреЗ

### рдореБрдЦреНрдп рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди

**рдбрд┐рдлреЙрд▓реНрдЯ рдХреЕрдЯрд▓реЙрдЧ (CPU рдореЙрдбреЗрд▓реНрд╕):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**рдкрд░реНрдпрд╛рдпреА (GPU рдореЙрдбреЗрд▓реНрд╕):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### рд╣реЗрддреВ рдУрд│рдЦ

рд░рд╛рдЙрдЯрд░ рд╣реЗрддреВ рдУрд│рдЦрдгреНрдпрд╛рд╕рд╛рдареА regex рдкреЕрдЯрд░реНрдиреНрд╕ рд╡рд╛рдкрд░рддреЛ:

| рд╣реЗрддреВ | рдкреЕрдЯрд░реНрди рдЙрджрд╛рд╣рд░рдгреЗ | рд░реВрдЯреЗрдб рдЯреВ |
|------|-----------------|----------|
| `code` | "refactor", "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize", "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize", "tl;dr" | phi-4-mini-cpu |
| `general` | рдмрд╛рдХреА рд╕рд░реНрд╡ | phi-4-mini-cpu |

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
тЬУ Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

тЬУ Success! All prompts routed correctly.
```

### рд╕рд╛рдиреБрдХреВрд▓рди

**рд╕рд╛рдиреБрдХреВрд▓ рд╣реЗрддреВ рдЬреЛрдбрд╛:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ч┐╗шпС', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**рдЯреЛрдХрди рдЯреНрд░реЕрдХрд┐рдВрдЧ рд╕рдХреНрд╖рдо рдХрд░рд╛:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### GPU рдореЙрдбреЗрд▓реНрд╕рд╡рд░ рд╕реНрд╡рд┐рдЪ рдХрд░рдгреЗ

рдЬрд░ рддреБрдордЪреНрдпрд╛рдХрдбреЗ 8GB+ VRAM рдЕрд╕реЗрд▓:

1. **Cell #6** рдордзреНрдпреЗ CPU рдХреЕрдЯрд▓реЙрдЧ рдХреЙрдореЗрдВрдЯ рдХрд░рд╛
2. GPU рдХреЕрдЯрд▓реЙрдЧ рдЕрдирдХреЙрдореЗрдВрдЯ рдХрд░рд╛
3. GPU рдореЙрдбреЗрд▓реНрд╕ рд▓реЛрдб рдХрд░рд╛:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. рдХрд░реНрдирд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░рд╛ рдЖрдгрд┐ рдиреЛрдЯрдмреБрдХ рдкреБрдиреНрд╣рд╛ рдЪрд╛рд▓рд╡рд╛

### рд╡реЗрд│ рдЕрдВрджрд╛рдЬ
- **рдкрд╣рд┐рд▓рд╛ рд░рди:** 5-10 рдорд┐рдирд┐рдЯреЗ (рдореЙрдбреЗрд▓ рд▓реЛрдбрд┐рдВрдЧ)
- **рдкреБрдвреАрд▓ рд░рди:** рдкреНрд░рддрд┐ рдЪрд╛рдЪрдгреА 30-60 рд╕реЗрдХрдВрдж

---

## рдкрд░реНрдпрд╛рд╡рд░рдгреАрдп рд╡реНрд╣реЗрд░рд┐рдПрдмрд▓реНрд╕

### рдЧреНрд▓реЛрдмрд▓ рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди

Jupyter/VS Code рд╕реБрд░реВ рдХрд░рдгреНрдпрд╛рдкреВрд░реНрд╡реА рд╕реЗрдЯ рдХрд░рд╛:

**Windows (Command Prompt):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**Windows (PowerShell):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### рдиреЛрдЯрдмреБрдХрдордзреАрд▓ рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди

рдХреЛрдгрддреНрдпрд╛рд╣реА рдиреЛрдЯрдмреБрдХрдЪреНрдпрд╛ рд╕реБрд░реБрд╡рд╛рддреАрд▓рд╛ рд╕реЗрдЯ рдХрд░рд╛:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## рд╕рд╛рдорд╛рдиреНрдп рдХрдорд╛рдВрдбреНрд╕

### рд╕реЗрд╡рд╛ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### рдореЙрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### рдПрдВрдбрдкреЙрдЗрдВрдЯреНрд╕ рдЪрд╛рдЪрдгреА

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рдХрдорд╛рдВрдбреНрд╕

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## рд╕рд░реНрд╡реЛрддреНрддрдо рдкрджреНрдзрддреА

### рдХреЛрдгрддреЗрд╣реА рдиреЛрдЯрдмреБрдХ рд╕реБрд░реВ рдХрд░рдгреНрдпрд╛рдкреВрд░реНрд╡реА

1. **рд╕реЗрд╡рд╛ рдЪрд╛рд▓реВ рдЖрд╣реЗ рдХрд╛ рддреЗ рддрдкрд╛рд╕рд╛:**
   ```bash
   foundry service status
   ```

2. **рдореЙрдбреЗрд▓реНрд╕ рд▓реЛрдб рдЭрд╛рд▓реЗ рдЖрд╣реЗрдд рдХрд╛ рддреЗ рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░рд╛:**
   ```bash
   foundry model ls
   ```

3. **рдиреЛрдЯрдмреБрдХ рдХрд░реНрдирд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░рд╛** рдЬрд░ рдкреБрдиреНрд╣рд╛ рдЪрд╛рд▓рд╡рдд рдЕрд╕рд╛рд▓

4. **рд╕рд░реНрд╡ рдЖрдЙрдЯрдкреБрдЯ рдХреНрд▓рд┐рдЕрд░ рдХрд░рд╛** рд╕реНрд╡рдЪреНрдЫ рд░рдирд╕рд╛рдареА

### рд╕рдВрд╕рд╛рдзрди рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

1. **рдбрд┐рдлреЙрд▓реНрдЯрдиреЗ CPU рдореЙрдбреЗрд▓реНрд╕ рд╡рд╛рдкрд░рд╛** рд╕реБрд╕рдВрдЧрддрддреЗрд╕рд╛рдареА
2. **GPU рдореЙрдбреЗрд▓реНрд╕рд╡рд░ рд╕реНрд╡рд┐рдЪ рдХрд░рд╛** рдлрдХреНрдд 8GB+ VRAM рдЕрд╕рд▓реНрдпрд╛рд╕
3. **рдЗрддрд░ GPU рдЕреЕрдкреНрд▓рд┐рдХреЗрд╢рдиреНрд╕ рдмрдВрдж рдХрд░рд╛** рдЪрд╛рд▓рд╡рдгреНрдпрд╛рдкреВрд░реНрд╡реА
4. **рд╕реЗрд╡рд╛ рдЪрд╛рд▓реВ рдареЗрд╡рд╛** рдиреЛрдЯрдмреБрдХ рд╕рддреНрд░рд╛рдВрджрд░рдореНрдпрд╛рди
5. **рд╕рдВрд╕рд╛рдзрди рд╡рд╛рдкрд░ рдореЙрдирд┐рдЯрд░ рдХрд░рд╛** Task Manager / nvidia-smi рд╕рд╣

### рд╕рдорд╕реНрдпрд╛ рдирд┐рд╡рд╛рд░рдг

1. **рдХреЛрдб рдбреАрдмрдЧ рдХрд░рдгреНрдпрд╛рдкреВрд░реНрд╡реА рдиреЗрд╣рдореА рд╕реЗрд╡рд╛ рддрдкрд╛рд╕рд╛**
2. **рдХрд░реНрдирд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░рд╛** рдЬрд░ рдЬреБрдиреНрдпрд╛ рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди рджрд┐рд╕рдд рдЕрд╕реЗрд▓
3. **рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рд╕реЗрд▓реНрд╕ рдкреБрдиреНрд╣рд╛ рдЪрд╛рд▓рд╡рд╛** рдХреЛрдгрддреНрдпрд╛рд╣реА рдмрджрд▓рд╛рдирдВрддрд░
4. **рдореЙрдбреЗрд▓ рдирд╛рд╡реЗ рддрдкрд╛рд╕рд╛** рд▓реЛрдб рдХреЗрд▓реЗрд▓реНрдпрд╛ рдореЙрдбреЗрд▓реНрд╕рд╢реА рдЬреБрд│рддрд╛рдд рдХрд╛
5. **рдПрдВрдбрдкреЙрдЗрдВрдЯ рдкреЛрд░реНрдЯ рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░рд╛** рд╕реЗрд╡рд╛ рд╕реНрдерд┐рддреАрд╢реА рдЬреБрд│рддреЗ рдХрд╛

---

## рдЬрд▓рдж рд╕рдВрджрд░реНрдн: рдореЙрдбреЗрд▓ рдЙрдкрдирд╛рдо

### рд╕рд╛рдорд╛рдиреНрдп рдореЙрдбреЗрд▓реНрд╕

| рдЙрдкрдирд╛рдо | рдЖрдХрд╛рд░ | рд╕рд░реНрд╡реЛрддреНрддрдо рдЙрдкрдпреЛрдЧ | RAM/VRAM | рдкреНрд░рдХрд╛рд░ |
|-------|------|----------------|----------|-------|
| `phi-4-mini` | ~4B | рд╕рд╛рдорд╛рдиреНрдп рдЪреЕрдЯ, рд╕рд╛рд░рд╛рдВрд╢ | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | рдХреЛрдб рдЬрдирд░реЗрд╢рди, рд░реАрдлреЕрдХреНрдЯрд░рд┐рдВрдЧ | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | рд╕рд╛рдорд╛рдиреНрдп рдХрд╛рд░реНрдп, рдХрд╛рд░реНрдпрдХреНрд╖рдо | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | рдЬрд▓рдж, рдХрдореА рд╕рдВрд╕рд╛рдзрди | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | рд╡рд░реНрдЧреАрдХрд░рдг, рдХрд┐рдорд╛рди рд╕рдВрд╕рд╛рдзрди | 1-2GB | `-cpu`, `-cuda-gpu` |

### рдкреНрд░рдХрд╛рд░ рдирд╛рдордХрд░рдг

- **рдореВрд▓ рдирд╛рд╡** (рдЙрджрд╛., `phi-4-mini`): рддреБрдордЪреНрдпрд╛ рд╣рд╛рд░реНрдбрд╡реЗрдЕрд░рд╕рд╛рдареА рд╕рд░реНрд╡реЛрддреНрддрдо рдкреНрд░рдХрд╛рд░ рдЖрдкреЛрдЖрдк рдирд┐рд╡рдбрддреЗ
- **`-cpu`**: CPU-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭреНрдб, рд╕рд░реНрд╡рддреНрд░ рдХрд╛рд░реНрдп рдХрд░рддреЗ
- **`-cuda-gpu`**: NVIDIA GPU рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭреНрдб, 8GB+ VRAM рдЖрд╡рд╢реНрдпрдХ
- **`-npu`**: Qualcomm NPU рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭреНрдб, NPU рдбреНрд░рд╛рдпрд╡реНрд╣рд░реНрд╕ рдЖрд╡рд╢реНрдпрдХ

**рд╢рд┐рдлрд╛рд░рд╕:** рдореВрд▓ рдирд╛рд╡реЗ (рд╢реЗрд╡рдЯрдЪрд╛ рдкреНрд░рддреНрдпрдп рди рд▓рд╛рд╡рддрд╛) рд╡рд╛рдкрд░рд╛ рдЖрдгрд┐ рдлрд╛рдЙрдВрдбреНрд░реА рд▓реЛрдХрд▓ рд╕рд░реНрд╡реЛрддреНрддрдо рдкреНрд░рдХрд╛рд░ рдЖрдкреЛрдЖрдк рдирд┐рд╡рдбреВ рджреЗ.

---

## рдпрд╢рд╛рдЪреЗ рд╕рдВрдХреЗрдд

рддреБрдореНрд╣реА рддрдпрд╛рд░ рдЖрд╣рд╛рдд рдЬреЗрд╡реНрд╣рд╛ рддреБрдореНрд╣рд╛рд▓рд╛ рджрд┐рд╕рддреЗ:

тЬЕ `foundry service status` "running" рджрд░реНрд╢рд╡рддреЗ  
тЬЕ `foundry model ls` рддреБрдордЪреНрдпрд╛рд╕рд╛рдареА рдЖрд╡рд╢реНрдпрдХ рдореЙрдбреЗрд▓реНрд╕ рджрд░реНрд╢рд╡рддреЗ  
тЬЕ рд╕реЗрд╡рд╛ рдпреЛрдЧреНрдп рдПрдВрдбрдкреЙрдЗрдВрдЯрд╡рд░ рдкреНрд░рд╡реЗрд╢рдпреЛрдЧреНрдп рдЖрд╣реЗ  
тЬЕ рд╣реЗрд▓реНрде рдЪреЗрдХ 200 OK рдкрд░рдд рдХрд░рддреЗ  
тЬЕ рдиреЛрдЯрдмреБрдХ рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рд╕реЗрд▓реНрд╕ рдкрд╛рд╕ рд╣реЛрддрд╛рдд  
тЬЕ рдЖрдЙрдЯрдкреБрдЯрдордзреНрдпреЗ рдХреЛрдгрддреАрд╣реА рдХрдиреЗрдХреНрд╢рди рддреНрд░реБрдЯреА рдирд╛рд╣реА  

---

## рдорджрдд рдорд┐рд│рд╡рд╛

### рджрд╕реНрддрдРрд╡рдЬреАрдХрд░рдг
- **рдореБрдЦреНрдп рд░рд┐рдкреЙрдЭрд┐рдЯрд░реА:** https://github.com/microsoft/Foundry-Local  
- **Python SDK:** https://github.com/microsoft/Foundry-Local/tree/main/sdk/python  
- **CLI рд╕рдВрджрд░реНрдн:** https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md  
- **рд╕рдорд╕реНрдпрд╛ рдирд┐рд╡рд╛рд░рдг:** рдпрд╛ рдбрд┐рд░реЗрдХреНрдЯрд░реАрддреАрд▓ `troubleshooting.md` рдкрд╣рд╛  

### GitHub рд╕рдорд╕реНрдпрд╛
- https://github.com/microsoft/Foundry-Local/issues  
- https://github.com/microsoft/edgeai-for-beginners/issues  

---

**рд╢реЗрд╡рдЯрдЪреЗ рдЕрджреНрдпрддрди:** 8 рдСрдХреНрдЯреЛрдмрд░, 2025  
**рдЖрд╡реГрддреНрддреА:** рд╡рд░реНрдХрд╢реЙрдк рдиреЛрдЯрдмреБрдХреНрд╕ 2.0  

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рд╣рд╛ рджрд╕реНрддрдРрд╡рдЬ [Co-op Translator](https://github.com/Azure/co-op-translator) рдпрд╛ рдПрдЖрдп рднрд╛рд╖рд╛рдВрддрд░ рд╕реЗрд╡реЗрдЪрд╛ рд╡рд╛рдкрд░ рдХрд░реВрди рднрд╛рд╖рд╛рдВрддрд░рд┐рдд рдХрд░рдгреНрдпрд╛рдд рдЖрд▓рд╛ рдЖрд╣реЗ. рдЖрдореНрд╣реА рдЕрдЪреВрдХрддреЗрд╕рд╛рдареА рдкреНрд░рдпрддреНрдирд╢реАрд▓ рдЕрд╕рд▓реЛ рддрд░реА рдХреГрдкрдпрд╛ рд▓рдХреНрд╖рд╛рдд рдШреНрдпрд╛ рдХреА рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рднрд╛рд╖рд╛рдВрддрд░рд╛рдВрдордзреНрдпреЗ рддреНрд░реБрдЯреА рдХрд┐рдВрд╡рд╛ рдЕрдЪреВрдХрддреЗрдЪрд╛ рдЕрднрд╛рд╡ рдЕрд╕реВ рд╢рдХрддреЛ. рдореВрд│ рднрд╛рд╖реЗрддреАрд▓ рджрд╕реНрддрдРрд╡рдЬ рд╣рд╛ рдЕрдзрд┐рдХреГрдд рд╕реНрд░реЛрдд рдорд╛рдирд▓рд╛ рдЬрд╛рд╡рд╛. рдорд╣рддреНрддреНрд╡рд╛рдЪреНрдпрд╛ рдорд╛рд╣рд┐рддреАрд╕рд╛рдареА рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдорд╛рдирд╡реА рднрд╛рд╖рд╛рдВрддрд░рд╛рдЪреА рд╢рд┐рдлрд╛рд░рд╕ рдХреЗрд▓реА рдЬрд╛рддреЗ. рдпрд╛ рднрд╛рд╖рд╛рдВрддрд░рд╛рдЪрд╛ рд╡рд╛рдкрд░ рдХреЗрд▓реНрдпрд╛рдореБрд│реЗ рдЙрджреНрднрд╡рдгрд╛рд▒реНрдпрд╛ рдХреЛрдгрддреНрдпрд╛рд╣реА рдЧреИрд░рд╕рдордЬ рдХрд┐рдВрд╡рд╛ рдЪреБрдХреАрдЪреНрдпрд╛ рдЕрд░реНрдерд╛рд╕рд╛рдареА рдЖрдореНрд╣реА рдЬрдмрд╛рдмрджрд╛рд░ рд░рд╛рд╣рдгрд╛рд░ рдирд╛рд╣реА.