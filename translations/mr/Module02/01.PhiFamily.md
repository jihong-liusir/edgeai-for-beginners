<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T19:54:28+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "mr"
}
-->
# विभाग 1: Microsoft Phi मॉडेल कुटुंबाची मूलभूत माहिती

Microsoft Phi मॉडेल कुटुंब कृत्रिम बुद्धिमत्तेमध्ये एक मोठा बदल दर्शवते, ज्यामध्ये लहान आणि कार्यक्षम मॉडेल्स पारंपरिक मोठ्या भाषा मॉडेल्सपेक्षा कमी संसाधनांचा वापर करून उल्लेखनीय कामगिरी करू शकतात. Phi कुटुंब विविध कार्यांमध्ये उच्च कार्यक्षमता राखून कमी संगणकीय आवश्यकता कशा सक्षम करते हे समजून घेणे महत्त्वाचे आहे.

## विकसकांसाठी संसाधने

### Azure AI Foundry Model Catalog
Phi मॉडेल्स (Phi-silica वगळता) [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi) द्वारे उपलब्ध आहेत, ज्यामुळे विकसकांना हे मॉडेल्स सहजपणे ऍक्सेस, फाइन-ट्यून आणि त्यांच्या ऍप्लिकेशन्समध्ये डिप्लॉय करता येतात. कॅटलॉग विविध Phi प्रकारांवर प्रयोग करण्याचा आणि त्यांना तुमच्या प्रकल्पांमध्ये समाकलित करण्याचा सोपा मार्ग प्रदान करते.

### Azure AI Foundry
तुम्ही [Azure AI Foundry](https://ai.azure.com) वापरून Phi मॉडेल्स डिप्लॉय आणि त्यावर प्रयोग करू शकता, जे AI सोल्यूशन्स तयार करण्यासाठी, चाचणी घेण्यासाठी आणि डिप्लॉय करण्यासाठी एक व्यापक वातावरण प्रदान करते.

### Foundry Local
स्थानिक विकास आणि डिप्लॉयमेंटसाठी [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) तपासा, जे तुम्हाला तुमच्या विकास मशीनवर Phi मॉडेल्स ऑप्टिमाइझ केलेल्या कॉन्फिगरेशन्ससह चालवण्यास सक्षम करते.

### दस्तऐवज संसाधने
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## परिचय

या धड्यात, आपण Microsoft च्या Phi मॉडेल कुटुंब आणि त्याच्या मूलभूत संकल्पनांचा अभ्यास करू. Phi कुटुंबाचा विकास, Phi मॉडेल्स कार्यक्षम बनवणाऱ्या नाविन्यपूर्ण प्रशिक्षण पद्धती, कुटुंबातील प्रमुख प्रकार आणि विविध परिस्थितींमध्ये व्यावहारिक अनुप्रयोग यावर चर्चा केली जाईल.

## शिकण्याची उद्दिष्टे

या धड्याच्या शेवटी, तुम्ही खालील गोष्टी सक्षमपणे करू शकाल:

- Microsoft च्या Phi मॉडेल कुटुंबाची डिझाइन तत्त्वज्ञान आणि विकास समजून घेणे.
- Phi मॉडेल्स कमी पॅरामीटर्ससह उच्च कार्यक्षमता साध्य करण्यास सक्षम करणाऱ्या प्रमुख नाविन्यपूर्ण गोष्टी ओळखणे.
- विविध Phi मॉडेल प्रकारांचे फायदे आणि मर्यादा ओळखणे.
- वास्तविक परिस्थितीसाठी योग्य प्रकार निवडण्यासाठी Phi मॉडेल्सचे ज्ञान लागू करणे.

## पारंपरिक AI मॉडेल पॅराडाइम समजून घेणे

पारंपरिकपणे, नैसर्गिक भाषा प्रक्रिया क्षेत्रात उच्च कार्यक्षमता साध्य करण्यासाठी अब्जावधी किंवा शेकडो अब्ज पॅरामीटर्स असलेल्या मोठ्या भाषा मॉडेल्सची आवश्यकता होती. संस्थांनी सहसा GPU क्लस्टर्सवर हे मॉडेल्स डिप्लॉय केले, त्यांच्या क्षमतांचा API इंटरफेस किंवा विशेष हार्डवेअर इन्फ्रास्ट्रक्चरद्वारे उपयोग केला.

ही पद्धत अनेक ऍप्लिकेशन्ससाठी चांगली कार्य करते, परंतु व्यावहारिक डिप्लॉयमेंट परिस्थितीत काही मर्यादा असतात. पारंपरिक पद्धतीमध्ये मोठ्या प्रमाणात संगणकीय संसाधने, मोठ्या प्रमाणात मेमरी आणि लक्षणीय ऊर्जा वापर आवश्यक असते. ही पद्धत अत्याधुनिक क्षमतांपर्यंत प्रवेश प्रदान करते, परंतु महागड्या हार्डवेअरवर अवलंबित्व निर्माण करते, उच्च ऑपरेशनल खर्च आणते आणि डिप्लॉयमेंटची लवचिकता मर्यादित करते.

## कार्यक्षम AI डिप्लॉयमेंटची गरज

विविध परिस्थितींमध्ये अधिक कार्यक्षम AI ची गरज वाढत आहे. गोपनीयतेच्या कारणास्तव स्थानिक डिप्लॉयमेंट आवश्यक असलेल्या ऍप्लिकेशन्स, जिथे क्लाउड API खर्च अडथळा ठरतो अशा खर्च-संवेदनशील अंमलबजावणी, मर्यादित हार्डवेअर संसाधनांसह एज संगणन परिस्थिती किंवा जिथे विलंब महत्त्वाचा आहे अशा रिअल-टाइम ऍप्लिकेशन्स विचार करा.

### प्रमुख डिप्लॉयमेंट मर्यादा

पारंपरिक मोठ्या मॉडेल डिप्लॉयमेंटमध्ये काही मूलभूत मर्यादा असतात ज्यामुळे त्यांची व्यावहारिक उपयुक्तता मर्यादित होते:

- **खर्च मर्यादा**: उच्च संगणकीय खर्चामुळे सतत डिप्लॉयमेंट अनेक संस्थांसाठी महाग होते.
- **संसाधन मर्यादा**: उच्च-स्तरीय GPU इन्फ्रास्ट्रक्चरचा मर्यादित प्रवेश डिप्लॉयमेंट पर्याय मर्यादित करतो.
- **गोपनीयता आवश्यकता**: संवेदनशील ऍप्लिकेशन्ससाठी डेटा गोपनीयता राखण्यासाठी स्थानिक प्रक्रिया आवश्यक असते.
- **विलंब संवेदनशीलता**: रिअल-टाइम ऍप्लिकेशन्सला क्लाउड राउंड-ट्रिप विलंबाशिवाय त्वरित प्रतिसाद आवश्यक असतो.

## Microsoft Phi मॉडेल तत्त्वज्ञान

Microsoft Phi मॉडेल कुटुंब AI मॉडेल डिझाइन तत्त्वज्ञानामध्ये एक मूलभूत बदल दर्शवते, कार्यक्षमता आणि व्यावहारिक डिप्लॉयमेंटला प्राधान्य देत असताना मजबूत कार्यक्षमता वैशिष्ट्ये राखते. Phi मॉडेल्स नाविन्यपूर्ण आर्किटेक्चर, उच्च-गुणवत्तेच्या प्रशिक्षण पद्धती आणि विशेष ऑप्टिमायझेशन तंत्रांद्वारे हे साध्य करतात.

Phi कुटुंब विविध दृष्टिकोनांचा समावेश करते जे प्रति पॅरामीटर कार्यक्षमता वाढवण्यासाठी डिझाइन केले आहेत, मानक हार्डवेअरवर डिप्लॉयमेंट सक्षम करताना अर्थपूर्ण AI क्षमता प्रदान करतात. उद्दिष्ट म्हणजे संगणकीय आवश्यकता, मेमरी वापर आणि ऑपरेशनल खर्च मोठ्या प्रमाणात कमी करताना स्पर्धात्मक कार्यक्षमता राखणे.

### Phi डिझाइनची मुख्य तत्त्वे

Phi मॉडेल्स पारंपरिक मोठ्या भाषा मॉडेल्सपासून वेगळे करणाऱ्या अनेक मूलभूत तत्त्वांवर आधारित आहेत:

- **प्रथम कार्यक्षमता**: पूर्ण प्रमाणाऐवजी प्रति पॅरामीटर जास्तीत जास्त कार्यक्षमता साध्य करण्यासाठी ऑप्टिमाइझ केले.
- **गुणवत्तापूर्ण प्रशिक्षण**: मोठ्या डेटासेटऐवजी उच्च-गुणवत्तेच्या, क्युरेटेड प्रशिक्षण डेटावर लक्ष केंद्रित केले.
- **डिप्लॉयमेंट लवचिकता**: विविध हार्डवेअर कॉन्फिगरेशन्सवर प्रभावीपणे चालण्यासाठी डिझाइन केले.
- **विशेष क्षमता**: विशिष्ट कार्ये किंवा डोमेनसाठी ऑप्टिमाइझ केलेले, प्रभावीपणा वाढवण्यासाठी.

## Phi कुटुंब सक्षम करणाऱ्या प्रमुख तंत्रज्ञान

### "टेक्स्टबुक" प्रशिक्षण पद्धत

Phi कुटुंबातील सर्वात क्रांतिकारी पैलू म्हणजे "टेक्स्टबुक गुणवत्ता" प्रशिक्षण पद्धत. इंटरनेटवरील मोठ्या प्रमाणात न फिल्टर केलेल्या डेटावर प्रशिक्षण देण्याऐवजी, Phi मॉडेल्स काळजीपूर्वक क्युरेटेड, उच्च-गुणवत्तेच्या शैक्षणिक सामग्रीचा वापर करतात, ज्यामुळे तर्कशास्त्र, गणित, कोडिंग आणि सामान्य ज्ञान प्रभावीपणे शिकवले जाते.

ही पद्धत उच्च-गुणवत्तेच्या पाठ्यपुस्तकांप्रमाणे शैक्षणिक सामग्री तयार करून कार्य करते. प्रशिक्षण डेटा विशेषतः स्पष्ट स्पष्टीकरणे, चरण-दर-चरण तर्कशास्त्र आणि संरचित ज्ञान सादरीकरणावर लक्ष केंद्रित करून पेडॅगॉजिकली ध्वनी बनवण्यासाठी डिझाइन केलेला आहे.

### प्रगत तर्कशास्त्र प्रशिक्षण

अलीकडील Phi मॉडेल्समध्ये जटिल बहु-चरण समस्या सोडवण्यासाठी प्रगत तर्कशास्त्र प्रशिक्षण पद्धतींचा समावेश आहे. यामध्ये खालील तंत्रांचा समावेश आहे:

**चेन-ऑफ-थॉट प्रशिक्षण**: मॉडेल्स जटिल समस्यांचे मध्यवर्ती तर्कशास्त्र चरणांमध्ये विभाजन शिकतात, ज्यामुळे त्यांची समस्या सोडवण्याची प्रक्रिया अधिक पारदर्शक आणि विश्वासार्ह होते.

**इन्फरन्स-टाइम स्केलिंग**: प्रतिसाद निर्मिती दरम्यान मॉडेल्स तपशीलवार तर्कशास्त्र साखळ्या तयार करतात, ज्यामुळे अतिरिक्त संगणकीय संसाधनांचा उपयोग करून अचूकता सुधारली जाते.

**एज-ऑफ-कॅपॅबिलिटी प्रशिक्षण**: प्रशिक्षण डेटा मॉडेलच्या विद्यमान क्षमतेच्या काठावर आव्हान देण्यासाठी विशेषतः निवडला जातो, जटिल तर्कशास्त्र नमुन्यांचे शिक्षण प्रोत्साहित करण्यासाठी.

### आर्किटेक्चरल नाविन्य

Phi कुटुंब कार्यक्षमतेसाठी विशेषतः डिझाइन केलेल्या अनेक आर्किटेक्चरल ऑप्टिमायझेशन्सचा समावेश करते:

**पॅरामीटर कार्यक्षमता**: मॉडेलमधील प्रत्येक पॅरामीटरचा प्रभाव जास्तीत जास्त करण्यासाठी काळजीपूर्वक आर्किटेक्चरल निवडी.

**मल्टी-मोडल समाकलन**: कॉम्पॅक्ट आर्किटेक्चर्समध्ये मजकूर, व्हिजन आणि स्पीच प्रोसेसिंग क्षमतांचा कार्यक्षम समाकलन.

**हार्डवेअर ऑप्टिमायझेशन**: विशिष्ट हार्डवेअर प्लॅटफॉर्म आणि डिप्लॉयमेंट परिस्थितीसाठी ऑप्टिमाइझ केलेले विशेष प्रकार.

## Phi मॉडेल्ससाठी हार्डवेअर ऑप्टिमायझेशन

आधुनिक डिप्लॉयमेंट वातावरण विविध हार्डवेअर कॉन्फिगरेशन्समध्ये Phi मॉडेल्सच्या कार्यक्षमतेचा लाभ घेतात:

### CPU-ऑप्टिमाइझ केलेले डिप्लॉयमेंट

Phi मॉडेल्स CPU-फक्त हार्डवेअरवर प्रभावीपणे चालण्यासाठी डिझाइन केले आहेत, ज्यामुळे विशेष AI ऍक्सेलरेटर्सची आवश्यकता न ठेवता मानक संगणकीय इन्फ्रास्ट्रक्चरवर डिप्लॉयमेंट सुलभ होते.

### GPU प्रवेग

शक्तिशाली GPUs ची आवश्यकता नसतानाही, Phi मॉडेल्स उपलब्ध GPU संसाधनांचा उपयोग करून कार्यक्षमता वाढवू शकतात, डिप्लॉयमेंट कॉन्फिगरेशन्समध्ये लवचिकता प्रदान करतात.

### एज डिव्हाइस समाकलन

Phi-3-Silica सारखे विशेष प्रकार विशिष्ट एज संगणन प्लॅटफॉर्मसाठी ऑप्टिमाइझ केले आहेत, ज्यामुळे फक्त 1.5W वीज वापरासह 650 टोकन्स प्रति सेकंद कार्यक्षमता मिळते.

## Phi मॉडेल कुटुंबाचे फायदे

### खर्च कार्यक्षमता

Phi मॉडेल्स लक्षणीय कमी संगणकीय इन्फ्रास्ट्रक्चरची आवश्यकता असल्यामुळे ऑपरेशनल खर्च मोठ्या प्रमाणात कमी करतात, स्पर्धात्मक कार्यक्षमता राखून AI अधिक प्रवेशयोग्य बनवतात.

### डिप्लॉयमेंट लवचिकता

Phi मॉडेल्सची कार्यक्षमता वैयक्तिक लॅपटॉपपासून एंटरप्राइझ सर्व्हर्सपर्यंत विविध हार्डवेअर कॉन्फिगरेशन्समध्ये डिप्लॉयमेंट सक्षम करते, संस्थांना त्यांच्या AI इन्फ्रास्ट्रक्चर निवडींमध्ये अधिक लवचिकता प्रदान करते.

### गोपनीयता आणि सुरक्षा

Phi मॉडेल्सची कार्यक्षमता गोपनीयता-संवेदनशील ऍप्लिकेशन्ससाठी स्थानिक डिप्लॉयमेंट सक्षम करते, संवेदनशील डेटा संस्थेच्या नियंत्रणाखाली ठेवत शक्तिशाली AI क्षमता प्रदान करते.

### रिअल-टाइम कार्यक्षमता

कमी संगणकीय आवश्यकता जलद इन्फरन्स वेळांमध्ये अनुवादित होतात, त्वरित प्रतिसाद आवश्यक असलेल्या रिअल-टाइम ऍप्लिकेशन्स सक्षम करतात, AI क्षमता गुणवत्तेवर तडजोड न करता.

### प्रवेशयोग्य AI

डिप्लॉयमेंट अडथळे कमी करून, Phi मॉडेल्स प्रगत AI क्षमता मर्यादित संसाधनांसह संस्थांसाठी प्रवेशयोग्य बनवतात, लहान टीम्स आणि वैयक्तिक विकसकांना परिष्कृत भाषा समजून घेण्याचा लाभ घेण्यास सक्षम करतात.

## व्यावहारिक उदाहरणे आणि उपयोग प्रकरणे

तांत्रिक विकासात जाण्यापूर्वी, Phi मॉडेल्स काय साध्य करू शकतात याचे काही ठोस उदाहरणे पाहूया:

### गणितीय तर्कशास्त्र उदाहरण

Phi-4-mini-reasoning चरण-दर-चरण गणितीय समस्या सोडवण्यात उत्कृष्ट आहे. उदाहरणार्थ, "3*x^2+4*x+5=1 कसे सोडवायचे?" विचारल्यावर मॉडेल तपशीलवार तर्कशास्त्र चरण प्रदान करते:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### बहुभाषिक समर्थन उदाहरण

Phi-3.5-mini-instruct विविध भाषांमध्ये मजबूत बहुभाषिक क्षमता दर्शवते. येथे एक उदाहरण प्रॉम्प्ट स्वरूप आहे:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### मल्टीमोडल क्षमता उदाहरण

Phi-4-multimodal मजकूर, प्रतिमा आणि भाषण एकाच वेळी प्रक्रिया करू शकते. येथे काही व्यावहारिक अनुप्रयोग आहेत:

**ऑडिओ इनपुटसह प्रवास नियोजन**:
Phi-4 Multimodal कसे बोलल्या जाणाऱ्या भाषेचे विश्लेषण करून सिएटलला प्रवास नियोजित करण्यात मदत करते हे पाहा, त्याच्या प्रगत ऑडिओ प्रक्रिया आणि शिफारस क्षमतांचे प्रदर्शन करते.

**प्रतिमांमधून गणितीय समस्या सोडवणे**:
Phi-4 Multimodal कसे प्रतिमांमध्ये सादर केलेल्या समीकरणांचे विश्लेषण करून जटिल गणितीय समस्या सोडवते हे पाहा.

**फंक्शन कॉलिंग उदाहरण**:
फंक्शन कॉलिंगसह, Phi-4-mini आणि Phi-4-multimodal त्यांच्या मजकूर-प्रक्रिया क्षमतांचा विस्तार शोध इंजिन, विविध टूल्सशी कनेक्ट करून करू शकतात. उदाहरण म्हणून, Phi-4-mini प्रीमियर लीग सामन्याची माहिती पुनर्प्राप्त करू शकते, बाह्य डेटा स्रोतांसह सहजपणे संवाद साधण्याची क्षमता दर्शवते.

### कोड जनरेशन उदाहरण

Phi-4-multimodal प्रतिमा सामग्री आणि दिलेल्या प्रॉम्प्ट्सच्या आधारे संरचित प्रकल्प कोड तयार करू शकते, जसे की या व्यावहारिक कार्यप्रवाहात दाखवले आहे:

1. वायरफ्रेम किंवा डिझाइनची प्रतिमा अपलोड करा
2. प्रकल्पाच्या आवश्यकता संदर्भात प्रदान करा
3. मॉडेल संपूर्ण, कार्यात्मक कोड संरचना तयार करते
4. कोड विशिष्ट फ्रेमवर्क किंवा भाषांनुसार सानुकूलित केला जाऊ शकतो

### एज डिप्लॉयमेंट उदाहरण

आम्ही क्वांटाइझ केलेले मॉडेल एज डिव्हाइसवर डिप्लॉय करू शकतो. Microsoft Olive आणि ONNX GenAI Runtime एकत्र करून, आम्ही Phi-4-mini Windows, iPhone, Android आणि इतर डिव्हाइसवर डिप्लॉय करू शकतो. हे iPhone 12 Pro वर चालवलेले उदाहरण आहे.

डिप्लॉयमेंट प्रक्रियेमध्ये समाविष्ट आहे:
- मोबाइल ऑप्टिमायझेशनसाठी मॉडेल क्वांटायझेशन
- क्रॉस-प्लॅटफॉर्म सुसंगततेसाठी ONNX रनटाइम समाकलन
- इंटरनेट कनेक्टिव्हिटीशिवाय स्थानिक इन्फरन्स
- किमान वीज वापरासह रिअल-टाइम कार्यक्षमता

## Phi कुटुंबाचा विकास

### Phi-1 आणि Phi-2: फाउंडेशन मॉडेल्स

प्रारंभिक Phi मॉडेल्सने उच्च-गुणवत्तेच्या प्रशिक्षण डेटा आणि कार्यक्षम आर्किटेक्चर्सच्या मूलभूत तत्त्वांची स्थापना केली:

- **Phi-1 (1.3B पॅरामीटर्स)**: मूलभूत भाषा समज आणि कोड जनरेशनसाठी क्युरेटेड प्रशिक्षण डेटाची संकल्पना सादर केली.
- **Phi-2 (2.7B पॅरामीटर्स)**: सिंथेटिक NLP डेटा आणि काळजीपूर्वक फिल्टर केलेल्या वेब सामग्रीद्वारे तर्कशास्त्र क्षमता वाढवली.

### Phi-3 कुटुंब: मुख्य प्रवाहात स्वीकार

Phi-3 मालिकेने SLM क्षमतांमध्ये अनेक विशेष प्रकारांसह एक मोठी प्रगती केली:

- **Phi-3-mini (3.8B पॅरामीटर्स)**: अपवादात्मक कार्यक्षमतेसह सामान्य भाषा कार्ये, त्याच्या आकाराच्या दुप्पट मॉडेल्सपेक्षा चांगले कार्य करते.
- **Phi-3-small (7B पॅरामीटर्स)**: GPT-3.5 Turbo पेक्षा विविध बेंचमार्कवर उत्कृष्ट कामगिरी.
- **Phi-3-medium (14B पॅरामीटर्स)**: एंटरप्राइझ-ग्रेड कार्यक्षमता Gemini 1.0 Pro पेक्षा च
Phi कुटुंब दाखवते की AI तंत्रज्ञानाचा भविष्यातील वापर फक्त मोठे मॉडेल्स तयार करण्यात नाही, तर अधिक स्मार्ट आणि कार्यक्षम मॉडेल्स तयार करण्यात आहे, जे विविध हार्डवेअर वातावरणात प्रभावीपणे कार्य करू शकतात आणि उच्च कार्यक्षमता मानक राखू शकतात.

## विकास आणि समाकलन उदाहरणे

### ट्रान्सफॉर्मर्ससह जलद सुरुवात

Hugging Face Transformers लायब्ररी वापरून Phi मॉडेल्ससह सुरुवात कशी करावी:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### फाइन-ट्यूनिंग उदाहरण

खालील उदाहरण Phi-4-mini-instruct विशिष्ट कार्यांसाठी फाइन-ट्यून कसे करावे हे दाखवते:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### विशेष प्रॉम्प्ट स्वरूप

**तर्कसंगत कार्यांसाठी (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**गणितीय कार्यांसाठी (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### ONNX सह मोबाइल डिप्लॉयमेंट

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## कार्यक्षमता बेंचमार्क आणि उपलब्धी

Phi मॉडेल कुटुंबाने विविध बेंचमार्कवर उल्लेखनीय कार्यक्षमता प्राप्त केली आहे, अनेकदा खूप मोठ्या मॉडेल्सपेक्षा चांगले प्रदर्शन केले आहे:

### मुख्य कार्यक्षमता ठळक मुद्दे

**गणितीय तर्कसंगततेतील उत्कृष्टता:**
- Phi-4 ने AIME 2025 (Math Olympiad qualifier) वर 82.5% अचूकता प्राप्त केली
- Phi-4-reasoning (14B) ने reasoning बेंचमार्कवर DeepSeek-R1-Distill-70B (5x मोठे) पेक्षा चांगले प्रदर्शन केले
- Phi-4-mini-reasoning (3.8B) ने गणितीय तर्कसंगततेच्या कार्यांमध्ये त्याच्या दुप्पट आकाराच्या मॉडेल्सशी स्पर्धा केली

**कार्यक्षमता उपलब्धी:**
- Phi-3-Silica ने फक्त 1.5W वीज वापरासह 650 टोकन्स प्रति सेकंद गती प्राप्त केली
- Phi-4-mini (3.8B) ने खूप मोठ्या मॉडेल्ससारखी कार्यक्षमता प्राप्त केली

**बेंचमार्क कार्यक्षमता:**
- **MMLU (Massive Multitask Language Understanding)**: 57 शैक्षणिक विषयांमध्ये स्पर्धात्मक कार्यक्षमता
- **HumanEval**: विशेषतः Python मध्ये मजबूत कोड जनरेशन क्षमता
- **MGSM**: बहुभाषिक प्राथमिक गणित समस्या सोडवणे
- **DROP**: जटिल समज आणि तर्कसंगत कार्ये
- **SimpleQA**: तथ्यात्मक प्रतिसाद अचूकता

### 📊 मॉडेल तुलना मॅट्रिक्स

| मॉडेल | पॅरामीटर्स | संदर्भ लांबी | मुख्य ताकदी | सर्वोत्तम उपयोग प्रकरणे |
|-------|------------|----------------|---------------|----------------|
| **Phi-3-mini** | 3.8B | 4K/128K | सामान्य कार्यक्षमता | मोबाइल अॅप्स, मूलभूत चॅटबॉट्स |
| **Phi-3.5-mini** | 3.8B | 128K | बहुभाषिक समर्थन | आंतरराष्ट्रीय अनुप्रयोग |
| **Phi-4-mini** | 3.8B | 128K | सुधारित तर्कसंगतता, फंक्शन कॉलिंग | व्यवसाय ऑटोमेशन |
| **Phi-4-mini-reasoning** | 3.8B | 128K | गणितीय तर्कसंगतता | शैक्षणिक प्लॅटफॉर्म |
| **Phi-4** | 14B | 32K | जटिल तर्कसंगतता | संशोधन, प्रगत विश्लेषण |
| **Phi-4-reasoning** | 14B | 32K/64K | मल्टी-स्टेप तर्कसंगतता | वैज्ञानिक संगणन |
| **Phi-4-reasoning-plus** | 14B | 32K | जास्तीत जास्त अचूकता तर्कसंगतता | महत्त्वपूर्ण निर्णय घेणे |
| **Phi-4-multimodal** | 5.6B | बदलणारे | भाषण, व्हिजन, टेक्स्ट | मल्टीमीडिया अनुप्रयोग |

## मॉडेल निवड मार्गदर्शक

### मूलभूत अनुप्रयोगांसाठी
- **Phi-3-mini**: साधे टेक्स्ट जनरेशन, मूलभूत Q&A, जलद प्रतिसाद
- **Phi-4-mini**: फंक्शन कॉलिंग क्षमतांसह सुधारित तर्कसंगतता

### गणितीय आणि तर्कसंगत कार्यांसाठी
- **Phi-4**: जटिल गणितीय समस्या सोडवणे आणि तर्कसंगतता
- **Phi-4-reasoning**: तपशीलवार स्पष्टीकरणांसह मल्टी-स्टेप तर्कसंगतता
- **Phi-4-reasoning-plus**: महत्त्वपूर्ण तर्कसंगत अनुप्रयोगांसाठी जास्तीत जास्त अचूकता
- **Phi-4-mini-reasoning**: संसाधन-आधारित वातावरणासाठी कार्यक्षम गणितीय तर्कसंगतता

### मल्टीमोडल अनुप्रयोगांसाठी
- **Phi-3-vision**: प्रतिमा आणि टेक्स्ट प्रक्रिया संयोजन
- **Phi-4-multimodal**: व्यापक भाषण, व्हिजन, आणि टेक्स्ट क्षमता

### एंटरप्राइझ डिप्लॉयमेंटसाठी
- **Phi-3-medium**: व्यवसाय अनुप्रयोगांसाठी प्रगत भाषा समज
- **Phi-3-Silica**: विशिष्ट हार्डवेअर प्लॅटफॉर्मसाठी ऑप्टिमाइझ केलेले

## डिप्लॉयमेंट प्लॅटफॉर्म्स आणि प्रवेशयोग्यता

### क्लाउड प्लॅटफॉर्म्स
- **Azure AI Foundry**: एंटरप्राइझ टूल्ससह पूर्ण-वैशिष्ट्यीकृत डिप्लॉयमेंट
- **Hugging Face**: ओपन-सोर्स मॉडेल रिपॉझिटरी आणि समुदाय संसाधने
- **NVIDIA API Catalog**: मायक्रोसर्व्हिस डिप्लॉयमेंट पर्याय

### स्थानिक विकास फ्रेमवर्क्स
- **Ollama**: स्थानिक मॉडेल डिप्लॉयमेंटसाठी हलके फ्रेमवर्क
- **ONNX Runtime**: विविध हार्डवेअर कॉन्फिगरेशनसाठी ऑप्टिमाइझ केलेले  
- **DirectML**: Windows-ऑप्टिमाइझ केलेली कार्यक्षमता
- **llama.cpp**: क्रॉस-प्लॅटफॉर्म इनफरन्स इंजिन

### शिकण्याची संसाधने
- **Phi Portal**: Microsoft Phi चे अधिकृत दस्तऐवज केंद्र
- **Phi Cookbook**: सर्वसमावेशक उदाहरणे आणि ट्यूटोरियल्स
- **Technical Reports**: arxiv वर सखोल संशोधन पेपर्स
- **Community Spaces**: Hugging Face इंटरएक्टिव डेमो

### Phi मॉडेल्ससह सुरुवात

#### विकास प्लॅटफॉर्म्स
1. **Azure AI Foundry**: सोपे स्थानिक CLI आणि मॉडेल व्यवस्थापन.
2. **Hugging Face Transformers**: जलद स्थानिक प्रयोग
3. **Ollama**: चाचणीसाठी सोपे स्थानिक डिप्लॉयमेंट

#### शिकण्याचा मार्ग
1. **मूलभूत संकल्पना समजून घ्या**: मूलभूत डिझाइन तत्त्वांचा अभ्यास करा
2. **विविध प्रकारांवर प्रयोग करा**: Phi मॉडेल्सची क्षमता समजण्यासाठी प्रयत्न करा
3. **अंमलबजावणीचा सराव करा**: चाचणी वातावरणात मॉडेल्स डिप्लॉय करा
4. **डिप्लॉयमेंट स्केल करा**: यशस्वी पायलट्सच्या आधारे वापर हळूहळू वाढवा

#### सर्वोत्तम पद्धती
- **लहान सुरुवात करा**: प्रारंभिक विकासासाठी Phi-mini मॉडेल्ससह प्रारंभ करा
- **प्रॉम्प्ट्स ऑप्टिमाइझ करा**: सर्वोत्तम परिणामांसाठी योग्य चॅट स्वरूपन वापरा
- **कार्यक्षमता निरीक्षण करा**: इनफरन्स गती आणि अचूकता मेट्रिक्स ट्रॅक करा
- **हार्डवेअर विचारात घ्या**: उपलब्ध संगणकीय संसाधनांशी मॉडेल आकार जुळवा

## निष्कर्ष

Microsoft Phi मॉडेल कुटुंब AI मॉडेल डिझाइनसाठी क्रांतिकारी दृष्टिकोनाचे प्रतिनिधित्व करते, दाखवते की लहान, अधिक कार्यक्षम मॉडेल्स विविध कार्यांमध्ये उल्लेखनीय कार्यक्षमता प्राप्त करू शकतात. उच्च-गुणवत्तेच्या प्रशिक्षण डेटावर आणि आर्किटेक्चरल ऑप्टिमायझेशनवर लक्ष केंद्रित करून, Phi कुटुंब पारंपरिक मोठ्या भाषा मॉडेल्सच्या तुलनेत लक्षणीय कमी संगणकीय आवश्यकता असलेल्या अपवादात्मक क्षमता प्रदान करते.

## मुख्य शिकण्याचे उद्दिष्ट

1. Microsoft च्या Phi मॉडेल कुटुंबाचा Phi-1 ते Phi-4 पर्यंतचा डिझाइन तत्त्वज्ञान आणि उत्क्रांती समजून घ्या
2. "टेक्स्टबुक गुणवत्ता" प्रशिक्षण आणि आर्किटेक्चरल ऑप्टिमायझेशनसह मुख्य नवकल्पना ओळखा
3. विविध डिप्लॉयमेंट परिस्थितींमध्ये वेगवेगळ्या Phi प्रकारांचे फायदे आणि मर्यादा ओळखा
4. विशिष्ट उपयोग प्रकरणे आणि हार्डवेअर मर्यादांसाठी योग्य Phi मॉडेल्स निवडण्यासाठी ज्ञान लागू करा
5. संसाधन-आधारित उपकरणांवर Phi मॉडेल्स डिप्लॉय करण्यासाठी ऑप्टिमायझेशन तंत्रे अंमलात आणा
6. पारंपरिक मोठ्या भाषा मॉडेल्सच्या तुलनेत Phi मॉडेल कुटुंबाचे आर्किटेक्चरल फायदे स्पष्ट करा
7. विशिष्ट अनुप्रयोग आवश्यकता आणि हार्डवेअर मर्यादांवर आधारित योग्य Phi प्रकार निवडा
8. क्लाउड आणि एज डिप्लॉयमेंट परिस्थितींमध्ये Phi मॉडेल्स ऑप्टिमाइझ केलेल्या कॉन्फिगरेशनसह अंमलात आणा
9. लक्ष्य उपकरणांवर Phi मॉडेल कार्यक्षमता सुधारण्यासाठी क्वांटायझेशन आणि ऑप्टिमायझेशन तंत्रे लागू करा
10. Phi कुटुंबातील मॉडेल आकार, कार्यक्षमता, आणि क्षमता यामधील व्यापार-offs मूल्यांकन करा

## पुढील काय

- [02: Qwen Family Fundamentals](02.QwenFamily.md)

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात ठेवा की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर करून उद्भवलेल्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.