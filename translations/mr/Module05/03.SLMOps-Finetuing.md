<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T21:20:10+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "mr"
}
-->
# विभाग 3: फाइन-ट्यूनिंग - विशिष्ट कार्यांसाठी मॉडेल्स सानुकूलित करणे

## विषय सूची
1. [फाइन-ट्यूनिंगची ओळख](../../../Module05)
2. [फाइन-ट्यूनिंग का महत्त्वाचे आहे](../../../Module05)
3. [फाइन-ट्यूनिंगचे प्रकार](../../../Module05)
4. [Microsoft Olive सह फाइन-ट्यूनिंग](../../../Module05)
5. [हँड्स-ऑन उदाहरणे](../../../Module05)
6. [सर्वोत्तम पद्धती आणि मार्गदर्शक तत्त्वे](../../../Module05)
7. [प्रगत तंत्रज्ञान](../../../Module05)
8. [मूल्यांकन आणि निरीक्षण](../../../Module05)
9. [सामान्य आव्हाने आणि उपाय](../../../Module05)
10. [निष्कर्ष](../../../Module05)

## फाइन-ट्यूनिंगची ओळख

**फाइन-ट्यूनिंग** ही एक प्रभावी मशीन लर्निंग तंत्र आहे ज्यामध्ये पूर्व-प्रशिक्षित मॉडेलला विशिष्ट कार्ये करण्यासाठी किंवा विशेष डेटासेटसह काम करण्यासाठी अनुकूलित केले जाते. मॉडेलला सुरुवातीपासून प्रशिक्षण देण्याऐवजी, फाइन-ट्यूनिंग पूर्व-प्रशिक्षित मॉडेलने आधीच शिकलेल्या ज्ञानाचा उपयोग करते आणि ते तुमच्या विशिष्ट उपयोगासाठी समायोजित करते.

### फाइन-ट्यूनिंग म्हणजे काय?

फाइन-ट्यूनिंग ही **ट्रान्सफर लर्निंग**ची एक प्रकार आहे जिथे तुम्ही:
- मोठ्या डेटासेट्समधून सामान्य नमुने शिकलेल्या पूर्व-प्रशिक्षित मॉडेलसह सुरुवात करता
- तुमच्या विशिष्ट डेटासेटचा वापर करून मॉडेलचे अंतर्गत पॅरामीटर्स समायोजित करता
- मौल्यवान ज्ञान टिकवून ठेवता आणि मॉडेलला तुमच्या कार्यासाठी विशेष बनवता

याचा विचार कुशल शेफला नवीन प्रकारचे स्वयंपाक शिकवण्यासारखा करा - त्यांना आधीच स्वयंपाकाचे मूलभूत ज्ञान आहे, परंतु त्यांना नवीन शैलीसाठी विशिष्ट तंत्र आणि चव शिकण्याची आवश्यकता आहे.

### मुख्य फायदे

- **वेळेची बचत**: सुरुवातीपासून प्रशिक्षण देण्यापेक्षा लक्षणीय वेगवान
- **डेटाची बचत**: चांगल्या कामगिरीसाठी लहान डेटासेटची आवश्यकता
- **खर्च-प्रभावी**: कमी संगणकीय आवश्यकता
- **उत्तम कामगिरी**: सुरुवातीपासून प्रशिक्षण देण्यापेक्षा अनेकदा उत्कृष्ट परिणाम मिळवते
- **संसाधनांचा योग्य वापर**: लहान टीम्स आणि संस्थांसाठी शक्तिशाली AI उपलब्ध करते

## फाइन-ट्यूनिंग का महत्त्वाचे आहे

### वास्तविक-जगातील उपयोग

फाइन-ट्यूनिंग अनेक परिस्थितींमध्ये आवश्यक आहे:

**1. डोमेन अडॅप्टेशन**
- वैद्यकीय AI: वैद्यकीय शब्दावली आणि क्लिनिकल नोट्ससाठी सामान्य भाषा मॉडेल्स अनुकूलित करणे
- कायदेशीर तंत्रज्ञान: कायदेशीर दस्तऐवज विश्लेषण आणि करार पुनरावलोकनासाठी मॉडेल्स विशेष बनवणे
- वित्तीय सेवा: वित्तीय अहवाल विश्लेषण आणि जोखीम मूल्यांकनासाठी मॉडेल्स सानुकूलित करणे

**2. कार्य विशेषीकरण**
- सामग्री निर्मिती: विशिष्ट लेखन शैली किंवा टोनसाठी फाइन-ट्यूनिंग
- कोड निर्मिती: विशिष्ट प्रोग्रामिंग भाषा किंवा फ्रेमवर्कसाठी मॉडेल्स अनुकूलित करणे
- भाषांतर: विशिष्ट भाषा जोड्या किंवा तांत्रिक डोमेनसाठी कामगिरी सुधारणे

**3. कॉर्पोरेट उपयोग**
- ग्राहक सेवा: कंपनी-विशिष्ट शब्दावली समजणारे चॅटबॉट्स तयार करणे
- अंतर्गत दस्तऐवजीकरण: संस्थात्मक प्रक्रियांशी परिचित AI सहाय्यक तयार करणे
- उद्योग-विशिष्ट उपाय: क्षेत्र-विशिष्ट शब्दावली आणि कार्यप्रवाह समजणारे मॉडेल्स विकसित करणे

## फाइन-ट्यूनिंगचे प्रकार

### 1. पूर्ण फाइन-ट्यूनिंग (इन्स्ट्रक्शन फाइन-ट्यूनिंग)

पूर्ण फाइन-ट्यूनिंगमध्ये, प्रशिक्षणादरम्यान सर्व मॉडेल पॅरामीटर्स अपडेट केले जातात. या पद्धतीचे फायदे:
- जास्तीत जास्त लवचिकता आणि कामगिरी क्षमता प्रदान करते
- लक्षणीय संगणकीय संसाधनांची आवश्यकता असते
- मॉडेलचा पूर्णपणे नवीन आवृत्ती तयार होते
- मोठ्या प्रमाणात प्रशिक्षण डेटा आणि संगणकीय संसाधने असल्यास सर्वोत्तम

### 2. पॅरामीटर-इफिशियंट फाइन-ट्यूनिंग (PEFT)

PEFT पद्धती फक्त काही पॅरामीटर्स अपडेट करतात, ज्यामुळे प्रक्रिया अधिक कार्यक्षम होते:

#### लो-रँक अडॅप्टेशन (LoRA)
- विद्यमान वजनांमध्ये लहान ट्रेन करण्यायोग्य रँक डीकंपोजिशन मॅट्रिसेस जोडते
- ट्रेन करण्यायोग्य पॅरामीटर्सची संख्या लक्षणीयरीत्या कमी करते
- पूर्ण फाइन-ट्यूनिंगच्या जवळपास कामगिरी टिकवते
- वेगवेगळ्या अडॅप्टेशन्समध्ये सहज स्विचिंग सक्षम करते

#### QLoRA (क्वांटाइज्ड LoRA)
- LoRA ला क्वांटायझेशन तंत्रांसह एकत्र करते
- मेमरी आवश्यकता आणखी कमी करते
- ग्राहक हार्डवेअरवर मोठ्या मॉडेल्सचे फाइन-ट्यूनिंग सक्षम करते
- कार्यक्षमता आणि कामगिरी यामध्ये संतुलन राखते

#### अडॅप्टर्स
- विद्यमान स्तरांमध्ये लहान न्यूरल नेटवर्क्स घालतात
- बेस मॉडेल स्थिर ठेवून लक्ष्यित फाइन-ट्यूनिंग सक्षम करतात
- मॉडेल सानुकूलित करण्यासाठी मॉड्युलर दृष्टिकोन सक्षम करतात

### 3. कार्य-विशिष्ट फाइन-ट्यूनिंग

विशिष्ट डाउनस्ट्रीम कार्यांसाठी मॉडेल्स अनुकूलित करण्यावर लक्ष केंद्रित करते:
- **वर्गीकरण**: वर्गीकरण कार्यांसाठी मॉडेल समायोजित करणे
- **निर्मिती**: सामग्री निर्मिती आणि मजकूर निर्मितीसाठी अनुकूलित करणे
- **माहिती काढणे**: माहिती काढणे आणि नामित घटक ओळखण्यासाठी फाइन-ट्यूनिंग
- **सारांश तयार करणे**: दस्तऐवज सारांशासाठी मॉडेल्स विशेष बनवणे

## Microsoft Olive सह फाइन-ट्यूनिंग

Microsoft Olive हे एक व्यापक मॉडेल ऑप्टिमायझेशन टूलकिट आहे जे फाइन-ट्यूनिंग प्रक्रिया सुलभ करते आणि एंटरप्राइझ-ग्रेड वैशिष्ट्ये प्रदान करते.

### Microsoft Olive म्हणजे काय?

Microsoft Olive हे एक ओपन-सोर्स मॉडेल ऑप्टिमायझेशन टूल आहे जे:
- विविध हार्डवेअर लक्ष्यांसाठी फाइन-ट्यूनिंग वर्कफ्लो सुलभ करते
- लोकप्रिय मॉडेल आर्किटेक्चर (Llama, Phi, Qwen, Gemma) साठी अंगभूत समर्थन प्रदान करते
- क्लाउड आणि स्थानिक तैनाती पर्याय ऑफर करते
- Azure ML आणि इतर Microsoft AI सेवांसह सहजपणे समाकलित होते
- स्वयंचलित ऑप्टिमायझेशन आणि क्वांटायझेशनला समर्थन देते

### मुख्य वैशिष्ट्ये

- **हार्डवेअर-अवेयर ऑप्टिमायझेशन**: विशिष्ट हार्डवेअर (CPU, GPU, NPU) साठी मॉडेल्स स्वयंचलितपणे ऑप्टिमाइझ करते
- **मल्टी-फॉरमॅट समर्थन**: PyTorch, Hugging Face, आणि ONNX मॉडेल्ससह कार्य करते
- **स्वयंचलित वर्कफ्लो**: मॅन्युअल कॉन्फिगरेशन आणि ट्रायल-एंड-एरर कमी करते
- **एंटरप्राइझ समाकलन**: Azure ML आणि क्लाउड तैनातीसाठी अंगभूत समर्थन
- **विस्तारणीय आर्किटेक्चर**: सानुकूल ऑप्टिमायझेशन तंत्र सक्षम करते

### स्थापना आणि सेटअप

#### मूलभूत स्थापना

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### पर्यायी अवलंबित्वे

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### स्थापना सत्यापित करा

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## हँड्स-ऑन उदाहरणे

### उदाहरण 1: Olive CLI सह मूलभूत फाइन-ट्यूनिंग

फ्रेज वर्गीकरणासाठी लहान भाषा मॉडेल फाइन-ट्यूनिंगचे उदाहरण:

#### चरण 1: तुमचे वातावरण तयार करा

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### चरण 2: मॉडेल फाइन-ट्यून करा

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### चरण 3: तैनातीसाठी ऑप्टिमाइझ करा

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### उदाहरण 2: सानुकूल डेटासेटसह प्रगत कॉन्फिगरेशन

#### चरण 1: सानुकूल डेटासेट तयार करा

तुमच्या प्रशिक्षण डेटासह JSON फाइल तयार करा:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### चरण 2: कॉन्फिगरेशन फाइल तयार करा

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### चरण 3: फाइन-ट्यूनिंग कार्यान्वित करा

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### उदाहरण 3: मेमरी कार्यक्षमतेसाठी QLoRA फाइन-ट्यूनिंग

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## सर्वोत्तम पद्धती आणि मार्गदर्शक तत्त्वे

### डेटा तयारी

**1. गुणवत्तेवर भर द्या**
- मोठ्या प्रमाणातील खराब डेटापेक्षा उच्च-गुणवत्तेच्या, विविध उदाहरणांना प्राधान्य द्या
- डेटा तुमच्या लक्ष्य उपयोग प्रकरणाचे प्रतिनिधित्व करत असल्याची खात्री करा
- डेटा सातत्याने स्वच्छ करा आणि पूर्व-प्रक्रिया करा

**2. डेटा स्वरूप आणि टेम्पलेट्स**
- सर्व प्रशिक्षण उदाहरणांमध्ये सातत्यपूर्ण स्वरूपन वापरा
- तुमच्या उपयोग प्रकरणाशी जुळणारे स्पष्ट इनपुट-आउटपुट टेम्पलेट्स तयार करा
- इन्स्ट्रक्शन-ट्यून केलेल्या मॉडेल्ससाठी योग्य इन्स्ट्रक्शन स्वरूपन समाविष्ट करा

**3. डेटासेट विभाजन**
- 10-20% डेटा व्हॅलिडेशनसाठी राखून ठेवा
- ट्रेन/व्हॅलिडेशन विभाजनांमध्ये समान वितरण राखा
- वर्गीकरण कार्यांसाठी स्ट्रॅटिफाइड सॅम्पलिंगचा विचार करा

### प्रशिक्षण कॉन्फिगरेशन

**1. लर्निंग रेट निवड**
- फाइन-ट्यूनिंगसाठी लहान लर्निंग रेट्स (1e-5 ते 1e-4) सह प्रारंभ करा
- चांगल्या अभिसरणासाठी लर्निंग रेट शेड्युलिंग वापरा
- लॉस कर्व्ह्सचे निरीक्षण करून दर समायोजित करा

**2. बॅच साइज ऑप्टिमायझेशन**
- उपलब्ध मेमरीसह बॅच साइज संतुलित करा
- मोठ्या प्रभावी बॅच साइजसाठी ग्रेडियंट अॅक्युम्युलेशन वापरा
- बॅच साइज आणि लर्निंग रेटमधील संबंध विचारात घ्या

**3. प्रशिक्षण कालावधी**
- ओव्हरफिटिंग टाळण्यासाठी व्हॅलिडेशन मेट्रिक्सचे निरीक्षण करा
- व्हॅलिडेशन कामगिरी स्थिर झाल्यावर अर्ली स्टॉपिंग वापरा
- पुनर्प्राप्ती आणि विश्लेषणासाठी नियमितपणे चेकपॉइंट्स सेव्ह करा

### मॉडेल निवड

**1. बेस मॉडेल निवड**
- शक्य असल्यास समान डोमेनवर पूर्व-प्रशिक्षित मॉडेल्स निवडा
- तुमच्या संगणकीय मर्यादांशी संबंधित मॉडेल आकार विचारात घ्या
- व्यावसायिक उपयोगासाठी परवाना आवश्यकता मूल्यांकन करा

**2. फाइन-ट्यूनिंग पद्धती निवड**
- संसाधन-आधारित वातावरणासाठी LoRA/QLoRA वापरा
- जास्तीत जास्त कामगिरी महत्त्वाची असल्यास पूर्ण फाइन-ट्यूनिंग निवडा
- अनेक कार्य परिस्थितीसाठी अडॅप्टर-आधारित दृष्टिकोन विचारात घ्या

### संसाधन व्यवस्थापन

**1. हार्डवेअर ऑप्टिमायझेशन**
- तुमच्या मॉडेल आकार आणि पद्धतीसाठी योग्य हार्डवेअर निवडा
- ग्रेडियंट चेकपॉइंटिंगसह GPU मेमरी कार्यक्षमतेने वापरा
- मोठ्या मॉडेल्ससाठी क्लाउड-आधारित उपायांचा विचार करा

**2. मेमरी व्यवस्थापन**
- उपलब्ध असल्यास मिक्स्ड प्रिसिजन प्रशिक्षण वापरा
- मेमरी मर्यादांसाठी ग्रेडियंट अॅक्युम्युलेशन अंमलात आणा
- प्रशिक्षणादरम्यान GPU मेमरी वापराचे निरीक्षण करा

## प्रगत तंत्रज्ञान

### मल्टी-अडॅप्टर प्रशिक्षण

मॉडेल शेअर करताना वेगवेगळ्या कार्यांसाठी अनेक अडॅप्टर प्रशिक्षण द्या:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### हायपरपॅरामीटर ऑप्टिमायझेशन

सिस्टेमॅटिक हायपरपॅरामीटर ट्यूनिंग अंमलात आणा:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### सानुकूल लॉस फंक्शन्स

डोमेन-विशिष्ट लॉस फंक्शन्स अंमलात आणा:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## मूल्यांकन आणि निरीक्षण

### मेट्रिक्स आणि मूल्यांकन

**1. मानक मेट्रिक्स**
- **अचूकता**: वर्गीकरण कार्यांसाठी एकूण शुद्धता
- **पर्प्लेक्सिटी**: भाषा मॉडेलिंग गुणवत्ता मोजमाप
- **BLEU/ROUGE**: मजकूर निर्मिती आणि सारांश गुणवत्ता
- **F1 स्कोअर**: वर्गीकरणासाठी संतुलित प्रिसिजन आणि रिकॉल

**2. डोमेन-विशिष्ट मेट्रिक्स**
- **कार्य-विशिष्ट बेंचमार्क्स**: तुमच्या डोमेनसाठी स्थापित बेंचमार्क्स वापरा
- **मानवी मूल्यांकन**: व्यक्तिनिष्ठ कार्यांसाठी मानवी मूल्यांकन समाविष्ट करा
- **व्यवसाय मेट्रिक्स**: वास्तविक व्यवसाय उद्दिष्टांशी जुळवा

**3. मूल्यांकन सेटअप**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### प्रशिक्षण प्रगतीचे निरीक्षण

**1. लॉस ट्रॅकिंग**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. व्हॅलिडेशन निरीक्षण**
- प्रशिक्षण लॉससह व्हॅलिडेशन लॉस ट्रॅक करा
- ओव्हरफिटिंगच्या चिन्हांसाठी निरीक्षण करा (प्रशिक्षण लॉस कमी होत असताना व्हॅलिडेशन लॉस वाढतो)
- व्हॅलिडेशन मेट्रिक्सवर आधारित अर्ली स्टॉपिंग वापरा

**3. संसाधन निरीक्षण**
- GPU/CPU उपयोगाचे निरीक्षण करा
- मेमरी वापराचे नमुने ट्रॅक करा
- प्रशिक्षण गती आणि थ्रूपुटचे निरीक्षण करा

## सामान्य आव्हाने आणि उपाय

### आव्हान 1: ओव्हरफिटिंग

**लक्षणे:**
- प्रशिक्षण लॉस सतत कमी होत असतो तर व्हॅलिडेशन लॉस वाढतो
- प्रशिक्षण आणि व्हॅलिडेशन कामगिरीमध्ये मोठी तफावत
- नवीन डेटावर खराब सामान्यीकरण

**उपाय:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### आव्हान 2: मेमरी मर्यादा

**उपाय:**
- ग्रेडियंट चेकपॉइंटिंग वापरा
- ग्रेडियंट अॅक्युम्युलेशन अंमलात आणा
- संसाधन-आधारित पद्धती (LoRA, QLoRA) निवडा
- मोठ्या मॉडेल्ससाठी मॉडेल पॅरॅललिझम वापरा

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### आव्हान 3: प्रशिक्षण मंद गती

**उपाय:**
- डेटा लोडिंग पाइपलाइन्स ऑप्टिमाइझ करा
- मिक्स्ड प्रिसिजन प्रशिक्षण वापरा
- कार्यक्षम बॅचिंग रणनीती अंमलात आणा
- मोठ्या डेटासेटसाठी वितरित प्रशिक्षणाचा विचार करा

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### आव्हान 4: खराब कामगिरी

**निदान चरण:**
1. डेटा गुणवत्ता आणि स्वरूपन सत्यापित करा
2. लर्निंग रेट आणि प्रशिक्षण कालावधी तपासा
3. बेस मॉडेल निवड मूल्यांकन करा
4. पूर्व-प्रक्रिया आणि टोकनायझेशन पुनरावलोकन करा

**उपाय:**
- प्रशिक्षण डेटा विविधता वाढवा
- लर्निंग रेट शेड्यूल समायोजित करा
- वेगवेगळ्या बेस मॉडेल्स वापरून पहा
- डेटा ऑगमेंटेशन तंत्र अंमलात आणा

## निष्कर्ष

फाइन-ट्यूनिंग ही एक शक्तिशाली तंत्र आहे जी अत्याधुनिक AI क्षमता सर्वांसाठी उपलब्ध करते. Microsoft Olive सारख्या ट

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.