<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "27be883865b4bad1e3c7e02c696da642",
  "translation_date": "2025-09-17T21:31:20+00:00",
  "source_file": "Module03/01.SLMAdvancedLearning.md",
  "language_code": "mr"
}
-->
# рд╡рд┐рднрд╛рдЧ 1: SLM рдкреНрд░рдЧрдд рд╢рд┐рдХреНрд╖рдг - рдкрд╛рдпрд╛ рдЖрдгрд┐ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди

рд▓рд╣рд╛рди рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕ (SLMs) рд╣реЗ EdgeAI рдордзреАрд▓ рдПрдХ рдорд╣рддреНрддреНрд╡рд╛рдЪреЗ рдкреНрд░рдЧрдд рддрдВрддреНрд░рдЬреНрдЮрд╛рди рдЖрд╣реЗ, рдЬреЗ рдорд░реНрдпрд╛рджрд┐рдд рд╕рдВрд╕рд╛рдзрди рдЕрд╕рд▓реЗрд▓реНрдпрд╛ рдЙрдкрдХрд░рдгрд╛рдВрд╡рд░ рдкреНрд░рдЧрдд рдиреИрд╕рд░реНрдЧрд┐рдХ рднрд╛рд╖рд╛ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХреНрд╖рдорддрд╛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ. SLMs рдкреНрд░рднрд╛рд╡реАрдкрдгреЗ рддреИрдирд╛рдд рдХрд░рдгреЗ, рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдХрд░рдгреЗ рдЖрдгрд┐ рддреНрдпрд╛рдВрдЪрд╛ рдЙрдкрдпреЛрдЧ рдХрд╕рд╛ рдХрд░рд╛рдпрдЪрд╛ рд╣реЗ рд╕рдордЬреВрди рдШреЗрдгреЗ, рдПрдЬ-рдЖрдзрд╛рд░рд┐рдд AI рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕ рддрдпрд╛рд░ рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА рдЕрддреНрдпрд╛рд╡рд╢реНрдпрдХ рдЖрд╣реЗ.

## рдкрд░рд┐рдЪрдп

рдпрд╛ рдзрдбреНрдпрд╛рдд, рдЖрдкрдг рд▓рд╣рд╛рди рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕ (SLMs) рдЖрдгрд┐ рддреНрдпрд╛рдВрдЪреНрдпрд╛ рдкреНрд░рдЧрдд рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА рдзреЛрд░рдгрд╛рдВрдЪрд╛ рдЕрднреНрдпрд╛рд╕ рдХрд░реВ. рдЖрдкрдг SLMs рдЪреЗ рдореВрд▓рднреВрдд рд╕рдВрдХрд▓реНрдкрдирд╛, рддреНрдпрд╛рдВрдЪреЗ рдкреЕрд░рд╛рдореАрдЯрд░ рдорд░реНрдпрд╛рджрд╛ рдЖрдгрд┐ рд╡рд░реНрдЧреАрдХрд░рдг, рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рддрдВрддреНрд░ рдЖрдгрд┐ рдПрдЬ рд╕рдВрдЧрдгрди рд╡рд╛рддрд╛рд╡рд░рдгрд╛рд╕рд╛рдареА рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рддреИрдирд╛рддреА рдзреЛрд░рдгреЗ рдпрд╛рдВрдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдХрд░реВ.

## рд╢рд┐рдХрдгреНрдпрд╛рдЪреА рдЙрджреНрджрд┐рд╖реНрдЯреЗ

рдпрд╛ рдзрдбреНрдпрд╛рдЪреНрдпрд╛ рд╢реЗрд╡рдЯреА, рдЖрдкрдг рд╣реЗ рдХрд░реВ рд╢рдХрд╛рд▓:

- ЁЯФв рд▓рд╣рд╛рди рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕рдЪреНрдпрд╛ рдкреЕрд░рд╛рдореАрдЯрд░ рдорд░реНрдпрд╛рджрд╛ рдЖрдгрд┐ рд╡рд░реНрдЧреАрдХрд░рдг рд╕рдордЬреВрди рдШреНрдпрд╛.
- ЁЯЫая╕П рдПрдЬ рдЙрдкрдХрд░рдгрд╛рдВрд╡рд░ SLM рддреИрдирд╛рддреАрд╕рд╛рдареА рдорд╣рддреНрддреНрд╡рд╛рдЪреА рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рддрдВрддреНрд░реЗ рдУрд│рдЦрд╛.
- ЁЯЪА SLMs рд╕рд╛рдареА рдкреНрд░рдЧрдд рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдЖрдгрд┐ рдХреЙрдореНрдкреНрд░реЗрд╢рди рдзреЛрд░рдгреЗ рдЕрдВрдорд▓рд╛рдд рдЖрдгрд╛.

## SLM рдкреЕрд░рд╛рдореАрдЯрд░ рдорд░реНрдпрд╛рджрд╛ рдЖрдгрд┐ рд╡рд░реНрдЧреАрдХрд░рдг рд╕рдордЬреВрди рдШреЗрдгреЗ

рд▓рд╣рд╛рди рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕ (SLMs) рд╣реЗ AI рдореЙрдбреЗрд▓реНрд╕ рдЖрд╣реЗрдд, рдЬреЗ рдореЛрдареНрдпрд╛ рдореЙрдбреЗрд▓реНрд╕рдЪреНрдпрд╛ рддреБрд▓рдиреЗрдд рдЦреВрдкрдЪ рдХрдореА рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕рд╕рд╣ рдиреИрд╕рд░реНрдЧрд┐рдХ рднрд╛рд╖рд╛ рд╕рд╛рдордЧреНрд░реА рдкреНрд░рдХреНрд░рд┐рдпрд╛, рд╕рдордЬрдгреЗ рдЖрдгрд┐ рдирд┐рд░реНрдорд╛рдг рдХрд░рдгреЗ рдпрд╛рд╕рд╛рдареА рдбрд┐рдЭрд╛рдЗрди рдХреЗрд▓реЗрд▓реЗ рдЖрд╣реЗрдд. рдЬрд┐рдереЗ рдореЛрдареНрдпрд╛ рднрд╛рд╖рд╛ рдореЙрдбреЗрд▓реНрд╕ (LLMs) рдордзреНрдпреЗ рдЕрдмреНрдЬрд╛рд╡рдзреА рддреЗ рдЯреНрд░рд┐рд▓рд┐рдпрди рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕ рдЕрд╕рддрд╛рдд, рддрд┐рдереЗ SLMs рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЖрдгрд┐ рдПрдЬ рддреИрдирд╛рддреАрд╕рд╛рдареА рдЦрд╛рд╕ рдбрд┐рдЭрд╛рдЗрди рдХреЗрд▓реЗрд▓реЗ рдЕрд╕рддрд╛рдд.

рдкреЕрд░рд╛рдореАрдЯрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдлреНрд░реЗрдорд╡рд░реНрдХ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ SLMs рдЪреНрдпрд╛ рд╡рд┐рд╡рд┐рдз рд╢реНрд░реЗрдгреА рдЖрдгрд┐ рддреНрдпрд╛рдВрдЪреНрдпрд╛ рдпреЛрдЧреНрдп рдЙрдкрдпреЛрдЧ рдкреНрд░рдХрд░рдгреЗ рд╕рдордЬреВрди рдШреЗрдгреНрдпрд╛рд╕ рдорджрдд рдХрд░рддреЗ. рд╣реЗ рд╡рд░реНрдЧреАрдХрд░рдг рд╡рд┐рд╢рд┐рд╖реНрдЯ рдПрдЬ рд╕рдВрдЧрдгрди рдкрд░рд┐рд╕реНрдерд┐рддреАрд╕рд╛рдареА рдпреЛрдЧреНрдп рдореЙрдбреЗрд▓ рдирд┐рд╡рдбрдгреНрдпрд╛рд╕рд╛рдареА рдорд╣рддреНрддреНрд╡рд╛рдЪреЗ рдЖрд╣реЗ.

### рдкреЕрд░рд╛рдореАрдЯрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдлреНрд░реЗрдорд╡рд░реНрдХ

рдкреЕрд░рд╛рдореАрдЯрд░ рдорд░реНрдпрд╛рджрд╛ рд╕рдордЬреВрди рдШреЗрдгреЗ рд╡рд┐рд╡рд┐рдз рдПрдЬ рд╕рдВрдЧрдгрди рдкрд░рд┐рд╕реНрдерд┐рддреАрд╕рд╛рдареА рдпреЛрдЧреНрдп рдореЙрдбреЗрд▓реНрд╕ рдирд┐рд╡рдбрдгреНрдпрд╛рдд рдорджрдд рдХрд░рддреЗ:

- **ЁЯФм рдорд╛рдпрдХреНрд░реЛ SLMs**: 100M - 1.4B рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕ (рдореЛрдмрд╛рдИрд▓ рдЙрдкрдХрд░рдгрд╛рдВрд╕рд╛рдареА рдЕрд▓реНрдЯреНрд░рд╛-рд▓рд╛рдЗрдЯрд╡реЗрдЯ)
- **ЁЯУ▒ рд▓рд╣рд╛рди SLMs**: 1.5B - 13.9B рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕ (рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЖрдгрд┐ рдХрд╛рд░реНрдпрдХреНрд╖рдорддреЗрдЪрд╛ рд╕рдорддреЛрд▓)
- **тЪЦя╕П рдордзреНрдпрдо SLMs**: 14B - 30B рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕ (LLM рдХреНрд╖рдорддрд╛рдВрдЪреНрдпрд╛ рдЬрд╡рд│ рдЬрд╛рддрд╛рдирд╛ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЯрд┐рдХрд╡реВрди рдареЗрд╡рдгреЗ)

рд╕рдВрд╢реЛрдзрди рд╕рдореБрджрд╛рдпрд╛рдордзреНрдпреЗ рдЕрдЪреВрдХ рдорд░реНрдпрд╛рджрд╛ рдЕрджреНрдпрд╛рдк рдкреНрд░рд╡рд╛рд╣реА рдЖрд╣реЗ, рдкрд░рдВрддреБ рдмрд╣реБрддреЗрдХ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ 30 рдЕрдмреНрдЬ рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕рдкреЗрдХреНрд╖рд╛ рдХрдореА рдореЙрдбреЗрд▓реНрд╕рдирд╛ "рд▓рд╣рд╛рди" рдорд╛рдирддрд╛рдд, рддрд░ рдХрд╛рд╣реА рд╕реНрд░реЛрдд рд╣реА рдорд░реНрдпрд╛рджрд╛ 10 рдЕрдмреНрдЬ рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕рдкрд░реНрдпрдВрдд рдЖрдгрддрд╛рдд.

### SLMs рдЪреЗ рдореБрдЦреНрдп рдлрд╛рдпрджреЗ

SLMs рдордзреНрдпреЗ рдХрд╛рд╣реА рдореВрд▓рднреВрдд рдлрд╛рдпрджреЗ рдЖрд╣реЗрдд, рдЬреЗ рддреНрдпрд╛рдВрдирд╛ рдПрдЬ рд╕рдВрдЧрдгрди рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рдЖрджрд░реНрд╢ рдмрдирд╡рддрд╛рдд:

**рдСрдкрд░реЗрд╢рдирд▓ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛**: SLMs рдордзреНрдпреЗ рдХрдореА рдкреЕрд░рд╛рдореАрдЯрд░реНрд╕ рдЕрд╕рд▓реНрдпрд╛рдореБрд│реЗ, рддреНрдпрд╛рдВрдЪреА рдЗрдиреНрдлрд░рдиреНрд╕ рд╡реЗрд│ рдЬрд▓рдж рдЕрд╕рддреЗ, рдЬреА рд░рд┐рдЕрд▓-рдЯрд╛рдЗрдо рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рдЖрджрд░реНрд╢ рдЖрд╣реЗ. рддреНрдпрд╛рдВрдирд╛ рдХрдореА рд╕рдВрдЧрдгрдХреАрдп рд╕рдВрд╕рд╛рдзрдиреЗ рд▓рд╛рдЧрддрд╛рдд, рдЬреНрдпрд╛рдореБрд│реЗ рдорд░реНрдпрд╛рджрд┐рдд рд╕рдВрд╕рд╛рдзрди рдЕрд╕рд▓реЗрд▓реНрдпрд╛ рдЙрдкрдХрд░рдгрд╛рдВрд╡рд░ рддреИрдирд╛рдд рдХрд░рдгреЗ рд╢рдХреНрдп рд╣реЛрддреЗ, рдКрд░реНрдЬрд╛ рдХрдореА рд▓рд╛рдЧрддреЗ рдЖрдгрд┐ рдХрд╛рд░реНрдмрди рдлреВрдЯрдкреНрд░рд┐рдВрдЯ рдХрдореА рд░рд╛рд╣рддреЛ.

**рддреИрдирд╛рддреАрдЪреА рд▓рд╡рдЪрд┐рдХрддрд╛**: рд╣реЗ рдореЙрдбреЗрд▓реНрд╕ рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡реНрд╣рд┐рдЯреАрд╢рд┐рд╡рд╛рдп рдСрди-рдбрд┐рд╡реНрд╣рд╛рдЗрд╕ AI рдХреНрд╖рдорддрд╛ рд╕рдХреНрд╖рдо рдХрд░рддрд╛рдд, рд╕реНрдерд╛рдирд┐рдХ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХрд░реВрди рдЧреЛрдкрдиреАрдпрддрд╛ рдЖрдгрд┐ рд╕реБрд░рдХреНрд╖рд╛ рд╡рд╛рдврд╡рддрд╛рдд, рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рд╕рд╛рдиреБрдХреВрд▓рд┐рдд рдХрд░рддрд╛ рдпреЗрддрд╛рдд рдЖрдгрд┐ рд╡рд┐рд╡рд┐рдз рдПрдЬ рд╕рдВрдЧрдгрди рд╡рд╛рддрд╛рд╡рд░рдгрд╛рд╕рд╛рдареА рдпреЛрдЧреНрдп рдЖрд╣реЗрдд.

**рдЦрд░реНрдЪ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛**: SLMs рдордзреНрдпреЗ LLMs рдЪреНрдпрд╛ рддреБрд▓рдиреЗрдд рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЖрдгрд┐ рддреИрдирд╛рддреАрдЪрд╛ рдЦрд░реНрдЪ рдХрдореА рдЕрд╕рддреЛ, рдСрдкрд░реЗрд╢рдирд▓ рдЦрд░реНрдЪ рдХрдореА рд╣реЛрддреЛ рдЖрдгрд┐ рдПрдЬ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рдмрдБрдбрд╡рд┐рдбреНрдердЪреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдХрдореА рд╣реЛрддреЗ.

## рдкреНрд░рдЧрдд рдореЙрдбреЗрд▓ рдЕрдзрд┐рдЧреНрд░рд╣рдг рдзреЛрд░рдгреЗ

### рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдЗрдХреЛрд╕рд┐рд╕реНрдЯрдо

рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рд╣реЗ рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ SLMs рд╢реЛрдзрдгреНрдпрд╛рд╕рд╛рдареА рдЖрдгрд┐ рдкреНрд░рд╡реЗрд╢ рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА рдкреНрд░рд╛рдердорд┐рдХ рдХреЗрдВрджреНрд░ рдЖрд╣реЗ. рдкреНрд▓реЕрдЯрдлреЙрд░реНрдо рдореЙрдбреЗрд▓ рд╢реЛрдз рдЖрдгрд┐ рддреИрдирд╛рддреАрд╕рд╛рдареА рд╡реНрдпрд╛рдкрдХ рд╕рдВрд╕рд╛рдзрдиреЗ рдкреНрд░рджрд╛рди рдХрд░рддреЛ:

**рдореЙрдбреЗрд▓ рд╢реЛрдз рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ**: рдкреНрд▓реЕрдЯрдлреЙрд░реНрдо рдкреЕрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛, рдкрд░рд╡рд╛рдирд╛ рдкреНрд░рдХрд╛рд░ рдЖрдгрд┐ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдореЗрдЯреНрд░рд┐рдХреНрд╕рджреНрд╡рд╛рд░реЗ рдкреНрд░рдЧрдд рдлрд┐рд▓реНрдЯрд░рд┐рдВрдЧ рдСрдлрд░ рдХрд░рддреЛ. рд╡рд╛рдкрд░рдХрд░реНрддреЗ рд╕рд╛рдЗрдб-рдмрд╛рдп-рд╕рд╛рдЗрдб рдореЙрдбреЗрд▓ рддреБрд▓рдирд╛ рд╕рд╛рдзрдиреЗ, рд░рд┐рдЕрд▓-рдЯрд╛рдЗрдо рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдмреЗрдВрдЪрдорд╛рд░реНрдХ рдЖрдгрд┐ рдореВрд▓реНрдпрд╛рдВрдХрди рдкрд░рд┐рдгрд╛рдо, рддрд╕реЗрдЪ рддреНрд╡рд░рд┐рдд рдЪрд╛рдЪрдгреАрд╕рд╛рдареА WebGPU рдбреЗрдореЛрдордзреНрдпреЗ рдкреНрд░рд╡реЗрд╢ рдХрд░реВ рд╢рдХрддрд╛рдд.

**рдХреНрдпреБрд░реЗрдЯреЗрдб SLM рд╕рдВрдЧреНрд░рд╣**: рд▓реЛрдХрдкреНрд░рд┐рдп рдореЙрдбреЗрд▓реНрд╕рдордзреНрдпреЗ рдкреНрд░рдЧрдд рддрд░реНрдХрд╢рдХреНрддреА рдХрд╛рд░реНрдпрд╛рдВрд╕рд╛рдареА Phi-4-mini-3.8B, рдмрд╣реБрднрд╛рд╖рд┐рдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА Qwen3 рдорд╛рд▓рд┐рдХрд╛ (0.6B/1.7B/4B), рдХрд╛рд░реНрдпрдХреНрд╖рдо рд╕рд╛рдорд╛рдиреНрдп-рдЙрджреНрджреЗрд╢ рдХрд╛рд░реНрдпрд╛рдВрд╕рд╛рдареА Google Gemma3 рдЖрдгрд┐ рдЕрд▓реНрдЯреНрд░рд╛-рд▓реЛ рдкреНрд░рд┐рд╕рд┐рдЬрди рддреИрдирд╛рддреАрд╕рд╛рдареА BitNET рд╕рд╛рд░рдЦреНрдпрд╛ рдкреНрд░рд╛рдпреЛрдЧрд┐рдХ рдореЙрдбреЗрд▓реНрд╕рдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдЖрд╣реЗ. рдкреНрд▓реЕрдЯрдлреЙрд░реНрдордордзреНрдпреЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдбреЛрдореЗрдирд╕рд╛рдареА рд╡рд┐рд╢реЗрд╖ рдореЙрдбреЗрд▓реНрд╕рд╕рд╣ рд╕рдореБрджрд╛рдп-рдЪрд╛рд▓рд┐рдд рд╕рдВрдЧреНрд░рд╣ рджреЗрдЦреАрд▓ рдЖрд╣реЗрдд, рддрд╕реЗрдЪ рд╡рд┐рд╡рд┐рдз рдЙрдкрдпреЛрдЧ рдкреНрд░рдХрд░рдгрд╛рдВрд╕рд╛рдареА рдкреНрд░реА-рдЯреНрд░реЗрди рдХреЗрд▓реЗрд▓реЗ рдЖрдгрд┐ рдЗрдиреНрд╕реНрдЯреНрд░рдХреНрд╢рди-рдЯреНрдпреВрди рдХреЗрд▓реЗрд▓реЗ рдкреНрд░рдХрд╛рд░ рдЖрд╣реЗрдд.

### Azure AI Foundry рдореЙрдбреЗрд▓ рдХреЕрдЯрд▓реЙрдЧ

Azure AI Foundry рдореЙрдбреЗрд▓ рдХреЕрдЯрд▓реЙрдЧ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ-рдЧреНрд░реЗрдб SLMs рд╕рд╛рдареА рд╡рд░реНрдзрд┐рдд рдПрдХрддреНрд░реАрдХрд░рдг рдХреНрд╖рдорддрд╛рдВрд╕рд╣ рдкреНрд░рд╡реЗрд╢ рдкреНрд░рджрд╛рди рдХрд░рддреЛ:

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ рдПрдХрддреНрд░реАрдХрд░рдг**: рдХреЕрдЯрд▓реЙрдЧрдордзреНрдпреЗ Azure рджреНрд╡рд╛рд░реЗ рдереЗрдЯ рд╡рд┐рдХрд▓реНрдпрд╛ рдЬрд╛рдгрд╛рд▒реНрдпрд╛ рдореЙрдбреЗрд▓реНрд╕рдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдЖрд╣реЗ, рдЬреНрдпрд╛рдордзреНрдпреЗ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ-рдЧреНрд░реЗрдб рд╕рдорд░реНрдерди рдЖрдгрд┐ SLA рдЖрд╣реЗрдд. рдпрд╛рдордзреНрдпреЗ рдкреНрд░рдЧрдд рддрд░реНрдХрд╢рдХреНрддреА рдХреНрд╖рдорддрд╛рдВрд╕рд╛рдареА Phi-4-mini-3.8B рдЖрдгрд┐ рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреАрд╕рд╛рдареА Llama 3-8B рдпрд╛рдВрдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдЖрд╣реЗ. рддрд╕реЗрдЪ, Qwen3 8B рд╕рд╛рд░рдЦреНрдпрд╛ рд╡рд┐рд╢реНрд╡рд╛рд╕рд╛рд░реНрд╣ рддреГрддреАрдп-рдкрдХреНрд╖реАрдп рдУрдкрди рд╕реЛрд░реНрд╕ рдореЙрдбреЗрд▓реНрд╕рдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдЖрд╣реЗ.

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ рдлрд╛рдпрджреЗ**: рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ, рдирд┐рд░реАрдХреНрд╖рдгрдХреНрд╖рдорддрд╛ рдЖрдгрд┐ рдЬрдмрд╛рдмрджрд╛рд░ AI рд╕рд╛рдареА рдЕрдВрдЧрднреВрдд рд╕рд╛рдзрдиреЗ, рдореЙрдбреЗрд▓ рдХреБрдЯреБрдВрдмрд╛рдВрдордзреНрдпреЗ рдлрдВрдЧрд┐рдмрд▓ рдкреНрд░реЛрд╡реНрд╣рд┐рдЬрди рдХреЗрд▓реЗрд▓реЗ рдереНрд░реВрдкреБрдЯ, рдереЗрдЯ Microsoft рд╕рдорд░реНрдердирд╛рд╕рд╣ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ SLA, рдПрдХрддреНрд░рд┐рдд рд╕реБрд░рдХреНрд╖рд╛ рдЖрдгрд┐ рдЕрдиреБрдкрд╛рд▓рди рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ, рддрд╕реЗрдЪ рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ рдЕрдиреБрднрд╡ рд╡рд╛рдврд╡рддрд╛рдд.

## рдкреНрд░рдЧрдд рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдЖрдгрд┐ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рддрдВрддреНрд░

### Llama.cpp рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдлреНрд░реЗрдорд╡рд░реНрдХ

Llama.cpp рдПрдЬ рддреИрдирд╛рддреАрд╕рд╛рдареА рдЬрд╛рд╕реНрддреАрдд рдЬрд╛рд╕реНрдд рдХрд╛рд░реНрдпрдХреНрд╖рдорддреЗрд╕рд╛рдареА рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рддрдВрддреНрд░ рдкреНрд░рджрд╛рди рдХрд░рддреЗ:

**рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдкрджреНрдзрддреА**: рдлреНрд░реЗрдорд╡рд░реНрдХ рд╡рд┐рд╡рд┐рдз рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рд╕реНрддрд░рд╛рдВрдирд╛ рд╕рдорд░реНрдерди рджреЗрддреЗ, рдЬреНрдпрд╛рдд Q4_0 (4-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдЙрддреНрдХреГрд╖реНрдЯ рдЖрдХрд╛рд░ рдХрдореА рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА - Qwen3-0.6B рдореЛрдмрд╛рдЗрд▓ рддреИрдирд╛рддреАрд╕рд╛рдареА рдЖрджрд░реНрд╢), Q5_1 (5-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдЧреБрдгрд╡рддреНрддрд╛ рдЖрдгрд┐ рдХреЙрдореНрдкреНрд░реЗрд╢рди рдпрд╛рдордзреНрдпреЗ рд╕рдорддреЛрд▓ рд░рд╛рдЦрдгреНрдпрд╛рд╕рд╛рдареА - Phi-4-mini-3.8B рдПрдЬ рдЗрдиреНрдлрд░рдиреНрд╕рд╕рд╛рдареА рдпреЛрдЧреНрдп), рдЖрдгрд┐ Q8_0 (рдореВрд│ рдЧреБрдгрд╡рддреНрддреЗрд╕рд╛рдареА рдЬрд╡рд│рдЬрд╡рд│ - Google Gemma3 рдЙрддреНрдкрд╛рджрди рд╡рд╛рдкрд░рд╛рд╕рд╛рдареА рд╢рд┐рдлрд╛рд░рд╕ рдХреЗрд▓реЗрд▓реЗ) рдпрд╛рдВрдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдЖрд╣реЗ. BitNET рдЕрд▓реНрдЯреНрд░рд╛-рдХреЙрдореНрдкреНрд░реЗрд╢рди рдкрд░рд┐рд╕реНрдерд┐рддреАрд╕рд╛рдареА 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рдирд╕рд╣ рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдЖрд╣реЗ.

**рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА рдлрд╛рдпрджреЗ**: SIMD рдкреНрд░рд╡реЗрдЧрд╛рд╕рд╣ CPU-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭреНрдб рдЗрдиреНрдлрд░рдиреНрд╕ рдореЗрдорд░реА-рдХрд╛рд░реНрдпрдХреНрд╖рдо рдореЙрдбреЗрд▓ рд▓реЛрдбрд┐рдВрдЧ рдЖрдгрд┐ рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА рдкреНрд░рджрд╛рди рдХрд░рддреЗ. x86, ARM рдЖрдгрд┐ Apple Silicon рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░реНрд╕рдордзреНрдпреЗ рдХреНрд░реЙрд╕-рдкреНрд▓реЕрдЯрдлреЙрд░реНрдо рд╕реБрд╕рдВрдЧрддрддрд╛ рд╣рд╛рд░реНрдбрд╡реЗрдЕрд░-рдЕрдЬреНрдЮреЗрдпрд╡рд╛рджреА рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ.

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА рдЙрджрд╛рд╣рд░рдг**:

```bash
# Clone and build llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release

# Convert Phi-4-mini model from Hugging Face to GGUF format
# First, download the model from Hugging Face
cd ..
python convert.py --outtype f16 --outfile phi-4-mini.gguf /path/to/downloaded/phi-4-mini/model

# Quantize the model to 4-bit precision (Q4_0)
./build/bin/quantize phi-4-mini.gguf phi-4-mini-q4_0.gguf q4_0

# Benchmark the model to check performance
./build/bin/llama-bench -m phi-4-mini-q4_0.gguf -p "Write a function to calculate the Fibonacci sequence"

# Run inference with the quantized model
./build/bin/main -m phi-4-mini-q4_0.gguf -n 512 -p "Explain quantum computing in simple terms"
```

**рдореЗрдорд░реА рдлреВрдЯрдкреНрд░рд┐рдВрдЯ рддреБрд▓рдирд╛**:

```python
# Python script to analyze model size differences
import os
import matplotlib.pyplot as plt
import numpy as np

# Model sizes (in GB)
models = ['Phi-4-mini', 'Qwen3-0.6B', 'Gemma3']
original_sizes = [7.6, 1.2, 4.8]  # F16 format
q4_0_sizes = [2.0, 0.35, 1.3]     # Q4_0 format
q8_0_sizes = [3.9, 0.68, 2.5]     # Q8_0 format

# Calculate reduction percentages
q4_reduction = [(orig - q4) / orig * 100 for orig, q4 in zip(original_sizes, q4_0_sizes)]
q8_reduction = [(orig - q8) / orig * 100 for orig, q8 in zip(original_sizes, q8_0_sizes)]

print("Model Size Reduction:")
for i, model in enumerate(models):
    print(f"{model}: Q4_0 reduces size by {q4_reduction[i]:.1f}%, Q8_0 reduces size by {q8_reduction[i]:.1f}%")

# Memory usage during inference will be approximately:
# - Original F16: ~2x model size
# - Q4_0: ~1.2x model size
# - Q8_0: ~1.5x model size
```

### Microsoft Olive рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рд╕реВрдЯ

Microsoft Olive рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдгрд╛рд╕рд╛рдареА рдбрд┐рдЭрд╛рдЗрди рдХреЗрд▓реЗрд▓реНрдпрд╛ рд╡реНрдпрд╛рдкрдХ рдореЙрдбреЗрд▓ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдкреНрд░рджрд╛рди рдХрд░рддреЗ:

**рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рддрдВрддреНрд░**: рд╕реВрдЯрдордзреНрдпреЗ рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рдЕрдЪреВрдХрддрд╛ рдирд┐рд╡рдбреАрд╕рд╛рдареА рдбрд╛рдпрдиреЕрдорд┐рдХ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди (рд╡рд┐рд╢реЗрд╖рддрдГ Qwen3 рдорд╛рд▓рд┐рдХреЗрд╕рд╛рдареА рдкреНрд░рднрд╛рд╡реА), рдЧреНрд░рд╛рдл рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдЖрдгрд┐ рдСрдкрд░реЗрдЯрд░ рдлреНрдпреВрдЬрди (Google Gemma3 рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рд╕рд╛рдареА рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭ рдХреЗрд▓реЗрд▓реЗ), CPU, GPU рдЖрдгрд┐ NPU рд╕рд╛рдареА рд╣рд╛рд░реНрдбрд╡реЗрдЕрд░-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди (ARM рдЙрдкрдХрд░рдгрд╛рдВрд╡рд░реАрд▓ Phi-4-mini-3.8B рд╕рд╛рдареА рд╡рд┐рд╢реЗрд╖ рд╕рдорд░реНрдердирд╛рд╕рд╣), рдЖрдгрд┐ рдорд▓реНрдЯрд┐-рд╕реНрдЯреЗрдЬ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдкрд╛рдЗрдкрд▓рд╛рдЗрди рдпрд╛рдВрдЪрд╛ рд╕рдорд╛рд╡реЗрд╢ рдЖрд╣реЗ. BitNET рдореЙрдбреЗрд▓реНрд╕рдордзреНрдпреЗ Olive рдлреНрд░реЗрдорд╡рд░реНрдХрдордзреНрдпреЗ рд╡рд┐рд╢реЗрд╖ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдЖрд╡рд╢реНрдпрдХ рдЖрд╣реЗрдд.

**рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рд╕реНрд╡рдпрдВрдЪрд▓рди**: рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рджрд░рдореНрдпрд╛рди рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдЯреНрд░рд┐рдХ рдЯрд┐рдХрд╡реВрди рдареЗрд╡рдгреНрдпрд╛рд╕рд╛рдареА рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдкреНрд░рдХрд╛рд░рд╛рдВрдордзреНрдпреЗ рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рдмреЗрдВрдЪрдорд╛рд░реНрдХрд┐рдВрдЧ. PyTorch рдЖрдгрд┐ ONNX рд╕рд╛рд░рдЦреНрдпрд╛ рд▓реЛрдХрдкреНрд░рд┐рдп ML рдлреНрд░реЗрдорд╡рд░реНрдХрд╕рд╣ рдПрдХрддреНрд░реАрдХрд░рдг рдХреНрд▓рд╛рдЙрдб рдЖрдгрд┐ рдПрдЬ рддреИрдирд╛рддреА рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдХреНрд╖рдорддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддреЗ.

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА рдЙрджрд╛рд╣рд░рдг**:

```python
# Microsoft Olive optimization workflow for SLM
from olive.model import PyTorchModel, ONNXModel
from olive.workflows import run_workflow
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Define the workflow configuration
def create_olive_config(model_id="microsoft/phi-4-mini-instruct"):
    # Load model and create sample inputs
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)
    
    # Create sample inputs for tracing
    sample_text = "Explain the concept of edge computing"
    inputs = tokenizer(sample_text, return_tensors="pt")
    
    # Export to ONNX first
    model_path = f"{model_id.split('/')[-1]}.onnx"
    torch.onnx.export(
        model,
        (inputs["input_ids"],),
        model_path,
        input_names=["input_ids"],
        output_names=["logits"],
        dynamic_axes={
            "input_ids": {0: "batch", 1: "sequence"},
            "logits": {0: "batch", 1: "sequence"}
        },
        opset_version=15
    )
    
    # Create Olive optimization config
    config = {
        "input_model": ONNXModel(model_path),
        "systems": {
            "local_system": {
                "type": "LocalSystem"
            }
        },
        "passes": {
            # Graph optimization pass
            "graph_optimization": {
                "type": "OrtTransformersOptimization",
                "config": {
                    "optimization_options": {
                        "enable_gelu": True,
                        "enable_layer_norm": True,
                        "enable_attention": True,
                        "use_multi_head_attention": True
                    }
                }
            },
            # Quantization pass for INT8
            "quantization": {
                "type": "OrtQuantization",
                "config": {
                    "quant_mode": "static",
                    "activation_type": "int8",
                    "weight_type": "int8",
                    "op_types_to_quantize": ["MatMul", "Add", "Conv"]
                },
                "disable_search": True
            }
        },
        "engine": {
            "log_severity_level": 0,
            "cache_dir": "./cache"
        }
    }
    
    return config

# Run the optimization workflow
config = create_olive_config()
result = run_workflow(config)

# Save the optimized model
optimized_model = result.optimized_model
optimized_model.save("./optimized_phi4_mini")

# Benchmark performance comparison
print(f"Original model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
print(f"Optimized model size: {os.path.getsize('./optimized_phi4_mini/model.onnx') / (1024 * 1024):.2f} MB")
```

### Apple MLX рдлреНрд░реЗрдорд╡рд░реНрдХ

Apple MLX рд╡рд┐рд╢реЗрд╖рддрдГ Apple Silicon рдЙрдкрдХрд░рдгрд╛рдВрд╕рд╛рдареА рдбрд┐рдЭрд╛рдЗрди рдХреЗрд▓реЗрд▓реЗ рдореВрд│ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдкреНрд░рджрд╛рди рдХрд░рддреЗ:

**Apple Silicon рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди**: рдлреНрд░реЗрдорд╡рд░реНрдХ рдореЗрдЯрд▓ рдкрд░рдлреЙрд░реНрдордиреНрд╕ рд╢реЗрдбрд░реНрд╕ рдЗрдВрдЯрд┐рдЧреНрд░реЗрд╢рдирд╕рд╣ рдПрдХрддреНрд░рд┐рдд рдореЗрдорд░реА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рдЪрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ, рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рдорд┐рд╢реНрд░рд┐рдд рдЕрдЪреВрдХрддрд╛ рдЗрдиреНрдлрд░рдиреНрд╕ (рд╡рд┐рд╢реЗрд╖рддрдГ Google Gemma3 рд╕рд╣ рдкреНрд░рднрд╛рд╡реА), рдЖрдгрд┐ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭ рдХреЗрд▓реЗрд▓реЗ рдореЗрдорд░реА рдмрдБрдбрд╡рд┐рдбреНрде рдЙрдкрдпреЛрдЧ. Phi-4-mini-3.8B M-рд╕реАрд░реАрдЬ рдЪрд┐рдкреНрд╕рд╡рд░ рдЕрдкрд╡рд╛рджрд╛рддреНрдордХ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рджрд░реНрд╢рд╡рддреЗ, рддрд░ Qwen3-1.7B MacBook Air рддреИрдирд╛рддреАрд╕рд╛рдареА рдЗрд╖реНрдЯрддрдо рд╕рдорддреЛрд▓ рдкреНрд░рджрд╛рди рдХрд░рддреЗ.

**рд╡рд┐рдХрд╛рд╕ рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ**: NumPy-рд╕реБрд╕рдВрдЧрдд рдЕреЕрд░реЗ рдСрдкрд░реЗрд╢рдиреНрд╕рд╕рд╣ Python рдЖрдгрд┐ Swift API рд╕рдорд░реНрдерди, рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рднрд┐рдиреНрдирддрд╛ рдХреНрд╖рдорддрд╛, рдЖрдгрд┐ Apple рд╡рд┐рдХрд╛рд╕ рд╕рд╛рдзрдирд╛рдВрд╕рд╣ рдЕрдЦрдВрдб рдПрдХрддреНрд░реАрдХрд░рдг рдПрдХ рд╡реНрдпрд╛рдкрдХ рд╡рд┐рдХрд╛рд╕ рд╡рд╛рддрд╛рд╡рд░рдг рдкреНрд░рджрд╛рди рдХрд░рддреЗ.

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА рдЙрджрд╛рд╣рд░рдг**:

```python
# Apple MLX optimization for Phi-4-mini model
import mlx.core as mx
import mlx.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from mlx_lm import load, generate

# Install the required packages
# pip install mlx transformers mlx-lm

# Load the Phi-4-mini model with MLX optimization
model_path = "microsoft/phi-4-mini-instruct"
model, tokenizer = load(model_path)

# Convert to float16 for better performance on Apple Silicon
model.convert_to_float16()

# Sample inference
prompt = "Write a function to find prime numbers in Python"
results = generate(
    model, 
    tokenizer,
    prompt=prompt,
    max_tokens=512,
    temperature=0.7,
    top_p=0.9,
)

print(results[0]["generation"])

# Benchmark the model
import time

def benchmark_inference(model, tokenizer, prompt, runs=10):
    # Warmup
    generate(model, tokenizer, prompt=prompt, max_tokens=128)
    
    # Benchmark
    start_time = time.time()
    for _ in range(runs):
        generate(model, tokenizer, prompt=prompt, max_tokens=128)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / runs
    return avg_time

avg_inference_time = benchmark_inference(model, tokenizer, "Explain quantum computing")
print(f"Average inference time: {avg_inference_time:.4f} seconds")

# Save the optimized model for later use
model.save_weights("phi4_mini_optimized_mlx.npz")
```

## рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреА рдЖрдгрд┐ рдЗрдиреНрдлрд░рдиреНрд╕ рдзреЛрд░рдгреЗ

### Ollama: рд╕реЛрдкреА рд╕реНрдерд╛рдирд┐рдХ рддреИрдирд╛рддреА

Ollama рд╕реНрдерд╛рдирд┐рдХ рдЖрдгрд┐ рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдгрд╛рд╕рд╛рдареА рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ-рд░реЗрдбреА рд╡реИрд╢рд┐рд╖реНрдЯреНрдпрд╛рдВрд╕рд╣ SLM рддреИрдирд╛рддреА рд╕реБрд▓рдн рдХрд░рддреЗ:

**рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛**: рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рдореЙрдбреЗрд▓ рдкреБрд▓рд┐рдВрдЧ рдЖрдгрд┐ рдХреЕрд╢рд┐рдВрдЧрд╕рд╣ рдПрдХ-рдХрдорд╛рдВрдб рдореЙрдбреЗрд▓ рд╕реНрдерд╛рдкрдирд╛ рдЖрдгрд┐ рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА. Phi-4-mini-3.8B, рд╕рдВрдкреВрд░реНрдг Qwen3 рдорд╛рд▓рд┐рдХрд╛ (0.6B/1.7B/4B), рдЖрдгрд┐ Google Gemma3 рд╕рд╛рдареА рд╕рдорд░реНрдерди, REST API рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдПрдХрддреНрд░реАрдХрд░рдгрд╛рд╕рд╛рдареА, рддрд╕реЗрдЪ рдорд▓реНрдЯрд┐-рдореЙрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдЖрдгрд┐ рд╕реНрд╡рд┐рдЪрд┐рдВрдЧ рдХреНрд╖рдорддрд╛. BitNET рдореЙрдбреЗрд▓реНрд╕рд╕рд╛рдареА 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рд╕рдорд░реНрдердирд╛рд╕рд╛рдареА рдкреНрд░рд╛рдпреЛрдЧрд┐рдХ рдмрд┐рд▓реНрдб рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди рдЖрд╡рд╢реНрдпрдХ рдЖрд╣реЗ.

**рдкреНрд░рдЧрдд рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ**: рд╕рд╛рдиреБрдХреВрд▓ рдореЙрдбреЗрд▓ рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рд╕рдорд░реНрдерди, рдХрдВрдЯреЗрдирд░рд╛рдЗрдЬреНрдб рддреИрдирд╛рддреАрд╕рд╛рдареА Dockerfile рдирд┐рд░реНрдорд┐рддреА, GPU рдкреНрд░рд╡реЗрдЧрд╛рд╕рд╣ рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рд╢реЛрдз, рдЖрдгрд┐ рдореЙрдбреЗрд▓ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рдЖрдгрд┐ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдкрд░реНрдпрд╛рдп рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рд▓рд╡рдЪрд┐рдХрддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛рдд.

### VLLM: рдЙрдЪреНрдЪ-рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЗрдиреНрдлрд░рдиреНрд╕

VLLM рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ рдкрд░рд┐рд╕реНрдерд┐рддреАрд╕рд╛рдареА рдЙрддреНрдкрд╛рджрди-рдЧреНрд░реЗрдб рдЗрдиреНрдлрд░рдиреНрд╕ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдкреНрд░рджрд╛рди рдХрд░рддреЗ:

**рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди**: PagedAttention рдореЗрдорд░реА-рдХрд╛рд░реНрдпрдХреНрд╖рдо рд▓рдХреНрд╖ рд╕рдВрдЧрдгрдиреЗрд╕рд╛рдареА (рд╡рд┐рд╢реЗрд╖рддрдГ Phi-4-mini-3.8B рдЪреНрдпрд╛ рдЯреНрд░рд╛рдиреНрд╕рдлреЙрд░реНрдорд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рд╕рд╛рдареА рдлрд╛рдпрджреЗрд╢реАрд░), рдереНрд░реВрдкреБрдЯ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рдирд╕рд╛рдареА рдбрд╛рдпрдиреЕрдорд┐рдХ рдмреЕрдЪрд┐рдВрдЧ (Qwen3 рдорд╛рд▓рд┐рдХреЗрд╕рд╛рдареА рд╕рдорд╛рдВрддрд░ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭ рдХреЗрд▓реЗрд▓реА), рдорд▓реНрдЯрд┐-GPU рд╕реНрдХреЗрд▓рд┐рдВрдЧрд╕рд╛рдареА рдЯреЗрдиреНрд╕рд░ рдкреЕрд░рд▓рд▓рд┐рдЭрдо (Google Gemma3 рд╕рдорд░реНрдерди), рдЖрдгрд┐ рд╡рд┐рд▓рдВрдм рдХрдореА рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА рд╕реНрдкреЗрдХреНрдпреБрд▓реЗрдЯрд┐рд╡реНрд╣ рдбрд┐рдХреЛрдбрд┐рдВрдЧ. BitNET рдореЙрдбреЗрд▓реНрд╕рд╕рд╛рдареА 1-рдмрд┐рдЯ рдСрдкрд░реЗрд╢рдиреНрд╕рд╕рд╛рдареА рд╡рд┐рд╢реЗрд╖ рдЗрдиреНрдлрд░рдиреНрд╕ рдХрд░реНрдирд▓ рдЖрд╡рд╢реНрдпрдХ рдЖрд╣реЗрдд.

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ рдПрдХрддреНрд░реАрдХрд░рдг**: OpenAI-рд╕реБрд╕рдВрдЧрдд API рдПрдВрдбрдкреЙрдЗрдВрдЯреНрд╕, Kubernetes рддреИрдирд╛рддреА рд╕рдорд░реНрдерди, рдирд┐рд░реАрдХреНрд╖рдг рдЖрдгрд┐ рдирд┐рд░реАрдХреНрд╖рдг рдПрдХрддреНрд░реАрдХрд░рдг, рдЖрдгрд┐ рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рд╕реНрдХреЗрд▓рд┐рдВрдЧ рдХреНрд╖рдорддрд╛ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ-рдЧреНрд░реЗрдб рддреИрдирд╛рддреА рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕ рдкреНрд░рджрд╛рди рдХрд░рддрд╛рдд.

### Foundry Local: Microsoft рдЪреЗ рдПрдЬ рд╕реЛрд▓реНрдпреВрд╢рди

Foundry Local рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ рд╡рд╛рддрд╛рд╡рд░рдгрд╛рд╕рд╛рдареА рд╡реНрдпрд╛рдкрдХ рдПрдЬ рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддреЗ:

**рдПрдЬ рд╕рдВрдЧрдгрди рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ**: рдСрдлрд▓рд╛рдЗрди-рдкреНрд░рдердо рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдбрд┐рдЭрд╛рдЗрдирд╕рд╣ рд╕рдВрд╕рд╛рдзрди рдорд░реНрдпрд╛рджрд╛ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди, рд╕реНрдерд╛рдирд┐рдХ рдореЙрдбреЗрд▓ рд░рдЬрд┐рд╕реНрдЯреНрд░реА рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди, рдЖрдгрд┐ рдПрдЬ-рдЯреВ-рдХреНрд▓рд╛рдЙрдб рд╕рдордХреНрд░рдордг рдХреНрд╖рдорддрд╛ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рдПрдЬ рддреИрдирд╛рддреА рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛рдд.

**рд╕реБрд░рдХреНрд╖рд╛ рдЖрдгрд┐ рдЕрдиреБрдкрд╛рд▓рди**: рдЧреЛрдкрдиреАрдпрддрд╛ рдЬрдкрдгреНрдпрд╛рд╕рд╛рдареА рд╕реНрдерд╛рдирд┐рдХ рдбреЗрдЯрд╛ рдкреНрд░рдХреНрд░рд┐рдпрд╛, рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдВрддреНрд░рдг, рдСрдбрд┐рдЯ рд▓реЙрдЧрд┐рдВрдЧ рдЖрдгрд┐ рдЕрдиреБрдкрд╛рд▓рди рдЕрд╣рд╡рд╛рд▓, рдЖрдгрд┐ рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдкреНрд░рд╡реЗрд╢ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдПрдЬ рддреИрдирд╛рддреАрд╕рд╛рдареА рд╡реНрдпрд╛рдкрдХ рд╕реБрд░рдХреНрд╖рд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛рдд.

## SLM рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреАрд╕рд╛рдареА рд╕рд░реНрд╡реЛрддреНрддрдо рдкрджреНрдзрддреА

### рдореЙрдбреЗрд▓ рдирд┐рд╡рдб рдорд╛рд░реНрдЧрджрд░реНрд╢рдХ рддрддреНрддреНрд╡реЗ

рдПрдЬ рддреИрдирд╛рддреАрд╕рд╛рдареА SLMs рдирд┐рд╡рдбрддрд╛рдирд╛, рдЦрд╛рд▓реАрд▓ рдШрдЯрдХрд╛рдВрдЪрд╛ рд╡рд┐рдЪрд╛рд░ рдХрд░рд╛:

**рдкреЕрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛ рд╡рд┐рдЪрд╛рд░**: рдЕрд▓реНрдЯреНрд░рд╛-рд▓рд╛рдЗрдЯрд╡реЗрдЯ рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА Qwen3-0.6B рд╕рд╛рд░рдЦреЗ рдорд╛рдпрдХреНрд░реЛ SLMs рдирд┐рд╡рдбрд╛, рд╕рдВрддреБрд▓рд┐рдд рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдкрд░рд┐рд╕реНрдерд┐рддреАрд╕рд╛рдареА Qwen3-1.7B рдХрд┐рдВрд╡рд╛ Google Gemma3 рд╕рд╛рд░рдЦреЗ рд▓рд╣рд╛рди SLMs, рдЖрдгрд┐ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЯрд┐рдХрд╡реВрди рдареЗрд╡рддрд╛рдирд╛ LLM рдХреНрд╖рдорддрд╛рдВрдЪреНрдпрд╛ рдЬрд╡рд│ рдЬрд╛рдгреНрдпрд╛рд╕рд╛рдареА Phi-4-mini-3.8B рдХрд┐рдВрд╡рд╛ Qwen3-4B рд╕рд╛рд░рдЦреЗ рдордзреНрдпрдо SLMs. BitNET рдореЙрдбреЗрд▓реНрд╕ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕рдВрд╢реЛрдзрди рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рдкреНрд░рд╛рдпреЛрдЧрд┐рдХ рдЕрд▓реНрдЯреНрд░рд╛-рдХреЙрдореНрдкреНрд░реЗрд╢рди рд╕рдХреНрд╖рдо рдХрд░рддрд╛рдд.

**рд╡рд╛рдкрд░ рдкреНрд░рдХрд░рдг рд╕рдВрд░реЗрдЦрди**: рдкреНрд░рддрд┐рд╕рд╛рдж рдЧреБрдгрд╡рддреНрддрд╛, рдЗрдиреНрдлрд░рдиреНрд╕ рдЧрддреА, рдореЗрдорд░реА рдорд░реНрдпрд╛рджрд╛, рдЖрдгрд┐ рдСрдлрд▓рд╛рдЗрди рдСрдкрд░реЗрд╢рди рдЖрд╡рд╢реНрдпрдХрддрд╛ рдпрд╛рд╕рд╛рд░рдЦреНрдпрд╛ рдШрдЯрдХрд╛рдВрдЪрд╛ рд╡рд┐рдЪрд╛рд░ рдХрд░реВрди рдореЙрдбреЗрд▓ рдХреНрд╖рдорддрд╛ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдЖрд╡рд╢реНрдпрдХрддрд╛ рдЬреБрд│рд╡рд╛.

### рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдзреЛрд░рдг рдирд┐рд╡рдб

**рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рджреГрд╖реНрдЯрд┐рдХреЛрди**: рдЧреБрдгрд╡рддреНрддрд╛ рдЖрд╡рд╢реНрдпрдХрддрд╛ рдЖрдгрд┐ рд╣рд╛рд░реНрдбрд╡реЗрдЕрд░ рдорд░реНрдпрд╛рджрд╛ рдпрд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рдпреЛрдЧреНрдп рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рд╕реНрддрд░ рдирд┐рд╡рдбрд╛. рдЬрд╛рд╕реНрддреАрдд рдЬрд╛рд╕реНрдд рдХреЙрдореНрдкреНрд░реЗрд╢рдирд╕рд╛рдареА Q4_0 рд╡рд┐рдЪрд╛рд░рд╛рдд рдШреНрдпрд╛ (Qwen3-0.6B рдореЛрдмрд╛рдЗрд▓ рддреИрдирд╛рддреАрд╕рд╛рдареА рдЖрджрд░реНрд╢), рдЧреБрдгрд╡рддреНрддрд╛-рдХреЙрдореНрдкреНрд░реЗрд╢рди рд╡реНрдпрд╛рдкрд╛рд░рд╛рд╕рд╛рдареА Q5_1 (Phi-4-mini-3.8B рдЖрдгрд┐ Google Gemma3 рд╕рд╛рдареА рдпреЛрдЧреНрдп), рдЖрдгрд┐ рдореВрд│ рдЧреБрдгрд╡рддреНрддреЗрд╕рд╛рдареА Q8_0 (Qwen3-4B рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдгрд╛рд╕рд╛рдареА рд╢рд┐рдлрд╛рд░рд╕ рдХреЗрд▓реЗрд▓реЗ). BitNET рдЪреЗ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдпрдЭреЗрд╢рди рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рдЕрддреНрдпрдВрдд рдХреЙрдореНрдкреНрд░реЗрд╢рди рдлреНрд░рдВрдЯрд┐рдпрд░ рджрд░реНрд╢рд╡рддреЗ.

**рдлреНрд░реЗрдорд╡рд░реНрдХ рдирд┐рд╡рдб**: рд▓рдХреНрд╖реНрдп рд╣рд╛рд░реНрдбрд╡реЗрдЕрд░ рдЖрдгрд┐ рддреИрдирд╛рддреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдпрд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдлреНрд░реЗрдорд╡рд░реНрдХ рдирд┐рд╡рдбрд╛. CPU-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЭреНрдб рддреИрдирд╛рддреАрд╕рд╛рдареА Llama.cpp рд╡рд╛рдкрд░рд╛, рд╡реНрдпрд╛рдкрдХ рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╛рдВрд╕рд╛рдареА Microsoft Olive рд╡рд╛рдкрд░рд╛, рдЖрдгрд┐ Apple Silicon рдЙрдкрдХрд░рдгрд╛рдВрд╕рд╛рдареА Apple MLX рд╡рд╛рдкрд░рд╛.

## рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдореЙрдбреЗрд▓ рдЙрджрд╛рд╣рд░рдгреЗ рдЖрдгрд┐ рдЙрдкрдпреЛрдЧ рдкреНрд░рдХрд░рдгреЗ

### рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рдЬрдЧрд╛рддреАрд▓ рддреИрдирд╛рддреА рдкрд░рд┐рд╕реНрдерд┐рддреА

**рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧ**: Qwen3-0.6B рдХрдореА рдореЗрдорд░реА рдлреВрдЯрдкреНрд░рд┐рдВрдЯрд╕рд╣ рд╕реНрдорд╛рд░реНрдЯрдлреЛрди рдЪреЕрдЯрдмреЙрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрдордзреНрдпреЗ рдЙрддреНрдХреГрд╖реНрдЯ рдЖрд╣реЗ, рддрд░ Google Gemma3 рдЯреЕрдмрд▓реЗрдЯ-рдЖрдзрд╛рд░рд┐рдд рд╢реИрдХреНрд╖рдгрд┐рдХ рд╕рд╛рдзрдирд╛рдВрд╕рд╛рдареА рд╕рдВрддреБрд▓рд┐рдд рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддреЗ. Phi-4-mini-3.8B рдореЛрдмрд╛рдЗрд▓ рдЙрддреНрдкрд╛рджрдХрддрд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрд╕рд╛рдареА рдЙрддреНрдХреГрд╖реНрдЯ рддрд░реНрдХрд╢рдХреНрддреА рдХреНрд╖рдорддрд╛

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рд╣рд╛ рджрд╕реНрддрдРрд╡рдЬ AI рднрд╛рд╖рд╛рдВрддрд░ рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рд╡рд╛рдкрд░реВрди рднрд╛рд╖рд╛рдВрддрд░рд┐рдд рдХрд░рдгреНрдпрд╛рдд рдЖрд▓рд╛ рдЖрд╣реЗ. рдЖрдореНрд╣реА рдЕрдЪреВрдХрддреЗрд╕рд╛рдареА рдкреНрд░рдпрддреНрдирд╢реАрд▓ рдЕрд╕рд▓реЛ рддрд░реА, рдХреГрдкрдпрд╛ рд▓рдХреНрд╖рд╛рдд рдареЗрд╡рд╛ рдХреА рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рднрд╛рд╖рд╛рдВрддрд░рд╛рдВрдордзреНрдпреЗ рддреНрд░реБрдЯреА рдХрд┐рдВрд╡рд╛ рдЕрдЪреВрдХрддреЗрдЪрд╛ рдЕрднрд╛рд╡ рдЕрд╕реВ рд╢рдХрддреЛ. рдореВрд│ рднрд╛рд╖реЗрддреАрд▓ рджрд╕реНрддрдРрд╡рдЬ рд╣рд╛ рдЕрдзрд┐рдХреГрдд рд╕реНрд░реЛрдд рдорд╛рдирд▓рд╛ рдЬрд╛рд╡рд╛. рдорд╣рддреНрддреНрд╡рд╛рдЪреНрдпрд╛ рдорд╛рд╣рд┐рддреАрд╕рд╛рдареА рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдорд╛рдирд╡реА рднрд╛рд╖рд╛рдВрддрд░рд╛рдЪреА рд╢рд┐рдлрд╛рд░рд╕ рдХреЗрд▓реА рдЬрд╛рддреЗ. рдпрд╛ рднрд╛рд╖рд╛рдВрддрд░рд╛рдЪрд╛ рд╡рд╛рдкрд░ рдХрд░реВрди рдирд┐рд░реНрдорд╛рдг рд╣реЛрдгрд╛рд▒реНрдпрд╛ рдХреЛрдгрддреНрдпрд╛рд╣реА рдЧреИрд░рд╕рдордЬ рдХрд┐рдВрд╡рд╛ рдЪреБрдХреАрдЪреНрдпрд╛ рдЕрд░реНрдерд╛рд╕рд╛рдареА рдЖрдореНрд╣реА рдЬрдмрд╛рдмрджрд╛рд░ рд░рд╛рд╣рдгрд╛рд░ рдирд╛рд╣реА.