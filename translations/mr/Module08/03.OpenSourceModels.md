<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-09-30T23:50:55+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "mr"
}
-->
# सत्र ३: ओपन-सोर्स मॉडेल शोध आणि व्यवस्थापन

## आढावा

या सत्रात Foundry Local च्या मदतीने मॉडेल शोध आणि व्यवस्थापनावर लक्ष केंद्रित केले आहे. तुम्ही उपलब्ध मॉडेल्स कसे यादी करायचे, विविध पर्याय कसे तपासायचे आणि मूलभूत कार्यक्षमता वैशिष्ट्ये कशी समजून घ्यायची हे शिकाल. योग्य मॉडेल्स निवडण्यासाठी Foundry CLI च्या वापरावर आधारित व्यावहारिक दृष्टिकोनावर भर दिला जातो.

## शिकण्याची उद्दिष्टे

- मॉडेल शोध आणि व्यवस्थापनासाठी Foundry CLI कमांड्समध्ये प्राविण्य मिळवा
- मॉडेल कॅशे आणि स्थानिक स्टोरेज पॅटर्न समजून घ्या
- विविध मॉडेल्स जलदपणे तपासणे आणि तुलना करणे शिका
- मॉडेल निवड आणि बेंचमार्किंगसाठी व्यावहारिक कार्यप्रवाह स्थापित करा
- Foundry Local द्वारे उपलब्ध मॉडेल्सच्या वाढत्या इकोसिस्टमचा शोध घ्या

## पूर्वतयारी

- सत्र १ पूर्ण केले आहे: Foundry Local सह सुरुवात
- Foundry Local CLI स्थापित आणि प्रवेशयोग्य आहे
- मॉडेल डाउनलोडसाठी पुरेशी स्टोरेज जागा (मॉडेल्स १GB ते २०GB+ पर्यंत असू शकतात)
- मॉडेल प्रकार आणि उपयोग प्रकरणांची मूलभूत समज

## आढावा

या सत्रात ओपन-सोर्स मॉडेल्स Foundry Local मध्ये आणण्याचा अभ्यास केला जातो.

## भाग ६: व्यावहारिक व्यायाम

### व्यायाम: मॉडेल शोध आणि तुलना

Sample 03 वर आधारित तुमची स्वतःची मॉडेल मूल्यांकन स्क्रिप्ट तयार करा:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### तुमचे कार्य

1. **Sample 03 स्क्रिप्ट चालवा**: `samples\03\list_and_bench.cmd`
2. **विविध मॉडेल्स वापरून पहा**: किमान ३ वेगवेगळ्या मॉडेल्सची चाचणी करा
3. **कामगिरीची तुलना करा**: गती आणि प्रतिसाद गुणवत्तेतील फरक नोंदवा
4. **निष्कर्ष दस्तऐवजीकरण करा**: एक साधी तुलना चार्ट तयार करा

### उदाहरण तुलना स्वरूप

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## भाग ७: समस्या निवारण आणि सर्वोत्तम पद्धती

### सामान्य समस्या आणि उपाय

**मॉडेल सुरू होत नाही:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**अपुरे मेमरी:**
- लहान मॉडेल्सने सुरुवात करा (`phi-4-mini`)
- इतर अनुप्रयोग बंद करा
- वारंवार मर्यादा गाठल्यास RAM अपग्रेड करा

**स्लो परफॉर्मन्स:**
- मॉडेल पूर्णपणे लोड झाले आहे याची खात्री करा (विस्तृत आउटपुट तपासा)
- अनावश्यक पार्श्वभूमी अनुप्रयोग बंद करा
- जलद स्टोरेज (SSD) विचारात घ्या

### सर्वोत्तम पद्धती

1. **लहान सुरुवात करा**: सेटअप सत्यापित करण्यासाठी `phi-4-mini` वापरा
2. **एकावेळी एक मॉडेल**: नवीन मॉडेल सुरू करण्यापूर्वी मागील मॉडेल थांबवा
3. **संसाधने मॉनिटर करा**: मेमरी वापरावर लक्ष ठेवा
4. **सुसंगत चाचणी करा**: निष्पक्ष तुलना करण्यासाठी समान प्रॉम्प्ट्स वापरा
5. **परिणाम दस्तऐवजीकरण करा**: तुमच्या उपयोग प्रकरणांसाठी मॉडेल कामगिरीवर नोंदी ठेवा

## भाग ८: पुढील पायऱ्या आणि संदर्भ

### सत्र ४ साठी तयारी

- **सत्र ४ लक्ष केंद्रित**: ऑप्टिमायझेशन साधने आणि तंत्रे
- **पूर्वतयारी**: मॉडेल स्विचिंग आणि मूलभूत कामगिरी चाचणीमध्ये आरामदायक
- **शिफारस केलेले**: या सत्रातून २-३ आवडते मॉडेल्स ओळखले आहेत

### अतिरिक्त संसाधने

- **[Foundry Local दस्तऐवजीकरण](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: अधिकृत दस्तऐवजीकरण
- **[CLI संदर्भ](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: संपूर्ण कमांड संदर्भ
- **[Model Mondays](https://aka.ms/model-mondays)**: साप्ताहिक मॉडेल स्पॉटलाइट्स
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: समुदाय आणि समस्या
- **[Sample 03: मॉडेल शोध](samples/03/README.md)**: व्यावहारिक उदाहरण स्क्रिप्ट

### मुख्य मुद्दे

✅ **मॉडेल शोध**: उपलब्ध मॉडेल्स एक्सप्लोर करण्यासाठी `foundry model list` वापरा  
✅ **जलद चाचणी**: जलद मूल्यांकनासाठी `list_and_bench.cmd` पॅटर्न  
✅ **कामगिरी मॉनिटरिंग**: मूलभूत संसाधन वापर आणि प्रतिसाद वेळ मोजणे  
✅ **मॉडेल निवड**: उपयोग प्रकरणानुसार मॉडेल्स निवडण्यासाठी व्यावहारिक मार्गदर्शक  
✅ **कॅशे व्यवस्थापन**: स्टोरेज आणि क्लीनअप प्रक्रियेची समज  

तुमच्याकडे आता Foundry Local च्या सोप्या CLI दृष्टिकोनाचा वापर करून तुमच्या AI अनुप्रयोगांसाठी योग्य मॉडेल्स शोधणे, चाचणी करणे आणि निवडण्याचे व्यावहारिक कौशल्य आहे.

References:
- Foundry Local docs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Compile Hugging Face models: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Model Mondays: https://aka.ms/model-mondays
- Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

## शिकण्याची उद्दिष्टे
- स्थानिक इनफरन्ससाठी ओपन-सोर्स मॉडेल्स शोधा आणि मूल्यांकन करा
- Foundry Local मध्ये निवडक Hugging Face मॉडेल्स संकलित करा आणि चालवा
- अचूकता, विलंबता आणि संसाधन गरजांसाठी मॉडेल निवड धोरणे लागू करा
- कॅशे आणि आवृत्ती व्यवस्थापनासह मॉडेल्स स्थानिकपणे व्यवस्थापित करा

## भाग १: Foundry CLI सह मॉडेल शोध

### मूलभूत मॉडेल व्यवस्थापन कमांड्स

Foundry CLI मॉडेल शोध आणि व्यवस्थापनासाठी सोप्या कमांड्स प्रदान करते:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### तुमची पहिली मॉडेल्स चालवणे

कामगिरी वैशिष्ट्ये समजण्यासाठी लोकप्रिय, चांगल्या प्रकारे चाचणी केलेल्या मॉडेल्सने सुरुवात करा:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**टीप:** `--verbose` फ्लॅग तपशीलवार स्टार्टअप माहिती प्रदान करते, ज्यामध्ये समाविष्ट आहे:
- मॉडेल डाउनलोड प्रगती (पहिल्या रनवर)
- मेमरी वाटप तपशील
- सेवा बाइंडिंग माहिती
- कामगिरी प्रारंभिक मेट्रिक्स

### मॉडेल श्रेणी समजून घेणे

**लहान भाषा मॉडेल्स (SLMs):**
- `phi-4-mini`: जलद, कार्यक्षम, सामान्य चॅटसाठी उत्कृष्ट
- `phi-4`: चांगल्या तर्कसंगततेसह अधिक सक्षम आवृत्ती

**मध्यम मॉडेल्स:**
- `qwen2.5-7b`: उत्कृष्ट तर्कसंगतता आणि लांब संदर्भ
- `deepseek-r1-7b`: कोड जनरेशनसाठी ऑप्टिमाइझ केलेले

**मोठे मॉडेल्स:**
- `llama-3.2`: Meta चे नवीनतम ओपन-सोर्स मॉडेल
- `qwen2.5-14b`: एंटरप्राइझ-ग्रेड तर्कसंगतता

## भाग २: जलद मॉडेल चाचणी आणि तुलना

### Sample 03 दृष्टिकोन: साधी यादी आणि बेंच

आमच्या Sample 03 पॅटर्नवर आधारित, येथे किमान कार्यप्रवाह आहे:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### मॉडेल कामगिरी चाचणी

मॉडेल चालू झाल्यावर, सुसंगत प्रॉम्प्ट्ससह चाचणी करा:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### PowerShell चाचणी पर्याय

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## भाग ३: मॉडेल कॅशे आणि स्टोरेज व्यवस्थापन

### मॉडेल कॅशे समजून घेणे

Foundry Local स्वयंचलितपणे मॉडेल डाउनलोड्स आणि कॅशे व्यवस्थापित करते:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### मॉडेल स्टोरेज विचार

**सामान्य मॉडेल आकार:**
- `phi-4-mini`: ~२.५ GB
- `qwen2.5-7b`: ~४.१ GB  
- `deepseek-r1-7b`: ~४.३ GB
- `llama-3.2`: ~४.९ GB
- `qwen2.5-14b`: ~८.२ GB

**स्टोरेज सर्वोत्तम पद्धती:**
- जलद स्विचिंगसाठी २-३ मॉडेल्स कॅशे ठेवा
- जागा मोकळी करण्यासाठी न वापरलेली मॉडेल्स काढा: `foundry cache clean`
- विशेषतः लहान SSD वर डिस्क वापर मॉनिटर करा
- मॉडेल आकार आणि क्षमता व्यापार-ऑफ विचारात घ्या

### मॉडेल कामगिरी मॉनिटरिंग

मॉडेल्स चालू असताना, सिस्टम संसाधने मॉनिटर करा:

**Windows Task Manager:**
- मेमरी वापर पहा (मॉडेल्स RAM मध्ये लोड राहतात)
- इनफरन्स दरम्यान CPU उपयोग मॉनिटर करा
- प्रारंभिक मॉडेल लोडिंग दरम्यान डिस्क I/O तपासा

**कमांड लाइन मॉनिटरिंग:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## भाग ४: व्यावहारिक मॉडेल निवड मार्गदर्शक

### उपयोग प्रकरणानुसार मॉडेल्स निवडणे

**सामान्य चॅट आणि प्रश्नोत्तरासाठी:**
- सुरुवात करा: `phi-4-mini` (जलद, कार्यक्षम)
- अपग्रेड करा: `phi-4` (चांगली तर्कसंगतता)
- प्रगत: `qwen2.5-7b` (लांब संदर्भ)

**कोड जनरेशनसाठी:**
- शिफारस केलेले: `deepseek-r1-7b`
- पर्याय: `qwen2.5-7b` (कोडसाठी देखील चांगले)

**जटिल तर्कसंगततेसाठी:**
- सर्वोत्तम: `qwen2.5-7b` किंवा `qwen2.5-14b`
- बजेट पर्याय: `phi-4`

### हार्डवेअर आवश्यकता मार्गदर्शक

**किमान सिस्टम आवश्यकता:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**सर्वोत्तम कामगिरीसाठी शिफारस केलेले:**
- आरामदायक मल्टी-मॉडेल स्विचिंगसाठी ३२GB+ RAM
- जलद मॉडेल लोडिंगसाठी SSD स्टोरेज
- चांगल्या सिंगल-थ्रेड कामगिरीसह आधुनिक CPU
- त्वरणासाठी NPU समर्थन (Windows 11 Copilot+ PCs)

### मॉडेल स्विचिंग कार्यप्रवाह

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## भाग ५: साधी मॉडेल बेंचमार्किंग

### मूलभूत कामगिरी चाचणी

मॉडेल कामगिरीची तुलना करण्यासाठी येथे एक सोपा दृष्टिकोन आहे:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### मॅन्युअल गुणवत्ता मूल्यांकन

प्रत्येक मॉडेलसाठी, सुसंगत प्रॉम्प्ट्ससह चाचणी करा आणि मॅन्युअली मूल्यांकन करा:

**चाचणी प्रॉम्प्ट्स:**
1. "क्वांटम कंप्युटिंग सोप्या शब्दांत समजावून सांगा."
2. "यादी सॉर्ट करण्यासाठी Python फंक्शन लिहा."
3. "दूरस्थ कामाचे फायदे आणि तोटे काय आहेत?"
4. "एज AI चे फायदे संक्षेप करा."

**मूल्यांकन निकष:**
- **अचूकता**: माहिती योग्य आहे का?
- **स्पष्टता**: स्पष्टीकरण समजण्यास सोपे आहे का?
- **पूर्णता**: संपूर्ण प्रश्नाला उत्तर देते का?
- **गती**: प्रतिसाद किती जलद आहे?

### संसाधन वापर मॉनिटरिंग

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## भाग ६: पुढील पायऱ्या
- नवीन मॉडेल्स आणि टिप्ससाठी Model Mondays सबस्क्राइब करा: https://aka.ms/model-mondays
- तुमच्या टीमच्या `models.json` मध्ये निष्कर्ष योगदान द्या
- सत्र ४ साठी तयारी करा: LLMs vs SLMs, स्थानिक vs क्लाउड इनफरन्स, आणि व्यावहारिक डेमो तुलना

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून अनुवादित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी कृपया लक्षात ठेवा की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर करून निर्माण होणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.