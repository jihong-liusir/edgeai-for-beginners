<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ab6b3d55f53ea3d498b3c067b17f8816",
  "translation_date": "2025-09-19T02:05:08+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "bg"
}
-->
# AI Toolkit за Visual Studio Code - Ръководство за разработка на Edge AI

## Въведение

Добре дошли в подробното ръководство за използване на AI Toolkit за Visual Studio Code в разработката на Edge AI. С развитието на изкуствения интелект от централизирани облачни изчисления към разпределени edge устройства, разработчиците се нуждаят от мощни, интегрирани инструменти, които да се справят с уникалните предизвикателства на edge внедряването - от ограниченията на ресурсите до изискванията за работа офлайн.

AI Toolkit за Visual Studio Code запълва тази празнина, като предоставя цялостна среда за разработка, специално създадена за изграждане, тестване и оптимизиране на AI приложения, които работят ефективно на edge устройства. Независимо дали разработвате за IoT сензори, мобилни устройства, вградени системи или edge сървъри, този инструментариум улеснява целия процес на разработка в познатата среда на VS Code.

Това ръководство ще ви преведе през основните концепции, инструменти и добри практики за използване на AI Toolkit във вашите Edge AI проекти - от избора на модел до внедряването в продукция.

## Преглед

AI Toolkit предоставя интегрирана среда за разработка за целия жизнен цикъл на Edge AI приложенията в рамките на VS Code. Той предлага безпроблемна интеграция с популярни AI модели от доставчици като OpenAI, Anthropic, Google и GitHub, като същевременно поддържа локално внедряване на модели чрез ONNX и Ollama - ключови възможности за Edge AI приложения, които изискват локално изпълнение.

Това, което отличава AI Toolkit за Edge AI разработка, е фокусът върху целия процес на внедряване на edge. За разлика от традиционните инструменти за AI разработка, които основно се насочват към облачно внедряване, AI Toolkit включва специализирани функции за оптимизация на модели, тестване при ограничени ресурси и оценка на производителността, специфична за edge. Инструментариумът разбира, че разработката на Edge AI изисква различни съображения - по-малки размери на моделите, по-бързо време за изпълнение, офлайн възможности и оптимизации, специфични за хардуера.

Платформата поддържа множество сценарии за внедряване - от просто локално изпълнение на модели до сложни архитектури с множество модели на edge. Тя предоставя инструменти за конвертиране, квантизация и оптимизация на модели, които са от съществено значение за успешното внедряване на edge, като същевременно запазва продуктивността на разработчиците, с която VS Code е известен.

## Цели на обучението

До края на това ръководство ще можете:

### Основни компетенции
- **Да инсталирате и конфигурирате** AI Toolkit за Visual Studio Code за работни процеси на Edge AI разработка
- **Да навигирате и използвате** интерфейса на AI Toolkit, включително Model Catalog, Playground и Agent Builder
- **Да избирате и оценявате** AI модели, подходящи за edge внедряване, въз основа на производителност и ограничения на ресурсите
- **Да конвертирате и оптимизирате** модели, използвайки ONNX формат и техники за квантизация за edge устройства

### Умения за разработка на Edge AI
- **Да проектирате и внедрявате** Edge AI приложения, използвайки интегрираната среда за разработка
- **Да тествате модели** в условия, подобни на edge, чрез локално изпълнение и мониторинг на ресурсите
- **Да създавате и персонализирате** AI агенти, оптимизирани за сценарии на edge внедряване
- **Да оценявате производителността на моделите** чрез метрики, релевантни за edge изчисления (латентност, използване на памет, точност)

### Оптимизация и внедряване
- **Да прилагате техники за квантизация и изрязване** за намаляване на размера на моделите, като същевременно поддържате приемлива производителност
- **Да оптимизирате модели** за специфични edge хардуерни платформи, включително ускорение чрез CPU, GPU и NPU
- **Да внедрявате добри практики** за разработка на Edge AI, включително управление на ресурси и стратегии за резервиране
- **Да подготвяте модели и приложения** за внедряване в продукция на edge устройства

### Напреднали концепции за Edge AI
- **Да интегрирате с edge AI рамки** като ONNX Runtime, Windows ML и TensorFlow Lite
- **Да внедрявате архитектури с множество модели** и сценарии за федеративно обучение в edge среди
- **Да отстранявате често срещани проблеми** в Edge AI, включително ограничения на паметта, скорост на изпълнение и съвместимост с хардуера
- **Да проектирате стратегии за мониторинг и логване** за Edge AI приложения в продукция

### Практическо приложение
- **Да изграждате цялостни Edge AI решения** от избора на модел до внедряването
- **Да демонстрирате умения** в специфични за edge работни процеси и техники за оптимизация
- **Да прилагате научените концепции** към реални случаи на Edge AI, включително IoT, мобилни и вградени приложения
- **Да оценявате и сравнявате** различни стратегии за внедряване на Edge AI и техните компромиси

## Основни функции за разработка на Edge AI

### 1. Каталог на модели и откриване
- **Поддръжка на локални модели**: Откривайте и достъпвайте AI модели, специално оптимизирани за edge внедряване
- **Интеграция с ONNX**: Достъп до модели във формат ONNX за ефективно изпълнение на edge
- **Поддръжка на Ollama**: Използвайте локално изпълняващи се модели чрез Ollama за поверителност и работа офлайн
- **Сравнение на модели**: Сравнявайте модели един до друг, за да намерите оптималния баланс между производителност и консумация на ресурси за edge устройства

### 2. Интерактивна площадка
- **Локална тестова среда**: Тествайте модели локално преди внедряване на edge
- **Мултимодални експерименти**: Тествайте с изображения, текст и други входни данни, типични за edge сценарии
- **Настройка на параметри**: Експериментирайте с различни параметри на моделите за оптимизация при ограничения на edge
- **Мониторинг на производителността в реално време**: Наблюдавайте скоростта на изпълнение и използването на ресурси по време на разработката

### 3. Създател на агенти за Edge приложения
- **Инженеринг на подсказки**: Създавайте оптимизирани подсказки, които работят ефективно с по-малки edge модели
- **Интеграция с MCP инструменти**: Интегрирайте инструменти за Model Context Protocol за подобрени възможности на edge агентите
- **Генериране на код**: Генерирайте готов за продукция код, оптимизиран за сценарии на edge внедряване
- **Структурирани изходи**: Проектирайте агенти, които предоставят последователни, структурирани отговори, подходящи за edge приложения

### 4. Оценка и тестване на модели
- **Метрики за производителност**: Оценявайте модели чрез метрики, релевантни за edge внедряване (латентност, използване на памет, точност)
- **Групово тестване**: Тествайте множество конфигурации на модели едновременно, за да намерите оптимални настройки за edge
- **Персонализирана оценка**: Създавайте персонализирани критерии за оценка, специфични за случаи на Edge AI
- **Профилиране на ресурси**: Анализирайте изискванията за памет и изчисления за планиране на edge внедряване

### 5. Конвертиране и оптимизация на модели
- **Конвертиране към ONNX**: Конвертирайте модели от различни формати към ONNX за съвместимост с edge
- **Квантизация**: Намалете размера на моделите и подобрете скоростта на изпълнение чрез техники за квантизация
- **Оптимизация за хардуер**: Оптимизирайте модели за специфичен edge хардуер (CPU, GPU, NPU)
- **Трансформация на формати**: Трансформирайте модели от Hugging Face и други източници за edge внедряване

### 6. Фина настройка за Edge сценарии
- **Адаптация към домейн**: Персонализирайте модели за специфични edge случаи и среди
- **Локално обучение**: Обучавайте модели локално с GPU поддръжка за специфични изисквания на edge
- **Интеграция с Azure**: Използвайте Azure Container Apps за облачно фина настройка преди edge внедряване
- **Трансферно обучение**: Адаптирайте предварително обучени модели за задачи и ограничения, специфични за edge

### 7. Мониторинг и проследяване на производителността
- **Анализ на производителността на edge**: Наблюдавайте производителността на моделите в условия, подобни на edge
- **Събиране на проследяващи данни**: Събирайте подробни данни за производителността за оптимизация
- **Идентифициране на тесни места**: Откривайте проблеми с производителността преди внедряване на edge устройства
- **Проследяване на използването на ресурси**: Наблюдавайте паметта, CPU и времето за изпълнение за оптимизация на edge

## Работен процес за разработка на Edge AI

### Фаза 1: Откриване и избор на модели
1. **Разгледайте каталога на модели**: Използвайте каталога на модели, за да намерите подходящи за edge внедряване
2. **Сравнете производителността**: Оценявайте модели въз основа на размер, точност и скорост на изпълнение
3. **Тествайте локално**: Използвайте Ollama или ONNX модели за локално тестване преди edge внедряване
4. **Оценете изискванията за ресурси**: Определете нуждите от памет и изчисления за целевите edge устройства

### Фаза 2: Оптимизация на модели
1. **Конвертирайте към ONNX**: Конвертирайте избраните модели към ONNX формат за съвместимост с edge
2. **Прилагайте квантизация**: Намалете размера на моделите чрез INT8 или INT4 квантизация
3. **Оптимизация за хардуер**: Оптимизирайте за целевия edge хардуер (ARM, x86, специализирани ускорители)
4. **Валидирайте производителността**: Уверете се, че оптимизираните модели запазват приемлива точност

### Фаза 3: Разработка на приложения
1. **Проектиране на агенти**: Използвайте Agent Builder за създаване на AI агенти, оптимизирани за edge
2. **Инженеринг на подсказки**: Разработете подсказки, които работят ефективно с по-малки модели
3. **Тестване на интеграция**: Тествайте агентите в симулирани edge условия
4. **Генериране на код**: Генерирайте продукционен код, оптимизиран за edge внедряване

### Фаза 4: Оценка и тестване
1. **Групова оценка**: Тествайте множество конфигурации, за да намерите оптимални настройки за edge
2. **Профилиране на производителността**: Анализирайте скоростта на изпълнение, използването на памет и точността
3. **Симулация на edge**: Тествайте в условия, подобни на целевата среда за edge внедряване
4. **Стрес тестове**: Оценявайте производителността при различни натоварвания

### Фаза 5: Подготовка за внедряване
1. **Финална оптимизация**: Прилагайте последни оптимизации въз основа на резултатите от тестването
2. **Опаковане за внедряване**: Опаковайте модели и код за edge внедряване
3. **Документация**: Документирайте изискванията за внедряване и конфигурация
4. **Настройка на мониторинг**: Подгответе мониторинг и логване за внедряване в продукция

## Целева аудитория за разработка на Edge AI

### Разработчици на Edge AI
- Разработчици на приложения, изграждащи edge устройства и IoT решения с AI
- Разработчици на вградени системи, интегриращи AI възможности в устройства с ограничени ресурси
- Мобилни разработчици, създаващи AI приложения за смартфони и таблети

### Инженери на Edge AI
- AI инженери, оптимизиращи модели за edge внедряване и управляващи изпълнителни тръбопроводи
- DevOps инженери, внедряващи и управляващи AI модели в разпределена edge инфраструктура
- Инженери по производителност, оптимизиращи AI натоварвания за ограниченията на edge хардуера

### Изследователи и преподаватели
- AI изследователи, разработващи ефективни модели и алгоритми за edge изчисления
- Преподаватели, обучаващи концепции за Edge AI и демонстриращи техники за оптимизация
- Студенти, изучаващи предизвикателствата и решенията при внедряване на Edge AI

## Приложения на Edge AI

### Умни IoT устройства
- **Разпознаване на изображения в реално време**: Внедряване на модели за компютърно зрение на IoT камери и сензори
- **Обработка на глас**: Реализиране на разпознаване на реч и обработка на естествен език на умни говорители
- **Предиктивна поддръжка**: Изпълнение на модели за откриване на аномалии на индустриални edge устройства
- **Мониторинг на околната среда**: Внедряване на модели за анализ на данни от сензори за екологични приложения

### Мобилни и вградени приложения
- **Превод на устройството**: Реализиране на модели за превод на езици, които работят офлайн
- **Добавена реалност**: Внедряване на разпознаване и проследяване на обекти в реално време за AR приложения
- **Мониторинг на здравето**: Изпълнение на модели за анализ на здравето на носими устройства и медицинско оборудване
- **Автономни системи**: Реализиране на модели за вземане на решения за дронове, роботи и превозни средства

### Edge инфраструктура за изчисления
- **Edge центрове за данни**: Внедряване на AI модели в edge центрове за данни за приложения с ниска латентност
- **Интеграция с CDN**: Интегриране на AI възможности за обработка в мрежи за доставка на съдържание
- **5G Edge**: Използване на 5G edge изчисления за AI приложения
- **Fog Computing**: Реализиране на AI обработка в среди за fog computing

## Инсталация и настройка

### Бърза инсталация
Инсталирайте разширението AI Toolkit директно от Visual Studio Code Marketplace:

```
Install: AI Toolkit for Visual Studio Code (ms-windows-ai-studio.windows-ai-studio)
```

### Предварителни изисквания за разработка на Edge AI
- **ONNX Runtime**: Инсталирайте ONNX Runtime за изпълнение на модели
- **Ollama** (по избор): Инсталирайте Ollama за локално обслужване на модели
- **Python среда**: Настройте Python с необходимите AI библиотеки
- **Инструменти за edge хардуер**: Инсталирайте инструменти за разработка, специфични за хардуера (CUDA, OpenVINO и др.)

### Първоначална конфигурация
1. Отворете VS Code и инсталирайте разширението AI Toolkit
2. Конфигурирайте източниците на модели (ONNX, Ollama, облачни доставчици)
3. Настройте локална среда за разработка за edge тестване
4. Конфигурирайте опции за хардуерно ускорение за вашата машина за разработка

## Първи стъпки с разработката на Edge AI

### Стъпка 1: Избор на модел
1. Отворете изгледа AI Toolkit в Activity Bar
2. Разгледайте каталога на модели за съвмест
- **Сигурност**: Прилагайте подходящи мерки за сигурност за приложения с Edge AI

## Интеграция с Edge AI рамки

### ONNX Runtime
- **Мултиплатформено внедряване**: Внедрявайте ONNX модели на различни edge платформи
- **Хардуерна оптимизация**: Използвайте хардуерно-специфичните оптимизации на ONNX Runtime
- **Поддръжка за мобилни устройства**: Използвайте ONNX Runtime Mobile за приложения на смартфони и таблети
- **Интеграция с IoT**: Внедрявайте на IoT устройства с леките дистрибуции на ONNX Runtime

### Windows ML
- **Windows устройства**: Оптимизирайте за edge устройства и компютри с Windows
- **Ускорение с NPU**: Използвайте Neural Processing Units на Windows устройства
- **DirectML**: Използвайте DirectML за GPU ускорение на Windows платформи
- **Интеграция с UWP**: Интегрирайте с приложения за Universal Windows Platform

### TensorFlow Lite
- **Оптимизация за мобилни устройства**: Внедрявайте TensorFlow Lite модели на мобилни и вградени устройства
- **Хардуерни делегати**: Използвайте специализирани хардуерни делегати за ускорение
- **Микроконтролери**: Внедрявайте на микроконтролери с TensorFlow Lite Micro
- **Мултиплатформена поддръжка**: Внедрявайте на Android, iOS и вградени Linux системи

### Azure IoT Edge
- **Хибрид облак-edge**: Комбинирайте обучение в облака с извеждане на резултати на edge устройства
- **Модулно внедряване**: Внедрявайте AI модели като IoT Edge модули
- **Управление на устройства**: Управлявайте edge устройства и актуализации на модели дистанционно
- **Телеметрия**: Събирайте данни за производителността и метрики на модели от edge внедрения

## Разширени сценарии за Edge AI

### Внедряване на множество модели
- **Моделни ансамбли**: Внедрявайте множество модели за подобрена точност или резервираност
- **A/B тестване**: Тествайте различни модели едновременно на edge устройства
- **Динамичен избор**: Избирайте модели според текущите условия на устройството
- **Споделяне на ресурси**: Оптимизирайте използването на ресурси между множество внедрени модели

### Федеративно обучение
- **Разпределено обучение**: Обучавайте модели на множество edge устройства
- **Запазване на поверителността**: Съхранявайте данните за обучение локално, като споделяте само подобренията на модела
- **Съвместно обучение**: Позволете на устройствата да се учат от колективния опит
- **Координация между edge и облак**: Координирайте обучението между edge устройства и облачната инфраструктура

### Обработка в реално време
- **Обработка на потоци**: Обработвайте непрекъснати потоци от данни на edge устройства
- **Извеждане с ниска латентност**: Оптимизирайте за минимална латентност при извеждане
- **Партидна обработка**: Ефективно обработвайте партиди от данни на edge устройства
- **Адаптивна обработка**: Настройвайте обработката според текущите възможности на устройството

## Отстраняване на проблеми при разработка на Edge AI

### Често срещани проблеми
- **Ограничения на паметта**: Моделът е твърде голям за паметта на целевото устройство
- **Скорост на извеждане**: Извеждането на модела е твърде бавно за изискванията в реално време
- **Деградация на точността**: Оптимизацията намалява точността на модела до неприемливо ниво
- **Съвместимост с хардуера**: Моделът не е съвместим с целевия хардуер

### Стратегии за дебъгване
- **Профилиране на производителността**: Използвайте функциите за проследяване на AI Toolkit, за да идентифицирате тесните места
- **Мониторинг на ресурсите**: Наблюдавайте използването на паметта и процесора по време на разработката
- **Инкрементално тестване**: Тествайте оптимизациите постепенно, за да изолирате проблемите
- **Симулация на хардуер**: Използвайте инструменти за разработка, за да симулирате целевия хардуер

### Решения за оптимизация
- **Допълнителна квантизация**: Прилагайте по-агресивни техники за квантизация
- **Архитектура на модела**: Обмислете различни архитектури на модели, оптимизирани за edge
- **Оптимизация на предварителната обработка**: Оптимизирайте предварителната обработка на данни за ограниченията на edge
- **Оптимизация на извеждането**: Използвайте хардуерно-специфични оптимизации за извеждане

## Ресурси и следващи стъпки

### Документация
- [Ръководство за AI Toolkit модели](https://code.visualstudio.com/docs/intelligentapps/models)
- [Документация за Model Playground](https://code.visualstudio.com/docs/intelligentapps/playground)
- [Документация за ONNX Runtime](https://onnxruntime.ai/)
- [Документация за Windows ML](https://docs.microsoft.com/en-us/windows/ai/)

### Общност и поддръжка
- [VS Code AI Toolkit GitHub](https://github.com/microsoft/vscode-ai-toolkit)
- [ONNX общност](https://github.com/onnx/onnx)
- [Общност на разработчиците на Edge AI](https://docs.microsoft.com/en-us/azure/iot-edge/community)
- [Пазар за разширения на VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### Ресурси за обучение
- [Курс за основи на Edge AI](./Module01/README.md)
- [Ръководство за малки езикови модели](./Module02/README.md)
- [Стратегии за внедряване на Edge](./Module03/README.md)
- [Разработка на Edge AI за Windows](./windowdeveloper.md)

## Заключение

AI Toolkit за Visual Studio Code предоставя цялостна платформа за разработка на Edge AI, от откриване и оптимизация на модели до внедряване и мониторинг. Чрез използването на интегрираните инструменти и работни процеси, разработчиците могат ефективно да създават, тестват и внедряват AI приложения, които работят успешно на устройства с ограничени ресурси.

Поддръжката на инструмента за ONNX, Ollama и различни облачни доставчици, съчетана с неговите възможности за оптимизация и оценка, го прави идеален избор за разработка на Edge AI. Независимо дали създавате IoT приложения, AI функции за мобилни устройства или вградени интелигентни системи, AI Toolkit предоставя необходимите инструменти и работни процеси за успешно внедряване на Edge AI.

С развитието на Edge AI, AI Toolkit за VS Code остава начело, предоставяйки на разработчиците най-новите инструменти и възможности за създаване на следващото поколение интелигентни edge приложения.

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.