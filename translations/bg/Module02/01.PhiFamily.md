<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:41:42+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "bg"
}
-->
# Раздел 1: Основи на семейството модели Microsoft Phi

Семейството модели Microsoft Phi представлява промяна в парадигмата на изкуствения интелект, демонстрирайки, че компактни и ефективни модели могат да постигнат забележителна производителност, като същевременно са значително по-ресурсно ефективни от традиционните големи езикови модели. Важно е да разберем как семейството Phi предоставя мощни AI възможности с намалени изчислителни изисквания, като същевременно поддържа висока производителност в различни задачи.

## Ресурси за разработчици

### Каталог на модели Azure AI Foundry
Моделите от семейството Phi (с изключение на Phi-silica) са достъпни чрез [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), което улеснява разработчиците да ги достъпват, настройват и внедряват в своите приложения. Каталогът предоставя опростен начин за експериментиране с различни варианти на Phi и интегрирането им във вашите проекти.

### Azure AI Foundry
Можете да внедрите и експериментирате с моделите Phi, използвайки [Azure AI Foundry](https://ai.azure.com), който предоставя цялостна среда за изграждане, тестване и внедряване на AI решения с минимална настройка.

### Foundry Local
За локално разработване и внедряване, разгледайте [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), който ви позволява да стартирате модели Phi на вашата разработваща машина с оптимизирани конфигурации.

### Ресурси за документация
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Въведение

В този урок ще разгледаме семейството модели Microsoft Phi и неговите основни концепции. Ще обсъдим еволюцията на семейството Phi, иновативните методологии за обучение, които правят моделите Phi ефективни, ключовите варианти в семейството и практическите приложения в различни сценарии.

## Цели на обучението

До края на този урок ще можете:

- Да разберете философията на дизайна и еволюцията на семейството модели Microsoft Phi.
- Да идентифицирате ключовите иновации, които позволяват моделите Phi да постигат висока производителност с по-малко параметри.
- Да разпознаете предимствата и ограниченията на различните варианти на моделите Phi.
- Да приложите знанията си за моделите Phi, за да изберете подходящи варианти за реални сценарии.

## Разбиране на традиционната парадигма на AI моделите

Традиционно, постигането на висока производителност в обработката на естествен език изискваше масивни езикови модели с милиарди или стотици милиарди параметри. Организациите обикновено внедряват тези модели на мощни GPU клъстери, като достъпват техните възможности чрез API интерфейси или специализирана хардуерна инфраструктура.

Този подход работи добре за много приложения, но има присъщи ограничения, когато става въпрос за практическо внедряване. Конвенционалният метод включва използване на модели, които изискват значителни изчислителни ресурси, големи количества памет и значителна енергийна консумация. Въпреки че този подход предоставя достъп до най-съвременни възможности, той създава зависимости от скъп хардуер, въвежда високи оперативни разходи и ограничава гъвкавостта на внедряване.

## Предизвикателството за ефективно внедряване на AI

Необходимостта от по-ефективен AI става все по-важна в различни сценарии. Помислете за приложения, изискващи локално внедряване поради причини за поверителност, чувствителни към разходите реализации, където разходите за API в облака стават непосилни, сценарии за edge computing с ограничени хардуерни ресурси или приложения в реално време, където латентността е критична.

### Основни ограничения при внедряване

Традиционните внедрявания на големи модели се сблъскват с няколко фундаментални ограничения, които ограничават тяхната практическа приложимост:

- **Ограничения на разходите**: Високите изчислителни разходи правят непрекъснатото внедряване скъпо за много организации.
- **Ограничения на ресурсите**: Ограниченият достъп до висококачествена GPU инфраструктура ограничава опциите за внедряване.
- **Изисквания за поверителност**: Чувствителните приложения изискват локална обработка за запазване на поверителността на данните.
- **Чувствителност към латентност**: Приложенията в реално време се нуждаят от незабавни отговори без забавяне от облака.

## Философията на моделите Microsoft Phi

Семейството модели Microsoft Phi представлява фундаментална промяна във философията на дизайна на AI модели, като приоритизира ефективността и практическото внедряване, като същевременно поддържа силни характеристики на производителност. Моделите Phi постигат това чрез иновативни архитектури, висококачествени методологии за обучение и специализирани техники за оптимизация.

Семейството Phi обхваща различни подходи, предназначени да максимизират производителността на параметър, позволявайки внедряване на стандартен хардуер, като същевременно предоставя значими AI възможности. Целта е да се поддържа конкурентна производителност, като същевременно се намаляват драстично изчислителните изисквания, използването на памет и оперативните разходи.

### Основни принципи на дизайна на Phi

Моделите Phi са изградени върху няколко основни принципа, които ги отличават от традиционните големи езикови модели:

- **Ефективност на първо място**: Оптимизирани за максимална производителност на параметър, а не за абсолютен мащаб.
- **Качествено обучение**: Фокус върху висококачествени, подбрани данни за обучение, вместо масивни набори от данни.
- **Гъвкавост на внедряване**: Проектирани да работят ефективно на различни хардуерни конфигурации.
- **Специализирани възможности**: Често оптимизирани за специфични задачи или домейни за максимална ефективност.

## Ключови технологии, позволяващи семейството Phi

### Подходът "учебник" за обучение

Един от най-революционните аспекти на семейството Phi е методологията за обучение с "качество на учебник". Вместо да се обучават върху масивни количества нефилтрирани интернет данни, моделите Phi използват внимателно подбрано, висококачествено образователно съдържание, предназначено да учи ефективно на разсъждения, математика, програмиране и общи знания.

Този подход работи чрез създаване на синтетично образователно съдържание, което отразява висококачествени учебници и академични материали. Данните за обучение са специално проектирани да бъдат педагогически издържани, като се фокусират върху ясни обяснения, стъпка по стъпка разсъждения и структурирано представяне на знания.

### Разширено обучение за разсъждения

Последните модели Phi включват сложни методологии за обучение за разсъждения, които позволяват решаване на сложни многостъпкови проблеми. Тези техники включват:

**Обучение с верига от мисли**: Моделите се учат да разбиват сложни проблеми на междинни стъпки на разсъждения, правейки процеса на решаване по-прозрачен и надежден.

**Мащабиране по време на извеждане**: Моделите генерират подробни вериги от разсъждения, които използват допълнителни изчислителни ресурси по време на генериране на отговори за подобрена точност.

**Обучение на границата на възможностите**: Данните за обучение са специално избрани, за да предизвикат модела на границата на текущите му възможности, насърчавайки изучаването на сложни модели на разсъждения.

### Архитектурни иновации

Семейството Phi включва няколко архитектурни оптимизации, специално проектирани за ефективност:

**Ефективност на параметрите**: Внимателни архитектурни избори, които максимизират въздействието на всеки параметър в модела.

**Интеграция на мултимодалност**: Ефективна интеграция на текст, визия и обработка на реч в компактни архитектури.

**Оптимизация за хардуер**: Специализирани варианти, оптимизирани за специфични хардуерни платформи и сценарии за внедряване.

## Оптимизация на хардуера за модели Phi

Съвременните среди за внедряване се възползват от ефективността на моделите Phi в различни хардуерни конфигурации:

### Оптимизирано внедряване на CPU

Моделите Phi са проектирани да работят ефективно на хардуер само с CPU, което ги прави достъпни за внедряване на стандартна компютърна инфраструктура без необходимост от специализирани AI ускорители.

### GPU ускорение

Въпреки че не изискват мощни GPU, моделите Phi могат да използват наличните GPU ресурси за подобрена производителност, предоставяйки гъвкавост в конфигурациите за внедряване.

### Интеграция на edge устройства

Специализирани варианти като Phi-3-Silica са оптимизирани за специфични платформи за edge computing, постигайки забележителни показатели за ефективност, като например 650 токена в секунда с консумация на мощност от само 1.5W.

## Предимства на семейството модели Phi

### Ефективност на разходите

Моделите Phi драстично намаляват оперативните разходи, като изискват значително по-малко изчислителна инфраструктура, като същевременно поддържат конкурентна производителност. Това прави AI достъпен за организации с ограничени бюджети или приложения с голям обем, където разходите на инференция са от значение.

### Гъвкавост на внедряване

Ефективността на моделите Phi позволява внедряване в широк спектър от хардуерни конфигурации, от лични лаптопи до корпоративни сървъри, предоставяйки на организациите по-голяма гъвкавост в избора на AI инфраструктура.

### Поверителност и сигурност

Ефективността на моделите Phi позволява локално внедряване за приложения, чувствителни към поверителност, като гарантира, че чувствителните данни никога не напускат контрола на организацията, като същевременно предоставят мощни AI възможности.

### Производителност в реално време

Намалените изчислителни изисквания се превръщат в по-бързи времена за инференция, позволявайки приложения в реално време, които изискват незабавни отговори, без компромис с качеството на AI възможностите.

### Достъпен AI

Чрез намаляване на бариерите за внедряване на AI, моделите Phi правят напредналите AI възможности достъпни за организации с ограничени ресурси, позволявайки на по-малки екипи и индивидуални разработчици да използват сложни езикови разбирания.

## Практически примери и случаи на употреба

Преди да се потопим в техническата еволюция, нека разгледаме някои конкретни примери за това какво могат да постигнат моделите Phi:

### Пример за математическо разсъждение

Phi-4-mini-reasoning се отличава в стъпка по стъпка решаване на математически проблеми. Например, когато бъде попитан "Как да решим 3*x^2+4*x+5=1?", моделът предоставя подробни стъпки на разсъждение:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Пример за многоезична поддръжка

Phi-3.5-mini-instruct демонстрира силни многоезични възможности в различни езици. Ето примерен формат на подканата:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Пример за мултимодални възможности

Phi-4-multimodal може да обработва текст, изображения и реч едновременно. Ето някои практически приложения:

**Планиране на пътуване с аудио вход:**
Вижте как Phi-4 Multimodal анализира говорим език, за да помогне при планиране на пътуване до Сиатъл, демонстрирайки своите напреднали възможности за обработка на аудио и препоръки.

**Решаване на математически проблеми от изображения:**
Вижте как Phi-4 Multimodal се справя със сложни математически проблеми чрез визуални входове, демонстрирайки способността си да обработва и решава уравнения, представени в изображения.

**Пример за извикване на функции:**
С извикване на функции, Phi-4-mini и Phi-4-multimodal могат да разширят своите текстови възможности, като интегрират търсачки, свързват различни инструменти и други. Както е показано, моделът може да извлече информация за мачове от Premier League чрез Phi-4-mini, демонстрирайки способността си да се свързва безпроблемно с външни източници на данни.

### Пример за генериране на код

Phi-4-multimodal може да генерира структуриран проектен код въз основа на съдържание на изображения и предоставени подканяния, както е показано в този практически работен процес:

1. Качете изображение на wireframe или дизайн.
2. Предоставете контекст за изискванията на проекта.
3. Моделът генерира пълни, функционални кодови структури.
4. Кодът може да бъде персонализиран въз основа на специфични рамки или езици.

### Пример за внедряване на edge устройства

Можем да внедрим квантизиран модел на edge устройства. Чрез комбиниране на Microsoft Olive и ONNX GenAI Runtime, можем да внедрим Phi-4-mini на Windows, iPhone, Android и други устройства. Това е пример за работа на iPhone 12 Pro.

Процесът на внедряване включва:
- Квантизация на модела за мобилна оптимизация.
- Интеграция на ONNX runtime за съвместимост между платформи.
- Локална инференция без интернет свързаност.
- Производителност в реално време с минимална консумация на мощност.

## Еволюцията на семейството Phi

### Phi-1 и Phi-2: Основни модели

Ранните модели Phi установиха основните принципи на висококачествени данни за обучение и ефективни архитектури:

- **Phi-1 (1.3B параметри)**: Въведе концепцията за подбрани данни за обучение за основно езиково разбиране и генериране на код.
- **Phi-2 (2.7B параметри)**: Подобри възможностите за разсъждение чрез синтетични NLP данни и внимателно филтрирано уеб съдържание.

### Семейство Phi-3: Масово приемане

Серията Phi-3 отбеляза пробив в SLM възможностите с множество специализирани варианти:

- **Phi-3-mini (3.8B параметри)**: Общи езикови задачи с изключителна ефективност, надминаващи модели два пъти по-големи.
- **Phi-3-small (7B параметри)**: Напреднала производителност, надминаваща GPT-3.5 Turbo в различни бенчмаркове.
- **Phi-3-medium (14B параметри)**: Производителност на корпоративно ниво, надминаваща Gemini 1.0 Pro.
- **Phi-3-vision (4.2B параметри)**: Мултимодални възможности за обработка на изображения и текст.
- **Phi-3-Silica (3.3B параметри)**: Специализирана оптимизация за вградено внедряване в Windows 11.

### Семейство Phi-4: Разширено разсъждение

Последното поколение разширява границите на възможностите за разсъждение:

- **Phi-4 (14B параметри)**:
Семейството Phi демонстрира, че бъдещето на внедряването на AI не се крие само в изграждането на по-големи модели, а в създаването на по-умни и ефективни модели, които могат да работят успешно в разнообразни хардуерни среди, като същевременно поддържат високи стандарти за производителност.

## Примери за разработка и интеграция

### Бърз старт с Transformers

Ето как да започнете работа с моделите Phi, използвайки библиотеката Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Пример за фина настройка

Следният пример показва как да направите фина настройка на Phi-4-mini-instruct за специфични задачи:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Специализирани формати за подсказки

**За задачи с разсъждения (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**За математически задачи (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Мобилно внедряване с ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Бенчмаркове за производителност и постижения

Семейството модели Phi постигна забележителни резултати в различни бенчмаркове, често надминавайки много по-големи модели:

### Основни акценти в производителността

**Изключителни математически разсъждения:**
- Phi-4 постига 82.5% точност на AIME 2025 (квалификация за математическа олимпиада)
- Phi-4-reasoning (14B) надминава DeepSeek-R1-Distill-70B (5 пъти по-голям) в бенчмаркове за разсъждения
- Phi-4-mini-reasoning (3.8B) съперничи на модели два пъти по-големи в задачи за математически разсъждения

**Постижения в ефективността:**
- Phi-3-Silica постига 650 токена в секунда с консумация на енергия само 1.5W
- Phi-4-mini (3.8B) постига подобна производителност на много по-големи модели

**Производителност в бенчмаркове:**
- **MMLU (Масово многозадачно езиково разбиране)**: Конкурентна производителност в 57 академични предмета
- **HumanEval**: Силни способности за генериране на код, особено в Python
- **MGSM**: Многоезично решаване на математически задачи за начално училище
- **DROP**: Сложни задачи за разбиране и разсъждение
- **SimpleQA**: Точност на отговорите на фактически въпроси

### 📊 Матрица за сравнение на модели

| Модел | Параметри | Дължина на контекста | Основни предимства | Най-добри приложения |
|-------|-----------|----------------------|--------------------|-----------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Обща ефективност | Мобилни приложения, основни чатботове |
| **Phi-3.5-mini** | 3.8B | 128K | Многоезична поддръжка | Международни приложения |
| **Phi-4-mini** | 3.8B | 128K | Подобрени разсъждения, извикване на функции | Бизнес автоматизация |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Математически разсъждения | Образователни платформи |
| **Phi-4** | 14B | 32K | Сложни разсъждения | Изследвания, напреднал анализ |
| **Phi-4-reasoning** | 14B | 32K/64K | Многоетапни разсъждения | Научни изчисления |
| **Phi-4-reasoning-plus** | 14B | 32K | Максимална точност в разсъжденията | Критично вземане на решения |
| **Phi-4-multimodal** | 5.6B | Променлива | Реч, визия, текст | Мултимедийни приложения |

## Ръководство за избор на модел

### За основни приложения
- **Phi-3-mini**: Генериране на текст, основни въпроси и отговори, бързи реакции
- **Phi-4-mini**: Подобрени разсъждения с възможности за извикване на функции

### За математически и логически задачи
- **Phi-4**: Сложно решаване на математически задачи и разсъждения
- **Phi-4-reasoning**: Многоетапни разсъждения с подробни обяснения
- **Phi-4-reasoning-plus**: Максимална точност за критични приложения с разсъждения
- **Phi-4-mini-reasoning**: Ефективни математически разсъждения за среди с ограничени ресурси

### За мултимодални приложения
- **Phi-3-vision**: Комбинации от обработка на изображения и текст
- **Phi-4-multimodal**: Комплексни възможности за реч, визия и текст

### За корпоративно внедряване
- **Phi-3-medium**: Напреднало езиково разбиране за бизнес приложения
- **Phi-3-Silica**: Оптимизиран за специфични хардуерни платформи

## Платформи за внедряване и достъпност

### Облачни платформи
- **Azure AI Foundry**: Пълнофункционално внедряване с инструменти за предприятия
- **Hugging Face**: Отворен код за модели и ресурси на общността
- **NVIDIA API Catalog**: Опции за внедряване на микросервиси

### Локални рамки за разработка
- **Ollama**: Лека рамка за локално внедряване на модели
- **ONNX Runtime**: Оптимизиран за различни хардуерни конфигурации  
- **DirectML**: Оптимизирана производителност за Windows
- **llama.cpp**: Мултиплатформен двигател за инференция

### Ресурси за обучение
- **Phi Portal**: Официален център за документация на Microsoft Phi
- **Phi Cookbook**: Изчерпателни примери и уроци
- **Technical Reports**: Задълбочени изследователски статии в arxiv
- **Community Spaces**: Интерактивни демонстрации в Hugging Face

### Започване с модели Phi

#### Платформи за разработка
1. **Azure AI Foundry**: Прост локален CLI и управление на модели.
2. **Hugging Face Transformers**: Бърза локална експериментация
3. **Ollama**: Локално внедряване за тестване

#### Път за обучение
1. **Разберете основните концепции**: Изучете фундаменталните принципи на дизайна
2. **Експериментирайте с варианти**: Опитайте различни модели Phi, за да разберете възможностите
3. **Практикувайте внедряване**: Внедрете модели в тестови среди
4. **Разширете внедряването**: Постепенно увеличете употребата въз основа на успешни пилотни проекти

#### Най-добри практики
- **Започнете с малки модели**: Започнете с Phi-mini за първоначална разработка
- **Оптимизирайте подсказките**: Използвайте правилно форматиране за най-добри резултати
- **Следете производителността**: Проследявайте скоростта на инференция и точността
- **Съобразете хардуера**: Съчетайте размера на модела с наличните изчислителни ресурси

## Заключение

Семейството модели Microsoft Phi представлява революционен подход към дизайна на AI модели, демонстрирайки, че по-малки и по-ефективни модели могат да постигнат забележителни резултати в различни задачи. Чрез фокусиране върху висококачествени тренировъчни данни и архитектурни оптимизации, семейството Phi предоставя изключителни възможности с значително намалени изчислителни изисквания в сравнение с традиционните големи езикови модели.

## Основни цели на обучението

1. Разберете философията на дизайна и еволюцията на семейството модели Microsoft Phi от Phi-1 до Phi-4
2. Идентифицирайте ключовите иновации, включително "учебникарско качество" на тренировъчните данни и архитектурни оптимизации
3. Разпознайте предимствата и ограниченията на различните варианти Phi в различни сценарии за внедряване
4. Приложете знанията за избор на подходящи модели Phi за специфични случаи и хардуерни ограничения
5. Внедрете техники за оптимизация за внедряване на модели Phi на устройства с ограничени ресурси
6. Обяснете архитектурните предимства на семейството модели Phi спрямо традиционните големи езикови модели
7. Изберете подходящия вариант Phi въз основа на специфични изисквания за приложение и хардуерни ограничения
8. Внедрете модели Phi както в облачни, така и в периферни сценарии с оптимизирани конфигурации
9. Приложете техники за квантизация и оптимизация за подобряване на производителността на моделите Phi на целеви устройства
10. Оценете компромисите между размер на модела, производителност и възможности в семейството Phi

## Какво следва

- [02: Основи на семейството Qwen](02.QwenFamily.md)

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.