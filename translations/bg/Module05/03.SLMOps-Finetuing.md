<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-19T01:13:28+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "bg"
}
-->
# Раздел 3: Фина настройка - Персонализиране на модели за специфични задачи

## Съдържание
1. [Въведение във фина настройка](../../../Module05)
2. [Защо фина настройка е важна](../../../Module05)
3. [Видове фина настройка](../../../Module05)
4. [Фина настройка с Microsoft Olive](../../../Module05)
5. [Практически примери](../../../Module05)
6. [Най-добри практики и насоки](../../../Module05)
7. [Напреднали техники](../../../Module05)
8. [Оценка и мониторинг](../../../Module05)
9. [Чести предизвикателства и решения](../../../Module05)
10. [Заключение](../../../Module05)

## Въведение във фина настройка

**Фина настройка** е мощна техника в машинното обучение, която включва адаптиране на предварително обучен модел, за да изпълнява специфични задачи или да работи със специализирани набори от данни. Вместо да обучавате модел от нулата, фина настройка използва вече придобитите знания на предварително обучен модел и ги адаптира към вашия конкретен случай.

### Какво е фина настройка?

Фина настройка е форма на **трансферно обучение**, при която:
- Започвате с предварително обучен модел, който е научил общи модели от големи набори от данни
- Настройвате вътрешните параметри на модела с помощта на вашия специфичен набор от данни
- Запазвате ценните знания, като същевременно специализирате модела за вашата задача

Представете си, че обучавате опитен готвач да приготвя нова кухня - той вече разбира основите на готвенето, но трябва да научи специфични техники и вкусове за новия стил.

### Основни предимства

- **Ефективност във времето**: Значително по-бързо от обучението от нулата
- **Ефективност на данните**: Изисква по-малки набори от данни за постигане на добри резултати
- **Икономичност**: По-ниски изисквания за изчислителни ресурси
- **По-добра производителност**: Често постига по-добри резултати в сравнение с обучението от нулата
- **Оптимизация на ресурсите**: Прави мощния AI достъпен за по-малки екипи и организации

## Защо фина настройка е важна

### Приложения в реалния свят

Фина настройка е от съществено значение в множество сценарии:

**1. Адаптация към домейн**
- Медицински AI: Адаптиране на общи езикови модели към медицинска терминология и клинични бележки
- Правни технологии: Специализиране на модели за анализ на правни документи и преглед на договори
- Финансови услуги: Персонализиране на модели за анализ на финансови отчети и оценка на риска

**2. Специализация на задачи**
- Генериране на съдържание: Фина настройка за специфични стилове или тонове на писане
- Генериране на код: Адаптиране на модели за определени програмни езици или рамки
- Превод: Подобряване на производителността за специфични езикови двойки или технически домейни

**3. Корпоративни приложения**
- Обслужване на клиенти: Създаване на чатботове, които разбират специфична терминология на компанията
- Вътрешна документация: Изграждане на AI асистенти, запознати с организационните процеси
- Решения за специфични индустрии: Разработване на модели, които разбират жаргон и работни процеси в сектора

## Видове фина настройка

### 1. Пълна фина настройка (Instruction Fine-Tuning)

При пълна фина настройка всички параметри на модела се актуализират по време на обучението. Този подход:
- Осигурява максимална гъвкавост и потенциал за производителност
- Изисква значителни изчислителни ресурси
- Резултира в напълно нова версия на модела
- Най-подходящ за сценарии, при които разполагате със значителни данни за обучение и ресурси

### 2. Ефективна фина настройка на параметри (PEFT)

Методите PEFT актуализират само малка част от параметрите, което прави процеса по-ефективен:

#### Low-Rank Adaptation (LoRA)
- Добавя малки обучаеми матрици за разлагане към съществуващите тегла
- Драстично намалява броя на обучаемите параметри
- Поддържа производителност, близка до пълната фина настройка
- Позволява лесно превключване между различни адаптации

#### QLoRA (Quantized LoRA)
- Комбинира LoRA с техники за квантуване
- Допълнително намалява изискванията за памет
- Позволява фина настройка на по-големи модели на потребителски хардуер
- Балансира ефективност и производителност

#### Адаптери
- Вмъкват малки невронни мрежи между съществуващите слоеве
- Позволяват целенасочена фина настройка, като запазват базовия модел замразен
- Осигуряват модулен подход към персонализирането на модела

### 3. Фина настройка за специфични задачи

Фокусира се върху адаптиране на модели за специфични задачи:
- **Класификация**: Настройване на модели за задачи по категоризация
- **Генериране**: Оптимизация за създаване на съдържание и генериране на текст
- **Извличане**: Фина настройка за извличане на информация и разпознаване на именувани обекти
- **Резюмиране**: Специализиране на модели за резюмиране на документи

## Фина настройка с Microsoft Olive

Microsoft Olive е цялостен инструмент за оптимизация на модели, който опростява процеса на фина настройка, като предоставя функции на корпоративно ниво.

### Какво е Microsoft Olive?

Microsoft Olive е инструмент с отворен код за оптимизация на модели, който:
- Опростява работните процеси за фина настройка за различни хардуерни цели
- Осигурява вградена поддръжка за популярни архитектури на модели (Llama, Phi, Qwen, Gemma)
- Предлага както облачни, така и локални опции за внедряване
- Интегрира се безпроблемно с Azure ML и други AI услуги на Microsoft
- Поддържа автоматична оптимизация и квантуване

### Основни функции

- **Оптимизация, съобразена с хардуера**: Автоматично оптимизира модели за специфичен хардуер (CPU, GPU, NPU)
- **Поддръжка на множество формати**: Работи с PyTorch, Hugging Face и ONNX модели
- **Автоматизирани работни процеси**: Намалява ръчната конфигурация и проби-грешки
- **Интеграция за предприятия**: Вградена поддръжка за Azure ML и облачни внедрения
- **Разширяема архитектура**: Позволява персонализирани техники за оптимизация

### Инсталация и настройка

#### Основна инсталация

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Допълнителни зависимости

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Проверка на инсталацията

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Практически примери

### Пример 1: Основна фина настройка с Olive CLI

Този пример демонстрира фина настройка на малък езиков модел за класификация на фрази:

#### Стъпка 1: Подгответе средата си

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Стъпка 2: Фина настройка на модела

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Стъпка 3: Оптимизация за внедряване

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Пример 2: Напреднала конфигурация с персонализиран набор от данни

#### Стъпка 1: Подгответе персонализиран набор от данни

Създайте JSON файл с вашите данни за обучение:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Стъпка 2: Създайте конфигурационен файл

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Стъпка 3: Изпълнете фина настройка

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Пример 3: QLoRA фина настройка за ефективност на паметта

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Най-добри практики и насоки

### Подготовка на данни

**1. Качество на данните пред количество**
- Приоритизирайте висококачествени, разнообразни примери пред големи обеми от слаби данни
- Уверете се, че данните са представителни за вашия целеви случай
- Почиствайте и предварително обработвайте данните последователно

**2. Формат и шаблони на данните**
- Използвайте последователно форматиране за всички примери за обучение
- Създавайте ясни шаблони за вход-изход, които съответстват на вашия случай
- Включвайте подходящо форматиране на инструкции за модели с фина настройка на инструкции

**3. Разделяне на набора от данни**
- Запазете 10-20% от данните за валидиране
- Поддържайте подобни разпределения между обучителните и валидиращите набори
- Обмислете стратифицирано вземане на проби за задачи по класификация

### Конфигурация на обучението

**1. Избор на скорост на обучение**
- Започнете с по-малки скорости на обучение (1e-5 до 1e-4) за фина настройка
- Използвайте планиране на скоростта на обучение за по-добра конвергенция
- Наблюдавайте кривите на загуба, за да коригирате скоростите

**2. Оптимизация на размера на партидата**
- Балансирайте размера на партидата с наличната памет
- Използвайте натрупване на градиенти за по-големи ефективни размери на партидата
- Обмислете връзката между размера на партидата и скоростта на обучение

**3. Продължителност на обучението**
- Наблюдавайте метриките за валидиране, за да избегнете пренасищане
- Използвайте ранно спиране, когато производителността на валидирането се стабилизира
- Запазвайте контролни точки редовно за възстановяване и анализ

### Избор на модел

**1. Избор на базов модел**
- Избирайте модели, предварително обучени на подобни домейни, когато е възможно
- Обмислете размера на модела спрямо вашите изчислителни ограничения
- Оценявайте лицензионните изисквания за комерсиална употреба

**2. Избор на метод за фина настройка**
- Използвайте LoRA/QLoRA за среди с ограничени ресурси
- Избирайте пълна фина настройка, когато максималната производителност е критична
- Обмислете подходи, базирани на адаптери, за сценарии с множество задачи

### Управление на ресурсите

**1. Оптимизация на хардуера**
- Избирайте подходящ хардуер за размера на модела и метода
- Използвайте GPU памет ефективно с контролиране на градиенти
- Обмислете облачни решения за по-големи модели

**2. Управление на паметта**
- Използвайте обучение с смесена точност, когато е налично
- Прилагайте натрупване на градиенти за ограничения на паметта
- Наблюдавайте използването на GPU памет по време на обучението

## Напреднали техники

### Обучение с множество адаптери

Обучавайте множество адаптери за различни задачи, като споделяте базовия модел:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Оптимизация на хиперпараметри

Прилагайте систематично настройване на хиперпараметри:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Персонализирани функции за загуба

Прилагайте функции за загуба, специфични за домейна:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Оценка и мониторинг

### Метрики и оценка

**1. Стандартни метрики**
- **Точност**: Обща коректност за задачи по класификация
- **Перплексия**: Мярка за качество на езиковото моделиране
- **BLEU/ROUGE**: Качество на генериране на текст и резюмиране
- **F1 резултат**: Балансирана прецизност и припомняне за класификация

**2. Метрики, специфични за домейна**
- **Бенчмаркове за задачи**: Използвайте установени бенчмаркове за вашия домейн
- **Човешка оценка**: Включвайте човешка оценка за субективни задачи
- **Бизнес метрики**: Съобразявайте се с реалните бизнес цели

**3. Настройка за оценка**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Мониторинг на напредъка в обучението

**1. Проследяване на загубата**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Мониторинг на валидирането**
- Проследявайте загубата при валидиране заедно със загубата при обучение
- Наблюдавайте за признаци на пренасищане (загубата при валидиране се увеличава, докато загубата при обучение намалява)
- Използвайте ранно спиране, базирано на метрики за валидиране

**3. Мониторинг на ресурсите**
- Наблюдавайте използването на GPU/CPU
- Проследявайте моделите на използване на паметта
- Наблюдавайте скоростта и пропускателната способност на обучението

## Чести предизвикателства и решения

### Предизвикателство 1: Пренасищане

**Симптоми:**
- Загубата при обучение продължава да намалява, докато загубата при валидиране се увеличава
- Голямо разминаване между производителността при обучение и валидиране
- Лоша генерализация към нови данни

**Решения:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Предизвикателство 2: Ограничения на паметта

**Решения:**
- Използвайте контролиране на градиенти
- Прилагайте натрупване на градиенти
- Избирайте методи за ефективност на параметрите (LoRA, QLoRA)
- Използвайте паралелизъм на модела за големи модели

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Предизвикателство 3: Бавно обучение

**Решения:**
- Оптимизирайте тръбопроводите за зареждане на данни
- Използвайте обучение с смесена точност
- Прилагайте ефективни стратегии за партиди
- Обмислете разпределено обучение за големи набори от данни

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Предизвикателство 4: Лоша производителност

**Стъпки за диагностика:**
1. Проверете качеството и форматирането на данните
2. Проверете скоростта на обучение и продължителността на обучението
3. Оценете избора на базов модел
4. Прегледайте предварителната обработка и токенизацията

**Решения:**
- Увеличете разнообразието на данните за обучение
- Настройте графика на скоростта на обучение
- Опитайте различни базови модели
- Прилагайте техники за увеличаване на данните

## Заключение

Фина настройка е мощна техника, която демократизира достъпа до най-съвременни AI възможности. С помощта на инструменти като Microsoft Olive, организациите могат ефективно да адаптират предварително обучени модели към своите специфични нужди, като същевременно оптимизират производителността и ресурсите.

### Основни изводи

1. **Изберете правилния подход**: Избирайте методи за фина настройка според вашите изчислителни ресурси и изисквания за производителност
2. **Качеството на данните е важно**: Инвестирайте в висококачествени, представителни данни за обучение
3. **Мониторинг и итерация**: Непрекъснато оценявайте и подобрявайте вашите модели
4. **Използвайте инструменти**: Използ

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.