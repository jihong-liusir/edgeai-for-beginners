<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-19T01:21:50+00:00",
  "source_file": "Module03/README.md",
  "language_code": "bg"
}
-->
# Глава 03: Разгръщане на Малки Езикови Модели (SLMs)

Тази подробна глава разглежда целия жизнен цикъл на разгръщането на Малки Езикови Модели (SLMs), обхващайки теоретични основи, практически стратегии за внедряване и готови за производство контейнеризирани решения. Главата е структурирана в три прогресивни секции, които водят читателите от основни концепции до напреднали сценарии за разгръщане.

## Структура на главата и учебно пътешествие

### **[Секция 1: Напреднало обучение на SLM - Основи и оптимизация](./01.SLMAdvancedLearning.md)**
Първата секция установява теоретичната основа за разбиране на Малките Езикови Модели и тяхното стратегическо значение в разгръщанията на edge AI. Тази секция обхваща:

- **Рамка за класификация на параметри**: Подробно разглеждане на категориите SLM, от Micro SLMs (100M-1.4B параметри) до Medium SLMs (14B-30B параметри), със специален фокус върху модели като Phi-4-mini-3.8B, серията Qwen3 и Google Gemma3, включително анализ на хардуерните изисквания и паметта за всяко ниво на модела
- **Напреднали техники за оптимизация**: Изчерпателно покритие на методите за квантизация с помощта на Llama.cpp, Microsoft Olive и Apple MLX рамки, включително най-новата BitNET 1-bit квантизация с практически примери за код, показващи процеси на квантизация и резултати от бенчмаркинг
- **Стратегии за придобиване на модели**: Задълбочен анализ на екосистемата Hugging Face и каталога на модели Azure AI Foundry за корпоративно разгръщане на SLM, с примери за код за програмно изтегляне, валидиране и конвертиране на формати
- **API за разработчици**: Примери за код на Python, C++ и C#, показващи как да се зареждат модели, да се извършва инференция и да се интегрират с популярни рамки като PyTorch, TensorFlow и ONNX Runtime

Тази основна секция подчертава баланса между оперативна ефективност, гъвкавост на разгръщане и икономичност, което прави SLMs идеални за edge computing сценарии, с практически примери за код, които разработчиците могат директно да приложат в своите проекти.

### **[Секция 2: Разгръщане в локална среда - Решения с приоритет на поверителността](./02.DeployingSLMinLocalEnv.md)**
Втората секция преминава от теория към практическо внедряване, фокусирайки се върху стратегии за локално разгръщане, които дават приоритет на суверенитета на данните и оперативната независимост. Основни области включват:

- **Платформа Ollama Universal**: Изчерпателно разглеждане на разгръщане на различни платформи с акцент върху удобни за разработчици работни процеси, управление на жизнения цикъл на модела и персонализация чрез Modelfiles, включително пълни примери за интеграция на REST API и CLI автоматизационни скриптове
- **Microsoft Foundry Local**: Корпоративни решения за разгръщане с оптимизация на базата на ONNX, интеграция с Windows ML и изчерпателни функции за сигурност, с примери за код на C# и Python за интеграция с родни приложения
- **Сравнителен анализ**: Подробно сравнение на рамки, обхващащо техническа архитектура, характеристики на производителността и насоки за оптимизация на случаи на употреба, с код за бенчмаркинг за оценка на скоростта на инференция и използването на паметта на различен хардуер
- **Интеграция на API**: Примерни приложения, показващи как да се изграждат уеб услуги, чат приложения и тръбопроводи за обработка на данни с локални SLM разгръщания, с примери за код на Node.js, Python Flask/FastAPI и ASP.NET Core
- **Тестови рамки**: Автоматизирани подходи за тестване на качеството на модела, включително примери за модулни и интеграционни тестове за SLM реализации

Тази секция предоставя практическо ръководство за организации, които искат да внедрят AI решения с приоритет на поверителността, като същевременно запазват пълен контрол върху своята среда за разгръщане, с готови за употреба примери за код, които разработчиците могат да адаптират към своите специфични изисквания.

### **[Секция 3: Контейнеризирано разгръщане в облака - Решения за мащабно производство](./03.DeployingSLMinCloud.md)**
Последната секция завършва с напреднали стратегии за контейнеризирано разгръщане, като основен казус е Phi-4-mini-instruct на Microsoft. Тази секция обхваща:

- **vLLM разгръщане**: Оптимизация на инференция с висока производителност с OpenAI-съвместими API, напреднало GPU ускорение и конфигурация за производство, включително пълни Dockerfiles, Kubernetes manifests и параметри за настройка на производителността
- **Оркестрация на контейнери Ollama**: Опростени работни процеси за разгръщане с Docker Compose, варианти за оптимизация на модела и интеграция на уеб интерфейс, с примери за CI/CD тръбопроводи за автоматизирано разгръщане и тестване
- **Имплементация на ONNX Runtime**: Оптимизирано за edge разгръщане с изчерпателно конвертиране на модели, стратегии за квантизация и съвместимост на различни платформи, включително подробни примери за код за оптимизация и разгръщане на модели
- **Мониторинг и наблюдаемост**: Имплементация на Prometheus/Grafana табла с персонализирани метрики за мониторинг на производителността на SLM, включително конфигурации за предупреждения и агрегиране на логове
- **Баланс на натоварването и мащабиране**: Практически примери за стратегии за хоризонтално и вертикално мащабиране с конфигурации за автоматично мащабиране, базирани на използването на CPU/GPU и модели на заявки
- **Укрепване на сигурността**: Най-добри практики за сигурност на контейнери, включително намаляване на привилегиите, политики за мрежата и управление на тайни за API ключове и достъп до модели

Всеки подход за разгръщане е представен с пълни примери за конфигурация, процедури за тестване, контролни списъци за готовност за производство и шаблони за инфраструктура като код, които разработчиците могат директно да приложат към своите работни процеси за разгръщане.

## Основни учебни резултати

След завършване на тази глава, читателите ще овладеят:

1. **Стратегически избор на модели**: Разбиране на границите на параметрите и избор на подходящи SLMs въз основа на ограниченията на ресурсите и изискванията за производителност
2. **Майсторство в оптимизацията**: Имплементиране на напреднали техники за квантизация в различни рамки за постигане на оптимален баланс между производителност и ефективност
3. **Гъвкавост на разгръщане**: Избор между локални решения с приоритет на поверителността и мащабируеми контейнеризирани разгръщания въз основа на нуждите на организацията
4. **Готовност за производство**: Конфигуриране на системи за мониторинг, сигурност и мащабиране за корпоративни SLM разгръщания

## Практическа насоченост и приложения в реалния свят

Главата поддържа силна практическа ориентация, включваща:

- **Практически примери**: Пълни конфигурационни файлове, процедури за тестване на API и скриптове за разгръщане
- **Бенчмаркинг на производителността**: Подробни сравнения на скоростта на инференция, използването на паметта и изискванията за ресурси
- **Съображения за сигурност**: Корпоративни практики за сигурност, рамки за съответствие и стратегии за защита на данни
- **Най-добри практики**: Насоки, доказани в производството, за мониторинг, мащабиране и поддръжка

## Перспектива за бъдещето

Главата завършва с поглед към бъдещите тенденции, включително:

- Напреднали архитектури на модели с подобрени коефициенти на ефективност
- По-дълбока интеграция с хардуер със специализирани AI ускорители
- Еволюция на екосистемата към стандартизация и оперативна съвместимост
- Модели на корпоративно приемане, водени от поверителност и изисквания за съответствие

Този изчерпателен подход гарантира, че читателите са добре подготвени да се справят както с текущите предизвикателства при разгръщането на SLM, така и с бъдещите технологични разработки, като вземат информирани решения, които съответстват на специфичните изисквания и ограничения на тяхната организация.

Главата служи както като практическо ръководство за незабавно внедряване, така и като стратегически ресурс за дългосрочно планиране на AI разгръщания, подчертавайки критичния баланс между способности, ефективност и оперативно съвършенство, който определя успешните разгръщания на SLM.

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или погрешни интерпретации, произтичащи от използването на този превод.