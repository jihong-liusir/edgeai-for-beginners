<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T23:17:40+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "no"
}
-->
# EdgeAI for Nybegynnere: Læringsveier og Studieplan

### Konsentrert Læringsvei (1 uke)

| Dag | Fokus | Estimert Timer |
|------|-------|------------------|
| Dag 1 | Modul 1: EdgeAI Grunnleggende | 3 timer |
| Dag 2 | Modul 2: SLM Grunnlag | 3 timer |
| Dag 3 | Modul 3: SLM Implementering | 2 timer |
| Dag 4-5 | Modul 4: Modelloptimalisering (6 rammeverk) | 4 timer |
| Dag 6 | Modul 5: SLMOps | 3 timer |
| Dag 7 | Modul 6-7: AI-agenter & Utviklingsverktøy | 4 timer |
| Dag 8 | Modul 8: Foundry Local Toolkit (Moderne Implementering) | 1 time |

### Konsentrert Læringsvei (2 uker)

| Dag | Fokus | Estimert Timer |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunnleggende | 3 timer |
| Dag 3-4 | Modul 2: SLM Grunnlag | 3 timer |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timer |
| Dag 7-8 | Modul 4: Modelloptimalisering | 4 timer |
| Dag 9-10 | Modul 5: SLMOps | 3 timer |
| Dag 11-12 | Modul 6: AI-agenter | 2 timer |
| Dag 13-14 | Modul 7: Utviklingsverktøy | 3 timer |

### Deltidsstudie (4 uker)

| Uke | Fokus | Estimert Timer |
|------|-------|------------------|
| Uke 1 | Modul 1-2: Grunnleggende & SLM Grunnlag | 6 timer |
| Uke 2 | Modul 3-4: Implementering & Optimalisering | 6 timer |
| Uke 3 | Modul 5-6: SLMOps & AI-agenter | 5 timer |
| Uke 4 | Modul 7: Utviklingsverktøy & Integrasjon | 3 timer |

| Dag | Fokus | Estimert Timer |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunnleggende | 3 timer |
| Dag 3-4 | Modul 2: SLM Grunnlag | 3 timer |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timer |
| Dag 7-8 | Modul 4: Modelloptimalisering | 4 timer |
| Dag 9-10 | Modul 5: SLMOps | 3 timer |
| Dag 11-12 | Modul 6: SLM Agentiske Systemer | 2 timer |
| Dag 13-14 | Modul 7: EdgeAI Implementeringsprøver | 2 timer |

| Modul | Fullføringsdato | Timer Brukt | Viktige Lærdommer |
|--------|----------------|-------------|--------------|
| Modul 1: EdgeAI Grunnleggende | | | |
| Modul 2: SLM Grunnlag | | | |
| Modul 3: SLM Implementering | | | |
| Modul 4: Modelloptimalisering (6 rammeverk) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiske Systemer | | | |
| Modul 7: EdgeAI Implementeringsprøver | | | |
| Praktiske Øvelser | | | |
| Mini-prosjekt | | | |

### Deltidsstudie (4 uker)

| Uke | Fokus | Estimert Timer |
|------|-------|------------------|
| Uke 1 | Modul 1-2: Grunnleggende & SLM Grunnlag | 6 timer |
| Uke 2 | Modul 3-4: Implementering & Optimalisering | 6 timer |
| Uke 3 | Modul 5-6: SLMOps & AI-agenter | 5 timer |
| Uke 4 | Modul 7: Utviklingsverktøy & Integrasjon | 3 timer |

## Introduksjon

Velkommen til studieveiledningen for EdgeAI for Nybegynnere! Dette dokumentet er laget for å hjelpe deg med å navigere kursmaterialet effektivt og få mest mulig ut av læringsopplevelsen. Det gir strukturerte læringsveier, foreslåtte studieplaner, sammendrag av nøkkelkonsepter og tilleggsmateriell for å utdype forståelsen av EdgeAI-teknologier.

Dette er et konsist 20-timers kurs som gir essensiell kunnskap om EdgeAI på en tidseffektiv måte, perfekt for travle profesjonelle og studenter som ønsker å raskt tilegne seg praktiske ferdigheter innen dette fremvoksende feltet.

## Kursoversikt

Kurset er organisert i syv omfattende moduler:

1. **EdgeAI Grunnleggende og Transformasjon** - Forstå kjernebegrepene og teknologiskiftet
2. **Grunnlag for Små Språkmodeller (SLM)** - Utforske ulike SLM-familier og deres arkitekturer
3. **Implementering av Små Språkmodeller** - Praktiske strategier for implementering
4. **Modellformatkonvertering og Kvantisering** - Avansert optimalisering med 6 rammeverk, inkludert OpenVINO
5. **SLMOps - Operasjoner for Små Språkmodeller** - Livssyklusadministrasjon og implementering
6. **SLM Agentiske Systemer** - AI-agenter, funksjonskall og Model Context Protocol
7. **EdgeAI Implementeringsprøver** - AI Toolkit, Windows-utvikling og plattformspesifikke implementeringer
8. **Microsoft Foundry Local – Komplett Utviklerverktøy** - Lokal-først utvikling med hybrid Azure-integrasjon (Modul 08)

## Hvordan Bruke Denne Studieveiledningen

- **Progressiv Læring**: Følg modulene i rekkefølge for den mest sammenhengende læringsopplevelsen
- **Kunnskapssjekkpunkter**: Bruk selvvurderingsspørsmålene etter hver seksjon
- **Praktisk Øvelse**: Fullfør de foreslåtte øvelsene for å styrke teoretiske konsepter
- **Tilleggsmateriell**: Utforsk ekstra ressurser for emner som interesserer deg mest

## Studieplan Anbefalinger

### Konsentrert Læringsvei (1 uke)

| Dag | Fokus | Estimert Timer |
|------|-------|-----------------|
| Dag 1-2 | Modul 1: EdgeAI Grunnleggende | 6 timer |
| Dag 3-4 | Modul 2: SLM Grunnlag | 8 timer |
| Dag 5 | Modul 3: SLM Implementering | 3 timer |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timer |

### Deltidsstudie (3 uker)

| Uke | Fokus | Estimert Timer |
|------|-------|-----------------|
| Uke 1 | Modul 1: EdgeAI Grunnleggende | 6-7 timer |
| Uke 2 | Modul 2: SLM Grunnlag | 7-8 timer |
| Uke 3 | Modul 3: SLM Implementering (3t) + Modul 8: Foundry Local Toolkit (2-3t) | 5-6 timer |

## Modul 1: EdgeAI Grunnleggende og Transformasjon

### Viktige Læringsmål

- Forstå forskjellene mellom skybasert og edgebasert AI
- Mestre kjerneoptimaliseringsteknikker for ressursbegrensede miljøer
- Analysere virkelige applikasjoner av EdgeAI-teknologier
- Sette opp et utviklingsmiljø for EdgeAI-prosjekter

### Studieområder

#### Seksjon 1: EdgeAI Grunnleggende
- **Prioriterte Konsepter**: 
  - Edge vs. Sky computing-paradigmer
  - Modellkvantiseringsteknikker
  - Maskinvareakselerasjonsalternativer (NPUer, GPUer, CPUer)
  - Personvern- og sikkerhetsfordeler

- **Tilleggsmateriell**:
  - [TensorFlow Lite Dokumentasjon](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentasjon](https://docs.edgeimpulse.com)

#### Seksjon 2: Virkelige Casestudier
- **Prioriterte Konsepter**: 
  - Microsoft Phi & Mu modelløkosystem
  - Praktiske implementeringer på tvers av industrier
  - Implementeringshensyn

#### Seksjon 3: Praktisk Implementeringsveiledning
- **Prioriterte Konsepter**: 
  - Oppsett av utviklingsmiljø
  - Kvantisering og optimaliseringsverktøy
  - Vurderingsmetoder for EdgeAI-implementeringer

#### Seksjon 4: Edge Implementeringsmaskinvare
- **Prioriterte Konsepter**: 
  - Sammenligning av maskinvareplattformer
  - Optimaliseringsstrategier for spesifikk maskinvare
  - Implementeringshensyn

### Selvtestspørsmål

1. Sammenlign og kontraster skybasert AI med edgebaserte AI-implementeringer.
2. Forklar tre nøkkelmetoder for å optimalisere modeller for edge-implementering.
3. Hva er de primære fordelene med å kjøre AI-modeller på edge?
4. Beskriv prosessen med å kvantisere en modell og hvordan det påvirker ytelsen.
5. Forklar hvordan ulike maskinvareakseleratorer (NPUer, GPUer, CPUer) påvirker EdgeAI-implementering.

### Praktiske Øvelser

1. **Rask Miljøoppsett**: Konfigurer et minimalt utviklingsmiljø med essensielle pakker (30 minutter)
2. **Modellutforskning**: Last ned og undersøk en forhåndstrent liten språkmodell (1 time)
3. **Grunnleggende Kvantisering**: Prøv enkel kvantisering på en liten modell (1 time)

## Modul 2: Grunnlag for Små Språkmodeller

### Viktige Læringsmål

- Forstå de arkitektoniske prinsippene for ulike SLM-familier
- Sammenligne modellkapabiliteter på tvers av ulike parameterstørrelser
- Evaluere modeller basert på effektivitet, kapabilitet og implementeringskrav
- Gjenkjenne passende bruksområder for ulike modelfamilier

### Studieområder

#### Seksjon 1: Microsoft Phi Modeller
- **Prioriterte Konsepter**: 
  - Designfilosofiutvikling
  - Effektivitet-først arkitektur
  - Spesialiserte kapabiliteter

#### Seksjon 2: Qwen Familie
- **Prioriterte Konsepter**: 
  - Åpen kildekode-bidrag
  - Skalerbare implementeringsalternativer
  - Avansert resonneringsarkitektur

#### Seksjon 3: Gemma Familie
- **Prioriterte Konsepter**: 
  - Forskningsdrevet innovasjon
  - Multimodale kapabiliteter
  - Mobiloptimalisering

#### Seksjon 4: BitNET Familie
- **Prioriterte Konsepter**: 
  - 1-bit kvantiseringsteknologi
  - Inference-optimaliseringsrammeverk
  - Bærekraftshensyn

#### Seksjon 5: Microsoft Mu Modell
- **Prioriterte Konsepter**: 
  - Enhets-først arkitektur
  - Systemintegrasjon med Windows
  - Personvernbevarende drift

#### Seksjon 6: Phi-Silica
- **Prioriterte Konsepter**: 
  - NPU-optimalisert arkitektur
  - Ytelsesmetrikker
  - Utviklerintegrasjon

### Selvtestspørsmål

1. Sammenlign de arkitektoniske tilnærmingene til Phi- og Qwen-modellfamiliene.
2. Forklar hvordan BitNETs kvantiseringsteknologi skiller seg fra tradisjonell kvantisering.
3. Hva er de unike fordelene med Mu-modellen for Windows-integrasjon?
4. Beskriv hvordan Phi-Silica utnytter NPU-maskinvare for ytelsesoptimalisering.
5. For en mobilapplikasjon med begrenset tilkobling, hvilken modelfamilie ville være mest passende og hvorfor?

### Praktiske Øvelser

1. **Modellsammenligning**: Rask benchmark av to ulike SLM-modeller (1 time)
2. **Enkel Tekstgenerering**: Grunnleggende implementering av tekstgenerering med en liten modell (1 time)
3. **Rask Optimalisering**: Bruk en optimaliseringsteknikk for å forbedre inference-hastighet (1 time)

## Modul 3: Implementering av Små Språkmodeller

### Viktige Læringsmål

- Velge passende modeller basert på implementeringsbegrensninger
- Mestre optimaliseringsteknikker for ulike implementeringsscenarier
- Implementere SLM-er i både lokale og skybaserte miljøer
- Designe produksjonsklare konfigurasjoner for EdgeAI-applikasjoner

### Studieområder

#### Seksjon 1: Avansert SLM Læring
- **Prioriterte Konsepter**: 
  - Parameterklassifiseringsrammeverk
  - Avanserte optimaliseringsteknikker
  - Strategier for modellanskaffelse

#### Seksjon 2: Lokal Implementering
- **Prioriterte Konsepter**: 
  - Ollama plattformimplementering
  - Microsoft Foundry lokale løsninger
  - Rammeverkssammenligning

#### Seksjon 3: Containerisert Skyimplementering
- **Prioriterte Konsepter**: 
  - vLLM høyytelses inference
  - Containerorkestrering
  - ONNX Runtime implementering

### Selvtestspørsmål

1. Hvilke faktorer bør vurderes når man velger mellom lokal implementering og skyimplementering?
2. Sammenlign Ollama og Microsoft Foundry Local som implementeringsalternativer.
3. Forklar fordelene med containerisering for SLM-implementering.
4. Hva er de viktigste ytelsesmetrikker å overvåke for en edge-implementert SLM?
5. Beskriv en komplett implementeringsarbeidsflyt fra modellvalg til produksjonsimplementering.

### Praktiske Øvelser

1. **Grunnleggende Lokal Implementering**: Implementer en enkel SLM ved bruk av Ollama (1 time)
2. **Ytelsessjekk**: Kjør en rask benchmark på din implementerte modell (30 minutter)
3. **Enkel Integrasjon**: Lag en minimal applikasjon som bruker din implementerte modell (1 time)

## Modul 4: Modellformatkonvertering og Kvantisering

### Viktige Læringsmål

- Mestre avanserte kvantiseringsteknikker fra 1-bit til 8-bit presisjon
- Forstå strategier for formatkonvertering (GGUF, ONNX)
- Implementere optimalisering på tvers av seks rammeverk (Llama.cpp, Olive, OpenVINO, MLX, arbeidsflytsyntese)
- Implementere optimaliserte modeller for produksjonsmiljøer på edge for Intel, Apple og tverrplattform-maskinvare

### Studieområder

#### Seksjon 1: Grunnlag for Kvantisering
- **Prioriterte Konsepter**: 
  - Presisjonsklassifiseringsrammeverk
  - Ytelse vs. nøyaktighet avveininger
  - Minnefotavtrykkoptimalisering

#### Seksjon 2: Llama.cpp Implementering
- **Prioriterte Konsepter**: 
  - Tverrplattformimplementering
  - GGUF formatoptimalisering
  - Maskinvareakselerasjonsteknikker

#### Seksjon 3: Microsoft Olive Suite
- **Prioriterte Konsepter**: 
  - Maskinvarebevisst optimalisering
  - Implementering i bedriftsmiljøer
  - Automatiserte optimaliseringsarbeidsflyter

#### Seksjon 4: OpenVINO Toolkit
- **Prioriterte Konsepter**: 
  - Intel maskinvareoptimalisering
  - Neural Network Compression Framework (NNCF)
  - Tverrplattform inference-implementering
  - OpenVINO GenAI for LLM-distribusjon

#### Seksjon 5: Apple MLX Framework
- **Prioriterte konsepter**: 
  - Optimalisering for Apple Silicon
  - Enhetlig minnearkitektur
  - LoRA finjusteringsmuligheter

#### Seksjon 6: Arbeidsflytsyntese for Edge AI-utvikling
- **Prioriterte konsepter**: 
  - Enhetlig arbeidsflytarkitektur
  - Beslutningstrær for valg av rammeverk
  - Validering av produksjonsklarhet
  - Strategier for fremtidssikring

### Selvrefleksjonsspørsmål

1. Sammenlign kvantiseringsstrategier på tvers av ulike presisjonsnivåer (1-bit til 8-bit).
2. Forklar fordelene med GGUF-formatet for distribusjon på kanten.
3. Hvordan forbedrer maskinvarebevisst optimalisering i Microsoft Olive distribusjonseffektiviteten?
4. Hva er de viktigste fordelene med OpenVINOs NNCF for modellkompresjon?
5. Beskriv hvordan Apple MLX utnytter enhetlig minnearkitektur for optimalisering.
6. Hvordan hjelper arbeidsflytsyntese med å velge optimale optimaliseringsrammeverk?

### Praktiske øvelser

1. **Modellkvantisering**: Bruk ulike kvantiseringsnivåer på en modell og sammenlign resultatene (1 time)
2. **OpenVINO-optimalisering**: Bruk NNCF til å komprimere en modell for Intel-maskinvare (1 time)
3. **Rammeverkssammenligning**: Test den samme modellen på tre forskjellige optimaliseringsrammeverk (1 time)
4. **Ytelsesbenchmarking**: Mål optimaliseringens innvirkning på inferenshastighet og minnebruk (1 time)

## Modul 5: SLMOps - Operasjoner for små språkmodeller

### Viktige læringsmål

- Forstå prinsippene for livssyklusadministrasjon i SLMOps
- Mestre distillasjons- og finjusteringsteknikker for distribusjon på kanten
- Implementere strategier for produksjonsdistribusjon med overvåking
- Bygge arbeidsflyter for drift og vedlikehold av SLM i bedriftsklasse

### Fokusområder for studier

#### Seksjon 1: Introduksjon til SLMOps
- **Prioriterte konsepter**: 
  - Paradigmeskiftet SLMOps i AI-operasjoner
  - Kostnadseffektivitet og personvernfokusert arkitektur
  - Strategisk forretningspåvirkning og konkurransefordeler

#### Seksjon 2: Modelldistillasjon
- **Prioriterte konsepter**: 
  - Kunnskapsoverføringsteknikker
  - Implementering av totrinns distillasjonsprosess
  - Distillasjonsarbeidsflyter i Azure ML

#### Seksjon 3: Finjusteringsstrategier
- **Prioriterte konsepter**: 
  - Parameter-effektiv finjustering (PEFT)
  - Avanserte metoder som LoRA og QLoRA
  - Multi-adapter trening og hyperparameteroptimalisering

#### Seksjon 4: Produksjonsdistribusjon
- **Prioriterte konsepter**: 
  - Modellkonvertering og kvantisering for produksjon
  - Konfigurasjon for Foundry Local-distribusjon
  - Ytelsesbenchmarking og kvalitetsvalidering

### Selvrefleksjonsspørsmål

1. Hvordan skiller SLMOps seg fra tradisjonell MLOps?
2. Forklar fordelene med modelldistillasjon for distribusjon på kanten.
3. Hva er de viktigste hensynene for finjustering av SLM-er i ressursbegrensede miljøer?
4. Beskriv en komplett produksjonsdistribusjonspipeline for Edge AI-applikasjoner.

### Praktiske øvelser

1. **Grunnleggende distillasjon**: Lag en mindre modell fra en større lærermodell (1 time)
2. **Finjusteringseksperiment**: Finjuster en modell for et spesifikt domene (1 time)
3. **Distribusjonspipeline**: Sett opp en grunnleggende CI/CD-pipeline for modelldistribusjon (1 time)

## Modul 6: SLM Agentiske Systemer - AI-agenter og funksjonskalling

### Viktige læringsmål

- Bygge intelligente AI-agenter for kantmiljøer ved bruk av små språkmodeller
- Implementere funksjonskall med systematiske arbeidsflyter
- Mestre integrasjon av Model Context Protocol (MCP) for standardisert verktøysinteraksjon
- Skape sofistikerte agentiske systemer med minimal menneskelig intervensjon

### Fokusområder for studier

#### Seksjon 1: AI-agenter og SLM-grunnlag
- **Prioriterte konsepter**: 
  - Rammeverk for klassifisering av agenter (refleks, modellbasert, målbasert, læringsagenter)
  - Analyse av avveininger mellom SLM og LLM
  - Designmønstre for agenter spesifikke for kanten
  - Ressursoptimalisering for agenter

#### Seksjon 2: Funksjonskalling i små språkmodeller
- **Prioriterte konsepter**: 
  - Implementering av systematiske arbeidsflyter (intensjonsdeteksjon, JSON-utgang, ekstern utførelse)
  - Plattformspesifikke implementeringer (Phi-4-mini, utvalgte Qwen-modeller, Microsoft Foundry Local)
  - Avanserte eksempler (samarbeid mellom flere agenter, dynamisk verktøyvalg)
  - Produksjonshensyn (ratebegrensning, revisjonslogging, sikkerhetstiltak)

#### Seksjon 3: Integrasjon av Model Context Protocol (MCP)
- **Prioriterte konsepter**: 
  - Protokollarkitektur og lagdelt systemdesign
  - Støtte for flere backend-løsninger (Ollama for utvikling, vLLM for produksjon)
  - Tilkoblingsprotokoller (STDIO og SSE-modus)
  - Virkelige applikasjoner (webautomatisering, databehandling, API-integrasjon)

### Selvrefleksjonsspørsmål

1. Hva er de viktigste arkitektoniske hensynene for AI-agenter på kanten?
2. Hvordan forbedrer funksjonskalling agentens evner?
3. Forklar rollen til Model Context Protocol i agentkommunikasjon.

### Praktiske øvelser

1. **Enkel agent**: Bygg en grunnleggende AI-agent med funksjonskalling (1 time)
2. **MCP-integrasjon**: Implementer MCP i en agentapplikasjon (30 minutter)

## Modul 7: Eksempler på EdgeAI-implementering

### Viktige læringsmål

- Mestre AI Toolkit for Visual Studio Code for omfattende EdgeAI-utviklingsarbeidsflyter
- Få ekspertise i Windows AI Foundry-plattformen og NPU-optimaliseringsstrategier
- Implementere EdgeAI på tvers av flere maskinvareplattformer og distribusjonsscenarier
- Bygge produksjonsklare EdgeAI-applikasjoner med plattformspesifikke optimaliseringer

### Fokusområder for studier

#### Seksjon 1: AI Toolkit for Visual Studio Code
- **Prioriterte konsepter**: 
  - Omfattende Edge AI-utviklingsmiljø i VS Code
  - Modellkatalog og oppdagelse for distribusjon på kanten
  - Lokale test-, optimaliserings- og agentutviklingsarbeidsflyter
  - Ytelsesovervåking og evaluering for kantscenarier

#### Seksjon 2: Windows EdgeAI-utviklingsveiledning
- **Prioriterte konsepter**: 
  - Omfattende oversikt over Windows AI Foundry-plattformen
  - Phi Silica API for effektiv NPU-inferens
  - Datamaskinvisjons-API-er for bildebehandling og OCR
  - Foundry Local CLI for lokal utvikling og testing

#### Seksjon 3: Plattformspesifikke implementeringer
- **Prioriterte konsepter**: 
  - Distribusjon på NVIDIA Jetson Orin Nano (67 TOPS AI-ytelse)
  - Mobilapplikasjoner med .NET MAUI og ONNX Runtime GenAI
  - Azure EdgeAI-løsninger med hybrid arkitektur mellom sky og kant
  - Windows ML-optimalisering med universell maskinvarestøtte
  - Foundry Local-applikasjoner med personvernfokusert RAG-implementering

### Selvrefleksjonsspørsmål

1. Hvordan effektiviserer AI Toolkit EdgeAI-utviklingsarbeidsflyten?
2. Sammenlign distribusjonsstrategier på tvers av forskjellige maskinvareplattformer.
3. Hva er fordelene med Windows AI Foundry for utvikling på kanten?
4. Forklar rollen til NPU-optimalisering i moderne Edge AI-applikasjoner.
5. Hvordan utnytter Phi Silica API NPU-maskinvare for ytelsesoptimalisering?
6. Sammenlign fordelene med lokal kontra skybasert distribusjon for personvernsensitive applikasjoner.

### Praktiske øvelser

1. **AI Toolkit-oppsett**: Konfigurer AI Toolkit og optimaliser en modell (1 time)
2. **Windows AI Foundry**: Bygg en enkel Windows AI-applikasjon ved bruk av Phi Silica API (1 time)
3. **Tverrplattformdistribusjon**: Distribuer den samme modellen på to forskjellige plattformer (1 time)
4. **NPU-optimalisering**: Test NPU-ytelse med Windows AI Foundry-verktøy (30 minutter)

## Modul 8: Microsoft Foundry Local – Komplett utviklerverktøysett (modernisert)

### Viktige læringsmål

- Installere og konfigurere Foundry Local med moderne SDK-integrasjon
- Implementere avanserte multi-agent-systemer med koordinator-mønstre
- Bygge intelligente modellrutere med automatisk oppgavebasert valg
- Distribuere produksjonsklare AI-løsninger med omfattende overvåking
- Integrere med Azure AI Foundry for hybride distribusjonsscenarier
- Mestre moderne SDK-mønstre med FoundryLocalManager og OpenAI-klient

### Fokusområder for studier

#### Seksjon 1: Moderne installasjon og konfigurasjon
- **Prioriterte konsepter**: 
  - FoundryLocalManager SDK-integrasjon
  - Automatisk tjenesteoppdagelse og helsesjekk
  - Konfigurasjonsmønstre basert på miljø
  - Hensyn for produksjonsdistribusjon

#### Seksjon 2: Avanserte multi-agent-systemer
- **Prioriterte konsepter**: 
  - Koordinator-mønster med spesialistagenter
  - Spesialisering for henting, resonnement og utførelse
  - Mekanismer for tilbakemeldingssløyfer for forbedring
  - Ytelsesovervåking og statistikksporing

#### Seksjon 3: Intelligent modellruting
- **Prioriterte konsepter**: 
  - Algoritmer for modellvalg basert på nøkkelord
  - Støtte for flere modeller (generell, resonnement, kode, kreativ)
  - Konfigurasjon av miljøvariabler for fleksibilitet
  - Helsesjekk for tjenester og feilhåndtering

#### Seksjon 4: Produksjonsklar implementering
- **Prioriterte konsepter**: 
  - Omfattende feilhåndtering og fallback-mekanismer
  - Overvåking av forespørsler og ytelsessporing
  - Interaktive Jupyter-notebook-eksempler med benchmarks
  - Integrasjonsmønstre med eksisterende applikasjoner

### Selvrefleksjonsspørsmål

1. Hvordan skiller den moderne FoundryLocalManager-tilnærmingen seg fra manuelle REST-kall?
2. Forklar koordinator-mønsteret og hvordan det orkestrerer spesialistagenter.
3. Hvordan velger den intelligente ruteren passende modeller basert på innholdet i forespørselen?
4. Hva er de viktigste komponentene i et produksjonsklart AI-agent-system?
5. Hvordan implementerer du omfattende helsesjekk for Foundry Local-tjenester?
6. Sammenlign fordelene med den moderniserte tilnærmingen kontra tradisjonelle implementeringsmønstre.

### Praktiske øvelser

1. **Moderne SDK-oppsett**: Konfigurer FoundryLocalManager med automatisk tjenesteoppdagelse (30 minutter)
2. **Multi-agent-system**: Kjør den avanserte koordinatoren med spesialistagenter (30 minutter)
3. **Intelligent ruting**: Test modellruteren med forskjellige forespørselstyper (30 minutter)
4. **Interaktiv utforskning**: Bruk Jupyter-notebooks for å utforske avanserte funksjoner (45 minutter)
5. **Produksjonsdistribusjon**: Implementer overvåkings- og feilhåndteringsmønstre (30 minutter)
6. **Hybrid integrasjon**: Konfigurer fallback-scenarier for Azure AI Foundry (30 minutter)

## Tidsallokeringsveiledning

For å hjelpe deg med å få mest mulig ut av den 20-timers kursplanen, her er en foreslått fordeling av tiden:

| Aktivitet | Tidsallokering | Beskrivelse |
|----------|----------------|-------------|
| Lesing av kjerneinnhold | 9 timer | Fokus på essensielle konsepter i hver modul |
| Praktiske øvelser | 6 timer | Praktisk implementering av viktige teknikker |
| Selvrefleksjon | 2 timer | Test forståelsen din gjennom spørsmål og refleksjon |
| Mini-prosjekt | 3 timer | Bruk kunnskapen til en liten praktisk implementering |

### Fokusområder basert på tidsbegrensning

**Hvis du bare har 10 timer:**
- Fullfør modulene 1, 2 og 3 (grunnleggende EdgeAI-konsepter)
- Gjør minst én praktisk øvelse per modul
- Fokuser på å forstå kjernekonseptene fremfor implementeringsdetaljer

**Hvis du kan dedikere hele 20 timer:**
- Fullfør alle syv modulene
- Utfør viktige praktiske øvelser fra hver modul
- Fullfør ett mini-prosjekt fra modul 7
- Utforsk minst 2-3 tilleggskilder

**Hvis du har mer enn 20 timer:**
- Fullfør alle modulene med detaljerte øvelser
- Bygg flere mini-prosjekter
- Utforsk avanserte optimaliseringsteknikker i modul 4
- Implementer produksjonsdistribusjon fra modul 5

## Essensielle ressurser

Disse nøye utvalgte ressursene gir mest verdi for din begrensede studietid:

### Må-lese dokumentasjon
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektive verktøyet for modelloptimalisering
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Raskeste måte å distribuere SLM-er lokalt
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referanse for en ledende kantoptimalisert modell
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattende optimaliseringsverktøysett
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrert EdgeAI-utviklingsmiljø
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-spesifikk EdgeAI-utviklingsplattform

### Tidsbesparende verktøy
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Rask modelltilgang og distribusjon
- [Gradio](https://www.gradio.app/docs/interface) - Rask UI-utvikling for AI-demoer
- [Microsoft Olive](https://github.com/microsoft/Olive) - Forenklet modelloptimalisering
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Rammeverk for kompresjon av nevrale nettverk
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Verktøysett for distribusjon av store språkmodeller

## Fremdriftssporingsmal

Bruk denne forenklede malen for å spore læringsfremdriften din gjennom det 20-timers kurset:

| Modul | Fullføringsdato | Timer brukt | Viktige lærdommer |
|--------|----------------|-------------|---------------|
| Modul 1: EdgeAI-grunnleggende | | | |
| Modul 2: SLM-grunnlag | | | |
| Modul 3: SLM-distribusjon | | | |
| Modul 4: Modelloptimalisering | | | |
| Modul 5: SLMOps | | | |
| Modul 6: AI-agenter | | | |
| Modul 7: Utviklingsverktøy | | | |
| Modul 8: Foundry Local Toolkit | | | |
| Praktiske øvelser | | | |
| Mini-prosjekt | | | |

## Ideer til mini-prosjekter

Vurder å fullføre ett av disse prosjektene for å øve på EdgeAI-konsepter (hver designet for å ta 2-4 timer):

### Nybegynnerprosjekter (2-3 timer hver)
1. **Edge Tekstassistent**: Lag et enkelt offline verktøy for tekstfullføring ved hjelp av en liten språkmodell
2. **Modellsammenligningsdashboard**: Bygg en grunnleggende visualisering av ytelsesmetrikker på tvers av ulike SLM-er
3. **Optimaliseringseksperiment**: Mål effekten av forskjellige kvantiseringsnivåer på samme basismodell

### Prosjekter for viderekomne (3-4 timer hver)
4. **AI Toolkit Workflow**: Bruk VS Code AI Toolkit til å optimalisere og distribuere en modell fra start til slutt
5. **Windows AI Foundry-applikasjon**: Lag en Windows-app ved hjelp av Phi Silica API og NPU-optimalisering
6. **Plattformuavhengig distribusjon**: Distribuer den samme optimaliserte modellen på Windows (OpenVINO) og mobil (.NET MAUI)
7. **Funksjonskall-agent**: Bygg en AI-agent med funksjonskallmuligheter for edge-scenarier

### Avanserte integrasjonsprosjekter (4-5 timer hver)
8. **OpenVINO-optimaliseringspipeline**: Implementer komplett modelloptimalisering ved hjelp av NNCF og GenAI-verktøy
9. **SLMOps-pipeline**: Implementer en komplett modelllivssyklus fra trening til edge-distribusjon
10. **Multi-modell edge-system**: Distribuer flere spesialiserte modeller som samarbeider på edge-maskinvare
11. **MCP-integrasjonssystem**: Bygg et agentbasert system ved hjelp av Model Context Protocol for verktøysinteraksjon

## Referanser

- Microsoft Learn (Foundry Local)
  - Oversikt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Kom i gang: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI-referanse: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrer med inferens-SDK-er: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Åpne WebUI-veiledning: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompiler Hugging Face-modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Oversikt: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agenter (oversikt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimaliserings- og inferensverktøy
  - Microsoft Olive (dokumentasjon): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (kom i gang): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive-integrasjon: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokumentasjon): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokumentasjon): https://ml-explore.github.io/mlx/build/html/index.html
- Distribusjonsrammeverk og modeller
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokumentasjon): https://docs.vllm.ai/
  - Ollama (kom i gang): https://github.com/ollama/ollama#get-started
- Utviklerverktøy (Windows og VS Code)
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (oversikt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Læringsfellesskap

Bli med i diskusjonen og koble deg til andre lærende:
- GitHub-diskusjoner på [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Konklusjon

EdgeAI representerer frontlinjen for implementering av kunstig intelligens, og bringer kraftige funksjoner direkte til enheter samtidig som viktige bekymringer rundt personvern, forsinkelse og tilkobling adresseres. Dette 20-timers kurset gir deg den essensielle kunnskapen og praktiske ferdighetene til å begynne å jobbe med EdgeAI-teknologier umiddelbart.

Kurset er bevisst kortfattet og fokusert på de viktigste konseptene, slik at du raskt kan oppnå verdifull ekspertise uten en overveldende tidsforpliktelse. Husk at praktisk øvelse, selv med enkle eksempler, er nøkkelen til å styrke det du har lært.

Lykke til med læringen!

---

