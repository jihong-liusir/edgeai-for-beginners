<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-09T14:11:38+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "no"
}
-->
# EdgeAI for Nybegynnere: Læringsveier og Studieplan

### Konsentrert Læringsvei (1 uke)

| Dag | Fokus | Estimerte Timer |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduksjon til EdgeAI | 1-2 timer |
| Dag 1 | Modul 1: EdgeAI Grunnleggende | 3 timer |
| Dag 2 | Modul 2: SLM Grunnlag | 3 timer |
| Dag 3 | Modul 3: SLM Implementering | 2 timer |
| Dag 4-5 | Modul 4: Modelloptimalisering (6 rammeverk) | 4 timer |
| Dag 6 | Modul 5: SLMOps | 3 timer |
| Dag 7 | Modul 6-7: AI-agenter & Utviklingsverktøy | 4 timer |
| Dag 8 | Modul 8: Foundry Local Toolkit (Moderne Implementering) | 1 time |

### Konsentrert Læringsvei (2 uker)

| Dag | Fokus | Estimerte Timer |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunnleggende | 3 timer |
| Dag 3-4 | Modul 2: SLM Grunnlag | 3 timer |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timer |
| Dag 7-8 | Modul 4: Modelloptimalisering | 4 timer |
| Dag 9-10 | Modul 5: SLMOps | 3 timer |
| Dag 11-12 | Modul 6: AI-agenter | 2 timer |
| Dag 13-14 | Modul 7: Utviklingsverktøy | 3 timer |

### Deltidsstudie (4 uker)

| Uke | Fokus | Estimerte Timer |
|------|-------|------------------|
| Uke 1 | Modul 1-2: Grunnleggende & SLM Grunnlag | 6 timer |
| Uke 2 | Modul 3-4: Implementering & Optimalisering | 6 timer |
| Uke 3 | Modul 5-6: SLMOps & AI-agenter | 5 timer |
| Uke 4 | Modul 7: Utviklingsverktøy & Integrasjon | 3 timer |

| Dag | Fokus | Estimerte Timer |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduksjon til EdgeAI | 1-2 timer |
| Dag 1-2 | Modul 1: EdgeAI Grunnleggende | 3 timer |
| Dag 3-4 | Modul 2: SLM Grunnlag | 3 timer |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timer |
| Dag 7-8 | Modul 4: Modelloptimalisering | 4 timer |
| Dag 9-10 | Modul 5: SLMOps | 3 timer |
| Dag 11-12 | Modul 6: SLM Agentiske Systemer | 2 timer |
| Dag 13-14 | Modul 7: EdgeAI Implementeringsprøver | 2 timer |

| Modul | Fullføringsdato | Timer Brukt | Viktige Lærdommer |
|--------|----------------|-------------|-------------------|
| Modul 0: Introduksjon til EdgeAI | | | |
| Modul 1: EdgeAI Grunnleggende | | | |
| Modul 2: SLM Grunnlag | | | |
| Modul 3: SLM Implementering | | | |
| Modul 4: Modelloptimalisering (6 rammeverk) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiske Systemer | | | |
| Modul 7: EdgeAI Implementeringsprøver | | | |
| Praktiske Øvelser | | | |
| Mini-prosjekt | | | |

### Deltidsstudie (4 uker)

| Uke | Fokus | Estimerte Timer |
|------|-------|------------------|
| Uke 1 | Modul 1-2: Grunnleggende & SLM Grunnlag | 6 timer |
| Uke 2 | Modul 3-4: Implementering & Optimalisering | 6 timer |
| Uke 3 | Modul 5-6: SLMOps & AI-agenter | 5 timer |
| Uke 4 | Modul 7: Utviklingsverktøy & Integrasjon | 3 timer |

## Introduksjon

Velkommen til studieveiledningen for EdgeAI for Nybegynnere! Dette dokumentet er laget for å hjelpe deg med å navigere kursmaterialet effektivt og få mest mulig ut av læringsopplevelsen. Det gir strukturerte læringsveier, foreslåtte studieplaner, sammendrag av nøkkelkonsepter og tilleggsmateriell for å utdype forståelsen av Edge AI-teknologier.

Dette er et konsist 20-timers kurs som gir essensiell kunnskap om EdgeAI i et tidseffektivt format, perfekt for travle profesjonelle og studenter som ønsker å raskt tilegne seg praktiske ferdigheter innen dette fremvoksende feltet.

## Kursoversikt

Kurset er organisert i åtte omfattende moduler:

0. **Introduksjon til EdgeAI** - Grunnlag og kontekst med bruksområder i industrien og læringsmål
1. **EdgeAI Grunnleggende og Transformasjon** - Forståelse av kjernebegreper og teknologiskift
2. **Grunnlag for Små Språkmodeller (SLM)** - Utforsking av ulike SLM-familier og deres arkitekturer
3. **Implementering av Små Språkmodeller** - Praktiske implementeringsstrategier
4. **Modellformatkonvertering og Kvantisering** - Avansert optimalisering med 6 rammeverk, inkludert OpenVINO
5. **SLMOps - Operasjoner for Små Språkmodeller** - Livssyklusadministrasjon og implementering
6. **SLM Agentiske Systemer** - AI-agenter, funksjonskall og Model Context Protocol
7. **EdgeAI Implementeringsprøver** - AI Toolkit, Windows-utvikling og plattformspesifikke implementeringer
8. **Microsoft Foundry Local – Komplett Utviklerverktøy** - Lokal-først utvikling med hybrid Azure-integrasjon (Modul 08)

## Hvordan Bruke Denne Studieveiledningen

- **Progressiv Læring**: Følg modulene i rekkefølge for den mest sammenhengende læringsopplevelsen
- **Kunnskapssjekkpunkter**: Bruk selvvurderingsspørsmålene etter hver seksjon
- **Praktisk Øvelse**: Fullfør de foreslåtte øvelsene for å styrke teoretiske konsepter
- **Tilleggsmateriell**: Utforsk ekstra ressurser for emner som interesserer deg mest

## Anbefalte Studieplaner

### Konsentrert Læringsvei (1 uke)

| Dag | Fokus | Estimerte Timer |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduksjon til EdgeAI | 1-2 timer |
| Dag 1-2 | Modul 1: EdgeAI Grunnleggende | 6 timer |
| Dag 3-4 | Modul 2: SLM Grunnlag | 8 timer |
| Dag 5 | Modul 3: SLM Implementering | 3 timer |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timer |

### Deltidsstudie (3 uker)

| Uke | Fokus | Estimerte Timer |
|------|-------|------------------|
| Uke 1 | Modul 0: Introduksjon + Modul 1: EdgeAI Grunnleggende | 7-9 timer |
| Uke 2 | Modul 2: SLM Grunnlag | 7-8 timer |
| Uke 3 | Modul 3: SLM Implementering (3t) + Modul 8: Foundry Local Toolkit (2-3t) | 5-6 timer |

## Modul 0: Introduksjon til EdgeAI

### Viktige Læringsmål

- Forstå hva Edge AI er og hvorfor det er viktig i dagens teknologilandskap
- Identifisere store industrier transformert av Edge AI og deres spesifikke bruksområder
- Forstå fordelene med Små Språkmodeller (SLM) for implementering på kanten
- Etablere klare læringsforventninger og mål for hele kurset
- Gjenkjenne karrieremuligheter og ferdighetskrav innen Edge AI

### Studieområder

#### Seksjon 1: Edge AI Paradigme og Definisjon
- **Prioriterte Konsepter**: 
  - Edge AI vs. tradisjonell skybasert AI-prosessering
  - Konvergensen av maskinvare, modelloptimalisering og forretningsbehov
  - Sanntids-, personvernbevarende og kostnadseffektiv AI-implementering

#### Seksjon 2: Bruksområder i Industrien
- **Prioriterte Konsepter**: 
  - Produksjon & Industri 4.0: Prediktivt vedlikehold og kvalitetskontroll
  - Helsevesen: Diagnostisk bildebehandling og pasientovervåking
  - Autonome Systemer: Selvkjørende kjøretøy og transport
  - Smarte Byer: Trafikkstyring og offentlig sikkerhet
  - Forbrukerteknologi: Smarttelefoner, wearables og smarte hjem

#### Seksjon 3: Grunnlag for Små Språkmodeller
- **Prioriterte Konsepter**: 
  - SLM-egenskaper og ytelsessammenligninger
  - Parameter-effektivitet vs. kapabilitet-avveininger
  - Begrensninger og optimaliseringsstrategier for implementering på kanten

#### Seksjon 4: Læringsrammeverk og Karrierevei
- **Prioriterte Konsepter**: 
  - Kursarkitektur og progressiv mestringstilnærming
  - Tekniske ferdigheter og praktiske implementeringsmål
  - Karriereutviklingsmuligheter og bruksområder i industrien

### Selvvurderingsspørsmål

1. Hva er de tre viktigste teknologiske trendene som har muliggjort Edge AI?
2. Sammenlign fordelene og utfordringene med Edge AI vs. skybasert AI.
3. Nevn tre industrier der Edge AI gir kritisk forretningsverdi og forklar hvorfor.
4. Hvordan gjør Små Språkmodeller Edge AI praktisk for implementering i virkeligheten?
5. Hva er de viktigste tekniske ferdighetene du vil utvikle gjennom dette kurset?
6. Beskriv den fire-fasede læringstilnærmingen som brukes i dette kurset.

### Praktiske Øvelser

1. **Industriforskning**: Velg ett bruksområde i industrien og undersøk en virkelig Edge AI-implementering (30 minutter)
2. **Modellutforsking**: Bla gjennom tilgjengelige Små Språkmodeller på Hugging Face og sammenlign parameterantall og kapabiliteter (30 minutter)
3. **Læringsplanlegging**: Gå gjennom hele kursstrukturen og lag din personlige studieplan (15 minutter)

### Tilleggsmateriell

- [Edge AI Markedsoversikt - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [Oversikt over Små Språkmodeller - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Edge Computing Foundation](https://www.edgecomputing.org/)

## Modul 1: EdgeAI Grunnleggende og Transformasjon

### Viktige Læringsmål

- Forstå forskjellene mellom skybasert og kantbasert AI
- Mestre kjerneoptimaliseringsteknikker for ressursbegrensede miljøer
- Analysere virkelige bruksområder for EdgeAI-teknologier
- Sette opp et utviklingsmiljø for EdgeAI-prosjekter

### Studieområder

#### Seksjon 1: EdgeAI Grunnleggende
- **Prioriterte Konsepter**: 
  - Edge vs. Sky computing paradigmer
  - Modellkvantiseringsteknikker
  - Maskinvareakselerasjonsalternativer (NPUs, GPUs, CPUs)
  - Personvern- og sikkerhetsfordeler

- **Tilleggsmateriell**:
  - [TensorFlow Lite Dokumentasjon](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentasjon](https://docs.edgeimpulse.com)

#### Seksjon 2: Virkelige Casestudier
- **Prioriterte Konsepter**: 
  - Microsoft Phi & Mu modelløkosystem
  - Praktiske implementeringer på tvers av industrier
  - Implementeringshensyn

#### Seksjon 3: Praktisk Implementeringsveiledning
- **Prioriterte Konsepter**: 
  - Oppsett av utviklingsmiljø
  - Kvantisering og optimaliseringsverktøy
  - Vurderingsmetoder for EdgeAI-implementeringer

#### Seksjon 4: Maskinvare for Kantimplementering
- **Prioriterte Konsepter**: 
  - Sammenligning av maskinvareplattformer
  - Optimaliseringsstrategier for spesifikk maskinvare
  - Implementeringshensyn

### Selvvurderingsspørsmål

1. Sammenlign og kontraster skybasert AI med kantbasert AI-implementeringer.
2. Forklar tre nøkkelteknikker for å optimalisere modeller for kantimplementering.
3. Hva er de primære fordelene med å kjøre AI-modeller på kanten?
4. Beskriv prosessen med å kvantisere en modell og hvordan det påvirker ytelsen.
5. Forklar hvordan ulike maskinvareakseleratorer (NPUs, GPUs, CPUs) påvirker EdgeAI-implementering.

### Praktiske Øvelser

1. **Rask Miljøoppsett**: Konfigurer et minimalt utviklingsmiljø med essensielle pakker (30 minutter)
2. **Modellutforsking**: Last ned og undersøk en forhåndstrent liten språkmodell (1 time)
3. **Grunnleggende Kvantisering**: Prøv enkel kvantisering på en liten modell (1 time)

## Modul 2: Grunnlag for Små Språkmodeller

### Viktige Læringsmål

- Forstå de arkitektoniske prinsippene for ulike SLM-familier
- Sammenligne modellkapabiliteter på tvers av ulike parameterstørrelser
- Evaluere modeller basert på effektivitet, kapabilitet og implementeringskrav
- Gjenkjenne passende bruksområder for ulike modelfamilier

### Studieområder

#### Seksjon 1: Microsoft Phi Modelfamilie
- **Prioriterte Konsepter**: 
  - Designfilosofiutvikling
  - Effektivitet-først arkitektur
  - Spesialiserte kapabiliteter

#### Seksjon 2: Qwen Familie
- **Prioriterte Konsepter**: 
  - Åpen kildekode-bidrag
  - Skalerbare implementeringsalternativer
  - Avansert resonneringsarkitektur

#### Seksjon 3: Gemma Familie
- **Prioriterte Konsepter**: 
  - Forskningsdrevet innovasjon
  - Multimodale kapabiliteter
  - Mobiloptimalisering

#### Seksjon 4: BitNET Familie
- **Prioriterte Konsepter**: 
  - 1-bit kvantiseringsteknologi
  - Inference-optimaliseringsrammeverk
  - Bærekraftshensyn

#### Seksjon 5: Microsoft Mu Modell
- **Prioriterte Konsepter**: 
  - Enhets-først arkitektur
  - Systemintegrasjon med Windows
  - Personvernbevarende operasjon

#### Seksjon 6: Phi-Silica
- **Prioriterte Konsepter**: 
  - NPU-optimalisert arkitektur
  - Ytelsesmålinger
  - Utviklerintegrasjon

### Selvvurderingsspørsmål

1. Sammenlign de arkitektoniske tilnærmingene til Phi- og Qwen-modellfamiliene.
2. Forklar hvordan BitNETs kvantiseringsteknologi skiller seg fra tradisjonell kvantisering.
3. Hva er de unike fordelene med Mu-modellen for Windows-integrasjon?
4. Beskriv hvordan Phi-Silica utnytter NPU-maskinvare for ytelsesoptimalisering.
5. For en mobilapplikasjon med begrenset tilkobling, hvilken modellfamilie vil være mest passende og hvorfor?

### Praktiske Øvelser

1. **Modellsammenligning**: Rask benchmark av to forskjellige SLM-modeller (1 time)
2. **Enkel Tekstgenerering**: Grunnleggende implementering av tekstgenerering med en liten modell (1 time)
3. **Rask Optimalisering**: Bruk en optimaliseringsteknikk for å forbedre inferenshastighet (1 time)

## Modul 3: Distribusjon av Små Språkmodeller

### Viktige Læringsmål

- Velge passende modeller basert på distribusjonsbegrensninger
- Mestre optimaliseringsteknikker for ulike distribusjonsscenarier
- Implementere SLM-er i både lokale og skybaserte miljøer
- Utforme produksjonsklare konfigurasjoner for EdgeAI-applikasjoner

### Fokusområder for Studier

#### Seksjon 1: Avansert Læring om SLM
- **Prioriterte Konsepter**: 
  - Rammeverk for parameterklassifisering
  - Avanserte optimaliseringsteknikker
  - Strategier for modellanskaffelse

#### Seksjon 2: Lokal Distribusjon
- **Prioriterte Konsepter**: 
  - Distribusjon på Ollama-plattformen
  - Microsoft Foundry lokale løsninger
  - Sammenligning av rammeverk

#### Seksjon 3: Containerbasert Skydistribusjon
- **Prioriterte Konsepter**: 
  - vLLM høyytelsesinferens
  - Orkestrering av containere
  - Implementering av ONNX Runtime

### Selvtestspørsmål

1. Hvilke faktorer bør vurderes når man velger mellom lokal distribusjon og skybasert distribusjon?
2. Sammenlign Ollama og Microsoft Foundry Local som distribusjonsalternativer.
3. Forklar fordelene med containerisering for SLM-distribusjon.
4. Hva er de viktigste ytelsesmålene å overvåke for en SLM distribuert på kanten?
5. Beskriv en komplett distribusjonsarbeidsflyt fra modellvalg til produksjonsimplementering.

### Praktiske Øvelser

1. **Grunnleggende Lokal Distribusjon**: Distribuer en enkel SLM ved bruk av Ollama (1 time)
2. **Ytelsessjekk**: Utfør en rask benchmark på din distribuerte modell (30 minutter)
3. **Enkel Integrasjon**: Lag en minimal applikasjon som bruker din distribuerte modell (1 time)

## Modul 4: Modellformatkonvertering og Kvantisering

### Viktige Læringsmål

- Mestre avanserte kvantiseringsteknikker fra 1-bit til 8-bit presisjon
- Forstå strategier for formatkonvertering (GGUF, ONNX)
- Implementere optimalisering på tvers av seks rammeverk (Llama.cpp, Olive, OpenVINO, MLX, arbeidsflytsyntese)
- Distribuere optimaliserte modeller for produksjonsmiljøer på kanten med Intel, Apple og plattformuavhengig maskinvare

### Fokusområder for Studier

#### Seksjon 1: Grunnleggende Kvantisering
- **Prioriterte Konsepter**: 
  - Rammeverk for presisjonsklassifisering
  - Avveining mellom ytelse og nøyaktighet
  - Optimalisering av minnebruk

#### Seksjon 2: Implementering av Llama.cpp
- **Prioriterte Konsepter**: 
  - Plattformuavhengig distribusjon
  - Optimalisering av GGUF-format
  - Maskinvareakselerasjonsteknikker

#### Seksjon 3: Microsoft Olive Suite
- **Prioriterte Konsepter**: 
  - Maskinvarebevisst optimalisering
  - Distribusjon på bedriftsnivå
  - Automatiserte optimaliseringsarbeidsflyter

#### Seksjon 4: OpenVINO Toolkit
- **Prioriterte Konsepter**: 
  - Optimalisering for Intel-maskinvare
  - Neural Network Compression Framework (NNCF)
  - Plattformuavhengig inferensdistribusjon
  - OpenVINO GenAI for distribusjon av LLM-er

#### Seksjon 5: Apple MLX Framework
- **Prioriterte Konsepter**: 
  - Optimalisering for Apple Silicon
  - Enhetlig minnearkitektur
  - LoRA finjusteringsevner

#### Seksjon 6: Arbeidsflytsyntese for Edge AI-utvikling
- **Prioriterte Konsepter**: 
  - Enhetlig arbeidsflytarkitektur
  - Beslutningstrær for rammeverksvalg
  - Validering av produksjonsklarhet
  - Strategier for fremtidssikring

### Selvtestspørsmål

1. Sammenlign kvantiseringstrategier på tvers av ulike presisjonsnivåer (1-bit til 8-bit).
2. Forklar fordelene med GGUF-format for distribusjon på kanten.
3. Hvordan forbedrer maskinvarebevisst optimalisering i Microsoft Olive distribusjonseffektiviteten?
4. Hva er de viktigste fordelene med OpenVINOs NNCF for modellkompresjon?
5. Beskriv hvordan Apple MLX utnytter enhetlig minnearkitektur for optimalisering.
6. Hvordan hjelper arbeidsflytsyntese med å velge optimale optimaliseringsrammeverk?

### Praktiske Øvelser

1. **Modellkvantisering**: Bruk ulike kvantiseringnivåer på en modell og sammenlign resultatene (1 time)
2. **OpenVINO Optimalisering**: Bruk NNCF til å komprimere en modell for Intel-maskinvare (1 time)
3. **Rammeverkssammenligning**: Test den samme modellen på tvers av tre forskjellige optimaliseringsrammeverk (1 time)
4. **Ytelsesbenchmarking**: Mål optimaliseringens innvirkning på inferenshastighet og minnebruk (1 time)

## Modul 5: SLMOps - Operasjoner for Små Språkmodeller

### Viktige Læringsmål

- Forstå prinsipper for livssyklusadministrasjon i SLMOps
- Mestre distillasjons- og finjusteringsteknikker for distribusjon på kanten
- Implementere strategier for produksjonsdistribusjon med overvåking
- Bygge arbeidsflyter for drift og vedlikehold av SLM-er på bedriftsnivå

### Fokusområder for Studier

#### Seksjon 1: Introduksjon til SLMOps
- **Prioriterte Konsepter**: 
  - Paradigmeskiftet i AI-operasjoner med SLMOps
  - Kostnadseffektivitet og personvernfokusert arkitektur
  - Strategisk forretningspåvirkning og konkurransefordeler

#### Seksjon 2: Modelldistillasjon
- **Prioriterte Konsepter**: 
  - Kunnskapsoverføringsteknikker
  - Implementering av to-trinns distillasjonsprosess
  - Distillasjonsarbeidsflyter i Azure ML

#### Seksjon 3: Finjusteringsstrategier
- **Prioriterte Konsepter**: 
  - Parameter-effektiv finjustering (PEFT)
  - Avanserte metoder som LoRA og QLoRA
  - Multi-adapter trening og hyperparameteroptimalisering

#### Seksjon 4: Produksjonsdistribusjon
- **Prioriterte Konsepter**: 
  - Modellkonvertering og kvantisering for produksjon
  - Konfigurasjon for Foundry Local distribusjon
  - Ytelsesbenchmarking og kvalitetsvalidering

### Selvtestspørsmål

1. Hvordan skiller SLMOps seg fra tradisjonell MLOps?
2. Forklar fordelene med modelldistillasjon for distribusjon på kanten.
3. Hva er de viktigste hensynene for finjustering av SLM-er i ressursbegrensede miljøer?
4. Beskriv en komplett produksjonsdistribusjonsarbeidsflyt for Edge AI-applikasjoner.

### Praktiske Øvelser

1. **Grunnleggende Distillasjon**: Lag en mindre modell fra en større lærermodell (1 time)
2. **Finjusteringseksperiment**: Finjuster en modell for et spesifikt domene (1 time)
3. **Distribusjonsarbeidsflyt**: Sett opp en grunnleggende CI/CD-arbeidsflyt for modelldistribusjon (1 time)

## Modul 6: Agentiske SLM-systemer - AI-agenter og Funksjonskalling

### Viktige Læringsmål

- Bygge intelligente AI-agenter for kantmiljøer ved bruk av små språkmodeller
- Implementere funksjonskalling med systematiske arbeidsflyter
- Mestre integrasjon av Model Context Protocol (MCP) for standardisert verktøysinteraksjon
- Skape sofistikerte agentiske systemer med minimal menneskelig intervensjon

### Fokusområder for Studier

#### Seksjon 1: AI-agenter og SLM-grunnlag
- **Prioriterte Konsepter**: 
  - Rammeverk for agentklassifisering (refleks, modellbasert, målbasert, læringsagenter)
  - Analyse av avveininger mellom SLM og LLM
  - Designmønstre for agenter spesifikke for kantmiljøer
  - Ressursoptimalisering for agenter

#### Seksjon 2: Funksjonskalling i Små Språkmodeller
- **Prioriterte Konsepter**: 
  - Implementering av systematiske arbeidsflyter (intensjonsdeteksjon, JSON-utdata, ekstern utførelse)
  - Plattformspesifikke implementeringer (Phi-4-mini, utvalgte Qwen-modeller, Microsoft Foundry Local)
  - Avanserte eksempler (samarbeid mellom flere agenter, dynamisk verktøyvalg)
  - Produksjonshensyn (ratebegrensning, revisjonslogging, sikkerhetstiltak)

#### Seksjon 3: Integrasjon av Model Context Protocol (MCP)
- **Prioriterte Konsepter**: 
  - Protokollarkitektur og lagdelt systemdesign
  - Støtte for flere backend-løsninger (Ollama for utvikling, vLLM for produksjon)
  - Tilkoblingsprotokoller (STDIO og SSE-modus)
  - Virkelige applikasjoner (webautomatisering, databehandling, API-integrasjon)

### Selvtestspørsmål

1. Hva er de viktigste arkitektoniske hensynene for AI-agenter på kanten?
2. Hvordan forbedrer funksjonskalling agentens evner?
3. Forklar rollen til Model Context Protocol i agentkommunikasjon.

### Praktiske Øvelser

1. **Enkel Agent**: Bygg en grunnleggende AI-agent med funksjonskalling (1 time)
2. **MCP-integrasjon**: Implementer MCP i en agentapplikasjon (30 minutter)

## Workshop: Praktisk Læringssti

### Viktige Læringsmål

- Bygge produksjonsklare AI-applikasjoner ved bruk av Foundry Local SDK og beste praksis
- Implementere omfattende feilhåndtering og mønstre for brukerfeedback
- Lage RAG-arbeidsflyter med kvalitetsvurdering og ytelsesovervåking
- Utvikle systemer med flere agenter og koordinator-mønstre
- Mestre intelligent modellruting for oppgavebasert modellvalg
- Distribuere lokal-først AI-løsninger med personvernbevarende arkitekturer

### Fokusområder for Studier

#### Sesjon 01: Komme i Gang med Foundry Local
- **Prioriterte Konsepter**:
  - Integrasjon av FoundryLocalManager SDK og automatisk tjenesteoppdagelse
  - Grunnleggende og strømmende chat-implementeringer
  - Mønstre for feilhåndtering og brukerfeedback
  - Konfigurasjon basert på miljø

#### Sesjon 02: Bygge AI-løsninger med RAG
- **Prioriterte Konsepter**:
  - In-memory vektorembedding med sentence-transformers
  - Implementering av RAG-arbeidsflyt (hente → generere)
  - Kvalitetsvurdering med RAGAS-metrikker
  - Import-sikkerhet for valgfrie avhengigheter

#### Sesjon 03: Åpne Kildemodeller
- **Prioriterte Konsepter**:
  - Strategier for benchmarking av flere modeller
  - Måling av latens og gjennomstrømning
  - Grasiøs degradering og feilhåndtering
  - Ytelsessammenligning på tvers av modellfamilier

#### Sesjon 04: Banebrytende Modeller
- **Prioriterte Konsepter**:
  - Metodikk for sammenligning av SLM og LLM
  - Type hints og omfattende utdataformatering
  - Feilhåndtering per modell
  - Strukturert resultat for analyse

#### Sesjon 05: AI-drevne Agenter
- **Prioriterte Konsepter**:
  - Orkestrering av flere agenter med koordinator-mønster
  - Minnehåndtering og tilstandssporing for agenter
  - Feilhåndtering i arbeidsflyt og logging av stadier
  - Ytelsesovervåking og statistikk

#### Sesjon 06: Modeller som Verktøy
- **Prioriterte Konsepter**:
  - Intensjonsdeteksjon og mønstergjenkjenning
  - Algoritmer for modellruting basert på nøkkelord
  - Flertrinns arbeidsflyter (plan → utfør → forbedre)
  - Omfattende dokumentasjon av funksjoner

### Selvtestspørsmål

1. Hvordan forenkler FoundryLocalManager tjenesteadministrasjon sammenlignet med manuelle REST-kall?
2. Forklar viktigheten av importbeskyttelse for valgfrie avhengigheter som sentence-transformers.
3. Hvilke strategier sikrer grasiøs degradering i benchmarking av flere modeller?
4. Hvordan orkestrerer koordinator-mønsteret flere spesialistagenter?
5. Beskriv komponentene i en intelligent modellruter.
6. Hva er de viktigste elementene i produksjonsklar feilhåndtering?

### Praktiske Øvelser

1. **Chat-applikasjon**: Implementer strømmende chat med feilhåndtering (45 minutter)
2. **RAG-arbeidsflyt**: Bygg en minimal RAG med kvalitetsvurdering (1 time)
3. **Modellbenchmarking**: Sammenlign 3+ modeller på ytelse (1 time)
4. **System med Flere Agenter**: Lag en koordinator med 2 spesialistagenter (1,5 timer)
5. **Intelligent Ruter**: Bygg oppgavebasert modellvalg (1 time)
6. **Produksjonsdistribusjon**: Legg til overvåking og omfattende feilhåndtering (45 minutter)

### Tidsallokering

**Konsentrert Læring (1 uke)**:
- Dag 1: Sesjon 01-02 (Chat + RAG) - 3 timer
- Dag 2: Sesjon 03-04 (Benchmarking + Sammenligning) - 3 timer
- Dag 3: Sesjon 05-06 (Agenter + Ruting) - 3 timer
- Dag 4: Praktiske øvelser og validering - 2 timer

**Deltidsstudie (2 uker)**:
- Uke 1: Sesjoner 01-03 (6 timer totalt)
- Uke 2: Sesjoner 04-06 + øvelser (5 timer totalt)

## Modul 7: Eksempler på EdgeAI-implementering

### Viktige Læringsmål

- Mestre AI Toolkit for Visual Studio Code for omfattende EdgeAI-utviklingsarbeidsflyter
- Få ekspertise i Windows AI Foundry-plattformen og NPU-optimaliseringsstrategier
- Implementere EdgeAI på tvers av flere maskinvareplattformer og distribusjonsscenarier
- Bygge produksjonsklare EdgeAI-applikasjoner med plattformspesifikke optimaliseringer

### Fokusområder for Studier

#### Seksjon 1: AI Toolkit for Visual Studio Code
- **Prioriterte Konsepter**: 
  - Omfattende Edge AI-utviklingsmiljø i VS Code
  - Modellkatalog og oppdagelse for distribusjon på kanten
  - Lokal testing, optimalisering og utviklingsarbeidsflyter for agenter
  - Ytelsesovervåking og evaluering for kantmiljøer

#### Seksjon 2: Windows EdgeAI Utviklingsguide
- **Prioriterte Konsepter**: 
  - Omfattende oversikt over Windows AI Foundry-plattformen
  - Phi Silica API for effektiv NPU-inferens
  - Computer Vision API-er for bildebehandling og OCR
  - Foundry Local CLI for lokal utvikling og testing

#### Seksjon 3: Plattformspesifikke Implementeringer
- **Prioriterte Konsepter**: 
  - Distribusjon på NVIDIA Jetson Orin Nano (67 TOPS AI-ytelse)
  - Mobilapplikasjoner med .NET MAUI og ONNX Runtime GenAI
  - Azure EdgeAI-løsninger med hybrid arkitektur mellom sky og kant
  - Windows ML-optimalisering med universell maskinvarestøtte
  - Foundry Local-applikasjoner med personvernfokusert RAG-implementering

### Selvtestspørsmål

1. Hvordan effektiviserer AI Toolkit arbeidsflyten for EdgeAI-utvikling?
2. Sammenlign distribusjonsstrategier på tvers av ulike maskinvareplattformer.
3. Hva er fordelene med Windows AI Foundry for utvikling på kanten?
4. Forklar rollen til NPU-optimalisering i moderne Edge AI-applikasjoner.  
5. Hvordan utnytter Phi Silica API NPU-maskinvare for ytelsesoptimalisering?  
6. Sammenlign fordelene ved lokal kontra skybasert distribusjon for applikasjoner med sensitiv personvern.

### Praktiske Øvelser

1. **AI Toolkit-oppsett**: Konfigurer AI Toolkit og optimaliser en modell (1 time)  
2. **Windows AI Foundry**: Bygg en enkel Windows AI-applikasjon ved hjelp av Phi Silica API (1 time)  
3. **Plattformuavhengig distribusjon**: Distribuer den samme modellen på to forskjellige plattformer (1 time)  
4. **NPU-optimalisering**: Test NPU-ytelse med Windows AI Foundry-verktøy (30 minutter)  

## Modul 8: Microsoft Foundry Local – Komplett utviklerverktøysett (Modernisert)

### Viktige Læringsmål

- Installer og konfigurer Foundry Local med moderne SDK-integrasjon  
- Implementer avanserte multi-agent-systemer med koordinator-mønstre  
- Bygg intelligente modellrutere med automatisk oppgavebasert valg  
- Distribuer produksjonsklare AI-løsninger med omfattende overvåking  
- Integrer med Azure AI Foundry for hybride distribusjonsscenarier  
- Mestre moderne SDK-mønstre med FoundryLocalManager og OpenAI-klient  

### Studieområder

#### Seksjon 1: Moderne installasjon og konfigurasjon  
- **Prioriterte konsepter**:  
  - FoundryLocalManager SDK-integrasjon  
  - Automatisk tjenesteoppdagelse og helsesjekk  
  - Konfigurasjonsmønstre basert på miljø  
  - Betraktninger for produksjonsdistribusjon  

#### Seksjon 2: Avanserte multi-agent-systemer  
- **Prioriterte konsepter**:  
  - Koordinator-mønster med spesialistagenter  
  - Spesialisering av agenter for henting, resonnement og utførelse  
  - Tilbakemeldingssløyfer for forbedring  
  - Overvåking av ytelse og statistikk  

#### Seksjon 3: Intelligent modellruting  
- **Prioriterte konsepter**:  
  - Algoritmer for modellvalg basert på nøkkelord  
  - Støtte for flere modeller (generell, resonnement, kode, kreativ)  
  - Konfigurasjon av miljøvariabler for fleksibilitet  
  - Helsesjekk av tjenester og feilhåndtering  

#### Seksjon 4: Produksjonsklar implementering  
- **Prioriterte konsepter**:  
  - Omfattende feilhåndtering og fallback-mekanismer  
  - Overvåking av forespørsler og ytelsessporing  
  - Interaktive Jupyter-notebook-eksempler med benchmarks  
  - Integrasjonsmønstre med eksisterende applikasjoner  

### Selvtestspørsmål

1. Hvordan skiller den moderne FoundryLocalManager-tilnærmingen seg fra manuelle REST-kall?  
2. Forklar koordinator-mønsteret og hvordan det orkestrerer spesialistagenter.  
3. Hvordan velger den intelligente ruteren passende modeller basert på innholdet i forespørselen?  
4. Hva er de viktigste komponentene i et produksjonsklart AI-agent-system?  
5. Hvordan implementerer du omfattende helsesjekk for Foundry Local-tjenester?  
6. Sammenlign fordelene ved den moderniserte tilnærmingen kontra tradisjonelle implementeringsmønstre.  

### Praktiske Øvelser

1. **Moderne SDK-oppsett**: Konfigurer FoundryLocalManager med automatisk tjenesteoppdagelse (30 minutter)  
2. **Multi-agent-system**: Kjør den avanserte koordinatoren med spesialistagenter (30 minutter)  
3. **Intelligent ruting**: Test modellruteren med forskjellige forespørselstyper (30 minutter)  
4. **Interaktiv utforskning**: Bruk Jupyter-notebooks for å utforske avanserte funksjoner (45 minutter)  
5. **Produksjonsdistribusjon**: Implementer overvåkings- og feilhåndteringsmønstre (30 minutter)  
6. **Hybrid integrasjon**: Konfigurer fallback-scenarier med Azure AI Foundry (30 minutter)  

## Tidsallokeringsguide

For å hjelpe deg med å få mest mulig ut av den utvidede 30-timers kursplanen (inkludert workshop), her er en foreslått fordeling av tiden:

| Aktivitet | Tidsallokering | Beskrivelse |  
|-----------|----------------|-------------|  
| Lesing av kjerneinnhold | 12 timer | Fokus på essensielle konsepter i hver modul |  
| Praktiske øvelser | 10 timer | Praktisk implementering av nøkkelteknikker (inkludert workshop) |  
| Selvtest | 3 timer | Test forståelsen din gjennom spørsmål og refleksjon |  
| Mini-prosjekt | 5 timer | Bruk kunnskapen til en liten praktisk implementering |  

### Viktige fokusområder basert på tidsbegrensning

**Hvis du kun har 10 timer:**  
- Fullfør Modul 0 (Introduksjon) og Modulene 1, 2 og 3 (grunnleggende EdgeAI-konsepter)  
- Gjør minst én praktisk øvelse per modul  
- Fokuser på å forstå kjernekonseptene fremfor implementeringsdetaljer  

**Hvis du kan dedikere hele 20 timer:**  
- Fullfør alle åtte modulene (inkludert introduksjon)  
- Utfør nøkkeløvelser fra hver modul  
- Fullfør ett mini-prosjekt fra Modul 7  
- Utforsk minst 2-3 supplerende ressurser  

**Hvis du har mer enn 20 timer:**  
- Fullfør alle modulene (inkludert introduksjon) med detaljerte øvelser  
- Bygg flere mini-prosjekter  
- Utforsk avanserte optimaliseringsteknikker i Modul 4  
- Implementer produksjonsdistribusjon fra Modul 5  

## Essensielle Ressurser

Disse nøye utvalgte ressursene gir mest verdi for din begrensede studietid:

### Må-lese dokumentasjon  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektive verktøyet for modelloptimalisering  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Raskeste måte å distribuere SLM-er lokalt  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referanse for en ledende edge-optimalisert modell  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattende optimaliseringsverktøysett  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrert EdgeAI-utviklingsmiljø  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-spesifikk EdgeAI-utviklingsplattform  

### Tidsbesparende verktøy  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Rask tilgang til modeller og distribusjon  
- [Gradio](https://www.gradio.app/docs/interface) - Rask UI-utvikling for AI-demoer  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Forenklet modelloptimalisering  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Rammeverk for komprimering av nevrale nettverk  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Verktøysett for distribusjon av store språkmodeller  

## Fremdriftssporingsmal

Bruk denne forenklede malen for å spore læringsfremdriften din gjennom det 20-timers kurset:

| Modul | Fullføringsdato | Timer brukt | Viktige lærdommer |  
|-------|-----------------|-------------|-------------------|  
| Modul 0: Introduksjon til EdgeAI | | | |  
| Modul 1: EdgeAI-grunnleggende | | | |  
| Modul 2: SLM-grunnlag | | | |  
| Modul 3: SLM-distribusjon | | | |  
| Modul 4: Modelloptimalisering | | | |  
| Modul 5: SLMOps | | | |  
| Modul 6: AI-agenter | | | |  
| Modul 7: Utviklingsverktøy | | | |  
| Workshop: Praktisk læring | | | |  
| Modul 8: Foundry Local Toolkit | | | |  
| Praktiske øvelser | | | |  
| Mini-prosjekt | | | |  

## Mini-prosjektideer

Vurder å fullføre ett av disse prosjektene for å øve på EdgeAI-konsepter (hver designet for å ta 2-4 timer):

### Nybegynnerprosjekter (2-3 timer hver)  
1. **Edge tekstassistent**: Lag et enkelt offline tekstfullføringsverktøy ved hjelp av en liten språkmodell  
2. **Modellsammenligningsdashboard**: Bygg en grunnleggende visualisering av ytelsesmetrikker på tvers av forskjellige SLM-er  
3. **Optimaliseringseksperiment**: Mål effekten av forskjellige kvantiseringsnivåer på den samme basismodellen  

### Prosjekter for viderekomne (3-4 timer hver)  
4. **AI Toolkit-arbeidsflyt**: Bruk VS Code AI Toolkit til å optimalisere og distribuere en modell fra start til slutt  
5. **Windows AI Foundry-applikasjon**: Lag en Windows-app ved hjelp av Phi Silica API og NPU-optimalisering  
6. **Plattformuavhengig distribusjon**: Distribuer den samme optimaliserte modellen på Windows (OpenVINO) og mobil (.NET MAUI)  
7. **Funksjonskall-agent**: Bygg en AI-agent med funksjonskallkapabiliteter for edge-scenarier  

### Avanserte integrasjonsprosjekter (4-5 timer hver)  
8. **OpenVINO-optimaliseringspipeline**: Implementer komplett modelloptimalisering ved hjelp av NNCF og GenAI-verktøysett  
9. **SLMOps-pipeline**: Implementer en komplett modell-livssyklus fra trening til edge-distribusjon  
10. **Multi-modell edge-system**: Distribuer flere spesialiserte modeller som jobber sammen på edge-maskinvare  
11. **MCP-integrasjonssystem**: Bygg et agentbasert system ved hjelp av Model Context Protocol for verktøysinteraksjon  

## Referanser

- Microsoft Learn (Foundry Local)  
  - Oversikt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Kom i gang: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI-referanse: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrer med inferens-SDK-er: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Åpne WebUI-veiledning: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Kompiler Hugging Face-modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Oversikt: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agenter (oversikt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimalisering og inferensverktøy  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (kom i gang): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive-integrasjon: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Distribusjonsrammeverk og modeller  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (kom i gang): https://github.com/ollama/ollama#get-started  
- Utviklerverktøy (Windows og VS Code)  
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (oversikt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Læringsfellesskap

Bli med i diskusjonen og koble deg til andre lærende:  
- GitHub-diskusjoner på [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Konklusjon

EdgeAI representerer frontlinjen innen implementering av kunstig intelligens, og bringer kraftige kapabiliteter direkte til enheter samtidig som det adresserer kritiske bekymringer rundt personvern, forsinkelse og tilkobling. Dette 20-timers kurset gir deg essensiell kunnskap og praktiske ferdigheter for å begynne å arbeide med EdgeAI-teknologier umiddelbart.

Kurset er bevisst kortfattet og fokusert på de viktigste konseptene, slik at du raskt kan oppnå verdifull ekspertise uten en overveldende tidsforpliktelse. Husk at praktisk øvelse, selv med enkle eksempler, er nøkkelen til å styrke det du har lært.

Lykke til med læringen!

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber nøyaktighet, vær oppmerksom på at automatiserte oversettelser kan inneholde feil eller unøyaktigheter. Det originale dokumentet på sitt opprinnelige språk bør anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.