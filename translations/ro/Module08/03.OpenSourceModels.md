<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-10-01T01:26:04+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "ro"
}
-->
# Sesiunea 3: Descoperirea și Gestionarea Modelelor Open-Source

## Prezentare Generală

Această sesiune se concentrează pe descoperirea și gestionarea practică a modelelor cu Foundry Local. Vei învăța cum să listezi modelele disponibile, să testezi diferite opțiuni și să înțelegi caracteristicile de performanță de bază. Abordarea pune accent pe explorarea practică cu CLI-ul Foundry pentru a te ajuta să selectezi modelele potrivite pentru cazurile tale de utilizare.

## Obiective de Învățare

- Stăpânirea comenzilor CLI Foundry pentru descoperirea și gestionarea modelelor
- Înțelegerea cache-ului de modele și a tiparelor de stocare locală
- Învățarea testării rapide și comparării diferitelor modele
- Stabilirea fluxurilor de lucru practice pentru selecția și evaluarea modelelor
- Explorarea ecosistemului în creștere de modele disponibile prin Foundry Local

## Cerințe Prealabile

- Finalizarea Sesiunii 1: Introducere în Foundry Local
- CLI Foundry Local instalat și accesibil
- Spațiu de stocare suficient pentru descărcarea modelelor (modelele pot varia între 1GB și peste 20GB)
- Înțelegerea de bază a tipurilor de modele și a cazurilor de utilizare

## Partea 6: Exercițiu Practic

### Exercițiu: Descoperirea și Compararea Modelelor

Creează propriul script de evaluare a modelelor bazat pe Exemplul 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Sarcina Ta

1. **Rulează scriptul Exemplu 03**: `samples\03\list_and_bench.cmd`
2. **Testează diferite modele**: Testează cel puțin 3 modele diferite
3. **Compară performanța**: Notează diferențele în viteză și calitatea răspunsurilor
4. **Documentează concluziile**: Creează un grafic simplu de comparație

### Format Exemplu de Comparație

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## Partea 7: Depanare și Cele Mai Bune Practici

### Probleme Comune și Soluții

**Modelul Nu Pornește:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Memorie Insuficientă:**
- Începe cu modele mai mici (`phi-4-mini`)
- Închide alte aplicații
- Upgradează RAM-ul dacă întâmpini frecvent limite

**Performanță Lentă:**
- Asigură-te că modelul este complet încărcat (verifică ieșirea detaliată)
- Închide aplicațiile de fundal inutile
- Ia în considerare stocarea mai rapidă (SSD)

### Cele Mai Bune Practici

1. **Începe Mic**: Începe cu `phi-4-mini` pentru a valida configurarea
2. **Un Model la un Moment Dat**: Oprește modelele anterioare înainte de a porni altele noi
3. **Monitorizează Resursele**: Urmărește utilizarea memoriei
4. **Testează Consistent**: Folosește aceleași prompturi pentru comparații corecte
5. **Documentează Rezultatele**: Păstrează notițe despre performanța modelelor pentru cazurile tale de utilizare

## Partea 8: Pași Următori și Referințe

### Pregătirea pentru Sesiunea 4

- **Focusul Sesiunii 4**: Instrumente și tehnici de optimizare
- **Cerințe Prealabile**: Confortabil cu schimbarea modelelor și testarea de bază a performanței
- **Recomandat**: Identifică 2-3 modele preferate din această sesiune

### Resurse Suplimentare

- **[Documentația Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Documentație oficială
- **[Referință CLI](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Referință completă pentru comenzi
- **[Model Mondays](https://aka.ms/model-mondays)**: Modele săptămânale în prim-plan
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Comunitate și probleme
- **[Exemplu 03: Descoperirea Modelelor](samples/03/README.md)**: Script practic exemplu

### Concluzii Cheie

✅ **Descoperirea Modelelor**: Folosește `foundry model list` pentru a explora modelele disponibile  
✅ **Testare Rapidă**: Modelul `list_and_bench.cmd` pentru evaluare rapidă  
✅ **Monitorizarea Performanței**: Măsurarea utilizării resurselor și a timpului de răspuns  
✅ **Selecția Modelelor**: Ghiduri practice pentru alegerea modelelor în funcție de cazurile de utilizare  
✅ **Gestionarea Cache-ului**: Înțelegerea procedurilor de stocare și curățare  

Acum ai abilitățile practice pentru a descoperi, testa și selecta modele potrivite pentru aplicațiile tale AI folosind abordarea simplă CLI a Foundry Local: selectarea modelelor comunitare, integrarea conținutului Hugging Face și adoptarea strategiilor „aduci propriul model” (BYOM). De asemenea, vei descoperi seria Model Mondays pentru învățare continuă și descoperirea modelelor.

Referințe:
- Documentația Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Compilarea modelelor Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Model Mondays: https://aka.ms/model-mondays
- Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

## Obiective de Învățare
- Descoperirea și evaluarea modelelor open-source pentru inferență locală
- Compilarea și rularea modelelor selectate Hugging Face în Foundry Local
- Aplicarea strategiilor de selecție a modelelor pentru acuratețe, latență și nevoi de resurse
- Gestionarea modelelor local cu cache și versionare

## Partea 1: Descoperirea Modelelor cu Foundry CLI

### Comenzi de Bază pentru Gestionarea Modelelor

CLI-ul Foundry oferă comenzi simple pentru descoperirea și gestionarea modelelor:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Rularea Primelor Tale Modele

Începe cu modele populare, bine testate, pentru a înțelege caracteristicile de performanță:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**Notă:** Flag-ul `--verbose` oferă informații detaliate despre pornire, inclusiv:
- Progresul descărcării modelului (la prima rulare)
- Detalii despre alocarea memoriei
- Informații despre legarea serviciului
- Metrice de inițializare a performanței

### Înțelegerea Categoriilor de Modele

**Modele de Limbaj Mici (SLM):**
- `phi-4-mini`: Rapid, eficient, excelent pentru chat general
- `phi-4`: Versiune mai capabilă cu raționament mai bun

**Modele Medii:**
- `qwen2.5-7b`: Raționament excelent și context mai lung
- `deepseek-r1-7b`: Optimizat pentru generarea de cod

**Modele Mari:**
- `llama-3.2`: Cel mai recent model open-source de la Meta
- `qwen2.5-14b`: Raționament de nivel enterprise

## Partea 2: Testare Rapidă și Comparare a Modelelor

### Abordarea Exemplu 03: Listare și Evaluare Simplă

Bazat pe modelul nostru Exemplu 03, iată fluxul de lucru minim:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Testarea Performanței Modelului

Odată ce un model rulează, testează-l cu prompturi consistente:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### Alternativa de Testare în PowerShell

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## Partea 3: Gestionarea Cache-ului și Stocării Modelelor

### Înțelegerea Cache-ului de Modele

Foundry Local gestionează automat descărcările și cache-ul modelelor:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Considerații privind Stocarea Modelelor

**Dimensiuni Tipice ale Modelelor:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b`: ~4.1 GB  
- `deepseek-r1-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b`: ~8.2 GB

**Cele Mai Bune Practici pentru Stocare:**
- Păstrează 2-3 modele în cache pentru comutare rapidă
- Elimină modelele neutilizate pentru a elibera spațiu: `foundry cache clean`
- Monitorizează utilizarea discului, mai ales pe SSD-uri mai mici
- Ia în considerare compromisurile între dimensiunea modelului și capabilități

### Monitorizarea Performanței Modelului

În timp ce modelele rulează, monitorizează resursele sistemului:

**Task Manager Windows:**
- Urmărește utilizarea memoriei (modelele rămân încărcate în RAM)
- Monitorizează utilizarea CPU în timpul inferenței
- Verifică I/O-ul discului în timpul încărcării inițiale a modelului

**Monitorizare din Linia de Comandă:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## Partea 4: Ghiduri Practice pentru Selecția Modelelor

### Alegerea Modelelor în Funcție de Cazul de Utilizare

**Pentru Chat General și Întrebări/Răspunsuri:**
- Începe cu: `phi-4-mini` (rapid, eficient)
- Upgradează la: `phi-4` (raționament mai bun)
- Avansat: `qwen2.5-7b` (context mai lung)

**Pentru Generarea de Cod:**
- Recomandat: `deepseek-r1-7b`
- Alternativă: `qwen2.5-7b` (de asemenea bun pentru cod)

**Pentru Raționament Complex:**
- Cel mai bun: `qwen2.5-7b` sau `qwen2.5-14b`
- Opțiune de buget: `phi-4`

### Ghid pentru Cerințele Hardware

**Cerințe Minime ale Sistemului:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Recomandat pentru Performanță Optimă:**
- 32GB+ RAM pentru comutare confortabilă între modele
- Stocare SSD pentru încărcare mai rapidă a modelelor
- CPU modern cu performanță bună pe un singur fir
- Suport NPU (PC-uri Windows 11 Copilot+) pentru accelerare

### Fluxul de Lucru pentru Comutarea Modelelor

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## Partea 5: Evaluarea Simplă a Performanței Modelelor

### Testare de Performanță de Bază

Iată o abordare simplă pentru compararea performanței modelelor:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Evaluare Manuală a Calității

Pentru fiecare model, testează cu prompturi consistente și evaluează manual:

**Prompturi de Testare:**
1. "Explică calculul cuantic în termeni simpli."
2. "Scrie o funcție Python pentru a sorta o listă."
3. "Care sunt avantajele și dezavantajele muncii la distanță?"
4. "Rezumă beneficiile AI-ului de tip edge."

**Criterii de Evaluare:**
- **Acuratețe**: Informația este corectă?
- **Claritate**: Explicația este ușor de înțeles?
- **Completitudine**: Răspunde complet la întrebare?
- **Viteză**: Cât de rapid răspunde?

### Monitorizarea Utilizării Resurselor

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## Partea 6: Pași Următori
- Abonează-te la Model Mondays pentru modele și sfaturi noi: https://aka.ms/model-mondays
- Contribuie cu concluzii la `models.json` al echipei tale
- Pregătește-te pentru Sesiunea 4: compararea LLM-urilor vs SLM-urilor, inferență locală vs cloud și demonstrații practice

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim să asigurăm acuratețea, vă rugăm să fiți conștienți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa natală ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.