<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-23T01:05:00+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "ro"
}
-->
# Sesiunea 1: Introducere în Foundry Local

## Prezentare Generală

Microsoft Foundry Local aduce capabilitățile Azure AI Foundry direct în mediul tău de dezvoltare Windows 11, permițând dezvoltarea AI cu latență redusă și protecția confidențialității, utilizând instrumente de nivel enterprise. Această sesiune acoperă instalarea completă, configurarea și implementarea practică a unor modele populare, inclusiv phi, qwen, deepseek și GPT-OSS-20B.

## Obiective de Învățare

Până la finalul acestei sesiuni, vei putea:
- Instala și configura Foundry Local pe Windows 11
- Stăpâni comenzile CLI și opțiunile de configurare
- Înțelege strategiile de caching ale modelelor pentru performanță optimă
- Rula cu succes modelele phi, qwen, deepseek și GPT-OSS-20B
- Crea prima ta aplicație AI folosind Foundry Local

## Cerințe Prealabile

### Cerințe de Sistem
- **Windows 11**: Versiunea 22H2 sau mai recentă
- **RAM**: Minimum 16GB, recomandat 32GB
- **Spațiu de stocare**: 50GB liberi pentru modele și cache
- **Hardware**: Dispozitiv cu NPU sau GPU preferat (PC Copilot+ sau GPU NVIDIA)
- **Rețea**: Internet de mare viteză pentru descărcarea modelelor

### Mediu de Dezvoltare
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## Partea 1: Instalare și Configurare

### Pasul 1: Instalarea Foundry Local

Instalează Foundry Local folosind Winget sau descarcă instalatorul de pe GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Pasul 2: Verificarea Instalării

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Partea 2: Înțelegerea CLI

### Structura Comenzilor de Bază

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Partea 3: Caching și Managementul Modelelor

Foundry Local implementează un sistem inteligent de caching al modelelor pentru optimizarea performanței și stocării:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Partea 4: Implementarea Practică a Modelelor

### Rularea Modelelor Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Lucrul cu Modelele Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### Rularea Modelelor DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### Rularea GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Partea 5: Crearea Primei Tale Aplicații

### Interfață Simplă de Chat (API compatibil OpenAI)

Creează o aplicație de chat de bază folosind API-ul REST compatibil OpenAI al Foundry Local. Asigură-te că un model rulează într-un alt terminal.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Rularea Aplicației de Chat

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## Partea 6: Depanare și Cele Mai Bune Practici

### Probleme Comune și Soluții

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Monitorizarea Resurselor Sistemului (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Cele Mai Bune Practici

- Preferă comenzile `foundry model ...`, `foundry cache ...` și `foundry service ...` (vezi referința CLI)
- Actualizează regulat pentru a accesa modele și corecții noi
- Începe cu modele mai mici (Phi mini, Qwen 7B) și extinde treptat
- Monitorizează CPU/GPU/memoria în timp ce ajustezi prompturile și setările

## Partea 7: Exerciții Practice

### Exercițiul 1: Rulări Rapide Multi-Model

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Exercițiul 2: Benchmark de Latență de Bază

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Referințe

- Începe cu Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- Referință CLI și prezentare generală a comenzilor: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Compilează modele Hugging Face pentru Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

