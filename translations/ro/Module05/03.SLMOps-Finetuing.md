<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T19:01:52+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "ro"
}
-->
# Secțiunea 3: Fine-Tuning - Personalizarea modelelor pentru sarcini specifice

## Cuprins
1. [Introducere în Fine-Tuning](../../../Module05)
2. [De ce este important Fine-Tuning](../../../Module05)
3. [Tipuri de Fine-Tuning](../../../Module05)
4. [Fine-Tuning cu Microsoft Olive](../../../Module05)
5. [Exemple practice](../../../Module05)
6. [Cele mai bune practici și recomandări](../../../Module05)
7. [Tehnici avansate](../../../Module05)
8. [Evaluare și monitorizare](../../../Module05)
9. [Provocări comune și soluții](../../../Module05)
10. [Concluzie](../../../Module05)

## Introducere în Fine-Tuning

**Fine-tuning** este o tehnică puternică de învățare automată care implică adaptarea unui model pre-antrenat pentru a îndeplini sarcini specifice sau pentru a lucra cu seturi de date specializate. În loc să antrenezi un model de la zero, fine-tuning-ul valorifică cunoștințele deja învățate de un model pre-antrenat și le ajustează pentru cazul tău particular.

### Ce este Fine-Tuning?

Fine-tuning-ul este o formă de **transfer learning** în care:
- Pornești de la un model pre-antrenat care a învățat modele generale din seturi de date mari
- Ajustezi parametrii interni ai modelului folosind setul tău de date specific
- Păstrezi cunoștințele valoroase în timp ce specializezi modelul pentru sarcina ta

Gândește-te la asta ca la învățarea unui bucătar experimentat să gătească o bucătărie nouă - el înțelege deja fundamentele gătitului, dar trebuie să învețe tehnici și arome specifice pentru noul stil.

### Beneficii cheie

- **Eficiență în timp**: Semnificativ mai rapid decât antrenarea de la zero
- **Eficiență în utilizarea datelor**: Necesită seturi de date mai mici pentru a obține performanțe bune
- **Cost redus**: Cerințe computaționale mai mici
- **Performanță mai bună**: Adesea obține rezultate superioare comparativ cu antrenarea de la zero
- **Optimizarea resurselor**: Face ca AI-ul puternic să fie accesibil echipelor și organizațiilor mai mici

## De ce este important Fine-Tuning

### Aplicații în lumea reală

Fine-tuning-ul este esențial în numeroase scenarii:

**1. Adaptare la domeniu**
- AI medical: Adaptarea modelelor de limbaj general pentru terminologia medicală și notele clinice
- Tehnologie juridică: Specializarea modelelor pentru analiza documentelor juridice și revizuirea contractelor
- Servicii financiare: Personalizarea modelelor pentru analiza rapoartelor financiare și evaluarea riscurilor

**2. Specializare pe sarcini**
- Generarea de conținut: Fine-tuning pentru stiluri sau tonuri de scriere specifice
- Generarea de cod: Adaptarea modelelor pentru limbaje de programare sau cadre specifice
- Traducere: Îmbunătățirea performanței pentru perechi de limbi specifice sau domenii tehnice

**3. Aplicații corporative**
- Serviciul clienți: Crearea de chatbots care înțeleg terminologia specifică companiei
- Documentație internă: Construirea de asistenți AI familiarizați cu procesele organizaționale
- Soluții specifice industriei: Dezvoltarea de modele care înțeleg jargonul și fluxurile de lucru specifice sectorului

## Tipuri de Fine-Tuning

### 1. Fine-Tuning complet (Instruction Fine-Tuning)

În fine-tuning-ul complet, toți parametrii modelului sunt actualizați în timpul antrenării. Această abordare:
- Oferă flexibilitate maximă și potențial de performanță
- Necesită resurse computaționale semnificative
- Rezultă într-o versiune complet nouă a modelului
- Este ideală pentru scenarii în care ai date de antrenament substanțiale și resurse computaționale suficiente

### 2. Fine-Tuning eficient din punct de vedere al parametrilor (PEFT)

Metodele PEFT actualizează doar un subset mic de parametri, făcând procesul mai eficient:

#### Low-Rank Adaptation (LoRA)
- Adaugă matrice de decompoziție de rang mic, antrenabile, la greutățile existente
- Reduce dramatic numărul de parametri antrenabili
- Menține performanța aproape de fine-tuning-ul complet
- Permite comutarea ușoară între diferite adaptări

#### QLoRA (Quantized LoRA)
- Combină LoRA cu tehnici de cuantizare
- Reduce și mai mult cerințele de memorie
- Permite fine-tuning-ul modelelor mai mari pe hardware de consum
- Echilibrează eficiența cu performanța

#### Adapters
- Inserează rețele neuronale mici între straturile existente
- Permite fine-tuning țintit, păstrând modelul de bază nemodificat
- Oferă o abordare modulară pentru personalizarea modelului

### 3. Fine-Tuning specific sarcinii

Se concentrează pe adaptarea modelelor pentru sarcini specifice:
- **Clasificare**: Ajustarea modelelor pentru sarcini de categorisire
- **Generare**: Optimizarea pentru crearea de conținut și generarea de text
- **Extragere**: Fine-tuning pentru extragerea informațiilor și recunoașterea entităților numite
- **Sumarizare**: Specializarea modelelor pentru sumarizarea documentelor

## Fine-Tuning cu Microsoft Olive

Microsoft Olive este un toolkit cuprinzător pentru optimizarea modelelor, care simplifică procesul de fine-tuning oferind în același timp funcții de nivel enterprise.

### Ce este Microsoft Olive?

Microsoft Olive este un instrument open-source pentru optimizarea modelelor care:
- Simplifică fluxurile de lucru de fine-tuning pentru diverse ținte hardware
- Oferă suport integrat pentru arhitecturi populare de modele (Llama, Phi, Qwen, Gemma)
- Oferă opțiuni de implementare atât în cloud, cât și local
- Se integrează perfect cu Azure ML și alte servicii AI Microsoft
- Suportă optimizarea și cuantizarea automată

### Funcții cheie

- **Optimizare orientată pe hardware**: Optimizează automat modelele pentru hardware specific (CPU, GPU, NPU)
- **Suport multi-format**: Funcționează cu modele PyTorch, Hugging Face și ONNX
- **Fluxuri de lucru automatizate**: Reduce configurarea manuală și încercările repetate
- **Integrare enterprise**: Suport integrat pentru Azure ML și implementări în cloud
- **Arhitectură extensibilă**: Permite tehnici de optimizare personalizate

### Instalare și configurare

#### Instalare de bază

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dependențe opționale

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verificarea instalării

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Exemple practice

### Exemplu 1: Fine-Tuning de bază cu Olive CLI

Acest exemplu demonstrează fine-tuning-ul unui model de limbaj mic pentru clasificarea frazelor:

#### Pasul 1: Pregătește mediul

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Pasul 2: Fine-Tune modelul

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Pasul 3: Optimizează pentru implementare

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Exemplu 2: Configurare avansată cu set de date personalizat

#### Pasul 1: Pregătește setul de date personalizat

Creează un fișier JSON cu datele tale de antrenament:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Pasul 2: Creează fișierul de configurare

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Pasul 3: Execută Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Exemplu 3: Fine-Tuning QLoRA pentru eficiență memoriei

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Cele mai bune practici și recomandări

### Pregătirea datelor

**1. Calitatea datelor peste cantitate**
- Prioritizează exemplele de înaltă calitate și diverse în detrimentul volumelor mari de date slabe
- Asigură-te că datele sunt reprezentative pentru cazul tău de utilizare
- Curăță și preprocesează datele în mod consecvent

**2. Formatul și șabloanele datelor**
- Folosește formatare consecventă pentru toate exemplele de antrenament
- Creează șabloane clare de intrare-ieșire care să se potrivească cazului tău de utilizare
- Include formatarea adecvată a instrucțiunilor pentru modelele ajustate pe instrucțiuni

**3. Împărțirea setului de date**
- Rezervă 10-20% din date pentru validare
- Menține distribuții similare între împărțirile de antrenament/validare
- Ia în considerare eșantionarea stratificată pentru sarcinile de clasificare

### Configurarea antrenamentului

**1. Selectarea ratei de învățare**
- Începe cu rate de învățare mai mici (1e-5 până la 1e-4) pentru fine-tuning
- Folosește programarea ratei de învățare pentru o convergență mai bună
- Monitorizează curbele pierderii pentru a ajusta ratele corespunzător

**2. Optimizarea dimensiunii batch-ului**
- Echilibrează dimensiunea batch-ului cu memoria disponibilă
- Folosește acumularea gradientului pentru dimensiuni batch mai mari efective
- Ia în considerare relația dintre dimensiunea batch-ului și rata de învățare

**3. Durata antrenamentului**
- Monitorizează metricele de validare pentru a evita supra-antrenarea
- Folosește oprirea timpurie când performanța validării se stabilizează
- Salvează puncte de control regulat pentru recuperare și analiză

### Selectarea modelului

**1. Alegerea modelului de bază**
- Selectează modele pre-antrenate pe domenii similare, dacă este posibil
- Ia în considerare dimensiunea modelului în raport cu constrângerile tale computaționale
- Evaluează cerințele de licențiere pentru utilizarea comercială

**2. Alegerea metodei de fine-tuning**
- Folosește LoRA/QLoRA pentru medii cu resurse limitate
- Alege fine-tuning complet când performanța maximă este critică
- Ia în considerare abordările bazate pe adaptoare pentru scenarii cu sarcini multiple

### Gestionarea resurselor

**1. Optimizarea hardware-ului**
- Alege hardware-ul potrivit pentru dimensiunea modelului și metoda utilizată
- Utilizează eficient memoria GPU cu checkpointing-ul gradientului
- Ia în considerare soluțiile bazate pe cloud pentru modele mai mari

**2. Gestionarea memoriei**
- Folosește antrenament cu precizie mixtă, dacă este disponibil
- Implementați acumularea gradientului pentru constrângerile de memorie
- Monitorizează utilizarea memoriei GPU pe parcursul antrenamentului

## Tehnici avansate

### Antrenament multi-adaptor

Antrenează mai mulți adaptoare pentru sarcini diferite, păstrând modelul de bază:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optimizarea hiperparametrilor

Implementați ajustarea sistematică a hiperparametrilor:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Funcții de pierdere personalizate

Implementați funcții de pierdere specifice domeniului:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluare și monitorizare

### Metrice și evaluare

**1. Metrice standard**
- **Acuratețe**: Corectitudinea generală pentru sarcinile de clasificare
- **Perplexitate**: Măsură a calității modelării limbajului
- **BLEU/ROUGE**: Calitatea generării de text și sumarizării
- **Scor F1**: Echilibru între precizie și recall pentru clasificare

**2. Metrice specifice domeniului**
- **Repere specifice sarcinii**: Folosește repere stabilite pentru domeniul tău
- **Evaluare umană**: Include evaluarea umană pentru sarcini subiective
- **Metrice de afaceri**: Aliniază-te cu obiectivele reale de afaceri

**3. Configurarea evaluării**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitorizarea progresului antrenamentului

**1. Urmărirea pierderii**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Monitorizarea validării**
- Urmărește pierderea validării alături de pierderea antrenamentului
- Monitorizează semnele de supra-antrenare (pierderi de validare în creștere în timp ce pierderile de antrenament scad)
- Folosește oprirea timpurie bazată pe metricele de validare

**3. Monitorizarea resurselor**
- Monitorizează utilizarea GPU/CPU
- Urmărește modelele de utilizare a memoriei
- Monitorizează viteza și debitul antrenamentului

## Provocări comune și soluții

### Provocare 1: Supra-antrenare

**Simptome:**
- Pierderea antrenamentului continuă să scadă în timp ce pierderea validării crește
- Diferență mare între performanța antrenamentului și validării
- Generalizare slabă la date noi

**Soluții:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Provocare 2: Limitări de memorie

**Soluții:**
- Folosește checkpointing-ul gradientului
- Implementați acumularea gradientului
- Alege metode eficiente din punct de vedere al parametrilor (LoRA, QLoRA)
- Utilizează paralelismul modelului pentru modele mari

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Provocare 3: Antrenament lent

**Soluții:**
- Optimizează conductele de încărcare a datelor
- Folosește antrenament cu precizie mixtă
- Implementați strategii eficiente de batching
- Ia în considerare antrenamentul distribuit pentru seturi de date mari

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Provocare 4: Performanță slabă

**Pași de diagnosticare:**
1. Verifică calitatea și formatarea datelor
2. Verifică rata de învățare și durata antrenamentului
3. Evaluează alegerea modelului de bază
4. Revizuiește preprocesarea și tokenizarea

**Soluții:**
- Crește diversitatea datelor de antrenament
- Ajustează programul ratei de învățare
- Încearcă modele de bază diferite
- Implementați tehnici de augmentare a datelor

## Concluzie

Fine-tuning-ul este o tehnică puternică care democratizează accesul la capacitățile AI de ultimă generație. Prin utilizarea instrumentelor precum Microsoft Olive, organizațiile pot adapta eficient modelele pre-antrenate la nevoile lor specifice, optimizând în același timp performanța și constrângerile de resurse.

### Concluzii cheie

1. **Alege abordarea potrivită**: Selectează metodele de fine-tuning în funcție de resursele computaționale și cerințele de performanță
2. **Calitatea datelor contează**: Investește în date de antrenament de înaltă calitate și reprezentative
3. **Monitorizează și iterează**: Evaluează și îmbunătățește continuu modelele tale
4. **Valorifică instrumentele**: Folosește cadre precum Olive pentru a simplifica și optimiza procesul
5. **Ia în considerare implementarea**: Planifică optimizarea și implementarea modelului de la început

## ➡️ Ce urmează

- [04: Implementare - Model gata de producție](./04.SLMOps.Deployment.md)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim să asigurăm acuratețea, vă rugăm să fiți conștienți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa natală ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.