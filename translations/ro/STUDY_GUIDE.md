<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T09:45:24+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru Începători: Căi de Învățare și Program de Studiu

### Cale de Învățare Concentrată (1 săptămână)

| Zi | Focus | Ore Estimate |
|------|-------|------------------|
| Ziua 0 | Modulul 0: Introducere în EdgeAI | 1-2 ore |
| Ziua 1 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Ziua 2 | Modulul 2: Bazele SLM | 3 ore |
| Ziua 3 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 4-5 | Modulul 4: Optimizarea Modelului (6 cadre) | 4 ore |
| Ziua 6 | Modulul 5: SLMOps | 3 ore |
| Ziua 7 | Modulele 6-7: Agenți AI & Instrumente de Dezvoltare | 4 ore |
| Ziua 8 | Modulul 8: Foundry Local Toolkit (Implementare Modernă) | 1 oră |

### Cale de Învățare Concentrată (2 săptămâni)

| Zi | Focus | Ore Estimate |
|------|-------|------------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Bazele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Agenți AI | 2 ore |
| Zilele 13-14 | Modulul 7: Instrumente de Dezvoltare | 3 ore |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimate |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Bazele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

| Zi | Focus | Ore Estimate |
|------|-------|------------------|
| Ziua 0 | Modulul 0: Introducere în EdgeAI | 1-2 ore |
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Bazele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Sisteme Agentice SLM | 2 ore |
| Zilele 13-14 | Modulul 7: Exemple de Implementare EdgeAI | 2 ore |

| Modul | Data Finalizării | Ore Petrecute | Concluzii Cheie |
|--------|----------------|-------------|--------------|
| Modulul 0: Introducere în EdgeAI | | | |
| Modulul 1: Fundamentele EdgeAI | | | |
| Modulul 2: Bazele SLM | | | |
| Modulul 3: Implementarea SLM | | | |
| Modulul 4: Optimizarea Modelului (6 cadre) | | | |
| Modulul 5: SLMOps | | | |
| Modulul 6: Sisteme Agentice SLM | | | |
| Modulul 7: Exemple de Implementare EdgeAI | | | |
| Exerciții Practice | | | |
| Mini-Proiect | | | |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimate |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Bazele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

## Introducere

Bine ați venit la ghidul de studiu EdgeAI pentru Începători! Acest document este conceput pentru a vă ajuta să navigați eficient prin materialele cursului și să maximizați experiența de învățare. Oferă căi de învățare structurate, programe de studiu sugerate, rezumate ale conceptelor cheie și resurse suplimentare pentru a vă aprofunda înțelegerea tehnologiilor Edge AI.

Acesta este un curs concis de 20 de ore care oferă cunoștințe esențiale despre EdgeAI într-un format eficient din punct de vedere al timpului, fiind ideal pentru profesioniștii ocupați și studenții care doresc să dobândească rapid abilități practice în acest domeniu emergent.

## Prezentare Generală a Cursului

Cursul este organizat în opt module cuprinzătoare:

0. **Introducere în EdgeAI** - Stabilirea fundației și a contextului cu aplicații din industrie și obiective de învățare
1. **Fundamentele și Transformarea EdgeAI** - Înțelegerea conceptelor de bază și a schimbării tehnologice
2. **Bazele Micilor Modele de Limbaj (SLM)** - Explorarea diferitelor familii SLM și a arhitecturilor acestora
3. **Implementarea Micilor Modele de Limbaj** - Strategii practice de implementare
4. **Conversia Formatului Modelului și Cuantizare** - Optimizare avansată cu 6 cadre, inclusiv OpenVINO
5. **SLMOps - Operațiuni pentru Micile Modele de Limbaj** - Managementul ciclului de viață și implementare
6. **Sisteme Agentice SLM** - Agenți AI, apelarea funcțiilor și Protocolul Contextului Modelului
7. **Exemple de Implementare EdgeAI** - AI Toolkit, dezvoltare pe Windows și implementări specifice platformei
8. **Microsoft Foundry Local – Set complet de instrumente pentru dezvoltatori** - Dezvoltare locală cu integrare hibridă Azure (Modulul 08)

## Cum să Utilizați Acest Ghid de Studiu

- **Învățare Progresivă**: Urmați modulele în ordine pentru o experiență de învățare coerentă
- **Puncte de Verificare a Cunoștințelor**: Utilizați întrebările de autoevaluare după fiecare secțiune
- **Practica Practică**: Finalizați exercițiile sugerate pentru a consolida conceptele teoretice
- **Resurse Suplimentare**: Explorați materiale suplimentare pentru subiectele care vă interesează cel mai mult

## Recomandări pentru Programul de Studiu

### Cale de Învățare Concentrată (1 săptămână)

| Zi | Focus | Ore Estimate |
|------|-------|------------------|
| Ziua 0 | Modulul 0: Introducere în EdgeAI | 1-2 ore |
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 6 ore |
| Zilele 3-4 | Modulul 2: Bazele SLM | 8 ore |
| Ziua 5 | Modulul 3: Implementarea SLM | 3 ore |
| Ziua 6 | Modulul 8: Foundry Local Toolkit | 3 ore |

### Studiu Part-Time (3 săptămâni)

| Săptămână | Focus | Ore Estimate |
|------|-------|------------------|
| Săptămâna 1 | Modulul 0: Introducere + Modulul 1: Fundamentele EdgeAI | 7-9 ore |
| Săptămâna 2 | Modulul 2: Bazele SLM | 7-8 ore |
| Săptămâna 3 | Modulul 3: Implementarea SLM (3h) + Modulul 8: Foundry Local Toolkit (2-3h) | 5-6 ore |

## Modulul 0: Introducere în EdgeAI

### Obiective Cheie de Învățare

- Înțelegerea conceptului de Edge AI și a importanței sale în peisajul tehnologic actual
- Identificarea principalelor industrii transformate de Edge AI și a cazurilor lor specifice de utilizare
- Înțelegerea avantajelor Micilor Modele de Limbaj (SLM) pentru implementarea la margine
- Stabilirea așteptărilor clare de învățare și a rezultatelor pentru întregul curs
- Recunoașterea oportunităților de carieră și a cerințelor de competențe în domeniul Edge AI

### Zone de Focus pentru Studiu

#### Secțiunea 1: Paradigma și Definiția Edge AI
- **Concepte Prioritare**: 
  - Edge AI vs. procesarea tradițională AI în cloud
  - Convergența hardware-ului, optimizarea modelelor și cerințele de afaceri
  - Implementare AI în timp real, cu protecția confidențialității și eficiență a costurilor

#### Secțiunea 2: Aplicații Industriale
- **Concepte Prioritare**: 
  - Producție & Industria 4.0: Mentenanță predictivă și controlul calității
  - Sănătate: Imagistică diagnostică și monitorizarea pacienților
  - Sisteme Autonome: Vehicule autonome și transport
  - Orașe Inteligente: Managementul traficului și siguranța publică
  - Tehnologie pentru Consumatori: Smartphone-uri, dispozitive purtabile și case inteligente

#### Secțiunea 3: Fundamentele Micilor Modele de Limbaj
- **Concepte Prioritare**: 
  - Caracteristicile și comparațiile de performanță ale SLM
  - Eficiența parametrilor vs. compromisurile de capabilitate
  - Constrângerile de implementare la margine și strategiile de optimizare

#### Secțiunea 4: Cadru de Învățare și Cale de Carieră
- **Concepte Prioritare**: 
  - Arhitectura cursului și abordarea de stăpânire progresivă
  - Abilități tehnice și obiective practice de implementare
  - Oportunități de avansare în carieră și aplicații industriale

### Întrebări de Autoevaluare

1. Care sunt cele trei tendințe tehnologice principale care au permis Edge AI?
2. Comparați avantajele și provocările Edge AI vs. AI bazat pe cloud.
3. Numiți trei industrii în care Edge AI oferă valoare critică pentru afaceri și explicați de ce.
4. Cum fac Micile Modele de Limbaj Edge AI practic pentru implementarea în lumea reală?
5. Care sunt abilitățile tehnice cheie pe care le veți dezvolta pe parcursul acestui curs?
6. Descrieți abordarea de învățare în patru faze utilizată în acest curs.

### Exerciții Practice

1. **Cercetare Industrială**: Alegeți o aplicație industrială și cercetați o implementare reală Edge AI (30 minute)
2. **Explorarea Modelelor**: Răsfoiți Micile Modele de Limbaj disponibile pe Hugging Face și comparați numărul lor de parametri și capabilitățile (30 minute)
3. **Planificarea Învățării**: Revizuiți structura completă a cursului și creați-vă propriul program de studiu (15 minute)

### Materiale Suplimentare

- [Prezentare Generală a Pieței Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [Prezentare Generală a Micilor Modele de Limbaj - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Fundația Edge Computing](https://www.edgecomputing.org/)

## Modulul 1: Fundamentele și Transformarea EdgeAI

### Obiective Cheie de Învățare

- Înțelegerea diferențelor dintre AI bazat pe cloud și AI bazat pe margine
- Stăpânirea tehnicilor de optimizare pentru medii cu resurse limitate
- Analiza aplicațiilor reale ale tehnologiilor EdgeAI
- Configurarea unui mediu de dezvoltare pentru proiecte EdgeAI

### Zone de Focus pentru Studiu

#### Secțiunea 1: Fundamentele EdgeAI
- **Concepte Prioritare**: 
  - Paradigmele de calcul Edge vs. Cloud
  - Tehnici de cuantizare a modelelor
  - Opțiuni de accelerare hardware (NPU-uri, GPU-uri, CPU-uri)
  - Avantaje legate de confidențialitate și securitate

- **Materiale Suplimentare**:
  - [Documentația TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentația Edge Impulse](https://docs.edgeimpulse.com)

#### Secțiunea 2: Studii de Caz Reale
- **Concepte Prioritare**: 
  - Ecosistemul de modele Microsoft Phi & Mu
  - Implementări practice în diverse industrii
  - Considerații pentru implementare

#### Secțiunea 3: Ghid Practic de Implementare
- **Concepte Prioritare**: 
  - Configurarea mediului de dezvoltare
  - Instrumente de cuantizare și optimizare
  - Metode de evaluare pentru implementările EdgeAI

#### Secțiunea 4: Hardware pentru Implementare la Margine
- **Concepte Prioritare**: 
  - Comparații între platformele hardware
  - Strategii de optimizare pentru hardware specific
  - Considerații pentru implementare

### Întrebări de Autoevaluare

1. Comparați și contrastați implementările AI bazate pe cloud cu cele bazate pe margine.
2. Explicați trei tehnici cheie pentru optimizarea modelelor pentru implementarea la margine.
3. Care sunt principalele avantaje ale rulării modelelor AI la margine?
4. Descrieți procesul de cuantizare a unui model și cum afectează performanța.
5. Explicați cum influențează diferiții acceleratori hardware (NPU-uri, GPU-uri, CPU-uri) implementarea EdgeAI.

### Exerciții Practice

1. **Configurare Rapidă a Mediului**: Configurați un mediu minim de dezvoltare cu pachetele esențiale (30 minute)
2. **Explorarea Modelelor**: Descărcați și examinați un mic model de limbaj pre-antrenat (1 oră)
3. **Cuantizare de Bază**: Încercați o cuantizare simplă pe un model mic (1 oră)

## Modulul 2: Bazele Micilor Modele de Limbaj

### Obiective Cheie de Învățare

- Înțelegerea principiilor arhitecturale ale diferitelor familii SLM
- Compararea capabilităților modelelor pe diferite scări de parametri
- Evaluarea modelelor pe baza eficienței, capabilităților și cerințelor de implementare
- Recunoașterea cazurilor de utilizare potrivite pentru diferite familii de modele

### Zone de Focus pentru Studiu

#### Secțiunea 1: Familia de Modele Microsoft Phi
- **Concepte Prioritare**: 
  - Evoluția filozofiei de design
  - Arhitectură axată pe eficiență
  - Capabilități specializate

#### Secțiunea 2: Familia Qwen
- **Concepte Prioritare**: 
  - Contribuții open source
  - Opțiuni scalabile de implementare
  - Arhitectură avansată pentru raționament

#### Secțiunea 3: Familia Gemma
- **Concepte Prioritare**: 
  - Inovație bazată pe cercetare
  - Capabilități multimodale
  - Optimizare pentru dispozitive mobile

#### Secțiunea 4: Familia BitNET
- **Concepte Prioritare**: 
  - Tehnologia de cuantizare pe 1-bit
  - Cadru de optimizare pentru inferență
  - Considerații de sustenabilitate

#### Secțiunea 5: Modelul Microsoft Mu
- **Concepte Prioritare**: 
  - Arhitectură axată pe dispozitive
  - Integrare cu sistemul Windows
  - Operare cu protecția confidențialității

#### Secțiunea 6: Phi-Silica
- **Concepte Prioritare**: 
  - Arhitectură optimizată pentru NPU
  - Metrice de performanță
  - Integrare pentru dezvoltatori

### Întrebări de Autoevaluare

1. Comparați abordările arhitecturale ale familiilor de modele Phi și Qwen.
2. Explicați cum diferă tehnologia de cuantizare
3. Care sunt avantajele unice ale modelului Mu pentru integrarea cu Windows?
4. Descrie modul în care Phi-Silica utilizează hardware-ul NPU pentru optimizarea performanței.
5. Pentru o aplicație mobilă cu conectivitate limitată, care familie de modele ar fi cea mai potrivită și de ce?

### Exerciții practice

1. **Compararea modelelor**: Benchmark rapid între două modele SLM diferite (1 oră)
2. **Generare simplă de text**: Implementare de bază a generării de text cu un model mic (1 oră)
3. **Optimizare rapidă**: Aplicarea unei tehnici de optimizare pentru îmbunătățirea vitezei de inferență (1 oră)

## Modulul 3: Implementarea modelelor mici de limbaj (SLM)

### Obiective cheie de învățare

- Selectarea modelelor adecvate în funcție de constrângerile de implementare
- Stăpânirea tehnicilor de optimizare pentru diverse scenarii de implementare
- Implementarea SLM-urilor atât în medii locale, cât și în cloud
- Proiectarea configurațiilor pregătite pentru producție în aplicații EdgeAI

### Zone de studiu

#### Secțiunea 1: Învățare avansată SLM
- **Concepte prioritare**: 
  - Cadru de clasificare a parametrilor
  - Tehnici avansate de optimizare
  - Strategii de achiziție a modelelor

#### Secțiunea 2: Implementare în mediu local
- **Concepte prioritare**: 
  - Implementarea platformei Ollama
  - Soluții locale Microsoft Foundry
  - Analiza comparativă a cadrelor

#### Secțiunea 3: Implementare containerizată în cloud
- **Concepte prioritare**: 
  - Inferență performantă vLLM
  - Orchestrarea containerelor
  - Implementarea ONNX Runtime

### Întrebări de autoevaluare

1. Ce factori ar trebui luați în considerare atunci când se selectează între implementarea locală și cea în cloud?
2. Compară Ollama și Microsoft Foundry Local ca opțiuni de implementare.
3. Explică beneficiile containerizării pentru implementarea SLM.
4. Care sunt principalele metrici de performanță de monitorizat pentru un SLM implementat la margine?
5. Descrie un flux complet de implementare, de la selecția modelului până la implementarea în producție.

### Exerciții practice

1. **Implementare locală de bază**: Implementarea unui SLM simplu folosind Ollama (1 oră)
2. **Verificarea performanței**: Rularea unui benchmark rapid pe modelul implementat (30 minute)
3. **Integrare simplă**: Crearea unei aplicații minimale care utilizează modelul implementat (1 oră)

## Modulul 4: Conversia formatului modelului și cuantizare

### Obiective cheie de învățare

- Stăpânirea tehnicilor avansate de cuantizare de la precizie de 1-bit la 8-bit
- Înțelegerea strategiilor de conversie a formatului (GGUF, ONNX)
- Implementarea optimizării în șase cadre (Llama.cpp, Olive, OpenVINO, MLX, sinteza fluxului de lucru)
- Implementarea modelelor optimizate pentru medii de producție la margine pe hardware Intel, Apple și cross-platform

### Zone de studiu

#### Secțiunea 1: Fundamentele cuantizării
- **Concepte prioritare**: 
  - Cadru de clasificare a preciziei
  - Compromisuri între performanță și acuratețe
  - Optimizarea amprentei de memorie

#### Secțiunea 2: Implementarea Llama.cpp
- **Concepte prioritare**: 
  - Implementare cross-platform
  - Optimizarea formatului GGUF
  - Tehnici de accelerare hardware

#### Secțiunea 3: Suita Microsoft Olive
- **Concepte prioritare**: 
  - Optimizare conștientă de hardware
  - Implementare la nivel de întreprindere
  - Fluxuri de lucru automate de optimizare

#### Secțiunea 4: Toolkit OpenVINO
- **Concepte prioritare**: 
  - Optimizarea hardware-ului Intel
  - Cadru de comprimare a rețelelor neuronale (NNCF)
  - Implementare cross-platform pentru inferență
  - OpenVINO GenAI pentru implementarea LLM

#### Secțiunea 5: Cadru Apple MLX
- **Concepte prioritare**: 
  - Optimizarea pentru Apple Silicon
  - Arhitectura memoriei unificate
  - Capacități de fine-tuning LoRA

#### Secțiunea 6: Sinteza fluxului de lucru Edge AI
- **Concepte prioritare**: 
  - Arhitectura unificată a fluxului de lucru
  - Arbori de decizie pentru selecția cadrelor
  - Validarea pregătirii pentru producție
  - Strategii de viitor

### Întrebări de autoevaluare

1. Compară strategiile de cuantizare la diferite niveluri de precizie (1-bit la 8-bit).
2. Explică avantajele formatului GGUF pentru implementarea la margine.
3. Cum îmbunătățește optimizarea conștientă de hardware din Microsoft Olive eficiența implementării?
4. Care sunt beneficiile cheie ale NNCF din OpenVINO pentru comprimarea modelelor?
5. Descrie modul în care Apple MLX utilizează arhitectura memoriei unificate pentru optimizare.
6. Cum ajută sinteza fluxului de lucru în selecția cadrelor optime de optimizare?

### Exerciții practice

1. **Cuantizarea modelului**: Aplicarea diferitelor niveluri de cuantizare unui model și compararea rezultatelor (1 oră)
2. **Optimizare OpenVINO**: Utilizarea NNCF pentru comprimarea unui model pentru hardware-ul Intel (1 oră)
3. **Compararea cadrelor**: Testarea aceluiași model în trei cadre de optimizare diferite (1 oră)
4. **Benchmarking performanță**: Măsurarea impactului optimizării asupra vitezei de inferență și utilizării memoriei (1 oră)

## Modulul 5: SLMOps - Operațiuni pentru modele mici de limbaj

### Obiective cheie de învățare

- Înțelegerea principiilor de gestionare a ciclului de viață SLMOps
- Stăpânirea tehnicilor de distilare și fine-tuning pentru implementarea la margine
- Implementarea strategiilor de implementare în producție cu monitorizare
- Construirea fluxurilor de lucru de operare și întreținere SLM la nivel de întreprindere

### Zone de studiu

#### Secțiunea 1: Introducere în SLMOps
- **Concepte prioritare**: 
  - Schimbarea paradigmei SLMOps în operațiunile AI
  - Eficiență costuri și arhitectură orientată spre confidențialitate
  - Impact strategic asupra afacerii și avantaje competitive

#### Secțiunea 2: Distilarea modelului
- **Concepte prioritare**: 
  - Tehnici de transfer de cunoștințe
  - Implementarea procesului de distilare în două etape
  - Fluxuri de lucru de distilare Azure ML

#### Secțiunea 3: Strategii de fine-tuning
- **Concepte prioritare**: 
  - Fine-tuning eficient din punct de vedere al parametrilor (PEFT)
  - Metode avansate LoRA și QLoRA
  - Antrenament multi-adaptor și optimizarea hiperparametrilor

#### Secțiunea 4: Implementare în producție
- **Concepte prioritare**: 
  - Conversia și cuantizarea modelului pentru producție
  - Configurarea implementării Foundry Local
  - Benchmarking performanță și validarea calității

### Întrebări de autoevaluare

1. Cum diferă SLMOps de MLOps tradițional?
2. Explică beneficiile distilării modelului pentru implementarea la margine.
3. Care sunt considerațiile cheie pentru fine-tuning-ul SLM-urilor în medii cu resurse limitate?
4. Descrie un flux complet de implementare în producție pentru aplicații Edge AI.

### Exerciții practice

1. **Distilare de bază**: Crearea unui model mai mic dintr-un model profesor mai mare (1 oră)
2. **Experiment de fine-tuning**: Fine-tuning-ul unui model pentru un domeniu specific (1 oră)
3. **Pipeline de implementare**: Configurarea unui pipeline CI/CD de bază pentru implementarea modelului (1 oră)

## Modulul 6: Sisteme agentice SLM - Agenți AI și apelarea funcțiilor

### Obiective cheie de învățare

- Construirea agenților AI inteligenți pentru medii la margine folosind modele mici de limbaj
- Implementarea capacităților de apelare a funcțiilor cu fluxuri de lucru sistematice
- Stăpânirea integrării Model Context Protocol (MCP) pentru interacțiunea standardizată cu instrumentele
- Crearea sistemelor agentice sofisticate cu intervenție umană minimă

### Zone de studiu

#### Secțiunea 1: Agenți AI și fundamentele SLM
- **Concepte prioritare**: 
  - Cadru de clasificare a agenților (reflex, bazat pe model, bazat pe obiective, agenți de învățare)
  - Analiza compromisurilor SLM vs LLM
  - Modele de design pentru agenți specifici marginii
  - Optimizarea resurselor pentru agenți

#### Secțiunea 2: Apelarea funcțiilor în modele mici de limbaj
- **Concepte prioritare**: 
  - Implementarea fluxurilor de lucru sistematice (detectarea intenției, output JSON, execuție externă)
  - Implementări specifice platformei (Phi-4-mini, modele Qwen selectate, Microsoft Foundry Local)
  - Exemple avansate (colaborare multi-agent, selecție dinamică de instrumente)
  - Considerații pentru producție (limitarea ratei, jurnalizare audit, măsuri de securitate)

#### Secțiunea 3: Integrarea Model Context Protocol (MCP)
- **Concepte prioritare**: 
  - Arhitectura protocolului și designul sistemului stratificat
  - Suport multi-backend (Ollama pentru dezvoltare, vLLM pentru producție)
  - Protocoale de conexiune (moduri STDIO și SSE)
  - Aplicații reale (automatizare web, procesare de date, integrare API)

### Întrebări de autoevaluare

1. Care sunt considerațiile arhitecturale cheie pentru agenții AI la margine?
2. Cum îmbunătățește apelarea funcțiilor capacitățile agenților?
3. Explică rolul Model Context Protocol în comunicarea agenților.

### Exerciții practice

1. **Agent simplu**: Construirea unui agent AI de bază cu apelarea funcțiilor (1 oră)
2. **Integrarea MCP**: Implementarea MCP într-o aplicație de agent (30 minute)

## Modulul 7: Exemple de implementare EdgeAI

### Obiective cheie de învățare

- Stăpânirea AI Toolkit pentru Visual Studio Code pentru fluxuri de lucru complete de dezvoltare EdgeAI
- Dobândirea expertizei în platforma Windows AI Foundry și strategiile de optimizare NPU
- Implementarea EdgeAI pe mai multe platforme hardware și scenarii de implementare
- Construirea aplicațiilor EdgeAI pregătite pentru producție cu optimizări specifice platformei

### Zone de studiu

#### Secțiunea 1: AI Toolkit pentru Visual Studio Code
- **Concepte prioritare**: 
  - Mediu complet de dezvoltare Edge AI în cadrul VS Code
  - Catalog de modele și descoperire pentru implementarea la margine
  - Testare locală, optimizare și fluxuri de lucru pentru dezvoltarea agenților
  - Monitorizarea performanței și evaluarea pentru scenarii la margine

#### Secțiunea 2: Ghid de dezvoltare Windows EdgeAI
- **Concepte prioritare**: 
  - Prezentare generală a platformei Windows AI Foundry
  - API-ul Phi Silica pentru inferență eficientă NPU
  - API-uri de Computer Vision pentru procesarea imaginilor și OCR
  - CLI Foundry Local pentru dezvoltare și testare locală

#### Secțiunea 3: Implementări specifice platformei
- **Concepte prioritare**: 
  - Implementarea NVIDIA Jetson Orin Nano (performanță AI de 67 TOPS)
  - Aplicații mobile cu .NET MAUI și ONNX Runtime GenAI
  - Soluții Azure EdgeAI cu arhitectură hibridă cloud-margine
  - Optimizarea Windows ML cu suport hardware universal
  - Aplicații Foundry Local cu implementare RAG orientată spre confidențialitate

### Întrebări de autoevaluare

1. Cum simplifică AI Toolkit fluxul de lucru de dezvoltare EdgeAI?
2. Compară strategiile de implementare pe diferite platforme hardware.
3. Care sunt avantajele Windows AI Foundry pentru dezvoltarea la margine?
4. Explică rolul optimizării NPU în aplicațiile moderne Edge AI.
5. Cum utilizează API-ul Phi Silica hardware-ul NPU pentru optimizarea performanței?
6. Compară beneficiile implementării locale vs. în cloud pentru aplicațiile sensibile la confidențialitate.

### Exerciții practice

1. **Configurarea AI Toolkit**: Configurarea AI Toolkit și optimizarea unui model (1 oră)
2. **Windows AI Foundry**: Construirea unei aplicații AI simple pentru Windows folosind API-ul Phi Silica (1 oră)
3. **Implementare cross-platform**: Implementarea aceluiași model pe două platforme diferite (1 oră)
4. **Optimizare NPU**: Testarea performanței NPU cu instrumentele Windows AI Foundry (30 minute)

## Modulul 8: Microsoft Foundry Local – Kit complet pentru dezvoltatori (modernizat)

### Obiective cheie de învățare

- Instalarea și configurarea Foundry Local cu integrarea SDK modernă
- Implementarea sistemelor multi-agent avansate cu modele de coordonare
- Construirea routerelor inteligente de modele cu selecție automată bazată pe sarcini
- Implementarea soluțiilor AI pregătite pentru producție cu monitorizare cuprinzătoare
- Integrarea cu Azure AI Foundry pentru scenarii de implementare hibride
- Stăpânirea modelelor SDK moderne cu FoundryLocalManager și clientul OpenAI

### Zone de studiu

#### Secțiunea 1: Instalare și configurare modernă
- **Concepte prioritare**: 
  - Integrarea SDK FoundryLocalManager
  - Descoperirea automată a serviciilor și monitorizarea sănătății
  - Modele de configurare bazate pe mediu
  - Considerații pentru implementarea în producție

#### Secțiunea 2: Sisteme multi-agent avansate
- **Concepte prioritare**: 
  - Modelul de coordonare cu agenți specializați
  - Specializarea agenților pentru recuperare, raționament și execuție
  - Mecanisme de feedback pentru rafinare
  - Monitorizarea performanței și urmărirea statisticilor

#### Secțiunea 3: Rutare inteligentă a modelelor
- **Concepte prioritare**: 
  - Algoritmi de selecție a modelelor bazate pe cuvinte cheie
  - Suport pentru modele multiple (general, raționament, cod, creativ)
  - Configurarea variabilelor de mediu pentru flexibilitate
  - Verificarea sănătății serviciilor și gestionarea erorilor

#### Secțiunea 4: Implementare pregătită pentru producție
- **Concepte prioritare**: 
  - Gestionarea cuprinzătoare a erorilor și mecanisme de rezervă
  - Monitorizarea cererilor și urmărirea performanței
  - Exemple interactive în Jupyter notebook cu benchmark-uri
  - Modele de integrare cu aplicații existente

### Întrebări de autoevaluare

1. Cum diferă abordarea modernă FoundryLocalManager de apelurile REST manuale?
2. Explică modelul de coordonare și modul în care acesta orchestrează agenții specializați.
3. Cum selectează routerul inteligent modelele adecvate pe baza conținutului interogării?
4. Care sunt componentele cheie ale unui sistem de agenți AI pregătit pentru producție?
5. Cum implementezi monitorizarea cuprinzătoare a sănătății pentru serviciile Foundry Local?
6. Compară beneficiile abordării modernizate vs. modelele tradiționale de implementare.

### Exerciții practice

1. **Configurarea SDK modern**: Configurarea FoundryLocalManager cu descoperirea automată a serviciilor (30 minute)
2. **Sistem multi-agent**: Rularea coordonatorului avansat cu agenți specializați (30 minute)
3. **Rutare inteligentă**: Testarea routerului de modele cu diferite tipuri de interogări (30 minute)
4. **Explorare interactivă**: Utilizarea Jupyter notebooks pentru explorarea caracteristicilor avansate (45 minute)
5. **Implementare în producție**: Implementarea modelelor de monitorizare și gestionare a erorilor (30 minute)
6. **Integrare hibridă**: Configurarea scenariilor de rezervă Azure
| Exerciții practice | 6 ore | Implementarea practică a tehnicilor cheie |
| Autoevaluare | 2 ore | Testarea înțelegerii prin întrebări și reflecție |
| Mini-proiect | 3 ore | Aplicarea cunoștințelor într-o implementare practică mică |

### Zone cheie de focus în funcție de timpul disponibil

**Dacă ai doar 10 ore:**
- Finalizează Modulul 0 (Introducere) și Modulele 1, 2 și 3 (concepte de bază EdgeAI)
- Realizează cel puțin un exercițiu practic pe modul
- Concentrează-te pe înțelegerea conceptelor de bază, mai degrabă decât pe detaliile de implementare

**Dacă poți dedica 20 de ore complete:**
- Finalizează toate cele opt module (inclusiv Introducerea)
- Realizează exercițiile practice cheie din fiecare modul
- Finalizează un mini-proiect din Modulul 7
- Explorează cel puțin 2-3 resurse suplimentare

**Dacă ai mai mult de 20 de ore:**
- Finalizează toate modulele (inclusiv Introducerea) cu exerciții detaliate
- Construiește mai multe mini-proiecte
- Explorează tehnici avansate de optimizare în Modulul 4
- Implementează un proces de implementare în producție din Modulul 5

## Resurse esențiale

Aceste resurse atent selectate oferă cea mai mare valoare pentru timpul tău limitat de studiu:

### Documentație obligatorie
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Cel mai eficient instrument de optimizare a modelelor
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cea mai rapidă metodă de a implementa SLM-uri local
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referință pentru un model optimizat pentru edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Setul de instrumente complet de optimizare de la Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Mediu integrat de dezvoltare EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platformă specifică Windows pentru dezvoltare EdgeAI

### Instrumente care economisesc timp
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acces rapid la modele și implementare
- [Gradio](https://www.gradio.app/docs/interface) - Dezvoltare rapidă de interfețe UI pentru demonstrații AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimizare simplificată a modelelor
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferență eficientă pe CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Cadru pentru comprimarea rețelelor neuronale
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Set de instrumente pentru implementarea modelelor mari de limbaj

## Șablon pentru urmărirea progresului

Folosește acest șablon simplificat pentru a urmări progresul în cadrul cursului de 20 de ore:

| Modul | Data finalizării | Ore petrecute | Idei principale |
|-------|------------------|---------------|-----------------|
| Modulul 0: Introducere în EdgeAI | | | |
| Modulul 1: Fundamente EdgeAI | | | |
| Modulul 2: Fundamente SLM | | | |
| Modulul 3: Implementarea SLM | | | |
| Modulul 4: Optimizarea modelelor | | | |
| Modulul 5: SLMOps | | | |
| Modulul 6: Agenți AI | | | |
| Modulul 7: Instrumente de dezvoltare | | | |
| Modulul 8: Foundry Local Toolkit | | | |
| Exerciții practice | | | |
| Mini-proiect | | | |

## Idei pentru mini-proiecte

Ia în considerare realizarea unuia dintre aceste proiecte pentru a exersa conceptele EdgeAI (fiecare proiect este conceput să dureze 2-4 ore):

### Proiecte pentru începători (2-3 ore fiecare)
1. **Asistent text pentru Edge**: Creează un instrument simplu de completare a textului offline folosind un model de limbaj mic
2. **Tablou de bord pentru comparația modelelor**: Construiește o vizualizare de bază a metricilor de performanță pentru diferite SLM-uri
3. **Experiment de optimizare**: Măsoară impactul diferitelor niveluri de cuantizare asupra aceluiași model de bază

### Proiecte intermediare (3-4 ore fiecare)
4. **Flux de lucru cu AI Toolkit**: Folosește AI Toolkit din VS Code pentru a optimiza și implementa un model de la început până la sfârșit
5. **Aplicație Windows AI Foundry**: Creează o aplicație Windows folosind API-ul Phi Silica și optimizarea NPU
6. **Implementare multiplatformă**: Implementează același model optimizat pe Windows (OpenVINO) și pe mobil (.NET MAUI)
7. **Agent cu funcții apelabile**: Construiește un agent AI cu capacități de apelare a funcțiilor pentru scenarii edge

### Proiecte avansate de integrare (4-5 ore fiecare)
8. **Pipeline de optimizare OpenVINO**: Implementează o optimizare completă a modelului folosind NNCF și setul de instrumente GenAI
9. **Pipeline SLMOps**: Implementează un ciclu complet de viață al modelului, de la antrenare la implementare pe edge
10. **Sistem Edge multi-model**: Implementează mai multe modele specializate care lucrează împreună pe hardware edge
11. **Sistem de integrare MCP**: Construiește un sistem agentic folosind Model Context Protocol pentru interacțiunea cu instrumentele

## Referințe

- Microsoft Learn (Foundry Local)
  - Prezentare generală: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Începe: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referință CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrare cu SDK-uri de inferență: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Cum să deschizi WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compilare modele Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Prezentare generală: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agenți (prezentare generală): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Instrumente de optimizare și inferență
  - Microsoft Olive (documentație): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (începe): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integrare ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (documentație): https://docs.openvino.ai/2025/index.html
  - Apple MLX (documentație): https://ml-explore.github.io/mlx/build/html/index.html
- Framework-uri de implementare și modele
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (documentație): https://docs.vllm.ai/
  - Ollama (începe rapid): https://github.com/ollama/ollama#get-started
- Instrumente pentru dezvoltatori (Windows și VS Code)
  - AI Toolkit pentru VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (prezentare generală): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Comunitatea de învățare

Alătură-te discuțiilor și conectează-te cu alți cursanți:
- Discuții pe GitHub în [repository-ul EdgeAI pentru începători](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Concluzie

EdgeAI reprezintă frontiera implementării inteligenței artificiale, aducând capabilități puternice direct pe dispozitive, în timp ce abordează preocupări critice legate de confidențialitate, latență și conectivitate. Acest curs de 20 de ore îți oferă cunoștințele esențiale și abilitățile practice pentru a începe să lucrezi imediat cu tehnologiile EdgeAI.

Cursul este conceput să fie concis și axat pe cele mai importante concepte, permițându-ți să dobândești rapid expertiză valoroasă fără un angajament de timp copleșitor. Amintește-ți că practica practică, chiar și cu exemple simple, este cheia consolidării a ceea ce ai învățat.

Învățare plăcută!

---

