<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T15:11:06+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru Începători: Căi de Învățare și Program de Studiu

### Cale de Învățare Intensivă (1 săptămână)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Ziua 0 | Modulul 0: Introducere în EdgeAI | 1-2 ore |
| Ziua 1 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Ziua 2 | Modulul 2: Fundamentele SLM | 3 ore |
| Ziua 3 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 4-5 | Modulul 4: Optimizarea Modelului (6 cadre de lucru) | 4 ore |
| Ziua 6 | Modulul 5: SLMOps | 3 ore |
| Ziua 7 | Modulele 6-7: Agenți AI & Instrumente de Dezvoltare | 4 ore |
| Ziua 8 | Modulul 8: Foundry Local Toolkit (Implementare Modernă) | 1 oră |

### Cale de Învățare Intensivă (2 săptămâni)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Agenți AI | 2 ore |
| Zilele 13-14 | Modulul 7: Instrumente de Dezvoltare | 3 ore |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Fundamentele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Ziua 0 | Modulul 0: Introducere în EdgeAI | 1-2 ore |
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Sisteme Agentice SLM | 2 ore |
| Zilele 13-14 | Modulul 7: Exemple de Implementare EdgeAI | 2 ore |

| Modul | Data Finalizării | Ore Petrecute | Concluzii Cheie |
|--------|----------------|-------------|--------------|
| Modulul 0: Introducere în EdgeAI | | | |
| Modulul 1: Fundamentele EdgeAI | | | |
| Modulul 2: Fundamentele SLM | | | |
| Modulul 3: Implementarea SLM | | | |
| Modulul 4: Optimizarea Modelului (6 cadre de lucru) | | | |
| Modulul 5: SLMOps | | | |
| Modulul 6: Sisteme Agentice SLM | | | |
| Modulul 7: Exemple de Implementare EdgeAI | | | |
| Exerciții Practice | | | |
| Mini-Proiect | | | |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Fundamentele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

## Introducere

Bine ați venit la ghidul de studiu EdgeAI pentru Începători! Acest document este conceput pentru a vă ajuta să navigați eficient materialele cursului și să maximizați experiența de învățare. Oferă căi de învățare structurate, programe de studiu sugerate, rezumate ale conceptelor cheie și resurse suplimentare pentru a aprofunda înțelegerea tehnologiilor Edge AI.

Acesta este un curs concis de 20 de ore care oferă cunoștințe esențiale despre EdgeAI într-un format eficient din punct de vedere al timpului, fiind ideal pentru profesioniști ocupați și studenți care doresc să dobândească rapid abilități practice în acest domeniu emergent.

## Prezentare Generală a Cursului

Cursul este organizat în opt module cuprinzătoare:

0. **Introducere în EdgeAI** - Fundamente și stabilirea contextului cu aplicații industriale și obiective de învățare  
1. **Fundamentele și Transformarea EdgeAI** - Înțelegerea conceptelor de bază și a schimbării tehnologice  
2. **Fundamentele Modelului de Limbaj Mic (SLM)** - Explorarea diferitelor familii SLM și a arhitecturilor acestora  
3. **Implementarea Modelului de Limbaj Mic** - Strategii practice de implementare  
4. **Conversia Formatului Modelului și Cuantizare** - Optimizare avansată cu 6 cadre de lucru, inclusiv OpenVINO  
5. **SLMOps - Operațiuni pentru Modele de Limbaj Mic** - Managementul ciclului de viață al producției și implementării  
6. **Sisteme Agentice SLM** - Agenți AI, apelarea funcțiilor și Protocolul Contextului Modelului  
7. **Exemple de Implementare EdgeAI** - Toolkit AI, dezvoltare pe Windows și implementări specifice platformei  
8. **Microsoft Foundry Local – Toolkit Complet pentru Dezvoltatori** - Dezvoltare locală cu integrare hibridă Azure (Modulul 08)

## Cum să Utilizați Acest Ghid de Studiu

- **Învățare Progresivă**: Urmați modulele în ordine pentru o experiență de învățare coerentă  
- **Puncte de Verificare a Cunoștințelor**: Utilizați întrebările de autoevaluare după fiecare secțiune  
- **Practica Practică**: Finalizați exercițiile sugerate pentru a consolida conceptele teoretice  
- **Resurse Suplimentare**: Explorați materiale suplimentare pentru subiectele care vă interesează cel mai mult  

## Recomandări pentru Programul de Studiu

### Cale de Învățare Intensivă (1 săptămână)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Ziua 0 | Modulul 0: Introducere în EdgeAI | 1-2 ore |
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 6 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 8 ore |
| Ziua 5 | Modulul 3: Implementarea SLM | 3 ore |
| Ziua 6 | Modulul 8: Foundry Local Toolkit | 3 ore |

### Studiu Part-Time (3 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulul 0: Introducere + Modulul 1: Fundamentele EdgeAI | 7-9 ore |
| Săptămâna 2 | Modulul 2: Fundamentele SLM | 7-8 ore |
| Săptămâna 3 | Modulul 3: Implementarea SLM (3h) + Modulul 8: Foundry Local Toolkit (2-3h) | 5-6 ore |

## Modulul 0: Introducere în EdgeAI

### Obiective Cheie de Învățare

- Înțelegeți ce este Edge AI și de ce este important în peisajul tehnologic actual  
- Identificați industriile majore transformate de Edge AI și cazurile lor specifice de utilizare  
- Înțelegeți avantajele Modelelor de Limbaj Mic (SLM) pentru implementarea la margine  
- Stabiliți așteptări clare de învățare și rezultate pentru întregul curs  
- Recunoașteți oportunitățile de carieră și cerințele de competențe în domeniul Edge AI  

### Zone de Focus pentru Studiu

#### Secțiunea 1: Paradigma și Definiția Edge AI
- **Concepte Prioritare**:  
  - Edge AI vs. procesarea tradițională AI în cloud  
  - Convergența hardware-ului, optimizarea modelului și cerințele de afaceri  
  - Implementare AI în timp real, care protejează confidențialitatea și este eficientă din punct de vedere al costurilor  

#### Secțiunea 2: Aplicații Industriale
- **Concepte Prioritare**:  
  - Producție & Industria 4.0: Mentenanță predictivă și controlul calității  
  - Sănătate: Imagistică diagnostică și monitorizarea pacienților  
  - Sisteme Autonome: Vehicule autonome și transport  
  - Orașe Inteligente: Managementul traficului și siguranța publică  
  - Tehnologie pentru Consumatori: Smartphone-uri, dispozitive purtabile și case inteligente  

#### Secțiunea 3: Fundamentele Modelelor de Limbaj Mic
- **Concepte Prioritare**:  
  - Caracteristicile și comparațiile de performanță ale SLM  
  - Eficiența parametrilor vs. compromisurile de capabilitate  
  - Constrângerile de implementare la margine și strategiile de optimizare  

#### Secțiunea 4: Cadru de Învățare și Cale de Carieră
- **Concepte Prioritare**:  
  - Arhitectura cursului și abordarea progresivă a stăpânirii  
  - Abilități tehnice și obiective de implementare practică  
  - Oportunități de avansare în carieră și aplicații industriale  

### Întrebări de Autoevaluare

1. Care sunt cele trei tendințe tehnologice principale care au permis Edge AI?  
2. Comparați avantajele și provocările Edge AI vs. AI bazat pe cloud.  
3. Numiți trei industrii în care Edge AI oferă valoare critică pentru afaceri și explicați de ce.  
4. Cum fac Modelele de Limbaj Mic ca Edge AI să fie practic pentru implementarea în lumea reală?  
5. Care sunt abilitățile tehnice cheie pe care le veți dezvolta pe parcursul acestui curs?  
6. Descrieți abordarea de învățare în patru faze utilizată în acest curs.  

### Exerciții Practice

1. **Cercetare Industrială**: Alegeți o aplicație industrială și cercetați o implementare reală Edge AI (30 minute)  
2. **Explorarea Modelului**: Răsfoiți Modelele de Limbaj Mic disponibile pe Hugging Face și comparați numărul de parametri și capabilitățile acestora (30 minute)  
3. **Planificarea Învățării**: Revizuiți structura completă a cursului și creați programul personal de studiu (15 minute)  

### Materiale Suplimentare

- [Prezentare Generală a Pieței Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Prezentare Generală a Modelelor de Limbaj Mic - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Fundamentele Calculului la Margine](https://www.edgecomputing.org/)  

## Modulul 1: Fundamentele și Transformarea EdgeAI

### Obiective Cheie de Învățare

- Înțelegeți diferențele dintre AI bazat pe cloud și AI bazat pe margine  
- Stăpâniți tehnicile de optimizare de bază pentru medii cu resurse limitate  
- Analizați aplicațiile reale ale tehnologiilor EdgeAI  
- Configurați un mediu de dezvoltare pentru proiecte EdgeAI  

### Zone de Focus pentru Studiu

#### Secțiunea 1: Fundamentele EdgeAI
- **Concepte Prioritare**:  
  - Paradigmele de calcul Edge vs. Cloud  
  - Tehnici de cuantizare a modelului  
  - Opțiuni de accelerare hardware (NPU-uri, GPU-uri, CPU-uri)  
  - Avantajele confidențialității și securității  

- **Materiale Suplimentare**:  
  - [Documentația TensorFlow Lite](https://www.tensorflow.org/lite)  
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)  
  - [Documentația Edge Impulse](https://docs.edgeimpulse.com)  

#### Secțiunea 2: Studii de Caz Reale
- **Concepte Prioritare**:  
  - Ecosistemul de modele Microsoft Phi & Mu  
  - Implementări practice în diverse industrii  
  - Considerații de implementare  

#### Secțiunea 3: Ghid Practic de Implementare
- **Concepte Prioritare**:  
  - Configurarea mediului de dezvoltare  
  - Instrumente de cuantizare și optimizare  
  - Metode de evaluare pentru implementările EdgeAI  

#### Secțiunea 4: Hardware pentru Implementare la Margine
- **Concepte Prioritare**:  
  - Compararea platformelor hardware  
  - Strategii de optimizare pentru hardware specific  
  - Considerații de implementare  

### Întrebări de Autoevaluare

1. Comparați și contrastați implementările AI bazate pe cloud cu cele bazate pe margine.  
2. Explicați trei tehnici cheie pentru optimizarea modelelor pentru implementarea la margine.  
3. Care sunt principalele avantaje ale rulării modelelor AI la margine?  
4. Descrieți procesul de cuantizare a unui model și cum afectează performanța.  
5. Explicați cum diferiți acceleratori hardware (NPU-uri, GPU-uri, CPU-uri) influențează implementarea EdgeAI.  

### Exerciții Practice

1. **Configurare Rapidă a Mediului**: Configurați un mediu de dezvoltare minim cu pachetele esențiale (30 minute)  
2. **Explorarea Modelului**: Descărcați și examinați un model de limbaj mic pre-antrenat (1 oră)  
3. **Cuantizare de Bază**: Încercați o cuantizare simplă pe un model mic (1 oră)  

## Modulul 2: Fundamentele Modelului de Limbaj Mic

### Obiective Cheie de Învățare

- Înțelegeți principiile arhitecturale ale diferitelor familii SLM  
- Comparați capabilitățile modelelor pe diferite scale de parametri  
- Evaluați modelele pe baza eficienței, capabilității și cerințelor de implementare  
- Recunoașteți cazurile de utilizare adecvate pentru diferite familii de modele  

### Zone de Focus pentru Studiu

#### Secțiunea 1: Familia de Modele Microsoft Phi
- **Concepte Prioritare**:  
  - Evoluția filozofiei de design  
  - Arhitectura orientată spre eficiență  
  - Capabilități specializate  

#### Secțiunea 2: Familia Qwen
- **Concepte Prioritare**:  
  - Contribuții open source  
  - Opțiuni scalabile de implementare  
  - Arhitectura avansată de raționament  

#### Secțiunea 3: Familia Gemma
- **Concepte Prioritare**:  
  - Inovație bazată pe cercetare  
  - Capabilități multimodale  
  - Optimizare pentru mobil  

#### Secțiunea 4: Familia BitNET
- **Concepte Prioritare**:  
  - Tehnologia de cuantizare la 1-bit  
  - Cadru de optimizare pentru inferență  
  - Considerații de sustenabilitate  

#### Secțiunea 5: Modelul Microsoft Mu
- **Concepte Prioritare**:  
  - Arhitectura orientată spre dispozitive  
  - Integrarea sistemului cu Windows  
  - Operare care protejează confidențialitatea  

#### Secțiunea 6: Phi-Silica
- **Concepte Prioritare**:  
  - Arhitectura optimizată pentru NPU  
  - Metrice de performanță  
  - Integrarea pentru dezvoltatori  

### Î
3. Care sunt avantajele unice ale modelului Mu pentru integrarea cu Windows?
4. Descrie modul în care Phi-Silica utilizează hardware-ul NPU pentru optimizarea performanței.
5. Pentru o aplicație mobilă cu conectivitate limitată, care familie de modele ar fi cea mai potrivită și de ce?

### Exerciții practice

1. **Compararea modelelor**: Benchmark rapid între două modele SLM diferite (1 oră)
2. **Generare simplă de text**: Implementare de bază a generării de text cu un model mic (1 oră)
3. **Optimizare rapidă**: Aplicarea unei tehnici de optimizare pentru îmbunătățirea vitezei de inferență (1 oră)

## Modulul 3: Implementarea modelelor de limbaj mici

### Obiective cheie de învățare

- Selectarea modelelor adecvate în funcție de constrângerile de implementare
- Stăpânirea tehnicilor de optimizare pentru diverse scenarii de implementare
- Implementarea modelelor SLM atât în medii locale, cât și în cloud
- Proiectarea configurațiilor pregătite pentru producție în aplicații EdgeAI

### Zone de studiu

#### Secțiunea 1: Învățare avansată SLM
- **Concepte prioritare**: 
  - Cadru de clasificare a parametrilor
  - Tehnici avansate de optimizare
  - Strategii de achiziție a modelelor

#### Secțiunea 2: Implementare în mediu local
- **Concepte prioritare**: 
  - Implementarea platformei Ollama
  - Soluții locale Microsoft Foundry
  - Analiza comparativă a cadrelor

#### Secțiunea 3: Implementare containerizată în cloud
- **Concepte prioritare**: 
  - Inferență performantă vLLM
  - Orchestrarea containerelor
  - Implementarea ONNX Runtime

### Întrebări de autoevaluare

1. Ce factori trebuie luați în considerare atunci când se alege între implementarea locală și cea în cloud?
2. Compară Ollama și Microsoft Foundry Local ca opțiuni de implementare.
3. Explică beneficiile containerizării pentru implementarea SLM.
4. Care sunt principalele metrici de performanță de monitorizat pentru un SLM implementat la margine?
5. Descrie un flux complet de implementare, de la selecția modelului până la implementarea în producție.

### Exerciții practice

1. **Implementare locală de bază**: Implementarea unui SLM simplu folosind Ollama (1 oră)
2. **Verificarea performanței**: Rularea unui benchmark rapid pe modelul implementat (30 minute)
3. **Integrare simplă**: Crearea unei aplicații minimale care utilizează modelul implementat (1 oră)

## Modulul 4: Conversia formatului modelului și cuantizare

### Obiective cheie de învățare

- Stăpânirea tehnicilor avansate de cuantizare de la precizie de 1-bit la 8-bit
- Înțelegerea strategiilor de conversie a formatului (GGUF, ONNX)
- Implementarea optimizării în șase cadre (Llama.cpp, Olive, OpenVINO, MLX, sinteza fluxului de lucru)
- Implementarea modelelor optimizate pentru medii de producție la margine pe hardware Intel, Apple și cross-platform

### Zone de studiu

#### Secțiunea 1: Fundamentele cuantizării
- **Concepte prioritare**: 
  - Cadru de clasificare a preciziei
  - Compromisuri între performanță și acuratețe
  - Optimizarea amprentei de memorie

#### Secțiunea 2: Implementarea Llama.cpp
- **Concepte prioritare**: 
  - Implementare cross-platform
  - Optimizarea formatului GGUF
  - Tehnici de accelerare hardware

#### Secțiunea 3: Microsoft Olive Suite
- **Concepte prioritare**: 
  - Optimizare conștientă de hardware
  - Implementare de nivel enterprise
  - Fluxuri de lucru de optimizare automatizate

#### Secțiunea 4: OpenVINO Toolkit
- **Concepte prioritare**: 
  - Optimizarea hardware-ului Intel
  - Cadru de compresie a rețelelor neuronale (NNCF)
  - Implementare de inferență cross-platform
  - OpenVINO GenAI pentru implementarea LLM

#### Secțiunea 5: Apple MLX Framework
- **Concepte prioritare**: 
  - Optimizarea pentru Apple Silicon
  - Arhitectura memoriei unificate
  - Capacități de fine-tuning LoRA

#### Secțiunea 6: Sinteza fluxului de lucru Edge AI
- **Concepte prioritare**: 
  - Arhitectura unificată a fluxului de lucru
  - Arbori de decizie pentru selecția cadrelor
  - Validarea pregătirii pentru producție
  - Strategii de viitor

### Întrebări de autoevaluare

1. Compară strategiile de cuantizare la diferite niveluri de precizie (1-bit la 8-bit).
2. Explică avantajele formatului GGUF pentru implementarea la margine.
3. Cum îmbunătățește optimizarea conștientă de hardware din Microsoft Olive eficiența implementării?
4. Care sunt beneficiile cheie ale NNCF din OpenVINO pentru compresia modelelor?
5. Descrie modul în care Apple MLX utilizează arhitectura memoriei unificate pentru optimizare.
6. Cum ajută sinteza fluxului de lucru în selecția cadrelor optime de optimizare?

### Exerciții practice

1. **Cuantizarea modelului**: Aplicarea diferitelor niveluri de cuantizare unui model și compararea rezultatelor (1 oră)
2. **Optimizare OpenVINO**: Utilizarea NNCF pentru comprimarea unui model pentru hardware-ul Intel (1 oră)
3. **Compararea cadrelor**: Testarea aceluiași model pe trei cadre de optimizare diferite (1 oră)
4. **Benchmarking de performanță**: Măsurarea impactului optimizării asupra vitezei de inferență și utilizării memoriei (1 oră)

## Modulul 5: SLMOps - Operațiuni pentru modele de limbaj mici

### Obiective cheie de învățare

- Înțelegerea principiilor de gestionare a ciclului de viață SLMOps
- Stăpânirea tehnicilor de distilare și fine-tuning pentru implementarea la margine
- Implementarea strategiilor de implementare în producție cu monitorizare
- Construirea fluxurilor de lucru de operațiuni și întreținere SLM de nivel enterprise

### Zone de studiu

#### Secțiunea 1: Introducere în SLMOps
- **Concepte prioritare**: 
  - Schimbarea paradigmei SLMOps în operațiunile AI
  - Arhitectură eficientă din punct de vedere al costurilor și orientată spre confidențialitate
  - Impact strategic asupra afacerii și avantaje competitive

#### Secțiunea 2: Distilarea modelului
- **Concepte prioritare**: 
  - Tehnici de transfer de cunoștințe
  - Implementarea procesului de distilare în două etape
  - Fluxuri de lucru de distilare Azure ML

#### Secțiunea 3: Strategii de fine-tuning
- **Concepte prioritare**: 
  - Fine-tuning eficient din punct de vedere al parametrilor (PEFT)
  - Metode avansate LoRA și QLoRA
  - Antrenament multi-adaptor și optimizarea hiperparametrilor

#### Secțiunea 4: Implementare în producție
- **Concepte prioritare**: 
  - Conversia și cuantizarea modelului pentru producție
  - Configurarea implementării Foundry Local
  - Benchmarking de performanță și validarea calității

### Întrebări de autoevaluare

1. Cum diferă SLMOps de MLOps tradițional?
2. Explică beneficiile distilării modelului pentru implementarea la margine.
3. Care sunt considerațiile cheie pentru fine-tuning-ul SLM-urilor în medii cu resurse limitate?
4. Descrie un flux complet de implementare în producție pentru aplicații Edge AI.

### Exerciții practice

1. **Distilare de bază**: Crearea unui model mai mic dintr-un model profesor mai mare (1 oră)
2. **Experiment de fine-tuning**: Fine-tuning-ul unui model pentru un domeniu specific (1 oră)
3. **Pipeline de implementare**: Configurarea unui pipeline CI/CD de bază pentru implementarea modelului (1 oră)

## Modulul 6: Sisteme agentice SLM - Agenți AI și apelarea funcțiilor

### Obiective cheie de învățare

- Construirea agenților AI inteligenți pentru medii la margine folosind modele de limbaj mici
- Implementarea capacităților de apelare a funcțiilor cu fluxuri de lucru sistematice
- Stăpânirea integrării Model Context Protocol (MCP) pentru interacțiunea standardizată cu instrumentele
- Crearea sistemelor agentice sofisticate cu intervenție umană minimă

### Zone de studiu

#### Secțiunea 1: Agenți AI și fundamentele SLM
- **Concepte prioritare**: 
  - Cadru de clasificare a agenților (reflex, bazat pe model, bazat pe obiective, agenți de învățare)
  - Analiza compromisurilor SLM vs LLM
  - Modele de design specifice pentru agenți la margine
  - Optimizarea resurselor pentru agenți

#### Secțiunea 2: Apelarea funcțiilor în modele de limbaj mici
- **Concepte prioritare**: 
  - Implementarea fluxurilor de lucru sistematice (detectarea intenției, output JSON, execuție externă)
  - Implementări specifice platformei (Phi-4-mini, modele Qwen selectate, Microsoft Foundry Local)
  - Exemple avansate (colaborare multi-agent, selecție dinamică de instrumente)
  - Considerații pentru producție (limitarea ratei, jurnalizarea auditului, măsuri de securitate)

#### Secțiunea 3: Integrarea Model Context Protocol (MCP)
- **Concepte prioritare**: 
  - Arhitectura protocolului și designul sistemului stratificat
  - Suport multi-backend (Ollama pentru dezvoltare, vLLM pentru producție)
  - Protocoale de conexiune (moduri STDIO și SSE)
  - Aplicații reale (automatizare web, procesare de date, integrare API)

### Întrebări de autoevaluare

1. Care sunt considerațiile arhitecturale cheie pentru agenții AI la margine?
2. Cum îmbunătățește apelarea funcțiilor capacitățile agenților?
3. Explică rolul Model Context Protocol în comunicarea agenților.

### Exerciții practice

1. **Agent simplu**: Construirea unui agent AI de bază cu apelarea funcțiilor (1 oră)
2. **Integrarea MCP**: Implementarea MCP într-o aplicație de agent (30 minute)

## Atelier: Calea de învățare practică

### Obiective cheie de învățare

- Construirea aplicațiilor AI pregătite pentru producție folosind SDK-ul Foundry Local și cele mai bune practici
- Implementarea gestionării erorilor și a modelelor de feedback pentru utilizatori
- Crearea de pipeline-uri RAG cu evaluarea calității și monitorizarea performanței
- Dezvoltarea sistemelor multi-agent cu modele de coordonare
- Stăpânirea rutării inteligente a modelelor pentru selecția bazată pe sarcini
- Implementarea soluțiilor AI locale cu arhitecturi care protejează confidențialitatea

### Zone de studiu

#### Sesiunea 01: Începerea cu Foundry Local
- **Concepte prioritare**:
  - Integrarea SDK FoundryLocalManager și descoperirea automată a serviciilor
  - Implementări de chat de bază și streaming
  - Modele de gestionare a erorilor și feedback pentru utilizatori
  - Configurare bazată pe mediu

#### Sesiunea 02: Construirea soluțiilor AI cu RAG
- **Concepte prioritare**:
  - Încorporări vectoriale în memorie cu sentence-transformers
  - Implementarea pipeline-ului RAG (recuperare → generare)
  - Evaluarea calității cu metrici RAGAS
  - Siguranța importurilor pentru dependențe opționale

#### Sesiunea 03: Modele open-source
- **Concepte prioritare**:
  - Strategii de benchmarking multi-model
  - Măsurători de latență și throughput
  - Degradare grațioasă și recuperare din erori
  - Compararea performanței între familiile de modele

#### Sesiunea 04: Modele de ultimă generație
- **Concepte prioritare**:
  - Metodologia de comparație SLM vs LLM
  - Hinturi de tip și formatarea cuprinzătoare a output-ului
  - Gestionarea erorilor per-model
  - Rezultate structurate pentru analiză

#### Sesiunea 05: Agenți alimentați de AI
- **Concepte prioritare**:
  - Orchestrarea multi-agent cu modelul de coordonare
  - Gestionarea memoriei agenților și urmărirea stării
  - Gestionarea erorilor în pipeline și jurnalizarea etapelor
  - Monitorizarea performanței și statistici

#### Sesiunea 06: Modele ca instrumente
- **Concepte prioritare**:
  - Detectarea intenției și potrivirea modelelor
  - Algoritmi de rutare a modelelor bazate pe cuvinte cheie
  - Pipeline-uri multi-pas (planificare → execuție → rafinare)
  - Documentație cuprinzătoare a funcțiilor

### Întrebări de autoevaluare

1. Cum simplifică FoundryLocalManager gestionarea serviciilor comparativ cu apelurile REST manuale?
2. Explică importanța protecțiilor pentru dependențele opționale, cum ar fi sentence-transformers.
3. Ce strategii asigură o degradare grațioasă în benchmarking-ul multi-model?
4. Cum orchestrează modelul de coordonare mai mulți agenți specializați?
5. Descrie componentele unui router inteligent de modele.
6. Care sunt elementele cheie ale gestionării erorilor pregătite pentru producție?

### Exerciții practice

1. **Aplicație de chat**: Implementarea unui chat streaming cu gestionarea erorilor (45 minute)
2. **Pipeline RAG**: Construirea unui RAG minimal cu evaluarea calității (1 oră)
3. **Benchmarking de modele**: Compararea a 3+ modele pe performanță (1 oră)
4. **Sistem multi-agent**: Crearea unui coordonator cu 2 agenți specializați (1.5 ore)
5. **Router inteligent**: Construirea selecției de modele bazate pe sarcini (1 oră)
6. **Implementare în producție**: Adăugarea monitorizării și gestionării cuprinzătoare a erorilor (45 minute)

### Alocarea timpului

**Învățare concentrată (1 săptămână)**:
- Ziua 1: Sesiunile 01-02 (Chat + RAG) - 3 ore
- Ziua 2: Sesiunile 03-04 (Benchmarking + Comparație) - 3 ore
- Ziua 3: Sesiunile 05-06 (Agenți + Rutare) - 3 ore
- Ziua 4: Exerciții practice și validare - 2 ore

**Studiu part-time (2 săptămâni)**:
- Săptămâna 1: Sesiunile 01-03 (6 ore total)
- Săptămâna 2: Sesiunile 04-06 + exerciții (5 ore total)

## Modulul 7: Exemple de implementare EdgeAI

### Obiective cheie de învățare

- Stăpânirea AI Toolkit pentru Visual Studio Code pentru fluxuri de lucru complete de dezvoltare EdgeAI
- Dobândirea de expertiză în platforma Windows AI Foundry și strategiile de optimizare NPU
- Implementarea EdgeAI pe mai multe platforme hardware și scenarii de implementare
- Construirea aplicațiilor EdgeAI pregătite pentru producție cu optimizări specifice platformei

### Zone de studiu

#### Secțiunea 1: AI Toolkit pentru Visual Studio Code
- **Concepte prioritare**: 
  - Mediu complet de dezvoltare Edge AI în cadrul VS Code
  - Catalogul de modele și descoperirea pentru implementarea la margine
  - Testare locală, optimizare și fluxuri de lucru pentru dezvoltarea agenților
  - Monitorizarea performanței și evaluarea pentru scenarii la margine

#### Secțiunea 2: Ghid de dezvoltare Windows EdgeAI
- **Concepte prioritare**: 
  - Prezentare generală a platformei Windows AI Foundry
  - API-ul Phi Silica pentru inferență eficientă NPU
  - API-uri de Computer Vision pentru procesarea imaginilor și OCR
  - CLI Foundry Local pentru dezvoltare și testare locală

#### Secțiunea 3: Implementări specifice platformei
- **Concepte prioritare**: 
  - Implementare NVIDIA Jetson Orin Nano (performanță AI de 67 TOP
4. Explicați rolul optimizării NPU în aplicațiile moderne de AI la margine.  
5. Cum utilizează API-ul Phi Silica hardware-ul NPU pentru optimizarea performanței?  
6. Comparați beneficiile implementării locale versus în cloud pentru aplicațiile sensibile la confidențialitate.  

### Exerciții practice  

1. **Configurarea AI Toolkit**: Configurați AI Toolkit și optimizați un model (1 oră)  
2. **Windows AI Foundry**: Creați o aplicație simplă Windows AI utilizând API-ul Phi Silica (1 oră)  
3. **Implementare pe platforme multiple**: Implementați același model pe două platforme diferite (1 oră)  
4. **Optimizare NPU**: Testați performanța NPU cu instrumentele Windows AI Foundry (30 minute)  

## Modulul 8: Microsoft Foundry Local – Kit complet pentru dezvoltatori (modernizat)  

### Obiective cheie de învățare  

- Instalați și configurați Foundry Local cu integrarea SDK modernă  
- Implementați sisteme avansate multi-agent cu modele de coordonare  
- Creați routere inteligente de modele cu selecție automată bazată pe sarcini  
- Implementați soluții AI pregătite pentru producție cu monitorizare cuprinzătoare  
- Integrați cu Azure AI Foundry pentru scenarii de implementare hibridă  
- Stăpâniți modelele SDK moderne cu FoundryLocalManager și clientul OpenAI  

### Zone de studiu  

#### Secțiunea 1: Instalare și configurare modernă  
- **Concepte prioritare**:  
  - Integrarea SDK FoundryLocalManager  
  - Descoperirea automată a serviciilor și monitorizarea sănătății  
  - Modele de configurare bazate pe mediu  
  - Considerații pentru implementarea în producție  

#### Secțiunea 2: Sisteme avansate multi-agent  
- **Concepte prioritare**:  
  - Modelul de coordonare cu agenți specializați  
  - Specializarea agenților pentru recuperare, raționament și execuție  
  - Mecanisme de buclă de feedback pentru rafinare  
  - Monitorizarea performanței și urmărirea statisticilor  

#### Secțiunea 3: Rutare inteligentă a modelelor  
- **Concepte prioritare**:  
  - Algoritmi de selecție a modelelor bazate pe cuvinte cheie  
  - Suport pentru modele multiple (general, raționament, cod, creativ)  
  - Configurarea variabilelor de mediu pentru flexibilitate  
  - Verificarea sănătății serviciilor și gestionarea erorilor  

#### Secțiunea 4: Implementare pregătită pentru producție  
- **Concepte prioritare**:  
  - Gestionarea cuprinzătoare a erorilor și mecanisme de rezervă  
  - Monitorizarea cererilor și urmărirea performanței  
  - Exemple interactive în Jupyter notebook cu benchmark-uri  
  - Modele de integrare cu aplicații existente  

### Întrebări de autoevaluare  

1. Cum diferă abordarea modernă FoundryLocalManager de apelurile REST manuale?  
2. Explicați modelul de coordonare și cum orchestrează agenții specializați.  
3. Cum selectează routerul inteligent modelele adecvate pe baza conținutului interogării?  
4. Care sunt componentele cheie ale unui sistem AI pregătit pentru producție?  
5. Cum implementați monitorizarea cuprinzătoare a sănătății pentru serviciile Foundry Local?  
6. Comparați beneficiile abordării modernizate față de modelele tradiționale de implementare.  

### Exerciții practice  

1. **Configurarea SDK modern**: Configurați FoundryLocalManager cu descoperirea automată a serviciilor (30 minute)  
2. **Sistem multi-agent**: Rulați coordonatorul avansat cu agenți specializați (30 minute)  
3. **Rutare inteligentă**: Testați routerul de modele cu diferite tipuri de interogări (30 minute)  
4. **Explorare interactivă**: Utilizați Jupyter notebooks pentru a explora funcționalități avansate (45 minute)  
5. **Implementare în producție**: Implementați modele de monitorizare și gestionare a erorilor (30 minute)  
6. **Integrare hibridă**: Configurați scenarii de rezervă Azure AI Foundry (30 minute)  

## Ghid de alocare a timpului  

Pentru a profita la maximum de cele 30 de ore extinse ale cursului (inclusiv atelierul), iată o sugestie de împărțire a timpului:  

| Activitate | Alocare de timp | Descriere |  
|------------|-----------------|-----------|  
| Citirea materialelor de bază | 12 ore | Concentrarea pe conceptele esențiale din fiecare modul |  
| Exerciții practice | 10 ore | Implementarea practică a tehnicilor cheie (inclusiv atelierul) |  
| Autoevaluare | 3 ore | Testarea înțelegerii prin întrebări și reflecție |  
| Mini-proiect | 5 ore | Aplicarea cunoștințelor într-o implementare practică mică |  

### Zone cheie de concentrare în funcție de constrângerile de timp  

**Dacă aveți doar 10 ore:**  
- Finalizați Modulul 0 (Introducere) și Modulele 1, 2 și 3 (concepte de bază EdgeAI)  
- Realizați cel puțin un exercițiu practic pe modul  
- Concentrați-vă pe înțelegerea conceptelor de bază, mai degrabă decât pe detalii de implementare  

**Dacă puteți dedica 20 de ore:**  
- Finalizați toate cele opt module (inclusiv Introducerea)  
- Realizați exerciții practice cheie din fiecare modul  
- Finalizați un mini-proiect din Modulul 7  
- Explorați cel puțin 2-3 resurse suplimentare  

**Dacă aveți mai mult de 20 de ore:**  
- Finalizați toate modulele (inclusiv Introducerea) cu exerciții detaliate  
- Construiți mai multe mini-proiecte  
- Explorați tehnici avansate de optimizare din Modulul 4  
- Implementați implementarea în producție din Modulul 5  

## Resurse esențiale  

Aceste resurse atent selectate oferă cea mai mare valoare pentru timpul dvs. limitat de studiu:  

### Documentație obligatorie  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Cel mai eficient instrument de optimizare a modelelor  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cea mai rapidă modalitate de a implementa SLM-uri local  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referință pentru un model optimizat pentru margine  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit complet de optimizare de la Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Mediu de dezvoltare EdgeAI integrat  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platformă de dezvoltare EdgeAI specifică Windows  

### Instrumente care economisesc timp  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acces rapid la modele și implementare  
- [Gradio](https://www.gradio.app/docs/interface) - Dezvoltare rapidă de UI pentru demonstrații AI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimizare simplificată a modelelor  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferență eficientă pe CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Cadru de compresie a rețelelor neuronale  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit de implementare pentru modele de limbaj mari  

## Șablon de urmărire a progresului  

Utilizați acest șablon simplificat pentru a urmări progresul dvs. de învățare prin cursul de 20 de ore:  

| Modul | Data finalizării | Ore petrecute | Concluzii cheie |  
|-------|------------------|---------------|-----------------|  
| Modulul 0: Introducere în EdgeAI | | | |  
| Modulul 1: Fundamentele EdgeAI | | | |  
| Modulul 2: Fundamentele SLM | | | |  
| Modulul 3: Implementarea SLM | | | |  
| Modulul 4: Optimizarea modelelor | | | |  
| Modulul 5: SLMOps | | | |  
| Modulul 6: Agenți AI | | | |  
| Modulul 7: Instrumente de dezvoltare | | | |  
| Atelier: Învățare practică | | | |  
| Modulul 8: Kitul Foundry Local | | | |  
| Exerciții practice | | | |  
| Mini-proiect | | | |  

## Idei de mini-proiecte  

Luați în considerare finalizarea unuia dintre aceste proiecte pentru a exersa conceptele EdgeAI (fiecare proiect este conceput să dureze 2-4 ore):  

### Proiecte pentru începători (2-3 ore fiecare)  
1. **Asistent text la margine**: Creați un instrument simplu de completare text offline utilizând un model de limbaj mic  
2. **Tablou de bord pentru comparația modelelor**: Construiți o vizualizare de bază a metricilor de performanță pentru diferite SLM-uri  
3. **Experiment de optimizare**: Măsurați impactul diferitelor niveluri de cuantizare asupra aceluiași model de bază  

### Proiecte intermediare (3-4 ore fiecare)  
4. **Flux de lucru AI Toolkit**: Utilizați AI Toolkit din VS Code pentru a optimiza și implementa un model de la început la sfârșit  
5. **Aplicație Windows AI Foundry**: Creați o aplicație Windows utilizând API-ul Phi Silica și optimizarea NPU  
6. **Implementare pe platforme multiple**: Implementați același model optimizat pe Windows (OpenVINO) și mobil (.NET MAUI)  
7. **Agent de apelare funcții**: Construiți un agent AI cu capacități de apelare funcții pentru scenarii la margine  

### Proiecte avansate de integrare (4-5 ore fiecare)  
8. **Pipeline de optimizare OpenVINO**: Implementați optimizarea completă a modelelor utilizând NNCF și GenAI toolkit  
9. **Pipeline SLMOps**: Implementați un ciclu complet de viață al modelului, de la antrenare la implementare la margine  
10. **Sistem multi-model la margine**: Implementați mai multe modele specializate care lucrează împreună pe hardware la margine  
11. **Sistem de integrare MCP**: Construiți un sistem agentic utilizând Model Context Protocol pentru interacțiunea cu instrumente  

## Referințe  

- Microsoft Learn (Foundry Local)  
  - Prezentare generală: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Începeți: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Referință CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrare cu SDK-uri de inferență: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Cum să deschideți WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Compilarea modelelor Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Prezentare generală: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agenți (prezentare generală): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Instrumente de optimizare și inferență  
  - Microsoft Olive (documentație): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (începeți): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Integrarea ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (documentație): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (documentație): https://ml-explore.github.io/mlx/build/html/index.html  
- Framework-uri de implementare și modele  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (documentație): https://docs.vllm.ai/  
  - Ollama (începeți rapid): https://github.com/ollama/ollama#get-started  
- Instrumente pentru dezvoltatori (Windows și VS Code)  
  - AI Toolkit pentru VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (prezentare generală): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Comunitatea de învățare  

Alăturați-vă discuțiilor și conectați-vă cu alți cursanți:  
- Discuții pe GitHub în [repository-ul EdgeAI pentru începători](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Concluzie  

EdgeAI reprezintă frontiera implementării inteligenței artificiale, aducând capabilități puternice direct pe dispozitive, în timp ce abordează preocupări critice legate de confidențialitate, latență și conectivitate. Acest curs de 20 de ore vă oferă cunoștințele esențiale și abilitățile practice pentru a începe să lucrați imediat cu tehnologiile EdgeAI.  

Cursul este deliberat concis și concentrat pe cele mai importante concepte, permițându-vă să dobândiți rapid expertiză valoroasă fără un angajament de timp copleșitor. Amintiți-vă că practica practică, chiar și cu exemple simple, este cheia consolidării a ceea ce ați învățat.  

Învățare plăcută!  

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim să asigurăm acuratețea, vă rugăm să fiți conștienți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa maternă ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.