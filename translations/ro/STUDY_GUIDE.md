<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-25T01:32:49+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru Începători: Căi de Învățare și Program de Studiu

### Cale de Învățare Intensivă (1 săptămână)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Ziua 1 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Ziua 2 | Modulul 2: Fundamentele SLM | 3 ore |
| Ziua 3 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 4-5 | Modulul 4: Optimizarea Modelului (6 cadre) | 4 ore |
| Ziua 6 | Modulul 5: SLMOps | 3 ore |
| Ziua 7 | Modulele 6-7: Agenți AI & Instrumente de Dezvoltare | 4 ore |
| Ziua 8 | Modulul 8: Foundry Local Toolkit (Implementare Modernă) | 1 oră |

### Cale de Învățare Intensivă (2 săptămâni)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Agenți AI | 2 ore |
| Zilele 13-14 | Modulul 7: Instrumente de Dezvoltare | 3 ore |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Fundamentele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Sisteme Agentice SLM | 2 ore |
| Zilele 13-14 | Modulul 7: Exemple de Implementare EdgeAI | 2 ore |

| Modul | Data Finalizării | Ore Petrecute | Concluzii Cheie |
|--------|----------------|-------------|--------------|
| Modulul 1: Fundamentele EdgeAI | | | |
| Modulul 2: Fundamentele SLM | | | |
| Modulul 3: Implementarea SLM | | | |
| Modulul 4: Optimizarea Modelului (6 cadre) | | | |
| Modulul 5: SLMOps | | | |
| Modulul 6: Sisteme Agentice SLM | | | |
| Modulul 7: Exemple de Implementare EdgeAI | | | |
| Exerciții Practice | | | |
| Mini-Proiect | | | |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Fundamentele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

## Introducere

Bine ați venit la ghidul de studiu EdgeAI pentru Începători! Acest document este conceput pentru a vă ajuta să navigați eficient prin materialele cursului și să maximizați experiența de învățare. Oferă căi de învățare structurate, programe de studiu sugerate, rezumate ale conceptelor cheie și resurse suplimentare pentru a aprofunda înțelegerea tehnologiilor EdgeAI.

Acesta este un curs concis de 20 de ore care oferă cunoștințe esențiale despre EdgeAI într-un format eficient din punct de vedere al timpului, fiind ideal pentru profesioniști ocupați și studenți care doresc să dobândească rapid abilități practice în acest domeniu emergent.

## Prezentare Generală a Cursului

Cursul este organizat în șapte module cuprinzătoare:

1. **Fundamentele și Transformarea EdgeAI** - Înțelegerea conceptelor de bază și a schimbării tehnologice
2. **Fundamentele Modelului de Limbaj Mic (SLM)** - Explorarea diferitelor familii SLM și a arhitecturilor acestora
3. **Implementarea Modelului de Limbaj Mic** - Strategii practice de implementare
4. **Conversia Formatului Modelului și Cuantizare** - Optimizare avansată cu 6 cadre, inclusiv OpenVINO
5. **SLMOps - Operațiuni pentru Modele de Limbaj Mic** - Managementul ciclului de viață al producției și implementării
6. **Sisteme Agentice SLM** - Agenți AI, apelarea funcțiilor și Protocolul Contextului Modelului
7. **Exemple de Implementare EdgeAI** - Instrumente AI, dezvoltare pe Windows și implementări specifice platformei
8. **Microsoft Foundry Local – Kit Complet pentru Dezvoltatori** - Dezvoltare locală cu integrare hibridă Azure (Modulul 08)

## Cum să Utilizați Acest Ghid de Studiu

- **Învățare Progresivă**: Urmați modulele în ordine pentru o experiență de învățare coerentă
- **Puncte de Verificare a Cunoștințelor**: Folosiți întrebările de autoevaluare după fiecare secțiune
- **Practica Practică**: Finalizați exercițiile sugerate pentru a consolida conceptele teoretice
- **Resurse Suplimentare**: Explorați materiale suplimentare pentru subiectele care vă interesează cel mai mult

## Recomandări pentru Programul de Studiu

### Cale de Învățare Intensivă (1 săptămână)

| Zi | Focus | Ore Estimative |
|------|-------|-----------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 6 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 8 ore |
| Ziua 5 | Modulul 3: Implementarea SLM | 3 ore |
| Ziua 6 | Modulul 8: Foundry Local Toolkit | 3 ore |

### Studiu Part-Time (3 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|-----------------|
| Săptămâna 1 | Modulul 1: Fundamentele EdgeAI | 6-7 ore |
| Săptămâna 2 | Modulul 2: Fundamentele SLM | 7-8 ore |
| Săptămâna 3 | Modulul 3: Implementarea SLM (3h) + Modulul 8: Foundry Local Toolkit (2-3h) | 5-6 ore |

## Modulul 1: Fundamentele și Transformarea EdgeAI

### Obiective Cheie de Învățare

- Înțelegeți diferențele dintre AI bazat pe cloud și AI bazat pe edge
- Stăpâniți tehnicile de optimizare de bază pentru medii cu resurse limitate
- Analizați aplicațiile reale ale tehnologiilor EdgeAI
- Configurați un mediu de dezvoltare pentru proiecte EdgeAI

### Zone de Focus pentru Studiu

#### Secțiunea 1: Fundamentele EdgeAI
- **Concepte Prioritare**: 
  - Paradigmele de calcul Edge vs. Cloud
  - Tehnici de cuantizare a modelului
  - Opțiuni de accelerare hardware (NPUs, GPUs, CPUs)
  - Avantajele privind confidențialitatea și securitatea

- **Materiale Suplimentare**:
  - [Documentația TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentația Edge Impulse](https://docs.edgeimpulse.com)

#### Secțiunea 2: Studii de Caz Reale
- **Concepte Prioritare**: 
  - Ecosistemul de modele Microsoft Phi & Mu
  - Implementări practice în diverse industrii
  - Considerații pentru implementare

#### Secțiunea 3: Ghid Practic de Implementare
- **Concepte Prioritare**: 
  - Configurarea mediului de dezvoltare
  - Instrumente de cuantizare și optimizare
  - Metode de evaluare pentru implementările EdgeAI

#### Secțiunea 4: Hardware pentru Implementare Edge
- **Concepte Prioritare**: 
  - Compararea platformelor hardware
  - Strategii de optimizare pentru hardware specific
  - Considerații pentru implementare

### Întrebări de Autoevaluare

1. Comparați și contrastați AI bazat pe cloud cu implementările AI bazate pe edge.
2. Explicați trei tehnici cheie pentru optimizarea modelelor pentru implementarea pe edge.
3. Care sunt principalele avantaje ale rulării modelelor AI pe edge?
4. Descrieți procesul de cuantizare a unui model și cum afectează performanța.
5. Explicați cum diferiți acceleratori hardware (NPUs, GPUs, CPUs) influențează implementarea EdgeAI.

### Exerciții Practice

1. **Configurare Rapidă a Mediului**: Configurați un mediu de dezvoltare minimal cu pachetele esențiale (30 minute)
2. **Explorarea Modelului**: Descărcați și examinați un model de limbaj mic pre-antrenat (1 oră)
3. **Cuantizare de Bază**: Încercați o cuantizare simplă pe un model mic (1 oră)

## Modulul 2: Fundamentele Modelului de Limbaj Mic

### Obiective Cheie de Învățare

- Înțelegeți principiile arhitecturale ale diferitelor familii SLM
- Comparați capacitățile modelelor pe diferite scale de parametri
- Evaluați modelele pe baza eficienței, capacității și cerințelor de implementare
- Recunoașteți cazurile de utilizare adecvate pentru diferite familii de modele

### Zone de Focus pentru Studiu

#### Secțiunea 1: Familia de Modele Microsoft Phi
- **Concepte Prioritare**: 
  - Evoluția filozofiei de design
  - Arhitectura orientată spre eficiență
  - Capacități specializate

#### Secțiunea 2: Familia Qwen
- **Concepte Prioritare**: 
  - Contribuții open source
  - Opțiuni scalabile de implementare
  - Arhitectură avansată de raționament

#### Secțiunea 3: Familia Gemma
- **Concepte Prioritare**: 
  - Inovație bazată pe cercetare
  - Capacități multimodale
  - Optimizare pentru mobil

#### Secțiunea 4: Familia BitNET
- **Concepte Prioritare**: 
  - Tehnologia de cuantizare 1-bit
  - Cadru de optimizare pentru inferență
  - Considerații privind sustenabilitatea

#### Secțiunea 5: Modelul Microsoft Mu
- **Concepte Prioritare**: 
  - Arhitectură orientată spre dispozitive
  - Integrarea sistemului cu Windows
  - Operare care protejează confidențialitatea

#### Secțiunea 6: Phi-Silica
- **Concepte Prioritare**: 
  - Arhitectură optimizată pentru NPU
  - Metrice de performanță
  - Integrarea pentru dezvoltatori

### Întrebări de Autoevaluare

1. Comparați abordările arhitecturale ale familiilor de modele Phi și Qwen.
2. Explicați cum tehnologia de cuantizare a BitNET diferă de cuantizarea tradițională.
3. Care sunt avantajele unice ale modelului Mu pentru integrarea cu Windows?
4. Descrieți cum Phi-Silica utilizează hardware-ul NPU pentru optimizarea performanței.
5. Pentru o aplicație mobilă cu conectivitate limitată, care familie de modele ar fi cea mai potrivită și de ce?

### Exerciții Practice

1. **Compararea Modelelor**: Benchmark rapid al două modele SLM diferite (1 oră)
2. **Generare Simplă de Text**: Implementare de bază a generării de text cu un model mic (1 oră)
3. **Optimizare Rapidă**: Aplicați o tehnică de optimizare pentru a îmbunătăți viteza de inferență (1 oră)

## Modulul 3: Implementarea Modelului de Limbaj Mic

### Obiective Cheie de Învățare

- Selectați modele adecvate pe baza constrângerilor de implementare
- Stăpâniți tehnicile de optimizare pentru diverse scenarii de implementare
- Implementați SLM-uri atât în medii locale, cât și în cloud
- Proiectați configurații pregătite pentru producție pentru aplicații EdgeAI

### Zone de Focus pentru Studiu

#### Secțiunea 1: Învățare Avansată SLM
- **Concepte Prioritare**: 
  - Cadru de clasificare a parametrilor
  - Tehnici avansate de optimizare
  - Strategii de achiziție a modelelor

#### Secțiunea 2: Implementare în Mediu Local
- **Concepte Prioritare**: 
  - Implementare pe platforma Ollama
  - Soluții locale Microsoft Foundry
  - Analiza comparativă a cadrelor

#### Secțiunea 3: Implementare în Cloud Containerizat
- **Concepte Prioritare**: 
  - Inferență performantă vLLM
  - Orchestrarea containerelor
  - Implementare ONNX Runtime

### Întrebări de Autoevaluare

1. Ce factori trebuie luați în considerare atunci când se selectează între implementarea locală și cea în cloud?
2. Comparați Ollama și Microsoft Foundry Local ca opțiuni de implementare.
3. Explicați beneficiile containerizării pentru implementarea SLM.
4. Care sunt principalele metrici de performanță de monitorizat pentru un SLM implementat pe edge?
5. Descrieți un flux complet de implementare, de la selecția modelului la implementarea în producție.

### Exerciții Practice

1. **Implementare Locală de Bază**: Implementați un SLM simplu folosind Ollama (1 oră)
2. **Verificare Performanță**: Rulați un benchmark rapid pe modelul implementat (30 minute)
3. **Integrare Simplă**: Creați o aplicație minimală care utilizează modelul implementat (1 oră)

## Modulul 4: Conversia Formatului Modelului și Cuantizare

### Obiective Cheie de Învățare

- Stăpâniți tehnici avansate de cuantizare de la precizie de 1-bit la 8-bit
- Înțelegeți strategiile de conversie a formatului (GGUF, ONNX)
- Implementați optimizarea în șase cadre (Llama.cpp, Olive, OpenVINO, MLX, sinteza fluxului de lucru)
- Implementați modele optimizate pentru medii de producție edge pe hardware Intel, Apple și hardware cross-platform

### Zone de Focus pentru Studiu

#### Secțiunea 1: Fundamentele Cuantizării
- **Concepte Prioritare**: 
  - Cadru de clasificare a preciziei
  - Compromisuri între performanță și acuratețe
  - Optimizarea amprentei de memorie

#### Secțiunea 2: Implementarea Llama.cpp
- **Concepte Prioritare**: 
  - Implementare cross-platform
  - Optimizarea formatului GGUF
  - Tehnici de accelerare hardware

#### Secțiunea 3: Suita Microsoft Olive
- **Concepte Prioritare**: 
  - Optimizare orientată pe hardware
  - Implementare de nivel enterprise
  - Fluxuri de lucru automate pentru optimizare

#### Secțiunea 4: Toolkit OpenVINO
- **Concepte Prioritare**: 
  - Optimizare pentru hardware Intel
  - Cadru de compresie a rețelelor neuronale (NNCF)
  - Implementare de inferență cross-platform
  - OpenVINO GenAI pentru implementarea LLM

#### Secțiunea 5: Framework-ul Apple MLX
- **Concepte prioritare**: 
  - Optimizarea pentru Apple Silicon
  - Arhitectura de memorie unificată
  - Capacități de fine-tuning LoRA

#### Secțiunea 6: Sinteza fluxului de lucru pentru dezvoltarea Edge AI
- **Concepte prioritare**: 
  - Arhitectura unificată a fluxului de lucru
  - Arborele decizional pentru selecția framework-urilor
  - Validarea pregătirii pentru producție
  - Strategii pentru viitor

### Întrebări de autoevaluare

1. Compară strategiile de cuantizare pentru diferite niveluri de precizie (1-bit la 8-bit).
2. Explică avantajele formatului GGUF pentru implementarea la margine.
3. Cum îmbunătățește optimizarea hardware-aware din Microsoft Olive eficiența implementării?
4. Care sunt beneficiile cheie ale NNCF din OpenVINO pentru comprimarea modelelor?
5. Descrie cum utilizează Apple MLX arhitectura de memorie unificată pentru optimizare.
6. Cum ajută sinteza fluxului de lucru în selecția framework-urilor optime de optimizare?

### Exerciții practice

1. **Cuantizarea modelului**: Aplică diferite niveluri de cuantizare unui model și compară rezultatele (1 oră)
2. **Optimizare OpenVINO**: Folosește NNCF pentru a comprima un model pentru hardware Intel (1 oră)
3. **Compararea framework-urilor**: Testează același model pe trei framework-uri diferite de optimizare (1 oră)
4. **Benchmarking de performanță**: Măsoară impactul optimizării asupra vitezei de inferență și utilizării memoriei (1 oră)

## Modulul 5: SLMOps - Operarea modelelor de limbaj mici

### Obiective cheie de învățare

- Înțelegerea principiilor de gestionare a ciclului de viață SLMOps
- Stăpânirea tehnicilor de distilare și fine-tuning pentru implementarea la margine
- Implementarea strategiilor de implementare în producție cu monitorizare
- Construirea fluxurilor de lucru pentru operarea și întreținerea SLM la nivel enterprise

### Zone de studiu

#### Secțiunea 1: Introducere în SLMOps
- **Concepte prioritare**: 
  - Schimbarea paradigmei SLMOps în operațiunile AI
  - Eficiență costuri și arhitectură orientată pe confidențialitate
  - Impact strategic asupra afacerilor și avantaje competitive

#### Secțiunea 2: Distilarea modelului
- **Concepte prioritare**: 
  - Tehnici de transfer de cunoștințe
  - Implementarea procesului de distilare în două etape
  - Fluxuri de lucru pentru distilare în Azure ML

#### Secțiunea 3: Strategii de fine-tuning
- **Concepte prioritare**: 
  - Fine-tuning eficient din punct de vedere al parametrilor (PEFT)
  - Metode avansate LoRA și QLoRA
  - Antrenament multi-adaptor și optimizarea hiperparametrilor

#### Secțiunea 4: Implementare în producție
- **Concepte prioritare**: 
  - Conversia și cuantizarea modelelor pentru producție
  - Configurarea implementării locale Foundry
  - Benchmarking de performanță și validarea calității

### Întrebări de autoevaluare

1. Cum diferă SLMOps de MLOps tradițional?
2. Explică beneficiile distilării modelelor pentru implementarea la margine.
3. Care sunt considerațiile cheie pentru fine-tuning-ul SLM-urilor în medii cu resurse limitate?
4. Descrie un flux complet de implementare în producție pentru aplicații AI la margine.

### Exerciții practice

1. **Distilare de bază**: Creează un model mai mic dintr-un model profesor mai mare (1 oră)
2. **Experiment de fine-tuning**: Fine-tunează un model pentru un domeniu specific (1 oră)
3. **Pipeline de implementare**: Configurează un pipeline CI/CD de bază pentru implementarea modelului (1 oră)

## Modulul 6: Sisteme agentice SLM - Agenți AI și apelarea funcțiilor

### Obiective cheie de învățare

- Construirea agenților AI inteligenți pentru medii la margine folosind modele de limbaj mici
- Implementarea capacităților de apelare a funcțiilor cu fluxuri de lucru sistematice
- Stăpânirea integrării Model Context Protocol (MCP) pentru interacțiunea standardizată cu instrumentele
- Crearea sistemelor agentice sofisticate cu intervenție umană minimă

### Zone de studiu

#### Secțiunea 1: Agenți AI și fundamentele SLM
- **Concepte prioritare**: 
  - Cadru de clasificare a agenților (reflex, bazat pe model, bazat pe obiective, agenți de învățare)
  - Analiza compromisurilor SLM vs LLM
  - Modele de design pentru agenți specifici marginii
  - Optimizarea resurselor pentru agenți

#### Secțiunea 2: Apelarea funcțiilor în modele de limbaj mici
- **Concepte prioritare**: 
  - Implementarea fluxurilor de lucru sistematice (detectarea intenției, output JSON, execuție externă)
  - Implementări specifice platformei (Phi-4-mini, modele Qwen selectate, Microsoft Foundry Local)
  - Exemple avansate (colaborare multi-agent, selecție dinamică de instrumente)
  - Considerații pentru producție (limitarea ratei, jurnalizare audit, măsuri de securitate)

#### Secțiunea 3: Integrarea Model Context Protocol (MCP)
- **Concepte prioritare**: 
  - Arhitectura protocolului și designul sistemului stratificat
  - Suport multi-backend (Ollama pentru dezvoltare, vLLM pentru producție)
  - Protocoale de conexiune (moduri STDIO și SSE)
  - Aplicații reale (automatizare web, procesare de date, integrare API)

### Întrebări de autoevaluare

1. Care sunt considerațiile arhitecturale cheie pentru agenții AI la margine?
2. Cum îmbunătățește apelarea funcțiilor capacitățile agenților?
3. Explică rolul Model Context Protocol în comunicarea agenților.

### Exerciții practice

1. **Agent simplu**: Construiește un agent AI de bază cu apelarea funcțiilor (1 oră)
2. **Integrarea MCP**: Implementează MCP într-o aplicație de agent (30 minute)

## Modulul 7: Exemple de implementare EdgeAI

### Obiective cheie de învățare

- Stăpânirea AI Toolkit pentru Visual Studio Code pentru fluxuri de lucru complete de dezvoltare EdgeAI
- Dobândirea expertizei în platforma Windows AI Foundry și strategiile de optimizare NPU
- Implementarea EdgeAI pe mai multe platforme hardware și scenarii de implementare
- Construirea aplicațiilor EdgeAI pregătite pentru producție cu optimizări specifice platformei

### Zone de studiu

#### Secțiunea 1: AI Toolkit pentru Visual Studio Code
- **Concepte prioritare**: 
  - Mediu complet de dezvoltare Edge AI în cadrul VS Code
  - Catalogul de modele și descoperirea pentru implementarea la margine
  - Testare locală, optimizare și fluxuri de lucru pentru dezvoltarea agenților
  - Monitorizarea performanței și evaluarea pentru scenarii la margine

#### Secțiunea 2: Ghid de dezvoltare Windows EdgeAI
- **Concepte prioritare**: 
  - Prezentare generală a platformei Windows AI Foundry
  - API-ul Phi Silica pentru inferență eficientă pe NPU
  - API-uri de Computer Vision pentru procesarea imaginilor și OCR
  - CLI-ul Foundry Local pentru dezvoltare și testare locală

#### Secțiunea 3: Implementări specifice platformei
- **Concepte prioritare**: 
  - Implementarea pe NVIDIA Jetson Orin Nano (performanță AI de 67 TOPS)
  - Aplicații mobile cu .NET MAUI și ONNX Runtime GenAI
  - Soluții Azure EdgeAI cu arhitectură hibridă cloud-margine
  - Optimizarea Windows ML cu suport hardware universal
  - Aplicații Foundry Local cu implementare RAG orientată pe confidențialitate

### Întrebări de autoevaluare

1. Cum simplifică AI Toolkit fluxul de lucru pentru dezvoltarea EdgeAI?
2. Compară strategiile de implementare pe diferite platforme hardware.
3. Care sunt avantajele Windows AI Foundry pentru dezvoltarea la margine?
4. Explică rolul optimizării NPU în aplicațiile moderne Edge AI.
5. Cum utilizează API-ul Phi Silica hardware-ul NPU pentru optimizarea performanței?
6. Compară beneficiile implementării locale vs. în cloud pentru aplicațiile sensibile la confidențialitate.

### Exerciții practice

1. **Configurarea AI Toolkit**: Configurează AI Toolkit și optimizează un model (1 oră)
2. **Windows AI Foundry**: Construiește o aplicație Windows AI simplă folosind API-ul Phi Silica (1 oră)
3. **Implementare cross-platform**: Implementează același model pe două platforme diferite (1 oră)
4. **Optimizare NPU**: Testează performanța NPU cu instrumentele Windows AI Foundry (30 minute)

## Modulul 8: Microsoft Foundry Local – Toolkit complet pentru dezvoltatori (modernizat)

### Obiective cheie de învățare

- Instalează și configurează Foundry Local cu integrarea SDK modernă
- Implementează sisteme multi-agent avansate cu modele de coordonare
- Construiește routere inteligente de modele cu selecție automată bazată pe sarcini
- Implementează soluții AI pregătite pentru producție cu monitorizare completă
- Integrează cu Azure AI Foundry pentru scenarii de implementare hibride
- Stăpânește modelele SDK moderne cu FoundryLocalManager și clientul OpenAI

### Zone de studiu

#### Secțiunea 1: Instalare și configurare modernă
- **Concepte prioritare**: 
  - Integrarea SDK FoundryLocalManager
  - Descoperirea automată a serviciilor și monitorizarea sănătății
  - Modele de configurare bazate pe mediu
  - Considerații pentru implementarea în producție

#### Secțiunea 2: Sisteme multi-agent avansate
- **Concepte prioritare**: 
  - Modelul de coordonare cu agenți specializați
  - Specializarea agenților pentru recuperare, raționament și execuție
  - Mecanisme de buclă de feedback pentru rafinare
  - Monitorizarea performanței și urmărirea statisticilor

#### Secțiunea 3: Rutare inteligentă a modelelor
- **Concepte prioritare**: 
  - Algoritmi de selecție a modelelor bazate pe cuvinte cheie
  - Suport pentru modele multiple (general, raționament, cod, creativ)
  - Configurarea variabilelor de mediu pentru flexibilitate
  - Verificarea sănătății serviciilor și gestionarea erorilor

#### Secțiunea 4: Implementare pregătită pentru producție
- **Concepte prioritare**: 
  - Gestionarea completă a erorilor și mecanisme de fallback
  - Monitorizarea cererilor și urmărirea performanței
  - Exemple interactive în Jupyter notebook cu benchmark-uri
  - Modele de integrare cu aplicații existente

### Întrebări de autoevaluare

1. Cum diferă abordarea modernă FoundryLocalManager de apelurile REST manuale?
2. Explică modelul de coordonare și cum orchestrează agenții specializați.
3. Cum selectează routerul inteligent modelele adecvate pe baza conținutului interogării?
4. Care sunt componentele cheie ale unui sistem de agenți AI pregătit pentru producție?
5. Cum implementezi monitorizarea completă a sănătății pentru serviciile Foundry Local?
6. Compară beneficiile abordării modernizate vs. modele tradiționale de implementare.

### Exerciții practice

1. **Configurarea SDK modern**: Configurează FoundryLocalManager cu descoperirea automată a serviciilor (30 minute)
2. **Sistem multi-agent**: Rulează coordonatorul avansat cu agenți specializați (30 minute)
3. **Rutare inteligentă**: Testează routerul de modele cu diferite tipuri de interogări (30 minute)
4. **Explorare interactivă**: Folosește Jupyter notebooks pentru a explora funcționalități avansate (45 minute)
5. **Implementare în producție**: Implementează modele de monitorizare și gestionare a erorilor (30 minute)
6. **Integrare hibridă**: Configurează scenarii de fallback pentru Azure AI Foundry (30 minute)

## Ghid de alocare a timpului

Pentru a profita la maximum de cele 20 de ore ale cursului, iată o sugestie de împărțire a timpului:

| Activitate | Alocare de timp | Descriere |
|------------|-----------------|-----------|
| Citirea materialelor de bază | 9 ore | Concentrare pe conceptele esențiale din fiecare modul |
| Exerciții practice | 6 ore | Implementarea practică a tehnicilor cheie |
| Autoevaluare | 2 ore | Testarea înțelegerii prin întrebări și reflecție |
| Mini-proiect | 3 ore | Aplicarea cunoștințelor într-o implementare practică mică |

### Zone cheie de focus în funcție de constrângerile de timp

**Dacă ai doar 10 ore:**
- Completează modulele 1, 2 și 3 (concepte de bază EdgeAI)
- Realizează cel puțin un exercițiu practic pe modul
- Concentrează-te pe înțelegerea conceptelor de bază, mai degrabă decât pe detalii de implementare

**Dacă poți dedica toate cele 20 de ore:**
- Completează toate cele șapte module
- Realizează exercițiile practice cheie din fiecare modul
- Finalizează un mini-proiect din Modulul 7
- Explorează cel puțin 2-3 resurse suplimentare

**Dacă ai mai mult de 20 de ore:**
- Completează toate modulele cu exerciții detaliate
- Construiește mai multe mini-proiecte
- Explorează tehnici avansate de optimizare din Modulul 4
- Implementează implementarea în producție din Modulul 5

## Resurse esențiale

Aceste resurse atent selectate oferă cea mai mare valoare pentru timpul tău limitat de studiu:

### Documentație obligatorie
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Cel mai eficient instrument de optimizare a modelelor
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cea mai rapidă metodă de a implementa SLM-uri local
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referință pentru un model optimizat pentru margine
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit-ul complet de optimizare Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Mediu integrat de dezvoltare EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platforma de dezvoltare EdgeAI specifică Windows

### Instrumente care economisesc timp
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acces rapid la modele și implementare
- [Gradio](https://www.gradio.app/docs/interface) - Dezvoltare rapidă de UI pentru demonstrații AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimizare simplificată a modelelor
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferență eficientă pe CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework pentru comprimarea rețelelor neuronale
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit pentru implementarea modelelor de limbaj mari

## Șablon de urmărire a progresului

Folosește acest șablon simplificat pentru a urmări progresul în cadrul cursului de 20 de ore:

| Modul | Data finalizării | Ore petrecute | Concluzii cheie |
|-------|------------------|---------------|-----------------|
| Modulul 1: Fundamente EdgeAI | | | |
| Modulul 2: Fundamente SLM | | | |
| Modulul 3: Implementarea SLM | | | |
| Modulul 4: Optimizarea modelelor | | | |
| Modulul 5: SLMOps | | | |
| Modulul 6: Agenți AI | | | |
| Modulul 7: Instrumente de dezvoltare | | | |
| Modulul 8: Toolkit Foundry Local | | | |
| Exerciții practice | | | |
| Mini-Proiect | | | |

## Idei de Mini-Proiecte

Luați în considerare realizarea unuia dintre aceste proiecte pentru a exersa conceptele EdgeAI (fiecare proiect este conceput să dureze 2-4 ore):

### Proiecte pentru Începători (2-3 ore fiecare)
1. **Asistent Text Edge**: Creați un instrument simplu de completare text offline folosind un model lingvistic mic
2. **Tablou de Bord pentru Compararea Modelului**: Construiți o vizualizare de bază a metricilor de performanță pentru diferite SLM-uri
3. **Experiment de Optimizare**: Măsurați impactul diferitelor niveluri de cuantizare asupra aceluiași model de bază

### Proiecte Intermediare (3-4 ore fiecare)
4. **Flux de Lucru AI Toolkit**: Utilizați VS Code AI Toolkit pentru a optimiza și implementa un model de la început până la sfârșit
5. **Aplicație Windows AI Foundry**: Creați o aplicație Windows folosind API-ul Phi Silica și optimizarea NPU
6. **Implementare Cross-Platform**: Implementați același model optimizat pe Windows (OpenVINO) și mobil (.NET MAUI)
7. **Agent de Apelare Funcții**: Construiți un agent AI cu capacități de apelare funcții pentru scenarii edge

### Proiecte de Integrare Avansată (4-5 ore fiecare)
8. **Pipeline de Optimizare OpenVINO**: Implementați optimizarea completă a modelului folosind NNCF și GenAI toolkit
9. **Pipeline SLMOps**: Implementați un ciclu complet de viață al modelului, de la antrenare la implementare edge
10. **Sistem Edge Multi-Model**: Implementați mai multe modele specializate care lucrează împreună pe hardware edge
11. **Sistem de Integrare MCP**: Construiți un sistem agentic folosind Model Context Protocol pentru interacțiunea cu instrumente

## Referințe

- Microsoft Learn (Foundry Local)
  - Prezentare generală: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Începeți: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referință CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrare cu SDK-uri de inferență: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Cum să deschideți WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compilare modele Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Prezentare generală: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agenți (prezentare generală): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Instrumente de Optimizare și Inferență
  - Microsoft Olive (documentație): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (începeți): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integrare ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (documentație): https://docs.openvino.ai/2025/index.html
  - Apple MLX (documentație): https://ml-explore.github.io/mlx/build/html/index.html
- Framework-uri de Implementare și Modele
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (documentație): https://docs.vllm.ai/
  - Ollama (începeți rapid): https://github.com/ollama/ollama#get-started
- Instrumente pentru Dezvoltatori (Windows și VS Code)
  - AI Toolkit pentru VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (prezentare generală): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Comunitatea de Învățare

Alăturați-vă discuțiilor și conectați-vă cu alți cursanți:
- Discuții pe GitHub în [repository-ul EdgeAI pentru Începători](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Concluzie

EdgeAI reprezintă frontiera implementării inteligenței artificiale, aducând capabilități puternice direct pe dispozitive, în timp ce abordează preocupări critice legate de confidențialitate, latență și conectivitate. Acest curs de 20 de ore vă oferă cunoștințele esențiale și abilitățile practice pentru a începe să lucrați cu tehnologiile EdgeAI imediat.

Cursul este conceput să fie concis și concentrat pe cele mai importante concepte, permițându-vă să dobândiți rapid expertiză valoroasă fără un angajament de timp copleșitor. Amintiți-vă că practica practică, chiar și cu exemple simple, este cheia consolidării a ceea ce ați învățat.

Învățare plăcută!

---

