<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-18T18:05:57+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru Începători: Căi de Învățare și Program de Studiu

### Cale de Învățare Concentrată (1 săptămână)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Ziua 1 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Ziua 2 | Modulul 2: Fundamentele SLM | 3 ore |
| Ziua 3 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 4-5 | Modulul 4: Optimizarea Modelului (6 cadre) | 4 ore |
| Ziua 6 | Modulul 5: SLMOps | 3 ore |
| Ziua 7 | Modulele 6-7: Agenți AI & Instrumente de Dezvoltare | 5 ore |

### Cale de Învățare Concentrată (2 săptămâni)

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Agenți AI | 2 ore |
| Zilele 13-14 | Modulul 7: Instrumente de Dezvoltare | 3 ore |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Fundamentele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

| Zi | Focus | Ore Estimative |
|------|-------|------------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 3 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 3 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 2 ore |
| Zilele 7-8 | Modulul 4: Optimizarea Modelului | 4 ore |
| Zilele 9-10 | Modulul 5: SLMOps | 3 ore |
| Zilele 11-12 | Modulul 6: Sisteme Agentice SLM | 2 ore |
| Zilele 13-14 | Modulul 7: Exemple de Implementare EdgeAI | 2 ore |

| Modul | Data Finalizării | Ore Petrecute | Concluzii Cheie |
|--------|----------------|-------------|--------------|
| Modulul 1: Fundamentele EdgeAI | | | |
| Modulul 2: Fundamentele SLM | | | |
| Modulul 3: Implementarea SLM | | | |
| Modulul 4: Optimizarea Modelului (6 cadre) | | | |
| Modulul 5: SLMOps | | | |
| Modulul 6: Sisteme Agentice SLM | | | |
| Modulul 7: Exemple de Implementare EdgeAI | | | |
| Exerciții Practice | | | |
| Mini-Proiect | | | |

### Studiu Part-Time (4 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|------------------|
| Săptămâna 1 | Modulele 1-2: Fundamente & Fundamentele SLM | 6 ore |
| Săptămâna 2 | Modulele 3-4: Implementare & Optimizare | 6 ore |
| Săptămâna 3 | Modulele 5-6: SLMOps & Agenți AI | 5 ore |
| Săptămâna 4 | Modulul 7: Instrumente de Dezvoltare & Integrare | 3 ore |

## Introducere

Bine ați venit la ghidul de studiu EdgeAI pentru Începători! Acest document este conceput pentru a vă ajuta să navigați eficient prin materialele cursului și să maximizați experiența de învățare. Oferă căi de învățare structurate, programe de studiu sugerate, rezumate ale conceptelor cheie și resurse suplimentare pentru a aprofunda înțelegerea tehnologiilor EdgeAI.

Acesta este un curs concis de 20 de ore care oferă cunoștințe esențiale despre EdgeAI într-un format eficient din punct de vedere al timpului, fiind perfect pentru profesioniști ocupați și studenți care doresc să dobândească rapid abilități practice în acest domeniu emergent.

## Prezentare Generală a Cursului

Cursul este organizat în șapte module cuprinzătoare:

1. **Fundamentele și Transformarea EdgeAI** - Înțelegerea conceptelor de bază și a schimbării tehnologice
2. **Fundamentele Modelului de Limbaj Mic (SLM)** - Explorarea diferitelor familii SLM și a arhitecturilor acestora
3. **Implementarea Modelului de Limbaj Mic** - Strategii practice de implementare
4. **Conversia Formatului Modelului și Cuantizarea** - Optimizare avansată cu 6 cadre, inclusiv OpenVINO
5. **SLMOps - Operațiuni pentru Modele de Limbaj Mic** - Managementul ciclului de viață și implementarea în producție
6. **Sisteme Agentice SLM** - Agenți AI, apelarea funcțiilor și Protocolul Contextului Modelului
7. **Exemple de Implementare EdgeAI** - Instrumente AI, dezvoltare pe Windows și implementări specifice platformei

## Cum să Utilizați Acest Ghid de Studiu

- **Învățare Progresivă**: Urmați modulele în ordine pentru o experiență de învățare coerentă
- **Puncte de Verificare a Cunoștințelor**: Utilizați întrebările de autoevaluare după fiecare secțiune
- **Practica Practică**: Finalizați exercițiile sugerate pentru a consolida conceptele teoretice
- **Resurse Suplimentare**: Explorați materiale suplimentare pentru subiectele care vă interesează cel mai mult

## Recomandări pentru Programul de Studiu

### Cale de Învățare Concentrată (1 săptămână)

| Zi | Focus | Ore Estimative |
|------|-------|-----------------|
| Zilele 1-2 | Modulul 1: Fundamentele EdgeAI | 6 ore |
| Zilele 3-4 | Modulul 2: Fundamentele SLM | 8 ore |
| Zilele 5-6 | Modulul 3: Implementarea SLM | 6 ore |

### Studiu Part-Time (3 săptămâni)

| Săptămână | Focus | Ore Estimative |
|------|-------|-----------------|
| Săptămâna 1 | Modulul 1: Fundamentele EdgeAI | 6-7 ore |
| Săptămâna 2 | Modulul 2: Fundamentele SLM | 7-8 ore |
| Săptămâna 3 | Modulul 3: Implementarea SLM | 5-6 ore |

## Modulul 1: Fundamentele și Transformarea EdgeAI

### Obiective Cheie de Învățare

- Înțelegerea diferențelor dintre AI bazat pe cloud și AI bazat pe edge
- Stăpânirea tehnicilor de optimizare de bază pentru medii cu resurse limitate
- Analiza aplicațiilor reale ale tehnologiilor EdgeAI
- Configurarea unui mediu de dezvoltare pentru proiecte EdgeAI

### Zone de Focus pentru Studiu

#### Secțiunea 1: Fundamentele EdgeAI
- **Concepte Prioritare**: 
  - Paradigmele de calcul Edge vs. Cloud
  - Tehnici de cuantizare a modelului
  - Opțiuni de accelerare hardware (NPU-uri, GPU-uri, CPU-uri)
  - Avantajele privind confidențialitatea și securitatea

- **Materiale Suplimentare**:
  - [Documentația TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentația Edge Impulse](https://docs.edgeimpulse.com)

#### Secțiunea 2: Studii de Caz Reale
- **Concepte Prioritare**: 
  - Ecosistemul de modele Microsoft Phi & Mu
  - Implementări practice în diverse industrii
  - Considerații privind implementarea

#### Secțiunea 3: Ghid Practic de Implementare
- **Concepte Prioritare**: 
  - Configurarea mediului de dezvoltare
  - Instrumente de cuantizare și optimizare
  - Metode de evaluare pentru implementările EdgeAI

#### Secțiunea 4: Hardware pentru Implementare Edge
- **Concepte Prioritare**: 
  - Compararea platformelor hardware
  - Strategii de optimizare pentru hardware specific
  - Considerații privind implementarea

### Întrebări de Autoevaluare

1. Comparați și contrastați AI bazat pe cloud cu implementările AI bazate pe edge.
2. Explicați trei tehnici cheie pentru optimizarea modelelor pentru implementarea pe edge.
3. Care sunt principalele avantaje ale rulării modelelor AI pe edge?
4. Descrieți procesul de cuantizare a unui model și cum afectează performanța.
5. Explicați cum diferiți acceleratori hardware (NPU-uri, GPU-uri, CPU-uri) influențează implementarea EdgeAI.

### Exerciții Practice

1. **Configurare Rapidă a Mediului**: Configurați un mediu de dezvoltare minimal cu pachetele esențiale (30 minute)
2. **Explorarea Modelului**: Descărcați și examinați un model de limbaj mic pre-antrenat (1 oră)
3. **Cuantizare de Bază**: Încercați o cuantizare simplă pe un model mic (1 oră)
- Arborele decizional pentru selecția framework-urilor  
- Validarea pregătirii pentru producție  
- Strategii pentru asigurarea viabilității pe termen lung  

### Întrebări de autoevaluare  

1. Compară strategiile de cuantizare la diferite niveluri de precizie (1-bit până la 8-bit).  
2. Explică avantajele formatului GGUF pentru implementarea la margine.  
3. Cum îmbunătățește optimizarea hardware-aware din Microsoft Olive eficiența implementării?  
4. Care sunt beneficiile principale ale NNCF din OpenVINO pentru comprimarea modelelor?  
5. Descrie cum Apple MLX utilizează arhitectura de memorie unificată pentru optimizare.  
6. Cum ajută sinteza fluxului de lucru în selectarea framework-urilor optime de optimizare?  

### Exerciții practice  

1. **Cuantizarea modelului**: Aplică diferite niveluri de cuantizare unui model și compară rezultatele (1 oră)  
2. **Optimizare OpenVINO**: Utilizează NNCF pentru a comprima un model destinat hardware-ului Intel (1 oră)  
3. **Compararea framework-urilor**: Testează același model pe trei framework-uri diferite de optimizare (1 oră)  
4. **Benchmarking performanță**: Măsoară impactul optimizării asupra vitezei de inferență și utilizării memoriei (1 oră)  

## Modulul 5: SLMOps - Operarea modelelor lingvistice mici  

### Obiective principale de învățare  

- Înțelegerea principiilor de gestionare a ciclului de viață SLMOps  
- Stăpânirea tehnicilor de distilare și fine-tuning pentru implementarea la margine  
- Implementarea strategiilor de implementare în producție cu monitorizare  
- Construirea fluxurilor de lucru pentru operarea și întreținerea modelelor lingvistice la nivel enterprise  

### Zone de studiu  

#### Secțiunea 1: Introducere în SLMOps  
- **Concepte prioritare**:  
  - Schimbarea paradigmei SLMOps în operațiunile AI  
  - Eficiența costurilor și arhitectura orientată spre confidențialitate  
  - Impact strategic asupra afacerilor și avantaje competitive  

#### Secțiunea 2: Distilarea modelului  
- **Concepte prioritare**:  
  - Tehnici de transfer de cunoștințe  
  - Implementarea procesului de distilare în două etape  
  - Fluxuri de lucru pentru distilare în Azure ML  

#### Secțiunea 3: Strategii de fine-tuning  
- **Concepte prioritare**:  
  - Fine-tuning eficient din punct de vedere al parametrilor (PEFT)  
  - Metode avansate LoRA și QLoRA  
  - Antrenament multi-adaptor și optimizarea hiperparametrilor  

#### Secțiunea 4: Implementare în producție  
- **Concepte prioritare**:  
  - Conversia și cuantizarea modelelor pentru producție  
  - Configurarea implementării locale Foundry  
  - Benchmarking performanță și validarea calității  

### Întrebări de autoevaluare  

1. Cum diferă SLMOps de MLOps tradițional?  
2. Explică beneficiile distilării modelelor pentru implementarea la margine.  
3. Care sunt considerațiile cheie pentru fine-tuning-ul modelelor lingvistice mici în medii cu resurse limitate?  
4. Descrie un flux complet de implementare în producție pentru aplicații AI la margine.  

### Exerciții practice  

1. **Distilare de bază**: Creează un model mai mic dintr-un model profesor mai mare (1 oră)  
2. **Experiment de fine-tuning**: Ajustează un model pentru un domeniu specific (1 oră)  
3. **Pipeline de implementare**: Configurează un pipeline CI/CD de bază pentru implementarea modelului (1 oră)  

## Modulul 6: Sisteme agentice SLM - Agenți AI și apelarea funcțiilor  

### Obiective principale de învățare  

- Construirea agenților AI inteligenți pentru medii la margine utilizând modele lingvistice mici  
- Implementarea capacităților de apelare a funcțiilor cu fluxuri de lucru sistematice  
- Stăpânirea integrării Model Context Protocol (MCP) pentru interacțiunea standardizată cu instrumentele  
- Crearea sistemelor agentice sofisticate cu intervenție umană minimă  

### Zone de studiu  

#### Secțiunea 1: Agenți AI și fundamentele SLM  
- **Concepte prioritare**:  
  - Cadru de clasificare a agenților (reflex, bazat pe model, bazat pe obiective, agenți de învățare)  
  - Analiza compromisurilor SLM vs LLM  
  - Modele de design specifice marginii pentru agenți  
  - Optimizarea resurselor pentru agenți  

#### Secțiunea 2: Apelarea funcțiilor în modele lingvistice mici  
- **Concepte prioritare**:  
  - Implementarea fluxurilor de lucru sistematice (detectarea intenției, output JSON, execuție externă)  
  - Implementări specifice platformei (Phi-4-mini, modele Qwen selectate, Microsoft Foundry Local)  
  - Exemple avansate (colaborare multi-agent, selecție dinamică de instrumente)  
  - Considerații pentru producție (limitarea ratei, jurnalizare audit, măsuri de securitate)  

#### Secțiunea 3: Integrarea Model Context Protocol (MCP)  
- **Concepte prioritare**:  
  - Arhitectura protocolului și designul sistemului stratificat  
  - Suport multi-backend (Ollama pentru dezvoltare, vLLM pentru producție)  
  - Protocoale de conexiune (moduri STDIO și SSE)  
  - Aplicații reale (automatizare web, procesare de date, integrare API)  

### Întrebări de autoevaluare  

1. Care sunt considerațiile arhitecturale cheie pentru agenții AI la margine?  
2. Cum îmbunătățește apelarea funcțiilor capacitățile agenților?  
3. Explică rolul Model Context Protocol în comunicarea agenților.  

### Exerciții practice  

1. **Agent simplu**: Construiește un agent AI de bază cu apelarea funcțiilor (1 oră)  
2. **Integrarea MCP**: Implementează MCP într-o aplicație de agent (30 minute)  

## Modulul 7: Exemple de implementare EdgeAI  

### Obiective principale de învățare  

- Stăpânirea AI Toolkit pentru Visual Studio Code pentru fluxuri de lucru complete de dezvoltare EdgeAI  
- Dobândirea expertizei în platforma Windows AI Foundry și strategiile de optimizare NPU  
- Implementarea EdgeAI pe mai multe platforme hardware și scenarii de implementare  
- Construirea aplicațiilor EdgeAI pregătite pentru producție cu optimizări specifice platformei  

### Zone de studiu  

#### Secțiunea 1: AI Toolkit pentru Visual Studio Code  
- **Concepte prioritare**:  
  - Mediu complet de dezvoltare Edge AI în cadrul VS Code  
  - Catalog de modele și descoperire pentru implementarea la margine  
  - Testare locală, optimizare și fluxuri de lucru pentru dezvoltarea agenților  
  - Monitorizarea performanței și evaluarea pentru scenarii la margine  

#### Secțiunea 2: Ghid de dezvoltare Windows EdgeAI  
- **Concepte prioritare**:  
  - Prezentare generală a platformei Windows AI Foundry  
  - API-ul Phi Silica pentru inferență eficientă pe NPU  
  - API-uri de Computer Vision pentru procesarea imaginilor și OCR  
  - CLI Foundry Local pentru dezvoltare și testare locală  

#### Secțiunea 3: Implementări specifice platformei  
- **Concepte prioritare**:  
  - Implementare NVIDIA Jetson Orin Nano (performanță AI de 67 TOPS)  
  - Aplicații mobile cu .NET MAUI și ONNX Runtime GenAI  
  - Soluții Azure EdgeAI cu arhitectură hibridă cloud-margine  
  - Optimizare Windows ML cu suport hardware universal  
  - Aplicații Foundry Local cu implementare RAG orientată spre confidențialitate  

### Întrebări de autoevaluare  

1. Cum simplifică AI Toolkit fluxul de lucru de dezvoltare EdgeAI?  
2. Compară strategiile de implementare pe diferite platforme hardware.  
3. Care sunt avantajele Windows AI Foundry pentru dezvoltarea la margine?  
4. Explică rolul optimizării NPU în aplicațiile moderne Edge AI.  
5. Cum utilizează API-ul Phi Silica hardware-ul NPU pentru optimizarea performanței?  
6. Compară beneficiile implementării locale vs. în cloud pentru aplicațiile sensibile la confidențialitate.  

### Exerciții practice  

1. **Configurare AI Toolkit**: Configurează AI Toolkit și optimizează un model (1 oră)  
2. **Windows AI Foundry**: Construiește o aplicație Windows AI simplă utilizând API-ul Phi Silica (1 oră)  
3. **Implementare cross-platform**: Implementează același model pe două platforme diferite (1 oră)  
4. **Optimizare NPU**: Testează performanța NPU cu instrumentele Windows AI Foundry (30 minute)  

## Ghid de alocare a timpului  

Pentru a profita la maximum de cele 20 de ore ale cursului, iată o sugestie de împărțire a timpului:  

| Activitate | Alocare de timp | Descriere |  
|------------|-----------------|-----------|  
| Citirea materialelor de bază | 9 ore | Concentrarea pe conceptele esențiale din fiecare modul |  
| Exerciții practice | 6 ore | Implementarea practică a tehnicilor cheie |  
| Autoevaluare | 2 ore | Testarea înțelegerii prin întrebări și reflecție |  
| Mini-proiect | 3 ore | Aplicarea cunoștințelor într-o implementare practică mică |  

### Zone de focus în funcție de constrângerile de timp  

**Dacă ai doar 10 ore:**  
- Completează modulele 1, 2 și 3 (concepte de bază EdgeAI)  
- Realizează cel puțin un exercițiu practic pe modul  
- Concentrează-te pe înțelegerea conceptelor de bază, mai degrabă decât pe detalii de implementare  

**Dacă poți dedica toate cele 20 de ore:**  
- Completează toate cele șapte module  
- Realizează exercițiile practice cheie din fiecare modul  
- Finalizează un mini-proiect din Modulul 7  
- Explorează cel puțin 2-3 resurse suplimentare  

**Dacă ai mai mult de 20 de ore:**  
- Completează toate modulele cu exerciții detaliate  
- Construiește mai multe mini-proiecte  
- Explorează tehnici avansate de optimizare din Modulul 4  
- Implementează implementarea în producție din Modulul 5  

## Resurse esențiale  

Aceste resurse selectate cu grijă oferă cea mai mare valoare pentru timpul tău limitat de studiu:  

### Documentație obligatorie  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Cel mai eficient instrument de optimizare a modelelor  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cea mai rapidă metodă de implementare locală a SLM-urilor  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referință pentru un model optimizat pentru margine  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit-ul cuprinzător de optimizare de la Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Mediu integrat de dezvoltare EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platforma specifică Windows pentru dezvoltare EdgeAI  

### Instrumente care economisesc timp  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acces rapid la modele și implementare  
- [Gradio](https://www.gradio.app/docs/interface) - Dezvoltare rapidă de interfețe pentru demonstrații AI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Optimizare simplificată a modelelor  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferență eficientă pe CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Cadru de comprimare a rețelelor neuronale  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit pentru implementarea modelelor lingvistice mari  

## Șablon de urmărire a progresului  

Folosește acest șablon simplificat pentru a urmări progresul în cadrul cursului de 20 de ore:  

| Modul | Data finalizării | Ore petrecute | Concluzii principale |  
|-------|------------------|---------------|-----------------------|  
| Modulul 1: Fundamente EdgeAI | | | |  
| Modulul 2: Fundamente SLM | | | |  
| Modulul 3: Implementare SLM | | | |  
| Modulul 4: Optimizarea modelelor | | | |  
| Modulul 5: SLMOps | | | |  
| Modulul 6: Agenți AI | | | |  
| Modulul 7: Instrumente de dezvoltare | | | |  
| Exerciții practice | | | |  
| Mini-proiect | | | |  

## Idei de mini-proiecte  

Ia în considerare finalizarea unuia dintre aceste proiecte pentru a exersa conceptele EdgeAI (fiecare proiect este conceput să dureze 2-4 ore):  

### Proiecte pentru începători (2-3 ore fiecare)  
1. **Asistent text la margine**: Creează un instrument simplu de completare text offline utilizând un model lingvistic mic  
2. **Dashboard de comparație a modelelor**: Construiește o vizualizare de bază a metricilor de performanță pentru diferite SLM-uri  
3. **Experiment de optimizare**: Măsoară impactul diferitelor niveluri de cuantizare asupra aceluiași model de bază  

### Proiecte intermediare (3-4 ore fiecare)  
4. **Flux de lucru AI Toolkit**: Utilizează AI Toolkit din VS Code pentru a optimiza și implementa un model de la început până la sfârșit  
5. **Aplicație Windows AI Foundry**: Creează o aplicație Windows utilizând API-ul Phi Silica și optimizarea NPU  
6. **Implementare cross-platform**: Implementează același model optimizat pe Windows (OpenVINO) și mobil (.NET MAUI)  
7. **Agent cu apelare funcții**: Construiește un agent AI cu capacități de apelare funcții pentru scenarii la margine  

### Proiecte avansate de integrare (4-5 ore fiecare)  
8. **Pipeline de optimizare OpenVINO**: Implementează optimizarea completă a modelului utilizând NNCF și toolkit-ul GenAI  
9. **Pipeline SLMOps**: Implementează un ciclu complet de viață al modelului, de la antrenare la implementare la margine  
10. **Sistem multi-model la margine**: Implementează mai multe modele specializate care lucrează împreună pe hardware la margine  
11. **Sistem de integrare MCP**: Construiește un sistem agentic utilizând Model Context Protocol pentru interacțiunea cu instrumentele  

## Comunitatea de învățare  

Alătură-te discuțiilor și conectează-te cu alți cursanți:  
- Discuții pe GitHub în [repository-ul EdgeAI pentru începători](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Comunitatea tehnologică Microsoft](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Concluzie  

EdgeAI reprezintă frontiera implementării inteligenței artificiale, aducând capabilități puternice direct pe dispozitive, în timp ce abordează preocupări critice legate de confidențialitate, latență și conectivitate. Acest curs de 20 de ore îți oferă cunoștințele esențiale și abilitățile practice pentru a începe să lucrezi imediat cu tehnologiile EdgeAI.  

Cursul este deliberat concis și concentrat pe cele mai importante concepte, permițându-ți să dobândești rapid expertiză valoroasă fără un angajament de timp copleșitor. Amintește-ți că practica practică, chiar și cu exemple simple, este cheia consolidării a ceea ce ai învățat.  

Învățare plăcută!  

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim să asigurăm acuratețea, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa natală ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.