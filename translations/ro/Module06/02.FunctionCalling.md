<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-18T18:34:43+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "ro"
}
-->
# Section02 : Apelarea Funcțiilor în Modele de Limbaj Mic (SLMs)

## Cuprins
1. [Ce este Apelarea Funcțiilor?](../../../Module06)
2. [Cum Funcționează Apelarea Funcțiilor](../../../Module06)
3. [Scenarii de Aplicație](../../../Module06)
4. [Configurarea Apelării Funcțiilor cu Phi-4-mini și Ollama](../../../Module06)
5. [Lucrul cu Apelarea Funcțiilor Qwen3](../../../Module06)
6. [Integrarea Locală Foundry](../../../Module06)
7. [Cele Mai Bune Practici și Rezolvarea Problemelor](../../../Module06)
8. [Exemple Avansate](../../../Module06)

## Ce este Apelarea Funcțiilor?

Apelarea funcțiilor este o capacitate puternică care permite Modelelor de Limbaj Mic (SLMs) să interacționeze cu instrumente externe, API-uri și servicii. În loc să fie limitate la datele lor de antrenament, SLM-urile pot acum:

- **Conecta la API-uri externe** (servicii meteo, baze de date, motoare de căutare)
- **Executa funcții specifice** pe baza cererilor utilizatorului
- **Obține informații în timp real** din diverse surse
- **Realiza sarcini computaționale** prin instrumente specializate
- **Conecta mai multe operațiuni** pentru fluxuri de lucru complexe

Această capacitate transformă SLM-urile din generatoare statice de text în agenți AI dinamici care pot îndeplini sarcini reale.

## Cum Funcționează Apelarea Funcțiilor

Procesul de apelare a funcțiilor urmează un flux de lucru sistematic:

### 1. Integrarea Instrumentelor
- **Instrumente Externe**: SLM-urile se pot conecta la API-uri meteo, baze de date, servicii web și alte sisteme externe
- **Definiții ale Funcțiilor**: Fiecare instrument este definit cu parametri specifici, formate de intrare/ieșire și descrieri
- **Compatibilitate API**: Instrumentele sunt integrate prin interfețe standardizate (REST APIs, SDK-uri etc.)

### 2. Definiția Funcțiilor
Funcțiile sunt definite cu trei componente cheie:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Detectarea Intenției
- **Procesare Limbaj Natural**: SLM-ul analizează intrarea utilizatorului pentru a înțelege intenția
- **Potrivirea Funcțiilor**: Determină ce funcție/funcții sunt necesare pentru a îndeplini cererea
- **Extracția Parametrilor**: Identifică și extrage parametrii necesari din mesajul utilizatorului

### 4. Generarea Output-ului JSON
SLM-ul generează un JSON structurat care conține:
- Numele funcției de apelat
- Parametrii necesari cu valorile corespunzătoare
- Contextul execuției și metadatele

### 5. Execuția Externă
- **Validarea Parametrilor**: Se asigură că toți parametrii necesari sunt prezenți și formatul este corect
- **Execuția Funcției**: Aplicația execută funcția specificată cu parametrii furnizați
- **Gestionarea Erorilor**: Se ocupă de eșecuri, timeout-uri și răspunsuri invalide

### 6. Integrarea Răspunsului
- **Procesarea Rezultatelor**: Output-ul funcției este returnat către SLM
- **Integrarea Contextului**: SLM-ul încorporează rezultatele în răspunsul său
- **Comunicarea cu Utilizatorul**: Prezintă informațiile într-un format natural, conversațional

## Scenarii de Aplicație

### Recuperarea Datelor
Transformă interogările în limbaj natural în apeluri API structurate:
- **"Arată-mi comenzile recente"** → Interogare bază de date cu ID utilizator și filtre de dată
- **"Cum e vremea în Tokyo?"** → Apel API meteo cu parametru locație
- **"Găsește emailuri de la John săptămâna trecută"** → Interogare serviciu email cu expeditor și filtre de dată

### Execuția Operațiunilor
Transformă cererile utilizatorului în apeluri de funcții specifice:
- **"Programează o întâlnire pentru mâine la ora 14:00"** → Integrare API calendar
- **"Trimite un mesaj echipei"** → API platformă de comunicare
- **"Creează un backup al fișierelor mele"** → Operațiune sistem de fișiere

### Sarcini Computaționale
Gestionează operațiuni matematice sau logice complexe:
- **"Calculează dobânda compusă pentru $10,000 la 5% timp de 10 ani"** → Funcție de calcul financiar
- **"Analizează acest set de date pentru tendințe"** → Instrumente de analiză statistică
- **"Optimizează această rută pentru livrare"** → Algoritmi de optimizare rută

### Fluxuri de Lucru pentru Procesarea Datelor
Conectează mai multe apeluri de funcții pentru operațiuni complexe:
1. **Recuperează date** din surse multiple
2. **Parcurge și validează** informațiile
3. **Transformă** datele în formatul necesar
4. **Stochează rezultatele** în sisteme adecvate
5. **Generează rapoarte** sau vizualizări

### Integrarea UI/UX
Permite actualizări dinamice ale interfeței:
- **"Arată datele de vânzări pe tabloul de bord"** → Generare și afișare grafic
- **"Actualizează harta cu locații noi"** → Integrare date geospațiale
- **"Reîmprospătează afișajul inventarului"** → Sincronizare date în timp real

## Configurarea Apelării Funcțiilor cu Phi-4-mini și Ollama

Phi-4-mini de la Microsoft suportă atât apelarea funcțiilor individuale, cât și apelarea funcțiilor în paralel prin Ollama. Iată cum se configurează:

### Cerințe Prealabile
- Ollama versiunea 0.5.13 sau mai recentă
- Modelul Phi-4-mini (recomandat: `phi4-mini:3.8b-fp16`)

### Pași de Instalare

#### 1. Instalează și Rulează Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Creează un Template Personalizat ModelFile
Din cauza limitărilor actuale ale template-urilor implicite Ollama, trebuie să creezi un ModelFile personalizat cu următorul template:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Creează Modelul Personalizat
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Exemplu de Apelare Funcție Individuală

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Exemplu de Apelare Funcții în Paralel

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Lucrul cu Apelarea Funcțiilor Qwen3

Qwen3 oferă capacități avansate de apelare a funcțiilor cu performanță și flexibilitate excelente. Iată cum se implementează:

### Utilizarea Framework-ului Qwen-Agent

Qwen-Agent oferă un framework de nivel înalt care simplifică implementarea apelării funcțiilor:

#### Instalare
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Configurare de Bază

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Implementarea Funcțiilor Personalizate

De asemenea, poți defini funcții personalizate pentru Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Funcționalități Avansate Qwen3

#### Controlul Modului de Gândire
Qwen3 suportă comutarea dinamică între modurile de gândire și non-gândire:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Apelarea Funcțiilor în Mai Multe Etape
Qwen3 excelează în conectarea mai multor apeluri de funcții:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Integrarea Locală Foundry

Foundry Local de la Microsoft oferă un API compatibil OpenAI pentru rularea modelelor local cu confidențialitate și performanță îmbunătățite.

### Configurare și Instalare

#### Windows
Descarcă installer-ul de pe [pagina de lansări Foundry Local](https://github.com/microsoft/Foundry-Local/releases) și urmează instrucțiunile de instalare.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Utilizare de Bază

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Funcționalități Avansate Foundry Local

#### Managementul Modelului
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Optimizarea Performanței
Foundry Local selectează automat cea mai bună variantă de model pentru hardware-ul tău:
- **GPU CUDA**: Descarcă modele optimizate pentru GPU
- **NPU Qualcomm**: Utilizează variante accelerate NPU
- **Doar CPU**: Selectează modele optimizate pentru CPU

## Cele Mai Bune Practici și Rezolvarea Problemelor

### Cele Mai Bune Practici pentru Definirea Funcțiilor

#### 1. Denumire Clară și Descriptivă
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Definiții Complete ale Parametrilor
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Validarea Intrărilor și Gestionarea Erorilor
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Probleme Comune și Soluții

#### Problemă 1: Funcția Nu Este Apelată
**Simptome**: Modelul răspunde cu text în loc să apeleze funcția

**Soluții**:
1. **Verifică descrierea funcției**: Asigură-te că se potrivește clar cu intenția utilizatorului
2. **Verifică definițiile parametrilor**: Asigură-te că toți parametrii necesari sunt definiți corect
3. **Revizuiește prompt-ul sistemului**: Include instrucțiuni clare despre când să folosești funcțiile
4. **Testează cu cereri explicite**: Încearcă "Te rog folosește funcția meteo pentru a obține date pentru Londra"

#### Problemă 2: Parametri Incorecți
**Simptome**: Funcția este apelată cu parametri greșiți sau lipsă

**Soluții**:
1. **Adaugă exemple de parametri**: Include valori de exemplu în descrierile parametrilor
2. **Folosește constrângeri enum**: Limitează valorile parametrilor la opțiuni specifice, dacă este posibil
3. **Implementează valori implicite**: Oferă valori implicite sensibile pentru parametrii opționali

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Problemă 3: Eșecuri în Apelarea Funcțiilor în Paralel
**Simptome**: Doar o funcție se execută când ar trebui să ruleze mai multe

**Soluții**:
1. **Verifică suportul modelului**: Asigură-te că modelul tău suportă apelarea funcțiilor în paralel
2. **Actualizează prompt-ul sistemului**: Include "unele instrumente" sau "mai multe instrumente" în mesajul sistemului
3. **Folosește versiuni adecvate ale modelului**: Phi-4-mini:3.8b-fp16 recomandat pentru Ollama

#### Problemă 4: Probleme cu Template-ul Ollama
**Simptome**: Apelarea funcțiilor nu funcționează cu configurația implicită Ollama

**Soluții**:
1. **Folosește ModelFile personalizat**: Aplică template-ul corectat furnizat în acest tutorial
2. **Actualizează Ollama**: Asigură-te că folosești versiunea 0.5.13 sau mai recentă
3. **Verifică cuantizarea modelului**: Niveluri mai ridicate de cuantizare (Q8_0, fp16) funcționează mai bine decât versiunile puternic cuantizate

### Optimizarea Performanței

#### 1. Design Eficient al Funcțiilor
- **Menține funcțiile concentrate**: Fiecare funcție ar trebui să aibă un scop unic, clar
- **Minimizează dependențele externe**: Redu apelurile API și cererile de rețea, dacă este posibil
- **Cachează rezultatele**: Stochează datele solicitate frecvent pentru a îmbunătăți timpii de răspuns

#### 2. Operațiuni Batch și Async
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Managementul Resurselor
- **Pooling conexiuni**: Reutilizează conexiunile la baze de date și API-uri
- **Limitarea ratei**: Implementați limitarea ratei pentru API-uri externe
- **Gestionarea timeout-urilor**: Setează timeout-uri rezonabile pentru toate apelurile externe

## Exemple Avansate

### Sistem de Colaborare Multi-Agent

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Sistem de Selecție Dinamică a Instrumentelor

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Format standard pentru toate apelurile de funcții"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Agent AI pregătit pentru producție cu capacități cuprinzătoare de apelare a funcțiilor"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Inițializează funcțiile de bază ale afacerii
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Înregistrează toate funcțiile disponibile ale afacerii"""
        
        # Funcții CRM
        self.register_function(
            name="get_customer_info",
            description="Recuperează informații despre client din CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # apeluri pe minut
        )
        
        # Funcții de Vânzări
        self.register_function(
            name="create_sales_opportunity",
            description="Creează o oportunitate de vânzări nouă",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Funcții de Analiză
        self.register_function(
            name="generate_sales_report",
            description="Generează raportul de performanță al vânzărilor",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Funcții de Notificare
        self.register_function(
            name="send_notification",
            description="Trimite notificări membrilor echipei",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Înregistrează o funcție nouă cu agentul"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Desigur! Vă rog să îmi furnizați fișierul Markdown pe care doriți să-l traduc.
„Execută o funcție cu gestionare cuprinzătoare a erorilor și jurnalizare”
start_time = datetime.now()

try:
    # Validează existența funcției
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Funcția '{function_name}' nu a fost găsită",
            timestamp=start_time
        )
    
    # Verifică limitele de utilizare
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Limita de utilizare depășită pentru funcția '{function_name}'",
            timestamp=start_time
        )
    
    # Validează parametrii
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Execută funcția
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Jurnalizează execuția reușită
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Jurnalizează execuția eșuată
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Verifică dacă apelul funcției respectă limitele de utilizare"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Resetează contorul dacă a trecut un minut
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Verifică dacă este sub limită
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Validează parametrii funcției"""
    func_params = self.functions[function_name]['parameters']
    
    # Verifică parametrii obligatorii
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Lipsește parametrul obligatoriu: {param_name}"
            )
    
    # Validează tipurile și constrângerile parametrilor
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Validare tip
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Parametrul '{param_name}' trebuie să fie un șir de caractere"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Parametrul '{param_name}' trebuie să fie un număr"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Parametrul '{param_name}' trebuie să fie un boolean"
                )
            
            # Validare enum
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Parametrul '{param_name}' trebuie să fie unul dintre: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Jurnalizează apelul funcției pentru audit"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Opțional, scrie în sistemul extern de jurnalizare
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Scrie intrarea de jurnal în sistemul extern de jurnalizare"""
    # Implementarea depinde de infrastructura de jurnalizare
    # de exemplu, trimitere către ELK stack, CloudWatch etc.
    pass

# Implementări ale funcțiilor de business
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Recuperează informații despre client din sistemul CRM"""
    # Simulează apelul la baza de date/API
    await asyncio.sleep(0.1)  # Simulează întârzierea rețelei
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'activ',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Produs A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Produs B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """Creează o oportunitate de vânzare nouă"""
    # Simulează apelul API CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'deschis',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """Generează un raport de vânzări cuprinzător"""
    # Simulează agregarea datelor
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'mediu', channel: str = 'email') -> Dict:
    """Trimite notificări prin canalul specificat"""
    # Simulează apelul serviciului de notificări
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'trimis',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Obține definițiile funcțiilor compatibile cu OpenAI pentru toate funcțiile înregistrate"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Exemplu de utilizare pentru integrarea în mediul enterprise
async def enterprise_demo():
    """Demonstrează capacitățile agentului AI pentru mediul enterprise"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Exemplu 1: Procesarea cererilor clienților
    print("=== Procesarea cererilor clienților ===")
    
    # Obține informații despre client
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Informații despre client recuperate: {result.data['name']}")
        print(f"Timp de execuție: {result.execution_time:.3f}s")
    
    # Exemplu 2: Crearea unei oportunități de vânzare
    print("\n=== Crearea unei oportunități de vânzare ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Oportunitate creată: {result.data['opportunity_id']}")
    
    # Exemplu 3: Operațiuni în lot
    print("\n=== Operațiuni în lot ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Oportunitate nouă creată',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Sarcina {i+1} finalizată cu succes")
        else:
            print(f"Sarcina {i+1} eșuată: {result.error}")
    
    # Afișează jurnalul de audit
    print(f"\n=== Jurnal de audit ({len(agent.audit_log)} intrări) ===")
    for entry in agent.audit_log[-3:]:  # Afișează ultimele 3 intrări
        print(f"{entry['timestamp']}: {entry['function_name']} - {'SUCCES' if entry['success'] else 'EȘEC'}")

# Rulează demonstrația pentru mediul enterprise
# asyncio.run(enterprise_demo())

## Concluzie

Apelarea funcțiilor în Modelele de Limbaj Mic reprezintă o schimbare de paradigmă de la asistenți AI statici la agenți dinamici, capabili să interacționeze cu lumea reală. Acest tutorial a acoperit:

### Idei principale

1. **Înțelegerea fundamentelor**: Apelarea funcțiilor permite extinderea SLM-urilor dincolo de datele lor de antrenament prin conectarea la instrumente și servicii externe.

2. **Flexibilitate în implementare**: Există multiple abordări, de la implementări de nivel scăzut cu șabloane personalizate la cadre avansate precum Qwen-Agent și Foundry Local.

3. **Considerații pentru producție**: Implementările enterprise necesită atenție la gestionarea erorilor, limitarea utilizării, securitate și jurnalizare pentru audit.

4. **Optimizarea performanței**: Designul adecvat al funcțiilor, execuția eficientă și utilizarea inteligentă a cache-ului pot îmbunătăți semnificativ timpii de răspuns.

### Direcții viitoare

Pe măsură ce tehnologia SLM continuă să evolueze, ne putem aștepta la:

- **Acuratețe îmbunătățită în apelarea funcțiilor**: Detectarea mai bună a intențiilor și extragerea parametrilor
- **Procesare paralelă avansată**: Orchestrarea mai sofisticată a funcțiilor multiple
- **Standarde de integrare îmbunătățite**: Protocoale standardizate pentru integrarea instrumentelor
- **Caracteristici de securitate avansate**: Mecanisme îmbunătățite de autentificare și autorizare
- **Extinderea ecosistemului**: Bibliotecă în creștere de funcții predefinite și integrări

### Începeți acum

Pentru a începe implementarea apelării funcțiilor în proiectele dvs.:

1. **Începeți simplu**: Începeți cu scenarii de funcții simple
2. **Alegeți cadrul potrivit**: Selectați între implementare directă (Ollama/Phi-4) sau asistată de cadru (Qwen-Agent)
3. **Proiectați funcțiile cu atenție**: Concentrați-vă pe definiții clare și bine documentate ale funcțiilor
4. **Implementați gestionarea erorilor**: Construiți gestionarea robustă a erorilor de la început
5. **Scalați treptat**: Trecerea de la scenarii simple la complexe pe măsură ce câștigați experiență

Apelarea funcțiilor transformă SLM-urile din generatoare impresionante de text în agenți AI practici, capabili să rezolve probleme reale. Urmând modelele și practicile prezentate în acest tutorial, puteți construi sisteme AI puternice și fiabile, care depășesc interfețele tradiționale de chat.

### Resurse și referințe
- **Modele Phi-4**: [Colecția Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Documentația Qwen3**: [Documentația oficială Qwen](https://qwen.readthedocs.io/)
- **Ollama**: [Site-ul oficial](https://ollama.com/)
- **Foundry Local**: [Repository GitHub](https://github.com/microsoft/Foundry-Local)
- **Cele mai bune practici pentru apelarea funcțiilor**: [Ghid Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)

Rețineți că apelarea funcțiilor este un domeniu în continuă evoluție, iar menținerea la curent cu cele mai recente dezvoltări în cadrul framework-urilor și modelelor alese vă va ajuta să construiți agenți AI mai eficienți.


## ➡️ Ce urmează

- [03: Integrarea Protocolului de Context al Modelului (MCP)](./03.IntroduceMCP.md)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim să asigurăm acuratețea, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa maternă ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.