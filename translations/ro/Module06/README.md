<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-18T18:36:27+00:00",
  "source_file": "Module06/README.md",
  "language_code": "ro"
}
-->
# Capitolul 06: Sisteme Agentice SLM: O Privire de Ansamblu

Peisajul inteligenței artificiale trece printr-o transformare fundamentală, evoluând de la chatbot-uri simple la agenți AI sofisticați alimentați de Modele de Limbaj Mic (SLM). Acest ghid cuprinzător explorează trei aspecte critice ale sistemelor agentice moderne SLM: concepte fundamentale și strategii de implementare, capacități de apelare a funcțiilor și integrarea revoluționară a Protocolului de Context al Modelului (MCP).

## [Secțiunea 1: Agenți AI și Fundamentele Modelelor de Limbaj Mic](./01.IntroduceAgent.md)

Prima secțiune stabilește înțelegerea de bază a agenților AI și a Modelelor de Limbaj Mic, poziționând anul 2025 ca anul agenților AI, după era chatbot-urilor din 2023 și boom-ul copilotului din 2024. Această secțiune introduce **sisteme AI agentice** care gândesc, raționează, planifică, utilizează instrumente și execută sarcini cu un aport minim din partea oamenilor.

### Concepte Cheie Abordate:
- **Cadru de Clasificare a Agenților**: De la agenți reflexivi simpli la agenți care învață, oferind o taxonomie cuprinzătoare pentru diferite scenarii de calcul
- **Fundamentele SLM**: Definirea Modelelor de Limbaj Mic ca modele cu mai puțin de 10 miliarde de parametri, capabile să efectueze inferențe practice pe dispozitive de consum
- **Strategii Avansate de Optimizare**: Acoperirea formatului de implementare GGUF, tehnici de cuantizare (Q4_K_M, Q5_K_S, Q8_0) și cadre optimizate pentru edge, precum Llama.cpp și Apple MLX
- **Compromisuri SLM vs LLM**: Demonstrând o reducere a costurilor de 10-30× cu SLM-uri, menținând în același timp eficiența pentru 70-80% din sarcinile tipice ale agenților

Secțiunea se încheie cu strategii practice de implementare utilizând Ollama, VLLM și soluțiile edge ale Microsoft, stabilind SLM-urile ca viitorul implementării AI agentice, eficiente din punct de vedere al costurilor și care protejează confidențialitatea.

## [Secțiunea 2: Apelarea Funcțiilor în Modelele de Limbaj Mic](./02.FunctionCalling.md)

A doua secțiune aprofundează **capacitățile de apelare a funcțiilor**, mecanismul care transformă modelele de limbaj statice în agenți AI dinamici capabili de interacțiune în lumea reală. Această analiză tehnică detaliată acoperă întregul flux de lucru, de la detectarea intenției la integrarea răspunsului.

### Zone Cheie de Implementare:
- **Flux de Lucru Sistematic**: Explorare detaliată a integrării instrumentelor, definirea funcțiilor, detectarea intenției, generarea de ieșiri JSON și execuția externă
- **Implementări Specifice Platformei**: Ghiduri cuprinzătoare pentru Phi-4-mini cu Ollama, apelarea funcțiilor Qwen3 și integrarea Microsoft Foundry Local
- **Exemple Avansate**: Sisteme de colaborare multi-agent, selecție dinamică a instrumentelor și modele de integrare în întreprinderi cu gestionarea completă a erorilor
- **Considerații pentru Producție**: Limitarea ratei, jurnalizarea auditului, măsuri de securitate și strategii de optimizare a performanței

Această secțiune oferă atât înțelegere teoretică, cât și modele practice de implementare, permițând dezvoltatorilor să construiască sisteme robuste de apelare a funcțiilor, capabile să gestioneze totul, de la apeluri API simple la fluxuri de lucru complexe în întreprinderi.

## [Secțiunea 3: Integrarea Protocolului de Context al Modelului (MCP)](./03.IntroduceMCP.md)

Ultima secțiune introduce **Protocolul de Context al Modelului (MCP)**, un cadru revoluționar care standardizează modul în care modelele de limbaj interacționează cu instrumente și sisteme externe. Această secțiune demonstrează cum MCP creează o punte între modelele AI și lumea reală prin protocoale bine definite.

### Repere ale Integrării:
- **Arhitectura Protocolului**: Design de sistem stratificat care acoperă aplicația, clientul LLM, clientul MCP și straturile de procesare a instrumentelor
- **Suport Multi-Backend**: Implementare flexibilă care susține atât backend-urile Ollama (dezvoltare locală), cât și vLLM (producție)
- **Protocoale de Conexiune**: Modul STDIO pentru comunicarea directă a proceselor și modul SSE pentru streaming bazat pe HTTP
- **Aplicații în Lumea Reală**: Exemple de automatizare web, procesare de date și integrare API cu gestionarea completă a erorilor

Integrarea MCP demonstrează cum SLM-urile pot fi augmentate cu capacități externe, compensând numărul mai mic de parametri prin funcționalitate îmbunătățită, menținând în același timp beneficiile implementării locale și eficienței resurselor.

## Implicații Strategice

Împreună, aceste trei secțiuni prezintă un cadru cuprinzător pentru înțelegerea și implementarea sistemelor agentice SLM. Evoluția de la concepte fundamentale prin apelarea funcțiilor până la integrarea MCP demonstrează un parcurs clar către implementarea democratizată a AI, unde:

- **Eficiența se întâlnește cu capacitatea** prin modele mici optimizate
- **Eficiența costurilor** permite adoptarea pe scară largă
- **Protocoale standardizate** asigură interoperabilitatea
- **Implementarea locală** protejează confidențialitatea și reduce latența

Această progresie reprezintă nu doar un avans tehnologic, ci și o schimbare de paradigmă către sisteme AI mai accesibile, eficiente și practice, capabile să funcționeze eficient în medii cu resurse limitate, oferind în același timp capacități agentice sofisticate.

Combinarea SLM-urilor cu strategii avansate de implementare, apelarea funcțiilor robuste și protocoale standardizate de integrare a instrumentelor poziționează aceste sisteme ca fundația pentru generația următoare de agenți AI, care vor transforma modul în care interacționăm cu inteligența artificială și beneficiem de aceasta în diverse industrii și aplicații.

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim să asigurăm acuratețea, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa natală ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.