<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2db7a2f6e9873c3cd09fea6736bf360b",
  "translation_date": "2025-07-22T04:21:17+00:00",
  "source_file": "Module05/README.md",
  "language_code": "ko"
}
-->
# Chapter 05 : SLMOps - 소형 언어 모델 운영에 대한 종합 가이드

## 개요

SLMOps(소형 언어 모델 운영)은 효율성, 비용 절감, 엣지 컴퓨팅 기능을 우선시하는 AI 배포의 혁신적인 접근 방식을 나타냅니다. 이 종합 가이드는 SLM 운영의 전체 수명 주기를 다루며, 기본 개념 이해부터 실무 배포까지를 포함합니다.

---

## [Section 1: SLMOps 소개](./01.IntroduceSLMOps.md)

**엣지에서의 AI 운영 혁신**

이 기본 장에서는 기존 대규모 AI 운영에서 소형 언어 모델 운영(SLMOps)으로의 패러다임 전환을 소개합니다. SLMOps가 비용 효율성과 개인정보 보호 준수를 유지하면서 대규모 AI 배포의 주요 과제를 어떻게 해결하는지 알아볼 수 있습니다.

**배울 내용:**
- 현대 AI 전략에서 SLMOps의 등장과 중요성
- SLM이 성능과 자원 효율성 간의 격차를 어떻게 메우는지
- 지능형 자원 관리와 개인정보 보호 중심 아키텍처를 포함한 핵심 운영 원칙
- 실제 구현에서의 도전 과제와 해결 방안
- 전략적 비즈니스 영향과 경쟁 우위

**핵심 요약:** SLMOps는 제한된 기술 인프라를 가진 조직도 고급 언어 처리 기능을 활용할 수 있도록 AI 배포를 민주화하며, 더 빠른 개발 주기와 예측 가능한 운영 비용을 가능하게 합니다.

---

## [Section 2: 모델 증류 - 이론에서 실무로](./02.SLMOps-Distillation.md)

**지식 전이를 통한 효율적인 모델 생성**

모델 증류는 더 작은 모델이 더 큰 모델의 성능을 유지하면서도 효율적으로 작동할 수 있도록 만드는 핵심 기술입니다. 이 장에서는 대형 교사 모델에서 소형 학생 모델로 지식을 전이하는 증류 워크플로우 구현에 대한 종합적인 가이드를 제공합니다.

**배울 내용:**
- 모델 증류의 기본 개념과 이점
- 두 단계 증류 과정: 합성 데이터 생성 및 학생 모델 학습
- DeepSeek V3 및 Phi-4-mini와 같은 최신 모델을 활용한 실무 구현 전략
- Azure ML 증류 워크플로우와 실습 예제
- 하이퍼파라미터 튜닝 및 평가 전략에 대한 모범 사례
- 비용 및 성능 개선을 보여주는 실제 사례 연구

**핵심 요약:** 모델 증류는 추론 시간을 85% 줄이고 메모리 요구 사항을 95% 감소시키면서 원래 모델 정확도의 92%를 유지할 수 있어 고급 AI 기능을 실질적으로 배포 가능하게 만듭니다.

---

## [Section 3: 파인튜닝 - 특정 작업에 맞춘 모델 커스터마이징](./03.SLMOps-Finetuing.md)

**사전 학습된 모델을 고유한 요구 사항에 맞게 조정하기**

파인튜닝은 범용 모델을 특정 사용 사례와 도메인에 맞춘 전문 솔루션으로 변환합니다. 이 장에서는 기본 매개변수 조정부터 LoRA 및 QLoRA와 같은 고급 기술을 활용한 효율적인 모델 커스터마이징까지를 다룹니다.

**배울 내용:**
- 파인튜닝 방법론과 그 응용에 대한 종합적인 개요
- 풀 파인튜닝, 매개변수 효율적 파인튜닝(PEFT), 작업별 접근 방식 등 다양한 파인튜닝 유형
- Microsoft Olive를 활용한 실습 예제와 구현 방법
- 멀티 어댑터 학습 및 하이퍼파라미터 최적화와 같은 고급 기술
- 데이터 준비, 학습 구성, 자원 관리에 대한 모범 사례
- 성공적인 파인튜닝 프로젝트를 위한 일반적인 도전 과제와 검증된 해결 방안

**핵심 요약:** Microsoft Olive와 같은 도구를 활용한 파인튜닝은 사전 학습된 모델을 특정 요구 사항에 효율적으로 맞추고 성능과 자원 제약을 최적화하여 다양한 응용 분야에서 최첨단 AI를 활용할 수 있도록 합니다.

---

## [Section 4: 배포 - 실무 준비된 모델 구현](./04.SLMOps.Deployment.md)

**Foundry Local을 활용한 파인튜닝된 모델의 배포**

마지막 장에서는 모델 변환, 양자화, 생산 구성 등 중요한 배포 단계를 다룹니다. Foundry Local을 사용하여 파인튜닝된 양자화 모델을 배포하는 방법을 배우고 최적의 성능과 자원 활용을 달성할 수 있습니다.

**배울 내용:**
- 환경 설정 및 도구 설치 절차
- 다양한 배포 시나리오에 맞춘 모델 변환 및 양자화 기술
- 모델별 최적화를 포함한 Foundry Local 배포 구성
- 성능 벤치마킹 및 품질 검증 방법론
- 일반적인 배포 문제 해결 및 최적화 전략
- 생산 모니터링 및 유지 관리 모범 사례

**핵심 요약:** 양자화 기술을 활용한 적절한 배포 구성은 모델 크기를 최대 75% 줄이면서도 수용 가능한 품질을 유지할 수 있어 다양한 하드웨어 구성에서 효율적인 생산 배포를 가능하게 합니다.

---

## 시작하기

이 가이드는 SLMOps의 기본 개념 이해부터 실무 배포 구현까지의 전체 여정을 안내하도록 설계되었습니다. 각 장은 이전 장을 기반으로 구축되며, 이론적 이해와 실무 구현 기술을 모두 제공합니다.

데이터 과학자로서 모델 배포를 최적화하려는 경우, DevOps 엔지니어로서 AI 운영을 구현하려는 경우, 또는 조직을 위해 SLMOps를 평가하려는 기술 리더인 경우, 이 종합 가이드는 소형 언어 모델 운영을 성공적으로 구현하는 데 필요한 지식과 도구를 제공합니다.

**준비되셨나요?** Chapter 1부터 시작하여 SLMOps의 기본 원칙을 이해하고 이후 장에서 다루는 고급 구현 기술을 위한 기초를 다지세요.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 책임을 지지 않습니다.