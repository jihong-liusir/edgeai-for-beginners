<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-07-22T03:00:34+00:00",
  "source_file": "Module01/README.md",
  "language_code": "ko"
}
-->
# Chapter 01: 엣지 AI 배포의 변혁

엣지 AI는 인공지능 배포의 패러다임 전환을 의미하며, 클라우드 기반 처리에서 로컬 엣지 디바이스로 AI 기능을 이동시키는 것을 말합니다. 이 장에서는 AI 구현의 이 혁신적인 접근 방식을 정의하는 기본 개념, 핵심 기술, 실용적인 응용 사례를 탐구합니다.

## 모듈 구조

### [Section 1: 엣지 AI 기본 개념](./01.EdgeAIFundamentals.md)
이 섹션에서는 전통적인 클라우드 기반 AI와 엣지 AI 배포 모델을 비교하며 기초를 다집니다. 모델 양자화, 압축 최적화, 그리고 엣지 디바이스의 계산 제약을 극복하는 소형 언어 모델(SLMs)과 같은 주요 기술을 살펴봅니다. 이러한 혁신이 강화된 개인정보 보호, 초저지연, 강력한 오프라인 처리 기능을 어떻게 제공하는지 강조합니다.

### [Section 2: 실제 사례 연구](./02.RealWorldCaseStudies.md)
Microsoft의 Phi 및 Mu 모델 생태계, 일본항공의 AI 보고 시스템과 같은 구체적인 사례를 통해 다양한 산업에서 성공적인 엣지 AI 구현을 보여줍니다. 이러한 사례 연구는 특화된 작업에서 SLMs의 뛰어난 성능을 입증하며 엣지 배포 전략의 실질적인 이점을 설명합니다.

### [Section 3: 실용적인 구현 가이드](./03.PracticalImplementationGuide.md)
이 섹션은 실습 학습을 위한 환경 준비 지침을 포괄적으로 제공하며, 필수 개발 도구, 하드웨어 요구 사항, 핵심 모델 리소스, 최적화 프레임워크를 다룹니다. 학습자가 자신만의 엣지 AI 솔루션을 구축하고 배포할 수 있는 기술적 기반을 마련합니다.

### [Section 4: 엣지 AI 배포 하드웨어 플랫폼](./04.EdgeDeployment.md)
이 섹션에서는 엣지 AI 배포를 가능하게 하는 하드웨어 생태계를 탐구하며 Intel, Qualcomm, NVIDIA, Windows AI PC 플랫폼을 다룹니다. 하드웨어 기능, 플랫폼별 최적화 기술, 다양한 엣지 컴퓨팅 시나리오에서의 실질적인 배포 고려 사항을 상세히 비교합니다.

## 주요 학습 결과

이 장을 마치면 독자는 다음을 이해할 수 있습니다:
- 클라우드와 엣지 AI 아키텍처의 근본적인 차이점
- 엣지 배포를 위한 핵심 최적화 기술
- 실제 응용 사례와 성공 사례
- 엣지 AI 솔루션 구현을 위한 실용적인 기술
- 하드웨어 플랫폼 선택 및 플랫폼별 최적화 접근법
- 성능 벤치마킹 및 배포 모범 사례

## 미래 전망

엣지 AI는 AI 배포의 미래를 형성하는 중요한 트렌드로 부상하며, 클라우드 연결 없이도 독립적으로 작동할 수 있는 분산적이고 효율적이며 개인정보를 보호하는 AI 시스템을 가능하게 합니다. 동시에 높은 성능 기준을 유지합니다.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 책임을 지지 않습니다.