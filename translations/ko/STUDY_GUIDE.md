<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T10:35:29+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ko"
}
-->
# EdgeAI 초보자를 위한 학습 경로 및 학습 일정

### 집중 학습 경로 (1주)

| 날짜 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Day 1 | 모듈 1: EdgeAI 기본 개념 | 3시간 |
| Day 2 | 모듈 2: SLM 기초 | 3시간 |
| Day 3 | 모듈 3: SLM 배포 | 2시간 |
| Day 4-5 | 모듈 4: 모델 최적화 (6개 프레임워크) | 4시간 |
| Day 6 | 모듈 5: SLMOps | 3시간 |
| Day 7 | 모듈 6-7: AI 에이전트 및 개발 도구 | 4시간 |
| Day 8 | 모듈 8: Foundry Local Toolkit (현대적 구현) | 1시간 |

### 집중 학습 경로 (2주)

| 날짜 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Day 1-2 | 모듈 1: EdgeAI 기본 개념 | 3시간 |
| Day 3-4 | 모듈 2: SLM 기초 | 3시간 |
| Day 5-6 | 모듈 3: SLM 배포 | 2시간 |
| Day 7-8 | 모듈 4: 모델 최적화 | 4시간 |
| Day 9-10 | 모듈 5: SLMOps | 3시간 |
| Day 11-12 | 모듈 6: AI 에이전트 | 2시간 |
| Day 13-14 | 모듈 7: 개발 도구 | 3시간 |

### 파트타임 학습 (4주)

| 주 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Week 1 | 모듈 1-2: 기본 개념 및 SLM 기초 | 6시간 |
| Week 2 | 모듈 3-4: 배포 및 최적화 | 6시간 |
| Week 3 | 모듈 5-6: SLMOps 및 AI 에이전트 | 5시간 |
| Week 4 | 모듈 7: 개발 도구 및 통합 | 3시간 |

| 날짜 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Day 1-2 | 모듈 1: EdgeAI 기본 개념 | 3시간 |
| Day 3-4 | 모듈 2: SLM 기초 | 3시간 |
| Day 5-6 | 모듈 3: SLM 배포 | 2시간 |
| Day 7-8 | 모듈 4: 모델 최적화 | 4시간 |
| Day 9-10 | 모듈 5: SLMOps | 3시간 |
| Day 11-12 | 모듈 6: SLM 에이전트 시스템 | 2시간 |
| Day 13-14 | 모듈 7: EdgeAI 구현 샘플 | 2시간 |

| 모듈 | 완료 날짜 | 소요 시간 | 주요 학습 내용 |
|------|----------|-----------|----------------|
| 모듈 1: EdgeAI 기본 개념 | | | |
| 모듈 2: SLM 기초 | | | |
| 모듈 3: SLM 배포 | | | |
| 모듈 4: 모델 최적화 (6개 프레임워크) | | | |
| 모듈 5: SLMOps | | | |
| 모듈 6: SLM 에이전트 시스템 | | | |
| 모듈 7: EdgeAI 구현 샘플 | | | |
| 실습 과제 | | | |
| 미니 프로젝트 | | | |

### 파트타임 학습 (4주)

| 주 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Week 1 | 모듈 1-2: 기본 개념 및 SLM 기초 | 6시간 |
| Week 2 | 모듈 3-4: 배포 및 최적화 | 6시간 |
| Week 3 | 모듈 5-6: SLMOps 및 AI 에이전트 | 5시간 |
| Week 4 | 모듈 7: 개발 도구 및 통합 | 3시간 |

## 소개

EdgeAI 초보자를 위한 학습 가이드에 오신 것을 환영합니다! 이 문서는 학습 자료를 효과적으로 탐색하고 학습 경험을 극대화할 수 있도록 설계되었습니다. 구조화된 학습 경로, 추천 학습 일정, 주요 개념 요약, 그리고 EdgeAI 기술에 대한 이해를 심화할 수 있는 추가 자료를 제공합니다.

이 과정은 EdgeAI에 대한 필수 지식을 시간 효율적으로 전달하는 20시간의 간결한 과정으로, 바쁜 전문가와 학생들이 이 신흥 분야에서 실용적인 기술을 빠르게 습득할 수 있도록 설계되었습니다.

## 과정 개요

이 과정은 다음의 7개 모듈로 구성된 포괄적인 학습 내용으로 구성되어 있습니다:

1. **EdgeAI 기본 개념 및 변환** - 핵심 개념과 기술 변화 이해
2. **소형 언어 모델(SLM) 기초** - 다양한 SLM 계열과 그 아키텍처 탐구
3. **소형 언어 모델 배포** - 실용적인 배포 전략 구현
4. **모델 형식 변환 및 양자화** - OpenVINO를 포함한 6개 프레임워크를 활용한 고급 최적화
5. **SLMOps - 소형 언어 모델 운영** - 생산 수명 주기 관리 및 배포
6. **SLM 에이전트 시스템** - AI 에이전트, 함수 호출, 모델 컨텍스트 프로토콜
7. **EdgeAI 구현 샘플** - AI 툴킷, Windows 개발, 플랫폼별 구현
8. **Microsoft Foundry Local – 완전한 개발자 툴킷** - Azure 통합을 포함한 로컬 우선 개발 (모듈 08)

## 학습 가이드 활용 방법

- **점진적 학습**: 가장 일관된 학습 경험을 위해 모듈을 순서대로 진행하세요.
- **지식 체크포인트**: 각 섹션 후 자기 평가 질문을 활용하세요.
- **실습 연습**: 이론적 개념을 강화하기 위해 추천된 연습을 완료하세요.
- **추가 자료**: 관심 있는 주제에 대해 추가 자료를 탐색하세요.

## 학습 일정 추천

### 집중 학습 경로 (1주)

| 날짜 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Day 1-2 | 모듈 1: EdgeAI 기본 개념 | 6시간 |
| Day 3-4 | 모듈 2: SLM 기초 | 8시간 |
| Day 5 | 모듈 3: SLM 배포 | 3시간 |
| Day 6 | 모듈 8: Foundry Local Toolkit | 3시간 |

### 파트타임 학습 (3주)

| 주 | 학습 내용 | 예상 시간 |
|------|----------|-----------|
| Week 1 | 모듈 1: EdgeAI 기본 개념 | 6-7시간 |
| Week 2 | 모듈 2: SLM 기초 | 7-8시간 |
| Week 3 | 모듈 3: SLM 배포 (3시간) + 모듈 8: Foundry Local Toolkit (2-3시간) | 5-6시간 |

## 모듈 1: EdgeAI 기본 개념 및 변환

### 주요 학습 목표

- 클라우드 기반 AI와 엣지 기반 AI의 차이점 이해
- 자원 제약 환경을 위한 핵심 최적화 기술 숙달
- EdgeAI 기술의 실제 응용 사례 분석
- EdgeAI 프로젝트를 위한 개발 환경 설정

### 학습 초점 영역

#### 섹션 1: EdgeAI 기본 개념
- **우선 개념**: 
  - 엣지 vs 클라우드 컴퓨팅 패러다임
  - 모델 양자화 기술
  - 하드웨어 가속 옵션 (NPU, GPU, CPU)
  - 개인정보 보호 및 보안 장점

- **추가 자료**:
  - [TensorFlow Lite 문서](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 문서](https://docs.edgeimpulse.com)

#### 섹션 2: 실제 사례 연구
- **우선 개념**: 
  - Microsoft Phi & Mu 모델 생태계
  - 다양한 산업에서의 실제 구현
  - 배포 고려 사항

#### 섹션 3: 실용적 구현 가이드
- **우선 개념**: 
  - 개발 환경 설정
  - 양자화 및 최적화 도구
  - EdgeAI 구현 평가 방법

#### 섹션 4: 엣지 배포 하드웨어
- **우선 개념**: 
  - 하드웨어 플랫폼 비교
  - 특정 하드웨어를 위한 최적화 전략
  - 배포 고려 사항

### 자기 평가 질문

1. 클라우드 기반 AI와 엣지 기반 AI 구현을 비교하고 대조하세요.
2. 엣지 배포를 위한 모델 최적화의 주요 기술 세 가지를 설명하세요.
3. 엣지에서 AI 모델을 실행할 때의 주요 장점은 무엇인가요?
4. 모델을 양자화하는 과정과 성능에 미치는 영향을 설명하세요.
5. NPU, GPU, CPU와 같은 하드웨어 가속기가 EdgeAI 배포에 미치는 영향을 설명하세요.

### 실습 과제

1. **빠른 환경 설정**: 필수 패키지를 사용하여 최소 개발 환경 구성 (30분)
2. **모델 탐색**: 사전 학습된 소형 언어 모델 다운로드 및 분석 (1시간)
3. **기본 양자화**: 작은 모델에 간단한 양자화를 시도 (1시간)

## 모듈 2: 소형 언어 모델 기초

### 주요 학습 목표

- 다양한 SLM 계열의 아키텍처 원칙 이해
- 모델의 매개변수 규모에 따른 기능 비교
- 효율성, 기능, 배포 요구 사항에 따라 모델 평가
- 각 모델 계열에 적합한 사용 사례 인식

### 학습 초점 영역

#### 섹션 1: Microsoft Phi 모델 계열
- **우선 개념**: 
  - 설계 철학의 진화
  - 효율성 중심 아키텍처
  - 특화된 기능

#### 섹션 2: Qwen 계열
- **우선 개념**: 
  - 오픈 소스 기여
  - 확장 가능한 배포 옵션
  - 고급 추론 아키텍처

#### 섹션 3: Gemma 계열
- **우선 개념**: 
  - 연구 중심 혁신
  - 멀티모달 기능
  - 모바일 최적화

#### 섹션 4: BitNET 계열
- **우선 개념**: 
  - 1비트 양자화 기술
  - 추론 최적화 프레임워크
  - 지속 가능성 고려

#### 섹션 5: Microsoft Mu 모델
- **우선 개념**: 
  - 디바이스 중심 아키텍처
  - Windows와의 시스템 통합
  - 개인정보 보호 운영

#### 섹션 6: Phi-Silica
- **우선 개념**: 
  - NPU 최적화 아키텍처
  - 성능 지표
  - 개발자 통합

### 자기 평가 질문

1. Phi와 Qwen 모델 계열의 아키텍처 접근 방식을 비교하세요.
2. BitNET의 양자화 기술이 기존 양자화와 어떻게 다른지 설명하세요.
3. Windows 통합을 위한 Mu 모델의 독특한 장점은 무엇인가요?
4. Phi-Silica가 NPU 하드웨어를 활용하여 성능을 최적화하는 방법을 설명하세요.
5. 연결이 제한된 모바일 애플리케이션에 가장 적합한 모델 계열은 무엇이며 그 이유는 무엇인가요?

### 실습 과제

1. **모델 비교**: 두 가지 다른 SLM 모델의 빠른 벤치마크 수행 (1시간)
2. **간단한 텍스트 생성**: 소형 모델을 사용하여 기본 텍스트 생성 구현 (1시간)
3. **빠른 최적화**: 추론 속도를 개선하기 위한 최적화 기술 하나 적용 (1시간)

## 모듈 3: 소형 언어 모델 배포

### 주요 학습 목표

- 배포 제약 조건에 따라 적합한 모델 선택
- 다양한 배포 시나리오를 위한 최적화 기술 숙달
- SLM을 로컬 및 클라우드 환경에서 구현
- EdgeAI 애플리케이션을 위한 생산 준비 구성 설계

### 학습 초점 영역

#### 섹션 1: SLM 고급 학습
- **우선 개념**: 
  - 매개변수 분류 프레임워크
  - 고급 최적화 기술
  - 모델 획득 전략

#### 섹션 2: 로컬 환경 배포
- **우선 개념**: 
  - Ollama 플랫폼 배포
  - Microsoft Foundry 로컬 솔루션
  - 프레임워크 비교 분석

#### 섹션 3: 컨테이너화된 클라우드 배포
- **우선 개념**: 
  - vLLM 고성능 추론
  - 컨테이너 오케스트레이션
  - ONNX Runtime 구현

### 자기 평가 질문

1. 로컬 배포와 클라우드 배포를 선택할 때 고려해야 할 요소는 무엇인가요?
2. Ollama와 Microsoft Foundry Local을 배포 옵션으로 비교하세요.
3. SLM 배포를 위한 컨테이너화의 이점은 무엇인가요?
4. 엣지에 배포된 SLM의 주요 성능 지표는 무엇인가요?
5. 모델 선택부터 생산 구현까지의 완전한 배포 워크플로를 설명하세요.

### 실습 과제

1. **기본 로컬 배포**: Ollama를 사용하여 간단한 SLM 배포 (1시간)
2. **성능 확인**: 배포된 모델에서 빠른 벤치마크 실행 (30분)
3. **간단한 통합**: 배포된 모델을 사용하는 최소 애플리케이션 생성 (1시간)

## 모듈 4: 모델 형식 변환 및 양자화

### 주요 학습 목표

- 1비트에서 8비트 정밀도까지 고급 양자화 기술 숙달
- 형식 변환 전략 이해 (GGUF, ONNX)
- 6개 프레임워크(Llama.cpp, Olive, OpenVINO, MLX, 워크플로우 합성)를 활용한 최적화 구현
- Intel, Apple 및 크로스 플랫폼 하드웨어를 위한 생산 엣지 환경에서 최적화된 모델 배포

### 학습 초점 영역

#### 섹션 1: 양자화 기초
- **우선 개념**: 
  - 정밀도 분류 프레임워크
  - 성능 vs 정확도 트레이드오프
  - 메모리 사용량 최적화

#### 섹션 2: Llama.cpp 구현
- **우선 개념**: 
  - 크로스 플랫폼 배포
  - GGUF 형식 최적화
  - 하드웨어 가속 기술

#### 섹션 3: Microsoft Olive Suite
- **우선 개념**: 
  - 하드웨어 인식 최적화
  - 엔터프라이즈급 배포
  - 자동화된 최적화 워크플로

#### 섹션 4: OpenVINO Toolkit
- **우선 개념**: 
  - Intel 하드웨어 최적화
  - 신경망 압축 프레임워크 (NNCF)
  - 크로스 플랫폼 추론 배포
- OpenVINO GenAI를 활용한 LLM 배포

#### 섹션 5: Apple MLX 프레임워크
- **우선 개념**: 
  - Apple Silicon 최적화
  - 통합 메모리 아키텍처
  - LoRA 미세 조정 기능

#### 섹션 6: Edge AI 개발 워크플로우 종합
- **우선 개념**: 
  - 통합 워크플로우 아키텍처
  - 프레임워크 선택 의사결정 트리
  - 프로덕션 준비 상태 검증
  - 미래 대비 전략

### 자기 평가 질문

1. 다양한 정밀도 수준(1비트에서 8비트)에서 양자화 전략을 비교하세요.
2. Edge 배포를 위한 GGUF 형식의 장점을 설명하세요.
3. Microsoft Olive의 하드웨어 인식 최적화가 배포 효율성을 어떻게 향상시키는지 설명하세요.
4. 모델 압축을 위한 OpenVINO의 NNCF의 주요 이점은 무엇인가요?
5. Apple MLX가 통합 메모리 아키텍처를 활용하여 최적화를 수행하는 방법을 설명하세요.
6. 워크플로우 종합이 최적의 최적화 프레임워크를 선택하는 데 어떻게 도움이 되는지 설명하세요.

### 실습 과제

1. **모델 양자화**: 모델에 다양한 양자화 수준을 적용하고 결과를 비교하세요 (1시간)
2. **OpenVINO 최적화**: NNCF를 사용하여 Intel 하드웨어용 모델을 압축하세요 (1시간)
3. **프레임워크 비교**: 동일한 모델을 세 가지 다른 최적화 프레임워크에서 테스트하세요 (1시간)
4. **성능 벤치마킹**: 추론 속도와 메모리 사용량에 대한 최적화 영향을 측정하세요 (1시간)

## 모듈 5: SLMOps - 소형 언어 모델 운영

### 주요 학습 목표

- SLMOps 라이프사이클 관리 원칙 이해
- Edge 배포를 위한 증류 및 미세 조정 기술 숙달
- 모니터링을 포함한 프로덕션 배포 전략 구현
- 엔터프라이즈급 SLM 운영 및 유지보수 워크플로우 구축

### 학습 집중 영역

#### 섹션 1: SLMOps 소개
- **우선 개념**: 
  - AI 운영에서 SLMOps 패러다임 전환
  - 비용 효율성과 프라이버시 우선 아키텍처
  - 전략적 비즈니스 영향 및 경쟁 우위

#### 섹션 2: 모델 증류
- **우선 개념**: 
  - 지식 전이 기술
  - 2단계 증류 프로세스 구현
  - Azure ML 증류 워크플로우

#### 섹션 3: 미세 조정 전략
- **우선 개념**: 
  - 파라미터 효율적 미세 조정(PEFT)
  - LoRA 및 QLoRA 고급 방법
  - 다중 어댑터 훈련 및 하이퍼파라미터 최적화

#### 섹션 4: 프로덕션 배포
- **우선 개념**: 
  - 프로덕션을 위한 모델 변환 및 양자화
  - Foundry Local 배포 구성
  - 성능 벤치마킹 및 품질 검증

### 자기 평가 질문

1. SLMOps는 기존 MLOps와 어떻게 다른가요?
2. Edge 배포를 위한 모델 증류의 이점을 설명하세요.
3. 자원이 제한된 환경에서 SLM을 미세 조정할 때 주요 고려 사항은 무엇인가요?
4. Edge AI 애플리케이션을 위한 완전한 프로덕션 배포 파이프라인을 설명하세요.

### 실습 과제

1. **기본 증류**: 더 큰 교사 모델에서 작은 모델을 생성하세요 (1시간)
2. **미세 조정 실험**: 특정 도메인에 맞는 모델을 미세 조정하세요 (1시간)
3. **배포 파이프라인**: 모델 배포를 위한 기본 CI/CD 파이프라인을 설정하세요 (1시간)

## 모듈 6: SLM 에이전틱 시스템 - AI 에이전트와 함수 호출

### 주요 학습 목표

- 소형 언어 모델을 사용하여 Edge 환경에서 지능형 AI 에이전트 구축
- 체계적인 워크플로우를 활용한 함수 호출 기능 구현
- 표준화된 도구 상호작용을 위한 Model Context Protocol(MCP) 통합 숙달
- 최소한의 인간 개입으로 정교한 에이전틱 시스템 생성

### 학습 집중 영역

#### 섹션 1: AI 에이전트와 SLM 기초
- **우선 개념**: 
  - 에이전트 분류 프레임워크(반사형, 모델 기반, 목표 기반, 학습 에이전트)
  - SLM과 LLM의 트레이드오프 분석
  - Edge 특화 에이전트 설계 패턴
  - 에이전트 자원 최적화

#### 섹션 2: 소형 언어 모델에서의 함수 호출
- **우선 개념**: 
  - 체계적인 워크플로우 구현(의도 감지, JSON 출력, 외부 실행)
  - 플랫폼별 구현(Phi-4-mini, 선택된 Qwen 모델, Microsoft Foundry Local)
  - 고급 예제(다중 에이전트 협업, 동적 도구 선택)
  - 프로덕션 고려 사항(속도 제한, 감사 로그, 보안 조치)

#### 섹션 3: Model Context Protocol(MCP) 통합
- **우선 개념**: 
  - 프로토콜 아키텍처와 계층적 시스템 설계
  - 다중 백엔드 지원(Ollama 개발용, vLLM 프로덕션용)
  - 연결 프로토콜(STDIO 및 SSE 모드)
  - 실제 응용 사례(웹 자동화, 데이터 처리, API 통합)

### 자기 평가 질문

1. Edge AI 에이전트의 주요 아키텍처 고려 사항은 무엇인가요?
2. 함수 호출이 에이전트 기능을 어떻게 향상시키나요?
3. 에이전트 통신에서 Model Context Protocol의 역할을 설명하세요.

### 실습 과제

1. **간단한 에이전트**: 함수 호출 기능이 포함된 기본 AI 에이전트를 구축하세요 (1시간)
2. **MCP 통합**: 에이전트 애플리케이션에 MCP를 구현하세요 (30분)

## 모듈 7: EdgeAI 구현 샘플

### 주요 학습 목표

- Visual Studio Code용 AI Toolkit을 활용하여 포괄적인 EdgeAI 개발 워크플로우 숙달
- Windows AI Foundry 플랫폼 및 NPU 최적화 전략에 대한 전문 지식 습득
- 다양한 하드웨어 플랫폼 및 배포 시나리오에서 EdgeAI 구현
- 플랫폼별 최적화를 통해 프로덕션 준비된 EdgeAI 애플리케이션 구축

### 학습 집중 영역

#### 섹션 1: Visual Studio Code용 AI Toolkit
- **우선 개념**: 
  - VS Code 내에서 포괄적인 Edge AI 개발 환경
  - Edge 배포를 위한 모델 카탈로그 및 검색
  - 로컬 테스트, 최적화 및 에이전트 개발 워크플로우
  - Edge 시나리오에 대한 성능 모니터링 및 평가

#### 섹션 2: Windows EdgeAI 개발 가이드
- **우선 개념**: 
  - Windows AI Foundry 플랫폼 포괄적 개요
  - 효율적인 NPU 추론을 위한 Phi Silica API
  - 이미지 처리 및 OCR을 위한 Computer Vision API
  - 로컬 개발 및 테스트를 위한 Foundry Local CLI

#### 섹션 3: 플랫폼별 구현
- **우선 개념**: 
  - NVIDIA Jetson Orin Nano 배포(67 TOPS AI 성능)
  - .NET MAUI 및 ONNX Runtime GenAI를 활용한 모바일 애플리케이션
  - 클라우드-엣지 하이브리드 아키텍처를 활용한 Azure EdgeAI 솔루션
  - 범용 하드웨어 지원을 통한 Windows ML 최적화
  - 프라이버시 중심 RAG 구현을 포함한 Foundry Local 애플리케이션

### 자기 평가 질문

1. AI Toolkit이 EdgeAI 개발 워크플로우를 어떻게 간소화하나요?
2. 다양한 하드웨어 플랫폼 간 배포 전략을 비교하세요.
3. Edge 개발을 위한 Windows AI Foundry의 장점은 무엇인가요?
4. 현대 Edge AI 애플리케이션에서 NPU 최적화의 역할을 설명하세요.
5. Phi Silica API가 NPU 하드웨어를 활용하여 성능을 최적화하는 방법을 설명하세요.
6. 프라이버시 민감한 애플리케이션에서 로컬 배포와 클라우드 배포의 장점을 비교하세요.

### 실습 과제

1. **AI Toolkit 설정**: AI Toolkit을 구성하고 모델을 최적화하세요 (1시간)
2. **Windows AI Foundry**: Phi Silica API를 사용하여 간단한 Windows AI 애플리케이션을 구축하세요 (1시간)
3. **크로스 플랫폼 배포**: 동일한 모델을 두 개의 다른 플랫폼에 배포하세요 (1시간)
4. **NPU 최적화**: Windows AI Foundry 도구를 사용하여 NPU 성능을 테스트하세요 (30분)

## 모듈 8: Microsoft Foundry Local – 완전한 개발자 툴킷(현대화됨)

### 주요 학습 목표

- 최신 SDK 통합을 통해 Foundry Local 설치 및 구성
- 코디네이터 패턴을 활용한 고급 다중 에이전트 시스템 구현
- 자동 작업 기반 선택을 통한 지능형 모델 라우터 구축
- 포괄적인 모니터링을 통해 프로덕션 준비된 AI 솔루션 배포
- Azure AI Foundry와 통합하여 하이브리드 배포 시나리오 구현
- FoundryLocalManager 및 OpenAI 클라이언트를 활용한 최신 SDK 패턴 숙달

### 학습 집중 영역

#### 섹션 1: 현대적 설치 및 구성
- **우선 개념**: 
  - FoundryLocalManager SDK 통합
  - 자동 서비스 검색 및 상태 모니터링
  - 환경 기반 구성 패턴
  - 프로덕션 배포 고려 사항

#### 섹션 2: 고급 다중 에이전트 시스템
- **우선 개념**: 
  - 전문 에이전트를 활용한 코디네이터 패턴
  - 검색, 추론 및 실행 에이전트 전문화
  - 개선을 위한 피드백 루프 메커니즘
  - 성능 모니터링 및 통계 추적

#### 섹션 3: 지능형 모델 라우팅
- **우선 개념**: 
  - 키워드 기반 모델 선택 알고리즘
  - 다중 모델 지원(일반, 추론, 코드, 창의적)
  - 유연성을 위한 환경 변수 구성
  - 서비스 상태 확인 및 오류 처리

#### 섹션 4: 프로덕션 준비 구현
- **우선 개념**: 
  - 포괄적인 오류 처리 및 대체 메커니즘
  - 요청 모니터링 및 성능 추적
  - 벤치마크가 포함된 대화형 Jupyter 노트북 예제
  - 기존 애플리케이션과의 통합 패턴

### 자기 평가 질문

1. 현대적 FoundryLocalManager 접근 방식이 수동 REST 호출과 어떻게 다른가요?
2. 코디네이터 패턴이 전문 에이전트를 어떻게 조율하는지 설명하세요.
3. 지능형 라우터가 쿼리 내용에 따라 적합한 모델을 선택하는 방법을 설명하세요.
4. 프로덕션 준비된 AI 에이전트 시스템의 주요 구성 요소는 무엇인가요?
5. Foundry Local 서비스에 대한 포괄적인 상태 모니터링을 어떻게 구현하나요?
6. 현대화된 접근 방식과 기존 구현 패턴의 장점을 비교하세요.

### 실습 과제

1. **현대적 SDK 설정**: 자동 서비스 검색을 통해 FoundryLocalManager를 구성하세요 (30분)
2. **다중 에이전트 시스템**: 전문 에이전트를 활용한 고급 코디네이터를 실행하세요 (30분)
3. **지능형 라우팅**: 다양한 쿼리 유형으로 모델 라우터를 테스트하세요 (30분)
4. **대화형 탐색**: Jupyter 노트북을 사용하여 고급 기능을 탐색하세요 (45분)
5. **프로덕션 배포**: 모니터링 및 오류 처리 패턴을 구현하세요 (30분)
6. **하이브리드 통합**: Azure AI Foundry 대체 시나리오를 구성하세요 (30분)

## 시간 할당 가이드

20시간의 코스 타임라인을 최대한 활용할 수 있도록 다음과 같은 시간 할당 제안을 제공합니다:

| 활동 | 시간 할당 | 설명 |
|------|----------|------|
| 핵심 자료 읽기 | 9시간 | 각 모듈의 필수 개념에 집중 |
| 실습 과제 | 6시간 | 주요 기술의 실질적 구현 |
| 자기 평가 | 2시간 | 질문과 반성을 통해 이해도 테스트 |
| 미니 프로젝트 | 3시간 | 소규모 실질적 구현에 지식 적용 |

### 시간 제약에 따른 주요 집중 영역

**10시간만 있는 경우:**
- 모듈 1, 2, 3 완료(핵심 EdgeAI 개념)
- 각 모듈에서 최소한 하나의 실습 과제 수행
- 구현 세부 사항보다는 핵심 개념 이해에 집중

**20시간을 모두 활용할 수 있는 경우:**
- 모든 7개 모듈 완료
- 각 모듈의 주요 실습 과제 수행
- 모듈 7에서 미니 프로젝트 하나 완료
- 최소 2-3개의 추가 자료 탐색

**20시간 이상 있는 경우:**
- 모든 모듈을 세부적으로 완료
- 여러 미니 프로젝트 구축
- 모듈 4에서 고급 최적화 기술 탐색
- 모듈 5에서 프로덕션 배포 구현

## 필수 자료

다음은 제한된 학습 시간 동안 가장 큰 가치를 제공하는 신중히 선택된 자료입니다:

### 필독 문서
- [ONNX Runtime 시작하기](https://onnxruntime.ai/docs/get-started/with-python.html) - 가장 효율적인 모델 최적화 도구
- [Ollama 빠른 시작](https://github.com/ollama/ollama#get-started) - SLM을 로컬에서 빠르게 배포하는 방법
- [Microsoft Phi 모델 카드](https://huggingface.co/microsoft/phi-2) - 선도적인 Edge 최적화 모델 참고 자료
- [OpenVINO 문서](https://docs.openvino.ai/2025/index.html) - Intel의 포괄적인 최적화 툴킷
- [VS Code용 AI Toolkit](https://code.visualstudio.com/docs/intelligentapps/overview) - 통합 EdgeAI 개발 환경
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 특화 EdgeAI 개발 플랫폼

### 시간 절약 도구
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 빠른 모델 액세스 및 배포
- [Gradio](https://www.gradio.app/docs/interface) - AI 데모를 위한 빠른 UI 개발
- [Microsoft Olive](https://github.com/microsoft/Olive) - 간소화된 모델 최적화
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 효율적인 CPU 추론
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 신경망 압축 프레임워크
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 대형 언어 모델 배포 툴킷

## 진행 추적 템플릿

20시간 코스를 통해 학습 진행 상황을 추적하기 위해 이 간단한 템플릿을 사용하세요:

| 모듈 | 완료 날짜 | 소요 시간 | 주요 학습 내용 |
|------|----------|----------|---------------|
| 모듈 1: EdgeAI 기본 | | | |
| 모듈 2: SLM 기초 | | | |
| 모듈 3: SLM 배포 | | | |
| 모듈 4: 모델 최적화 | | | |
| 모듈 5: SLMOps | | | |
| 모듈 6: AI 에이전트 | | | |
| 모듈 7: 개발 도구 | | | |
| 모듈 8: Foundry Local 툴킷 | | | |
| 실습 과제 | | | |
| 미니 프로젝트 | | | |

## 미니 프로젝트 아이디어

EdgeAI 개념을 연습하기 위해 다음 프로젝트 중 하나를 완료해 보세요. (각 프로젝트는 2~4시간 소요 예정):

### 초급 프로젝트 (각 2~3시간 소요)
1. **엣지 텍스트 어시스턴트**: 소형 언어 모델을 사용하여 간단한 오프라인 텍스트 완성 도구 만들기
2. **모델 비교 대시보드**: 다양한 SLM의 성능 지표를 시각화하는 기본 대시보드 구축
3. **최적화 실험**: 동일한 기본 모델에서 다양한 양자화 수준의 영향을 측정하기

### 중급 프로젝트 (각 3~4시간 소요)
4. **AI 툴킷 워크플로우**: VS Code AI Toolkit을 사용하여 모델을 처음부터 끝까지 최적화 및 배포하기
5. **Windows AI Foundry 애플리케이션**: Phi Silica API와 NPU 최적화를 활용하여 Windows 앱 만들기
6. **크로스 플랫폼 배포**: 동일한 최적화 모델을 Windows(OpenVINO)와 모바일(.NET MAUI)에 배포하기
7. **함수 호출 에이전트**: 엣지 시나리오를 위한 함수 호출 기능을 갖춘 AI 에이전트 구축

### 고급 통합 프로젝트 (각 4~5시간 소요)
8. **OpenVINO 최적화 파이프라인**: NNCF와 GenAI 툴킷을 사용하여 완전한 모델 최적화 구현
9. **SLMOps 파이프라인**: 모델의 전체 라이프사이클을 훈련부터 엣지 배포까지 구현하기
10. **다중 모델 엣지 시스템**: 엣지 하드웨어에서 협력하는 여러 전문화된 모델 배포
11. **MCP 통합 시스템**: Model Context Protocol을 사용하여 도구 상호작용을 위한 에이전틱 시스템 구축

## 참고 자료

- Microsoft Learn (Foundry Local)
  - 개요: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - 시작하기: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI 참조: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - 추론 SDK와 통합: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI 사용 방법: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Hugging Face 모델 컴파일: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - 개요: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - 에이전트(개요): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- 최적화 및 추론 도구
  - Microsoft Olive (문서): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (시작하기): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive 통합: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (문서): https://docs.openvino.ai/2025/index.html
  - Apple MLX (문서): https://ml-explore.github.io/mlx/build/html/index.html
- 배포 프레임워크 및 모델
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (문서): https://docs.vllm.ai/
  - Ollama (빠른 시작): https://github.com/ollama/ollama#get-started
- 개발 도구 (Windows 및 VS Code)
  - VS Code용 AI Toolkit: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (개요): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## 학습 커뮤니티

토론에 참여하고 다른 학습자들과 연결하세요:
- [EdgeAI for Beginners 저장소](https://github.com/microsoft/edgeai-for-beginners/discussions)의 GitHub Discussions
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 결론

EdgeAI는 인공지능 구현의 최전선에 있으며, 강력한 기능을 장치에 직접 제공하면서 프라이버시, 지연 시간, 연결성에 대한 중요한 문제를 해결합니다. 이 20시간 과정은 EdgeAI 기술을 즉시 활용할 수 있는 필수 지식과 실용적인 기술을 제공합니다.

이 과정은 가장 중요한 개념에 집중하여 간결하게 설계되었으며, 과도한 시간 투자 없이도 귀중한 전문 지식을 빠르게 얻을 수 있도록 합니다. 간단한 예제를 활용한 실습이 학습한 내용을 강화하는 핵심이라는 점을 기억하세요.

즐거운 학습 되세요!

---

