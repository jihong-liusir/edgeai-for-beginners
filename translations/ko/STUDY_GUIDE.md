<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T19:03:37+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ko"
}
-->
# EdgeAI 초보자를 위한 학습 경로 및 학습 일정

### 집중 학습 경로 (1주)

| 날짜 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Day 0 | 모듈 0: EdgeAI 소개 | 1-2시간 |
| Day 1 | 모듈 1: EdgeAI 기본 개념 | 3시간 |
| Day 2 | 모듈 2: SLM 기초 | 3시간 |
| Day 3 | 모듈 3: SLM 배포 | 2시간 |
| Day 4-5 | 모듈 4: 모델 최적화 (6개 프레임워크) | 4시간 |
| Day 6 | 모듈 5: SLMOps | 3시간 |
| Day 7 | 모듈 6-7: AI 에이전트 및 개발 도구 | 4시간 |
| Day 8 | 모듈 8: Foundry Local Toolkit (현대적 구현) | 1시간 |

### 집중 학습 경로 (2주)

| 날짜 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Day 1-2 | 모듈 1: EdgeAI 기본 개념 | 3시간 |
| Day 3-4 | 모듈 2: SLM 기초 | 3시간 |
| Day 5-6 | 모듈 3: SLM 배포 | 2시간 |
| Day 7-8 | 모듈 4: 모델 최적화 | 4시간 |
| Day 9-10 | 모듈 5: SLMOps | 3시간 |
| Day 11-12 | 모듈 6: AI 에이전트 | 2시간 |
| Day 13-14 | 모듈 7: 개발 도구 | 3시간 |

### 파트타임 학습 (4주)

| 주 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Week 1 | 모듈 1-2: 기본 개념 및 SLM 기초 | 6시간 |
| Week 2 | 모듈 3-4: 배포 및 최적화 | 6시간 |
| Week 3 | 모듈 5-6: SLMOps 및 AI 에이전트 | 5시간 |
| Week 4 | 모듈 7: 개발 도구 및 통합 | 3시간 |

| 날짜 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Day 0 | 모듈 0: EdgeAI 소개 | 1-2시간 |
| Day 1-2 | 모듈 1: EdgeAI 기본 개념 | 3시간 |
| Day 3-4 | 모듈 2: SLM 기초 | 3시간 |
| Day 5-6 | 모듈 3: SLM 배포 | 2시간 |
| Day 7-8 | 모듈 4: 모델 최적화 | 4시간 |
| Day 9-10 | 모듈 5: SLMOps | 3시간 |
| Day 11-12 | 모듈 6: SLM 에이전트 시스템 | 2시간 |
| Day 13-14 | 모듈 7: EdgeAI 구현 샘플 | 2시간 |

| 모듈 | 완료 날짜 | 소요 시간 | 주요 학습 내용 |
|------|----------|----------|---------------|
| 모듈 0: EdgeAI 소개 | | | |
| 모듈 1: EdgeAI 기본 개념 | | | |
| 모듈 2: SLM 기초 | | | |
| 모듈 3: SLM 배포 | | | |
| 모듈 4: 모델 최적화 (6개 프레임워크) | | | |
| 모듈 5: SLMOps | | | |
| 모듈 6: SLM 에이전트 시스템 | | | |
| 모듈 7: EdgeAI 구현 샘플 | | | |
| 실습 과제 | | | |
| 미니 프로젝트 | | | |

### 파트타임 학습 (4주)

| 주 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Week 1 | 모듈 1-2: 기본 개념 및 SLM 기초 | 6시간 |
| Week 2 | 모듈 3-4: 배포 및 최적화 | 6시간 |
| Week 3 | 모듈 5-6: SLMOps 및 AI 에이전트 | 5시간 |
| Week 4 | 모듈 7: 개발 도구 및 통합 | 3시간 |

## 소개

EdgeAI 초보자 학습 가이드에 오신 것을 환영합니다! 이 문서는 학습 자료를 효과적으로 탐색하고 학습 경험을 극대화할 수 있도록 설계되었습니다. 구조화된 학습 경로, 추천 학습 일정, 주요 개념 요약, 그리고 Edge AI 기술에 대한 이해를 심화할 수 있는 추가 자료를 제공합니다.

이 과정은 EdgeAI에 대한 필수 지식을 시간 효율적으로 전달하는 20시간의 간결한 과정으로, 바쁜 전문가와 학생들이 이 신흥 분야에서 실용적인 기술을 빠르게 습득할 수 있도록 설계되었습니다.

## 과정 개요

이 과정은 다음과 같은 8개의 포괄적인 모듈로 구성되어 있습니다:

0. **EdgeAI 소개** - 산업 응용 및 학습 목표를 설정하는 기초
1. **EdgeAI 기본 개념 및 변환** - 핵심 개념과 기술 변화 이해
2. **소형 언어 모델(SLM) 기초** - 다양한 SLM 계열과 그 아키텍처 탐구
3. **소형 언어 모델 배포** - 실질적인 배포 전략 구현
4. **모델 형식 변환 및 양자화** - OpenVINO를 포함한 6개 프레임워크를 활용한 고급 최적화
5. **SLMOps - 소형 언어 모델 운영** - 생산 수명 주기 관리 및 배포
6. **SLM 에이전트 시스템** - AI 에이전트, 함수 호출, 모델 컨텍스트 프로토콜
7. **EdgeAI 구현 샘플** - AI 툴킷, Windows 개발 및 플랫폼별 구현
8. **Microsoft Foundry Local – 완전한 개발자 툴킷** - 하이브리드 Azure 통합을 통한 로컬 우선 개발 (모듈 08)

## 학습 가이드 사용 방법

- **점진적 학습**: 가장 일관된 학습 경험을 위해 모듈을 순서대로 진행하세요.
- **지식 체크포인트**: 각 섹션 후 자기 평가 질문을 활용하세요.
- **실습 연습**: 이론적 개념을 강화하기 위해 제안된 연습을 완료하세요.
- **추가 자료**: 관심 있는 주제에 대해 추가 자료를 탐색하세요.

## 학습 일정 추천

### 집중 학습 경로 (1주)

| 날짜 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Day 0 | 모듈 0: EdgeAI 소개 | 1-2시간 |
| Day 1-2 | 모듈 1: EdgeAI 기본 개념 | 6시간 |
| Day 3-4 | 모듈 2: SLM 기초 | 8시간 |
| Day 5 | 모듈 3: SLM 배포 | 3시간 |
| Day 6 | 모듈 8: Foundry Local Toolkit | 3시간 |

### 파트타임 학습 (3주)

| 주 | 학습 내용 | 예상 소요 시간 |
|------|----------|----------------|
| Week 1 | 모듈 0: 소개 + 모듈 1: EdgeAI 기본 개념 | 7-9시간 |
| Week 2 | 모듈 2: SLM 기초 | 7-8시간 |
| Week 3 | 모듈 3: SLM 배포 (3시간) + 모듈 8: Foundry Local Toolkit (2-3시간) | 5-6시간 |

## 모듈 0: EdgeAI 소개

### 주요 학습 목표

- Edge AI가 무엇인지 이해하고 오늘날 기술 환경에서 왜 중요한지 파악하기
- Edge AI로 변혁된 주요 산업과 특정 사용 사례 식별하기
- 소형 언어 모델(SLM)이 엣지 배포에 제공하는 이점 이해하기
- 전체 과정에 대한 명확한 학습 기대치와 결과 설정하기
- Edge AI 분야에서의 경력 기회와 필요한 기술 요구 사항 인식하기

### 학습 초점 영역

#### 섹션 1: Edge AI 패러다임 및 정의
- **우선 개념**: 
  - Edge AI와 전통적인 클라우드 AI 처리 비교
  - 하드웨어, 모델 최적화, 비즈니스 요구의 융합
  - 실시간, 개인정보 보호, 비용 효율적인 AI 배포

#### 섹션 2: 산업 응용
- **우선 개념**: 
  - 제조 및 Industry 4.0: 예측 유지보수 및 품질 관리
  - 헬스케어: 진단 영상 및 환자 모니터링
  - 자율 시스템: 자율 주행 차량 및 교통
  - 스마트 시티: 교통 관리 및 공공 안전
  - 소비자 기술: 스마트폰, 웨어러블, 스마트 홈

#### 섹션 3: 소형 언어 모델 기초
- **우선 개념**: 
  - SLM 특성과 성능 비교
  - 파라미터 효율성과 기능 간의 균형
  - 엣지 배포 제약 및 최적화 전략

#### 섹션 4: 학습 프레임워크 및 경력 경로
- **우선 개념**: 
  - 과정 구조와 점진적 숙달 접근법
  - 기술적 기술과 실질적 구현 목표
  - 경력 발전 기회와 산업 응용

### 자기 평가 질문

1. Edge AI를 가능하게 한 세 가지 주요 기술 트렌드는 무엇인가요?
2. Edge AI와 클라우드 기반 AI의 장점과 과제를 비교하세요.
3. Edge AI가 중요한 비즈니스 가치를 제공하는 세 가지 산업을 말하고 이유를 설명하세요.
4. 소형 언어 모델이 실제 배포에서 Edge AI를 실현 가능하게 만드는 방법은 무엇인가요?
5. 이 과정에서 개발할 주요 기술적 기술은 무엇인가요?
6. 이 과정에서 사용되는 네 단계 학습 접근법을 설명하세요.

### 실습 과제

1. **산업 연구**: 한 가지 산업 응용을 선택하고 실제 Edge AI 구현 사례를 조사하세요 (30분)
2. **모델 탐색**: Hugging Face에서 제공되는 소형 언어 모델을 탐색하고 파라미터 수와 기능을 비교하세요 (30분)
3. **학습 계획**: 전체 과정 구조를 검토하고 개인 학습 일정을 만드세요 (15분)

### 추가 자료

- [Edge AI 시장 개요 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [소형 언어 모델 개요 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Edge Computing Foundation](https://www.edgecomputing.org/)

## 모듈 1: EdgeAI 기본 개념 및 변환

### 주요 학습 목표

- 클라우드 기반 AI와 엣지 기반 AI의 차이점 이해하기
- 자원 제약 환경을 위한 핵심 최적화 기술 숙달하기
- EdgeAI 기술의 실제 응용 사례 분석하기
- EdgeAI 프로젝트를 위한 개발 환경 설정하기

### 학습 초점 영역

#### 섹션 1: EdgeAI 기본 개념
- **우선 개념**: 
  - 엣지 vs. 클라우드 컴퓨팅 패러다임
  - 모델 양자화 기술
  - 하드웨어 가속 옵션 (NPU, GPU, CPU)
  - 개인정보 보호 및 보안 이점

- **추가 자료**:
  - [TensorFlow Lite 문서](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 문서](https://docs.edgeimpulse.com)

#### 섹션 2: 실제 사례 연구
- **우선 개념**: 
  - Microsoft Phi & Mu 모델 생태계
  - 다양한 산업에서의 실질적 구현
  - 배포 고려 사항

#### 섹션 3: 실질적 구현 가이드
- **우선 개념**: 
  - 개발 환경 설정
  - 양자화 및 최적화 도구
  - EdgeAI 구현 평가 방법

#### 섹션 4: 엣지 배포 하드웨어
- **우선 개념**: 
  - 하드웨어 플랫폼 비교
  - 특정 하드웨어에 대한 최적화 전략
  - 배포 고려 사항

### 자기 평가 질문

1. 클라우드 기반 AI와 엣지 기반 AI 구현을 비교하세요.
2. 엣지 배포를 위한 모델 최적화의 세 가지 주요 기술을 설명하세요.
3. 엣지에서 AI 모델을 실행하는 주요 장점은 무엇인가요?
4. 모델을 양자화하는 과정과 성능에 미치는 영향을 설명하세요.
5. NPU, GPU, CPU와 같은 하드웨어 가속기가 EdgeAI 배포에 미치는 영향을 설명하세요.

### 실습 과제

1. **빠른 환경 설정**: 필수 패키지를 사용하여 최소 개발 환경을 설정하세요 (30분)
2. **모델 탐색**: 사전 학습된 소형 언어 모델을 다운로드하고 분석하세요 (1시간)
3. **기본 양자화**: 작은 모델에 간단한 양자화를 시도하세요 (1시간)

## 모듈 2: 소형 언어 모델 기초

### 주요 학습 목표

- 다양한 SLM 계열의 아키텍처 원칙 이해하기
- 다양한 파라미터 규모에서 모델 기능 비교하기
- 효율성, 기능, 배포 요구 사항에 따라 모델 평가하기
- 각 모델 계열에 적합한 사용 사례 인식하기

### 학습 초점 영역

#### 섹션 1: Microsoft Phi 모델 계열
- **우선 개념**: 
  - 설계 철학의 진화
  - 효율성 중심 아키텍처
  - 특화된 기능

#### 섹션 2: Qwen 계열
- **우선 개념**: 
  - 오픈 소스 기여
  - 확장 가능한 배포 옵션
  - 고급 추론 아키텍처

#### 섹션 3: Gemma 계열
- **우선 개념**: 
  - 연구 중심 혁신
  - 멀티모달 기능
  - 모바일 최적화

#### 섹션 4: BitNET 계열
- **우선 개념**: 
  - 1비트 양자화 기술
  - 추론 최적화 프레임워크
  - 지속 가능성 고려 사항

#### 섹션 5: Microsoft Mu 모델
- **우선 개념**: 
  - 디바이스 중심 아키텍처
  - Windows와의 시스템 통합
  - 개인정보 보호 운영

#### 섹션 6: Phi-Silica
- **우선 개념**: 
  - NPU 최적화 아키텍처
  - 성능 지표
  - 개발자 통합

### 자기 평가 질문

1. Phi와 Qwen 모델 계열의 아키텍처 접근 방식을 비교하세요.
2. BitNET의 양자화 기술이 기존 양자화와 어떻게 다른지 설명하세요.
3. Windows 통합을 위한 Mu 모델의 독특한 장점은 무엇인가요?
4. Phi-Silica가 NPU 하드웨어를 활용하여 성능을 최적화하는 방법을 설명하세요.
5. 연결이 제한된 모바일 애플리케이션에 가장 적합한 모델 계열은 무엇이며, 그 이유는 무엇인가요?

### 실습 과제

1. **모델 비교**: 두 가지 다른 SLM 모델의 간단한 벤치마크 수행 (1시간)
2. **간단한 텍스트 생성**: 작은 모델을 사용하여 텍스트 생성의 기본 구현 (1시간)
3. **빠른 최적화**: 추론 속도를 개선하기 위한 최적화 기술 적용 (1시간)

## 모듈 3: 소형 언어 모델 배포

### 주요 학습 목표

- 배포 제약 조건에 따라 적합한 모델 선택
- 다양한 배포 시나리오에 대한 최적화 기술 숙달
- 로컬 및 클라우드 환경에서 SLM 구현
- EdgeAI 애플리케이션을 위한 프로덕션 준비 구성 설계

### 학습 집중 영역

#### 섹션 1: SLM 고급 학습
- **우선 개념**: 
  - 매개변수 분류 프레임워크
  - 고급 최적화 기술
  - 모델 획득 전략

#### 섹션 2: 로컬 환경 배포
- **우선 개념**: 
  - Ollama 플랫폼 배포
  - Microsoft Foundry 로컬 솔루션
  - 프레임워크 비교 분석

#### 섹션 3: 컨테이너화된 클라우드 배포
- **우선 개념**: 
  - vLLM 고성능 추론
  - 컨테이너 오케스트레이션
  - ONNX Runtime 구현

### 자기 평가 질문

1. 로컬 배포와 클라우드 배포를 선택할 때 고려해야 할 요소는 무엇인가요?
2. Ollama와 Microsoft Foundry Local을 배포 옵션으로 비교하세요.
3. SLM 배포를 위한 컨테이너화의 이점은 무엇인가요?
4. 엣지에 배포된 SLM의 주요 성능 지표는 무엇인가요?
5. 모델 선택부터 프로덕션 구현까지의 완전한 배포 워크플로를 설명하세요.

### 실습 과제

1. **기본 로컬 배포**: Ollama를 사용하여 간단한 SLM 배포 (1시간)
2. **성능 확인**: 배포된 모델에 대한 간단한 벤치마크 실행 (30분)
3. **간단한 통합**: 배포된 모델을 사용하는 최소 애플리케이션 생성 (1시간)

## 모듈 4: 모델 형식 변환 및 양자화

### 주요 학습 목표

- 1비트에서 8비트 정밀도까지의 고급 양자화 기술 숙달
- 형식 변환 전략 이해 (GGUF, ONNX)
- 여섯 가지 프레임워크(Llama.cpp, Olive, OpenVINO, MLX, 워크플로우 합성)에서 최적화 구현
- Intel, Apple 및 크로스 플랫폼 하드웨어를 위한 프로덕션 엣지 환경에서 최적화된 모델 배포

### 학습 집중 영역

#### 섹션 1: 양자화 기초
- **우선 개념**: 
  - 정밀도 분류 프레임워크
  - 성능 대 정확도 트레이드오프
  - 메모리 풋프린트 최적화

#### 섹션 2: Llama.cpp 구현
- **우선 개념**: 
  - 크로스 플랫폼 배포
  - GGUF 형식 최적화
  - 하드웨어 가속 기술

#### 섹션 3: Microsoft Olive Suite
- **우선 개념**: 
  - 하드웨어 인식 최적화
  - 엔터프라이즈급 배포
  - 자동화된 최적화 워크플로우

#### 섹션 4: OpenVINO Toolkit
- **우선 개념**: 
  - Intel 하드웨어 최적화
  - Neural Network Compression Framework (NNCF)
  - 크로스 플랫폼 추론 배포
  - OpenVINO GenAI를 활용한 LLM 배포

#### 섹션 5: Apple MLX Framework
- **우선 개념**: 
  - Apple Silicon 최적화
  - 통합 메모리 아키텍처
  - LoRA 미세 조정 기능

#### 섹션 6: Edge AI 개발 워크플로우 합성
- **우선 개념**: 
  - 통합 워크플로우 아키텍처
  - 프레임워크 선택 의사 결정 트리
  - 프로덕션 준비 검증
  - 미래 대비 전략

### 자기 평가 질문

1. 다양한 정밀도 수준(1비트에서 8비트)에서 양자화 전략을 비교하세요.
2. 엣지 배포를 위한 GGUF 형식의 장점을 설명하세요.
3. Microsoft Olive의 하드웨어 인식 최적화가 배포 효율성을 어떻게 개선하나요?
4. OpenVINO의 NNCF가 모델 압축에 제공하는 주요 이점은 무엇인가요?
5. Apple MLX가 통합 메모리 아키텍처를 활용하여 최적화를 수행하는 방법을 설명하세요.
6. 워크플로우 합성이 최적의 최적화 프레임워크 선택에 어떻게 도움이 되나요?

### 실습 과제

1. **모델 양자화**: 모델에 다양한 양자화 수준을 적용하고 결과 비교 (1시간)
2. **OpenVINO 최적화**: Intel 하드웨어를 위한 NNCF를 사용하여 모델 압축 (1시간)
3. **프레임워크 비교**: 동일한 모델을 세 가지 다른 최적화 프레임워크에서 테스트 (1시간)
4. **성능 벤치마킹**: 추론 속도와 메모리 사용량에 대한 최적화 영향을 측정 (1시간)

## 모듈 5: SLMOps - 소형 언어 모델 운영

### 주요 학습 목표

- SLMOps 라이프사이클 관리 원칙 이해
- 엣지 배포를 위한 증류 및 미세 조정 기술 숙달
- 모니터링을 포함한 프로덕션 배포 전략 구현
- 엔터프라이즈급 SLM 운영 및 유지보수 워크플로우 구축

### 학습 집중 영역

#### 섹션 1: SLMOps 소개
- **우선 개념**: 
  - SLMOps의 AI 운영 패러다임 변화
  - 비용 효율성과 프라이버시 우선 아키텍처
  - 전략적 비즈니스 영향 및 경쟁 우위

#### 섹션 2: 모델 증류
- **우선 개념**: 
  - 지식 전이 기술
  - 2단계 증류 프로세스 구현
  - Azure ML 증류 워크플로우

#### 섹션 3: 미세 조정 전략
- **우선 개념**: 
  - 매개변수 효율적 미세 조정(PEFT)
  - LoRA 및 QLoRA 고급 방법
  - 다중 어댑터 학습 및 하이퍼파라미터 최적화

#### 섹션 4: 프로덕션 배포
- **우선 개념**: 
  - 프로덕션을 위한 모델 변환 및 양자화
  - Foundry Local 배포 구성
  - 성능 벤치마킹 및 품질 검증

### 자기 평가 질문

1. SLMOps가 기존 MLOps와 어떻게 다른가요?
2. 엣지 배포를 위한 모델 증류의 이점을 설명하세요.
3. 자원이 제한된 환경에서 SLM을 미세 조정할 때 고려해야 할 주요 사항은 무엇인가요?
4. 엣지 AI 애플리케이션을 위한 완전한 프로덕션 배포 파이프라인을 설명하세요.

### 실습 과제

1. **기본 증류**: 더 큰 교사 모델에서 더 작은 모델 생성 (1시간)
2. **미세 조정 실험**: 특정 도메인에 맞는 모델 미세 조정 (1시간)
3. **배포 파이프라인**: 모델 배포를 위한 기본 CI/CD 파이프라인 설정 (1시간)

## 모듈 6: SLM 에이전트 시스템 - AI 에이전트 및 함수 호출

### 주요 학습 목표

- 소형 언어 모델을 사용하여 엣지 환경을 위한 지능형 AI 에이전트 구축
- 체계적인 워크플로우를 통한 함수 호출 기능 구현
- 표준화된 도구 상호작용을 위한 Model Context Protocol(MCP) 통합 숙달
- 최소한의 인간 개입으로 정교한 에이전트 시스템 생성

### 학습 집중 영역

#### 섹션 1: AI 에이전트 및 SLM 기초
- **우선 개념**: 
  - 에이전트 분류 프레임워크(반사형, 모델 기반, 목표 기반, 학습 에이전트)
  - SLM과 LLM의 트레이드오프 분석
  - 엣지 특화 에이전트 설계 패턴
  - 에이전트 자원 최적화

#### 섹션 2: 소형 언어 모델에서의 함수 호출
- **우선 개념**: 
  - 체계적인 워크플로우 구현(의도 감지, JSON 출력, 외부 실행)
  - 플랫폼별 구현(Phi-4-mini, 선택된 Qwen 모델, Microsoft Foundry Local)
  - 고급 예제(다중 에이전트 협업, 동적 도구 선택)
  - 프로덕션 고려 사항(속도 제한, 감사 로그, 보안 조치)

#### 섹션 3: Model Context Protocol(MCP) 통합
- **우선 개념**: 
  - 프로토콜 아키텍처 및 계층 시스템 설계
  - 다중 백엔드 지원(Ollama 개발용, vLLM 프로덕션용)
  - 연결 프로토콜(STDIO 및 SSE 모드)
  - 실제 응용 프로그램(웹 자동화, 데이터 처리, API 통합)

### 자기 평가 질문

1. 엣지 AI 에이전트를 위한 주요 아키텍처 고려 사항은 무엇인가요?
2. 함수 호출이 에이전트 기능을 어떻게 향상시키나요?
3. 에이전트 통신에서 Model Context Protocol의 역할을 설명하세요.

### 실습 과제

1. **간단한 에이전트**: 함수 호출을 포함한 기본 AI 에이전트 구축 (1시간)
2. **MCP 통합**: 에이전트 애플리케이션에서 MCP 구현 (30분)

## 워크숍: 실습 학습 경로

### 주요 학습 목표

- Foundry Local SDK와 모범 사례를 사용하여 프로덕션 준비된 AI 애플리케이션 구축
- 포괄적인 오류 처리 및 사용자 피드백 패턴 구현
- 품질 평가 및 성능 모니터링을 포함한 RAG 파이프라인 생성
- 조정자 패턴을 사용한 다중 에이전트 시스템 개발
- 작업 기반 모델 선택을 위한 지능형 모델 라우팅 숙달
- 프라이버시를 보호하는 아키텍처를 사용하여 로컬 우선 AI 솔루션 배포

### 학습 집중 영역

#### 세션 01: Foundry Local 시작하기
- **우선 개념**:
  - FoundryLocalManager SDK 통합 및 자동 서비스 검색
  - 기본 및 스트리밍 채팅 구현
  - 오류 처리 패턴 및 사용자 피드백
  - 환경 기반 구성

#### 세션 02: RAG를 활용한 AI 솔루션 구축
- **우선 개념**:
  - 문장 변환기를 사용한 인메모리 벡터 임베딩
  - RAG 파이프라인 구현(검색 → 생성)
  - RAGAS 메트릭을 사용한 품질 평가
  - 선택적 종속성에 대한 안전한 가져오기

#### 세션 03: 오픈 소스 모델
- **우선 개념**:
  - 다중 모델 벤치마킹 전략
  - 지연 시간 및 처리량 측정
  - 우아한 성능 저하 및 오류 복구
  - 모델 계열 간 성능 비교

#### 세션 04: 최첨단 모델
- **우선 개념**:
  - SLM과 LLM 비교 방법론
  - 타입 힌트 및 포괄적인 출력 형식화
  - 모델별 오류 처리
  - 분석을 위한 구조화된 결과

#### 세션 05: AI 기반 에이전트
- **우선 개념**:
  - 조정자 패턴을 사용한 다중 에이전트 오케스트레이션
  - 에이전트 메모리 관리 및 상태 추적
  - 파이프라인 오류 처리 및 단계별 로깅
  - 성능 모니터링 및 통계

#### 세션 06: 도구로서의 모델
- **우선 개념**:
  - 의도 감지 및 패턴 매칭
  - 키워드 기반 모델 라우팅 알고리즘
  - 다단계 파이프라인(계획 → 실행 → 수정)
  - 포괄적인 함수 문서화

### 자기 평가 질문

1. FoundryLocalManager가 수동 REST 호출에 비해 서비스 관리를 어떻게 간소화하나요?
2. 문장 변환기와 같은 선택적 종속성에 대한 가져오기 가드의 중요성을 설명하세요.
3. 다중 모델 벤치마킹에서 우아한 성능 저하를 보장하는 전략은 무엇인가요?
4. 조정자 패턴이 여러 전문 에이전트를 어떻게 오케스트레이션하나요?
5. 지능형 모델 라우터의 구성 요소를 설명하세요.
6. 프로덕션 준비 오류 처리의 주요 요소는 무엇인가요?

### 실습 과제

1. **채팅 애플리케이션**: 오류 처리를 포함한 스트리밍 채팅 구현 (45분)
2. **RAG 파이프라인**: 품질 평가를 포함한 최소 RAG 구축 (1시간)
3. **모델 벤치마킹**: 성능에 대해 3개 이상의 모델 비교 (1시간)
4. **다중 에이전트 시스템**: 2개의 전문 에이전트를 포함한 조정자 생성 (1.5시간)
5. **지능형 라우터**: 작업 기반 모델 선택 구축 (1시간)
6. **프로덕션 배포**: 모니터링 및 포괄적인 오류 처리 추가 (45분)

### 시간 할당

**집중 학습(1주)**:
- 1일차: 세션 01-02(채팅 + RAG) - 3시간
- 2일차: 세션 03-04(벤치마킹 + 비교) - 3시간
- 3일차: 세션 05-06(에이전트 + 라우팅) - 3시간
- 4일차: 실습 과제 및 검증 - 2시간

**파트타임 학습(2주)**:
- 1주차: 세션 01-03(총 6시간)
- 2주차: 세션 04-06 + 실습 과제(총 5시간)

## 모듈 7: EdgeAI 구현 샘플

### 주요 학습 목표

- Visual Studio Code용 AI Toolkit을 활용하여 포괄적인 EdgeAI 개발 워크플로우 숙달
- Windows AI Foundry 플랫폼 및 NPU 최적화 전략에 대한 전문성 확보
- 다양한 하드웨어 플랫폼 및 배포 시나리오에서 EdgeAI 구현
- 플랫폼별 최적화를 통해 프로덕션 준비된 EdgeAI 애플리케이션 구축

### 학습 집중 영역

#### 섹션 1: Visual Studio Code용 AI Toolkit
- **우선 개념**: 
  - VS Code 내에서 포괄적인 Edge AI 개발 환경
  - 엣지 배포를 위한 모델 카탈로그 및 검색
  - 로컬 테스트, 최적화 및 에이전트 개발 워크플로우
  - 엣지 시나리오에 대한 성능 모니터링 및 평가

#### 섹션 2: Windows EdgeAI 개발 가이드
- **우선 개념**: 
  - Windows AI Foundry 플랫폼의 포괄적인 개요
  - 효율적인 NPU 추론을 위한 Phi Silica API
  - 이미지 처리 및 OCR을 위한 컴퓨터 비전 API
  - 로컬 개발 및 테스트를 위한 Foundry Local CLI

#### 섹션 3: 플랫폼별 구현
- **우선 개념**: 
  - NVIDIA Jetson Orin Nano 배포(67 TOPS AI 성능)
  - .NET MAUI 및 ONNX Runtime GenAI를 활용한 모바일 애플리케이션
  - 클라우드-엣지 하이브리드 아키텍처를 활용한 Azure EdgeAI 솔루션
  - 범용 하드웨어 지원을 통한 Windows ML 최적화
  - 프라이버시 중심 RAG 구현을 포함한 Foundry Local 애플리케이션

### 자기 평가 질문

1. AI Toolkit이 EdgeAI 개발 워크플로우를 어떻게 간소화하나요?
2. 다양한 하드웨어 플랫폼 간 배포 전략을 비교하세요.
3. 엣지 개발을 위한 Windows AI Foundry의 장점은 무엇인가요?
4. 현대 엣지 AI 애플리케이션에서 NPU 최적화의 역할을 설명하세요.  
5. Phi Silica API가 NPU 하드웨어를 활용하여 성능을 최적화하는 방법은 무엇인가요?  
6. 개인정보 보호가 중요한 애플리케이션에서 로컬 배포와 클라우드 배포의 장점을 비교하세요.  

### 실습 과제

1. **AI 툴킷 설정**: AI 툴킷을 구성하고 모델을 최적화하기 (1시간)  
2. **Windows AI Foundry**: Phi Silica API를 사용하여 간단한 Windows AI 애플리케이션 구축하기 (1시간)  
3. **크로스 플랫폼 배포**: 동일한 모델을 두 개의 다른 플랫폼에 배포하기 (1시간)  
4. **NPU 최적화**: Windows AI Foundry 도구를 사용하여 NPU 성능 테스트하기 (30분)  

## 모듈 8: Microsoft Foundry Local – 완벽한 개발자 툴킷 (현대화된 버전)

### 주요 학습 목표

- Foundry Local을 최신 SDK와 통합하여 설치 및 구성하기  
- 코디네이터 패턴을 활용한 고급 다중 에이전트 시스템 구현하기  
- 자동 작업 기반 선택을 지원하는 지능형 모델 라우터 구축하기  
- 포괄적인 모니터링을 통해 프로덕션 준비된 AI 솔루션 배포하기  
- Azure AI Foundry와 통합하여 하이브리드 배포 시나리오 구현하기  
- FoundryLocalManager와 OpenAI 클라이언트를 활용한 최신 SDK 패턴 숙달하기  

### 학습 집중 영역

#### 섹션 1: 현대적인 설치 및 구성  
- **우선 개념**:  
  - FoundryLocalManager SDK 통합  
  - 자동 서비스 검색 및 상태 모니터링  
  - 환경 기반 구성 패턴  
  - 프로덕션 배포 고려 사항  

#### 섹션 2: 고급 다중 에이전트 시스템  
- **우선 개념**:  
  - 전문 에이전트를 활용한 코디네이터 패턴  
  - 검색, 추론, 실행 에이전트의 전문화  
  - 개선을 위한 피드백 루프 메커니즘  
  - 성능 모니터링 및 통계 추적  

#### 섹션 3: 지능형 모델 라우팅  
- **우선 개념**:  
  - 키워드 기반 모델 선택 알고리즘  
  - 다중 모델 지원 (일반, 추론, 코드, 창의적)  
  - 유연성을 위한 환경 변수 구성  
  - 서비스 상태 확인 및 오류 처리  

#### 섹션 4: 프로덕션 준비 구현  
- **우선 개념**:  
  - 포괄적인 오류 처리 및 대체 메커니즘  
  - 요청 모니터링 및 성능 추적  
  - 벤치마크와 함께 제공되는 대화형 Jupyter 노트북 예제  
  - 기존 애플리케이션과의 통합 패턴  

### 자기 평가 질문

1. 현대적인 FoundryLocalManager 접근 방식은 수동 REST 호출과 어떻게 다른가요?  
2. 코디네이터 패턴이 전문 에이전트를 어떻게 조율하는지 설명하세요.  
3. 지능형 라우터가 쿼리 내용에 따라 적합한 모델을 선택하는 방법은 무엇인가요?  
4. 프로덕션 준비된 AI 에이전트 시스템의 주요 구성 요소는 무엇인가요?  
5. Foundry Local 서비스의 포괄적인 상태 모니터링을 어떻게 구현하나요?  
6. 현대화된 접근 방식과 전통적인 구현 패턴의 장점을 비교하세요.  

### 실습 과제

1. **현대적인 SDK 설정**: 자동 서비스 검색을 사용하여 FoundryLocalManager 구성하기 (30분)  
2. **다중 에이전트 시스템**: 전문 에이전트를 활용한 고급 코디네이터 실행하기 (30분)  
3. **지능형 라우팅**: 다양한 쿼리 유형으로 모델 라우터 테스트하기 (30분)  
4. **대화형 탐색**: Jupyter 노트북을 사용하여 고급 기능 탐색하기 (45분)  
5. **프로덕션 배포**: 모니터링 및 오류 처리 패턴 구현하기 (30분)  
6. **하이브리드 통합**: Azure AI Foundry 대체 시나리오 구성하기 (30분)  

## 시간 배분 가이드

30시간의 확장된 강의 일정(워크숍 포함)을 최대한 활용하기 위해 다음과 같은 시간 배분을 제안합니다:

| 활동 | 시간 배분 | 설명 |  
|------|----------|------|  
| 핵심 자료 읽기 | 12시간 | 각 모듈의 필수 개념에 집중하기 |  
| 실습 과제 | 10시간 | 주요 기술의 실질적인 구현 (워크숍 포함) |  
| 자기 평가 | 3시간 | 질문과 반성을 통해 이해도 테스트하기 |  
| 미니 프로젝트 | 5시간 | 소규모 실질적 구현에 지식 적용하기 |  

### 시간 제약에 따른 주요 집중 영역

**10시간만 있는 경우:**  
- 모듈 0(소개) 및 모듈 1, 2, 3(핵심 EdgeAI 개념) 완료  
- 각 모듈에서 최소한 하나의 실습 과제 수행  
- 구현 세부 사항보다는 핵심 개념 이해에 집중  

**20시간을 할애할 수 있는 경우:**  
- 모든 8개 모듈(소개 포함) 완료  
- 각 모듈의 주요 실습 과제 수행  
- 모듈 7에서 하나의 미니 프로젝트 완료  
- 최소 2-3개의 추가 자료 탐색  

**20시간 이상 있는 경우:**  
- 모든 모듈(소개 포함)을 상세히 완료하고 실습 과제 수행  
- 여러 개의 미니 프로젝트 구축  
- 모듈 4에서 고급 최적화 기술 탐색  
- 모듈 5에서 프로덕션 배포 구현  

## 필수 자료

다음은 제한된 학습 시간에 가장 큰 가치를 제공하는 신중히 선택된 자료입니다:

### 필독 문서  
- [ONNX Runtime 시작하기](https://onnxruntime.ai/docs/get-started/with-python.html) - 가장 효율적인 모델 최적화 도구  
- [Ollama 빠른 시작](https://github.com/ollama/ollama#get-started) - SLM을 로컬에서 빠르게 배포하는 방법  
- [Microsoft Phi 모델 카드](https://huggingface.co/microsoft/phi-2) - 엣지 최적화 모델에 대한 참고 자료  
- [OpenVINO 문서](https://docs.openvino.ai/2025/index.html) - Intel의 포괄적인 최적화 툴킷  
- [VS Code용 AI 툴킷](https://code.visualstudio.com/docs/intelligentapps/overview) - 통합된 EdgeAI 개발 환경  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 전용 EdgeAI 개발 플랫폼  

### 시간 절약 도구  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 빠른 모델 액세스 및 배포  
- [Gradio](https://www.gradio.app/docs/interface) - AI 데모를 위한 신속한 UI 개발  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 간소화된 모델 최적화  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 효율적인 CPU 추론  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 신경망 압축 프레임워크  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 대형 언어 모델 배포 툴킷  

## 진행 추적 템플릿

20시간 강의를 통해 학습 진행 상황을 추적하기 위해 이 간단한 템플릿을 사용하세요:

| 모듈 | 완료 날짜 | 소요 시간 | 주요 학습 내용 |  
|------|----------|----------|---------------|  
| 모듈 0: EdgeAI 소개 | | | |  
| 모듈 1: EdgeAI 기본 | | | |  
| 모듈 2: SLM 기초 | | | |  
| 모듈 3: SLM 배포 | | | |  
| 모듈 4: 모델 최적화 | | | |  
| 모듈 5: SLMOps | | | |  
| 모듈 6: AI 에이전트 | | | |  
| 모듈 7: 개발 도구 | | | |  
| 워크숍: 실습 학습 | | | |  
| 모듈 8: Foundry Local 툴킷 | | | |  
| 실습 과제 | | | |  
| 미니 프로젝트 | | | |  

## 미니 프로젝트 아이디어

EdgeAI 개념을 연습하기 위해 다음 프로젝트 중 하나를 완료해 보세요(각각 2-4시간 소요):

### 초급 프로젝트 (각 2-3시간)  
1. **엣지 텍스트 어시스턴트**: 소형 언어 모델을 사용하여 간단한 오프라인 텍스트 완성 도구 만들기  
2. **모델 비교 대시보드**: 다양한 SLM의 성능 지표를 시각화하는 기본 대시보드 구축  
3. **최적화 실험**: 동일한 기본 모델에서 다양한 양자화 수준의 영향을 측정하기  

### 중급 프로젝트 (각 3-4시간)  
4. **AI 툴킷 워크플로우**: VS Code AI 툴킷을 사용하여 모델을 처음부터 끝까지 최적화 및 배포하기  
5. **Windows AI Foundry 애플리케이션**: Phi Silica API와 NPU 최적화를 사용하여 Windows 앱 만들기  
6. **크로스 플랫폼 배포**: 최적화된 동일 모델을 Windows(OpenVINO)와 모바일(.NET MAUI)에 배포하기  
7. **함수 호출 에이전트**: 엣지 시나리오를 위한 함수 호출 기능이 있는 AI 에이전트 구축하기  

### 고급 통합 프로젝트 (각 4-5시간)  
8. **OpenVINO 최적화 파이프라인**: NNCF와 GenAI 툴킷을 사용하여 완전한 모델 최적화 구현하기  
9. **SLMOps 파이프라인**: 모델의 전체 라이프사이클을 훈련부터 엣지 배포까지 구현하기  
10. **다중 모델 엣지 시스템**: 엣지 하드웨어에서 협력하는 여러 전문 모델 배포하기  
11. **MCP 통합 시스템**: 도구 상호작용을 위한 모델 컨텍스트 프로토콜을 사용하여 에이전트 시스템 구축하기  

## 참고 자료

- Microsoft Learn (Foundry Local)  
  - 개요: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - 시작하기: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI 참조: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - 추론 SDK와 통합하기: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI 사용 방법: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Hugging Face 모델 컴파일: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - 개요: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - 에이전트(개요): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- 최적화 및 추론 도구  
  - Microsoft Olive (문서): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (시작하기): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive 통합: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (문서): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (문서): https://ml-explore.github.io/mlx/build/html/index.html  
- 배포 프레임워크 및 모델  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (문서): https://docs.vllm.ai/  
  - Ollama (빠른 시작): https://github.com/ollama/ollama#get-started  
- 개발 도구 (Windows 및 VS Code)  
  - VS Code용 AI 툴킷: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (개요): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## 학습 커뮤니티

토론에 참여하고 다른 학습자들과 연결하세요:  
- [EdgeAI for Beginners 저장소](https://github.com/microsoft/edgeai-for-beginners/discussions)에서 GitHub 토론  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 결론

EdgeAI는 인공지능 구현의 최전선에 있으며, 강력한 기능을 장치에 직접 제공하면서 개인정보 보호, 지연 시간, 연결성에 대한 중요한 문제를 해결합니다. 이 20시간 강의는 EdgeAI 기술을 즉시 활용할 수 있는 필수 지식과 실질적인 기술을 제공합니다.

강의는 가장 중요한 개념에 집중하여 간결하고 효율적으로 설계되었으며, 과도한 시간 투자 없이도 귀중한 전문성을 빠르게 얻을 수 있습니다. 간단한 예제를 활용한 실습이 학습 내용을 강화하는 핵심이라는 점을 기억하세요.

즐거운 학습 되세요!  

---

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 신뢰할 수 있는 권위 있는 자료로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.