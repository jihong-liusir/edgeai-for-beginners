<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-07-22T04:38:32+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "ko"
}
-->
# Section02 : 소형 언어 모델(SLM)의 함수 호출

## 목차
1. [함수 호출이란?](../../../Module06)
2. [함수 호출 작동 방식](../../../Module06)
3. [적용 시나리오](../../../Module06)
4. [Phi-4-mini와 Ollama를 사용한 함수 호출 설정](../../../Module06)
5. [Qwen3 함수 호출 작업](../../../Module06)
6. [Foundry Local 통합](../../../Module06)
7. [모범 사례 및 문제 해결](../../../Module06)
8. [고급 예제](../../../Module06)

## 함수 호출이란?

함수 호출은 소형 언어 모델(SLM)이 외부 도구, API 및 서비스와 상호작용할 수 있도록 하는 강력한 기능입니다. SLM은 훈련 데이터에만 제한되지 않고 다음을 수행할 수 있습니다:

- **외부 API 연결** (날씨 서비스, 데이터베이스, 검색 엔진)
- **사용자 요청에 따라 특정 함수 실행**
- **다양한 소스에서 실시간 정보 검색**
- **특수 도구를 통한 계산 작업 수행**
- **복잡한 워크플로를 위해 여러 작업 연결**

이 기능은 SLM을 정적인 텍스트 생성기에서 실제 작업을 수행할 수 있는 동적 AI 에이전트로 변환합니다.

## 함수 호출 작동 방식

함수 호출 프로세스는 체계적인 워크플로를 따릅니다:

### 1. 도구 통합
- **외부 도구**: SLM은 날씨 API, 데이터베이스, 웹 서비스 및 기타 외부 시스템에 연결할 수 있습니다
- **함수 정의**: 각 도구는 특정 매개변수, 입력/출력 형식 및 설명으로 정의됩니다
- **API 호환성**: 도구는 표준화된 인터페이스(REST API, SDK 등)를 통해 통합됩니다

### 2. 함수 정의
함수는 세 가지 주요 구성 요소로 정의됩니다:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. 의도 감지
- **자연어 처리**: SLM은 사용자 입력을 분석하여 의도를 이해합니다
- **함수 매칭**: 요청을 충족하기 위해 필요한 함수(들)를 결정합니다
- **매개변수 추출**: 사용자의 메시지에서 필요한 매개변수를 식별하고 추출합니다

### 4. JSON 출력 생성
SLM은 다음을 포함하는 구조화된 JSON을 생성합니다:
- 호출할 함수 이름
- 적절한 값이 포함된 필요한 매개변수
- 실행 컨텍스트 및 메타데이터

### 5. 외부 실행
- **매개변수 검증**: 모든 필요한 매개변수가 존재하고 올바르게 형식화되었는지 확인합니다
- **함수 실행**: 제공된 매개변수로 지정된 함수를 애플리케이션이 실행합니다
- **오류 처리**: 실패, 시간 초과 및 잘못된 응답을 관리합니다

### 6. 응답 통합
- **결과 처리**: 함수 출력이 SLM으로 반환됩니다
- **컨텍스트 통합**: SLM은 결과를 응답에 통합합니다
- **사용자 커뮤니케이션**: 정보를 자연스럽고 대화형 형식으로 제공합니다

## 적용 시나리오

### 데이터 검색
자연어 쿼리를 구조화된 API 호출로 변환:
- **"내 최근 주문을 보여줘"** → 사용자 ID와 날짜 필터가 포함된 데이터베이스 쿼리
- **"도쿄의 날씨는 어때?"** → 위치 매개변수가 포함된 날씨 API 호출
- **"지난주 John에게서 온 이메일 찾아줘"** → 발신자와 날짜 필터가 포함된 이메일 서비스 쿼리

### 작업 실행
사용자 요청을 특정 함수 호출로 변환:
- **"내일 오후 2시에 회의 일정 잡아줘"** → 캘린더 API 통합
- **"팀에게 메시지 보내줘"** → 커뮤니케이션 플랫폼 API
- **"내 파일을 백업해줘"** → 파일 시스템 작업

### 계산 작업
복잡한 수학적 또는 논리적 작업 처리:
- **"$10,000에 대해 5%로 10년 동안 복리 계산해줘"** → 금융 계산 함수
- **"이 데이터셋을 분석해서 트렌드를 찾아줘"** → 통계 분석 도구
- **"배송을 위한 경로를 최적화해줘"** → 경로 최적화 알고리즘

### 데이터 처리 워크플로
복잡한 작업을 위해 여러 함수 호출 연결:
1. **여러 소스에서 데이터 검색**
2. **정보 구문 분석 및 검증**
3. **필요한 형식으로 데이터 변환**
4. **적절한 시스템에 결과 저장**
5. **보고서 또는 시각화 생성**

### UI/UX 통합
동적 인터페이스 업데이트 활성화:
- **"대시보드에 판매 데이터를 표시해줘"** → 차트 생성 및 표시
- **"새로운 위치로 지도를 업데이트해줘"** → 지리 데이터 통합
- **"재고 표시를 새로 고쳐줘"** → 실시간 데이터 동기화

## Phi-4-mini와 Ollama를 사용한 함수 호출 설정

Microsoft의 Phi-4-mini는 Ollama를 통해 단일 및 병렬 함수 호출을 지원합니다. 설정 방법은 다음과 같습니다:

### 사전 요구 사항
- Ollama 버전 0.5.13 이상
- Phi-4-mini 모델 (권장: `phi4-mini:3.8b-fp16`)

### 설치 단계

#### 1. Phi-4-mini 설치 및 실행
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. 사용자 정의 ModelFile 템플릿 생성
현재 Ollama의 기본 템플릿 제한으로 인해 다음 템플릿으로 사용자 정의 ModelFile을 생성해야 합니다:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. 사용자 정의 모델 생성
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### 단일 함수 호출 예제

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### 병렬 함수 호출 예제

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Qwen3 함수 호출 작업

Qwen3는 뛰어난 성능과 유연성을 갖춘 고급 함수 호출 기능을 제공합니다. 구현 방법은 다음과 같습니다:

### Qwen-Agent 프레임워크 사용

Qwen-Agent는 함수 호출 구현을 간소화하는 고급 프레임워크를 제공합니다:

#### 설치
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### 기본 설정

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### 사용자 정의 함수 구현

Qwen3에 대한 사용자 정의 함수를 정의할 수도 있습니다:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Qwen3의 고급 기능

#### 사고 모드 제어
Qwen3는 사고 모드와 비사고 모드 간의 동적 전환을 지원합니다:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### 다단계 함수 호출
Qwen3는 여러 함수 호출을 연결하는 데 뛰어납니다:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Foundry Local 통합

Microsoft의 Foundry Local은 향상된 개인정보 보호 및 성능을 제공하며 로컬에서 모델을 실행하기 위한 OpenAI 호환 API를 제공합니다.

### 설정 및 설치

#### Windows
[Foundry Local 릴리스 페이지](https://github.com/microsoft/Foundry-Local/releases)에서 설치 프로그램을 다운로드하고 설치 지침을 따르세요.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### 기본 사용법

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Foundry Local의 고급 기능

#### 모델 관리
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### 성능 최적화
Foundry Local은 하드웨어에 가장 적합한 모델 변형을 자동으로 선택합니다:
- **CUDA GPU**: GPU 최적화 모델 다운로드
- **Qualcomm NPU**: NPU 가속 변형 사용
- **CPU 전용**: CPU 최적화 모델 선택

## 모범 사례 및 문제 해결

### 함수 정의 모범 사례

#### 1. 명확하고 설명적인 이름 지정
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. 포괄적인 매개변수 정의
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. 입력 검증 및 오류 처리
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### 일반적인 문제 및 해결책

#### 문제 1: 함수가 호출되지 않음
**증상**: 모델이 함수 호출 대신 텍스트로 응답

**해결책**:
1. **함수 설명 확인**: 사용자 의도와 명확히 일치하는지 확인
2. **매개변수 정의 검증**: 모든 필요한 매개변수가 제대로 정의되었는지 확인
3. **시스템 프롬프트 검토**: 함수 사용 시기에 대한 명확한 지침 포함
4. **명시적 요청으로 테스트**: "런던의 데이터를 얻기 위해 날씨 함수를 사용해 주세요"와 같은 요청 시도

#### 문제 2: 잘못된 매개변수
**증상**: 잘못되거나 누락된 매개변수로 함수 호출

**해결책**:
1. **매개변수 예제 추가**: 매개변수 설명에 샘플 값을 포함
2. **열거형 제약 사용**: 가능한 경우 매개변수 값을 특정 옵션으로 제한
3. **대체 값 구현**: 선택적 매개변수에 대해 합리적인 기본값 제공

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### 문제 3: 병렬 함수 호출 실패
**증상**: 여러 함수가 실행되어야 할 때 하나만 실행됨

**해결책**:
1. **모델 지원 확인**: 모델이 병렬 함수 호출을 지원하는지 확인
2. **시스템 프롬프트 업데이트**: 시스템 메시지에 "일부 도구" 또는 "다중 도구" 포함
3. **적절한 모델 버전 사용**: Ollama에 대해 권장되는 Phi-4-mini:3.8b-fp16 사용

#### 문제 4: Ollama 템플릿 문제
**증상**: 기본 Ollama 설정으로 함수 호출이 작동하지 않음

**해결책**:
1. **사용자 정의 ModelFile 사용**: 이 튜토리얼에서 제공된 수정된 템플릿 적용
2. **Ollama 업데이트**: 버전 0.5.13 이상 사용 확인
3. **모델 양자화 확인**: 높은 양자화 수준(Q8_0, fp16)이 과도하게 양자화된 버전보다 더 잘 작동

### 성능 최적화

#### 1. 효율적인 함수 설계
- **함수를 집중적으로 유지**: 각 함수는 단일 명확한 목적을 가져야 함
- **외부 종속성 최소화**: API 호출 및 네트워크 요청을 가능한 한 줄이기
- **결과 캐싱**: 자주 요청되는 데이터를 저장하여 응답 시간 개선

#### 2. 배치 및 비동기 작업
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. 리소스 관리
- **연결 풀링**: 데이터베이스 및 API 연결 재사용
- **속도 제한**: 외부 API에 적절한 속도 제한 구현
- **시간 초과 처리**: 모든 외부 호출에 적절한 시간 초과 설정

## 고급 예제

### 다중 에이전트 협업 시스템

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### 동적 도구 선택 시스템

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """모든 함수 호출에 대한 표준 결과 형식"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """포괄적인 함수 호출 기능을 갖춘 생산 준비된 AI 에이전트"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # 핵심 비즈니스 함수 초기화
        self._register_core_functions()
    
    def _register_core_functions(self):
        """사용 가능한 모든 비즈니스 함수 등록"""
        
        # CRM 함수
        self.register_function(
            name="get_customer_info",
            description="CRM에서 고객 정보를 검색",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # 분당 호출 수
        )
        
        # 판매 함수
        self.register_function(
            name="create_sales_opportunity",
            description="새로운 판매 기회 생성",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # 분석 함수
        self.register_function(
            name="generate_sales_report",
            description="판매 성과 보고서 생성",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # 알림 함수
        self.register_function(
            name="send_notification",
            description="팀원에게 알림 전송",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """에이전트에 새 함수 등록"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
I'm sorry, but I need the content of the markdown file to proceed with the translation. Could you please provide the text you'd like me to translate?
"""포괄적인 오류 처리 및 로깅을 통해 함수를 실행합니다"""
start_time = datetime.now()

try:
    # 함수 존재 여부 확인
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"함수 '{function_name}'를 찾을 수 없습니다",
            timestamp=start_time
        )
    
    # 호출 제한 확인
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"함수 '{function_name}'에 대한 호출 제한 초과",
            timestamp=start_time
        )
    
    # 매개변수 유효성 검사
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # 함수 실행
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # 성공적인 실행 로그 기록
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # 실패한 실행 로그 기록
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """함수 호출이 호출 제한 내에 있는지 확인합니다"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # 1분이 지나면 카운터 초기화
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # 제한 내에 있는지 확인
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """함수 매개변수 유효성 검사"""
    func_params = self.functions[function_name]['parameters']
    
    # 필수 매개변수 확인
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"필수 매개변수 누락: {param_name}"
            )
    
    # 매개변수 유형 및 제약 조건 확인
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # 유형 유효성 검사
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"매개변수 '{param_name}'는 문자열이어야 합니다"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"매개변수 '{param_name}'는 숫자이어야 합니다"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"매개변수 '{param_name}'는 불리언이어야 합니다"
                )
            
            # 열거형 유효성 검사
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"매개변수 '{param_name}'는 다음 중 하나여야 합니다: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """감사를 위해 함수 호출 로그 기록"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # 외부 로깅 시스템에 기록 옵션
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """외부 로깅 시스템에 로그 항목 기록"""
    # 구현은 로깅 인프라에 따라 달라집니다
    # 예: ELK 스택, CloudWatch 등으로 전송
    pass

# 비즈니스 함수 구현
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """CRM 시스템에서 고객 정보를 검색합니다"""
    # 데이터베이스/API 호출 시뮬레이션
    await asyncio.sleep(0.1)  # 네트워크 지연 시뮬레이션
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Product A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Product B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """새로운 영업 기회를 생성합니다"""
    # CRM API 호출 시뮬레이션
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """포괄적인 영업 보고서를 생성합니다"""
    # 데이터 집계 시뮬레이션
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'medium', channel: str = 'email') -> Dict:
    """지정된 채널을 통해 알림을 보냅니다"""
    # 알림 서비스 호출 시뮬레이션
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """등록된 모든 함수에 대한 OpenAI 호환 함수 정의 가져오기"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# 엔터프라이즈 통합 사용 예제
async def enterprise_demo():
    """엔터프라이즈 AI 에이전트 기능 시연"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # 예제 1: 고객 문의 처리
    print("=== 고객 문의 처리 ===")
    
    # 고객 정보 가져오기
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"고객 정보 검색 완료: {result.data['name']}")
        print(f"실행 시간: {result.execution_time:.3f}s")
    
    # 예제 2: 영업 기회 생성
    print("\n=== 영업 기회 생성 ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"기회 생성 완료: {result.data['opportunity_id']}")
    
    # 예제 3: 배치 작업
    print("\n=== 배치 작업 ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': '새로운 기회가 생성되었습니다',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"작업 {i+1} 성공적으로 완료")
        else:
            print(f"작업 {i+1} 실패: {result.error}")
    
    # 감사 로그 표시
    print(f"\n=== 감사 로그 ({len(agent.audit_log)} 항목) ===")
    for entry in agent.audit_log[-3:]:  # 마지막 3개 항목 표시
        print(f"{entry['timestamp']}: {entry['function_name']} - {'성공' if entry['success'] else '실패'}")

# 엔터프라이즈 데모 실행
# asyncio.run(enterprise_demo())

## 결론

소형 언어 모델(SLM)의 함수 호출은 정적 AI 비서에서 실제 세계와 상호작용할 수 있는 동적이고 유능한 에이전트로의 패러다임 전환을 나타냅니다. 이 튜토리얼에서는 다음을 다루었습니다:

### 주요 요점

1. **기초 이해**: 함수 호출은 SLM이 외부 도구 및 서비스와 연결하여 학습 데이터 이상으로 확장할 수 있도록 합니다.

2. **유연한 구현**: 맞춤 템플릿을 사용한 저수준 구현부터 Qwen-Agent 및 Foundry Local과 같은 고수준 프레임워크까지 다양한 접근 방식이 존재합니다.

3. **프로덕션 고려사항**: 엔터프라이즈 배포는 오류 처리, 호출 제한, 보안 및 감사 로깅에 대한 주의가 필요합니다.

4. **성능 최적화**: 적절한 함수 설계, 효율적인 실행 및 스마트 캐싱은 응답 시간을 크게 개선할 수 있습니다.

### 미래 방향

SLM 기술이 계속 발전함에 따라 다음을 기대할 수 있습니다:

- **향상된 함수 호출 정확도**: 더 나은 의도 감지 및 매개변수 추출
- **고급 병렬 처리**: 더 정교한 다중 함수 오케스트레이션
- **통합 표준 개선**: 도구 통합을 위한 표준화된 프로토콜
- **고급 보안 기능**: 향상된 인증 및 권한 부여 메커니즘
- **확장된 생태계**: 사전 구축된 함수 및 통합 라이브러리의 성장

### 시작하기

프로젝트에서 함수 호출을 구현하려면:

1. **간단하게 시작**: 기본적인 단일 함수 시나리오로 시작
2. **프레임워크 선택**: 직접 구현(Ollama/Phi-4) 또는 프레임워크 지원(Qwen-Agent) 중 선택
3. **함수 설계 신중히**: 명확하고 잘 문서화된 함수 정의에 집중
4. **오류 처리 구현**: 처음부터 강력한 오류 처리를 구축
5. **점진적으로 확장**: 경험을 쌓으면서 간단한 시나리오에서 복잡한 시나리오로 이동

함수 호출은 SLM을 인상적인 텍스트 생성기에서 실제 문제를 해결할 수 있는 실용적인 AI 에이전트로 변환합니다. 이 튜토리얼에서 설명한 패턴과 관행을 따르면 전통적인 채팅 인터페이스를 넘어 강력하고 신뢰할 수 있는 AI 시스템을 구축할 수 있습니다.

### 리소스 및 참고 자료
- **Phi-4 모델**: [Hugging Face 컬렉션](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)  
- **Qwen3 문서**: [공식 Qwen 문서](https://qwen.readthedocs.io/)  
- **Ollama**: [공식 웹사이트](https://ollama.com/)  
- **Foundry Local**: [GitHub 저장소](https://github.com/microsoft/Foundry-Local)  
- **함수 호출 모범 사례**: [Hugging Face 가이드](https://huggingface.co/docs/hugs/en/guides/function-calling)  

함수 호출은 계속 발전하는 분야이므로, 선택한 프레임워크와 모델의 최신 개발 동향을 지속적으로 업데이트하면 더 효과적인 AI 에이전트를 구축하는 데 도움이 됩니다.  

## ➡️ 다음 단계  

- [03: 모델 컨텍스트 프로토콜(MCP) 통합](./03.IntroduceMCP.md)  

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 책임을 지지 않습니다.