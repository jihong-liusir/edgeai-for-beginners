{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d4d2e0",
   "metadata": {},
   "source": [
    "# 세션 6 – 다단계 파이프라인 (계획 → 실행 → 수정)\n",
    "\n",
    "라우팅 함수를 사용하여 단계별로 모델을 선택한 후 최종 답변을 수정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959acb1",
   "metadata": {},
   "source": [
    "### 설명: 종속성 설치\n",
    "`foundry-local-sdk`와 `openai`를 설치하여 단계별 채팅 호출에 필요합니다. 다시 실행해도 안전합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58285936",
   "metadata": {},
   "source": [
    "# 시나리오\n",
    "다단계 모델 파이프라인: (1) 작업을 개별 단계로 계획, (2) 의도 기반 모델 선택을 통해 각 단계를 실행, (3) 최종 합성된 답변을 개선. 효율성을 유지하면서 품질을 보존하기 위해 이질적인 SLM 기능을 연결하는 방법을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0b10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q foundry-local-sdk openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220de1ac",
   "metadata": {},
   "source": [
    "### 설명: 핵심 임포트\n",
    "의도 감지를 위한 regex, 별칭별 첨부를 위한 Foundry Local 매니저, 그리고 채팅 완료를 위한 OpenAI 클라이언트를 임포트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d63e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from foundry_local import FoundryLocalManager\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17da8d",
   "metadata": {},
   "source": [
    "### 설명: 기능 카탈로그 및 규칙\n",
    "기능 인식 카탈로그와 정규식 규칙을 정의하여 단계 텍스트를 의도 카테고리(코드, 요약, 분류, 일반)로 매핑합니다. 여러 모델이 동일한 의도를 지원하는 경우 우선순위 값이 낮은 것이 우선됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee8e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = {\n",
    " 'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},\n",
    " 'qwen2.5-coder-7b': {'capabilities':['code','refactor'],'priority':1},\n",
    " 'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':3},\n",
    "}\n",
    "RULES = [\n",
    " (re.compile('code|refactor|function', re.I), 'code'),\n",
    " (re.compile('summari|abstract|tl;dr', re.I), 'summarize'),\n",
    " (re.compile('classif|category|label', re.I), 'classification'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d29a6",
   "metadata": {},
   "source": [
    "### 설명: 의도, 모델 선택 및 채팅 도우미\n",
    "제공:\n",
    "- `detect_intent`: 정규 표현식을 기반으로 한 분류.\n",
    "- `pick_model`: 기능과 우선순위에 따라 최적의 별칭 선택.\n",
    "- `chat`: 별칭별 클라이언트를 생성하고 단일 턴 응답을 반환하는 편리한 래퍼.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fe43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intent(text: str):\n",
    "    \"\"\"Return an intent label based on simple regex rules; falls back to 'general'.\"\"\"\n",
    "    for pat, intent in RULES:\n",
    "        if pat.search(text):\n",
    "            return intent\n",
    "    return 'general'\n",
    "\n",
    "def pick_model(intent: str) -> str:\n",
    "    \"\"\"Pick the best model for an intent using capability match first, then priority.\"\"\"\n",
    "    ranked = []\n",
    "    for name, meta in CATALOG.items():\n",
    "        ranked.append((name, intent in meta['capabilities'], meta['priority']))\n",
    "    # Sort: capability match (True first), then lower priority value\n",
    "    ranked.sort(key=lambda t: (not t[1], t[2]))\n",
    "    return ranked[0][0]\n",
    "\n",
    "def chat(alias: str, content: str, temp: float = 0.4) -> str:\n",
    "    \"\"\"Simple helper to send a single user message to a Foundry Local model via OpenAI client.\"\"\"\n",
    "    m = FoundryLocalManager(alias)\n",
    "    client = OpenAI(base_url=m.endpoint, api_key=m.api_key or 'not-needed')\n",
    "    mid = m.get_model_info(alias).id\n",
    "    resp = client.chat.completions.create(\n",
    "        model=mid,\n",
    "        messages=[{'role': 'user', 'content': content}],\n",
    "        max_tokens=180,\n",
    "        temperature=temp,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ba53d",
   "metadata": {},
   "source": [
    "### 설명: 다단계 파이프라인 함수\n",
    "파이프라인을 구현합니다: 계획 → 단계 분석 → 의도 기반 라우팅으로 각각 실행 → 결합된 출력 정제. 검토 또는 평가를 위한 구조화된 dict를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22bf8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(task: str):\n",
    "    \"\"\"Multi-step pipeline: plan → execute steps → refine final answer.\n",
    "\n",
    "    Returns dict with keys: plan (raw plan text), steps (list of tuples), final (refined answer).\n",
    "    Each step tuple: (index, step_text, step_result, model_alias_used)\n",
    "    \"\"\"\n",
    "    # 1. Plan\n",
    "    plan_alias = pick_model('general')\n",
    "    plan_prompt = (\n",
    "        \"Break the task into 3 concise, actionable steps (no extra commentary).\\n\"\n",
    "        f\"Task: {task}\"\n",
    "    )\n",
    "    plan = chat(plan_alias, plan_prompt)\n",
    "\n",
    "    # 2. Parse steps (robust to numbering or bullet styles)\n",
    "    raw_lines = [l.strip() for l in plan.splitlines() if l.strip()]\n",
    "    steps = []\n",
    "    for line in raw_lines:\n",
    "        cleaned = re.sub(r'^\\d+[).:-]?\\s*', '', line)  # remove leading numbering\n",
    "        cleaned = re.sub(r'^[-*]\\s*', '', cleaned)      # remove bullet markers\n",
    "        if cleaned:\n",
    "            steps.append(cleaned)\n",
    "        if len(steps) == 3:\n",
    "            break\n",
    "    if not steps:\n",
    "        steps = [task]\n",
    "\n",
    "    # 3. Execute steps\n",
    "    outputs = []\n",
    "    for idx, step in enumerate(steps, 1):\n",
    "        intent = detect_intent(step)\n",
    "        exec_alias = pick_model(intent)\n",
    "        exec_prompt = (\n",
    "            f\"Execute step {idx} for the overall task.\\n\"\n",
    "            f\"Overall task: {task}\\n\"\n",
    "            f\"Step {idx}: {step}\\n\"\n",
    "            \"Return a concise result focusing only on the step objective.\"\n",
    "        )\n",
    "        result = chat(exec_alias, exec_prompt)\n",
    "        outputs.append((idx, step, result, exec_alias))\n",
    "\n",
    "    # 4. Refine final answer\n",
    "    refine_alias = pick_model('summarize')\n",
    "    combined = \"\\n\\n\".join(\n",
    "        f\"Step {idx} ({alias}) Output:\\n{res}\" for idx, _step, res, alias in outputs\n",
    "    )\n",
    "    refine_prompt = (\n",
    "        \"You are a senior assistant. Synthesize these step outputs into a cohesive final answer.\\n\"\n",
    "        \"Ensure clarity, avoid repetition, and highlight improvements or key insights if relevant.\\n\\n\"\n",
    "        f\"Task: {task}\\n\\n\"\n",
    "        f\"Step Outputs:\\n{combined}\"\n",
    "    )\n",
    "    final_ans = chat(refine_alias, refine_prompt)\n",
    "\n",
    "    return {\"plan\": plan, \"steps\": outputs, \"final\": final_ans}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282472b0",
   "metadata": {},
   "source": [
    "### 설명: 예제 작업 실행\n",
    "리팩터링 중심의 작업에서 혼합된 의도(코드 + 요약)를 보여주는 전체 파이프라인을 실행합니다. 결과 딕셔너리는 원시 계획, 단계별 출력(선택된 모델 별칭 포함), 그리고 최종적으로 합성된 답변을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac0f568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plan': '1. Profile the existing slow Python loop to identify bottlenecks.\\n2. Refactor the loop using optimized techniques (e.g., list comprehensions, map, or itertools).\\n3. Compare the performance of the refactored loop with the original using a benchmarking tool and summarize the gains.',\n",
       " 'steps': [(1,\n",
       "   'Profile the existing slow Python loop to identify bottlenecks.',\n",
       "   \"To execute step 1, you would use a profiling tool like `cProfile` in Python to analyze the performance of the existing slow loop. Here's an example of how you might do this:\\n\\n```python\\nimport cProfile\\n\\ndef slow_loop():\\n    # Example of a slow loop\\n    result = []\\n    for i in range(1000000):\\n        result.append(i * i)\\n    return result\\n\\n# Profile the slow loop\\ncProfile.run('slow_loop()', 'profile_stats')\\n\\n# To see the results, you can use pstats module\\nimport pstats\\np = pstats.Stats('profile_stats')\\np.sort_stats('cumulative').print_stats()\\n```\\n\\nThis code will run the `slow_loop` function and profile it, saving the results to 'profile_stats'. The `pstats` module can then be used to analyze the profiling data, which will show\",\n",
       "   'phi-4-mini'),\n",
       "  (2,\n",
       "   'Refactor the loop using optimized techniques (e.g., list comprehensions, map, or itertools).',\n",
       "   'To refactor a slow Python loop using optimized techniques such as list comprehensions, `map`, or `itertools`, follow these steps:\\n\\n1. **Identify the Loop**: Determine which loop in your code is causing the slowdown.\\n2. **Understand the Loop**: Analyze what the loop does, including any operations performed on each element.\\n3. **Choose an Optimization Technique**:\\n   - **List Comprehension**: If the loop constructs a new list, use a list comprehension.\\n   - **Map Function**: Use `map` if you need to apply a function to each item in an iterable.\\n   - **Itertools**: Utilize functions from the `itertools` module for more efficient looping patterns.\\n4. **Refactor the Loop**: Replace the original loop with the chosen optimization technique.\\n5. **Test the Code**: Ensure that the refactored code produces the same',\n",
       "   'qwen2.5-coder-7b'),\n",
       "  (3,\n",
       "   'Compare the performance of the refactored loop with the original using a benchmarking tool and summarize the gains.',\n",
       "   'To compare the performance of the refactored loop with the original using a benchmarking tool, follow these steps:\\n\\n1. **Choose a Benchmarking Tool**: Select an appropriate benchmarking tool such as `timeit`, `cProfile`, or `line_profiler` depending on your needs.\\n\\n2. **Set Up Your Environment**: Ensure that both the original and refactored code snippets are in separate functions or scripts so they can be easily compared.\\n\\n3. **Run Benchmarks**:\\n   - Use the chosen tool to measure the execution time of the original loop.\\n   - Repeat the process for the refactored loop.\\n\\n4. **Compare Results**: Analyze the results from both benchmarks to determine the performance gain achieved by the refactoring.\\n\\n5. **Summarize Gains**: Provide a concise summary of the performance improvements, including any specific metrics (e.g., speedup factor',\n",
       "   'qwen2.5-coder-7b')],\n",
       " 'final': 'To optimize a slow Python loop, you can use profiling tools like `cProfile` to identify the loop causing the slowdown. Once identified, you can refactor the loop using techniques such as list comprehensions, `map`, or `itertools` for more efficient looping patterns. After refactoring, you can use benchmarking tools like `timeit`, `cProfile`, or `line_profiler` to compare the performance of the original and refactored loops. The performance gains can be summarized in terms of speedup factor or other relevant metrics. This process can significantly improve the performance of your Python code.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline('Generate a refactored version of a slow Python loop and summarize performance gains.')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4251879",
   "metadata": {},
   "source": [
    "### 설명: 결과 객체 표시\n",
    "구조화된 파이프라인 출력을 보여주어 빠른 검사나 후속 평가(예: 단계 품질 측정 또는 개선 효과 평가)에 활용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**면책 조항**:  \n이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전이 권위 있는 출처로 간주되어야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "coopTranslator": {
   "original_hash": "4b16cb98e431df1b9f64f627bad7009c",
   "translation_date": "2025-10-08T19:44:46+00:00",
   "source_file": "Workshop/notebooks/session06_models_pipeline.ipynb",
   "language_code": "ko"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}