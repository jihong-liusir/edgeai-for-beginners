<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T08:30:27+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "pt"
}
-->
# EdgeAI para Iniciantes: Percursos de Aprendizagem e Cronograma de Estudos

### Percurso de Aprendizagem Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 2 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 3 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 4-5 | Módulo 4: Otimização de Modelos (6 frameworks) | 4 horas |
| Dia 6 | Módulo 5: SLMOps | 3 horas |
| Dia 7 | Módulo 6-7: Agentes de IA e Ferramentas de Desenvolvimento | 4 horas |
| Dia 8 | Módulo 8: Foundry Local Toolkit (Implementação Moderna) | 1 hora |

### Percurso de Aprendizagem Concentrado (2 semanas)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Agentes de IA | 2 horas |
| Dia 13-14 | Módulo 7: Ferramentas de Desenvolvimento | 3 horas |

### Estudo a Tempo Parcial (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos e Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implementação e Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps e Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento e Integração | 3 horas |

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Sistemas Agentes de SLM | 2 horas |
| Dia 13-14 | Módulo 7: Exemplos de Implementação de EdgeAI | 2 horas |

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizagens |
|--------|----------------|-------------|--------------------------|
| Módulo 0: Introdução ao EdgeAI | | | |
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implementação de SLM | | | |
| Módulo 4: Otimização de Modelos (6 frameworks) | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Sistemas Agentes de SLM | | | |
| Módulo 7: Exemplos de Implementação de EdgeAI | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

### Estudo a Tempo Parcial (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos e Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implementação e Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps e Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento e Integração | 3 horas |

## Introdução

Bem-vindo ao guia de estudos "EdgeAI para Iniciantes"! Este documento foi concebido para ajudá-lo a navegar pelos materiais do curso de forma eficaz e maximizar a sua experiência de aprendizagem. Ele oferece percursos de aprendizagem estruturados, cronogramas de estudo sugeridos, resumos de conceitos-chave e recursos suplementares para aprofundar o seu conhecimento sobre tecnologias de Edge AI.

Este é um curso conciso de 20 horas que fornece conhecimentos essenciais sobre EdgeAI de forma eficiente, sendo ideal para profissionais ocupados e estudantes que desejam adquirir rapidamente competências práticas nesta área emergente.

## Visão Geral do Curso

Este curso está organizado em oito módulos abrangentes:

0. **Introdução ao EdgeAI** - Fundamentos e contextualização com aplicações na indústria e objetivos de aprendizagem  
1. **Fundamentos e Transformação do EdgeAI** - Compreensão dos conceitos principais e da mudança tecnológica  
2. **Fundamentos de Modelos de Linguagem Pequenos (SLM)** - Exploração de várias famílias de SLM e suas arquiteturas  
3. **Implementação de Modelos de Linguagem Pequenos** - Estratégias práticas de implementação  
4. **Conversão de Formato de Modelos e Quantização** - Otimização avançada com 6 frameworks, incluindo OpenVINO  
5. **SLMOps - Operações de Modelos de Linguagem Pequenos** - Gestão do ciclo de vida e implementação em produção  
6. **Sistemas Agentes de SLM** - Agentes de IA, chamadas de funções e Protocolo de Contexto de Modelos  
7. **Exemplos de Implementação de EdgeAI** - Ferramentas de IA, desenvolvimento em Windows e implementações específicas de plataformas  
8. **Microsoft Foundry Local – Kit de Ferramentas Completo para Desenvolvedores** - Desenvolvimento local com integração híbrida ao Azure (Módulo 08)

## Como Usar Este Guia de Estudos

- **Aprendizagem Progressiva**: Siga os módulos na ordem para uma experiência de aprendizagem mais coerente  
- **Pontos de Verificação de Conhecimento**: Utilize as perguntas de autoavaliação após cada seção  
- **Prática Prática**: Complete os exercícios sugeridos para reforçar os conceitos teóricos  
- **Recursos Suplementares**: Explore materiais adicionais para os tópicos que mais lhe interessam  

## Recomendações de Cronograma de Estudos

### Percurso de Aprendizagem Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 6 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 8 horas |
| Dia 5 | Módulo 3: Implementação de SLM | 3 horas |
| Dia 6 | Módulo 8: Foundry Local Toolkit | 3 horas |

### Estudo a Tempo Parcial (3 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 0: Introdução + Módulo 1: Fundamentos do EdgeAI | 7-9 horas |
| Semana 2 | Módulo 2: Fundamentos de SLM | 7-8 horas |
| Semana 3 | Módulo 3: Implementação de SLM (3h) + Módulo 8: Foundry Local Toolkit (2-3h) | 5-6 horas |

## Módulo 0: Introdução ao EdgeAI

### Principais Objetivos de Aprendizagem

- Compreender o que é Edge AI e por que é relevante no cenário tecnológico atual  
- Identificar as principais indústrias transformadas pelo Edge AI e seus casos de uso específicos  
- Compreender as vantagens dos Modelos de Linguagem Pequenos (SLMs) para implementação em dispositivos de borda  
- Estabelecer expectativas claras de aprendizagem e resultados para o curso completo  
- Reconhecer oportunidades de carreira e competências necessárias na área de Edge AI  

### Áreas de Foco do Estudo

#### Seção 1: Paradigma e Definição de Edge AI
- **Conceitos Prioritários**:  
  - Edge AI vs. processamento tradicional em nuvem  
  - Convergência de hardware, otimização de modelos e demandas empresariais  
  - Implementação de IA em tempo real, preservação de privacidade e eficiência de custos  

#### Seção 2: Aplicações na Indústria
- **Conceitos Prioritários**:  
  - Indústria 4.0: Manutenção preditiva e controlo de qualidade  
  - Saúde: Imagem diagnóstica e monitorização de pacientes  
  - Sistemas Autónomos: Veículos autónomos e transporte  
  - Cidades Inteligentes: Gestão de tráfego e segurança pública  
  - Tecnologia de Consumo: Smartphones, wearables e casas inteligentes  

#### Seção 3: Fundamentos de Modelos de Linguagem Pequenos
- **Conceitos Prioritários**:  
  - Características e comparações de desempenho de SLMs  
  - Eficiência de parâmetros vs. trade-offs de capacidade  
  - Restrições de implementação em dispositivos de borda e estratégias de otimização  

#### Seção 4: Estrutura de Aprendizagem e Caminho de Carreira
- **Conceitos Prioritários**:  
  - Arquitetura do curso e abordagem de domínio progressivo  
  - Competências técnicas e objetivos de implementação prática  
  - Oportunidades de avanço na carreira e aplicações na indústria  

### Perguntas de Autoavaliação

1. Quais são as três principais tendências tecnológicas que possibilitaram o Edge AI?  
2. Compare as vantagens e desafios do Edge AI em relação ao AI baseado na nuvem.  
3. Nomeie três indústrias onde o Edge AI oferece valor comercial crítico e explique por quê.  
4. Como os Modelos de Linguagem Pequenos tornam o Edge AI prático para implementações no mundo real?  
5. Quais são as principais competências técnicas que você desenvolverá ao longo deste curso?  
6. Descreva a abordagem de aprendizagem em quatro fases utilizada neste curso.  

### Exercícios Práticos

1. **Pesquisa de Indústria**: Escolha uma aplicação industrial e pesquise uma implementação real de Edge AI (30 minutos)  
2. **Exploração de Modelos**: Navegue pelos Modelos de Linguagem Pequenos disponíveis no Hugging Face e compare os seus contadores de parâmetros e capacidades (30 minutos)  
3. **Planeamento de Aprendizagem**: Revise a estrutura completa do curso e crie o seu cronograma de estudos pessoal (15 minutos)  

### Materiais Suplementares

- [Visão Geral do Mercado de Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Visão Geral de Modelos de Linguagem Pequenos - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Fundação de Computação na Borda](https://www.edgecomputing.org/)  

## Módulo 1: Fundamentos e Transformação do EdgeAI

### Principais Objetivos de Aprendizagem

- Compreender as diferenças entre AI baseada na nuvem e AI baseada na borda  
- Dominar técnicas de otimização para ambientes com recursos limitados  
- Analisar aplicações reais de tecnologias EdgeAI  
- Configurar um ambiente de desenvolvimento para projetos de EdgeAI  

### Áreas de Foco do Estudo

#### Seção 1: Fundamentos do EdgeAI
- **Conceitos Prioritários**:  
  - Paradigmas de computação na borda vs. na nuvem  
  - Técnicas de quantização de modelos  
  - Opções de aceleração de hardware (NPUs, GPUs, CPUs)  
  - Vantagens de privacidade e segurança  

- **Materiais Suplementares**:  
  - [Documentação do TensorFlow Lite](https://www.tensorflow.org/lite)  
  - [GitHub do ONNX Runtime](https://github.com/microsoft/onnxruntime)  
  - [Documentação do Edge Impulse](https://docs.edgeimpulse.com)  

#### Seção 2: Estudos de Caso do Mundo Real
- **Conceitos Prioritários**:  
  - Ecossistema de modelos Microsoft Phi & Mu  
  - Implementações práticas em diferentes indústrias  
  - Considerações para implementação  

#### Seção 3: Guia Prático de Implementação
- **Conceitos Prioritários**:  
  - Configuração do ambiente de desenvolvimento  
  - Ferramentas de quantização e otimização  
  - Métodos de avaliação para implementações de EdgeAI  

#### Seção 4: Hardware para Implementação na Borda
- **Conceitos Prioritários**:  
  - Comparações de plataformas de hardware  
  - Estratégias de otimização para hardware específico  
  - Considerações para implementação  

### Perguntas de Autoavaliação

1. Compare e contraste implementações de AI na nuvem e na borda.  
2. Explique três técnicas-chave para otimizar modelos para implementação na borda.  
3. Quais são as principais vantagens de executar modelos de AI na borda?  
4. Descreva o processo de quantização de um modelo e como ele afeta o desempenho.  
5. Explique como diferentes aceleradores de hardware (NPUs, GPUs, CPUs) influenciam a implementação de EdgeAI.  

### Exercícios Práticos

1. **Configuração Rápida do Ambiente**: Configure um ambiente de desenvolvimento mínimo com os pacotes essenciais (30 minutos)  
2. **Exploração de Modelos**: Faça o download e examine um modelo de linguagem pequeno pré-treinado (1 hora)  
3. **Quantização Básica**: Experimente uma quantização simples em um modelo pequeno (1 hora)  

## Módulo 2: Fundamentos de Modelos de Linguagem Pequenos

### Principais Objetivos de Aprendizagem

- Compreender os princípios arquiteturais de diferentes famílias de SLM  
- Comparar capacidades de modelos em diferentes escalas de parâmetros  
- Avaliar modelos com base em eficiência, capacidade e requisitos de implementação  
- Reconhecer casos de uso apropriados para diferentes famílias de modelos  

### Áreas de Foco do Estudo

#### Seção 1: Família de Modelos Microsoft Phi
- **Conceitos Prioritários**:  
  - Evolução da filosofia de design  
  - Arquitetura com foco em eficiência  
  - Capacidades especializadas  

#### Seção 2: Família Qwen
- **Conceitos Prioritários**:  
  - Contribuições open source  
  - Opções escaláveis de implementação  
  - Arquitetura avançada de raciocínio  

#### Seção 3: Família Gemma
- **Conceitos Prioritários**:  
  - Inovação orientada por pesquisa  
  - Capacidades multimodais  
  - Otimização para dispositivos móveis  

#### Seção 4: Família BitNET
- **Conceitos Prioritários**:  
  - Tecnologia de quantização de 1 bit  
  - Framework de otimização de inferência  
  - Considerações de sustentabilidade  

#### Seção 5: Modelo Microsoft Mu
- **Conceitos Prioritários**:  
  - Arquitetura orientada para dispositivos  
  - Integração com sistemas Windows  
  - Operação com preservação de privacidade  

#### Seção 6: Phi-Silica
- **Conceitos Prioritários**:  
  - Arquitetura otimizada para NPU  
  - Métricas de desempenho  
  - Integração para desenvolvedores  

### Perguntas de Autoavaliação

1. Compare as abordagens arquiteturais das famílias de modelos Phi e Qwen.  
2. Explique como a tecnologia de quantização do BitNET difere da quantização tradicional.  
3. Quais são as vantagens únicas do modelo Mu para integração com Windows?  
4. Descreva como o Phi-Silica utiliza hardware NPU para otimização de desempenho.  
5. Para uma aplicação móvel com conectividade limitada, qual família de modelos seria mais apropriada e porquê?  

### Exercícios Práticos  

1. **Comparação de Modelos**: Benchmark rápido de dois modelos SLM diferentes (1 hora)  
2. **Geração de Texto Simples**: Implementação básica de geração de texto com um modelo pequeno (1 hora)  
3. **Otimização Rápida**: Aplicar uma técnica de otimização para melhorar a velocidade de inferência (1 hora)  

## Módulo 3: Implementação de Modelos de Linguagem Pequenos  

### Objetivos de Aprendizagem  

- Selecionar modelos apropriados com base em restrições de implementação  
- Dominar técnicas de otimização para diferentes cenários de implementação  
- Implementar SLMs em ambientes locais e na nuvem  
- Projetar configurações prontas para produção em aplicações EdgeAI  

### Áreas de Foco de Estudo  

#### Seção 1: Aprendizagem Avançada de SLM  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de parâmetros  
  - Técnicas avançadas de otimização  
  - Estratégias de aquisição de modelos  

#### Seção 2: Implementação em Ambiente Local  
- **Conceitos Prioritários**:  
  - Implementação na plataforma Ollama  
  - Soluções locais da Microsoft Foundry  
  - Análise comparativa de frameworks  

#### Seção 3: Implementação em Nuvem com Contêineres  
- **Conceitos Prioritários**:  
  - Inferência de alto desempenho com vLLM  
  - Orquestração de contêineres  
  - Implementação com ONNX Runtime  

### Perguntas de Autoavaliação  

1. Quais fatores devem ser considerados ao escolher entre implementação local e na nuvem?  
2. Compare Ollama e Microsoft Foundry Local como opções de implementação.  
3. Explique os benefícios da containerização para implementação de SLM.  
4. Quais são as principais métricas de desempenho a monitorar em um SLM implementado na borda?  
5. Descreva um fluxo completo de implementação, desde a seleção do modelo até a produção.  

### Exercícios Práticos  

1. **Implementação Local Básica**: Implementar um SLM simples usando Ollama (1 hora)  
2. **Verificação de Desempenho**: Executar um benchmark rápido no modelo implementado (30 minutos)  
3. **Integração Simples**: Criar uma aplicação mínima que utilize o modelo implementado (1 hora)  

## Módulo 4: Conversão de Formato e Quantização de Modelos  

### Objetivos de Aprendizagem  

- Dominar técnicas avançadas de quantização de 1-bit a 8-bit de precisão  
- Compreender estratégias de conversão de formato (GGUF, ONNX)  
- Implementar otimização em seis frameworks (Llama.cpp, Olive, OpenVINO, MLX, síntese de fluxos de trabalho)  
- Implementar modelos otimizados para ambientes de produção na borda em hardware Intel, Apple e multiplataforma  

### Áreas de Foco de Estudo  

#### Seção 1: Fundamentos de Quantização  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de precisão  
  - Compromissos entre desempenho e precisão  
  - Otimização de uso de memória  

#### Seção 2: Implementação com Llama.cpp  
- **Conceitos Prioritários**:  
  - Implementação multiplataforma  
  - Otimização de formato GGUF  
  - Técnicas de aceleração de hardware  

#### Seção 3: Suite Microsoft Olive  
- **Conceitos Prioritários**:  
  - Otimização orientada por hardware  
  - Implementação de nível empresarial  
  - Fluxos de trabalho de otimização automatizados  

#### Seção 4: Toolkit OpenVINO  
- **Conceitos Prioritários**:  
  - Otimização para hardware Intel  
  - Framework de Compressão de Redes Neurais (NNCF)  
  - Implementação de inferência multiplataforma  
  - OpenVINO GenAI para implementação de LLM  

#### Seção 5: Framework Apple MLX  
- **Conceitos Prioritários**:  
  - Otimização para Apple Silicon  
  - Arquitetura de memória unificada  
  - Capacidades de ajuste fino com LoRA  

#### Seção 6: Síntese de Fluxos de Trabalho para Edge AI  
- **Conceitos Prioritários**:  
  - Arquitetura de fluxos de trabalho unificados  
  - Árvores de decisão para seleção de frameworks  
  - Validação de prontidão para produção  
  - Estratégias para garantir longevidade  

### Perguntas de Autoavaliação  

1. Compare estratégias de quantização em diferentes níveis de precisão (1-bit a 8-bit).  
2. Explique as vantagens do formato GGUF para implementação na borda.  
3. Como a otimização orientada por hardware no Microsoft Olive melhora a eficiência de implementação?  
4. Quais são os principais benefícios do NNCF do OpenVINO para compressão de modelos?  
5. Descreva como o Apple MLX utiliza a arquitetura de memória unificada para otimização.  
6. Como a síntese de fluxos de trabalho ajuda na seleção de frameworks de otimização ideais?  

### Exercícios Práticos  

1. **Quantização de Modelos**: Aplicar diferentes níveis de quantização a um modelo e comparar os resultados (1 hora)  
2. **Otimização com OpenVINO**: Usar NNCF para comprimir um modelo para hardware Intel (1 hora)  
3. **Comparação de Frameworks**: Testar o mesmo modelo em três frameworks de otimização diferentes (1 hora)  
4. **Benchmark de Desempenho**: Medir o impacto da otimização na velocidade de inferência e uso de memória (1 hora)  

## Módulo 5: SLMOps - Operações com Modelos de Linguagem Pequenos  

### Objetivos de Aprendizagem  

- Compreender os princípios de gestão do ciclo de vida do SLMOps  
- Dominar técnicas de destilação e ajuste fino para implementação na borda  
- Implementar estratégias de implementação em produção com monitorização  
- Construir fluxos de trabalho de operações e manutenção de SLM de nível empresarial  

### Áreas de Foco de Estudo  

#### Seção 1: Introdução ao SLMOps  
- **Conceitos Prioritários**:  
  - Mudança de paradigma do SLMOps nas operações de IA  
  - Arquitetura com foco em eficiência de custos e privacidade  
  - Impacto estratégico nos negócios e vantagens competitivas  

#### Seção 2: Destilação de Modelos  
- **Conceitos Prioritários**:  
  - Técnicas de transferência de conhecimento  
  - Implementação do processo de destilação em duas etapas  
  - Fluxos de trabalho de destilação com Azure ML  

#### Seção 3: Estratégias de Ajuste Fino  
- **Conceitos Prioritários**:  
  - Ajuste fino eficiente em parâmetros (PEFT)  
  - Métodos avançados LoRA e QLoRA  
  - Treinamento multi-adaptador e otimização de hiperparâmetros  

#### Seção 4: Implementação em Produção  
- **Conceitos Prioritários**:  
  - Conversão e quantização de modelos para produção  
  - Configuração de implementação com Foundry Local  
  - Benchmark de desempenho e validação de qualidade  

### Perguntas de Autoavaliação  

1. Como o SLMOps difere do MLOps tradicional?  
2. Explique os benefícios da destilação de modelos para implementação na borda.  
3. Quais são as principais considerações para ajuste fino de SLMs em ambientes com recursos limitados?  
4. Descreva um pipeline completo de implementação em produção para aplicações de IA na borda.  

### Exercícios Práticos  

1. **Destilação Básica**: Criar um modelo menor a partir de um modelo maior (1 hora)  
2. **Experimento de Ajuste Fino**: Ajustar um modelo para um domínio específico (1 hora)  
3. **Pipeline de Implementação**: Configurar um pipeline básico de CI/CD para implementação de modelos (1 hora)  

## Módulo 6: Sistemas Agentes com SLM - Agentes de IA e Chamadas de Função  

### Objetivos de Aprendizagem  

- Construir agentes inteligentes de IA para ambientes na borda usando Modelos de Linguagem Pequenos  
- Implementar capacidades de chamadas de função com fluxos de trabalho sistemáticos  
- Dominar a integração do Protocolo de Contexto de Modelo (MCP) para interação padronizada com ferramentas  
- Criar sistemas agentes sofisticados com intervenção humana mínima  

### Áreas de Foco de Estudo  

#### Seção 1: Agentes de IA e Fundamentos de SLM  
- **Conceitos Prioritários**:  
  - Estrutura de classificação de agentes (reflexivos, baseados em modelo, baseados em objetivos, agentes de aprendizagem)  
  - Análise de compromissos entre SLM e LLM  
  - Padrões de design específicos para agentes na borda  
  - Otimização de recursos para agentes  

#### Seção 2: Chamadas de Função em Modelos de Linguagem Pequenos  
- **Conceitos Prioritários**:  
  - Implementação de fluxos de trabalho sistemáticos (detecção de intenção, saída em JSON, execução externa)  
  - Implementações específicas de plataforma (Phi-4-mini, modelos Qwen selecionados, Microsoft Foundry Local)  
  - Exemplos avançados (colaboração multi-agente, seleção dinâmica de ferramentas)  
  - Considerações para produção (limitação de taxa, registo de auditoria, medidas de segurança)  

#### Seção 3: Integração do Protocolo de Contexto de Modelo (MCP)  
- **Conceitos Prioritários**:  
  - Arquitetura de protocolo e design de sistema em camadas  
  - Suporte multi-backend (Ollama para desenvolvimento, vLLM para produção)  
  - Protocolos de conexão (modos STDIO e SSE)  
  - Aplicações reais (automação web, processamento de dados, integração com APIs)  

### Perguntas de Autoavaliação  

1. Quais são as principais considerações arquiteturais para agentes de IA na borda?  
2. Como as chamadas de função ampliam as capacidades dos agentes?  
3. Explique o papel do Protocolo de Contexto de Modelo na comunicação entre agentes.  

### Exercícios Práticos  

1. **Agente Simples**: Construir um agente de IA básico com chamadas de função (1 hora)  
2. **Integração MCP**: Implementar MCP numa aplicação de agente (30 minutos)  

## Módulo 7: Exemplos de Implementação de EdgeAI  

### Objetivos de Aprendizagem  

- Dominar o AI Toolkit para Visual Studio Code para fluxos de trabalho abrangentes de desenvolvimento EdgeAI  
- Obter expertise na plataforma Windows AI Foundry e estratégias de otimização NPU  
- Implementar EdgeAI em múltiplas plataformas de hardware e cenários de implementação  
- Construir aplicações EdgeAI prontas para produção com otimizações específicas de plataforma  

### Áreas de Foco de Estudo  

#### Seção 1: AI Toolkit para Visual Studio Code  
- **Conceitos Prioritários**:  
  - Ambiente abrangente de desenvolvimento de Edge AI no VS Code  
  - Catálogo de modelos e descoberta para implementação na borda  
  - Testes locais, otimização e fluxos de trabalho de desenvolvimento de agentes  
  - Monitorização de desempenho e avaliação para cenários na borda  

#### Seção 2: Guia de Desenvolvimento EdgeAI para Windows  
- **Conceitos Prioritários**:  
  - Visão geral abrangente da plataforma Windows AI Foundry  
  - API Phi Silica para inferência eficiente em NPU  
  - APIs de Visão Computacional para processamento de imagens e OCR  
  - CLI Foundry Local para desenvolvimento e testes locais  

#### Seção 3: Implementações Específicas de Plataforma  
- **Conceitos Prioritários**:  
  - Implementação no NVIDIA Jetson Orin Nano (67 TOPS de desempenho em IA)  
  - Aplicações móveis com .NET MAUI e ONNX Runtime GenAI  
  - Soluções Azure EdgeAI com arquitetura híbrida nuvem-borda  
  - Otimização Windows ML com suporte universal de hardware  
  - Aplicações Foundry Local com implementação RAG focada em privacidade  

### Perguntas de Autoavaliação  

1. Como o AI Toolkit simplifica o fluxo de trabalho de desenvolvimento EdgeAI?  
2. Compare estratégias de implementação em diferentes plataformas de hardware.  
3. Quais são as vantagens do Windows AI Foundry para desenvolvimento na borda?  
4. Explique o papel da otimização NPU em aplicações modernas de Edge AI.  
5. Como a API Phi Silica utiliza hardware NPU para otimização de desempenho?  
6. Compare os benefícios de implementação local vs. na nuvem para aplicações sensíveis à privacidade.  

### Exercícios Práticos  

1. **Configuração do AI Toolkit**: Configurar o AI Toolkit e otimizar um modelo (1 hora)  
2. **Windows AI Foundry**: Construir uma aplicação simples de IA para Windows usando a API Phi Silica (1 hora)  
3. **Implementação Multiplataforma**: Implementar o mesmo modelo em duas plataformas diferentes (1 hora)  
4. **Otimização NPU**: Testar o desempenho da NPU com ferramentas do Windows AI Foundry (30 minutos)  

## Módulo 8: Microsoft Foundry Local – Kit de Ferramentas Completo para Desenvolvedores (Modernizado)  

### Objetivos de Aprendizagem  

- Instalar e configurar o Foundry Local com integração moderna de SDK  
- Implementar sistemas avançados multi-agente com padrões de coordenação  
- Construir roteadores inteligentes de modelos com seleção automática baseada em tarefas  
- Implementar soluções de IA prontas para produção com monitorização abrangente  
- Integrar com Azure AI Foundry para cenários de implementação híbrida  
- Dominar padrões modernos de SDK com FoundryLocalManager e cliente OpenAI  

### Áreas de Foco de Estudo  

#### Seção 1: Instalação e Configuração Modernas  
- **Conceitos Prioritários**:  
  - Integração do SDK FoundryLocalManager  
  - Descoberta automática de serviços e monitorização de saúde  
  - Padrões de configuração baseados em ambiente  
  - Considerações para implementação em produção  

#### Seção 2: Sistemas Multi-Agente Avançados  
- **Conceitos Prioritários**:  
  - Padrão de coordenação com agentes especialistas  
  - Especialização de agentes em recuperação, raciocínio e execução  
  - Mecanismos de feedback para refinamento  
  - Monitorização de desempenho e rastreamento de estatísticas  

#### Seção 3: Roteamento Inteligente de Modelos  
- **Conceitos Prioritários**:  
  - Algoritmos de seleção de modelos baseados em palavras-chave  
  - Suporte a múltiplos modelos (geral, raciocínio, código, criativo)  
  - Configuração de variáveis de ambiente para flexibilidade  
  - Verificação de saúde de serviços e tratamento de erros  

#### Seção 4: Implementação Pronta para Produção  
- **Conceitos Prioritários**:  
  - Tratamento abrangente de erros e mecanismos de fallback  
  - Monitorização de solicitações e rastreamento de desempenho  
  - Exemplos interativos em Jupyter notebooks com benchmarks  
  - Padrões de integração com aplicações existentes  

### Perguntas de Autoavaliação  

1. Como a abordagem moderna do FoundryLocalManager difere de chamadas REST manuais?  
2. Explique o padrão de coordenação e como ele orquestra agentes especialistas.  
3. Como o roteador inteligente seleciona modelos apropriados com base no conteúdo da consulta?  
4. Quais são os principais componentes de um sistema de agentes de IA pronto para produção?  
5. Como implementar monitorização abrangente para serviços Foundry Local?  
6. Compare os benefícios da abordagem modernizada vs. padrões de implementação tradicionais.  

### Exercícios Práticos  

1. **Configuração do SDK Moderno**: Configurar o FoundryLocalManager com descoberta automática de serviços (30 minutos)  
2. **Sistema Multi-Agente**: Executar o coordenador avançado com agentes especialistas (30 minutos)  
3. **Roteamento Inteligente**: Testar o roteador de modelos com diferentes tipos de consulta (30 minutos)  
4. **Exploração Interativa**: Usar os Jupyter notebooks para explorar recursos avançados (45 minutos)  
5. **Implementação em Produção**: Implementar padrões de monitorização e tratamento de erros (30 minutos)  
6. **Integração Híbrida**: Configurar cenários de fallback com Azure AI Foundry (30 minutos)  

## Guia de Alocação de Tempo  

Para ajudar a aproveitar ao máximo as 20 horas do curso, aqui está uma sugestão de como alocar o tempo:  

| Atividade | Alocação de Tempo | Descrição |  
|-----------|-------------------|-----------|  
| Leitura de Materiais Essenciais | 9 horas | Foco nos conceitos essenciais de cada módulo |  
| Exercícios Práticos | 6 horas | Implementação prática de técnicas essenciais |
| Autoavaliação | 2 horas | Testar a sua compreensão através de perguntas e reflexão |
| Mini-Projeto | 3 horas | Aplicar conhecimentos numa pequena implementação prática |

### Áreas de Foco Principais por Limitação de Tempo

**Se só tiver 10 horas:**
- Complete o Módulo 0 (Introdução) e os Módulos 1, 2 e 3 (conceitos principais de EdgeAI)
- Realize pelo menos um exercício prático por módulo
- Foque-se em compreender os conceitos principais em vez de detalhes de implementação

**Se puder dedicar as 20 horas completas:**
- Complete todos os oito módulos (incluindo a Introdução)
- Realize os exercícios práticos principais de cada módulo
- Complete um mini-projeto do Módulo 7
- Explore pelo menos 2-3 recursos suplementares

**Se tiver mais de 20 horas:**
- Complete todos os módulos (incluindo a Introdução) com exercícios detalhados
- Desenvolva múltiplos mini-projetos
- Explore técnicas avançadas de otimização no Módulo 4
- Implemente a implantação em produção do Módulo 5

## Recursos Essenciais

Estes recursos cuidadosamente selecionados oferecem o maior valor para o seu tempo de estudo limitado:

### Documentação Essencial
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - A ferramenta mais eficiente para otimização de modelos
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Forma mais rápida de implementar SLMs localmente
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referência para um modelo otimizado para edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit de ferramentas abrangente de otimização da Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente integrado de desenvolvimento EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Plataforma de desenvolvimento EdgeAI específica para Windows

### Ferramentas que Poupam Tempo
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acesso rápido a modelos e implementação
- [Gradio](https://www.gradio.app/docs/interface) - Desenvolvimento rápido de UI para demonstrações de IA
- [Microsoft Olive](https://github.com/microsoft/Olive) - Otimização de modelos simplificada
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferência eficiente em CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework de compressão de redes neurais
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit de ferramentas para implementação de modelos de linguagem de grande escala

## Modelo de Acompanhamento de Progresso

Utilize este modelo simplificado para acompanhar o seu progresso de aprendizagem ao longo do curso de 20 horas:

| Módulo | Data de Conclusão | Horas Dedicadas | Principais Aprendizados |
|--------|-------------------|-----------------|-------------------------|
| Módulo 0: Introdução ao EdgeAI | | | |
| Módulo 1: Fundamentos de EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implementação de SLM | | | |
| Módulo 4: Otimização de Modelos | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Agentes de IA | | | |
| Módulo 7: Ferramentas de Desenvolvimento | | | |
| Módulo 8: Foundry Local Toolkit | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

## Ideias para Mini-Projetos

Considere realizar um destes projetos para praticar conceitos de EdgeAI (cada um projetado para durar 2-4 horas):

### Projetos para Iniciantes (2-3 horas cada)
1. **Assistente de Texto Edge**: Crie uma ferramenta simples de preenchimento de texto offline usando um modelo de linguagem pequeno
2. **Dashboard de Comparação de Modelos**: Desenvolva uma visualização básica de métricas de desempenho entre diferentes SLMs
3. **Experimento de Otimização**: Meça o impacto de diferentes níveis de quantização no mesmo modelo base

### Projetos Intermediários (3-4 horas cada)
4. **Workflow com AI Toolkit**: Utilize o AI Toolkit do VS Code para otimizar e implementar um modelo do início ao fim
5. **Aplicação Windows AI Foundry**: Crie uma aplicação Windows usando a API Phi Silica e otimização NPU
6. **Implementação Multiplataforma**: Implemente o mesmo modelo otimizado no Windows (OpenVINO) e em dispositivos móveis (.NET MAUI)
7. **Agente com Chamadas de Função**: Desenvolva um agente de IA com capacidades de chamadas de função para cenários edge

### Projetos de Integração Avançada (4-5 horas cada)
8. **Pipeline de Otimização OpenVINO**: Implemente uma otimização completa de modelo usando NNCF e o kit de ferramentas GenAI
9. **Pipeline SLMOps**: Implemente um ciclo de vida completo de modelo, desde o treino até à implementação em edge
10. **Sistema Edge Multi-Modelo**: Implemente múltiplos modelos especializados a trabalhar em conjunto em hardware edge
11. **Sistema de Integração MCP**: Desenvolva um sistema agente utilizando o Model Context Protocol para interação com ferramentas

## Referências

- Microsoft Learn (Foundry Local)
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Introdução: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referência CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integração com SDKs de inferência: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Como abrir o WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compilar modelos Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agentes (visão geral): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Ferramentas de Otimização e Inferência
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (introdução): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integração ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html
- Frameworks de Implementação e Modelos
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (docs): https://docs.vllm.ai/
  - Ollama (introdução): https://github.com/ollama/ollama#get-started
- Ferramentas de Desenvolvimento (Windows e VS Code)
  - AI Toolkit para VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (visão geral): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Comunidade de Aprendizagem

Participe na discussão e conecte-se com outros aprendizes:
- Discussões no GitHub no [repositório EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Conclusão

EdgeAI representa a vanguarda da implementação de inteligência artificial, trazendo capacidades poderosas diretamente para dispositivos enquanto aborda preocupações críticas sobre privacidade, latência e conectividade. Este curso de 20 horas fornece-lhe o conhecimento essencial e as competências práticas para começar a trabalhar com tecnologias EdgeAI imediatamente.

O curso é deliberadamente conciso e focado nos conceitos mais importantes, permitindo-lhe adquirir rapidamente uma expertise valiosa sem um compromisso de tempo excessivo. Lembre-se de que a prática prática, mesmo com exemplos simples, é a chave para reforçar o que aprendeu.

Boa aprendizagem!

---

