<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T20:27:32+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "pt"
}
-->
# EdgeAI para Iniciantes: Percursos de Aprendizagem e Cronograma de Estudo

### Percurso de Aprendizagem Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 2 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 3 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 4-5 | Módulo 4: Otimização de Modelos (6 frameworks) | 4 horas |
| Dia 6 | Módulo 5: SLMOps | 3 horas |
| Dia 7 | Módulo 6-7: Agentes de IA & Ferramentas de Desenvolvimento | 4 horas |
| Dia 8 | Módulo 8: Foundry Local Toolkit (Implementação Moderna) | 1 hora |

### Percurso de Aprendizagem Concentrado (2 semanas)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Agentes de IA | 2 horas |
| Dia 13-14 | Módulo 7: Ferramentas de Desenvolvimento | 3 horas |

### Estudo a Tempo Parcial (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implementação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Sistemas Agentes de SLM | 2 horas |
| Dia 13-14 | Módulo 7: Exemplos de Implementação de EdgeAI | 2 horas |

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|----------------|-------------|--------------|
| Módulo 0: Introdução ao EdgeAI | | | |
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implementação de SLM | | | |
| Módulo 4: Otimização de Modelos (6 frameworks) | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Sistemas Agentes de SLM | | | |
| Módulo 7: Exemplos de Implementação de EdgeAI | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

### Estudo a Tempo Parcial (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implementação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

## Introdução

Bem-vindo ao guia de estudo "EdgeAI para Iniciantes"! Este documento foi criado para ajudá-lo a navegar pelos materiais do curso de forma eficaz e maximizar a sua experiência de aprendizagem. Ele oferece percursos de aprendizagem estruturados, cronogramas de estudo sugeridos, resumos de conceitos-chave e recursos suplementares para aprofundar o seu entendimento sobre as tecnologias de Edge AI.

Este é um curso conciso de 20 horas que fornece conhecimentos essenciais sobre EdgeAI de forma eficiente, sendo ideal para profissionais ocupados e estudantes que desejam adquirir rapidamente competências práticas nesta área emergente.

## Visão Geral do Curso

Este curso está organizado em oito módulos abrangentes:

0. **Introdução ao EdgeAI** - Contextualização e fundamentos com aplicações na indústria e objetivos de aprendizagem  
1. **Fundamentos e Transformação do EdgeAI** - Compreensão dos conceitos principais e da mudança tecnológica  
2. **Fundamentos de Modelos de Linguagem Pequenos (SLM)** - Exploração de várias famílias de SLM e suas arquiteturas  
3. **Implementação de Modelos de Linguagem Pequenos** - Estratégias práticas de implementação  
4. **Conversão de Formatos de Modelos e Quantização** - Otimização avançada com 6 frameworks, incluindo OpenVINO  
5. **SLMOps - Operações de Modelos de Linguagem Pequenos** - Gestão do ciclo de vida e implementação em produção  
6. **Sistemas Agentes de SLM** - Agentes de IA, chamadas de funções e Protocolo de Contexto de Modelos  
7. **Exemplos de Implementação de EdgeAI** - Toolkit de IA, desenvolvimento em Windows e implementações específicas de plataformas  
8. **Microsoft Foundry Local – Toolkit Completo para Desenvolvedores** - Desenvolvimento local com integração híbrida ao Azure (Módulo 08)

## Como Utilizar Este Guia de Estudo

- **Aprendizagem Progressiva**: Siga os módulos na ordem para uma experiência de aprendizagem mais coerente  
- **Pontos de Verificação de Conhecimento**: Utilize as perguntas de autoavaliação após cada seção  
- **Prática Prática**: Complete os exercícios sugeridos para reforçar os conceitos teóricos  
- **Recursos Suplementares**: Explore materiais adicionais para tópicos que mais lhe interessam  

## Recomendações de Cronograma de Estudo

### Percurso de Aprendizagem Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 0 | Módulo 0: Introdução ao EdgeAI | 1-2 horas |
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 6 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 8 horas |
| Dia 5 | Módulo 3: Implementação de SLM | 3 horas |
| Dia 6 | Módulo 8: Foundry Local Toolkit | 3 horas |

### Estudo a Tempo Parcial (3 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 0: Introdução + Módulo 1: Fundamentos do EdgeAI | 7-9 horas |
| Semana 2 | Módulo 2: Fundamentos de SLM | 7-8 horas |
| Semana 3 | Módulo 3: Implementação de SLM (3h) + Módulo 8: Foundry Local Toolkit (2-3h) | 5-6 horas |

## Módulo 0: Introdução ao EdgeAI

### Objetivos de Aprendizagem Principais

- Compreender o que é Edge AI e por que é relevante no cenário tecnológico atual  
- Identificar as principais indústrias transformadas pelo Edge AI e seus casos de uso específicos  
- Compreender as vantagens dos Modelos de Linguagem Pequenos (SLMs) para implementação em edge  
- Estabelecer expectativas claras de aprendizagem e resultados para o curso completo  
- Reconhecer oportunidades de carreira e requisitos de competências na área de Edge AI  

### Áreas de Foco de Estudo

#### Seção 1: Paradigma e Definição de Edge AI
- **Conceitos Prioritários**:  
  - Edge AI vs. processamento tradicional em cloud  
  - A convergência de hardware, otimização de modelos e demandas empresariais  
  - Implementação de IA em tempo real, preservação de privacidade e eficiência de custos  

#### Seção 2: Aplicações na Indústria
- **Conceitos Prioritários**:  
  - Manufatura & Indústria 4.0: Manutenção preditiva e controle de qualidade  
  - Saúde: Imagem diagnóstica e monitorização de pacientes  
  - Sistemas Autônomos: Veículos autônomos e transporte  
  - Cidades Inteligentes: Gestão de tráfego e segurança pública  
  - Tecnologia de Consumo: Smartphones, wearables e casas inteligentes  

#### Seção 3: Fundamentos de Modelos de Linguagem Pequenos
- **Conceitos Prioritários**:  
  - Características e comparações de desempenho de SLM  
  - Eficiência de parâmetros vs. trade-offs de capacidade  
  - Restrições de implementação em edge e estratégias de otimização  

#### Seção 4: Estrutura de Aprendizagem e Caminho de Carreira
- **Conceitos Prioritários**:  
  - Arquitetura do curso e abordagem de domínio progressivo  
  - Competências técnicas e objetivos de implementação prática  
  - Oportunidades de avanço na carreira e aplicações na indústria  

### Perguntas de Autoavaliação

1. Quais são as três principais tendências tecnológicas que possibilitaram o Edge AI?  
2. Compare as vantagens e desafios do Edge AI em relação à IA baseada em cloud.  
3. Nomeie três indústrias onde o Edge AI oferece valor crítico para os negócios e explique por quê.  
4. Como os Modelos de Linguagem Pequenos tornam o Edge AI prático para implementações reais?  
5. Quais são as principais competências técnicas que você desenvolverá ao longo deste curso?  
6. Descreva a abordagem de aprendizagem em quatro fases utilizada neste curso.  

### Exercícios Práticos

1. **Pesquisa de Indústria**: Escolha uma aplicação industrial e pesquise uma implementação real de Edge AI (30 minutos)  
2. **Exploração de Modelos**: Navegue pelos Modelos de Linguagem Pequenos disponíveis no Hugging Face e compare os seus contagens de parâmetros e capacidades (30 minutos)  
3. **Planeamento de Aprendizagem**: Revise a estrutura completa do curso e crie o seu cronograma de estudo pessoal (15 minutos)  

### Materiais Suplementares

- [Visão Geral do Mercado de Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Visão Geral de Modelos de Linguagem Pequenos - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Fundação de Computação em Edge](https://www.edgecomputing.org/)  

## Módulo 1: Fundamentos e Transformação do EdgeAI

### Objetivos de Aprendizagem Principais

- Compreender as diferenças entre IA baseada em cloud e IA baseada em edge  
- Dominar técnicas de otimização para ambientes com recursos limitados  
- Analisar aplicações reais de tecnologias EdgeAI  
- Configurar um ambiente de desenvolvimento para projetos de EdgeAI  

### Áreas de Foco de Estudo

#### Seção 1: Fundamentos do EdgeAI
- **Conceitos Prioritários**:  
  - Paradigmas de computação em edge vs. cloud  
  - Técnicas de quantização de modelos  
  - Opções de aceleração de hardware (NPUs, GPUs, CPUs)  
  - Vantagens de privacidade e segurança  

- **Materiais Suplementares**:  
  - [Documentação do TensorFlow Lite](https://www.tensorflow.org/lite)  
  - [GitHub do ONNX Runtime](https://github.com/microsoft/onnxruntime)  
  - [Documentação do Edge Impulse](https://docs.edgeimpulse.com)  

#### Seção 2: Estudos de Caso Reais
- **Conceitos Prioritários**:  
  - Ecossistema de modelos Microsoft Phi & Mu  
  - Implementações práticas em diferentes indústrias  
  - Considerações de implementação  

#### Seção 3: Guia de Implementação Prática
- **Conceitos Prioritários**:  
  - Configuração do ambiente de desenvolvimento  
  - Ferramentas de quantização e otimização  
  - Métodos de avaliação para implementações de EdgeAI  

#### Seção 4: Hardware de Implementação em Edge
- **Conceitos Prioritários**:  
  - Comparações de plataformas de hardware  
  - Estratégias de otimização para hardware específico  
  - Considerações de implementação  

### Perguntas de Autoavaliação

1. Compare e contraste implementações de IA baseada em cloud com IA baseada em edge.  
2. Explique três técnicas principais para otimizar modelos para implementação em edge.  
3. Quais são as principais vantagens de executar modelos de IA em edge?  
4. Descreva o processo de quantização de um modelo e como ele afeta o desempenho.  
5. Explique como diferentes aceleradores de hardware (NPUs, GPUs, CPUs) influenciam a implementação de EdgeAI.  

### Exercícios Práticos

1. **Configuração Rápida de Ambiente**: Configure um ambiente de desenvolvimento mínimo com os pacotes essenciais (30 minutos)  
2. **Exploração de Modelos**: Baixe e examine um modelo de linguagem pequeno pré-treinado (1 hora)  
3. **Quantização Básica**: Experimente uma quantização simples em um modelo pequeno (1 hora)  

## Módulo 2: Fundamentos de Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem Principais

- Compreender os princípios arquiteturais de diferentes famílias de SLM  
- Comparar capacidades de modelos em diferentes escalas de parâmetros  
- Avaliar modelos com base em eficiência, capacidade e requisitos de implementação  
- Reconhecer casos de uso apropriados para diferentes famílias de modelos  

### Áreas de Foco de Estudo

#### Seção 1: Família de Modelos Microsoft Phi
- **Conceitos Prioritários**:  
  - Evolução da filosofia de design  
  - Arquitetura com foco em eficiência  
  - Capacidades especializadas  

#### Seção 2: Família Qwen
- **Conceitos Prioritários**:  
  - Contribuições open source  
  - Opções de implementação escaláveis  
  - Arquitetura avançada de raciocínio  

#### Seção 3: Família Gemma
- **Conceitos Prioritários**:  
  - Inovação orientada por pesquisa  
  - Capacidades multimodais  
  - Otimização para dispositivos móveis  

#### Seção 4: Família BitNET
- **Conceitos Prioritários**:  
  - Tecnologia de quantização de 1-bit  
  - Framework de otimização de inferência  
  - Considerações de sustentabilidade  

#### Seção 5: Modelo Microsoft Mu
- **Conceitos Prioritários**:  
  - Arquitetura orientada para dispositivos  
  - Integração com sistemas Windows  
  - Operação com preservação de privacidade  

#### Seção 6: Phi-Silica
- **Conceitos Prioritários**:  
  - Arquitetura otimizada para NPU  
  - Métricas de desempenho  
  - Integração para desenvolvedores  

### Perguntas de Autoavaliação

1. Compare as abordagens arquiteturais das famílias de modelos Phi e Qwen.  
2. Explique como a tecnologia de quantização do BitNET difere da quantização tradicional.  
3. Quais são as vantagens únicas do modelo Mu para integração com Windows?
4. Descreva como o Phi-Silica utiliza hardware NPU para otimização de desempenho.
5. Para uma aplicação móvel com conectividade limitada, qual família de modelos seria mais apropriada e porquê?

### Exercícios Práticos

1. **Comparação de Modelos**: Benchmark rápido de dois modelos SLM diferentes (1 hora)
2. **Geração de Texto Simples**: Implementação básica de geração de texto com um modelo pequeno (1 hora)
3. **Otimização Rápida**: Aplicar uma técnica de otimização para melhorar a velocidade de inferência (1 hora)

## Módulo 3: Implementação de Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem Principais

- Selecionar modelos apropriados com base em restrições de implementação
- Dominar técnicas de otimização para diferentes cenários de implementação
- Implementar SLMs em ambientes locais e na nuvem
- Projetar configurações prontas para produção em aplicações EdgeAI

### Áreas de Foco de Estudo

#### Seção 1: Aprendizagem Avançada de SLM
- **Conceitos Prioritários**: 
  - Estrutura de classificação de parâmetros
  - Técnicas avançadas de otimização
  - Estratégias de aquisição de modelos

#### Seção 2: Implementação em Ambiente Local
- **Conceitos Prioritários**: 
  - Implementação na plataforma Ollama
  - Soluções locais da Microsoft Foundry
  - Análise comparativa de frameworks

#### Seção 3: Implementação em Nuvem com Contêineres
- **Conceitos Prioritários**: 
  - Inferência de alto desempenho com vLLM
  - Orquestração de contêineres
  - Implementação do ONNX Runtime

### Perguntas de Autoavaliação

1. Quais fatores devem ser considerados ao escolher entre implementação local e na nuvem?
2. Compare Ollama e Microsoft Foundry Local como opções de implementação.
3. Explique os benefícios da containerização para implementação de SLM.
4. Quais são as métricas de desempenho principais a monitorar em um SLM implementado na borda?
5. Descreva um fluxo completo de implementação, desde a seleção do modelo até a produção.

### Exercícios Práticos

1. **Implementação Local Básica**: Implementar um SLM simples usando Ollama (1 hora)
2. **Verificação de Desempenho**: Executar um benchmark rápido no modelo implementado (30 minutos)
3. **Integração Simples**: Criar uma aplicação mínima que utilize o modelo implementado (1 hora)

## Módulo 4: Conversão de Formato e Quantização de Modelos

### Objetivos de Aprendizagem Principais

- Dominar técnicas avançadas de quantização de precisão de 1-bit a 8-bit
- Compreender estratégias de conversão de formato (GGUF, ONNX)
- Implementar otimização em seis frameworks (Llama.cpp, Olive, OpenVINO, MLX, síntese de workflows)
- Implementar modelos otimizados para ambientes de produção na borda em hardware Intel, Apple e multiplataforma

### Áreas de Foco de Estudo

#### Seção 1: Fundamentos de Quantização
- **Conceitos Prioritários**: 
  - Estrutura de classificação de precisão
  - Compromissos entre desempenho e precisão
  - Otimização de uso de memória

#### Seção 2: Implementação com Llama.cpp
- **Conceitos Prioritários**: 
  - Implementação multiplataforma
  - Otimização de formato GGUF
  - Técnicas de aceleração de hardware

#### Seção 3: Suite Microsoft Olive
- **Conceitos Prioritários**: 
  - Otimização orientada por hardware
  - Implementação de nível empresarial
  - Workflows de otimização automatizados

#### Seção 4: Toolkit OpenVINO
- **Conceitos Prioritários**: 
  - Otimização para hardware Intel
  - Framework de Compressão de Redes Neurais (NNCF)
  - Implementação de inferência multiplataforma
  - OpenVINO GenAI para implementação de LLM

#### Seção 5: Framework Apple MLX
- **Conceitos Prioritários**: 
  - Otimização para Apple Silicon
  - Arquitetura de memória unificada
  - Capacidades de ajuste fino com LoRA

#### Seção 6: Síntese de Workflows de Desenvolvimento Edge AI
- **Conceitos Prioritários**: 
  - Arquitetura de workflow unificada
  - Árvores de decisão para seleção de frameworks
  - Validação de prontidão para produção
  - Estratégias para garantir longevidade

### Perguntas de Autoavaliação

1. Compare estratégias de quantização em diferentes níveis de precisão (1-bit a 8-bit).
2. Explique as vantagens do formato GGUF para implementação na borda.
3. Como a otimização orientada por hardware no Microsoft Olive melhora a eficiência da implementação?
4. Quais são os principais benefícios do NNCF do OpenVINO para compressão de modelos?
5. Descreva como o Apple MLX utiliza a arquitetura de memória unificada para otimização.
6. Como a síntese de workflows ajuda na seleção de frameworks de otimização ideais?

### Exercícios Práticos

1. **Quantização de Modelos**: Aplicar diferentes níveis de quantização a um modelo e comparar os resultados (1 hora)
2. **Otimização com OpenVINO**: Usar NNCF para comprimir um modelo para hardware Intel (1 hora)
3. **Comparação de Frameworks**: Testar o mesmo modelo em três frameworks de otimização diferentes (1 hora)
4. **Benchmark de Desempenho**: Medir o impacto da otimização na velocidade de inferência e uso de memória (1 hora)

## Módulo 5: SLMOps - Operações com Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem Principais

- Compreender os princípios de gestão do ciclo de vida do SLMOps
- Dominar técnicas de destilação e ajuste fino para implementação na borda
- Implementar estratégias de implementação em produção com monitorização
- Construir workflows de operações e manutenção de SLMs de nível empresarial

### Áreas de Foco de Estudo

#### Seção 1: Introdução ao SLMOps
- **Conceitos Prioritários**: 
  - Mudança de paradigma do SLMOps nas operações de IA
  - Arquitetura com foco em eficiência de custos e privacidade
  - Impacto estratégico nos negócios e vantagens competitivas

#### Seção 2: Destilação de Modelos
- **Conceitos Prioritários**: 
  - Técnicas de transferência de conhecimento
  - Implementação do processo de destilação em duas etapas
  - Workflows de destilação com Azure ML

#### Seção 3: Estratégias de Ajuste Fino
- **Conceitos Prioritários**: 
  - Ajuste fino eficiente em parâmetros (PEFT)
  - Métodos avançados LoRA e QLoRA
  - Treinamento multi-adaptador e otimização de hiperparâmetros

#### Seção 4: Implementação em Produção
- **Conceitos Prioritários**: 
  - Conversão e quantização de modelos para produção
  - Configuração de implementação com Foundry Local
  - Benchmark de desempenho e validação de qualidade

### Perguntas de Autoavaliação

1. Como o SLMOps difere do MLOps tradicional?
2. Explique os benefícios da destilação de modelos para implementação na borda.
3. Quais são as principais considerações para ajuste fino de SLMs em ambientes com recursos limitados?
4. Descreva um pipeline completo de implementação em produção para aplicações de IA na borda.

### Exercícios Práticos

1. **Destilação Básica**: Criar um modelo menor a partir de um modelo maior (1 hora)
2. **Experimento de Ajuste Fino**: Ajustar um modelo para um domínio específico (1 hora)
3. **Pipeline de Implementação**: Configurar um pipeline básico de CI/CD para implementação de modelos (1 hora)

## Módulo 6: Sistemas Agentes com SLM - Agentes de IA e Chamadas de Função

### Objetivos de Aprendizagem Principais

- Construir agentes de IA inteligentes para ambientes de borda usando Modelos de Linguagem Pequenos
- Implementar capacidades de chamadas de função com workflows sistemáticos
- Dominar a integração do Protocolo de Contexto de Modelo (MCP) para interação padronizada com ferramentas
- Criar sistemas agentes sofisticados com intervenção humana mínima

### Áreas de Foco de Estudo

#### Seção 1: Agentes de IA e Fundamentos de SLM
- **Conceitos Prioritários**: 
  - Estrutura de classificação de agentes (reflexivos, baseados em modelo, baseados em objetivos, agentes de aprendizagem)
  - Análise de trade-offs entre SLM e LLM
  - Padrões de design específicos para agentes na borda
  - Otimização de recursos para agentes

#### Seção 2: Chamadas de Função em Modelos de Linguagem Pequenos
- **Conceitos Prioritários**: 
  - Implementação de workflows sistemáticos (detecção de intenção, saída em JSON, execução externa)
  - Implementações específicas de plataforma (Phi-4-mini, modelos Qwen selecionados, Microsoft Foundry Local)
  - Exemplos avançados (colaboração multi-agente, seleção dinâmica de ferramentas)
  - Considerações de produção (limitação de taxa, registo de auditoria, medidas de segurança)

#### Seção 3: Integração do Protocolo de Contexto de Modelo (MCP)
- **Conceitos Prioritários**: 
  - Arquitetura de protocolo e design de sistema em camadas
  - Suporte multi-backend (Ollama para desenvolvimento, vLLM para produção)
  - Protocolos de conexão (modos STDIO e SSE)
  - Aplicações reais (automação web, processamento de dados, integração de APIs)

### Perguntas de Autoavaliação

1. Quais são as principais considerações arquiteturais para agentes de IA na borda?
2. Como as chamadas de função ampliam as capacidades dos agentes?
3. Explique o papel do Protocolo de Contexto de Modelo na comunicação entre agentes.

### Exercícios Práticos

1. **Agente Simples**: Construir um agente de IA básico com chamadas de função (1 hora)
2. **Integração MCP**: Implementar MCP numa aplicação de agente (30 minutos)

## Workshop: Caminho de Aprendizagem Prático

### Objetivos de Aprendizagem Principais

- Construir aplicações de IA prontas para produção usando o SDK Foundry Local e melhores práticas
- Implementar padrões abrangentes de tratamento de erros e feedback do utilizador
- Criar pipelines RAG com avaliação de qualidade e monitorização de desempenho
- Desenvolver sistemas multi-agentes com padrões de coordenação
- Dominar o roteamento inteligente de modelos para seleção baseada em tarefas
- Implementar soluções de IA com arquitetura local-primeira e preservação de privacidade

### Áreas de Foco de Estudo

#### Sessão 01: Introdução ao Foundry Local
- **Conceitos Prioritários**:
  - Integração do SDK FoundryLocalManager e descoberta automática de serviços
  - Implementações básicas e de chat em streaming
  - Padrões de tratamento de erros e feedback do utilizador
  - Configuração baseada no ambiente

#### Sessão 02: Construção de Soluções de IA com RAG
- **Conceitos Prioritários**:
  - Embeddings vetoriais em memória com sentence-transformers
  - Implementação de pipeline RAG (recuperar → gerar)
  - Avaliação de qualidade com métricas RAGAS
  - Segurança de importação para dependências opcionais

#### Sessão 03: Modelos Open Source
- **Conceitos Prioritários**:
  - Estratégias de benchmarking multi-modelo
  - Medições de latência e throughput
  - Degradação graciosa e recuperação de erros
  - Comparação de desempenho entre famílias de modelos

#### Sessão 04: Modelos de Última Geração
- **Conceitos Prioritários**:
  - Metodologia de comparação entre SLM e LLM
  - Dicas de tipo e formatação abrangente de saída
  - Tratamento de erros por modelo
  - Resultados estruturados para análise

#### Sessão 05: Agentes Potenciados por IA
- **Conceitos Prioritários**:
  - Orquestração multi-agente com padrão de coordenação
  - Gestão de memória de agentes e rastreamento de estado
  - Tratamento de erros em pipeline e registo de etapas
  - Monitorização de desempenho e estatísticas

#### Sessão 06: Modelos como Ferramentas
- **Conceitos Prioritários**:
  - Detecção de intenção e correspondência de padrões
  - Algoritmos de roteamento de modelos baseados em palavras-chave
  - Pipelines multi-etapas (planejar → executar → refinar)
  - Documentação abrangente de funções

### Perguntas de Autoavaliação

1. Como o FoundryLocalManager simplifica a gestão de serviços em comparação com chamadas REST manuais?
2. Explique a importância de guardas de importação para dependências opcionais como sentence-transformers.
3. Quais estratégias garantem degradação graciosa em benchmarking multi-modelo?
4. Como o padrão de coordenação orquestra múltiplos agentes especialistas?
5. Descreva os componentes de um roteador inteligente de modelos.
6. Quais são os elementos-chave de um tratamento de erros pronto para produção?

### Exercícios Práticos

1. **Aplicação de Chat**: Implementar chat em streaming com tratamento de erros (45 minutos)
2. **Pipeline RAG**: Construir um RAG mínimo com avaliação de qualidade (1 hora)
3. **Benchmark de Modelos**: Comparar 3+ modelos em desempenho (1 hora)
4. **Sistema Multi-Agente**: Criar um coordenador com 2 agentes especialistas (1,5 horas)
5. **Roteador Inteligente**: Construir seleção de modelos baseada em tarefas (1 hora)
6. **Implementação em Produção**: Adicionar monitorização e tratamento de erros abrangente (45 minutos)

### Alocação de Tempo

**Aprendizagem Concentrada (1 semana)**:
- Dia 1: Sessões 01-02 (Chat + RAG) - 3 horas
- Dia 2: Sessões 03-04 (Benchmarking + Comparação) - 3 horas
- Dia 3: Sessões 05-06 (Agentes + Roteamento) - 3 horas
- Dia 4: Exercícios práticos e validação - 2 horas

**Estudo em Part-Time (2 semanas)**:
- Semana 1: Sessões 01-03 (6 horas no total)
- Semana 2: Sessões 04-06 + exercícios (5 horas no total)

## Módulo 7: Exemplos de Implementação EdgeAI

### Objetivos de Aprendizagem Principais

- Dominar o AI Toolkit para Visual Studio Code para workflows abrangentes de desenvolvimento EdgeAI
- Obter expertise na plataforma Windows AI Foundry e estratégias de otimização NPU
- Implementar EdgeAI em múltiplas plataformas de hardware e cenários de implementação
- Construir aplicações EdgeAI prontas para produção com otimizações específicas de plataforma

### Áreas de Foco de Estudo

#### Seção 1: AI Toolkit para Visual Studio Code
- **Conceitos Prioritários**: 
  - Ambiente abrangente de desenvolvimento Edge AI dentro do VS Code
  - Catálogo de modelos e descoberta para implementação na borda
  - Testes locais, otimização e workflows de desenvolvimento de agentes
  - Monitorização de desempenho e avaliação para cenários na borda

#### Seção 2: Guia de Desenvolvimento EdgeAI no Windows
- **Conceitos Prioritários**: 
  - Visão geral abrangente da plataforma Windows AI Foundry
  - API Phi Silica para inferência eficiente em NPU
  - APIs de Visão Computacional para processamento de imagens e OCR
  - CLI Foundry Local para desenvolvimento e testes locais

#### Seção 3: Implementações Específicas de Plataforma
- **Conceitos Prioritários**: 
  - Implementação no NVIDIA Jetson Orin Nano (67 TOPS de desempenho em IA)
  - Aplicações móveis com .NET MAUI e ONNX Runtime GenAI
  - Soluções Azure EdgeAI com arquitetura híbrida nuvem-borda
  - Otimização Windows ML com suporte universal de hardware
  - Aplicações Foundry Local com implementação RAG focada em privacidade

### Perguntas de Autoavaliação

1. Como o AI Toolkit simplifica o workflow de desenvolvimento EdgeAI?
2. Compare estratégias de implementação em diferentes plataformas de hardware.
3. Quais são as vantagens do Windows AI Foundry para desenvolvimento na borda?
4. Explique o papel da otimização de NPU nas aplicações modernas de IA na periferia.  
5. Como a API Phi Silica utiliza o hardware NPU para otimização de desempenho?  
6. Compare os benefícios da implementação local versus na nuvem para aplicações sensíveis à privacidade.  

### Exercícios Práticos  

1. **Configuração do AI Toolkit**: Configure o AI Toolkit e otimize um modelo (1 hora)  
2. **Windows AI Foundry**: Crie uma aplicação simples de IA para Windows usando a API Phi Silica (1 hora)  
3. **Implementação Multiplataforma**: Implemente o mesmo modelo em duas plataformas diferentes (1 hora)  
4. **Otimização de NPU**: Teste o desempenho da NPU com as ferramentas do Windows AI Foundry (30 minutos)  

## Módulo 8: Microsoft Foundry Local – Kit de Ferramentas Completo para Desenvolvedores (Modernizado)  

### Objetivos de Aprendizagem  

- Instalar e configurar o Foundry Local com integração moderna de SDK  
- Implementar sistemas avançados multiagente com padrões de coordenação  
- Construir roteadores inteligentes de modelos com seleção automática baseada em tarefas  
- Implementar soluções de IA prontas para produção com monitorização abrangente  
- Integrar com o Azure AI Foundry para cenários de implementação híbrida  
- Dominar padrões modernos de SDK com FoundryLocalManager e cliente OpenAI  

### Áreas de Estudo  

#### Secção 1: Instalação e Configuração Modernas  
- **Conceitos Prioritários**:  
  - Integração do SDK FoundryLocalManager  
  - Descoberta automática de serviços e monitorização de saúde  
  - Padrões de configuração baseados em ambiente  
  - Considerações para implementação em produção  

#### Secção 2: Sistemas Multiagente Avançados  
- **Conceitos Prioritários**:  
  - Padrão de coordenação com agentes especialistas  
  - Especialização de agentes em recuperação, raciocínio e execução  
  - Mecanismos de loop de feedback para refinamento  
  - Monitorização de desempenho e rastreamento de estatísticas  

#### Secção 3: Roteamento Inteligente de Modelos  
- **Conceitos Prioritários**:  
  - Algoritmos de seleção de modelos baseados em palavras-chave  
  - Suporte a múltiplos modelos (geral, raciocínio, código, criativo)  
  - Configuração de variáveis de ambiente para flexibilidade  
  - Verificação de saúde do serviço e tratamento de erros  

#### Secção 4: Implementação Pronta para Produção  
- **Conceitos Prioritários**:  
  - Mecanismos abrangentes de tratamento de erros e alternativas  
  - Monitorização de pedidos e rastreamento de desempenho  
  - Exemplos interativos em Jupyter notebooks com benchmarks  
  - Padrões de integração com aplicações existentes  

### Perguntas de Autoavaliação  

1. Como a abordagem moderna do FoundryLocalManager difere das chamadas REST manuais?  
2. Explique o padrão de coordenação e como ele orquestra agentes especialistas.  
3. Como o roteador inteligente seleciona modelos apropriados com base no conteúdo da consulta?  
4. Quais são os componentes principais de um sistema de agentes de IA pronto para produção?  
5. Como implementar uma monitorização abrangente de saúde para os serviços do Foundry Local?  
6. Compare os benefícios da abordagem modernizada versus padrões de implementação tradicionais.  

### Exercícios Práticos  

1. **Configuração do SDK Moderno**: Configure o FoundryLocalManager com descoberta automática de serviços (30 minutos)  
2. **Sistema Multiagente**: Execute o coordenador avançado com agentes especialistas (30 minutos)  
3. **Roteamento Inteligente**: Teste o roteador de modelos com diferentes tipos de consultas (30 minutos)  
4. **Exploração Interativa**: Utilize os Jupyter notebooks para explorar funcionalidades avançadas (45 minutos)  
5. **Implementação em Produção**: Implemente padrões de monitorização e tratamento de erros (30 minutos)  
6. **Integração Híbrida**: Configure cenários de fallback com Azure AI Foundry (30 minutos)  

## Guia de Alocação de Tempo  

Para ajudar a aproveitar ao máximo o cronograma estendido de 30 horas do curso (incluindo Workshop), aqui está uma sugestão de como alocar o seu tempo:  

| Atividade | Alocação de Tempo | Descrição |  
|-----------|-------------------|-----------|  
| Leitura de Materiais Essenciais | 12 horas | Foco nos conceitos essenciais de cada módulo |  
| Exercícios Práticos | 10 horas | Implementação prática de técnicas-chave (incluindo Workshop) |  
| Autoavaliação | 3 horas | Teste de compreensão através de perguntas e reflexão |  
| Mini-Projeto | 5 horas | Aplicação de conhecimentos numa implementação prática pequena |  

### Áreas de Foco por Restrições de Tempo  

**Se tiver apenas 10 horas:**  
- Complete o Módulo 0 (Introdução) e os Módulos 1, 2 e 3 (conceitos principais de EdgeAI)  
- Realize pelo menos um exercício prático por módulo  
- Foque na compreensão dos conceitos principais em vez de detalhes de implementação  

**Se puder dedicar as 20 horas completas:**  
- Complete todos os oito módulos (incluindo Introdução)  
- Realize os principais exercícios práticos de cada módulo  
- Complete um mini-projeto do Módulo 7  
- Explore pelo menos 2-3 recursos suplementares  

**Se tiver mais de 20 horas:**  
- Complete todos os módulos (incluindo Introdução) com exercícios detalhados  
- Desenvolva múltiplos mini-projetos  
- Explore técnicas avançadas de otimização no Módulo 4  
- Implemente a implementação em produção do Módulo 5  

## Recursos Essenciais  

Estes recursos cuidadosamente selecionados oferecem o máximo valor para o seu tempo de estudo limitado:  

### Documentação Essencial  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - A ferramenta mais eficiente para otimização de modelos  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Forma mais rápida de implementar SLMs localmente  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referência para um modelo otimizado para a periferia  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit de ferramentas abrangente de otimização da Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente integrado de desenvolvimento EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Plataforma de desenvolvimento EdgeAI específica para Windows  

### Ferramentas que Poupam Tempo  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acesso rápido a modelos e implementação  
- [Gradio](https://www.gradio.app/docs/interface) - Desenvolvimento rápido de UI para demonstrações de IA  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Otimização simplificada de modelos  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferência eficiente em CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework de compressão de redes neurais  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit de ferramentas para implementação de modelos de linguagem grandes  

## Modelo de Rastreamento de Progresso  

Utilize este modelo simplificado para acompanhar o seu progresso de aprendizagem ao longo do curso de 20 horas:  

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |  
|--------|-------------------|--------------|--------------------------|  
| Módulo 0: Introdução ao EdgeAI | | | |  
| Módulo 1: Fundamentos de EdgeAI | | | |  
| Módulo 2: Fundamentos de SLM | | | |  
| Módulo 3: Implementação de SLM | | | |  
| Módulo 4: Otimização de Modelos | | | |  
| Módulo 5: SLMOps | | | |  
| Módulo 6: Agentes de IA | | | |  
| Módulo 7: Ferramentas de Desenvolvimento | | | |  
| Workshop: Aprendizagem Prática | | | |  
| Módulo 8: Kit de Ferramentas Foundry Local | | | |  
| Exercícios Práticos | | | |  
| Mini-Projeto | | | |  

## Ideias de Mini-Projetos  

Considere realizar um destes projetos para praticar conceitos de EdgeAI (cada um projetado para levar 2-4 horas):  

### Projetos para Iniciantes (2-3 horas cada)  
1. **Assistente de Texto na Periferia**: Crie uma ferramenta simples de preenchimento de texto offline usando um modelo de linguagem pequeno  
2. **Dashboard de Comparação de Modelos**: Desenvolva uma visualização básica de métricas de desempenho entre diferentes SLMs  
3. **Experimento de Otimização**: Meça o impacto de diferentes níveis de quantização no mesmo modelo base  

### Projetos Intermediários (3-4 horas cada)  
4. **Workflow do AI Toolkit**: Utilize o AI Toolkit do VS Code para otimizar e implementar um modelo do início ao fim  
5. **Aplicação Windows AI Foundry**: Crie uma aplicação para Windows usando a API Phi Silica e otimização de NPU  
6. **Implementação Multiplataforma**: Implemente o mesmo modelo otimizado no Windows (OpenVINO) e em dispositivos móveis (.NET MAUI)  
7. **Agente de Chamadas de Função**: Desenvolva um agente de IA com capacidades de chamadas de função para cenários na periferia  

### Projetos de Integração Avançada (4-5 horas cada)  
8. **Pipeline de Otimização OpenVINO**: Implemente a otimização completa de modelos usando NNCF e o kit de ferramentas GenAI  
9. **Pipeline SLMOps**: Implemente um ciclo de vida completo de modelos, desde o treino até à implementação na periferia  
10. **Sistema Multi-Modelo na Periferia**: Implemente múltiplos modelos especializados trabalhando juntos em hardware na periferia  
11. **Sistema de Integração MCP**: Desenvolva um sistema agente utilizando o Model Context Protocol para interação com ferramentas  

## Referências  

- Microsoft Learn (Foundry Local)  
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Introdução: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Referência CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integração com SDKs de inferência: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Como abrir o WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Compilar modelos Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agentes (visão geral): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Ferramentas de Otimização e Inferência  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (introdução): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Integração ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Frameworks de Implementação e Modelos  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (introdução): https://github.com/ollama/ollama#get-started  
- Ferramentas de Desenvolvimento (Windows e VS Code)  
  - AI Toolkit para VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (visão geral): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Comunidade de Aprendizagem  

Participe na discussão e conecte-se com outros aprendizes:  
- Discussões no GitHub sobre o [repositório EdgeAI para Iniciantes](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Conclusão  

EdgeAI representa a vanguarda da implementação de inteligência artificial, trazendo capacidades poderosas diretamente para dispositivos enquanto aborda preocupações críticas sobre privacidade, latência e conectividade. Este curso de 20 horas fornece o conhecimento essencial e as habilidades práticas para começar a trabalhar com tecnologias EdgeAI imediatamente.  

O curso é deliberadamente conciso e focado nos conceitos mais importantes, permitindo que você adquira rapidamente uma expertise valiosa sem um compromisso de tempo excessivo. Lembre-se de que a prática prática, mesmo com exemplos simples, é a chave para reforçar o que aprendeu.  

Boa aprendizagem!  

---

**Aviso**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precisão, é importante notar que traduções automáticas podem conter erros ou imprecisões. O documento original na sua língua nativa deve ser considerado a fonte autoritária. Para informações críticas, recomenda-se uma tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes da utilização desta tradução.