<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T11:23:13+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "pt"
}
-->
# EdgeAI para Iniciantes: Percursos de Aprendizagem e Cronograma de Estudo

### Percurso de Aprendizagem Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 2 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 3 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 4-5 | Módulo 4: Otimização de Modelos (6 frameworks) | 4 horas |
| Dia 6 | Módulo 5: SLMOps | 3 horas |
| Dia 7 | Módulo 6-7: Agentes de IA & Ferramentas de Desenvolvimento | 4 horas |
| Dia 8 | Módulo 8: Toolkit Local Foundry (Implementação Moderna) | 1 hora |

### Percurso de Aprendizagem Concentrado (2 semanas)

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Agentes de IA | 2 horas |
| Dia 13-14 | Módulo 7: Ferramentas de Desenvolvimento | 3 horas |

### Estudo a Tempo Parcial (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implementação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

| Dia | Foco | Horas Estimadas |
|------|-------|------------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 3 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 3 horas |
| Dia 5-6 | Módulo 3: Implementação de SLM | 2 horas |
| Dia 7-8 | Módulo 4: Otimização de Modelos | 4 horas |
| Dia 9-10 | Módulo 5: SLMOps | 3 horas |
| Dia 11-12 | Módulo 6: Sistemas Agentes de SLM | 2 horas |
| Dia 13-14 | Módulo 7: Exemplos de Implementação de EdgeAI | 2 horas |

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|----------------|-------------|--------------|
| Módulo 1: Fundamentos do EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implementação de SLM | | | |
| Módulo 4: Otimização de Modelos (6 frameworks) | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Sistemas Agentes de SLM | | | |
| Módulo 7: Exemplos de Implementação de EdgeAI | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

### Estudo a Tempo Parcial (4 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|------------------|
| Semana 1 | Módulo 1-2: Fundamentos & Fundamentos de SLM | 6 horas |
| Semana 2 | Módulo 3-4: Implementação & Otimização | 6 horas |
| Semana 3 | Módulo 5-6: SLMOps & Agentes de IA | 5 horas |
| Semana 4 | Módulo 7: Ferramentas de Desenvolvimento & Integração | 3 horas |

## Introdução

Bem-vindo ao guia de estudo "EdgeAI para Iniciantes"! Este documento foi criado para ajudá-lo a navegar pelos materiais do curso de forma eficaz e maximizar a sua experiência de aprendizagem. Ele oferece percursos de aprendizagem estruturados, cronogramas de estudo sugeridos, resumos de conceitos-chave e recursos suplementares para aprofundar o seu conhecimento sobre tecnologias de EdgeAI.

Este é um curso conciso de 20 horas que fornece conhecimentos essenciais sobre EdgeAI de forma eficiente, sendo ideal para profissionais ocupados e estudantes que desejam adquirir rapidamente competências práticas nesta área emergente.

## Visão Geral do Curso

Este curso está organizado em sete módulos abrangentes:

1. **Fundamentos e Transformação do EdgeAI** - Compreender os conceitos principais e a mudança tecnológica
2. **Fundamentos de Modelos de Linguagem Pequenos (SLM)** - Explorar várias famílias de SLM e suas arquiteturas
3. **Implementação de Modelos de Linguagem Pequenos** - Estratégias práticas de implementação
4. **Conversão de Formatos de Modelos e Quantização** - Otimização avançada com 6 frameworks, incluindo OpenVINO
5. **SLMOps - Operações de Modelos de Linguagem Pequenos** - Gestão do ciclo de vida e implementação em produção
6. **Sistemas Agentes de SLM** - Agentes de IA, chamadas de funções e Protocolo de Contexto de Modelos
7. **Exemplos de Implementação de EdgeAI** - Toolkit de IA, desenvolvimento em Windows e implementações específicas de plataformas
8. **Microsoft Foundry Local – Toolkit Completo para Desenvolvedores** - Desenvolvimento local com integração híbrida ao Azure (Módulo 08)

## Como Utilizar Este Guia de Estudo

- **Aprendizagem Progressiva**: Siga os módulos na ordem para uma experiência de aprendizagem mais coerente
- **Pontos de Verificação de Conhecimento**: Utilize as perguntas de autoavaliação após cada seção
- **Prática Prática**: Complete os exercícios sugeridos para reforçar os conceitos teóricos
- **Recursos Suplementares**: Explore materiais adicionais para tópicos que mais lhe interessam

## Recomendações de Cronograma de Estudo

### Percurso de Aprendizagem Concentrado (1 semana)

| Dia | Foco | Horas Estimadas |
|------|-------|-----------------|
| Dia 1-2 | Módulo 1: Fundamentos do EdgeAI | 6 horas |
| Dia 3-4 | Módulo 2: Fundamentos de SLM | 8 horas |
| Dia 5 | Módulo 3: Implementação de SLM | 3 horas |
| Dia 6 | Módulo 8: Toolkit Local Foundry | 3 horas |

### Estudo a Tempo Parcial (3 semanas)

| Semana | Foco | Horas Estimadas |
|------|-------|-----------------|
| Semana 1 | Módulo 1: Fundamentos do EdgeAI | 6-7 horas |
| Semana 2 | Módulo 2: Fundamentos de SLM | 7-8 horas |
| Semana 3 | Módulo 3: Implementação de SLM (3h) + Módulo 8: Toolkit Local Foundry (2-3h) | 5-6 horas |

## Módulo 1: Fundamentos e Transformação do EdgeAI

### Objetivos de Aprendizagem Principais

- Compreender as diferenças entre IA baseada na nuvem e IA baseada na borda
- Dominar técnicas de otimização para ambientes com recursos limitados
- Analisar aplicações reais de tecnologias de EdgeAI
- Configurar um ambiente de desenvolvimento para projetos de EdgeAI

### Áreas de Foco de Estudo

#### Seção 1: Fundamentos do EdgeAI
- **Conceitos Prioritários**: 
  - Paradigmas de computação na borda vs. na nuvem
  - Técnicas de quantização de modelos
  - Opções de aceleração de hardware (NPUs, GPUs, CPUs)
  - Vantagens de privacidade e segurança

- **Materiais Suplementares**:
  - [Documentação do TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub do ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentação do Edge Impulse](https://docs.edgeimpulse.com)

#### Seção 2: Estudos de Caso Reais
- **Conceitos Prioritários**: 
  - Ecossistema de modelos Microsoft Phi & Mu
  - Implementações práticas em diferentes indústrias
  - Considerações de implementação

#### Seção 3: Guia de Implementação Prática
- **Conceitos Prioritários**: 
  - Configuração do ambiente de desenvolvimento
  - Ferramentas de quantização e otimização
  - Métodos de avaliação para implementações de EdgeAI

#### Seção 4: Hardware de Implementação na Borda
- **Conceitos Prioritários**: 
  - Comparações de plataformas de hardware
  - Estratégias de otimização para hardware específico
  - Considerações de implementação

### Perguntas de Autoavaliação

1. Compare e contraste implementações de IA na nuvem e na borda.
2. Explique três técnicas principais para otimizar modelos para implementação na borda.
3. Quais são as principais vantagens de executar modelos de IA na borda?
4. Descreva o processo de quantização de um modelo e como isso afeta o desempenho.
5. Explique como diferentes aceleradores de hardware (NPUs, GPUs, CPUs) influenciam a implementação de EdgeAI.

### Exercícios Práticos

1. **Configuração Rápida do Ambiente**: Configure um ambiente de desenvolvimento mínimo com os pacotes essenciais (30 minutos)
2. **Exploração de Modelos**: Baixe e examine um modelo de linguagem pequeno pré-treinado (1 hora)
3. **Quantização Básica**: Experimente uma quantização simples em um modelo pequeno (1 hora)

## Módulo 2: Fundamentos de Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem Principais

- Compreender os princípios arquiteturais de diferentes famílias de SLM
- Comparar capacidades de modelos em diferentes escalas de parâmetros
- Avaliar modelos com base em eficiência, capacidade e requisitos de implementação
- Reconhecer casos de uso apropriados para diferentes famílias de modelos

### Áreas de Foco de Estudo

#### Seção 1: Família de Modelos Microsoft Phi
- **Conceitos Prioritários**: 
  - Evolução da filosofia de design
  - Arquitetura com foco em eficiência
  - Capacidades especializadas

#### Seção 2: Família Qwen
- **Conceitos Prioritários**: 
  - Contribuições de código aberto
  - Opções de implementação escaláveis
  - Arquitetura avançada de raciocínio

#### Seção 3: Família Gemma
- **Conceitos Prioritários**: 
  - Inovação orientada por pesquisa
  - Capacidades multimodais
  - Otimização para dispositivos móveis

#### Seção 4: Família BitNET
- **Conceitos Prioritários**: 
  - Tecnologia de quantização de 1-bit
  - Framework de otimização de inferência
  - Considerações de sustentabilidade

#### Seção 5: Modelo Microsoft Mu
- **Conceitos Prioritários**: 
  - Arquitetura orientada para dispositivos
  - Integração com sistemas Windows
  - Operação com preservação de privacidade

#### Seção 6: Phi-Silica
- **Conceitos Prioritários**: 
  - Arquitetura otimizada para NPU
  - Métricas de desempenho
  - Integração para desenvolvedores

### Perguntas de Autoavaliação

1. Compare as abordagens arquiteturais das famílias de modelos Phi e Qwen.
2. Explique como a tecnologia de quantização do BitNET difere da quantização tradicional.
3. Quais são as vantagens únicas do modelo Mu para integração com Windows?
4. Descreva como o Phi-Silica aproveita o hardware NPU para otimização de desempenho.
5. Para uma aplicação móvel com conectividade limitada, qual família de modelos seria mais apropriada e por quê?

### Exercícios Práticos

1. **Comparação de Modelos**: Benchmark rápido de dois modelos SLM diferentes (1 hora)
2. **Geração de Texto Simples**: Implementação básica de geração de texto com um modelo pequeno (1 hora)
3. **Otimização Rápida**: Aplique uma técnica de otimização para melhorar a velocidade de inferência (1 hora)

## Módulo 3: Implementação de Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem Principais

- Selecionar modelos apropriados com base em restrições de implementação
- Dominar técnicas de otimização para vários cenários de implementação
- Implementar SLMs em ambientes locais e na nuvem
- Projetar configurações prontas para produção em aplicações de EdgeAI

### Áreas de Foco de Estudo

#### Seção 1: Aprendizagem Avançada de SLM
- **Conceitos Prioritários**: 
  - Framework de classificação de parâmetros
  - Técnicas avançadas de otimização
  - Estratégias de aquisição de modelos

#### Seção 2: Implementação em Ambiente Local
- **Conceitos Prioritários**: 
  - Implementação na plataforma Ollama
  - Soluções locais Microsoft Foundry
  - Análise comparativa de frameworks

#### Seção 3: Implementação em Nuvem com Contêineres
- **Conceitos Prioritários**: 
  - Inferência de alto desempenho com vLLM
  - Orquestração de contêineres
  - Implementação com ONNX Runtime

### Perguntas de Autoavaliação

1. Quais fatores devem ser considerados ao escolher entre implementação local e na nuvem?
2. Compare Ollama e Microsoft Foundry Local como opções de implementação.
3. Explique os benefícios da containerização para implementação de SLM.
4. Quais são as principais métricas de desempenho a monitorar para um SLM implementado na borda?
5. Descreva um fluxo completo de implementação desde a seleção do modelo até a implementação em produção.

### Exercícios Práticos

1. **Implementação Local Básica**: Implemente um SLM simples usando Ollama (1 hora)
2. **Verificação de Desempenho**: Execute um benchmark rápido no modelo implementado (30 minutos)
3. **Integração Simples**: Crie uma aplicação mínima que utilize o modelo implementado (1 hora)

## Módulo 4: Conversão de Formatos de Modelos e Quantização

### Objetivos de Aprendizagem Principais

- Dominar técnicas avançadas de quantização de 1-bit a 8-bit de precisão
- Compreender estratégias de conversão de formatos (GGUF, ONNX)
- Implementar otimização em seis frameworks (Llama.cpp, Olive, OpenVINO, MLX, síntese de workflows)
- Implementar modelos otimizados para ambientes de produção na borda em hardware Intel, Apple e multiplataforma

### Áreas de Foco de Estudo

#### Seção 1: Fundamentos de Quantização
- **Conceitos Prioritários**: 
  - Framework de classificação de precisão
  - Trade-offs entre desempenho e precisão
  - Otimização de memória

#### Seção 2: Implementação com Llama.cpp
- **Conceitos Prioritários**: 
  - Implementação multiplataforma
  - Otimização de formato GGUF
  - Técnicas de aceleração de hardware

#### Seção 3: Suite Microsoft Olive
- **Conceitos Prioritários**: 
  - Otimização orientada para hardware
  - Implementação em nível empresarial
  - Workflows automatizados de otimização

#### Seção 4: Toolkit OpenVINO
- **Conceitos Prioritários**: 
  - Otimização para hardware Intel
  - Framework de Compressão de Redes Neurais (NNCF)
  - Implementação de inferência multiplataforma
- OpenVINO GenAI para implementação de LLM

#### Secção 5: Framework Apple MLX
- **Conceitos Prioritários**: 
  - Otimização para Apple Silicon
  - Arquitetura de memória unificada
  - Capacidades de ajuste fino com LoRA

#### Secção 6: Síntese do Workflow de Desenvolvimento de Edge AI
- **Conceitos Prioritários**: 
  - Arquitetura de workflow unificada
  - Árvores de decisão para seleção de frameworks
  - Validação de prontidão para produção
  - Estratégias de preparação para o futuro

### Perguntas de Autoavaliação

1. Compare estratégias de quantização em diferentes níveis de precisão (1-bit a 8-bit).
2. Explique as vantagens do formato GGUF para implementação em edge.
3. Como a otimização orientada por hardware no Microsoft Olive melhora a eficiência de implementação?
4. Quais são os principais benefícios do NNCF do OpenVINO para compressão de modelos?
5. Descreva como o Apple MLX utiliza a arquitetura de memória unificada para otimização.
6. Como a síntese de workflows ajuda na seleção de frameworks de otimização ideais?

### Exercícios Práticos

1. **Quantização de Modelos**: Aplique diferentes níveis de quantização a um modelo e compare os resultados (1 hora)
2. **Otimização com OpenVINO**: Utilize o NNCF para comprimir um modelo para hardware Intel (1 hora)
3. **Comparação de Frameworks**: Teste o mesmo modelo em três frameworks de otimização diferentes (1 hora)
4. **Benchmarking de Performance**: Meça o impacto da otimização na velocidade de inferência e uso de memória (1 hora)

## Módulo 5: SLMOps - Operações com Modelos de Linguagem Pequenos

### Objetivos de Aprendizagem Principais

- Compreender os princípios de gestão do ciclo de vida do SLMOps
- Dominar técnicas de destilação e ajuste fino para implementação em edge
- Implementar estratégias de implementação em produção com monitorização
- Construir workflows de operações e manutenção de SLMs de nível empresarial

### Áreas de Estudo Focais

#### Secção 1: Introdução ao SLMOps
- **Conceitos Prioritários**: 
  - Mudança de paradigma do SLMOps nas operações de IA
  - Eficiência de custos e arquitetura centrada na privacidade
  - Impacto estratégico nos negócios e vantagens competitivas

#### Secção 2: Destilação de Modelos
- **Conceitos Prioritários**: 
  - Técnicas de transferência de conhecimento
  - Implementação do processo de destilação em duas etapas
  - Workflows de destilação no Azure ML

#### Secção 3: Estratégias de Ajuste Fino
- **Conceitos Prioritários**: 
  - Ajuste fino eficiente em parâmetros (PEFT)
  - Métodos avançados LoRA e QLoRA
  - Treino multi-adaptador e otimização de hiperparâmetros

#### Secção 4: Implementação em Produção
- **Conceitos Prioritários**: 
  - Conversão e quantização de modelos para produção
  - Configuração de implementação local com Foundry Local
  - Benchmarking de performance e validação de qualidade

### Perguntas de Autoavaliação

1. Como o SLMOps difere do MLOps tradicional?
2. Explique os benefícios da destilação de modelos para implementação em edge.
3. Quais são as principais considerações para ajustar SLMs em ambientes com recursos limitados?
4. Descreva um pipeline completo de implementação em produção para aplicações de IA em edge.

### Exercícios Práticos

1. **Destilação Básica**: Crie um modelo menor a partir de um modelo maior (1 hora)
2. **Experimento de Ajuste Fino**: Ajuste um modelo para um domínio específico (1 hora)
3. **Pipeline de Implementação**: Configure um pipeline básico de CI/CD para implementação de modelos (1 hora)

## Módulo 6: Sistemas Agentes SLM - Agentes de IA e Chamadas de Função

### Objetivos de Aprendizagem Principais

- Construir agentes de IA inteligentes para ambientes edge utilizando Modelos de Linguagem Pequenos
- Implementar capacidades de chamadas de função com workflows sistemáticos
- Dominar a integração do Protocolo de Contexto de Modelo (MCP) para interação padronizada com ferramentas
- Criar sistemas agentes sofisticados com intervenção humana mínima

### Áreas de Estudo Focais

#### Secção 1: Agentes de IA e Fundamentos de SLM
- **Conceitos Prioritários**: 
  - Framework de classificação de agentes (reflexivos, baseados em modelo, baseados em objetivos, agentes de aprendizagem)
  - Análise de trade-offs entre SLM e LLM
  - Padrões de design de agentes específicos para edge
  - Otimização de recursos para agentes

#### Secção 2: Chamadas de Função em Modelos de Linguagem Pequenos
- **Conceitos Prioritários**: 
  - Implementação de workflows sistemáticos (detecção de intenção, saída em JSON, execução externa)
  - Implementações específicas de plataforma (Phi-4-mini, modelos Qwen selecionados, Microsoft Foundry Local)
  - Exemplos avançados (colaboração multi-agente, seleção dinâmica de ferramentas)
  - Considerações de produção (limitação de taxa, registo de auditoria, medidas de segurança)

#### Secção 3: Integração do Protocolo de Contexto de Modelo (MCP)
- **Conceitos Prioritários**: 
  - Arquitetura do protocolo e design de sistema em camadas
  - Suporte multi-backend (Ollama para desenvolvimento, vLLM para produção)
  - Protocolos de conexão (modos STDIO e SSE)
  - Aplicações reais (automação web, processamento de dados, integração com APIs)

### Perguntas de Autoavaliação

1. Quais são as principais considerações arquiteturais para agentes de IA em edge?
2. Como as chamadas de função melhoram as capacidades dos agentes?
3. Explique o papel do Protocolo de Contexto de Modelo na comunicação entre agentes.

### Exercícios Práticos

1. **Agente Simples**: Construa um agente de IA básico com chamadas de função (1 hora)
2. **Integração MCP**: Implemente o MCP numa aplicação de agente (30 minutos)

## Módulo 7: Exemplos de Implementação de EdgeAI

### Objetivos de Aprendizagem Principais

- Dominar o AI Toolkit para Visual Studio Code para workflows abrangentes de desenvolvimento de EdgeAI
- Ganhar expertise na plataforma Windows AI Foundry e estratégias de otimização de NPU
- Implementar EdgeAI em múltiplas plataformas de hardware e cenários de implementação
- Construir aplicações EdgeAI prontas para produção com otimizações específicas de plataforma

### Áreas de Estudo Focais

#### Secção 1: AI Toolkit para Visual Studio Code
- **Conceitos Prioritários**: 
  - Ambiente abrangente de desenvolvimento de Edge AI dentro do VS Code
  - Catálogo de modelos e descoberta para implementação em edge
  - Testes locais, otimização e workflows de desenvolvimento de agentes
  - Monitorização de performance e avaliação para cenários em edge

#### Secção 2: Guia de Desenvolvimento de EdgeAI no Windows
- **Conceitos Prioritários**: 
  - Visão geral abrangente da plataforma Windows AI Foundry
  - API Phi Silica para inferência eficiente em NPU
  - APIs de Visão Computacional para processamento de imagens e OCR
  - CLI do Foundry Local para desenvolvimento e testes locais

#### Secção 3: Implementações Específicas de Plataforma
- **Conceitos Prioritários**: 
  - Implementação no NVIDIA Jetson Orin Nano (67 TOPS de performance em IA)
  - Aplicações móveis com .NET MAUI e ONNX Runtime GenAI
  - Soluções Azure EdgeAI com arquitetura híbrida cloud-edge
  - Otimização Windows ML com suporte universal de hardware
  - Aplicações Foundry Local com implementação RAG centrada na privacidade

### Perguntas de Autoavaliação

1. Como o AI Toolkit simplifica o workflow de desenvolvimento de EdgeAI?
2. Compare estratégias de implementação em diferentes plataformas de hardware.
3. Quais são as vantagens do Windows AI Foundry para desenvolvimento em edge?
4. Explique o papel da otimização de NPU em aplicações modernas de EdgeAI.
5. Como a API Phi Silica utiliza hardware NPU para otimização de performance?
6. Compare os benefícios de implementações locais vs. na cloud para aplicações sensíveis à privacidade.

### Exercícios Práticos

1. **Configuração do AI Toolkit**: Configure o AI Toolkit e otimize um modelo (1 hora)
2. **Windows AI Foundry**: Construa uma aplicação simples de IA no Windows utilizando a API Phi Silica (1 hora)
3. **Implementação Multi-Plataforma**: Implemente o mesmo modelo em duas plataformas diferentes (1 hora)
4. **Otimização de NPU**: Teste a performance de NPU com ferramentas do Windows AI Foundry (30 minutos)

## Módulo 8: Microsoft Foundry Local – Toolkit Completo para Desenvolvedores (Modernizado)

### Objetivos de Aprendizagem Principais

- Instalar e configurar o Foundry Local com integração moderna de SDK
- Implementar sistemas avançados multi-agente com padrões de coordenador
- Construir roteadores inteligentes de modelos com seleção automática baseada em tarefas
- Implementar soluções de IA prontas para produção com monitorização abrangente
- Integrar com Azure AI Foundry para cenários de implementação híbrida
- Dominar padrões modernos de SDK com FoundryLocalManager e cliente OpenAI

### Áreas de Estudo Focais

#### Secção 1: Instalação e Configuração Modernas
- **Conceitos Prioritários**: 
  - Integração do SDK FoundryLocalManager
  - Descoberta automática de serviços e monitorização de saúde
  - Padrões de configuração baseados em ambiente
  - Considerações para implementação em produção

#### Secção 2: Sistemas Multi-Agente Avançados
- **Conceitos Prioritários**: 
  - Padrão de coordenador com agentes especialistas
  - Especialização em recuperação, raciocínio e execução de agentes
  - Mecanismos de loop de feedback para refinamento
  - Monitorização de performance e rastreamento de estatísticas

#### Secção 3: Roteamento Inteligente de Modelos
- **Conceitos Prioritários**: 
  - Algoritmos de seleção de modelos baseados em palavras-chave
  - Suporte a múltiplos modelos (geral, raciocínio, código, criativo)
  - Configuração de variáveis de ambiente para flexibilidade
  - Verificação de saúde de serviços e tratamento de erros

#### Secção 4: Implementação Pronta para Produção
- **Conceitos Prioritários**: 
  - Tratamento abrangente de erros e mecanismos de fallback
  - Monitorização de pedidos e rastreamento de performance
  - Exemplos interativos em Jupyter notebooks com benchmarks
  - Padrões de integração com aplicações existentes

### Perguntas de Autoavaliação

1. Como a abordagem moderna do FoundryLocalManager difere de chamadas REST manuais?
2. Explique o padrão de coordenador e como ele orquestra agentes especialistas.
3. Como o roteador inteligente seleciona modelos apropriados com base no conteúdo da consulta?
4. Quais são os componentes principais de um sistema de agente de IA pronto para produção?
5. Como implementar monitorização abrangente de saúde para serviços do Foundry Local?
6. Compare os benefícios da abordagem modernizada vs. padrões de implementação tradicionais.

### Exercícios Práticos

1. **Configuração do SDK Moderno**: Configure o FoundryLocalManager com descoberta automática de serviços (30 minutos)
2. **Sistema Multi-Agente**: Execute o coordenador avançado com agentes especialistas (30 minutos)
3. **Roteamento Inteligente**: Teste o roteador de modelos com diferentes tipos de consulta (30 minutos)
4. **Exploração Interativa**: Utilize os Jupyter notebooks para explorar recursos avançados (45 minutos)
5. **Implementação em Produção**: Implemente padrões de monitorização e tratamento de erros (30 minutos)
6. **Integração Híbrida**: Configure cenários de fallback com Azure AI Foundry (30 minutos)

## Guia de Alocação de Tempo

Para ajudá-lo a aproveitar ao máximo as 20 horas do curso, aqui está uma sugestão de como alocar o seu tempo:

| Atividade | Alocação de Tempo | Descrição |
|-----------|-------------------|-----------|
| Leitura de Materiais Principais | 9 horas | Foco nos conceitos essenciais de cada módulo |
| Exercícios Práticos | 6 horas | Implementação prática de técnicas principais |
| Autoavaliação | 2 horas | Teste de compreensão através de perguntas e reflexão |
| Mini-Projeto | 3 horas | Aplicação de conhecimento numa implementação prática pequena |

### Áreas de Foco por Restrição de Tempo

**Se tiver apenas 10 horas:**
- Complete os Módulos 1, 2 e 3 (conceitos principais de EdgeAI)
- Realize pelo menos um exercício prático por módulo
- Foque na compreensão dos conceitos principais em vez de detalhes de implementação

**Se puder dedicar as 20 horas completas:**
- Complete todos os sete módulos
- Realize os principais exercícios práticos de cada módulo
- Complete um mini-projeto do Módulo 7
- Explore pelo menos 2-3 recursos suplementares

**Se tiver mais de 20 horas:**
- Complete todos os módulos com exercícios detalhados
- Construa múltiplos mini-projetos
- Explore técnicas avançadas de otimização no Módulo 4
- Implemente a implementação em produção do Módulo 5

## Recursos Essenciais

Estes recursos cuidadosamente selecionados oferecem o maior valor para o seu tempo de estudo limitado:

### Documentação Essencial
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - A ferramenta de otimização de modelos mais eficiente
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Forma mais rápida de implementar SLMs localmente
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referência para um modelo otimizado para edge
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit abrangente de otimização da Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente integrado de desenvolvimento de EdgeAI
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Plataforma de desenvolvimento de EdgeAI específica para Windows

### Ferramentas que Economizam Tempo
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Acesso rápido a modelos e implementação
- [Gradio](https://www.gradio.app/docs/interface) - Desenvolvimento rápido de UI para demonstrações de IA
- [Microsoft Olive](https://github.com/microsoft/Olive) - Otimização simplificada de modelos
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferência eficiente em CPU
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework de compressão de redes neurais
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit de implementação de modelos de linguagem grandes

## Template de Rastreamento de Progresso

Utilize este template simplificado para acompanhar o seu progresso de aprendizagem ao longo do curso de 20 horas:

| Módulo | Data de Conclusão | Horas Gastas | Principais Aprendizados |
|--------|-------------------|--------------|-------------------------|
| Módulo 1: Fundamentos de EdgeAI | | | |
| Módulo 2: Fundamentos de SLM | | | |
| Módulo 3: Implementação de SLM | | | |
| Módulo 4: Otimização de Modelos | | | |
| Módulo 5: SLMOps | | | |
| Módulo 6: Agentes de IA | | | |
| Módulo 7: Ferramentas de Desenvolvimento | | | |
| Módulo 8: Toolkit Foundry Local | | | |
| Exercícios Práticos | | | |
| Mini-Projeto | | | |

## Ideias para Mini-Projetos

Considere realizar um destes projetos para praticar conceitos de EdgeAI (cada um projetado para levar 2-4 horas):

### Projetos para Iniciantes (2-3 horas cada)
1. **Assistente de Texto Edge**: Crie uma ferramenta simples de preenchimento de texto offline usando um modelo de linguagem pequeno
2. **Dashboard de Comparação de Modelos**: Desenvolva uma visualização básica de métricas de desempenho entre diferentes SLMs
3. **Experimento de Otimização**: Meça o impacto de diferentes níveis de quantização no mesmo modelo base

### Projetos Intermediários (3-4 horas cada)
4. **Workflow com AI Toolkit**: Utilize o AI Toolkit do VS Code para otimizar e implementar um modelo do início ao fim
5. **Aplicação Windows AI Foundry**: Crie uma aplicação Windows usando a API Phi Silica e otimização NPU
6. **Implementação Multiplataforma**: Implemente o mesmo modelo otimizado no Windows (OpenVINO) e em dispositivos móveis (.NET MAUI)
7. **Agente de Chamadas de Função**: Desenvolva um agente de IA com capacidades de chamadas de função para cenários edge

### Projetos de Integração Avançada (4-5 horas cada)
8. **Pipeline de Otimização OpenVINO**: Implemente uma otimização completa de modelo usando NNCF e o toolkit GenAI
9. **Pipeline SLMOps**: Implemente um ciclo de vida completo de modelo, desde o treino até à implementação em edge
10. **Sistema Edge Multi-Modelo**: Implemente múltiplos modelos especializados trabalhando juntos em hardware edge
11. **Sistema de Integração MCP**: Desenvolva um sistema agente utilizando o Model Context Protocol para interação com ferramentas

## Referências

- Microsoft Learn (Foundry Local)
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Introdução: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Referência CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integração com SDKs de inferência: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Como usar Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compilar modelos Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Visão geral: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agentes (visão geral): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Ferramentas de Otimização e Inferência
  - Microsoft Olive (documentação): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (introdução): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integração ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (documentação): https://docs.openvino.ai/2025/index.html
  - Apple MLX (documentação): https://ml-explore.github.io/mlx/build/html/index.html
- Frameworks de Implementação e Modelos
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (documentação): https://docs.vllm.ai/
  - Ollama (introdução): https://github.com/ollama/ollama#get-started
- Ferramentas de Desenvolvimento (Windows e VS Code)
  - AI Toolkit para VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (visão geral): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Comunidade de Aprendizagem

Participe da discussão e conecte-se com outros aprendizes:
- Discussões no GitHub no [repositório EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Conclusão

EdgeAI representa a vanguarda da implementação de inteligência artificial, trazendo capacidades poderosas diretamente para os dispositivos enquanto aborda preocupações críticas sobre privacidade, latência e conectividade. Este curso de 20 horas fornece o conhecimento essencial e as habilidades práticas para começar a trabalhar com tecnologias EdgeAI imediatamente.

O curso é deliberadamente conciso e focado nos conceitos mais importantes, permitindo que adquira rapidamente uma expertise valiosa sem um compromisso de tempo excessivo. Lembre-se de que a prática prática, mesmo com exemplos simples, é a chave para reforçar o que aprendeu.

Boa aprendizagem!

---

