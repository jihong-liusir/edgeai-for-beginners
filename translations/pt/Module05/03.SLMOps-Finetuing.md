<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T13:39:38+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "pt"
}
-->
# Secção 3: Ajuste Fino - Personalização de Modelos para Tarefas Específicas

## Índice
1. [Introdução ao Ajuste Fino](../../../Module05)
2. [Por que o Ajuste Fino é Importante](../../../Module05)
3. [Tipos de Ajuste Fino](../../../Module05)
4. [Ajuste Fino com Microsoft Olive](../../../Module05)
5. [Exemplos Práticos](../../../Module05)
6. [Melhores Práticas e Diretrizes](../../../Module05)
7. [Técnicas Avançadas](../../../Module05)
8. [Avaliação e Monitorização](../../../Module05)
9. [Desafios Comuns e Soluções](../../../Module05)
10. [Conclusão](../../../Module05)

## Introdução ao Ajuste Fino

**Ajuste fino** é uma técnica poderosa de aprendizagem automática que consiste em adaptar um modelo pré-treinado para realizar tarefas específicas ou trabalhar com conjuntos de dados especializados. Em vez de treinar um modelo do zero, o ajuste fino aproveita o conhecimento já adquirido por um modelo pré-treinado e ajusta-o para o seu caso de uso particular.

### O que é Ajuste Fino?

O ajuste fino é uma forma de **aprendizagem por transferência**, onde:
- Começa-se com um modelo pré-treinado que aprendeu padrões gerais a partir de grandes conjuntos de dados
- Ajustam-se os parâmetros internos do modelo utilizando o seu conjunto de dados específico
- Retém-se o conhecimento valioso enquanto se especializa o modelo para a sua tarefa

Pense nisso como ensinar um chef experiente a cozinhar uma nova cozinha - ele já entende os fundamentos da culinária, mas precisa aprender técnicas e sabores específicos para o novo estilo.

### Benefícios Principais

- **Eficiência de Tempo**: Muito mais rápido do que treinar do zero
- **Eficiência de Dados**: Requer conjuntos de dados menores para alcançar um bom desempenho
- **Custo-Eficaz**: Menores requisitos computacionais
- **Melhor Desempenho**: Muitas vezes alcança resultados superiores em comparação com o treino do zero
- **Otimização de Recursos**: Torna a IA poderosa acessível a equipas e organizações menores

## Por que o Ajuste Fino é Importante

### Aplicações no Mundo Real

O ajuste fino é essencial em diversos cenários:

**1. Adaptação de Domínio**
- IA Médica: Adaptar modelos de linguagem geral para terminologia médica e notas clínicas
- Tecnologia Jurídica: Especializar modelos para análise de documentos legais e revisão de contratos
- Serviços Financeiros: Personalizar modelos para análise de relatórios financeiros e avaliação de riscos

**2. Especialização de Tarefas**
- Geração de Conteúdo: Ajustar para estilos ou tons de escrita específicos
- Geração de Código: Adaptar modelos para linguagens de programação ou frameworks específicos
- Tradução: Melhorar o desempenho para pares de idiomas específicos ou domínios técnicos

**3. Aplicações Corporativas**
- Serviço ao Cliente: Criar chatbots que compreendem terminologia específica da empresa
- Documentação Interna: Construir assistentes de IA familiarizados com processos organizacionais
- Soluções Específicas do Setor: Desenvolver modelos que entendam jargões e fluxos de trabalho específicos do setor

## Tipos de Ajuste Fino

### 1. Ajuste Fino Completo (Ajuste por Instrução)

No ajuste fino completo, todos os parâmetros do modelo são atualizados durante o treino. Esta abordagem:
- Oferece máxima flexibilidade e potencial de desempenho
- Requer recursos computacionais significativos
- Resulta numa versão completamente nova do modelo
- Ideal para cenários onde há muitos dados de treino e recursos computacionais disponíveis

### 2. Ajuste Fino Eficiente em Parâmetros (PEFT)

Os métodos PEFT atualizam apenas um pequeno subconjunto de parâmetros, tornando o processo mais eficiente:

#### Low-Rank Adaptation (LoRA)
- Adiciona pequenas matrizes de decomposição de rank treináveis aos pesos existentes
- Reduz drasticamente o número de parâmetros treináveis
- Mantém o desempenho próximo ao ajuste fino completo
- Permite alternar facilmente entre diferentes adaptações

#### QLoRA (LoRA Quantizado)
- Combina LoRA com técnicas de quantização
- Reduz ainda mais os requisitos de memória
- Permite ajuste fino de modelos maiores em hardware de consumo
- Equilibra eficiência com desempenho

#### Adaptadores
- Inserem pequenas redes neurais entre camadas existentes
- Permitem ajuste fino direcionado enquanto mantêm o modelo base congelado
- Facilitam uma abordagem modular para personalização de modelos

### 3. Ajuste Fino Específico de Tarefa

Foca-se na adaptação de modelos para tarefas específicas:
- **Classificação**: Ajustar modelos para tarefas de categorização
- **Geração**: Otimizar para criação de conteúdo e geração de texto
- **Extração**: Ajustar para extração de informações e reconhecimento de entidades nomeadas
- **Sumarização**: Especializar modelos para sumarização de documentos

## Ajuste Fino com Microsoft Olive

Microsoft Olive é uma ferramenta abrangente de otimização de modelos que simplifica o processo de ajuste fino enquanto oferece recursos de nível empresarial.

### O que é Microsoft Olive?

Microsoft Olive é uma ferramenta de otimização de modelos de código aberto que:
- Simplifica fluxos de trabalho de ajuste fino para vários alvos de hardware
- Oferece suporte integrado para arquiteturas de modelos populares (Llama, Phi, Qwen, Gemma)
- Disponibiliza opções de implementação na nuvem e localmente
- Integra-se perfeitamente com Azure ML e outros serviços de IA da Microsoft
- Suporta otimização e quantização automáticas

### Funcionalidades Principais

- **Otimização Sensível ao Hardware**: Otimiza automaticamente modelos para hardware específico (CPU, GPU, NPU)
- **Suporte Multi-Formato**: Funciona com modelos PyTorch, Hugging Face e ONNX
- **Fluxos de Trabalho Automatizados**: Reduz configuração manual e tentativa e erro
- **Integração Empresarial**: Suporte integrado para Azure ML e implementações na nuvem
- **Arquitetura Extensível**: Permite técnicas de otimização personalizadas

### Instalação e Configuração

#### Instalação Básica

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dependências Opcionais

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verificar Instalação

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Exemplos Práticos

### Exemplo 1: Ajuste Fino Básico com Olive CLI

Este exemplo demonstra o ajuste fino de um pequeno modelo de linguagem para classificação de frases:

#### Passo 1: Preparar o Ambiente

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Passo 2: Ajustar o Modelo

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Passo 3: Otimizar para Implementação

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Exemplo 2: Configuração Avançada com Conjunto de Dados Personalizado

#### Passo 1: Preparar Conjunto de Dados Personalizado

Crie um ficheiro JSON com os seus dados de treino:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Passo 2: Criar Ficheiro de Configuração

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Passo 3: Executar Ajuste Fino

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Exemplo 3: Ajuste Fino com QLoRA para Eficiência de Memória

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Melhores Práticas e Diretrizes

### Preparação de Dados

**1. Qualidade dos Dados Acima da Quantidade**
- Priorize exemplos de alta qualidade e diversidade em vez de grandes volumes de dados de baixa qualidade
- Certifique-se de que os dados são representativos do seu caso de uso
- Limpe e pré-processe os dados de forma consistente

**2. Formato e Templates de Dados**
- Utilize formatação consistente em todos os exemplos de treino
- Crie templates claros de entrada-saída que correspondam ao seu caso de uso
- Inclua formatação de instruções apropriada para modelos ajustados por instrução

**3. Divisão do Conjunto de Dados**
- Reserve 10-20% dos dados para validação
- Mantenha distribuições semelhantes entre os conjuntos de treino e validação
- Considere amostragem estratificada para tarefas de classificação

### Configuração de Treino

**1. Seleção da Taxa de Aprendizagem**
- Comece com taxas de aprendizagem menores (1e-5 a 1e-4) para ajuste fino
- Utilize agendamento de taxa de aprendizagem para melhor convergência
- Monitore curvas de perda para ajustar as taxas conforme necessário

**2. Otimização do Tamanho do Lote**
- Equilibre o tamanho do lote com a memória disponível
- Utilize acumulação de gradiente para tamanhos de lote efetivos maiores
- Considere a relação entre tamanho do lote e taxa de aprendizagem

**3. Duração do Treino**
- Monitore métricas de validação para evitar sobreajuste
- Utilize paragem antecipada quando o desempenho de validação estabilizar
- Salve checkpoints regularmente para recuperação e análise

### Seleção de Modelo

**1. Escolha do Modelo Base**
- Selecione modelos pré-treinados em domínios semelhantes sempre que possível
- Considere o tamanho do modelo em relação às suas restrições computacionais
- Avalie requisitos de licenciamento para uso comercial

**2. Seleção do Método de Ajuste Fino**
- Utilize LoRA/QLoRA para ambientes com restrições de recursos
- Escolha ajuste fino completo quando o desempenho máximo for crítico
- Considere abordagens baseadas em adaptadores para cenários de múltiplas tarefas

### Gestão de Recursos

**1. Otimização de Hardware**
- Escolha hardware apropriado para o tamanho do modelo e método
- Utilize memória GPU eficientemente com checkpointing de gradiente
- Considere soluções baseadas na nuvem para modelos maiores

**2. Gestão de Memória**
- Utilize treino de precisão mista quando disponível
- Implemente acumulação de gradiente para restrições de memória
- Monitore o uso de memória GPU durante o treino

## Técnicas Avançadas

### Treino Multi-Adaptador

Treine múltiplos adaptadores para diferentes tarefas enquanto partilha o modelo base:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Otimização de Hiperparâmetros

Implemente ajuste sistemático de hiperparâmetros:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Funções de Perda Personalizadas

Implemente funções de perda específicas do domínio:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Avaliação e Monitorização

### Métricas e Avaliação

**1. Métricas Padrão**
- **Precisão**: Correção geral para tarefas de classificação
- **Perplexidade**: Medida de qualidade de modelagem de linguagem
- **BLEU/ROUGE**: Qualidade de geração de texto e sumarização
- **F1 Score**: Equilíbrio entre precisão e recall para classificação

**2. Métricas Específicas de Domínio**
- **Benchmarks Específicos de Tarefa**: Utilize benchmarks estabelecidos para o seu domínio
- **Avaliação Humana**: Inclua avaliação humana para tarefas subjetivas
- **Métricas de Negócio**: Alinhe-se com objetivos reais de negócio

**3. Configuração de Avaliação**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitorização do Progresso do Treino

**1. Monitorização de Perda**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Monitorização de Validação**
- Acompanhe a perda de validação juntamente com a perda de treino
- Monitore sinais de sobreajuste (perda de validação a aumentar enquanto a perda de treino diminui)
- Utilize paragem antecipada com base em métricas de validação

**3. Monitorização de Recursos**
- Monitore a utilização de GPU/CPU
- Acompanhe padrões de uso de memória
- Monitore a velocidade e o rendimento do treino

## Desafios Comuns e Soluções

### Desafio 1: Sobreajuste

**Sintomas:**
- A perda de treino continua a diminuir enquanto a perda de validação aumenta
- Grande diferença entre desempenho de treino e validação
- Fraca generalização para novos dados

**Soluções:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Desafio 2: Limitações de Memória

**Soluções:**
- Utilize checkpointing de gradiente
- Implemente acumulação de gradiente
- Escolha métodos eficientes em parâmetros (LoRA, QLoRA)
- Utilize paralelismo de modelo para modelos grandes

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Desafio 3: Treino Lento

**Soluções:**
- Otimize pipelines de carregamento de dados
- Utilize treino de precisão mista
- Implemente estratégias de batching eficientes
- Considere treino distribuído para conjuntos de dados grandes

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Desafio 4: Desempenho Fraco

**Passos de Diagnóstico:**
1. Verifique a qualidade e formatação dos dados
2. Confirme a taxa de aprendizagem e duração do treino
3. Avalie a escolha do modelo base
4. Revise o pré-processamento e tokenização

**Soluções:**
- Aumente a diversidade dos dados de treino
- Ajuste o agendamento da taxa de aprendizagem
- Experimente diferentes modelos base
- Implemente técnicas de aumento de dados

## Conclusão

O ajuste fino é uma técnica poderosa que democratiza o acesso a capacidades de IA de última geração. Ao utilizar ferramentas como Microsoft Olive, as organizações podem adaptar eficientemente modelos pré-treinados às suas necessidades específicas enquanto otimizam para desempenho e restrições de recursos.

### Principais Conclusões

1. **Escolha a Abordagem Certa**: Selecione métodos de ajuste fino com base nos seus recursos computacionais e requisitos de desempenho
2. **A Qualidade dos Dados Importa**: Invista em dados de treino de alta qualidade e representativos
3. **Monitorize e Itere**: Avalie e melhore continuamente os seus modelos
4. **Aproveite as Ferramentas**: Utilize frameworks como Olive para simplificar e otimizar o processo
5. **Considere a Implementação**: Planeie a otimização e implementação do modelo desde o início

## ➡️ Próximos Passos

- [04: Implementação - Modelos Prontos para Produção](./04.SLMOps.Deployment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, é importante notar que traduções automáticas podem conter erros ou imprecisões. O documento original na sua língua nativa deve ser considerado a fonte autoritária. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes da utilização desta tradução.