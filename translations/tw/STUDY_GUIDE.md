<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T09:40:11+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tw"
}
-->
# EdgeAI 初學者指南：學習路徑與學習計劃

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第2天 | 模組2：SLM 基礎 | 3小時 |
| 第3天 | 模組3：SLM 部署 | 2小時 |
| 第4-5天 | 模組4：模型優化（6個框架） | 4小時 |
| 第6天 | 模組5：SLMOps | 3小時 |
| 第7天 | 模組6-7：AI 代理與開發工具 | 4小時 |
| 第8天 | 模組8：Foundry Local 工具包（現代實現） | 1小時 |

### 集中學習路徑（2週）

| 天數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：AI 代理 | 2小時 |
| 第13-14天 | 模組7：開發工具 | 3小時 |

### 兼職學習（4週）

| 週數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps 與 AI 代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

| 天數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：SLM 代理系統 | 2小時 |
| 第13-14天 | 模組7：EdgeAI 實現範例 | 2小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|------|----------|----------|----------|
| 模組1：EdgeAI 基礎 | | | |
| 模組2：SLM 基礎 | | | |
| 模組3：SLM 部署 | | | |
| 模組4：模型優化（6個框架） | | | |
| 模組5：SLMOps | | | |
| 模組6：SLM 代理系統 | | | |
| 模組7：EdgeAI 實現範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習（4週）

| 週數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps 與 AI 代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

## 簡介

歡迎使用 EdgeAI 初學者學習指南！本文件旨在幫助您有效地學習課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，幫助您深入了解 EdgeAI 技術。

這是一門簡潔的20小時課程，能以高效的方式傳授 EdgeAI 的基本知識，非常適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概覽

本課程分為七個全面的模組：

1. **EdgeAI 基礎與轉型** - 理解核心概念與技術轉變
2. **小型語言模型（SLM）基礎** - 探索各種SLM家族及其架構
3. **小型語言模型部署** - 實現實用的部署策略
4. **模型格式轉換與量化** - 使用包括 OpenVINO 在內的6個框架進行高級優化
5. **SLMOps - 小型語言模型運營** - 生產生命周期管理與部署
6. **SLM 代理系統** - AI 代理、函數調用與模型上下文協議
7. **EdgeAI 實現範例** - AI 工具包、Windows 開發與平台特定實現
8. **Microsoft Foundry Local – 完整開發工具包** - 本地優先開發與混合 Azure 整合（模組08）

## 如何使用本學習指南

- **循序漸進學習**：按順序學習模組以獲得最連貫的學習體驗
- **知識檢查點**：使用每節後的自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 6小時 |
| 第3-4天 | 模組2：SLM 基礎 | 8小時 |
| 第5天 | 模組3：SLM 部署 | 3小時 |
| 第6天 | 模組8：Foundry Local 工具包 | 3小時 |

### 兼職學習（3週）

| 週數 | 重點 | 預估時數 |
|------|-------|----------|
| 第1週 | 模組1：EdgeAI 基礎 | 6-7小時 |
| 第2週 | 模組2：SLM 基礎 | 7-8小時 |
| 第3週 | 模組3：SLM 部署（3小時）+ 模組8：Foundry Local 工具包（2-3小時） | 5-6小時 |

## 模組1：EdgeAI 基礎與轉型

### 主要學習目標

- 理解雲端AI與邊緣AI的差異
- 掌握資源受限環境的核心優化技術
- 分析 EdgeAI 技術的實際應用
- 為 EdgeAI 專案設置開發環境

### 學習重點區域

#### 第1節：EdgeAI 基礎
- **優先概念**：
  - 邊緣計算與雲計算的比較
  - 模型量化技術
  - 硬體加速選項（NPU、GPU、CPU）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文檔](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文檔](https://docs.edgeimpulse.com)

#### 第2節：實際案例研究
- **優先概念**：
  - Microsoft Phi 與 Mu 模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第3節：實際實現指南
- **優先概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI 實現的評估方法

#### 第4節：邊緣部署硬體
- **優先概念**：
  - 硬體平台比較
  - 特定硬體的優化策略
  - 部署考量

### 自我評估問題

1. 比較雲端AI與邊緣AI實現的異同。
2. 解釋三種優化模型以適應邊緣部署的關鍵技術。
3. 邊緣運行AI模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬體加速器（NPU、GPU、CPU）如何影響 EdgeAI 部署。

### 實作練習

1. **快速環境設置**：配置一個包含基本套件的最小開發環境（30分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1小時）
3. **基本量化**：對一個小型模型進行簡單量化（1小時）

## 模組2：小型語言模型（SLM）基礎

### 主要學習目標

- 理解不同SLM家族的架構原則
- 比較不同參數規模模型的能力
- 根據效率、能力和部署需求評估模型
- 辨識不同模型家族的適用場景

### 學習重點區域

#### 第1節：Microsoft Phi 模型家族
- **優先概念**：
  - 設計理念的演變
  - 以效率為核心的架構
  - 專業化能力

#### 第2節：Qwen 家族
- **優先概念**：
  - 開源貢獻
  - 可擴展的部署選項
  - 高級推理架構

#### 第3節：Gemma 家族
- **優先概念**：
  - 以研究為驅動的創新
  - 多模態能力
  - 移動端優化

#### 第4節：BitNET 家族
- **優先概念**：
  - 1位元量化技術
  - 推理優化框架
  - 可持續性考量

#### 第5節：Microsoft Mu 模型
- **優先概念**：
  - 以設備為核心的架構
  - 與 Windows 的系統整合
  - 隱私保護操作

#### 第6節：Phi-Silica
- **優先概念**：
  - 為 NPU 優化的架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較 Phi 和 Qwen 模型家族的架構方法。
2. 解釋 BitNET 的量化技術與傳統量化的不同之處。
3. Mu 模型在 Windows 整合方面的獨特優勢是什麼？
4. 描述 Phi-Silica 如何利用 NPU 硬體進行性能優化。
5. 對於一個連接有限的移動應用，哪個模型家族最適合？為什麼？

### 實作練習

1. **模型比較**：快速對兩個不同的SLM模型進行基準測試（1小時）
2. **簡單文本生成**：使用一個小型模型進行基本的文本生成實現（1小時）
3. **快速優化**：應用一種優化技術來提高推理速度（1小時）

## 模組3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實現SLM
- 設計適合 EdgeAI 應用的生產級配置

### 學習重點區域

#### 第1節：SLM 高級學習
- **優先概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第2節：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第3節：容器化雲端部署
- **優先概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實現

### 自我評估問題

1. 選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對於SLM部署的好處。
4. 邊緣部署SLM時需要監控的關鍵性能指標是什麼？
5. 描述從模型選擇到生產實現的完整部署工作流程。

### 實作練習

1. **基本本地部署**：使用 Ollama 部署一個簡單的SLM（1小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30分鐘）
3. **簡單整合**：創建一個使用已部署模型的最小應用程序（1小時）

## 模組4：模型格式轉換與量化

### 主要學習目標

- 掌握從1位元到8位元精度的高級量化技術
- 理解格式轉換策略（GGUF、ONNX）
- 在六個框架（Llama.cpp、Olive、OpenVINO、MLX、工作流合成）中實現優化
- 部署優化模型到 Intel、Apple 和跨平台硬體的生產邊緣環境

### 學習重點區域

#### 第1節：量化基礎
- **優先概念**：
  - 精度分類框架
  - 性能與準確性權衡
  - 記憶體佔用優化

#### 第2節：Llama.cpp 實現
- **優先概念**：
  - 跨平台部署
  - GGUF 格式優化
  - 硬體加速技術

#### 第3節：Microsoft Olive 套件
- **優先概念**：
  - 硬體感知優化
  - 企業級部署
  - 自動化優化工作流

#### 第4節：OpenVINO 工具包
- **優先概念**：
  - Intel 硬體優化
  - 神經網路壓縮框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI 用於部署大型語言模型

#### 第五章：Apple MLX 框架
- **重點概念**: 
  - Apple Silicon 優化
  - 統一記憶體架構
  - LoRA 微調能力

#### 第六章：邊緣 AI 開發工作流程綜合
- **重點概念**: 
  - 統一的工作流程架構
  - 框架選擇決策樹
  - 生產準備驗證
  - 未來適應性策略

### 自我評估問題

1. 比較不同精度級別（1-bit 到 8-bit）的量化策略。
2. 解釋 GGUF 格式在邊緣部署中的優勢。
3. Microsoft Olive 的硬體感知優化如何提升部署效率？
4. OpenVINO 的 NNCF 在模型壓縮方面的主要優勢是什麼？
5. Apple MLX 如何利用統一記憶體架構進行優化？
6. 工作流程綜合如何幫助選擇最佳的優化框架？

### 實作練習

1. **模型量化**: 對模型應用不同的量化級別並比較結果（1 小時）
2. **OpenVINO 優化**: 使用 NNCF 壓縮模型以適配 Intel 硬體（1 小時）
3. **框架比較**: 在三個不同的優化框架中測試同一模型（1 小時）
4. **性能基準測試**: 測量優化對推理速度和記憶體使用的影響（1 小時）

## 第五章：SLMOps - 小型語言模型操作

### 核心學習目標

- 理解 SLMOps 的生命周期管理原則
- 掌握邊緣部署的蒸餾和微調技術
- 實施具有監控功能的生產部署策略
- 建立企業級 SLM 操作和維護工作流程

### 學習重點領域

#### 第一節：SLMOps 簡介
- **重點概念**: 
  - SLMOps 在 AI 操作中的範式轉變
  - 成本效率和隱私優先架構
  - 戰略商業影響和競爭優勢

#### 第二節：模型蒸餾
- **重點概念**: 
  - 知識轉移技術
  - 兩階段蒸餾過程的實施
  - Azure ML 蒸餾工作流程

#### 第三節：微調策略
- **重點概念**: 
  - 參數高效微調（PEFT）
  - LoRA 和 QLoRA 高級方法
  - 多適配器訓練和超參數優化

#### 第四節：生產部署
- **重點概念**: 
  - 用於生產的模型轉換和量化
  - Foundry Local 部署配置
  - 性能基準測試和質量驗證

### 自我評估問題

1. SLMOps 與傳統 MLOps 有何不同？
2. 解釋模型蒸餾在邊緣部署中的優勢。
3. 在資源受限環境中微調 SLM 的主要考量是什麼？
4. 描述邊緣 AI 應用的完整生產部署管道。

### 實作練習

1. **基礎蒸餾**: 從較大的教師模型創建較小的模型（1 小時）
2. **微調實驗**: 為特定領域微調模型（1 小時）
3. **部署管道**: 設置基本的 CI/CD 管道以進行模型部署（1 小時）

## 第六章：SLM Agentic Systems - AI 代理和函數調用

### 核心學習目標

- 使用小型語言模型在邊緣環境中構建智能 AI 代理
- 實施具有系統化工作流程的函數調用功能
- 掌握模型上下文協議（MCP）集成以標準化工具交互
- 創建高級代理系統，減少人工干預

### 學習重點領域

#### 第一節：AI 代理和 SLM 基礎
- **重點概念**: 
  - 代理分類框架（反射型、基於模型、目標導向型、學習型代理）
  - SLM 與 LLM 的權衡分析
  - 邊緣特定代理設計模式
  - 代理的資源優化

#### 第二節：小型語言模型中的函數調用
- **重點概念**: 
  - 系統化工作流程實施（意圖檢測、JSON 輸出、外部執行）
  - 平台特定實施（Phi-4-mini、選定的 Qwen 模型、Microsoft Foundry Local）
  - 高級示例（多代理協作、動態工具選擇）
  - 生產考量（速率限制、審計記錄、安全措施）

#### 第三節：模型上下文協議（MCP）集成
- **重點概念**: 
  - 協議架構和分層系統設計
  - 多後端支持（Ollama 用於開發，vLLM 用於生產）
  - 連接協議（STDIO 和 SSE 模式）
  - 實際應用（網頁自動化、數據處理、API 集成）

### 自我評估問題

1. 邊緣 AI 代理的關鍵架構考量是什麼？
2. 函數調用如何增強代理功能？
3. 解釋模型上下文協議在代理通信中的作用。

### 實作練習

1. **簡單代理**: 使用函數調用構建基本 AI 代理（1 小時）
2. **MCP 集成**: 在代理應用中實施 MCP（30 分鐘）

## 第七章：邊緣 AI 實施範例

### 核心學習目標

- 掌握 Visual Studio Code 的 AI 工具包，用於全面的邊緣 AI 開發工作流程
- 熟悉 Windows AI Foundry 平台和 NPU 優化策略
- 在多個硬體平台和部署場景中實施邊緣 AI
- 使用平台特定的優化構建生產就緒的邊緣 AI 應用

### 學習重點領域

#### 第一節：Visual Studio Code 的 AI 工具包
- **重點概念**: 
  - 在 VS Code 中的全面邊緣 AI 開發環境
  - 用於邊緣部署的模型目錄和發現
  - 本地測試、優化和代理開發工作流程
  - 用於邊緣場景的性能監控和評估

#### 第二節：Windows 邊緣 AI 開發指南
- **重點概念**: 
  - Windows AI Foundry 平台全面概述
  - Phi Silica API 用於高效 NPU 推理
  - 用於圖像處理和 OCR 的計算機視覺 API
  - Foundry Local CLI 用於本地開發和測試

#### 第三節：平台特定實施
- **重點概念**: 
  - NVIDIA Jetson Orin Nano 部署（67 TOPS AI 性能）
  - 使用 .NET MAUI 和 ONNX Runtime GenAI 的移動應用
  - Azure 邊緣 AI 解決方案，具有雲-邊緣混合架構
  - Windows ML 優化，支持通用硬體
  - Foundry Local 應用，具有隱私專注的 RAG 實施

### 自我評估問題

1. AI 工具包如何簡化邊緣 AI 開發工作流程？
2. 比較不同硬體平台的部署策略。
3. Windows AI Foundry 在邊緣開發中的優勢是什麼？
4. NPU 優化在現代邊緣 AI 應用中的作用是什麼？
5. Phi Silica API 如何利用 NPU 硬體進行性能優化？
6. 比較本地部署與雲部署在隱私敏感應用中的優勢。

### 實作練習

1. **AI 工具包設置**: 配置 AI 工具包並優化模型（1 小時）
2. **Windows AI Foundry**: 使用 Phi Silica API 構建簡單的 Windows AI 應用（1 小時）
3. **跨平台部署**: 在兩個不同平台上部署同一模型（1 小時）
4. **NPU 優化**: 使用 Windows AI Foundry 工具測試 NPU 性能（30 分鐘）

## 第八章：Microsoft Foundry Local – 完整開發者工具包（現代化）

### 核心學習目標

- 安裝和配置 Foundry Local，集成現代 SDK
- 使用協調模式實施高級多代理系統
- 構建具有自動任務選擇的智能模型路由器
- 部署具有全面監控的生產就緒 AI 解決方案
- 與 Azure AI Foundry 集成，用於混合部署場景
- 掌握現代 SDK 模式，使用 FoundryLocalManager 和 OpenAI 客戶端

### 學習重點領域

#### 第一節：現代化安裝和配置
- **重點概念**: 
  - FoundryLocalManager SDK 集成
  - 自動服務發現和健康監控
  - 基於環境的配置模式
  - 生產部署考量

#### 第二節：高級多代理系統
- **重點概念**: 
  - 使用專家代理的協調模式
  - 檢索、推理和執行代理專業化
  - 用於改進的反饋循環機制
  - 性能監控和統計跟蹤

#### 第三節：智能模型路由
- **重點概念**: 
  - 基於關鍵字的模型選擇算法
  - 多模型支持（通用、推理、代碼、創意）
  - 環境變數配置的靈活性
  - 服務健康檢查和錯誤處理

#### 第四節：生產就緒實施
- **重點概念**: 
  - 全面的錯誤處理和回退機制
  - 請求監控和性能跟蹤
  - 帶基準測試的交互式 Jupyter notebook 示例
  - 與現有應用的集成模式

### 自我評估問題

1. 現代化的 FoundryLocalManager 方法與手動 REST 調用有何不同？
2. 解釋協調模式及其如何協調專家代理。
3. 智能路由器如何根據查詢內容選擇適合的模型？
4. 生產就緒的 AI 代理系統的關鍵組成部分是什麼？
5. 如何為 Foundry Local 服務實施全面的健康監控？
6. 比較現代化方法與傳統實施模式的優勢。

### 實作練習

1. **現代 SDK 設置**: 配置 FoundryLocalManager，實現自動服務發現（30 分鐘）
2. **多代理系統**: 運行具有專家代理的高級協調器（30 分鐘）
3. **智能路由**: 使用不同查詢類型測試模型路由器（30 分鐘）
4. **交互式探索**: 使用 Jupyter notebook 探索高級功能（45 分鐘）
5. **生產部署**: 實施監控和錯誤處理模式（30 分鐘）
6. **混合集成**: 配置 Azure AI Foundry 回退場景（30 分鐘）

## 時間分配指南

為幫助您充分利用 20 小時的課程時間，以下是建議的時間分配：

| 活動 | 時間分配 | 描述 |
|------|----------|------|
| 閱讀核心材料 | 9 小時 | 專注於每章的基本概念 |
| 實作練習 | 6 小時 | 關鍵技術的實際應用 |
| 自我評估 | 2 小時 | 通過問題和反思測試理解 |
| 小型專案 | 3 小時 | 將知識應用於小型實際實施 |

### 根據時間限制的重點領域

**如果您只有 10 小時:**
- 完成第 1、2 和 3 章（核心邊緣 AI 概念）
- 每章至少完成一個實作練習
- 專注於理解核心概念，而非實施細節

**如果您可以投入完整的 20 小時:**
- 完成所有七章
- 執行每章的關鍵實作練習
- 完成第 7 章的一個小型專案
- 探索至少 2-3 個補充資源

**如果您有超過 20 小時:**
- 詳細完成所有章節和練習
- 建立多個小型專案
- 探索第 4 章中的高級優化技術
- 實施第 5 章的生產部署

## 必備資源

以下精選資源能為您的有限學習時間提供最大價值：

### 必讀文檔
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型優化工具
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快的本地部署 SLM 方法
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考
- [OpenVINO 文檔](https://docs.openvino.ai/2025/index.html) - Intel 的全面優化工具包
- [VS Code 的 AI 工具包](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成的邊緣 AI 開發環境
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 特定的邊緣 AI 開發平台

### 節省時間的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問和部署
- [Gradio](https://www.gradio.app/docs/interface) - 快速開發 AI 演示的 UI
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化的模型優化工具
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的 CPU 推理工具
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網絡壓縮框架
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包

## 進度追蹤模板

使用此簡化模板追蹤您在 20 小時課程中的學習進度：

| 模組 | 完成日期 | 花費時間 | 主要收穫 |
|------|----------|----------|----------|
| 第 1 章：邊緣 AI 基礎 | | | |
| 第 2 章：SLM 基礎 | | | |
| 第 3 章：SLM 部署 | | | |
| 第 4 章：模型優化 | | | |
| 第 5 章：SLMOps | | | |
| 第 6 章：AI 代理 | | | |
| 第 7 章：開發工具 | | | |
| 第 8 章：Foundry Local 工具包 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

## 小型專案點子

考慮完成以下其中一個專案來練習 EdgeAI 概念（每個專案設計需時 2-4 小時）：

### 初級專案（每個需時 2-3 小時）
1. **邊緣文字助手**：使用小型語言模型創建一個簡單的離線文字補全工具
2. **模型比較儀表板**：建立一個基本的視覺化工具，用於比較不同 SLM 的性能指標
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響

### 中級專案（每個需時 3-4 小時）
4. **AI 工具包工作流程**：使用 VS Code AI 工具包完成模型的優化和部署
5. **Windows AI Foundry 應用程式**：使用 Phi Silica API 和 NPU 優化創建一個 Windows 應用程式
6. **跨平台部署**：將同一個優化模型部署到 Windows（OpenVINO）和移動端（.NET MAUI）
7. **函數調用代理**：構建一個具備函數調用能力的 AI 代理，用於邊緣場景

### 高級整合專案（每個需時 4-5 小時）
8. **OpenVINO 優化管道**：使用 NNCF 和 GenAI 工具包實現完整的模型優化
9. **SLMOps 管道**：實現從訓練到邊緣部署的完整模型生命周期
10. **多模型邊緣系統**：在邊緣硬體上部署多個專用模型協同工作
11. **MCP 整合系統**：使用模型上下文協議構建一個代理系統，用於工具交互

## 參考資料

- Microsoft Learn (Foundry Local)
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - 入門指南：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI 參考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - 與推理 SDK 整合：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - 開啟 WebUI 教學：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - 編譯 Hugging Face 模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/
  - 代理（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- 優化與推理工具
  - Microsoft Olive（文件）：https://microsoft.github.io/Olive/
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive
  - ONNX Runtime（入門指南）：https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive 整合：https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO（文件）：https://docs.openvino.ai/2025/index.html
  - Apple MLX（文件）：https://ml-explore.github.io/mlx/build/html/index.html
- 部署框架與模型
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index
  - vLLM（文件）：https://docs.vllm.ai/
  - Ollama（快速入門）：https://github.com/ollama/ollama#get-started
- 開發工具（Windows 和 VS Code）
  - VS Code 的 AI 工具包：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## 學習社群

加入討論並與其他學習者交流：
- [EdgeAI for Beginners GitHub 討論區](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft 技術社群](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

EdgeAI 代表了人工智慧應用的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等重要問題。本課程共 20 小時，提供了必要的知識和實用技能，讓您能立即開始使用 EdgeAI 技術。

課程內容精簡且專注於最重要的概念，讓您能快速獲得寶貴的專業知識，而不需要投入過多的時間。請記住，即使是簡單的實作練習，也能有效鞏固您所學的內容。

祝學習愉快！

---

