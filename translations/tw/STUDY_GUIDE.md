<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "64b8bb9e3cb942191493b8348a05127b",
  "translation_date": "2025-07-22T02:49:02+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tw"
}
-->
# EdgeAI 初學者指南：全面學習手冊

## 簡介

歡迎使用 EdgeAI 初學者學習手冊！本文件旨在幫助您有效地瀏覽課程材料，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，以加深您對 EdgeAI 技術的理解。

這是一門精簡的 20 小時課程，以高效的方式傳授 EdgeAI 的基本知識，非常適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概述

本課程分為三個主要模組：

1. **EdgeAI 基礎與轉型** - 理解核心概念及技術轉變
2. **小型語言模型基礎** - 探索各種模型家族及其架構
3. **小型語言模型部署** - 實現實際部署策略

## 如何使用本學習手冊

- **循序漸進學習**：按順序學習模組，以獲得最連貫的學習體驗
- **知識檢查點**：在每個章節後使用自我評估問題
- **動手練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|---------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 6小時 |
| 第3-4天 | 模組2：SLM 基礎 | 8小時 |
| 第5-6天 | 模組3：SLM 部署 | 6小時 |

### 兼職學習（3週）

| 週數 | 重點 | 預估時數 |
|------|-------|---------|
| 第1週 | 模組1：EdgeAI 基礎 | 6-7小時 |
| 第2週 | 模組2：SLM 基礎 | 7-8小時 |
| 第3週 | 模組3：SLM 部署 | 5-6小時 |

## 模組1：EdgeAI 基礎與轉型

### 主要學習目標

- 理解基於雲端與邊緣的 AI 之間的差異
- 掌握資源受限環境的核心優化技術
- 分析 EdgeAI 技術的實際應用
- 設置 EdgeAI 項目的開發環境

### 學習重點領域

#### 第一節：EdgeAI 基礎
- **優先概念**：
  - 邊緣計算與雲端計算的範式
  - 模型量化技術
  - 硬體加速選項（NPUs、GPUs、CPUs）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文件](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文件](https://docs.edgeimpulse.com)

#### 第二節：實際案例研究
- **優先概念**：
  - Microsoft Phi & Mu 模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第三節：實際實施指南
- **優先概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI 實施的評估方法

#### 第四節：邊緣部署硬體
- **優先概念**：
  - 硬體平台比較
  - 特定硬體的優化策略
  - 部署考量

### 自我評估問題

1. 比較基於雲端的 AI 與基於邊緣的 AI 實施。
2. 解釋三種優化模型以進行邊緣部署的關鍵技術。
3. 在邊緣運行 AI 模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬體加速器（NPUs、GPUs、CPUs）如何影響 EdgeAI 部署。

### 動手練習

1. **快速環境設置**：配置包含基本套件的最小開發環境（30分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1小時）
3. **基本量化**：嘗試對一個小型模型進行簡單量化（1小時）

## 模組2：小型語言模型基礎

### 主要學習目標

- 理解不同 SLM 家族的架構原則
- 比較不同參數規模的模型能力
- 根據效率、能力和部署需求評估模型
- 辨識不同模型家族的適用場景

### 學習重點領域

#### 第一節：Microsoft Phi 模型家族
- **優先概念**：
  - 設計理念的演變
  - 以效率為先的架構
  - 專業化能力

#### 第二節：Qwen 家族
- **優先概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第三節：Gemma 家族
- **優先概念**：
  - 以研究驅動的創新
  - 多模態能力
  - 移動優化

#### 第四節：BitNET 家族
- **優先概念**：
  - 1-bit 量化技術
  - 推理優化框架
  - 可持續性考量

#### 第五節：Microsoft Mu 模型
- **優先概念**：
  - 以設備為先的架構
  - 與 Windows 的系統整合
  - 隱私保護操作

#### 第六節：Phi-Silica
- **優先概念**：
  - NPU 優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較 Phi 和 Qwen 模型家族的架構方法。
2. 解釋 BitNET 的量化技術與傳統量化的不同之處。
3. Mu 模型在 Windows 整合方面的獨特優勢是什麼？
4. 描述 Phi-Silica 如何利用 NPU 硬體進行性能優化。
5. 對於一個有限連接的移動應用，哪個模型家族最適合？為什麼？

### 動手練習

1. **模型比較**：快速對兩個不同的 SLM 模型進行基準測試（1小時）
2. **簡單文本生成**：使用小型模型進行基本文本生成實現（1小時）
3. **快速優化**：應用一種優化技術以提高推理速度（1小時）

## 模組3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實施 SLM
- 設計適合生產的 EdgeAI 應用配置

### 學習重點領域

#### 第一節：SLM 高級學習
- **優先概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第二節：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第三節：容器化雲端部署
- **優先概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實施

### 自我評估問題

1. 選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 邊緣部署的 SLM 的關鍵性能指標是什麼？
5. 描述從模型選擇到生產實施的完整部署工作流程。

### 動手練習

1. **基本本地部署**：使用 Ollama 部署一個簡單的 SLM（1小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30分鐘）
3. **簡單整合**：創建一個使用已部署模型的最小應用程序（1小時）

## 時間分配指南

為幫助您充分利用 20 小時的課程時間，以下是建議的時間分配：

| 活動 | 時間分配 | 描述 |
|------|---------|-----|
| 閱讀核心材料 | 9小時 | 專注於每個模組的基本概念 |
| 動手練習 | 6小時 | 關鍵技術的實際實施 |
| 自我評估 | 2小時 | 通過問題和反思測試您的理解 |
| 小型項目 | 3小時 | 將知識應用於小型實際實施 |

### 根據時間限制的重點領域

**如果您只有10小時：**
- 完成模組1和模組2的前半部分
- 每個模組至少完成一個動手練習
- 專注於理解核心概念，而非實施細節

**如果您可以投入完整的20小時：**
- 完成所有三個模組
- 執行所有動手練習
- 完成一個小型項目
- 探索至少2-3個補充資源

## 必備資源

以下精選資源為您的有限學習時間提供最大價值：

### 必讀文件
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型優化工具
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快的本地部署 SLM 方法
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考

### 節省時間的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問與部署
- [Gradio](https://www.gradio.app/docs/interface) - 快速開發 AI 演示的 UI
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化模型優化

## 進度追蹤模板

使用此簡化模板追蹤您在 20 小時課程中的學習進度：

| 模組 | 完成日期 | 花費時間 | 主要收穫 |
|------|---------|---------|---------|
| 模組1：EdgeAI 基礎 | | | |
| 模組2：SLM 基礎 | | | |
| 模組3：SLM 部署 | | | |
| 動手練習 | | | |
| 小型項目 | | | |

## 小型項目建議

考慮完成以下小型項目之一以練習 EdgeAI 概念（每個設計為2-3小時）：

1. **邊緣文本助手**：使用小型語言模型創建一個簡單的離線文本補全工具
2. **模型比較儀表板**：構建一個基本的性能指標可視化工具，對不同 SLM 進行比較
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響

## 學習社群

加入討論並與其他學習者交流：
- [EdgeAI for Beginners GitHub 討論區](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft 技術社群](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

EdgeAI 代表了人工智慧實施的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等關鍵問題。本 20 小時課程為您提供了必要的知識和實用技能，讓您能夠立即開始使用 EdgeAI 技術。

課程內容精簡，專注於最重要的概念，讓您能夠快速獲得有價值的專業知識，而不需要投入過多的時間。請記住，即使是簡單的例子，動手練習也是鞏固所學的關鍵。

祝您學習愉快！

**免責聲明**：  
本文件使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋不承擔責任。