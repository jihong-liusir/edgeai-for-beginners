<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T16:05:17+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tw"
}
-->
# EdgeAI 初學者指南：學習路徑與學習計劃

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第2天 | 模組2：SLM 基礎 | 3小時 |
| 第3天 | 模組3：SLM 部署 | 2小時 |
| 第4-5天 | 模組4：模型優化（6個框架） | 4小時 |
| 第6天 | 模組5：SLMOps | 3小時 |
| 第7天 | 模組6-7：AI代理與開發工具 | 4小時 |
| 第8天 | 模組8：Foundry Local 工具包（現代實現） | 1小時 |

### 集中學習路徑（2週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：AI代理 | 2小時 |
| 第13-14天 | 模組7：開發工具 | 3小時 |

### 兼職學習（4週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：SLM代理系統 | 2小時 |
| 第13-14天 | 模組7：EdgeAI 實現範例 | 2小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|--------|----------------|-------------|--------------|
| 模組0：EdgeAI 簡介 | | | |
| 模組1：EdgeAI 基礎 | | | |
| 模組2：SLM 基礎 | | | |
| 模組3：SLM 部署 | | | |
| 模組4：模型優化（6個框架） | | | |
| 模組5：SLMOps | | | |
| 模組6：SLM代理系統 | | | |
| 模組7：EdgeAI 實現範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習（4週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

## 簡介

歡迎使用《EdgeAI 初學者指南》！本文件旨在幫助您有效地學習課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，幫助您深入了解EdgeAI技術。

這是一門精簡的20小時課程，旨在以高效的方式傳授EdgeAI的基本知識，非常適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概述

本課程分為八個全面的模組：

0. **EdgeAI 簡介** - 建立基礎並提供行業應用與學習目標
1. **EdgeAI 基礎與轉型** - 理解核心概念與技術變革
2. **小型語言模型（SLM）基礎** - 探索各種SLM家族及其架構
3. **小型語言模型部署** - 實現實際部署策略
4. **模型格式轉換與量化** - 使用6個框架進行高級優化，包括OpenVINO
5. **SLMOps - 小型語言模型運營** - 生產生命周期管理與部署
6. **SLM代理系統** - AI代理、函數調用與模型上下文協議
7. **EdgeAI 實現範例** - AI工具包、Windows開發與平台特定實現
8. **Microsoft Foundry Local – 完整開發工具包** - 本地優先開發與混合Azure整合（模組08）

## 如何使用本學習指南

- **循序漸進學習**：按順序學習模組以獲得最連貫的學習體驗
- **知識檢查點**：使用每節後的自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI 基礎 | 6小時 |
| 第3-4天 | 模組2：SLM 基礎 | 8小時 |
| 第5天 | 模組3：SLM 部署 | 3小時 |
| 第6天 | 模組8：Foundry Local 工具包 | 3小時 |

### 兼職學習（3週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組0：簡介 + 模組1：EdgeAI 基礎 | 7-9小時 |
| 第2週 | 模組2：SLM 基礎 | 7-8小時 |
| 第3週 | 模組3：SLM 部署（3小時）+ 模組8：Foundry Local 工具包（2-3小時） | 5-6小時 |

## 模組0：EdgeAI 簡介

### 主要學習目標

- 了解什麼是EdgeAI以及它在當今技術領域的重要性
- 識別被EdgeAI改變的主要行業及其具體應用案例
- 理解小型語言模型（SLM）在邊緣部署中的優勢
- 為整個課程建立清晰的學習期望與成果
- 認識EdgeAI領域的職業機會與技能需求

### 學習重點區域

#### 第1節：EdgeAI 範式與定義
- **重點概念**：
  - EdgeAI與傳統雲端AI處理的區別
  - 硬體、模型優化與商業需求的融合
  - 實時、隱私保護與成本效益的AI部署

#### 第2節：行業應用
- **重點概念**：
  - 製造業與工業4.0：預測性維護與品質控制
  - 醫療保健：診斷影像與患者監測
  - 自主系統：自駕車與交通運輸
  - 智慧城市：交通管理與公共安全
  - 消費技術：智能手機、穿戴設備與智能家居

#### 第3節：小型語言模型基礎
- **重點概念**：
  - SLM特性與性能比較
  - 參數效率與能力的權衡
  - 邊緣部署限制與優化策略

#### 第4節：學習框架與職業路徑
- **重點概念**：
  - 課程架構與漸進掌握方法
  - 技術技能與實際實現目標
  - 職業發展機會與行業應用

### 自我評估問題

1. 哪三個主要技術趨勢促成了EdgeAI的發展？
2. 比較EdgeAI與基於雲端的AI的優勢與挑戰。
3. 列出三個EdgeAI提供重要商業價值的行業並解釋原因。
4. 小型語言模型如何使EdgeAI在實際部署中更具可行性？
5. 在本課程中您將學到哪些關鍵技術技能？
6. 描述本課程使用的四階段學習方法。

### 實作練習

1. **行業研究**：選擇一個行業應用並研究一個真實的EdgeAI實現案例（30分鐘）
2. **模型探索**：瀏覽Hugging Face上的小型語言模型並比較其參數數量與能力（30分鐘）
3. **學習規劃**：審查完整課程結構並制定個人學習計劃（15分鐘）

### 補充材料

- [EdgeAI市場概述 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [小型語言模型概述 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [邊緣計算基礎](https://www.edgecomputing.org/)

## 模組1：EdgeAI 基礎與轉型

### 主要學習目標

- 了解基於雲端的AI與基於邊緣的AI的差異
- 掌握資源受限環境的核心優化技術
- 分析EdgeAI技術的真實應用案例
- 設置EdgeAI項目的開發環境

### 學習重點區域

#### 第1節：EdgeAI 基礎
- **重點概念**：
  - 邊緣與雲端計算範式
  - 模型量化技術
  - 硬體加速選項（NPU、GPU、CPU）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文檔](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文檔](https://docs.edgeimpulse.com)

#### 第2節：真實案例研究
- **重點概念**：
  - Microsoft Phi & Mu模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第3節：實際實現指南
- **重點概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI實現的評估方法

#### 第4節：邊緣部署硬體
- **重點概念**：
  - 硬體平台比較
  - 特定硬體的優化策略
  - 部署考量

### 自我評估問題

1. 比較基於雲端的AI與基於邊緣的AI的實現方式。
2. 解釋三種優化模型以適應邊緣部署的關鍵技術。
3. 在邊緣運行AI模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬體加速器（NPU、GPU、CPU）如何影響EdgeAI部署。

### 實作練習

1. **快速環境設置**：配置一個包含基本套件的最小開發環境（30分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1小時）
3. **基本量化**：嘗試對一個小型模型進行簡單量化（1小時）

## 模組2：小型語言模型基礎

### 主要學習目標

- 了解不同SLM家族的架構原則
- 比較不同參數規模模型的能力
- 根據效率、能力與部署需求評估模型
- 識別不同模型家族的適用場景

### 學習重點區域

#### 第1節：Microsoft Phi 模型家族
- **重點概念**：
  - 設計理念演變
  - 效率優先架構
  - 專業化能力

#### 第2節：Qwen 家族
- **重點概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第3節：Gemma 家族
- **重點概念**：
  - 研究驅動創新
  - 多模態能力
  - 移動優化

#### 第4節：BitNET 家族
- **重點概念**：
  - 1位元量化技術
  - 推理優化框架
  - 可持續性考量

#### 第5節：Microsoft Mu 模型
- **重點概念**：
  - 設備優先架構
  - 與Windows的系統整合
  - 隱私保護操作

#### 第6節：Phi-Silica
- **重點概念**：
  - NPU優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較Phi與Qwen模型家族的架構方法。
2. 解釋BitNET的量化技術如何與傳統量化技術不同。
3. Mu 模型在 Windows 整合方面有哪些獨特優勢？
4. Phi-Silica 如何利用 NPU 硬體進行性能優化？
5. 對於一個連接性有限的移動應用程式，哪個模型系列最適合？為什麼？

### 實作練習

1. **模型比較**：快速對比兩個不同的 SLM 模型（1 小時）
2. **簡單文本生成**：使用小型模型進行基本文本生成實作（1 小時）
3. **快速優化**：應用一種優化技術以提升推理速度（1 小時）

## 模組 3：小型語言模型部署

### 核心學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實作 SLM
- 設計適用於 EdgeAI 應用的生產級配置

### 學習重點領域

#### 第一節：SLM 高級學習
- **優先概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第二節：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第三節：容器化雲端部署
- **優先概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實作

### 自我評估問題

1. 在選擇本地部署和雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 對於邊緣部署的 SLM，應監控哪些關鍵性能指標？
5. 描述從模型選擇到生產實作的完整部署工作流程。

### 實作練習

1. **基本本地部署**：使用 Ollama 部署一個簡單的 SLM（1 小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30 分鐘）
3. **簡單整合**：創建一個使用已部署模型的最小應用程式（1 小時）

## 模組 4：模型格式轉換與量化

### 核心學習目標

- 掌握從 1-bit 到 8-bit 精度的高級量化技術
- 理解格式轉換策略（GGUF、ONNX）
- 在六個框架中實作優化（Llama.cpp、Olive、OpenVINO、MLX、工作流程綜合）
- 為 Intel、Apple 和跨平台硬體部署生產級優化模型

### 學習重點領域

#### 第一節：量化基礎
- **優先概念**：
  - 精度分類框架
  - 性能與準確性權衡
  - 記憶體占用優化

#### 第二節：Llama.cpp 實作
- **優先概念**：
  - 跨平台部署
  - GGUF 格式優化
  - 硬體加速技術

#### 第三節：Microsoft Olive 套件
- **優先概念**：
  - 硬體感知優化
  - 企業級部署
  - 自動化優化工作流程

#### 第四節：OpenVINO 工具包
- **優先概念**：
  - Intel 硬體優化
  - 神經網路壓縮框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI 用於 LLM 部署

#### 第五節：Apple MLX 框架
- **優先概念**：
  - Apple Silicon 優化
  - 統一記憶體架構
  - LoRA 微調能力

#### 第六節：邊緣 AI 開發工作流程綜合
- **優先概念**：
  - 統一工作流程架構
  - 框架選擇決策樹
  - 生產準備驗證
  - 未來適應性策略

### 自我評估問題

1. 比較不同精度級別（1-bit 到 8-bit）的量化策略。
2. 解釋 GGUF 格式對邊緣部署的優勢。
3. Microsoft Olive 的硬體感知優化如何提升部署效率？
4. OpenVINO 的 NNCF 在模型壓縮方面有哪些主要優勢？
5. 描述 Apple MLX 如何利用統一記憶體架構進行優化。
6. 工作流程綜合如何幫助選擇最佳優化框架？

### 實作練習

1. **模型量化**：對模型應用不同量化級別並比較結果（1 小時）
2. **OpenVINO 優化**：使用 NNCF 壓縮模型以適配 Intel 硬體（1 小時）
3. **框架比較**：在三個不同的優化框架中測試同一模型（1 小時）
4. **性能基準測試**：測量優化對推理速度和記憶體使用的影響（1 小時）

## 模組 5：SLMOps - 小型語言模型運營

### 核心學習目標

- 理解 SLMOps 生命周期管理原則
- 掌握邊緣部署的蒸餾和微調技術
- 實作具有監控功能的生產部署策略
- 建立企業級 SLM 運營和維護工作流程

### 學習重點領域

#### 第一節：SLMOps 簡介
- **優先概念**：
  - SLMOps 在 AI 運營中的範式轉變
  - 成本效率和隱私優先架構
  - 戰略性商業影響和競爭優勢

#### 第二節：模型蒸餾
- **優先概念**：
  - 知識轉移技術
  - 雙階段蒸餾過程實作
  - Azure ML 蒸餾工作流程

#### 第三節：微調策略
- **優先概念**：
  - 參數高效微調（PEFT）
  - LoRA 和 QLoRA 高級方法
  - 多適配器訓練和超參數優化

#### 第四節：生產部署
- **優先概念**：
  - 生產級模型轉換與量化
  - Foundry Local 部署配置
  - 性能基準測試和質量驗證

### 自我評估問題

1. SLMOps 與傳統 MLOps 有何不同？
2. 解釋模型蒸餾對邊緣部署的好處。
3. 在資源受限的環境中微調 SLM 時有哪些關鍵考量？
4. 描述邊緣 AI 應用的完整生產部署管道。

### 實作練習

1. **基本蒸餾**：從較大的教師模型創建較小的模型（1 小時）
2. **微調實驗**：針對特定領域微調模型（1 小時）
3. **部署管道**：設置基本的 CI/CD 管道以進行模型部署（1 小時）

## 模組 6：SLM Agentic 系統 - AI 代理與函數調用

### 核心學習目標

- 使用小型語言模型構建適用於邊緣環境的智能 AI 代理
- 實作具有系統化工作流程的函數調用功能
- 掌握模型上下文協議（MCP）整合以實現標準化工具交互
- 創建高級代理系統，減少人工干預

### 學習重點領域

#### 第一節：AI 代理與 SLM 基礎
- **優先概念**：
  - 代理分類框架（反射型、基於模型、目標導向型、學習型代理）
  - SLM 與 LLM 的權衡分析
  - 邊緣特定代理設計模式
  - 代理資源優化

#### 第二節：小型語言模型中的函數調用
- **優先概念**：
  - 系統化工作流程實作（意圖檢測、JSON 輸出、外部執行）
  - 平台特定實作（Phi-4-mini、選定的 Qwen 模型、Microsoft Foundry Local）
  - 高級示例（多代理協作、動態工具選擇）
  - 生產考量（速率限制、審計記錄、安全措施）

#### 第三節：模型上下文協議（MCP）整合
- **優先概念**：
  - 協議架構與分層系統設計
  - 多後端支持（Ollama 用於開發，vLLM 用於生產）
  - 連接協議（STDIO 和 SSE 模式）
  - 實際應用（網頁自動化、數據處理、API 整合）

### 自我評估問題

1. 邊緣 AI 代理的關鍵架構考量是什麼？
2. 函數調用如何增強代理功能？
3. 解釋模型上下文協議在代理通信中的作用。

### 實作練習

1. **簡單代理**：構建具有函數調用功能的基本 AI 代理（1 小時）
2. **MCP 整合**：在代理應用中實作 MCP（30 分鐘）

## 工作坊：實作學習路徑

### 核心學習目標

- 使用 Foundry Local SDK 和最佳實踐構建生產級 AI 應用
- 實作全面的錯誤處理和用戶反饋模式
- 創建 RAG 管道並進行質量評估和性能監控
- 開發具有協調模式的多代理系統
- 掌握智能模型路由以進行基於任務的模型選擇
- 部署以隱私保護架構為主的本地優先 AI 解決方案

### 學習重點領域

#### 第一節：使用 Foundry Local 入門
- **優先概念**：
  - FoundryLocalManager SDK 整合與自動服務發現
  - 基本和流式聊天實作
  - 錯誤處理模式與用戶反饋
  - 基於環境的配置

#### 第二節：使用 RAG 構建 AI 解決方案
- **優先概念**：
  - 使用 sentence-transformers 的內存向量嵌入
  - RAG 管道實作（檢索 → 生成）
  - 使用 RAGAS 指標進行質量評估
  - 可選依賴項的導入安全性

#### 第三節：開源模型
- **優先概念**：
  - 多模型基準測試策略
  - 延遲和吞吐量測量
  - 優雅降級與錯誤恢復
  - 模型系列性能比較

#### 第四節：尖端模型
- **優先概念**：
  - SLM 與 LLM 比較方法論
  - 類型提示與全面的輸出格式化
  - 每模型錯誤處理
  - 用於分析的結構化結果

#### 第五節：AI 驅動代理
- **優先概念**：
  - 使用協調模式進行多代理編排
  - 代理記憶管理與狀態跟蹤
  - 管道錯誤處理與階段記錄
  - 性能監控與統計

#### 第六節：模型作為工具
- **優先概念**：
  - 意圖檢測與模式匹配
  - 基於關鍵字的模型路由算法
  - 多步管道（計劃 → 執行 → 優化）
  - 全面的函數文檔

### 自我評估問題

1. FoundryLocalManager 如何簡化服務管理，相較於手動 REST 調用？
2. 解釋可選依賴項（如 sentence-transformers）的導入保護的重要性。
3. 哪些策略可確保多模型基準測試中的優雅降級？
4. 協調模式如何編排多個專家代理？
5. 描述智能模型路由器的組成部分。
6. 生產級錯誤處理的關鍵要素是什麼？

### 實作練習

1. **聊天應用**：實作具有錯誤處理功能的流式聊天（45 分鐘）
2. **RAG 管道**：構建最小 RAG 並進行質量評估（1 小時）
3. **模型基準測試**：比較 3 個以上模型的性能（1 小時）
4. **多代理系統**：創建具有 2 個專家代理的協調器（1.5 小時）
5. **智能路由器**：構建基於任務的模型選擇（1 小時）
6. **生產部署**：添加監控和全面的錯誤處理（45 分鐘）

### 時間分配

**集中學習（1 週）**：
- 第一天：Session 01-02（聊天 + RAG）- 3 小時
- 第二天：Session 03-04（基準測試 + 比較）- 3 小時
- 第三天：Session 05-06（代理 + 路由）- 3 小時
- 第四天：實作練習與驗證 - 2 小時

**兼職學習（2 週）**：
- 第 1 週：Session 01-03（共 6 小時）
- 第 2 週：Session 04-06 + 實作練習（共 5 小時）

## 模組 7：EdgeAI 實作範例

### 核心學習目標

- 掌握 Visual Studio Code 的 AI 工具包以進行全面的 EdgeAI 開發工作流程
- 熟悉 Windows AI Foundry 平台和 NPU 優化策略
- 在多種硬體平台和部署場景中實作 EdgeAI
- 構建具有平台特定優化的生產級 EdgeAI 應用

### 學習重點領域

#### 第一節：Visual Studio Code 的 AI 工具包
- **優先概念**：
  - 在 VS Code 中進行全面的 Edge AI 開發環境
  - 用於邊緣部署的模型目錄與發現
  - 本地測試、優化與代理開發工作流程
  - 邊緣場景的性能監控與評估

#### 第二節：Windows EdgeAI 開發指南
- **優先概念**：
  - Windows AI Foundry 平台全面概述
  - Phi Silica API 用於高效 NPU 推理
  - 用於圖像處理和 OCR 的計算機視覺 API
  - Foundry Local CLI 用於本地開發與測試

#### 第三節：平台特定實作
- **優先概念**：
  - NVIDIA Jetson Orin Nano 部署（67 TOPS AI 性能）
  - 使用 .NET MAUI 和 ONNX Runtime GenAI 的移動應用
  - Azure EdgeAI 解決方案與雲端-邊緣混合架構
  - Windows ML 優化與通用硬體支持
  - Foundry Local 應用與隱私保護的 RAG 實作

### 自我評估問題

1. AI 工具包如何簡化 EdgeAI 開發工作流程？
2. 比較不同硬體平台的部署策略。
3. Windows AI Foundry 在邊緣開發方面有哪些優勢？
4. 解釋 NPU 優化在現代邊緣 AI 應用中的角色。  
5. Phi Silica API 如何利用 NPU 硬體進行效能優化？  
6. 比較本地部署與雲端部署在隱私敏感應用中的優勢。

### 實作練習

1. **AI 工具包設置**：配置 AI 工具包並優化模型（1 小時）  
2. **Windows AI Foundry**：使用 Phi Silica API 建立一個簡單的 Windows AI 應用程式（1 小時）  
3. **跨平台部署**：將相同模型部署於兩個不同平台（1 小時）  
4. **NPU 優化**：使用 Windows AI Foundry 工具測試 NPU 效能（30 分鐘）  

## 模組 8：Microsoft Foundry Local – 完整開發者工具包（現代化）

### 主要學習目標

- 安裝並配置 Foundry Local，整合現代 SDK  
- 實現使用協調器模式的進階多代理系統  
- 建立具備自動任務選擇的智能模型路由器  
- 部署具備全面監控的生產級 AI 解決方案  
- 整合 Azure AI Foundry 以實現混合部署場景  
- 掌握 FoundryLocalManager 和 OpenAI 客戶端的現代 SDK 模式  

### 學習重點區域

#### 第 1 節：現代化安裝與配置
- **優先概念**：  
  - FoundryLocalManager SDK 整合  
  - 自動服務發現與健康監控  
  - 基於環境的配置模式  
  - 生產部署考量  

#### 第 2 節：進階多代理系統
- **優先概念**：  
  - 使用專家代理的協調器模式  
  - 檢索、推理與執行代理的專業化  
  - 用於改進的反饋迴路機制  
  - 效能監控與統計追蹤  

#### 第 3 節：智能模型路由
- **優先概念**：  
  - 基於關鍵字的模型選擇算法  
  - 支援多模型（通用、推理、代碼、創意）  
  - 環境變數配置的靈活性  
  - 服務健康檢查與錯誤處理  

#### 第 4 節：生產級實現
- **優先概念**：  
  - 全面的錯誤處理與回退機制  
  - 請求監控與效能追蹤  
  - 使用帶有基準測試的互動式 Jupyter notebook 範例  
  - 與現有應用程式的整合模式  

### 自我評估問題

1. 現代 FoundryLocalManager 方法與手動 REST 呼叫有何不同？  
2. 解釋協調器模式及其如何協調專家代理。  
3. 智能路由器如何根據查詢內容選擇適當的模型？  
4. 生產級 AI 代理系統的關鍵組成部分是什麼？  
5. 如何為 Foundry Local 服務實現全面的健康監控？  
6. 比較現代化方法與傳統實現模式的優勢。  

### 實作練習

1. **現代 SDK 設置**：配置 FoundryLocalManager，實現自動服務發現（30 分鐘）  
2. **多代理系統**：運行帶有專家代理的進階協調器（30 分鐘）  
3. **智能路由**：測試模型路由器處理不同查詢類型（30 分鐘）  
4. **互動式探索**：使用 Jupyter notebook 探索進階功能（45 分鐘）  
5. **生產部署**：實現監控與錯誤處理模式（30 分鐘）  
6. **混合整合**：配置 Azure AI Foundry 回退場景（30 分鐘）  

## 時間分配指南

為幫助您充分利用這個包含工作坊的 30 小時課程時間，以下是建議的時間分配：

| 活動 | 時間分配 | 描述 |  
|----------|----------------|-------------|  
| 閱讀核心材料 | 12 小時 | 專注於每個模組中的基本概念 |  
| 實作練習 | 10 小時 | 關鍵技術的實踐應用（包括工作坊） |  
| 自我評估 | 3 小時 | 通過問題和反思測試理解 |  
| 小型專案 | 5 小時 | 將知識應用於小型實踐實現 |  

### 根據時間限制的重點區域

**如果您只有 10 小時：**  
- 完成模組 0（介紹）以及模組 1、2 和 3（核心 EdgeAI 概念）  
- 每個模組至少完成一個實作練習  
- 專注於理解核心概念，而非實現細節  

**如果您能投入完整的 20 小時：**  
- 完成所有八個模組（包括介紹）  
- 執行每個模組的關鍵實作練習  
- 完成模組 7 的一個小型專案  
- 探索至少 2-3 個補充資源  

**如果您有超過 20 小時：**  
- 詳細完成所有模組（包括介紹）及相關練習  
- 建立多個小型專案  
- 探索模組 4 的進階優化技術  
- 實現模組 5 的生產部署  

## 必備資源

以下精選資源能為您的有限學習時間提供最大價值：

### 必讀文件
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最有效的模型優化工具  
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快速的本地 SLM 部署方式  
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 邊緣優化模型的參考  
- [OpenVINO 文件](https://docs.openvino.ai/2025/index.html) - Intel 的全面優化工具包  
- [VS Code 的 AI 工具包](https://code.visualstudio.com/docs/intelligentapps/overview) - 整合的 EdgeAI 開發環境  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 專用的 EdgeAI 開發平台  

### 節省時間的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問與部署  
- [Gradio](https://www.gradio.app/docs/interface) - 快速建立 AI 演示的 UI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化的模型優化工具  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的 CPU 推理工具  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網路壓縮框架  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包  

## 進度追蹤模板

使用此簡化模板追蹤您在 20 小時課程中的學習進度：

| 模組 | 完成日期 | 花費時間 | 關鍵收穫 |  
|--------|----------------|-------------|---------------|  
| 模組 0：EdgeAI 介紹 | | | |  
| 模組 1：EdgeAI 基礎 | | | |  
| 模組 2：SLM 基礎 | | | |  
| 模組 3：SLM 部署 | | | |  
| 模組 4：模型優化 | | | |  
| 模組 5：SLMOps | | | |  
| 模組 6：AI 代理 | | | |  
| 模組 7：開發工具 | | | |  
| 工作坊：實作學習 | | | |  
| 模組 8：Foundry Local 工具包 | | | |  
| 實作練習 | | | |  
| 小型專案 | | | |  

## 小型專案構想

考慮完成以下專案之一來練習 EdgeAI 概念（每個設計為 2-4 小時）：

### 初學者專案（每個 2-3 小時）
1. **邊緣文字助手**：使用小型語言模型創建一個簡單的離線文字補全工具  
2. **模型比較儀表板**：建立一個基本的可視化工具，展示不同 SLM 的效能指標  
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響  

### 中級專案（每個 3-4 小時）
4. **AI 工具包工作流程**：使用 VS Code AI 工具包從頭到尾優化並部署模型  
5. **Windows AI Foundry 應用程式**：使用 Phi Silica API 和 NPU 優化創建一個 Windows 應用程式  
6. **跨平台部署**：將相同的優化模型部署於 Windows（OpenVINO）和行動裝置（.NET MAUI）  
7. **函數調用代理**：為邊緣場景構建一個具備函數調用功能的 AI 代理  

### 高級整合專案（每個 4-5 小時）
8. **OpenVINO 優化管道**：使用 NNCF 和 GenAI 工具包實現完整的模型優化  
9. **SLMOps 管道**：實現從訓練到邊緣部署的完整模型生命周期  
10. **多模型邊緣系統**：在邊緣硬體上部署多個專業化模型協同工作  
11. **MCP 整合系統**：使用模型上下文協議構建一個代理系統以進行工具交互  

## 參考資料

- Microsoft Learn (Foundry Local)  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - 入門：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI 參考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - 與推理 SDK 整合：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - 開啟 WebUI 教學：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - 編譯 Hugging Face 模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - 代理（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- 優化與推理工具  
  - Microsoft Olive（文件）：https://microsoft.github.io/Olive/  
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive  
  - ONNX Runtime（入門）：https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive 整合：https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO（文件）：https://docs.openvino.ai/2025/index.html  
  - Apple MLX（文件）：https://ml-explore.github.io/mlx/build/html/index.html  
- 部署框架與模型  
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index  
  - vLLM（文件）：https://docs.vllm.ai/  
  - Ollama（快速入門）：https://github.com/ollama/ollama#get-started  
- 開發工具（Windows 和 VS Code）  
  - VS Code 的 AI 工具包：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## 學習社群

加入討論並與其他學習者聯繫：  
- [EdgeAI for Beginners GitHub 討論區](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft 技術社群](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 結論

EdgeAI 代表了人工智慧實現的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等關鍵問題。本 20 小時課程為您提供了必要的知識和實踐技能，讓您能立即開始使用 EdgeAI 技術。

課程內容精簡且專注於最重要的概念，讓您能快速獲得寶貴的專業知識，而不會感到時間壓力。請記住，即使是簡單的實作練習，也能有效鞏固您所學的內容。

祝學習愉快！

---

**免責聲明**：  
本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而產生的任何誤解或錯誤解釋不承擔責任。