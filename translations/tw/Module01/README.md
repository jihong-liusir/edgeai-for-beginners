<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-07-22T02:59:36+00:00",
  "source_file": "Module01/README.md",
  "language_code": "tw"
}
-->
# 第 01 章：改變 AI 部署方式以適應邊緣運算

邊緣 AI（EdgeAI）代表了一種人工智慧部署的範式轉移，將 AI 能力從基於雲端的處理轉移到本地邊緣設備。本章探討了定義這種 AI 實施轉型的基本概念、關鍵技術以及實際應用。

## 模組結構

### [第 1 節：邊緣 AI 基礎](./01.EdgeAIFundamentals.md)
本節透過對比傳統的基於雲端的 AI 與邊緣 AI 部署模型，建立基礎。我們探討了包括模型量化、壓縮優化以及小型語言模型（SLMs）等關鍵技術，這些技術克服了邊緣設備的計算限制。討論重點在於這些創新如何提供增強的隱私保護、超低延遲以及強大的離線處理能力。

### [第 2 節：實際案例研究](./02.RealWorldCaseStudies.md)
透過具體例子，例如微軟的 Phi 和 Mu 模型生態系統以及日本航空的 AI 報告系統，本節展示了邊緣 AI 在多個行業中的成功實施。這些案例研究驗證了 SLMs 在專業任務中的卓越表現，並說明了邊緣部署策略的實際效益。

### [第 3 節：實際實施指南](./03.PracticalImplementationGuide.md)
本節提供了全面的環境準備指南，涵蓋必要的開發工具、硬體需求、核心模型資源以及優化框架，為學習者建立技術基礎，以便構建和部署自己的邊緣 AI 解決方案。

### [第 4 節：邊緣 AI 部署硬體平台](./04.EdgeDeployment.md)
本節探討了支持邊緣 AI 部署的硬體生態系統，涵蓋 Intel、Qualcomm、NVIDIA 和 Windows AI PCs 等平台。提供了硬體能力的詳細比較、平台特定的優化技術以及在各種邊緣計算場景中的實際部署考量。

## 主要學習成果

完成本章後，讀者將能夠理解：
- 雲端 AI 與邊緣 AI 架構的基本差異
- 邊緣部署的核心優化技術
- 實際應用和成功案例
- 實施邊緣 AI 解決方案的實際技能
- 硬體平台選擇及平台特定的優化方法
- 性能基準測試及部署最佳實踐

## 未來影響

邊緣 AI 作為塑造 AI 部署未來的重要趨勢，為分散式、高效能且保護隱私的 AI 系統鋪平了道路，這些系統能夠在不依賴雲端連接的情況下獨立運作，同時保持高性能標準。

**免責聲明**：  
本文件使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。應以原始語言的文件作為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而產生的任何誤解或錯誤解讀概不負責。