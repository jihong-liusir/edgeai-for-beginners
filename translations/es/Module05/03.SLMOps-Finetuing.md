<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T13:40:19+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "es"
}
-->
# Sección 3: Ajuste Fino - Personalización de Modelos para Tareas Específicas

## Tabla de Contenidos
1. [Introducción al Ajuste Fino](../../../Module05)
2. [Por qué el Ajuste Fino es Importante](../../../Module05)
3. [Tipos de Ajuste Fino](../../../Module05)
4. [Ajuste Fino con Microsoft Olive](../../../Module05)
5. [Ejemplos Prácticos](../../../Module05)
6. [Mejores Prácticas y Directrices](../../../Module05)
7. [Técnicas Avanzadas](../../../Module05)
8. [Evaluación y Monitoreo](../../../Module05)
9. [Desafíos Comunes y Soluciones](../../../Module05)
10. [Conclusión](../../../Module05)

## Introducción al Ajuste Fino

**El ajuste fino** es una técnica poderosa de aprendizaje automático que consiste en adaptar un modelo preentrenado para realizar tareas específicas o trabajar con conjuntos de datos especializados. En lugar de entrenar un modelo desde cero, el ajuste fino aprovecha el conocimiento ya aprendido por un modelo preentrenado y lo ajusta para tu caso de uso particular.

### ¿Qué es el Ajuste Fino?

El ajuste fino es una forma de **aprendizaje por transferencia** en la que:
- Comienzas con un modelo preentrenado que ha aprendido patrones generales a partir de grandes conjuntos de datos.
- Ajustas los parámetros internos del modelo utilizando tu conjunto de datos específico.
- Conservas el conocimiento valioso mientras especializas el modelo para tu tarea.

Piensa en ello como enseñar a un chef experto a cocinar una nueva cocina: ya comprende los fundamentos de la cocina, pero necesita aprender técnicas y sabores específicos para el nuevo estilo.

### Beneficios Clave

- **Eficiencia de Tiempo**: Mucho más rápido que entrenar desde cero.
- **Eficiencia de Datos**: Requiere conjuntos de datos más pequeños para lograr un buen rendimiento.
- **Rentabilidad**: Menores requisitos computacionales.
- **Mejor Rendimiento**: A menudo logra resultados superiores en comparación con entrenar desde cero.
- **Optimización de Recursos**: Hace que la IA avanzada sea accesible para equipos y organizaciones más pequeñas.

## Por qué el Ajuste Fino es Importante

### Aplicaciones en el Mundo Real

El ajuste fino es esencial en numerosos escenarios:

**1. Adaptación de Dominio**
- IA Médica: Adaptar modelos de lenguaje general para terminología médica y notas clínicas.
- Tecnología Legal: Especializar modelos para análisis de documentos legales y revisión de contratos.
- Servicios Financieros: Personalizar modelos para análisis de informes financieros y evaluación de riesgos.

**2. Especialización de Tareas**
- Generación de Contenido: Ajuste fino para estilos o tonos de escritura específicos.
- Generación de Código: Adaptar modelos para lenguajes de programación o frameworks particulares.
- Traducción: Mejorar el rendimiento para pares de idiomas específicos o dominios técnicos.

**3. Aplicaciones Corporativas**
- Servicio al Cliente: Crear chatbots que comprendan la terminología específica de la empresa.
- Documentación Interna: Construir asistentes de IA familiarizados con procesos organizacionales.
- Soluciones Específicas de la Industria: Desarrollar modelos que comprendan jerga y flujos de trabajo específicos del sector.

## Tipos de Ajuste Fino

### 1. Ajuste Fino Completo (Ajuste Fino por Instrucción)

En el ajuste fino completo, se actualizan todos los parámetros del modelo durante el entrenamiento. Este enfoque:
- Ofrece máxima flexibilidad y potencial de rendimiento.
- Requiere recursos computacionales significativos.
- Resulta en una versión completamente nueva del modelo.
- Es ideal para escenarios donde tienes datos de entrenamiento sustanciales y recursos computacionales.

### 2. Ajuste Fino Eficiente en Parámetros (PEFT)

Los métodos PEFT actualizan solo un pequeño subconjunto de parámetros, haciendo el proceso más eficiente:

#### Adaptación de Baja Rango (LoRA)
- Agrega pequeñas matrices de descomposición de rango entrenables a los pesos existentes.
- Reduce drásticamente el número de parámetros entrenables.
- Mantiene un rendimiento cercano al ajuste fino completo.
- Permite cambiar fácilmente entre diferentes adaptaciones.

#### QLoRA (LoRA Cuantificado)
- Combina LoRA con técnicas de cuantificación.
- Reduce aún más los requisitos de memoria.
- Permite el ajuste fino de modelos más grandes en hardware de consumo.
- Equilibra eficiencia con rendimiento.

#### Adaptadores
- Inserta pequeñas redes neuronales entre capas existentes.
- Permite un ajuste fino dirigido mientras mantiene el modelo base congelado.
- Facilita un enfoque modular para la personalización del modelo.

### 3. Ajuste Fino Específico de Tarea

Se centra en adaptar modelos para tareas específicas:
- **Clasificación**: Ajustar modelos para tareas de categorización.
- **Generación**: Optimizar para creación de contenido y generación de texto.
- **Extracción**: Ajuste fino para extracción de información y reconocimiento de entidades nombradas.
- **Resumen**: Especializar modelos para resumen de documentos.

## Ajuste Fino con Microsoft Olive

Microsoft Olive es una herramienta integral de optimización de modelos que simplifica el proceso de ajuste fino mientras proporciona características de nivel empresarial.

### ¿Qué es Microsoft Olive?

Microsoft Olive es una herramienta de optimización de modelos de código abierto que:
- Simplifica los flujos de trabajo de ajuste fino para diversos objetivos de hardware.
- Ofrece soporte integrado para arquitecturas de modelos populares (Llama, Phi, Qwen, Gemma).
- Proporciona opciones de implementación tanto en la nube como localmente.
- Se integra perfectamente con Azure ML y otros servicios de IA de Microsoft.
- Admite optimización y cuantificación automáticas.

### Características Clave

- **Optimización Basada en Hardware**: Optimiza automáticamente los modelos para hardware específico (CPU, GPU, NPU).
- **Soporte Multi-Formato**: Funciona con modelos de PyTorch, Hugging Face y ONNX.
- **Flujos de Trabajo Automatizados**: Reduce la configuración manual y el ensayo y error.
- **Integración Empresarial**: Soporte integrado para Azure ML y despliegues en la nube.
- **Arquitectura Extensible**: Permite técnicas de optimización personalizadas.

### Instalación y Configuración

#### Instalación Básica

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dependencias Opcionales

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verificar Instalación

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Ejemplos Prácticos

### Ejemplo 1: Ajuste Fino Básico con Olive CLI

Este ejemplo demuestra el ajuste fino de un modelo de lenguaje pequeño para clasificación de frases:

#### Paso 1: Preparar el Entorno

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Paso 2: Ajustar el Modelo

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Paso 3: Optimizar para Despliegue

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Ejemplo 2: Configuración Avanzada con Conjunto de Datos Personalizado

#### Paso 1: Preparar Conjunto de Datos Personalizado

Crea un archivo JSON con tus datos de entrenamiento:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Paso 2: Crear Archivo de Configuración

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Paso 3: Ejecutar el Ajuste Fino

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Ejemplo 3: Ajuste Fino con QLoRA para Eficiencia de Memoria

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Mejores Prácticas y Directrices

### Preparación de Datos

**1. Calidad de Datos sobre Cantidad**
- Prioriza ejemplos diversos y de alta calidad sobre grandes volúmenes de datos deficientes.
- Asegúrate de que los datos sean representativos de tu caso de uso objetivo.
- Limpia y preprocesa los datos de manera consistente.

**2. Formato de Datos y Plantillas**
- Usa un formato consistente en todos los ejemplos de entrenamiento.
- Crea plantillas claras de entrada-salida que coincidan con tu caso de uso.
- Incluye un formato de instrucciones adecuado para modelos ajustados por instrucción.

**3. División del Conjunto de Datos**
- Reserva el 10-20% de los datos para validación.
- Mantén distribuciones similares entre las divisiones de entrenamiento/validación.
- Considera el muestreo estratificado para tareas de clasificación.

### Configuración de Entrenamiento

**1. Selección de Tasa de Aprendizaje**
- Comienza con tasas de aprendizaje más pequeñas (1e-5 a 1e-4) para ajuste fino.
- Usa programación de tasa de aprendizaje para una mejor convergencia.
- Monitorea las curvas de pérdida para ajustar las tasas según sea necesario.

**2. Optimización del Tamaño de Lote**
- Equilibra el tamaño de lote con la memoria disponible.
- Usa acumulación de gradientes para tamaños de lote efectivos más grandes.
- Considera la relación entre tamaño de lote y tasa de aprendizaje.

**3. Duración del Entrenamiento**
- Monitorea métricas de validación para evitar sobreajuste.
- Usa detención temprana cuando el rendimiento de validación se estabilice.
- Guarda puntos de control regularmente para recuperación y análisis.

### Selección de Modelo

**1. Elección del Modelo Base**
- Selecciona modelos preentrenados en dominios similares cuando sea posible.
- Considera el tamaño del modelo en relación con tus limitaciones computacionales.
- Evalúa los requisitos de licencia para uso comercial.

**2. Selección del Método de Ajuste Fino**
- Usa LoRA/QLoRA para entornos con recursos limitados.
- Elige ajuste fino completo cuando el rendimiento máximo sea crítico.
- Considera enfoques basados en adaptadores para escenarios de múltiples tareas.

### Gestión de Recursos

**1. Optimización de Hardware**
- Elige hardware adecuado para el tamaño de tu modelo y método.
- Utiliza la memoria de GPU eficientemente con puntos de control de gradientes.
- Considera soluciones basadas en la nube para modelos más grandes.

**2. Gestión de Memoria**
- Usa entrenamiento de precisión mixta cuando esté disponible.
- Implementa acumulación de gradientes para limitaciones de memoria.
- Monitorea el uso de memoria de GPU durante el entrenamiento.

## Técnicas Avanzadas

### Entrenamiento Multi-Adaptador

Entrena múltiples adaptadores para diferentes tareas mientras compartes el modelo base:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optimización de Hiperparámetros

Implementa una optimización sistemática de hiperparámetros:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Funciones de Pérdida Personalizadas

Implementa funciones de pérdida específicas del dominio:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluación y Monitoreo

### Métricas y Evaluación

**1. Métricas Estándar**
- **Precisión**: Corrección general para tareas de clasificación.
- **Perplejidad**: Medida de calidad de modelado de lenguaje.
- **BLEU/ROUGE**: Calidad de generación de texto y resumen.
- **Puntuación F1**: Equilibrio entre precisión y recuperación para clasificación.

**2. Métricas Específicas del Dominio**
- **Benchmarks Específicos de Tarea**: Usa benchmarks establecidos para tu dominio.
- **Evaluación Humana**: Incluye evaluación humana para tareas subjetivas.
- **Métricas de Negocio**: Alinea con objetivos reales de negocio.

**3. Configuración de Evaluación**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitoreo del Progreso del Entrenamiento

**1. Seguimiento de Pérdidas**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Monitoreo de Validación**
- Rastrea la pérdida de validación junto con la pérdida de entrenamiento.
- Monitorea signos de sobreajuste (la pérdida de validación aumenta mientras la pérdida de entrenamiento disminuye).
- Usa detención temprana basada en métricas de validación.

**3. Monitoreo de Recursos**
- Monitorea la utilización de GPU/CPU.
- Rastrea patrones de uso de memoria.
- Monitorea la velocidad y el rendimiento del entrenamiento.

## Desafíos Comunes y Soluciones

### Desafío 1: Sobreajuste

**Síntomas:**
- La pérdida de entrenamiento sigue disminuyendo mientras la pérdida de validación aumenta.
- Gran diferencia entre el rendimiento de entrenamiento y validación.
- Mala generalización a nuevos datos.

**Soluciones:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Desafío 2: Limitaciones de Memoria

**Soluciones:**
- Usa puntos de control de gradientes.
- Implementa acumulación de gradientes.
- Elige métodos eficientes en parámetros (LoRA, QLoRA).
- Utiliza paralelismo de modelos para modelos grandes.

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Desafío 3: Entrenamiento Lento

**Soluciones:**
- Optimiza las canalizaciones de carga de datos.
- Usa entrenamiento de precisión mixta.
- Implementa estrategias de agrupamiento eficientes.
- Considera entrenamiento distribuido para conjuntos de datos grandes.

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Desafío 4: Rendimiento Deficiente

**Pasos de Diagnóstico:**
1. Verifica la calidad y el formato de los datos.
2. Revisa la tasa de aprendizaje y la duración del entrenamiento.
3. Evalúa la elección del modelo base.
4. Revisa el preprocesamiento y la tokenización.

**Soluciones:**
- Aumenta la diversidad de datos de entrenamiento.
- Ajusta la programación de la tasa de aprendizaje.
- Prueba diferentes modelos base.
- Implementa técnicas de aumento de datos.

## Conclusión

El ajuste fino es una técnica poderosa que democratiza el acceso a capacidades de IA de última generación. Al aprovechar herramientas como Microsoft Olive, las organizaciones pueden adaptar eficientemente modelos preentrenados a sus necesidades específicas mientras optimizan el rendimiento y los recursos.

### Puntos Clave

1. **Elige el Enfoque Correcto**: Selecciona métodos de ajuste fino según tus recursos computacionales y requisitos de rendimiento.
2. **La Calidad de los Datos Importa**: Invierte en datos de entrenamiento representativos y de alta calidad.
3. **Monitorea e Itera**: Evalúa y mejora continuamente tus modelos.
4. **Aprovecha las Herramientas**: Usa frameworks como Olive para simplificar y optimizar el proceso.
5. **Considera el Despliegue**: Planifica la optimización y el despliegue del modelo desde el principio.

## ➡️ ¿Qué sigue?

- [04: Despliegue - Implementación de Modelos Listos para Producción](./04.SLMOps.Deployment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisión, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que puedan surgir del uso de esta traducción.