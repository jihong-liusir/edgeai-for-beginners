<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-17T13:03:26+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "es"
}
-->
# Sección02: Llamadas a Funciones en Modelos de Lenguaje Pequeños (SLMs)

## Tabla de Contenidos
1. [¿Qué es la Llamada a Funciones?](../../../Module06)
2. [Cómo Funciona la Llamada a Funciones](../../../Module06)
3. [Escenarios de Aplicación](../../../Module06)
4. [Configuración de Llamadas a Funciones con Phi-4-mini y Ollama](../../../Module06)
5. [Trabajando con Llamadas a Funciones de Qwen3](../../../Module06)
6. [Integración Local de Foundry](../../../Module06)
7. [Mejores Prácticas y Resolución de Problemas](../../../Module06)
8. [Ejemplos Avanzados](../../../Module06)

## ¿Qué es la Llamada a Funciones?

La llamada a funciones es una capacidad poderosa que permite a los Modelos de Lenguaje Pequeños (SLMs) interactuar con herramientas externas, APIs y servicios. En lugar de estar limitados a sus datos de entrenamiento, los SLMs ahora pueden:

- **Conectarse a APIs externas** (servicios meteorológicos, bases de datos, motores de búsqueda)
- **Ejecutar funciones específicas** basadas en solicitudes de los usuarios
- **Obtener información en tiempo real** de diversas fuentes
- **Realizar tareas computacionales** mediante herramientas especializadas
- **Encadenar múltiples operaciones** para flujos de trabajo complejos

Esta capacidad transforma a los SLMs de generadores de texto estáticos en agentes de IA dinámicos que pueden realizar tareas del mundo real.

## Cómo Funciona la Llamada a Funciones

El proceso de llamada a funciones sigue un flujo de trabajo sistemático:

### 1. Integración de Herramientas
- **Herramientas Externas**: Los SLMs pueden conectarse a APIs meteorológicas, bases de datos, servicios web y otros sistemas externos.
- **Definiciones de Funciones**: Cada herramienta se define con parámetros específicos, formatos de entrada/salida y descripciones.
- **Compatibilidad con APIs**: Las herramientas se integran mediante interfaces estandarizadas (APIs REST, SDKs, etc.).

### 2. Definición de Funciones
Las funciones se definen con tres componentes clave:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Detección de Intención
- **Procesamiento de Lenguaje Natural**: El SLM analiza la entrada del usuario para entender la intención.
- **Coincidencia de Funciones**: Determina qué función(es) son necesarias para cumplir con la solicitud.
- **Extracción de Parámetros**: Identifica y extrae los parámetros requeridos del mensaje del usuario.

### 4. Generación de Salida JSON
El SLM genera un JSON estructurado que contiene:
- Nombre de la función a llamar
- Parámetros requeridos con valores apropiados
- Contexto de ejecución y metadatos

### 5. Ejecución Externa
- **Validación de Parámetros**: Asegura que todos los parámetros requeridos estén presentes y correctamente formateados.
- **Ejecución de la Función**: La aplicación ejecuta la función especificada con los parámetros proporcionados.
- **Manejo de Errores**: Gestiona fallos, tiempos de espera y respuestas inválidas.

### 6. Integración de Respuesta
- **Procesamiento de Resultados**: La salida de la función se devuelve al SLM.
- **Integración de Contexto**: El SLM incorpora los resultados en su respuesta.
- **Comunicación con el Usuario**: Presenta la información en un formato natural y conversacional.

## Escenarios de Aplicación

### Recuperación de Datos
Convierte consultas en lenguaje natural en llamadas estructuradas a APIs:
- **"Muestra mis pedidos recientes"** → Consulta a base de datos con ID de usuario y filtros de fecha.
- **"¿Cuál es el clima en Tokio?"** → Llamada a API meteorológica con parámetro de ubicación.
- **"Encuentra correos de John la semana pasada"** → Consulta a servicio de correo con remitente y filtros de fecha.

### Ejecución de Operaciones
Transforma solicitudes de usuarios en llamadas a funciones específicas:
- **"Programa una reunión para mañana a las 2 PM"** → Integración con API de calendario.
- **"Envía un mensaje al equipo"** → API de plataforma de comunicación.
- **"Crea una copia de seguridad de mis archivos"** → Operación del sistema de archivos.

### Tareas Computacionales
Maneja operaciones matemáticas o lógicas complejas:
- **"Calcula el interés compuesto de $10,000 al 5% durante 10 años"** → Función de cálculo financiero.
- **"Analiza este conjunto de datos para tendencias"** → Herramientas de análisis estadístico.
- **"Optimiza esta ruta para entrega"** → Algoritmos de optimización de rutas.

### Flujos de Trabajo de Procesamiento de Datos
Encadena múltiples llamadas a funciones para operaciones complejas:
1. **Recuperar datos** de múltiples fuentes.
2. **Analizar y validar** la información.
3. **Transformar** los datos al formato requerido.
4. **Almacenar resultados** en sistemas apropiados.
5. **Generar informes** o visualizaciones.

### Integración UI/UX
Permite actualizaciones dinámicas de interfaces:
- **"Muestra datos de ventas en el tablero"** → Generación y visualización de gráficos.
- **"Actualiza el mapa con nuevas ubicaciones"** → Integración de datos geoespaciales.
- **"Refresca la visualización de inventario"** → Sincronización de datos en tiempo real.

## Configuración de Llamadas a Funciones con Phi-4-mini y Ollama

Phi-4-mini de Microsoft admite llamadas a funciones individuales y paralelas mediante Ollama. Aquí se explica cómo configurarlo:

### Requisitos Previos
- Versión 0.5.13 o superior de Ollama.
- Modelo Phi-4-mini (recomendado: `phi4-mini:3.8b-fp16`).

### Pasos de Instalación

#### 1. Instalar y Ejecutar Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Crear Plantilla de ModelFile Personalizada
Debido a limitaciones actuales en las plantillas predeterminadas de Ollama, necesitas crear un ModelFile personalizado con la siguiente plantilla:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Crear el Modelo Personalizado
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Ejemplo de Llamada a Función Individual

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Ejemplo de Llamada a Funciones Paralelas

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Trabajando con Llamadas a Funciones de Qwen3

Qwen3 ofrece capacidades avanzadas de llamadas a funciones con excelente rendimiento y flexibilidad. Aquí se explica cómo implementarlo:

### Usando el Framework Qwen-Agent

Qwen-Agent proporciona un framework de alto nivel que simplifica la implementación de llamadas a funciones:

#### Instalación
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Configuración Básica

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Implementación de Funciones Personalizadas

También puedes definir funciones personalizadas para Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Funciones Avanzadas de Qwen3

#### Control de Modo de Pensamiento
Qwen3 admite cambios dinámicos entre modos de pensamiento y no pensamiento:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Llamadas a Funciones en Múltiples Pasos
Qwen3 sobresale en el encadenamiento de múltiples llamadas a funciones:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Integración Local de Foundry

Foundry Local de Microsoft proporciona una API compatible con OpenAI para ejecutar modelos localmente con mayor privacidad y rendimiento.

### Configuración e Instalación

#### Windows
Descarga el instalador desde la [página de lanzamientos de Foundry Local](https://github.com/microsoft/Foundry-Local/releases) y sigue las instrucciones de instalación.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Uso Básico

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Funciones Avanzadas de Foundry Local

#### Gestión de Modelos
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Optimización de Rendimiento
Foundry Local selecciona automáticamente la mejor variante de modelo para tu hardware:
- **GPU CUDA**: Descarga modelos optimizados para GPU.
- **NPU Qualcomm**: Utiliza variantes aceleradas por NPU.
- **Solo CPU**: Selecciona modelos optimizados para CPU.

## Mejores Prácticas y Resolución de Problemas

### Mejores Prácticas para Definición de Funciones

#### 1. Nombres Claros y Descriptivos
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Definiciones de Parámetros Exhaustivas
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Validación de Entrada y Manejo de Errores
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Problemas Comunes y Soluciones

#### Problema 1: La Función No Se Llama
**Síntomas**: El modelo responde con texto en lugar de llamar a la función.

**Soluciones**:
1. **Revisar descripción de la función**: Asegúrate de que coincida claramente con la intención del usuario.
2. **Verificar definiciones de parámetros**: Asegúrate de que todos los parámetros requeridos estén correctamente definidos.
3. **Revisar el mensaje del sistema**: Incluye instrucciones claras sobre cuándo usar funciones.
4. **Prueba con solicitudes explícitas**: Intenta "Por favor usa la función meteorológica para obtener datos de Londres".

#### Problema 2: Parámetros Incorrectos
**Síntomas**: La función se llama con parámetros incorrectos o faltantes.

**Soluciones**:
1. **Agregar ejemplos de parámetros**: Incluye valores de muestra en las descripciones de parámetros.
2. **Usar restricciones de enumeración**: Limita los valores de parámetros a opciones específicas cuando sea posible.
3. **Implementar valores predeterminados**: Proporciona valores predeterminados razonables para parámetros opcionales.

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Problema 3: Fallos en Llamadas Paralelas a Funciones
**Síntomas**: Solo se ejecuta una función cuando deberían ejecutarse múltiples.

**Soluciones**:
1. **Verificar soporte del modelo**: Asegúrate de que tu modelo admite llamadas paralelas a funciones.
2. **Actualizar mensaje del sistema**: Incluye "algunas herramientas" o "múltiples herramientas" en el mensaje del sistema.
3. **Usar versiones apropiadas del modelo**: Se recomienda Phi-4-mini:3.8b-fp16 para Ollama.

#### Problema 4: Problemas de Plantilla con Ollama
**Síntomas**: Las llamadas a funciones no funcionan con la configuración predeterminada de Ollama.

**Soluciones**:
1. **Usar ModelFile personalizado**: Aplica la plantilla corregida proporcionada en este tutorial.
2. **Actualizar Ollama**: Asegúrate de usar la versión 0.5.13 o superior.
3. **Revisar la cuantización del modelo**: Los niveles de cuantización más altos (Q8_0, fp16) funcionan mejor que las versiones altamente cuantizadas.

### Optimización de Rendimiento

#### 1. Diseño Eficiente de Funciones
- **Mantén las funciones enfocadas**: Cada función debe tener un propósito único y claro.
- **Minimiza dependencias externas**: Reduce llamadas a APIs y solicitudes de red cuando sea posible.
- **Cachea resultados**: Almacena datos solicitados frecuentemente para mejorar los tiempos de respuesta.

#### 2. Operaciones en Lote y Asíncronas
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Gestión de Recursos
- **Agrupación de conexiones**: Reutiliza conexiones a bases de datos y APIs.
- **Limitación de tasa**: Implementa una limitación de tasa adecuada para APIs externas.
- **Manejo de tiempos de espera**: Establece tiempos de espera razonables para todas las llamadas externas.

## Ejemplos Avanzados

### Sistema de Colaboración Multi-Agente

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Sistema de Selección Dinámica de Herramientas

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Formato estándar de resultados para todas las llamadas a funciones"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Agente de IA listo para producción con capacidades completas de llamadas a funciones"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Inicializar funciones principales de negocio
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Registrar todas las funciones de negocio disponibles"""
        
        # Funciones de CRM
        self.register_function(
            name="get_customer_info",
            description="Recuperar información del cliente desde el CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # llamadas por minuto
        )
        
        # Funciones de Ventas
        self.register_function(
            name="create_sales_opportunity",
            description="Crear una nueva oportunidad de ventas",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Funciones de Análisis
        self.register_function(
            name="generate_sales_report",
            description="Generar informe de rendimiento de ventas",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Funciones de Notificación
        self.register_function(
            name="send_notification",
            description="Enviar notificación a miembros del equipo",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Registrar una nueva función con el agente"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Lo siento, no puedo realizar esta tarea.
"""Ejecutar una función con manejo de errores completo y registro"""
start_time = datetime.now()

try:
    # Validar que la función existe
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"No se encontró la función '{function_name}'",
            timestamp=start_time
        )
    
    # Verificar límites de uso
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Se excedió el límite de uso para la función '{function_name}'",
            timestamp=start_time
        )
    
    # Validar parámetros
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Ejecutar la función
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Registrar ejecución exitosa
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Registrar ejecución fallida
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Verificar si la llamada a la función está dentro de los límites de uso"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Reiniciar contador si ha pasado un minuto
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Verificar si está dentro del límite
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Validar parámetros de la función"""
    func_params = self.functions[function_name]['parameters']
    
    # Verificar parámetros requeridos
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Falta el parámetro requerido: {param_name}"
            )
    
    # Validar tipos y restricciones de parámetros
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Validación de tipo
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"El parámetro '{param_name}' debe ser una cadena de texto"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"El parámetro '{param_name}' debe ser un número"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"El parámetro '{param_name}' debe ser un valor booleano"
                )
            
            # Validación de enumeración
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"El parámetro '{param_name}' debe ser uno de: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Registrar llamada a la función para propósitos de auditoría"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Opcionalmente escribir en un sistema de registro externo
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Escribir entrada de registro en un sistema de registro externo"""
    # La implementación dependería de tu infraestructura de registro
    # Por ejemplo, enviar a ELK stack, CloudWatch, etc.
    pass

# Implementaciones de funciones empresariales
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Obtener información del cliente desde el sistema CRM"""
    # Simular llamada a base de datos/API
    await asyncio.sleep(0.1)  # Simular retraso de red
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Producto A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Producto B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                    estimated_value: float, expected_close_date: str) -> Dict:
    """Crear una nueva oportunidad de ventas"""
    # Simular llamada a API de CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                                 product_category: str = None) -> Dict:
    """Generar un informe de ventas completo"""
    # Simular agregación de datos
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                             priority: str = 'medium', channel: str = 'email') -> Dict:
    """Enviar notificación a través del canal especificado"""
    # Simular llamada al servicio de notificaciones
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Obtener definiciones de funciones compatibles con OpenAI para todas las funciones registradas"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Ejemplo de uso para integración empresarial
async def enterprise_demo():
    """Demostrar capacidades del agente de IA empresarial"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Ejemplo 1: Procesamiento de consultas de clientes
    print("=== Procesamiento de consultas de clientes ===")
    
    # Obtener información del cliente
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Información del cliente obtenida: {result.data['name']}")
        print(f"Tiempo de ejecución: {result.execution_time:.3f}s")
    
    # Ejemplo 2: Creación de oportunidad de ventas
    print("\n=== Creación de oportunidad de ventas ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Oportunidad creada: {result.data['opportunity_id']}")
    
    # Ejemplo 3: Operaciones en lote
    print("\n=== Operaciones en lote ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Nueva oportunidad creada',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Tarea {i+1} completada exitosamente")
        else:
            print(f"Tarea {i+1} fallida: {result.error}")
    
    # Mostrar registro de auditoría
    print(f"\n=== Registro de auditoría ({len(agent.audit_log)} entradas) ===")
    for entry in agent.audit_log[-3:]:  # Mostrar las últimas 3 entradas
        print(f"{entry['timestamp']}: {entry['function_name']} - {'ÉXITO' if entry['success'] else 'FALLÓ'}")

# Ejecutar la demostración empresarial
# asyncio.run(enterprise_demo())

## Conclusión

La llamada a funciones en Small Language Models representa un cambio de paradigma, pasando de asistentes de IA estáticos a agentes dinámicos y capaces de interactuar con el mundo real. Este tutorial ha cubierto:

### Puntos clave

1. **Comprensión básica**: La llamada a funciones permite que los SLMs se extiendan más allá de sus datos de entrenamiento al conectarse con herramientas y servicios externos.

2. **Flexibilidad de implementación**: Existen múltiples enfoques, desde implementaciones de bajo nivel con plantillas personalizadas hasta marcos avanzados como Qwen-Agent y Foundry Local.

3. **Consideraciones para producción**: Los despliegues empresariales requieren atención al manejo de errores, límites de uso, seguridad y registro de auditoría.

4. **Optimización de rendimiento**: Un diseño adecuado de funciones, ejecución eficiente y almacenamiento en caché inteligente pueden mejorar significativamente los tiempos de respuesta.

### Direcciones futuras

A medida que la tecnología SLM continúe evolucionando, podemos esperar:

- **Mayor precisión en la llamada a funciones**: Mejor detección de intenciones y extracción de parámetros
- **Procesamiento paralelo mejorado**: Orquestación más sofisticada de múltiples funciones
- **Estándares de integración mejorados**: Protocolos estandarizados para la integración de herramientas
- **Funciones de seguridad avanzadas**: Mecanismos mejorados de autenticación y autorización
- **Ecosistema ampliado**: Creciente biblioteca de funciones e integraciones preconstruidas

### Primeros pasos

Para comenzar a implementar la llamada a funciones en tus proyectos:

1. **Comienza simple**: Inicia con escenarios básicos de una sola función
2. **Elige tu marco**: Selecciona entre implementación directa (Ollama/Phi-4) o asistida por marco (Qwen-Agent)
3. **Diseña funciones cuidadosamente**: Enfócate en definiciones de funciones claras y bien documentadas
4. **Implementa manejo de errores**: Construye un manejo de errores robusto desde el principio
5. **Escala gradualmente**: Avanza de escenarios simples a complejos a medida que adquieras experiencia

La llamada a funciones transforma a los SLMs de generadores de texto impresionantes en agentes de IA prácticos capaces de resolver problemas del mundo real. Siguiendo los patrones y prácticas descritos en este tutorial, puedes construir sistemas de IA poderosos y confiables que van más allá de las interfaces de chat tradicionales.

### Recursos y referencias
- **Modelos Phi-4**: [Colección de Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Documentación de Qwen3**: [Documentación oficial de Qwen](https://qwen.readthedocs.io/)
- **Ollama**: [Sitio web oficial](https://ollama.com/)
- **Foundry Local**: [Repositorio de GitHub](https://github.com/microsoft/Foundry-Local)
- **Mejores prácticas para llamadas a funciones**: [Guía de Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)

Recuerda que las llamadas a funciones son un campo en constante evolución, y mantenerse al día con los últimos desarrollos en los marcos y modelos que elijas te ayudará a construir agentes de IA más efectivos.


## ➡️ ¿Qué sigue?

- [03: Integración del Protocolo de Contexto del Modelo (MCP)](./03.IntroduceMCP.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisión, tenga en cuenta que las traducciones automáticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que puedan surgir del uso de esta traducción.