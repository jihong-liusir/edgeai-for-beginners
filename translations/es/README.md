<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a189d7d9d47816a518ca119d79dc19b",
  "translation_date": "2025-09-22T12:38:45+00:00",
  "source_file": "README.md",
  "language_code": "es"
}
-->
# EdgeAI para Principiantes

![Imagen de portada del curso](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.es.png)

[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![GitHub issues](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![GitHub forks](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![GitHub stars](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Sigue estos pasos para comenzar a usar estos recursos:

1. **Haz un Fork del Repositorio**: Haz clic en [![GitHub forks](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Clona el Repositorio**: `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Únete al Discord de Azure AI Foundry y conecta con expertos y otros desarrolladores**](https://discord.com/invite/ByRwuEEgH4)  

### 🌐 Soporte Multilingüe

#### Disponible a través de GitHub Action (Automatizado y Siempre Actualizado)

[Árabe](../ar/README.md) | [Bengalí](../bn/README.md) | [Búlgaro](../bg/README.md) | [Birmano (Myanmar)](../my/README.md) | [Chino (Simplificado)](../zh/README.md) | [Chino (Tradicional, Hong Kong)](../hk/README.md) | [Chino (Tradicional, Macao)](../mo/README.md) | [Chino (Tradicional, Taiwán)](../tw/README.md) | [Croata](../hr/README.md) | [Checo](../cs/README.md) | [Danés](../da/README.md) | [Holandés](../nl/README.md) | [Finlandés](../fi/README.md) | [Francés](../fr/README.md) | [Alemán](../de/README.md) | [Griego](../el/README.md) | [Hebreo](../he/README.md) | [Hindi](../hi/README.md) | [Húngaro](../hu/README.md) | [Indonesio](../id/README.md) | [Italiano](../it/README.md) | [Japonés](../ja/README.md) | [Coreano](../ko/README.md) | [Malayo](../ms/README.md) | [Maratí](../mr/README.md) | [Nepalí](../ne/README.md) | [Noruego](../no/README.md) | [Persa (Farsi)](../fa/README.md) | [Polaco](../pl/README.md) | [Portugués (Brasil)](../br/README.md) | [Portugués (Portugal)](../pt/README.md) | [Punyabí (Gurmukhi)](../pa/README.md) | [Rumano](../ro/README.md) | [Ruso](../ru/README.md) | [Serbio (Cirílico)](../sr/README.md) | [Eslovaco](../sk/README.md) | [Esloveno](../sl/README.md) | [Español](./README.md) | [Swahili](../sw/README.md) | [Sueco](../sv/README.md) | [Tagalo (Filipino)](../tl/README.md) | [Tailandés](../th/README.md) | [Turco](../tr/README.md) | [Ucraniano](../uk/README.md) | [Urdu](../ur/README.md) | [Vietnamita](../vi/README.md)

**Si deseas que se admitan idiomas adicionales, consulta la lista [aquí](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Introducción

Bienvenido a **EdgeAI para Principiantes**: tu guía completa para explorar el mundo transformador de la Inteligencia Artificial en el borde. Este curso conecta las capacidades avanzadas de la IA con su implementación práctica en dispositivos de borde, permitiéndote aprovechar el potencial de la IA directamente donde se generan los datos y se toman las decisiones.

### Lo que Aprenderás

Este curso te llevará desde los conceptos fundamentales hasta implementaciones listas para producción, cubriendo:
- **Modelos de Lenguaje Pequeños (SLMs)** optimizados para despliegue en el borde
- **Optimización basada en hardware** para diversas plataformas
- **Inferencia en tiempo real** con capacidades de preservación de la privacidad
- **Estrategias de despliegue en producción** para aplicaciones empresariales

### Por qué es Importante EdgeAI

Edge AI representa un cambio de paradigma que aborda desafíos modernos críticos:
- **Privacidad y Seguridad**: Procesa datos sensibles localmente sin exponerlos a la nube
- **Rendimiento en Tiempo Real**: Elimina la latencia de red para aplicaciones críticas
- **Eficiencia de Costos**: Reduce el uso de ancho de banda y los gastos de computación en la nube
- **Operaciones Resilientes**: Mantén la funcionalidad durante interrupciones de red
- **Cumplimiento Normativo**: Cumple con los requisitos de soberanía de datos

### Edge AI

Edge AI se refiere a ejecutar algoritmos de IA y modelos de lenguaje localmente en hardware, cerca de donde se generan los datos, sin depender de recursos en la nube para la inferencia. Esto reduce la latencia, mejora la privacidad y permite la toma de decisiones en tiempo real.

### Principios Fundamentales:
- **Inferencia en el dispositivo**: Los modelos de IA se ejecutan en dispositivos de borde (teléfonos, routers, microcontroladores, PCs industriales)
- **Capacidad offline**: Funciona sin conexión a internet persistente
- **Baja latencia**: Respuestas inmediatas adecuadas para sistemas en tiempo real
- **Soberanía de datos**: Mantiene los datos sensibles localmente, mejorando la seguridad y el cumplimiento

### Modelos de Lenguaje Pequeños (SLMs)

Los SLMs como Phi-4, Mistral-7B y Gemma son versiones optimizadas de modelos de lenguaje grandes, entrenados o destilados para:
- **Menor uso de memoria**: Uso eficiente de la memoria limitada de los dispositivos de borde
- **Menor demanda de computación**: Optimización para rendimiento en CPU y GPU de borde
- **Inicio más rápido**: Inicialización rápida para aplicaciones receptivas

Estos modelos desbloquean capacidades avanzadas de procesamiento de lenguaje natural mientras cumplen con las restricciones de:
- **Sistemas embebidos**: Dispositivos IoT y controladores industriales
- **Dispositivos móviles**: Smartphones y tablets con capacidades offline
- **Dispositivos IoT**: Sensores y dispositivos inteligentes con recursos limitados
- **Servidores de borde**: Unidades de procesamiento local con recursos GPU limitados
- **Computadoras personales**: Escenarios de despliegue en desktops y laptops

## Arquitectura del Curso

### [Módulo 01: Fundamentos y Transformación de EdgeAI](./Module01/README.md)
**Tema**: El cambio transformador del despliegue de IA en el borde

#### Estructura del Capítulo:
- [**Sección 1: Fundamentos de EdgeAI**](./Module01/01.EdgeAIFundamentals.md)
  - Comparación entre IA en la nube tradicional y IA en el borde
  - Desafíos y limitaciones del edge computing
  - Tecnologías clave: cuantización de modelos, optimización por compresión, Modelos de Lenguaje Pequeños (SLMs)
  - Aceleración por hardware: NPUs, optimización de GPU, optimización de CPU
  - Ventajas: seguridad de privacidad, baja latencia, capacidades offline, eficiencia de costos

- [**Sección 2: Estudios de Caso del Mundo Real**](./Module01/02.RealWorldCaseStudies.md)
  - Ecosistema de modelos Phi y Mu de Microsoft
  - Estudio de caso del sistema de informes de IA de Japan Airlines
  - Impacto en el mercado y direcciones futuras
  - Consideraciones y mejores prácticas de despliegue

- [**Sección 3: Guía Práctica de Implementación**](./Module01/03.PracticalImplementationGuide.md)
  - Configuración del entorno de desarrollo (Python 3.10+, .NET 8+)
  - Requisitos de hardware y configuraciones recomendadas
  - Recursos de la familia de modelos principales
  - Herramientas de cuantización y optimización (Llama.cpp, Microsoft Olive, Apple MLX)
  - Lista de verificación de evaluación y verificación

- [**Sección 4: Plataformas de Hardware para Despliegue de Edge AI**](./Module01/04.EdgeDeployment.md)
  - Consideraciones y requisitos para el despliegue de Edge AI
  - Hardware de Edge AI de Intel y técnicas de optimización
  - Soluciones de Qualcomm para sistemas móviles y embebidos
  - NVIDIA Jetson y plataformas de computación en el borde
  - Plataformas de PC con Windows AI con aceleración NPU
  - Estrategias de optimización específicas para hardware

---

### [Módulo 02: Fundamentos de Modelos de Lenguaje Pequeños](./Module02/README.md)
**Tema**: Principios teóricos de SLM, estrategias de implementación y despliegue en producción

#### Estructura del Capítulo:
- [**Sección 1: Fundamentos de la Familia de Modelos Phi de Microsoft**](./Module02/01.PhiFamily.md)
  - Evolución de la filosofía de diseño (Phi-1 a Phi-4)
  - Diseño de arquitectura centrado en la eficiencia
  - Capacidades especializadas (razonamiento, multimodal, despliegue en el borde)

- [**Sección 2: Fundamentos de la Familia Qwen**](./Module02/02.QwenFamily.md)
  - Excelencia de código abierto (Qwen 1.0 a Qwen3) - disponible en Hugging Face
  - Arquitectura avanzada de razonamiento con capacidades de modo de pensamiento
  - Opciones de despliegue escalables (0.5B-235B parámetros)

- [**Sección 3: Fundamentos de la Familia Gemma**](./Module02/03.GemmaFamily.md)
  - Innovación impulsada por la investigación (Gemma 3 y 3n)
  - Excelencia multimodal
  - Arquitectura centrada en dispositivos móviles

- [**Sección 4: Fundamentos de la Familia BitNET**](./Module02/04.BitNETFamily.md)
  - Tecnología revolucionaria de cuantización (1.58-bit)
  - Marco de inferencia especializado desde https://github.com/microsoft/BitNet
  - Liderazgo en IA sostenible a través de eficiencia extrema

- [**Sección 5: Fundamentos del Modelo Mu de Microsoft**](./Module02/05.mumodel.md)
  - Arquitectura centrada en dispositivos integrada en Windows 11
  - Integración del sistema con Configuración de Windows 11
  - Operación offline que preserva la privacidad

- [**Sección 6: Fundamentos de Phi-Silica**](./Module02/06.phisilica.md)
  - Arquitectura optimizada para NPU integrada en PCs con Windows 11 Copilot+
  - Eficiencia excepcional (650 tokens/segundo a 1.5W)
  - Integración para desarrolladores con Windows App SDK

---

### [Módulo 03: Despliegue de Modelos de Lenguaje Pequeños](./Module03/README.md)
**Tema**: Ciclo completo de despliegue de SLM, desde la teoría hasta el entorno de producción

#### Estructura del Capítulo:
- [**Sección 1: Aprendizaje Avanzado de SLM**](./Module03/01.SLMAdvancedLearning.md)
  - Marco de clasificación de parámetros (Micro SLM 100M-1.4B, Medium SLM 14B-30B)
  - Técnicas avanzadas de optimización (métodos de cuantización, cuantización de 1-bit BitNET)
  - Estrategias de adquisición de modelos (Azure AI Foundry para modelos Phi, Hugging Face para modelos seleccionados)

- [**Sección 2: Despliegue en Entorno Local**](./Module03/02.DeployingSLMinLocalEnv.md)
  - Despliegue universal en la plataforma Ollama
  - Soluciones locales de nivel empresarial de Microsoft Foundry
  - Análisis comparativo de frameworks

- [**Sección 3: Despliegue en la Nube con Contenedores**](./Module03/03.DeployingSLMinCloud.md)
  - Despliegue de inferencia de alto rendimiento con vLLM
  - Orquestación de contenedores Ollama
  - Implementación optimizada para el borde con ONNX Runtime

---

### [Módulo 04: Conversión de Formato de Modelos y Cuantización](./Module04/README.md)
**Tema**: Kit completo de herramientas de optimización de modelos para despliegue en el borde en diversas plataformas

#### Estructura del Capítulo:
- [**Sección 1: Fundamentos de Conversión de Formato de Modelos y Cuantización**](./Module04/01.Introduce.md)
  - Marco de clasificación de precisión (ultra-baja, baja, media precisión)
  - Ventajas y casos de uso de los formatos GGUF y ONNX
  - Beneficios de la cuantización para la eficiencia operativa
  - Comparaciones de rendimiento y uso de memoria
- [**Sección 2: Guía de Implementación de Llama.cpp**](./Module04/02.Llamacpp.md)
  - Instalación multiplataforma (Windows, macOS, Linux)
  - Conversión al formato GGUF y niveles de cuantización (Q2_K a Q8_0)
  - Aceleración por hardware (CUDA, Metal, OpenCL, Vulkan)
  - Integración con Python y despliegue de API REST

- [**Sección 3: Suite de Optimización Microsoft Olive**](./Module04/03.MicrosoftOlive.md)
  - Optimización de modelos basada en hardware con más de 40 componentes integrados
  - Auto-optimización con cuantización dinámica y estática
  - Integración empresarial con flujos de trabajo de Azure ML
  - Soporte para modelos populares (Llama, Phi, modelos seleccionados de Qwen, Gemma)

- [**Sección 4: Suite de Optimización OpenVINO Toolkit**](./Module04/04.openvino.md)
  - Herramienta de código abierto de Intel para despliegue de IA multiplataforma
  - Marco de Compresión de Redes Neuronales (NNCF) para optimización avanzada
  - OpenVINO GenAI para despliegue de modelos de lenguaje a gran escala
  - Aceleración por hardware en CPU, GPU, VPU y aceleradores de IA

- [**Sección 5: Análisis Profundo del Marco Apple MLX**](./Module04/05.AppleMLX.md)
  - Arquitectura de memoria unificada para Apple Silicon
  - Soporte para LLaMA, Mistral, Phi, modelos seleccionados de Qwen
  - Ajuste fino LoRA y personalización de modelos
  - Integración con Hugging Face y cuantización de 4 bits/8 bits

- [**Sección 6: Síntesis del Flujo de Trabajo de Desarrollo de Edge AI**](./Module04/06.workflow-synthesis.md)
  - Arquitectura de flujo de trabajo unificado que integra múltiples marcos de optimización
  - Árboles de decisión para selección de marcos y análisis de compensaciones de rendimiento
  - Validación de preparación para producción y estrategias de despliegue completas
  - Estrategias para garantizar compatibilidad con hardware y arquitecturas de modelos emergentes

---

### [Módulo 05: SLMOps - Operaciones con Modelos de Lenguaje Pequeños](./Module05/README.md)
**Tema**: Operaciones completas del ciclo de vida de SLM, desde la destilación hasta el despliegue en producción

#### Estructura del Capítulo:
- [**Sección 1: Introducción a SLMOps**](./Module05/01.IntroduceSLMOps.md)
  - Cambio de paradigma de SLMOps en operaciones de IA
  - Eficiencia de costos y arquitectura centrada en la privacidad
  - Impacto estratégico en los negocios y ventajas competitivas
  - Desafíos y soluciones en implementaciones reales

- [**Sección 2: Destilación de Modelos - De la Teoría a la Práctica**](./Module05/02.SLMOps-Distillation.md)
  - Transferencia de conocimiento de modelos maestros a modelos estudiantes
  - Implementación del proceso de destilación en dos etapas
  - Flujos de trabajo de destilación en Azure ML con ejemplos prácticos
  - Reducción del tiempo de inferencia en un 85% con retención del 92% de precisión

- [**Sección 3: Ajuste Fino - Personalización de Modelos para Tareas Específicas**](./Module05/03.SLMOps-Finetuing.md)
  - Técnicas de ajuste fino eficientes en parámetros (PEFT)
  - Métodos avanzados como LoRA y QLoRA
  - Implementación de ajuste fino con Microsoft Olive
  - Entrenamiento multi-adaptador y optimización de hiperparámetros

- [**Sección 4: Despliegue - Implementación Lista para Producción**](./Module05/04.SLMOps.Deployment.md)
  - Conversión y cuantización de modelos para producción
  - Configuración de despliegue local con Foundry Local
  - Evaluación de rendimiento y validación de calidad
  - Reducción del tamaño en un 75% con monitoreo en producción

---

### [Módulo 06: Sistemas Agénticos SLM - Agentes de IA y Llamadas a Funciones](./Module06/README.md)
**Tema**: Implementación de sistemas agénticos SLM desde los fundamentos hasta llamadas avanzadas a funciones e integración del Protocolo de Contexto del Modelo (MCP)

#### Estructura del Capítulo:
- [**Sección 1: Fundamentos de Agentes de IA y Modelos de Lenguaje Pequeños**](./Module06/01.IntroduceAgent.md)
  - Marco de clasificación de agentes (reflejo, basado en modelos, basado en objetivos, agentes de aprendizaje)
  - Fundamentos de SLM y estrategias de optimización (GGUF, cuantización, marcos de trabajo en el borde)
  - Análisis de compensaciones entre SLM y LLM (reducción de costos de 10-30×, efectividad del 70-80% en tareas)
  - Despliegue práctico con Ollama, VLLM y soluciones de Microsoft para el borde

- [**Sección 2: Llamadas a Funciones en Modelos de Lenguaje Pequeños**](./Module06/02.FunctionCalling.md)
  - Implementación sistemática del flujo de trabajo (detección de intención, salida JSON, ejecución externa)
  - Implementaciones específicas de plataformas (Phi-4-mini, modelos seleccionados de Qwen, Microsoft Foundry Local)
  - Ejemplos avanzados (colaboración multi-agente, selección dinámica de herramientas)
  - Consideraciones para producción (limitación de tasas, registro de auditorías, medidas de seguridad)

- [**Sección 3: Integración del Protocolo de Contexto del Modelo (MCP)**](./Module06/03.IntroduceMCP.md)
  - Arquitectura del protocolo y diseño de sistema por capas
  - Soporte para múltiples backends (Ollama para desarrollo, vLLM para producción)
  - Protocolos de conexión (modos STDIO y SSE)
  - Aplicaciones reales (automatización web, procesamiento de datos, integración de API)

---

### [Módulo 07: Ejemplos de Implementación de EdgeAI](./Module07/README.md)
**Tema**: Implementaciones completas de EdgeAI en diversas plataformas y marcos de trabajo

#### Estructura del Capítulo:
- [**Herramienta de IA para Visual Studio Code**](./Module07/aitoolkit.md)
  - Entorno de desarrollo completo de Edge AI dentro de VS Code
  - Catálogo y descubrimiento de modelos para despliegue en el borde
  - Flujos de trabajo de prueba local, optimización y desarrollo de agentes
  - Monitoreo y evaluación de rendimiento para escenarios en el borde

- [**Guía de Desarrollo de EdgeAI en Windows**](./Module07/windowdeveloper.md)
  - Descripción general de la plataforma Windows AI Foundry
  - API Phi Silica para inferencia eficiente en NPU
  - APIs de Visión por Computadora para procesamiento de imágenes y OCR
  - CLI de Foundry Local para desarrollo y pruebas locales

- [**EdgeAI en NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Rendimiento de IA de 67 TOPS en un formato del tamaño de una tarjeta de crédito
  - Soporte para modelos de IA generativa (transformadores de visión, LLMs, modelos de visión-lenguaje)
  - Aplicaciones en robótica, drones, cámaras inteligentes, dispositivos autónomos
  - Plataforma asequible de $249 para democratizar el desarrollo de IA

- [**EdgeAI en Aplicaciones Móviles con .NET MAUI y ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - IA móvil multiplataforma con una única base de código en C#
  - Soporte para aceleración por hardware (CPU, GPU, procesadores de IA móviles)
  - Optimizaciones específicas de plataforma (CoreML para iOS, NNAPI para Android)
  - Implementación completa del ciclo de IA generativa

- [**EdgeAI en Azure con el Motor de Modelos de Lenguaje Pequeños**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Arquitectura híbrida de despliegue en la nube y el borde
  - Integración de servicios de Azure AI con ONNX Runtime
  - Despliegue a escala empresarial y gestión continua de modelos
  - Flujos de trabajo híbridos de IA para procesamiento inteligente de documentos

- [**EdgeAI con Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fundamentos de Windows AI Foundry para inferencia eficiente en dispositivos
  - Soporte universal de hardware (AMD, Intel, NVIDIA, Qualcomm)
  - Abstracción y optimización automática de hardware
  - Marco unificado para el diverso ecosistema de hardware de Windows

- [**EdgeAI con Aplicaciones Locales de Foundry**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Implementación de RAG centrada en la privacidad con recursos locales
  - Integración del modelo de lenguaje Phi-4 con búsqueda semántica (solo modelos Phi)
  - Soporte para bases de datos vectoriales locales (SQLite, Qdrant)
  - Capacidades de soberanía de datos y operación sin conexión

### [Módulo 08: Microsoft Foundry Local – Kit de Herramientas Completo para Desarrolladores](./Module08/README.md)
**Tema**: Construir, ejecutar e integrar IA localmente con Foundry Local; escalar e hibridar con Azure AI Foundry

#### Estructura del Capítulo:
- [**1: Introducción a Foundry Local**](./Module08/01.FoundryLocalSetup.md)
- [**2: Construcción de Soluciones de IA con Azure AI Foundry**](./Module08/02.AzureAIFoundryIntegration.md)
- [**3: Modelos de Código Abierto en Foundry Local**](./Module08/03.OpenSourceModels.md)
- [**4: Modelos de Última Generación e Inferencia en Dispositivos**](./Module08/04.CuttingEdgeModels.md)
- [**5: Agentes Impulsados por IA con Foundry Local**](./Module08/05.AIPoweredAgents.md)
- [**6: Modelos como Herramientas**](./Module08/06.ModelsAsTools.md)

## Objetivos de Aprendizaje del Curso

Al completar este curso integral de EdgeAI, desarrollarás la experiencia necesaria para diseñar, implementar y desplegar soluciones de EdgeAI listas para producción. Nuestro enfoque estructurado garantiza que domines tanto los fundamentos teóricos como las habilidades prácticas de implementación.

### Competencias Técnicas

**Conocimientos Fundamentales**
- Comprender las diferencias fundamentales entre arquitecturas de IA basadas en la nube y en el borde
- Dominar los principios de cuantización, compresión y optimización de modelos para entornos con recursos limitados
- Comprender las opciones de aceleración por hardware (NPUs, GPUs, CPUs) y sus implicaciones de despliegue

**Habilidades de Implementación**
- Desplegar Modelos de Lenguaje Pequeños en diversas plataformas de borde (móviles, embebidos, IoT, servidores de borde)
- Aplicar marcos de optimización como Llama.cpp, Microsoft Olive, ONNX Runtime y Apple MLX
- Implementar sistemas de inferencia en tiempo real con requisitos de respuesta en subsegundos

**Experiencia en Producción**
- Diseñar arquitecturas escalables de EdgeAI para aplicaciones empresariales
- Implementar estrategias de monitoreo, mantenimiento y actualización para sistemas desplegados
- Aplicar mejores prácticas de seguridad para implementaciones de EdgeAI que preserven la privacidad

### Capacidades Estratégicas

**Marco de Toma de Decisiones**
- Evaluar oportunidades de EdgeAI e identificar casos de uso adecuados para aplicaciones empresariales
- Analizar compensaciones entre precisión del modelo, velocidad de inferencia, consumo de energía y costos de hardware
- Seleccionar familias y configuraciones de SLM adecuadas según las restricciones específicas de despliegue

**Arquitectura de Sistemas**
- Diseñar soluciones de EdgeAI de extremo a extremo que se integren con la infraestructura existente
- Planificar arquitecturas híbridas de borde-nube para un rendimiento y eficiencia de costos óptimos
- Implementar flujos de datos y tuberías de procesamiento para aplicaciones de IA en tiempo real

### Aplicaciones Industriales

**Escenarios Prácticos de Despliegue**
- **Manufactura**: Sistemas de control de calidad, mantenimiento predictivo y optimización de procesos
- **Salud**: Herramientas de diagnóstico que preservan la privacidad y sistemas de monitoreo de pacientes
- **Transporte**: Toma de decisiones en vehículos autónomos y gestión del tráfico
- **Ciudades Inteligentes**: Infraestructura inteligente y sistemas de gestión de recursos
- **Electrónica de Consumo**: Aplicaciones móviles impulsadas por IA y dispositivos inteligentes para el hogar

## Resumen de Resultados de Aprendizaje

### Resultados de Aprendizaje del Módulo 01:
- Comprender las diferencias fundamentales entre arquitecturas de IA en la nube y en el borde
- Dominar técnicas básicas de optimización para despliegues en el borde
- Reconocer aplicaciones reales y casos de éxito
- Adquirir habilidades prácticas para implementar soluciones de EdgeAI

### Resultados de Aprendizaje del Módulo 02:
- Comprensión profunda de las diferentes filosofías de diseño de SLM y sus implicaciones de despliegue
- Dominar capacidades estratégicas de toma de decisiones basadas en restricciones computacionales y requisitos de rendimiento
- Comprender las compensaciones de flexibilidad en el despliegue
- Poseer conocimientos preparados para el futuro sobre arquitecturas de IA eficientes

### Resultados de Aprendizaje del Módulo 03:
- Capacidades estratégicas de selección de modelos
- Dominio de técnicas de optimización
- Dominio de flexibilidad en el despliegue
- Capacidades de configuración listas para producción

### Resultados de Aprendizaje del Módulo 04:
- Comprensión profunda de los límites de cuantización y sus aplicaciones prácticas
- Experiencia práctica con múltiples marcos de optimización (Llama.cpp, Olive, OpenVINO, MLX)
- Dominar la optimización de hardware de Intel con OpenVINO y NNCF
- Capacidades de selección de optimización basada en hardware en diversas plataformas
- Habilidades de despliegue en producción para entornos de computación en el borde multiplataforma
- Selección estratégica de marcos y síntesis de flujos de trabajo para soluciones óptimas de Edge AI

### Resultados de Aprendizaje del Módulo 05:
- Dominar el paradigma de SLMOps y sus principios operativos
- Implementar destilación de modelos para transferencia de conocimiento y optimización de eficiencia
- Aplicar técnicas de ajuste fino para personalización de modelos específicos de dominio
- Desplegar soluciones SLM listas para producción con estrategias de monitoreo y mantenimiento

### Resultados de Aprendizaje del Módulo 06:
- Comprender conceptos fundamentales de agentes de IA y arquitectura de Modelos de Lenguaje Pequeños
- Dominar la implementación de llamadas a funciones en múltiples plataformas y marcos
- Integrar el Protocolo de Contexto del Modelo (MCP) para interacción estandarizada con herramientas externas
- Construir sistemas agénticos sofisticados con requisitos mínimos de intervención humana

### Resultados de Aprendizaje del Módulo 07:
- Dominar la Herramienta de IA para Visual Studio Code para flujos de trabajo completos de desarrollo de Edge AI
- Adquirir experiencia en la plataforma Windows AI Foundry y estrategias de optimización para NPU
- Obtener experiencia práctica con diversas plataformas de EdgeAI y estrategias de implementación
- Dominar técnicas de optimización específicas de hardware en plataformas NVIDIA, móviles, Azure y Windows
- Comprender las compensaciones de despliegue entre rendimiento, costo y requisitos de privacidad
- Desarrollar habilidades prácticas para construir aplicaciones reales de EdgeAI en diferentes ecosistemas

## Resultados Esperados del Curso

Al completar con éxito este curso, estarás equipado con el conocimiento, las habilidades y la confianza para liderar iniciativas de EdgeAI en entornos profesionales.

### Preparación Profesional

**Liderazgo Técnico**
- **Arquitectura de Soluciones**: Diseñar sistemas completos de EdgeAI que cumplan con los requisitos empresariales
- **Optimización de Rendimiento**: Lograr un equilibrio óptimo entre precisión, velocidad y consumo de recursos
- **Despliegue Multiplataforma**: Implementar soluciones en Windows, Linux, móviles y plataformas embebidas
- **Operaciones en Producción**: Mantener y escalar sistemas de EdgeAI con confiabilidad de nivel empresarial

**Experiencia en la Industria**
- **Evaluación Tecnológica**: Evaluar y recomendar soluciones de EdgeAI para desafíos empresariales específicos
- **Planificación de Implementación**: Desarrollar cronogramas realistas y requisitos de recursos para proyectos de EdgeAI
- **Gestión de Riesgos**: Identificar y mitigar riesgos técnicos y operativos en implementaciones de EdgeAI  
- **Optimización del ROI**: Demostrar valor empresarial medible a partir de implementaciones de EdgeAI  

### Oportunidades de Crecimiento Profesional  

**Roles Profesionales**  
- Arquitecto de Soluciones EdgeAI  
- Ingeniero de Aprendizaje Automático (Especialización en Edge)  
- Desarrollador de IoT con IA  
- Desarrollador de Aplicaciones Móviles con IA  
- Consultor Empresarial en IA  

**Sectores Industriales**  
- Manufactura Inteligente e Industria 4.0  
- Vehículos Autónomos y Transporte  
- Tecnología Sanitaria y Dispositivos Médicos  
- Tecnología Financiera y Seguridad  
- Electrónica de Consumo y Aplicaciones Móviles  

### Certificación y Validación  

**Desarrollo de Portafolio**  
- Completar proyectos EdgeAI de principio a fin que demuestren competencia práctica  
- Implementar soluciones listas para producción en múltiples plataformas de hardware  
- Documentar estrategias de optimización y mejoras de rendimiento logradas  

**Ruta de Aprendizaje Continuo**  
- Base para especializaciones avanzadas en IA  
- Preparación para arquitecturas híbridas en la nube y el edge  
- Puerta de entrada a tecnologías y marcos emergentes de IA  

Este curso te posiciona en la vanguardia de la implementación de tecnología de IA, donde las capacidades inteligentes se integran perfectamente en los dispositivos y sistemas que impulsan la vida moderna.  

## Diagrama de Estructura de Archivos  

```
edgeai-for-beginners/
├── imgs/
│   └── cover.png
├── Module01/ (EdgeAI Fundamentals and Transformation)
│   ├── 01.EdgeAIFundamentals.md
│   ├── 02.RealWorldCaseStudies.md
│   ├── 03.PracticalImplementationGuide.md
│   ├── 04.EdgeDeployment.md
│   └── README.md
├── Module02/ (Small Language Model Foundations)
│   ├── 01.PhiFamily.md
│   ├── 02.QwenFamily.md
│   ├── 03.GemmaFamily.md
│   ├── 04.BitNETFamily.md
│   ├── 05.mumodel.md
│   ├── 06.phisilica.md
│   └── README.md
├── Module03/ (SLM Deployment Practice)
│   ├── 01.SLMAdvancedLearning.md
│   ├── 02.DeployingSLMinLocalEnv.md
│   ├── 03.DeployingSLMinCloud.md
│   └── README.md
├── Module04/ (Model Format Conversion and Quantization)
│   ├── 01.Introduce.md
│   ├── 02.Llamacpp.md
│   ├── 03.MicrosoftOlive.md
│   ├── 04.openvino.md
│   ├── 05.AppleMLX.md
│   ├── 06.workflow-synthesis.md
│   └── README.md
├── Module05/ (SLMOps - Small Language Model Operations)
│   ├── 01.IntroduceSLMOps.md
│   ├── 02.SLMOps-Distillation.md
│   ├── 03.SLMOps-Finetuing.md
│   ├── 04.SLMOps.Deployment.md
│   └── README.md
├── Module06/ (SLM Agentic Systems)
│   ├── 01.IntroduceAgent.md
│   ├── 02.FunctionCalling.md
│   ├── 03.IntroduceMCP.md
│   └── README.md
├── Module07/ (EdgeAI Implementation Samples)
│   ├── aitoolkit.md
│   ├── windowdeveloper.md
│   └── README.md
├── Module08/ (Hands on with Foundry Local)
│   ├── 01.FoundryLocalSetup.md
│   ├── 02.AzureAIFoundryIntegration.md
│   ├── 03.OpenSourceModels.md
│   ├── 04.CuttingEdgeModels.md
│   ├── 05.AIPoweredAgents.md
│   ├── 06.ModelsAsTools.md
│   └── README.md
├── CODE_OF_CONDUCT.md
├── LICENSE
├── README.md (This file)
├── SECURITY.md
├── STUDY_GUIDE.md
└── SUPPORT.md
```
  

## Características del Curso  

- **Aprendizaje Progresivo**: Avanza gradualmente desde conceptos básicos hasta implementaciones avanzadas  
- **Integración de Teoría y Práctica**: Cada módulo incluye fundamentos teóricos y operaciones prácticas  
- **Casos Reales**: Basados en casos reales de Microsoft, Alibaba, Google y otros  
- **Práctica Activa**: Archivos de configuración completos, procedimientos de prueba de API y scripts de implementación  
- **Comparativas de Rendimiento**: Comparaciones detalladas de velocidad de inferencia, uso de memoria y requisitos de recursos  
- **Consideraciones Empresariales**: Prácticas de seguridad, marcos de cumplimiento y estrategias de protección de datos  

## Cómo Empezar  

Ruta de Aprendizaje Recomendada:  
1. Comienza con **Module01** para construir una comprensión fundamental de EdgeAI  
2. Continúa con **Module02** para profundizar en las diversas familias de modelos SLM  
3. Aprende **Module03** para dominar habilidades prácticas de implementación  
4. Avanza con **Module04** para optimización avanzada de modelos, conversión de formatos y síntesis de marcos  
5. Completa **Module05** para dominar SLMOps en implementaciones listas para producción  
6. Explora **Module06** para entender sistemas SLM agenticos y capacidades de llamadas a funciones  
7. Finaliza con **Module07** para obtener experiencia práctica con AI Toolkit y ejemplos diversos de implementación de EdgeAI  
8. Explora **Module08** para un kit completo de desarrollo Foundry Local (desarrollo local con integración híbrida de Azure)  

Cada módulo está diseñado para ser completo de manera independiente, pero el aprendizaje secuencial proporcionará los mejores resultados.  

## Guía de Estudio  

Una [Guía de Estudio](STUDY_GUIDE.md) está disponible para ayudarte a maximizar tu experiencia de aprendizaje. La guía de estudio proporciona:  

- **Rutas de Aprendizaje Estructuradas**: Horarios optimizados para completar el curso en 20 horas  
- **Guía de Asignación de Tiempo**: Recomendaciones específicas para equilibrar lectura, ejercicios y proyectos  
- **Enfoque en Conceptos Clave**: Objetivos de aprendizaje priorizados para cada módulo  
- **Herramientas de Autoevaluación**: Preguntas y ejercicios para probar tu comprensión  
- **Ideas para Mini-Proyectos**: Aplicaciones prácticas para reforzar tu aprendizaje  

La guía de estudio está diseñada para acomodar tanto aprendizaje intensivo (1 semana) como estudio a tiempo parcial (3 semanas), con orientación clara sobre cómo asignar tu tiempo de manera efectiva incluso si solo puedes dedicar 10 horas al curso.  

---

**El futuro de EdgeAI radica en la mejora continua de arquitecturas de modelos, técnicas de cuantización y estrategias de implementación que prioricen la eficiencia y la especialización sobre capacidades de propósito general. Las organizaciones que adopten este cambio de paradigma estarán bien posicionadas para aprovechar el potencial transformador de la IA mientras mantienen el control sobre sus datos y operaciones.**  

## Otros Cursos  

¡Nuestro equipo produce otros cursos! Descubre:  

- [MCP para Principiantes](https://github.com/microsoft/mcp-for-beginners)  
- [Agentes de IA para Principiantes](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [IA Generativa para Principiantes usando .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)  
- [IA Generativa para Principiantes usando JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)  
- [IA Generativa para Principiantes](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [ML para Principiantes](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)  
- [Ciencia de Datos para Principiantes](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)  
- [IA para Principiantes](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)  
- [Ciberseguridad para Principiantes](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)  
- [Desarrollo Web para Principiantes](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)  
- [IoT para Principiantes](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)  
- [Desarrollo XR para Principiantes](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [Dominando GitHub Copilot para Programación en Pareja con IA](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)  
- [Dominando GitHub Copilot para Desarrolladores de C#/.NET](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)  
- [Elige tu Propia Aventura con Copilot](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)  

---

