<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7a474b8e201d5316c0095cdbc3bf0555",
  "translation_date": "2025-09-24T12:49:38+00:00",
  "source_file": "Module08/samples/04/webgpu-demo/README.md",
  "language_code": "hi"
}
-->
# WebGPU + ONNX Runtime डेमो

यह डेमो दिखाता है कि कैसे ब्राउज़र में ही AI मॉडल्स को WebGPU के हार्डवेयर एक्सेलेरेशन और ONNX Runtime Web का उपयोग करके चलाया जा सकता है।

## यह क्या दिखाता है

- **ब्राउज़र-आधारित AI**: मॉडल्स को पूरी तरह से ब्राउज़र में चलाएं  
- **WebGPU एक्सेलेरेशन**: हार्डवेयर-आधारित तेज़ निष्पादन (जब उपलब्ध हो)  
- **गोपनीयता-प्रथम**: आपका डेटा आपके डिवाइस से बाहर नहीं जाता  
- **शून्य इंस्टॉलेशन**: किसी भी संगत ब्राउज़र में काम करता है  
- **सुव्यवस्थित फॉलबैक**: WebGPU उपलब्ध न होने पर CPU पर स्विच करता है  

## आवश्यकताएँ

**ब्राउज़र संगतता:**
- Chrome/Edge 113+ जिसमें WebGPU सक्षम हो  
- WebGPU स्थिति जांचें: `chrome://gpu`  
- WebGPU सक्षम करें: `chrome://flags/#enable-unsafe-webgpu`  

## डेमो चलाना

### विकल्प 1: लोकल सर्वर (अनुशंसित)

```cmd
# Navigate to the demo directory
cd Module08\samples\04\webgpu-demo

# Start a local server
python -m http.server 5173

# Open browser to http://localhost:5173
```

### विकल्प 2: VS Code लाइव सर्वर

1. VS Code में "Live Server" एक्सटेंशन इंस्टॉल करें  
2. `index.html` पर राइट-क्लिक करें → "Open with Live Server" चुनें  
3. डेमो ब्राउज़र में स्वचालित रूप से खुल जाएगा  

## आप क्या देखेंगे

1. **WebGPU डिटेक्शन**: ब्राउज़र संगतता की जांच करता है  
2. **मॉडल लोडिंग**: MNIST क्लासिफायर को डाउनलोड और इनिशियलाइज़ करता है  
3. **इन्फरेंस निष्पादन**: सैंपल डेटा पर प्रेडिक्शन चलाता है  
4. **प्रदर्शन मेट्रिक्स**: लोड समय और निष्पादन गति दिखाता है  
5. **परिणाम प्रदर्शन**: प्रेडिक्शन कॉन्फिडेंस और रॉ आउटपुट्स दिखाता है  

## अपेक्षित प्रदर्शन

| निष्पादन प्रदाता | मॉडल लोड | इन्फरेंस | नोट्स |
|-------------------|------------|-----------|-------|
| **WebGPU** | ~2-5 सेकंड | ~10-50ms | हार्डवेयर एक्सेलेरेटेड |
| **CPU (WASM)** | ~2-5 सेकंड | ~50-200ms | सॉफ़्टवेयर फॉलबैक |

## समस्या निवारण

**WebGPU उपलब्ध नहीं:**
- Chrome/Edge 113+ में अपडेट करें  
- `chrome://flags` में WebGPU सक्षम करें  
- सुनिश्चित करें कि GPU ड्राइवर्स अपडेटेड हैं  
- डेमो स्वचालित रूप से CPU पर फॉलबैक करेगा  

**लोडिंग त्रुटियाँ:**
- सुनिश्चित करें कि आप HTTP के माध्यम से सर्व कर रहे हैं (file:// नहीं)  
- मॉडल डाउनलोड के लिए नेटवर्क कनेक्शन जांचें  
- सुनिश्चित करें कि CORS ONNX मॉडल को ब्लॉक नहीं कर रहा  

**प्रदर्शन समस्याएँ:**
- WebGPU CPU की तुलना में काफी तेज़ है  
- पहली बार रन धीमा हो सकता है क्योंकि मॉडल डाउनलोड हो रहा है  
- बाद के रन ब्राउज़र कैश का उपयोग करते हैं  

## Foundry Local के साथ एकीकरण

यह WebGPU डेमो Foundry Local के साथ निम्नलिखित को दर्शाता है:

- **क्लाइंट-साइड इन्फरेंस** के लिए उच्चतम गोपनीयता  
- **ऑफ़लाइन क्षमताएँ** जब इंटरनेट उपलब्ध न हो  
- **एज डिप्लॉयमेंट** संसाधन-सीमित वातावरण के लिए  
- **हाइब्रिड आर्किटेक्चर** जो लोकल और सर्वर इन्फरेंस को जोड़ता है  

उत्पादन अनुप्रयोगों के लिए विचार करें:
- सर्वर-साइड इन्फरेंस के लिए Foundry Local का उपयोग करें  
- क्लाइंट-साइड प्रीप्रोसेसिंग/पोस्टप्रोसेसिंग के लिए WebGPU का उपयोग करें  
- लोकल/रिमोट इन्फरेंस के बीच बुद्धिमान रूटिंग लागू करें  

## तकनीकी विवरण

**उपयोग किया गया मॉडल:**
- MNIST डिजिट क्लासिफायर (ONNX फॉर्मेट)  
- इनपुट: 28x28 ग्रेस्केल इमेजेस  
- आउटपुट: 10-क्लास प्रॉबेबिलिटी डिस्ट्रीब्यूशन  
- आकार: ~500KB (तेज़ डाउनलोड)  

**ONNX Runtime Web:**
- GPU एक्सेलेरेशन के लिए WebGPU निष्पादन प्रदाता  
- CPU फॉलबैक के लिए WASM निष्पादन प्रदाता  
- स्वचालित अनुकूलन और ग्राफ ऑप्टिमाइज़ेशन  

**ब्राउज़र APIs:**
- हार्डवेयर एक्सेस के लिए WebGPU  
- बैकग्राउंड प्रोसेसिंग के लिए Web Workers (भविष्य में सुधार)  
- कुशल गणना के लिए WebAssembly  

## अगले कदम

- कस्टम ONNX मॉडल्स के साथ प्रयास करें  
- वास्तविक इमेज अपलोड और क्लासिफिकेशन लागू करें  
- बड़े मॉडल्स के लिए स्ट्रीमिंग इन्फरेंस जोड़ें  
- कैमरा/माइक्रोफोन इनपुट के साथ एकीकरण करें  

---

