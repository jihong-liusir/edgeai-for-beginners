<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "27be883865b4bad1e3c7e02c696da642",
  "translation_date": "2025-09-17T16:03:42+00:00",
  "source_file": "Module03/01.SLMAdvancedLearning.md",
  "language_code": "hi"
}
-->
# рдЕрдиреБрднрд╛рдЧ 1: SLM рдЙрдиреНрдирдд рд╢рд┐рдХреНрд╖рдг - рдиреАрдВрд╡ рдФрд░ рдЕрдиреБрдХреВрд▓рди

рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLMs) EdgeAI рдореЗрдВ рдПрдХ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдкреНрд░рдЧрддрд┐ рдХрд╛ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдХрд░рддреЗ рд╣реИрдВ, рдЬреЛ рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рдЙрдиреНрдирдд рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреНрд╖рдорддрд╛рдУрдВ рдХреЛ рд╕рдХреНрд╖рдо рдмрдирд╛рддреЗ рд╣реИрдВред SLMs рдХреЛ рдкреНрд░рднрд╛рд╡реА рдврдВрдЧ рд╕реЗ рддреИрдирд╛рдд, рдЕрдиреБрдХреВрд▓рд┐рдд рдФрд░ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреА рд╕рдордЭ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдПрдЬ-рдЖрдзрд╛рд░рд┐рдд AI рд╕рдорд╛рдзрд╛рди рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рд╣реИред

## рдкрд░рд┐рдЪрдп

рдЗрд╕ рдкрд╛рда рдореЗрдВ, рд╣рдо рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLMs) рдФрд░ рдЙрдирдХреЗ рдЙрдиреНрдирдд рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд░рдгрдиреАрддрд┐рдпреЛрдВ рдХрд╛ рдкрддрд╛ рд▓рдЧрд╛рдПрдВрдЧреЗред рд╣рдо SLMs рдХреА рдореМрд▓рд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ, рдЙрдирдХреЗ рдкреИрд░рд╛рдореАрдЯрд░ рд╕реАрдорд╛рдУрдВ рдФрд░ рд╡рд░реНрдЧреАрдХрд░рдг, рдЕрдиреБрдХреВрд▓рди рддрдХрдиреАрдХреЛрдВ, рдФрд░ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рддреИрдирд╛рддреА рд░рдгрдиреАрддрд┐рдпреЛрдВ рдХреЛ рдХрд╡рд░ рдХрд░реЗрдВрдЧреЗред

## рд╕реАрдЦрдиреЗ рдХреЗ рдЙрджреНрджреЗрд╢реНрдп

рдЗрд╕ рдкрд╛рда рдХреЗ рдЕрдВрдд рддрдХ, рдЖрдк рд╕рдХреНрд╖рдо рд╣реЛрдВрдЧреЗ:

- ЁЯФв рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓реЛрдВ рдХреЗ рдкреИрд░рд╛рдореАрдЯрд░ рд╕реАрдорд╛рдУрдВ рдФрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдХреЛ рд╕рдордЭреЗрдВред
- ЁЯЫая╕П рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ SLM рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдкреНрд░рдореБрдЦ рдЕрдиреБрдХреВрд▓рди рддрдХрдиреАрдХреЛрдВ рдХреА рдкрд╣рдЪрд╛рди рдХрд░реЗрдВред
- ЁЯЪА SLMs рдХреЗ рд▓рд┐рдП рдЙрдиреНрдирдд рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рдФрд░ рд╕рдВрдкреАрдбрд╝рди рд░рдгрдиреАрддрд┐рдпреЛрдВ рдХреЛ рд▓рд╛рдЧреВ рдХрд░рдирд╛ рд╕реАрдЦреЗрдВред

## SLM рдкреИрд░рд╛рдореАрдЯрд░ рд╕реАрдорд╛рдУрдВ рдФрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдХреЛ рд╕рдордЭрдирд╛

рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLMs) AI рдореЙрдбрд▓ рд╣реИрдВ рдЬреЛ рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рд╕рд╛рдордЧреНрд░реА рдХреЛ рд╕рдВрд╕рд╛рдзрд┐рдд, рд╕рдордЭрдиреЗ рдФрд░ рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдП рдЧрдП рд╣реИрдВ, рдЬреЛ рдЙрдирдХреЗ рдмрдбрд╝реЗ рд╕рдордХрдХреНрд╖реЛрдВ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдХрд╛рдлреА рдХрдо рдкреИрд░рд╛рдореАрдЯрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред рдЬрдмрдХрд┐ рдмрдбрд╝реЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (LLMs) рдореЗрдВ рд╕реИрдХрдбрд╝реЛрдВ рдЕрд░рдмреЛрдВ рд╕реЗ рд▓реЗрдХрд░ рдЯреНрд░рд┐рд▓рд┐рдпрди рддрдХ рдкреИрд░рд╛рдореАрдЯрд░ рд╣реЛрддреЗ рд╣реИрдВ, SLMs рдХреЛ рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рджрдХреНрд╖рддрд╛ рдФрд░ рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред

рдкреИрд░рд╛рдореАрдЯрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдврд╛рдВрдЪрд╛ рд╣рдореЗрдВ SLMs рдХреА рд╡рд┐рднрд┐рдиреНрди рд╢реНрд░реЗрдгрд┐рдпреЛрдВ рдФрд░ рдЙрдирдХреЗ рдЙрдкрдпреБрдХреНрдд рдЙрдкрдпреЛрдЧ рдорд╛рдорд▓реЛрдВ рдХреЛ рд╕рдордЭрдиреЗ рдореЗрдВ рдорджрдж рдХрд░рддрд╛ рд╣реИред рдпрд╣ рд╡рд░реНрдЧреАрдХрд░рдг рд╡рд┐рд╢рд┐рд╖реНрдЯ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕рд╣реА рдореЙрдбрд▓ рдХрд╛ рдЪрдпрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИред

### рдкреИрд░рд╛рдореАрдЯрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдврд╛рдВрдЪрд╛

рдкреИрд░рд╛рдореАрдЯрд░ рд╕реАрдорд╛рдУрдВ рдХреЛ рд╕рдордЭрдирд╛ рд╡рд┐рднрд┐рдиреНрди рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рдореЙрдбрд▓ рдХрд╛ рдЪрдпрди рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░рддрд╛ рд╣реИ:

- **ЁЯФм рдорд╛рдЗрдХреНрд░реЛ SLMs**: 100M - 1.4B рдкреИрд░рд╛рдореАрдЯрд░ (рдореЛрдмрд╛рдЗрд▓ рдЙрдкрдХрд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрд▓реНрдЯреНрд░рд╛-рд▓рд╛рдЗрдЯрд╡реЗрдЯ)
- **ЁЯУ▒ рдЫреЛрдЯреЗ SLMs**: 1.5B - 13.9B рдкреИрд░рд╛рдореАрдЯрд░ (рд╕рдВрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдФрд░ рджрдХреНрд╖рддрд╛)
- **тЪЦя╕П рдордзреНрдпрдо SLMs**: 14B - 30B рдкреИрд░рд╛рдореАрдЯрд░ (LLM рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рдХрд░реАрдм рдкрд╣реБрдВрдЪрддреЗ рд╣реБрдП рджрдХреНрд╖рддрд╛ рдмрдирд╛рдП рд░рдЦрдирд╛)

рд╢реЛрдз рд╕рдореБрджрд╛рдп рдореЗрдВ рд╕рдЯреАрдХ рд╕реАрдорд╛ рддрд░рд▓ рдмрдиреА рд░рд╣рддреА рд╣реИ, рд▓реЗрдХрд┐рди рдЕрдзрд┐рдХрд╛рдВрд╢ рдЪрд┐рдХрд┐рддреНрд╕рдХ 30 рдЕрд░рдм рд╕реЗ рдХрдо рдкреИрд░рд╛рдореАрдЯрд░ рд╡рд╛рд▓реЗ рдореЙрдбрд▓реЛрдВ рдХреЛ "рдЫреЛрдЯрд╛" рдорд╛рдирддреЗ рд╣реИрдВ, рдХреБрдЫ рд╕реНрд░реЛрдд рдЗрд╕реЗ 10 рдЕрд░рдм рдкреИрд░рд╛рдореАрдЯрд░ рдкрд░ рднреА рдХрдо рд╕реЗрдЯ рдХрд░рддреЗ рд╣реИрдВред

### SLMs рдХреЗ рдкреНрд░рдореБрдЦ рд▓рд╛рдн

SLMs рдХрдИ рдореМрд▓рд┐рдХ рд▓рд╛рдн рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рдЙрдиреНрд╣реЗрдВ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢ рдмрдирд╛рддреЗ рд╣реИрдВ:

**рд╕рдВрдЪрд╛рд▓рди рджрдХреНрд╖рддрд╛**: SLMs рдХрдо рдкреИрд░рд╛рдореАрдЯрд░ рдХреЛ рд╕рдВрд╕рд╛рдзрд┐рдд рдХрд░рдиреЗ рдХреЗ рдХрд╛рд░рдг рддреЗрдЬрд╝ рдЕрдиреБрдорд╛рди рд╕рдордп рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ, рдЬреЛ рдЙрдиреНрд╣реЗрдВ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордп рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢ рдмрдирд╛рддрд╛ рд╣реИред рд╡реЗ рдХрдо рдХрдВрдкреНрдпреВрдЯреЗрд╢рдирд▓ рд╕рдВрд╕рд╛рдзрдиреЛрдВ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд░рдЦрддреЗ рд╣реИрдВ, рдЬрд┐рд╕рд╕реЗ рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рддреИрдирд╛рддреА рд╕рдВрднрд╡ рд╣реЛрддреА рд╣реИ, рд╕рд╛рде рд╣реА рдХрдо рдКрд░реНрдЬрд╛ рдЦрдкрдд рдФрд░ рдХрдо рдХрд╛рд░реНрдмрди рдлреБрдЯрдкреНрд░рд┐рдВрдЯ рдмрдирд╛рдП рд░рдЦрддреЗ рд╣реИрдВред

**рддреИрдирд╛рддреА рд▓рдЪреАрд▓рд╛рдкрди**: рдпреЗ рдореЙрдбрд▓ рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡рд┐рдЯреА рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рдмрд┐рдирд╛ рдСрди-рдбрд┐рд╡рд╛рдЗрд╕ AI рдХреНрд╖рдорддрд╛рдУрдВ рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ рд╣реИрдВ, рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рдФрд░ рд╕реБрд░рдХреНрд╖рд╛ рдХреЛ рдмрдврд╝рд╛рддреЗ рд╣реИрдВ, рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд┐рдП рдЬрд╛ рд╕рдХрддреЗ рд╣реИрдВ, рдФрд░ рд╡рд┐рднрд┐рдиреНрди рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╡рд╛рддрд╛рд╡рд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рд╣реИрдВред

**рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡рд╢реАрд▓рддрд╛**: SLMs рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдФрд░ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡реА рд╕рдорд╛рдзрд╛рди рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ, рдХрдо рдкрд░рд┐рдЪрд╛рд▓рди рд▓рд╛рдЧрдд рдФрд░ рдПрдЬ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдХрдо рдмреИрдВрдбрд╡рд┐рдбреНрде рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рд╕рд╛рдеред

## рдЙрдиреНрдирдд рдореЙрдбрд▓ рдЕрдзрд┐рдЧреНрд░рд╣рдг рд░рдгрдиреАрддрд┐рдпрд╛рдБ

### рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдЗрдХреЛрд╕рд┐рд╕реНрдЯрдо

рд╣рдЧрд┐рдВрдЧ рдлреЗрд╕ рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ SLMs рдХреА рдЦреЛрдЬ рдФрд░ рдкрд╣реБрдВрдЪ рдХреЗ рд▓рд┐рдП рдкреНрд░рд╛рдердорд┐рдХ рдХреЗрдВрджреНрд░ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░рддрд╛ рд╣реИред рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдореЙрдбрд▓ рдЦреЛрдЬ рдФрд░ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рдкрдХ рд╕рдВрд╕рд╛рдзрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдореЙрдбрд▓ рдЦреЛрдЬ рд╕реБрд╡рд┐рдзрд╛рдПрдБ**: рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдкреИрд░рд╛рдореАрдЯрд░ рдЧрдгрдирд╛, рд▓рд╛рдЗрд╕реЗрдВрд╕ рдкреНрд░рдХрд╛рд░, рдФрд░ рдкреНрд░рджрд░реНрд╢рди рдореЗрдЯреНрд░рд┐рдХреНрд╕ рджреНрд╡рд╛рд░рд╛ рдЙрдиреНрдирдд рдлрд╝рд┐рд▓реНрдЯрд░рд┐рдВрдЧ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рд╕рд╛рдЗрдб-рдмрд╛рдп-рд╕рд╛рдЗрдб рдореЙрдбрд▓ рддреБрд▓рдирд╛ рдЙрдкрдХрд░рдг, рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордп рдкреНрд░рджрд░реНрд╢рди рдмреЗрдВрдЪрдорд╛рд░реНрдХ рдФрд░ рдореВрд▓реНрдпрд╛рдВрдХрди рдкрд░рд┐рдгрд╛рдо, рдФрд░ рддрддреНрдХрд╛рд▓ рдкрд░реАрдХреНрд╖рдг рдХреЗ рд▓рд┐рдП WebGPU рдбреЗрдореЛ рддрдХ рдкрд╣реБрдВрдЪ рд╕рдХрддреЗ рд╣реИрдВред

**рдХреНрдпреВрд░реЗрдЯреЗрдб SLM рд╕рдВрдЧреНрд░рд╣**: рд▓реЛрдХрдкреНрд░рд┐рдп рдореЙрдбрд▓реЛрдВ рдореЗрдВ рдЙрдиреНрдирдд рддрд░реНрдХ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП Phi-4-mini-3.8B, рдмрд╣реБрднрд╛рд╖реА рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ (0.6B/1.7B/4B), рдХреБрд╢рд▓ рд╕рд╛рдорд╛рдиреНрдп-рдЙрджреНрджреЗрд╢реНрдп рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП Google Gemma3, рдФрд░ рдЕрд▓реНрдЯреНрд░рд╛-рд▓реЛ рдкреНрд░рд┐рд╕рд┐рдЬрди рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП BitNET рдЬреИрд╕реЗ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдореЙрдбрд▓ рд╢рд╛рдорд┐рд▓ рд╣реИрдВред рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдореЗрдВ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдбреЛрдореЗрди рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рдореЙрдбрд▓реЛрдВ рдХреЗ рд╕рд╛рде рд╕рд╛рдореБрджрд╛рдпрд┐рдХ-рд╕рдВрдЪрд╛рд▓рд┐рдд рд╕рдВрдЧреНрд░рд╣ рднреА рд╢рд╛рдорд┐рд▓ рд╣реИрдВ рдФрд░ рд╡рд┐рднрд┐рдиреНрди рдЙрдкрдпреЛрдЧ рдорд╛рдорд▓реЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдкреВрд░реНрд╡-рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдФрд░ рдирд┐рд░реНрджреЗрд╢-рдЯреНрдпреВрди рдХрд┐рдП рдЧрдП рд╡реЗрд░рд┐рдПрдВрдЯ рд╣реИрдВред

### Azure AI Foundry рдореЙрдбрд▓ рдХреИрдЯрд▓реЙрдЧ

Azure AI Foundry рдореЙрдбрд▓ рдХреИрдЯрд▓реЙрдЧ рдЙрдиреНрдирдд рдПрдХреАрдХрд░рдг рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рд╕рд╛рде SLMs рддрдХ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рдкрд╣реБрдВрдЪ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдПрдХреАрдХрд░рдг**: рдХреИрдЯрд▓реЙрдЧ рдореЗрдВ Azure рджреНрд╡рд╛рд░рд╛ рд╕реАрдзреЗ рдмреЗрдЪреЗ рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдореЙрдбрд▓ рд╢рд╛рдорд┐рд▓ рд╣реИрдВ, рдЬрд┐рд╕рдореЗрдВ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рд╕рдорд░реНрдерди рдФрд░ SLA рд╣реИрдВ, рдЬрд┐рд╕рдореЗрдВ рдЙрдиреНрдирдд рддрд░реНрдХ рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рд▓рд┐рдП Phi-4-mini-3.8B рдФрд░ рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП Llama 3-8B рд╢рд╛рдорд┐рд▓ рд╣реИрдВред рдЗрд╕рдореЗрдВ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рддреГрддреАрдп-рдкрдХреНрд╖ рдУрдкрди рд╕реЛрд░реНрд╕ рдореЙрдбрд▓ рд╕реЗ Qwen3 8B рдЬреИрд╕реЗ рдореЙрдбрд▓ рднреА рд╢рд╛рдорд┐рд▓ рд╣реИрдВред

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рд▓рд╛рдн**: рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ, рдЕрд╡рд▓реЛрдХрди, рдФрд░ рдЬрд┐рдореНрдореЗрджрд╛рд░ AI рдХреЗ рд▓рд┐рдП рдЕрдВрддрд░реНрдирд┐рд╣рд┐рдд рдЙрдкрдХрд░рдг рдореЙрдбрд▓ рдкрд░рд┐рд╡рд╛рд░реЛрдВ рдХреЗ рдмреАрдЪ рдлрдВрдЧрд┐рдмрд▓ рдкреНрд░реЛрд╡рд┐рдЬрдиреНрдб рдереНрд░реВрдкреБрдЯ рдХреЗ рд╕рд╛рде рдПрдХреАрдХреГрдд рд╣реИрдВред рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ SLA рдХреЗ рд╕рд╛рде рд╕реАрдзреЗ Microsoft рд╕рдорд░реНрдерди, рдПрдХреАрдХреГрдд рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рдЕрдиреБрдкрд╛рд▓рди рд╕реБрд╡рд┐рдзрд╛рдПрдБ, рдФрд░ рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдЕрдиреБрднрд╡ рдХреЛ рдмрдврд╝рд╛рддреЗ рд╣реИрдВред

## рдЙрдиреНрдирдд рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рдФрд░ рдЕрдиреБрдХреВрд▓рди рддрдХрдиреАрдХ

### Llama.cpp рдЕрдиреБрдХреВрд▓рди рдврд╛рдВрдЪрд╛

Llama.cpp рдПрдЬ рддреИрдирд╛рддреА рдореЗрдВ рдЕрдзрд┐рдХрддрдо рджрдХреНрд╖рддрд╛ рдХреЗ рд▓рд┐рдП рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рддрдХрдиреАрдХ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╡рд┐рдзрд┐рдпрд╛рдБ**: рдврд╛рдВрдЪрд╛ рд╡рд┐рднрд┐рдиреНрди рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░реЛрдВ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ Q4_0 (рдЙрддреНрдХреГрд╖реНрдЯ рдЖрдХрд╛рд░ рдореЗрдВ рдХрдореА рдХреЗ рд╕рд╛рде 4-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди - Qwen3-0.6B рдореЛрдмрд╛рдЗрд▓ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢), Q5_1 (рдЧреБрдгрд╡рддреНрддрд╛ рдФрд░ рд╕рдВрдкреАрдбрд╝рди рдХреЛ рд╕рдВрддреБрд▓рд┐рдд рдХрд░рдиреЗ рд╡рд╛рд▓рд╛ 5-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди - Phi-4-mini-3.8B рдПрдЬ рдЕрдиреБрдорд╛рди рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд), рдФрд░ Q8_0 (рдореВрд▓ рдЧреБрдгрд╡рддреНрддрд╛ рдХреЗ рдХрд░реАрдм 8-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди - Google Gemma3 рдЙрддреНрдкрд╛рджрди рдЙрдкрдпреЛрдЧ рдХреЗ рд▓рд┐рдП рдЕрдиреБрд╢рдВрд╕рд┐рдд)ред BitNET рдЕрддреНрдпрдзрд┐рдХ рд╕рдВрдкреАрдбрд╝рди рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рдХреЗ рд╕рд╛рде рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдХрд░рддрд╛ рд╣реИред

**рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд▓рд╛рдн**: SIMD рддреНрд╡рд░рдг рдХреЗ рд╕рд╛рде CPU-рдЕрдиреБрдХреВрд▓рд┐рдд рдЕрдиреБрдорд╛рди рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдореЙрдбрд▓ рд▓реЛрдбрд┐рдВрдЧ рдФрд░ рдирд┐рд╖реНрдкрд╛рджрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред x86, ARM, рдФрд░ Apple Silicon рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдореЗрдВ рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рд╕рдВрдЧрддрддрд╛ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░-рдЕрдЬреНрдЮреЗрдпрд╡рд╛рджреА рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рдУрдВ рдХреЛ рд╕рдХреНрд╖рдо рдмрдирд╛рддреА рд╣реИред

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг**:

```bash
# Clone and build llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release

# Convert Phi-4-mini model from Hugging Face to GGUF format
# First, download the model from Hugging Face
cd ..
python convert.py --outtype f16 --outfile phi-4-mini.gguf /path/to/downloaded/phi-4-mini/model

# Quantize the model to 4-bit precision (Q4_0)
./build/bin/quantize phi-4-mini.gguf phi-4-mini-q4_0.gguf q4_0

# Benchmark the model to check performance
./build/bin/llama-bench -m phi-4-mini-q4_0.gguf -p "Write a function to calculate the Fibonacci sequence"

# Run inference with the quantized model
./build/bin/main -m phi-4-mini-q4_0.gguf -n 512 -p "Explain quantum computing in simple terms"
```

**рдореЗрдореЛрд░реА рдлреБрдЯрдкреНрд░рд┐рдВрдЯ рддреБрд▓рдирд╛**:

```python
# Python script to analyze model size differences
import os
import matplotlib.pyplot as plt
import numpy as np

# Model sizes (in GB)
models = ['Phi-4-mini', 'Qwen3-0.6B', 'Gemma3']
original_sizes = [7.6, 1.2, 4.8]  # F16 format
q4_0_sizes = [2.0, 0.35, 1.3]     # Q4_0 format
q8_0_sizes = [3.9, 0.68, 2.5]     # Q8_0 format

# Calculate reduction percentages
q4_reduction = [(orig - q4) / orig * 100 for orig, q4 in zip(original_sizes, q4_0_sizes)]
q8_reduction = [(orig - q8) / orig * 100 for orig, q8 in zip(original_sizes, q8_0_sizes)]

print("Model Size Reduction:")
for i, model in enumerate(models):
    print(f"{model}: Q4_0 reduces size by {q4_reduction[i]:.1f}%, Q8_0 reduces size by {q8_reduction[i]:.1f}%")

# Memory usage during inference will be approximately:
# - Original F16: ~2x model size
# - Q4_0: ~1.2x model size
# - Q8_0: ~1.5x model size
```

### Microsoft Olive рдЕрдиреБрдХреВрд▓рди рд╕реВрдЯ

Microsoft Olive рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдП рдЧрдП рд╡реНрдпрд╛рдкрдХ рдореЙрдбрд▓ рдЕрдиреБрдХреВрд▓рди рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдЕрдиреБрдХреВрд▓рди рддрдХрдиреАрдХ**: рд╕реВрдЯ рдореЗрдВ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд╕рдЯреАрдХрддрд╛ рдЪрдпрди рдХреЗ рд▓рд┐рдП рдЧрддрд┐рд╢реАрд▓ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди (рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЙрдбрд▓реЛрдВ рдХреЗ рд╕рд╛рде рдкреНрд░рднрд╛рд╡реА), рдЧреНрд░рд╛рдл рдЕрдиреБрдХреВрд▓рди рдФрд░ рдСрдкрд░реЗрдЯрд░ рдлреНрдпреВрдЬрди (Google Gemma3 рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд), CPU, GPU, рдФрд░ NPU рдХреЗ рд▓рд┐рдП рд╣рд╛рд░реНрдбрд╡реЗрдпрд░-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдХреВрд▓рди (ARM рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ Phi-4-mini-3.8B рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рд╕рдорд░реНрдерди рдХреЗ рд╕рд╛рде), рдФрд░ рдмрд╣реБ-рдЪрд░рдг рдЕрдиреБрдХреВрд▓рди рдкрд╛рдЗрдкрд▓рд╛рдЗрдиреЛрдВ рдХреЛ рд╢рд╛рдорд┐рд▓ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред BitNET рдореЙрдбрд▓ Olive рдврд╛рдВрдЪреЗ рдХреЗ рднреАрддрд░ рд╡рд┐рд╢реЗрд╖ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИред

**рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рд╕реНрд╡рдЪрд╛рд▓рди**: рдЕрдиреБрдХреВрд▓рди рд╡реЗрд░рд┐рдПрдВрдЯ рдХреЗ рдмреАрдЪ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдмреЗрдВрдЪрдорд╛рд░реНрдХрд┐рдВрдЧ рдЕрдиреБрдХреВрд▓рди рдХреЗ рджреМрд░рд╛рди рдЧреБрдгрд╡рддреНрддрд╛ рдореАрдЯреНрд░рд┐рдХ рд╕рдВрд░рдХреНрд╖рдг рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛ рд╣реИред PyTorch рдФрд░ ONNX рдЬреИрд╕реЗ рд▓реЛрдХрдкреНрд░рд┐рдп ML рдлреНрд░реЗрдорд╡рд░реНрдХ рдХреЗ рд╕рд╛рде рдПрдХреАрдХрд░рдг рдХреНрд▓рд╛рдЙрдб рдФрд░ рдПрдЬ рддреИрдирд╛рддреА рдЕрдиреБрдХреВрд▓рди рдХреНрд╖рдорддрд╛рдПрдБ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг**:

```python
# Microsoft Olive optimization workflow for SLM
from olive.model import PyTorchModel, ONNXModel
from olive.workflows import run_workflow
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Define the workflow configuration
def create_olive_config(model_id="microsoft/phi-4-mini-instruct"):
    # Load model and create sample inputs
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)
    
    # Create sample inputs for tracing
    sample_text = "Explain the concept of edge computing"
    inputs = tokenizer(sample_text, return_tensors="pt")
    
    # Export to ONNX first
    model_path = f"{model_id.split('/')[-1]}.onnx"
    torch.onnx.export(
        model,
        (inputs["input_ids"],),
        model_path,
        input_names=["input_ids"],
        output_names=["logits"],
        dynamic_axes={
            "input_ids": {0: "batch", 1: "sequence"},
            "logits": {0: "batch", 1: "sequence"}
        },
        opset_version=15
    )
    
    # Create Olive optimization config
    config = {
        "input_model": ONNXModel(model_path),
        "systems": {
            "local_system": {
                "type": "LocalSystem"
            }
        },
        "passes": {
            # Graph optimization pass
            "graph_optimization": {
                "type": "OrtTransformersOptimization",
                "config": {
                    "optimization_options": {
                        "enable_gelu": True,
                        "enable_layer_norm": True,
                        "enable_attention": True,
                        "use_multi_head_attention": True
                    }
                }
            },
            # Quantization pass for INT8
            "quantization": {
                "type": "OrtQuantization",
                "config": {
                    "quant_mode": "static",
                    "activation_type": "int8",
                    "weight_type": "int8",
                    "op_types_to_quantize": ["MatMul", "Add", "Conv"]
                },
                "disable_search": True
            }
        },
        "engine": {
            "log_severity_level": 0,
            "cache_dir": "./cache"
        }
    }
    
    return config

# Run the optimization workflow
config = create_olive_config()
result = run_workflow(config)

# Save the optimized model
optimized_model = result.optimized_model
optimized_model.save("./optimized_phi4_mini")

# Benchmark performance comparison
print(f"Original model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
print(f"Optimized model size: {os.path.getsize('./optimized_phi4_mini/model.onnx') / (1024 * 1024):.2f} MB")
```

### Apple MLX рдлреНрд░реЗрдорд╡рд░реНрдХ

Apple MLX рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ Apple Silicon рдЙрдкрдХрд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдП рдЧрдП рджреЗрд╢реА рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**Apple Silicon рдЕрдиреБрдХреВрд▓рди**: рдлреНрд░реЗрдорд╡рд░реНрдХ рдореЗрдЯрд▓ рдкреНрд░рджрд░реНрд╢рди рд╢реЗрдбрд░реНрд╕ рдПрдХреАрдХрд░рдг рдХреЗ рд╕рд╛рде рдПрдХреАрдХреГрдд рдореЗрдореЛрд░реА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдорд┐рд╢реНрд░рд┐рдд рд╕рдЯреАрдХрддрд╛ рдЕрдиреБрдорд╛рди (рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ Google Gemma3 рдХреЗ рд╕рд╛рде рдкреНрд░рднрд╛рд╡реА), рдФрд░ рдЕрдиреБрдХреВрд▓рд┐рдд рдореЗрдореЛрд░реА рдмреИрдВрдбрд╡рд┐рдбреНрде рдЙрдкрдпреЛрдЧред Phi-4-mini-3.8B M-рд╢реНрд░реГрдВрдЦрд▓рд╛ рдЪрд┐рдкреНрд╕ рдкрд░ рдЕрд╕рд╛рдзрд╛рд░рдг рдкреНрд░рджрд░реНрд╢рди рджрд┐рдЦрд╛рддрд╛ рд╣реИ, рдЬрдмрдХрд┐ Qwen3-1.7B MacBook Air рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЗрд╖реНрдЯрддрдо рд╕рдВрддреБрд▓рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

**рд╡рд┐рдХрд╛рд╕ рд╕реБрд╡рд┐рдзрд╛рдПрдБ**: NumPy-рд╕рдВрдЧрдд рдРрд░реЗ рд╕рдВрдЪрд╛рд▓рди, рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рднрд┐рдиреНрдирддрд╛ рдХреНрд╖рдорддрд╛рдУрдВ, рдФрд░ Apple рд╡рд┐рдХрд╛рд╕ рдЙрдкрдХрд░рдгреЛрдВ рдХреЗ рд╕рд╛рде рд╕рд╣рдЬ рдПрдХреАрдХрд░рдг рдХреЗ рд╕рд╛рде Python рдФрд░ Swift API рд╕рдорд░реНрдерди рдПрдХ рд╡реНрдпрд╛рдкрдХ рд╡рд┐рдХрд╛рд╕ рд╡рд╛рддрд╛рд╡рд░рдг рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг**:

```python
# Apple MLX optimization for Phi-4-mini model
import mlx.core as mx
import mlx.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from mlx_lm import load, generate

# Install the required packages
# pip install mlx transformers mlx-lm

# Load the Phi-4-mini model with MLX optimization
model_path = "microsoft/phi-4-mini-instruct"
model, tokenizer = load(model_path)

# Convert to float16 for better performance on Apple Silicon
model.convert_to_float16()

# Sample inference
prompt = "Write a function to find prime numbers in Python"
results = generate(
    model, 
    tokenizer,
    prompt=prompt,
    max_tokens=512,
    temperature=0.7,
    top_p=0.9,
)

print(results[0]["generation"])

# Benchmark the model
import time

def benchmark_inference(model, tokenizer, prompt, runs=10):
    # Warmup
    generate(model, tokenizer, prompt=prompt, max_tokens=128)
    
    # Benchmark
    start_time = time.time()
    for _ in range(runs):
        generate(model, tokenizer, prompt=prompt, max_tokens=128)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / runs
    return avg_time

avg_inference_time = benchmark_inference(model, tokenizer, "Explain quantum computing")
print(f"Average inference time: {avg_inference_time:.4f} seconds")

# Save the optimized model for later use
model.save_weights("phi4_mini_optimized_mlx.npz")
```

## рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреА рдФрд░ рдЕрдиреБрдорд╛рди рд░рдгрдиреАрддрд┐рдпрд╛рдБ

### Ollama: рд╕рд░рд▓реАрдХреГрдд рд╕реНрдерд╛рдиреАрдп рддреИрдирд╛рддреА

Ollama рд╕реНрдерд╛рдиреАрдп рдФрд░ рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рд░реЗрдбреА рд╕реБрд╡рд┐рдзрд╛рдУрдВ рдХреЗ рд╕рд╛рде SLM рддреИрдирд╛рддреА рдХреЛ рд╕рд░рд▓ рдмрдирд╛рддрд╛ рд╣реИ:

**рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рдПрдБ**: рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдореЙрдбрд▓ рдЦреАрдВрдЪрдиреЗ рдФрд░ рдХреИрд╢рд┐рдВрдЧ рдХреЗ рд╕рд╛рде рдПрдХ-рдХрдорд╛рдВрдб рдореЙрдбрд▓ рд╕реНрдерд╛рдкрдирд╛ рдФрд░ рдирд┐рд╖реНрдкрд╛рджрдиред Phi-4-mini-3.8B, рдкреВрд░реА Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ (0.6B/1.7B/4B), рдФрд░ Google Gemma3 рдХреЗ рд▓рд┐рдП рд╕рдорд░реНрдерди REST API рдХреЗ рд╕рд╛рде рдПрдкреНрд▓рд┐рдХреЗрд╢рди рдПрдХреАрдХрд░рдг рдФрд░ рдмрд╣реБ-рдореЙрдбрд▓ рдкреНрд░рдмрдВрдзрди рдФрд░ рд╕реНрд╡рд┐рдЪрд┐рдВрдЧ рдХреНрд╖рдорддрд╛рдПрдБ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред BitNET рдореЙрдбрд▓ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╕рдорд░реНрдерди рдХреЗ рд▓рд┐рдП рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдмрд┐рд▓реНрдб рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИред

**рдЙрдиреНрдирдд рд╕реБрд╡рд┐рдзрд╛рдПрдБ**: рдХрд╕реНрдЯрдо рдореЙрдбрд▓ рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рд╕рдорд░реНрдерди, рдХрдВрдЯреЗрдирд░реАрдХреГрдд рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП Dockerfile рдкреАрдврд╝реА, GPU рддреНрд╡рд░рдг рдХреЗ рд╕рд╛рде рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкрд╣рдЪрд╛рди, рдФрд░ рдореЙрдбрд▓ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рдФрд░ рдЕрдиреБрдХреВрд▓рди рд╡рд┐рдХрд▓реНрдк рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рд▓рдЪреАрд▓рд╛рдкрди рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред

### VLLM: рдЙрдЪреНрдЪ-рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдорд╛рди

VLLM рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрддреНрдкрд╛рджрди-рдЧреНрд░реЗрдб рдЕрдиреБрдорд╛рди рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди**: рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдзреНрдпрд╛рди рдЧрдгрдирд╛ рдХреЗ рд▓рд┐рдП PagedAttention (рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ Phi-4-mini-3.8B рдХреЗ рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдХреЗ рд▓рд┐рдП рд▓рд╛рднрдХрд╛рд░реА), рдереНрд░реВрдкреБрдЯ рдЕрдиреБрдХреВрд▓рди рдХреЗ рд▓рд┐рдП рдЧрддрд┐рд╢реАрд▓ рдмреИрдЪрд┐рдВрдЧ (Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ рд╕рдорд╛рдирд╛рдВрддрд░ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд), рдмрд╣реБ-GPU рд╕реНрдХреЗрд▓рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рдЯреЗрдВрд╕рд░ рд╕рдорд╛рдирд╛рдВрддрд░рддрд╛ (Google Gemma3 рд╕рдорд░реНрдерди), рдФрд░ рд╡рд┐рд▓рдВрдмрддрд╛ рдореЗрдВ рдХрдореА рдХреЗ рд▓рд┐рдП рдЕрдиреБрдорд╛рдирд╛рддреНрдордХ рдбрд┐рдХреЛрдбрд┐рдВрдЧред BitNET рдореЙрдбрд▓ 1-рдмрд┐рдЯ рд╕рдВрдЪрд╛рд▓рди рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рдЕрдиреБрдорд╛рди рдХрд░реНрдиреЗрд▓ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИред

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдПрдХреАрдХрд░рдг**: OpenAI-рд╕рдВрдЧрдд API рдПрдВрдбрдкреЙрдЗрдВрдЯреНрд╕, Kubernetes рддреИрдирд╛рддреА рд╕рдорд░реНрдерди, рдирд┐рдЧрд░рд╛рдиреА рдФрд░ рдЕрд╡рд▓реЛрдХрди рдПрдХреАрдХрд░рдг, рдФрд░ рдСрдЯреЛ-рд╕реНрдХреЗрд▓рд┐рдВрдЧ рдХреНрд╖рдорддрд╛рдПрдБ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рддреИрдирд╛рддреА рд╕рдорд╛рдзрд╛рди рдкреНрд░рджрд╛рди рдХрд░рддреА рд╣реИрдВред

### Foundry Local: Microsoft рдХрд╛ рдПрдЬ рд╕рдорд╛рдзрд╛рди

Foundry Local рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рдкрдХ рдПрдЬ рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рдПрдБ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╕реБрд╡рд┐рдзрд╛рдПрдБ**: рдСрдлрд╝рд▓рд╛рдЗрди-рдкреНрд░рдердо рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдбрд┐рдЬрд╝рд╛рдЗрди рд╕рдВрд╕рд╛рдзрди рдмрд╛рдзрд╛ рдЕрдиреБрдХреВрд▓рди, рд╕реНрдерд╛рдиреАрдп рдореЙрдбрд▓ рд░рдЬрд┐рд╕реНрдЯреНрд░реА рдкреНрд░рдмрдВрдзрди, рдФрд░ рдПрдЬ-рд╕реЗ-рдХреНрд▓рд╛рдЙрдб рд╕рд┐рдВрдХреНрд░реЛрдирд╛рдЗрдЬрд╝реЗрд╢рди рдХреНрд╖рдорддрд╛рдПрдБ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рдПрдЬ рддреИрдирд╛рддреА рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддреА рд╣реИрдВред

**рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рдЕрдиреБрдкрд╛рд▓рди**: рдЧреЛрдкрдиреАрдпрддрд╛ рд╕рдВрд░рдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдбреЗрдЯрд╛ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг, рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдВрддреНрд░рдг, рдСрдбрд┐рдЯ рд▓реЙрдЧрд┐рдВрдЧ рдФрд░ рдЕрдиреБрдкрд╛рд▓рди рд░рд┐рдкреЛрд░реНрдЯрд┐рдВрдЧ, рдФрд░ рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдкрд╣реБрдВрдЪ рдкреНрд░рдмрдВрдзрди рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рдкрдХ рд╕реБрд░рдХреНрд╖рд╛ рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред

## SLM рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдХреЗ рд▓рд┐рдП рд╕рд░реНрд╡реЛрддреНрддрдо рдкреНрд░рдерд╛рдПрдБ

### рдореЙрдбрд▓ рдЪрдпрди рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢

рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП SLMs рдХрд╛ рдЪрдпрди рдХрд░рддреЗ рд╕рдордп рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдХрд╛рд░рдХреЛрдВ рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░реЗрдВ:

**рдкреИрд░рд╛рдореАрдЯрд░ рдЧрдгрдирд╛ рд╡рд┐рдЪрд╛рд░**: рдЕрд▓реНрдЯреНрд░рд╛-рд▓рд╛рдЗрдЯрд╡реЗрдЯ рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП Qwen3-0.6B рдЬреИрд╕реЗ рдорд╛рдЗрдХреНрд░реЛ SLMs рдЪреБрдиреЗрдВ, рд╕рдВрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП Qwen3-1.7B рдпрд╛ Google Gemma3 рдЬреИрд╕реЗ рдЫреЛрдЯреЗ SLMs, рдФрд░ рджрдХреНрд╖рддрд╛ рдмрдирд╛рдП рд░рдЦрддреЗ рд╣реБрдП LLM рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рдХрд░реАрдм рдкрд╣реБрдВрдЪрдиреЗ рдХреЗ рд▓рд┐рдП Phi-4-mini-3.8B рдпрд╛ Qwen3-4B рдЬреИрд╕реЗ рдордзреНрдпрдо SLMsред BitNET рдореЙрдбрд▓ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╢реЛрдз рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдЕрд▓реНрдЯреНрд░рд╛-рд╕рдВрдкреАрдбрд╝рди рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред

**рдЙрдкрдпреЛрдЧ рдХреЗрд╕ рд╕рдВрд░реЗрдЦрдг**: рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЧреБрдгрд╡рддреНрддрд╛, рдЕрдиреБрдорд╛рди рдЧрддрд┐, рдореЗрдореЛрд░реА рдмрд╛рдзрд╛рдУрдВ, рдФрд░ рдСрдлрд╝рд▓рд╛рдЗрди рд╕рдВрдЪрд╛рд▓рди рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдЬреИрд╕реЗ рдХрд╛рд░рдХреЛрдВ рдХреЛ рдзреНрдпрд╛рди рдореЗрдВ рд░рдЦрддреЗ рд╣реБрдП рдореЙрдбрд▓ рдХреНрд╖рдорддрд╛рдУрдВ рдХреЛ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдПрдкреНрд▓рд┐рдХреЗрд╢рди рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рд╕реЗ рдорд┐рд▓рд╛рдПрдВред

### рдЕрдиреБрдХреВрд▓рди рд░рдгрдиреАрддрд┐ рдЪрдпрди

**рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рджреГрд╖реНрдЯрд┐рдХреЛрдг**: рдЧреБрдгрд╡рддреНрддрд╛ рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдФрд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдмрд╛рдзрд╛рдУрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдЙрдкрдпреБрдХреНрдд рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░реЛрдВ рдХрд╛ рдЪрдпрди рдХрд░реЗрдВред рдЕрдзрд┐рдХрддрдо рд╕рдВрдкреА

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпрд╣ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдиреБрд╡рд╛рджрд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред рдЬрдмрдХрд┐ рд╣рдо рд╕рдЯреАрдХрддрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ, рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рдж рдореЗрдВ рддреНрд░реБрдЯрд┐рдпрд╛рдВ рдпрд╛ рдЕрд╢реБрджреНрдзрд┐рдпрд╛рдВ рд╣реЛ рд╕рдХрддреА рд╣реИрдВред рдореВрд▓ рднрд╛рд╖рд╛ рдореЗрдВ рдЙрдкрд▓рдмреНрдз рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЛ рдкреНрд░рд╛рдорд╛рдгрд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд╛ рдЬрд╛рдирд╛ рдЪрд╛рд╣рд┐рдПред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП, рдкреЗрд╢реЗрд╡рд░ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢ рдХреА рдЬрд╛рддреА рд╣реИред рдЗрд╕ рдЕрдиреБрд╡рд╛рдж рдХреЗ рдЙрдкрдпреЛрдЧ рд╕реЗ рдЙрддреНрдкрдиреНрди рдХрд┐рд╕реА рднреА рдЧрд▓рддрдлрд╣рдореА рдпрд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛ рдХреЗ рд▓рд┐рдП рд╣рдо рдЙрддреНрддрд░рджрд╛рдпреА рдирд╣реАрдВ рд╣реИрдВред