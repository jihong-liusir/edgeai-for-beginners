<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-17T15:56:29+00:00",
  "source_file": "Module03/README.md",
  "language_code": "hi"
}
-->
# अध्याय 03: छोटे भाषा मॉडल (SLMs) की तैनाती

यह व्यापक अध्याय छोटे भाषा मॉडल (SLMs) की तैनाती के पूरे जीवनचक्र की पड़ताल करता है, जिसमें सैद्धांतिक नींव, व्यावहारिक कार्यान्वयन रणनीतियाँ, और उत्पादन-तैयार कंटेनरीकृत समाधान शामिल हैं। अध्याय को तीन प्रगतिशील खंडों में संरचित किया गया है, जो पाठकों को बुनियादी अवधारणाओं से लेकर उन्नत तैनाती परिदृश्यों तक ले जाते हैं।

## अध्याय की संरचना और सीखने की यात्रा

### **[खंड 1: SLM उन्नत अध्ययन - नींव और अनुकूलन](./01.SLMAdvancedLearning.md)**
प्रारंभिक खंड छोटे भाषा मॉडल को समझने और एज एआई तैनाती में उनकी रणनीतिक महत्ता की सैद्धांतिक नींव स्थापित करता है। इस खंड में शामिल हैं:

- **पैरामीटर वर्गीकरण ढांचा**: माइक्रो SLMs (100M-1.4B पैरामीटर) से लेकर मीडियम SLMs (14B-30B पैरामीटर) तक के SLM श्रेणियों की विस्तृत पड़ताल, जैसे Phi-4-mini-3.8B, Qwen3 श्रृंखला, और Google Gemma3 मॉडल, जिसमें प्रत्येक मॉडल स्तर के लिए हार्डवेयर आवश्यकताओं और मेमोरी उपयोग का विश्लेषण शामिल है
- **उन्नत अनुकूलन तकनीकें**: Llama.cpp, Microsoft Olive, और Apple MLX फ्रेमवर्क का उपयोग करके क्वांटाइज़ेशन विधियों का व्यापक कवरेज, जिसमें BitNET 1-बिट क्वांटाइज़ेशन के नवीनतम उदाहरण और क्वांटाइज़ेशन पाइपलाइनों और बेंचमार्किंग परिणामों के व्यावहारिक कोड उदाहरण शामिल हैं
- **मॉडल अधिग्रहण रणनीतियाँ**: एंटरप्राइज़-ग्रेड SLM तैनाती के लिए Hugging Face इकोसिस्टम और Azure AI Foundry Model Catalog का गहन विश्लेषण, जिसमें प्रोग्रामेटिक मॉडल डाउनलोडिंग, सत्यापन और प्रारूप रूपांतरण के कोड नमूने शामिल हैं
- **डेवलपर APIs**: Python, C++, और C# में कोड उदाहरण, जो दिखाते हैं कि मॉडल कैसे लोड करें, अनुमान लगाएं, और PyTorch, TensorFlow, और ONNX Runtime जैसे लोकप्रिय फ्रेमवर्क के साथ एकीकृत करें

यह बुनियादी खंड ऑपरेशनल दक्षता, तैनाती लचीलापन, और लागत-प्रभावशीलता के बीच संतुलन पर जोर देता है, जो SLMs को एज कंप्यूटिंग परिदृश्यों के लिए आदर्श बनाता है, और व्यावहारिक कोड उदाहरण प्रदान करता है जिन्हें डेवलपर्स सीधे अपने प्रोजेक्ट्स में लागू कर सकते हैं।

### **[खंड 2: स्थानीय वातावरण तैनाती - गोपनीयता-प्रथम समाधान](./02.DeployingSLMinLocalEnv.md)**
दूसरा खंड सिद्धांत से व्यावहारिक कार्यान्वयन की ओर बढ़ता है, स्थानीय तैनाती रणनीतियों पर ध्यान केंद्रित करता है जो डेटा संप्रभुता और परिचालन स्वतंत्रता को प्राथमिकता देते हैं। मुख्य क्षेत्र शामिल हैं:

- **Ollama यूनिवर्सल प्लेटफ़ॉर्म**: क्रॉस-प्लेटफ़ॉर्म तैनाती की व्यापक पड़ताल, जिसमें डेवलपर-अनुकूल वर्कफ़्लो, मॉडल जीवनचक्र प्रबंधन, और Modelfiles के माध्यम से अनुकूलन शामिल है, जिसमें REST API एकीकरण के पूर्ण उदाहरण और CLI स्वचालन स्क्रिप्ट शामिल हैं
- **Microsoft Foundry Local**: ONNX-आधारित अनुकूलन, Windows ML एकीकरण, और व्यापक सुरक्षा सुविधाओं के साथ एंटरप्राइज़-ग्रेड तैनाती समाधान, जिसमें मूल एप्लिकेशन एकीकरण के लिए C# और Python कोड उदाहरण शामिल हैं
- **तुलनात्मक विश्लेषण**: तकनीकी आर्किटेक्चर, प्रदर्शन विशेषताओं, और उपयोग केस अनुकूलन दिशानिर्देशों को कवर करने वाले विस्तृत फ्रेमवर्क की तुलना, जिसमें विभिन्न हार्डवेयर पर अनुमान गति और मेमोरी उपयोग का मूल्यांकन करने के लिए बेंचमार्क कोड शामिल है
- **API एकीकरण**: स्थानीय SLM तैनाती का उपयोग करके वेब सेवाएँ, चैट एप्लिकेशन, और डेटा प्रोसेसिंग पाइपलाइन बनाने के तरीके दिखाने वाले नमूना एप्लिकेशन, Node.js, Python Flask/FastAPI, और ASP.NET Core में कोड उदाहरणों के साथ
- **परीक्षण फ्रेमवर्क**: मॉडल गुणवत्ता आश्वासन के लिए स्वचालित परीक्षण दृष्टिकोण, जिसमें SLM कार्यान्वयन के लिए यूनिट और इंटीग्रेशन परीक्षण के उदाहरण शामिल हैं

यह खंड उन संगठनों के लिए व्यावहारिक मार्गदर्शन प्रदान करता है जो गोपनीयता-संरक्षण एआई समाधान लागू करना चाहते हैं, जबकि अपने तैनाती वातावरण पर पूर्ण नियंत्रण बनाए रखते हैं, और तैयार-उपयोग कोड नमूने प्रदान करता है जिन्हें डेवलपर्स अपनी विशिष्ट आवश्यकताओं के अनुसार अनुकूलित कर सकते हैं।

### **[खंड 3: कंटेनरीकृत क्लाउड तैनाती - उत्पादन-स्तरीय समाधान](./03.DeployingSLMinCloud.md)**
अंतिम खंड उन्नत कंटेनरीकृत तैनाती रणनीतियों में परिणत होता है, जिसमें Microsoft के Phi-4-mini-instruct को प्राथमिक केस स्टडी के रूप में दिखाया गया है। इस खंड में शामिल हैं:

- **vLLM तैनाती**: OpenAI-संगत APIs, उन्नत GPU त्वरण, और उत्पादन-ग्रेड कॉन्फ़िगरेशन के साथ उच्च-प्रदर्शन अनुमान अनुकूलन, जिसमें पूर्ण Dockerfiles, Kubernetes मैनिफेस्ट, और प्रदर्शन ट्यूनिंग पैरामीटर शामिल हैं
- **Ollama कंटेनर ऑर्केस्ट्रेशन**: Docker Compose के साथ सरलीकृत तैनाती वर्कफ़्लो, मॉडल अनुकूलन वेरिएंट, और वेब UI एकीकरण, स्वचालित तैनाती और परीक्षण के लिए CI/CD पाइपलाइन उदाहरणों के साथ
- **ONNX Runtime कार्यान्वयन**: व्यापक मॉडल रूपांतरण, क्वांटाइज़ेशन रणनीतियों, और क्रॉस-प्लेटफ़ॉर्म संगतता के साथ एज-ऑप्टिमाइज़्ड तैनाती, जिसमें मॉडल अनुकूलन और तैनाती के लिए विस्तृत कोड नमूने शामिल हैं
- **निगरानी और अवलोकन**: SLM प्रदर्शन निगरानी के लिए कस्टम मेट्रिक्स के साथ Prometheus/Grafana डैशबोर्ड का कार्यान्वयन, जिसमें अलर्टिंग कॉन्फ़िगरेशन और लॉग एग्रीगेशन शामिल हैं
- **लोड बैलेंसिंग और स्केलिंग**: CPU/GPU उपयोग और अनुरोध पैटर्न के आधार पर ऑटोस्केलिंग कॉन्फ़िगरेशन के साथ क्षैतिज और ऊर्ध्वाधर स्केलिंग रणनीतियों के व्यावहारिक उदाहरण
- **सुरक्षा सुदृढ़ीकरण**: कंटेनर सुरक्षा सर्वोत्तम प्रथाएँ, जिनमें विशेषाधिकार में कमी, नेटवर्क नीतियाँ, और API कुंजियों और मॉडल एक्सेस क्रेडेंशियल्स के लिए सीक्रेट प्रबंधन शामिल हैं

प्रत्येक तैनाती दृष्टिकोण को पूर्ण कॉन्फ़िगरेशन उदाहरण, परीक्षण प्रक्रियाएँ, उत्पादन तत्परता चेकलिस्ट, और इंफ्रास्ट्रक्चर-एज़-कोड टेम्पलेट्स के साथ प्रस्तुत किया गया है, जिन्हें डेवलपर्स अपनी तैनाती वर्कफ़्लो में सीधे लागू कर सकते हैं।

## प्रमुख सीखने के परिणाम

इस अध्याय को पूरा करके पाठक निम्नलिखित में निपुण हो जाएंगे:

1. **रणनीतिक मॉडल चयन**: संसाधन बाधाओं और प्रदर्शन आवश्यकताओं के आधार पर उपयुक्त SLMs का चयन करना
2. **अनुकूलन में महारत**: विभिन्न फ्रेमवर्क में उन्नत क्वांटाइज़ेशन तकनीकों को लागू करना ताकि प्रदर्शन-दक्षता संतुलन प्राप्त हो सके
3. **तैनाती लचीलापन**: संगठनात्मक आवश्यकताओं के आधार पर स्थानीय गोपनीयता-केंद्रित समाधान और स्केलेबल कंटेनरीकृत तैनाती के बीच चयन करना
4. **उत्पादन तत्परता**: एंटरप्राइज़-ग्रेड SLM तैनाती के लिए निगरानी, सुरक्षा, और स्केलिंग सिस्टम को कॉन्फ़िगर करना

## व्यावहारिक ध्यान और वास्तविक-विश्व अनुप्रयोग

अध्याय पूरे समय एक मजबूत व्यावहारिक दृष्टिकोण बनाए रखता है, जिसमें शामिल हैं:

- **हैंड्स-ऑन उदाहरण**: पूर्ण कॉन्फ़िगरेशन फ़ाइलें, API परीक्षण प्रक्रियाएँ, और तैनाती स्क्रिप्ट
- **प्रदर्शन बेंचमार्किंग**: अनुमान गति, मेमोरी उपयोग, और संसाधन आवश्यकताओं की विस्तृत तुलना
- **सुरक्षा विचार**: एंटरप्राइज़-ग्रेड सुरक्षा प्रथाएँ, अनुपालन ढांचे, और डेटा सुरक्षा रणनीतियाँ
- **सर्वोत्तम प्रथाएँ**: निगरानी, स्केलिंग, और रखरखाव के लिए उत्पादन-सिद्ध दिशानिर्देश

## भविष्य के लिए तैयार दृष्टिकोण

अध्याय उभरते रुझानों पर दूरदर्शी अंतर्दृष्टि के साथ समाप्त होता है, जिसमें शामिल हैं:

- बेहतर दक्षता अनुपात के साथ उन्नत मॉडल आर्किटेक्चर
- विशेष एआई त्वरकों के साथ गहरा हार्डवेयर एकीकरण
- मानकीकरण और इंटरऑपरेबिलिटी की ओर इकोसिस्टम का विकास
- गोपनीयता और अनुपालन आवश्यकताओं द्वारा संचालित एंटरप्राइज़ अपनाने के पैटर्न

यह व्यापक दृष्टिकोण सुनिश्चित करता है कि पाठक न केवल वर्तमान SLM तैनाती चुनौतियों को नेविगेट करने में सक्षम हैं, बल्कि भविष्य के तकनीकी विकास के लिए भी तैयार हैं, और अपने विशिष्ट संगठनात्मक आवश्यकताओं और बाधाओं के साथ संरेखित सूचित निर्णय ले सकते हैं।

यह अध्याय तत्काल कार्यान्वयन के लिए एक व्यावहारिक मार्गदर्शिका और दीर्घकालिक एआई तैनाती योजना के लिए एक रणनीतिक संसाधन दोनों के रूप में कार्य करता है, जो सफल SLM तैनाती को परिभाषित करने वाली क्षमता, दक्षता, और परिचालन उत्कृष्टता के बीच महत्वपूर्ण संतुलन पर जोर देता है।

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।