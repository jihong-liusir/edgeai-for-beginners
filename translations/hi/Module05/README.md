<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2db7a2f6e9873c3cd09fea6736bf360b",
  "translation_date": "2025-09-17T15:48:40+00:00",
  "source_file": "Module05/README.md",
  "language_code": "hi"
}
-->
# अध्याय 05 : SLMOps - छोटे भाषा मॉडल संचालन के लिए व्यापक मार्गदर्शिका

## परिचय

SLMOps (छोटे भाषा मॉडल संचालन) AI तैनाती के लिए एक क्रांतिकारी दृष्टिकोण है जो दक्षता, लागत-प्रभावशीलता, और एज कंप्यूटिंग क्षमताओं को प्राथमिकता देता है। यह व्यापक मार्गदर्शिका SLM संचालन के पूरे जीवनचक्र को कवर करती है, जिसमें मूलभूत अवधारणाओं को समझने से लेकर उत्पादन-तैयार तैनाती तक शामिल है।

---

## [अनुभाग 1: SLMOps का परिचय](./01.IntroduceSLMOps.md)

**एज पर AI संचालन में क्रांति लाना**

यह मूलभूत अध्याय पारंपरिक बड़े पैमाने पर AI संचालन से छोटे भाषा मॉडल संचालन (SLMOps) में बदलाव को प्रस्तुत करता है। आप जानेंगे कि SLMOps कैसे AI को बड़े पैमाने पर तैनात करने की महत्वपूर्ण चुनौतियों को हल करता है, साथ ही लागत दक्षता और गोपनीयता अनुपालन बनाए रखता है।

**आप क्या सीखेंगे:**
- आधुनिक AI रणनीति में SLMOps का उदय और महत्व
- कैसे SLM प्रदर्शन और संसाधन दक्षता के बीच की खाई को पाटते हैं
- मुख्य संचालन सिद्धांत, जैसे कि बुद्धिमान संसाधन प्रबंधन और गोपनीयता-प्रथम वास्तुकला
- वास्तविक दुनिया में कार्यान्वयन की चुनौतियां और उनके समाधान
- रणनीतिक व्यावसायिक प्रभाव और प्रतिस्पर्धात्मक लाभ

**मुख्य निष्कर्ष:** SLMOps AI तैनाती को लोकतांत्रिक बनाता है, जिससे उन्नत भाषा प्रसंस्करण क्षमताएं उन संगठनों के लिए सुलभ हो जाती हैं जिनके पास सीमित तकनीकी बुनियादी ढांचा है, जिससे तेज विकास चक्र और अधिक अनुमानित संचालन लागत संभव होती है।

---

## [अनुभाग 2: मॉडल डिस्टिलेशन - सिद्धांत से व्यवहार तक](./02.SLMOps-Distillation.md)

**ज्ञान हस्तांतरण के माध्यम से कुशल मॉडल बनाना**

मॉडल डिस्टिलेशन छोटे, अधिक कुशल मॉडल बनाने की मुख्य तकनीक है जो उनके बड़े समकक्षों के प्रदर्शन को बनाए रखते हैं। यह अध्याय बड़े शिक्षक मॉडलों से छोटे छात्र मॉडलों में ज्ञान स्थानांतरित करने के लिए डिस्टिलेशन वर्कफ़्लो को लागू करने की व्यापक मार्गदर्शिका प्रदान करता है।

**आप क्या सीखेंगे:**
- मॉडल डिस्टिलेशन की मूलभूत अवधारणाएं और लाभ
- दो-चरणीय डिस्टिलेशन प्रक्रिया: सिंथेटिक डेटा निर्माण और छात्र मॉडल प्रशिक्षण
- DeepSeek V3 और Phi-4-mini जैसे अत्याधुनिक मॉडलों का उपयोग करके व्यावहारिक कार्यान्वयन रणनीतियां
- Azure ML डिस्टिलेशन वर्कफ़्लो के साथ हाथों-हाथ उदाहरण
- हाइपरपैरामीटर ट्यूनिंग और मूल्यांकन रणनीतियों के लिए सर्वोत्तम प्रथाएं
- वास्तविक दुनिया के केस स्टडी जो लागत और प्रदर्शन में महत्वपूर्ण सुधार दिखाते हैं

**मुख्य निष्कर्ष:** मॉडल डिस्टिलेशन संगठनों को 85% इन्फ्रेंस समय में कमी और 95% मेमोरी आवश्यकताओं में कमी प्राप्त करने में सक्षम बनाता है, जबकि मूल मॉडल की 92% सटीकता बनाए रखता है, जिससे उन्नत AI क्षमताएं व्यावहारिक रूप से तैनात की जा सकती हैं।

---

## [अनुभाग 3: फाइन-ट्यूनिंग - विशिष्ट कार्यों के लिए मॉडल को अनुकूलित करना](./03.SLMOps-Finetuing.md)

**पूर्व-प्रशिक्षित मॉडलों को आपकी अनूठी आवश्यकताओं के लिए अनुकूलित करना**

फाइन-ट्यूनिंग सामान्य-उद्देश्य वाले मॉडलों को विशेष समाधान में बदल देता है जो आपके विशिष्ट उपयोग मामलों और डोमेन के लिए तैयार होते हैं। यह अध्याय बुनियादी पैरामीटर समायोजन से लेकर LoRA और QLoRA जैसी उन्नत तकनीकों तक मॉडल अनुकूलन के लिए सब कुछ कवर करता है।

**आप क्या सीखेंगे:**
- फाइन-ट्यूनिंग पद्धतियों और उनके अनुप्रयोगों का व्यापक अवलोकन
- फाइन-ट्यूनिंग के विभिन्न प्रकार: पूर्ण फाइन-ट्यूनिंग, पैरामीटर-कुशल फाइन-ट्यूनिंग (PEFT), और कार्य-विशिष्ट दृष्टिकोण
- Microsoft Olive का उपयोग करके हाथों-हाथ कार्यान्वयन के व्यावहारिक उदाहरण
- मल्टी-एडाप्टर प्रशिक्षण और हाइपरपैरामीटर अनुकूलन जैसी उन्नत तकनीकें
- डेटा तैयारी, प्रशिक्षण कॉन्फ़िगरेशन, और संसाधन प्रबंधन के लिए सर्वोत्तम प्रथाएं
- सामान्य चुनौतियां और सफल फाइन-ट्यूनिंग परियोजनाओं के लिए सिद्ध समाधान

**मुख्य निष्कर्ष:** Microsoft Olive जैसे उपकरणों के साथ फाइन-ट्यूनिंग संगठनों को पूर्व-प्रशिक्षित मॉडलों को विशिष्ट आवश्यकताओं के लिए कुशलतापूर्वक अनुकूलित करने में सक्षम बनाता है, प्रदर्शन और संसाधन बाधाओं के लिए अनुकूलित करते हुए, जिससे विविध अनुप्रयोगों में अत्याधुनिक AI सुलभ हो जाता है।

---

## [अनुभाग 4: तैनाती - उत्पादन-तैयार मॉडल कार्यान्वयन](./04.SLMOps.Deployment.md)

**Foundry Local के साथ फाइन-ट्यून किए गए मॉडलों को उत्पादन में लाना**

अंतिम अध्याय महत्वपूर्ण तैनाती चरण पर केंद्रित है, जिसमें मॉडल रूपांतरण, क्वांटाइजेशन, और उत्पादन कॉन्फ़िगरेशन शामिल हैं। आप सीखेंगे कि Foundry Local का उपयोग करके फाइन-ट्यून किए गए क्वांटाइज्ड मॉडलों को कैसे तैनात करें ताकि प्रदर्शन और संसाधन उपयोग को अनुकूलित किया जा सके।

**आप क्या सीखेंगे:**
- संपूर्ण पर्यावरण सेटअप और टूल इंस्टॉलेशन प्रक्रियाएं
- विभिन्न तैनाती परिदृश्यों के लिए मॉडल रूपांतरण और क्वांटाइजेशन तकनीकें
- मॉडल-विशिष्ट अनुकूलन के साथ Foundry Local तैनाती कॉन्फ़िगरेशन
- प्रदर्शन बेंचमार्किंग और गुणवत्ता सत्यापन पद्धतियां
- सामान्य तैनाती समस्याओं का समाधान और अनुकूलन रणनीतियां
- उत्पादन निगरानी और रखरखाव के सर्वोत्तम प्रथाएं

**मुख्य निष्कर्ष:** क्वांटाइजेशन तकनीकों के साथ उचित तैनाती कॉन्फ़िगरेशन 75% आकार में कमी प्राप्त कर सकता है, जबकि स्वीकार्य मॉडल गुणवत्ता बनाए रखता है, जिससे विभिन्न हार्डवेयर कॉन्फ़िगरेशन में कुशल उत्पादन तैनाती संभव होती है।

---

## शुरुआत करें

यह मार्गदर्शिका आपको SLMOps की पूरी यात्रा के माध्यम से ले जाने के लिए डिज़ाइन की गई है, जिसमें मूलभूत अवधारणाओं को समझने से लेकर उत्पादन-तैयार तैनाती तक शामिल है। प्रत्येक अध्याय पिछले अध्याय पर आधारित है, जो सैद्धांतिक समझ और व्यावहारिक कार्यान्वयन कौशल दोनों प्रदान करता है।

चाहे आप एक डेटा वैज्ञानिक हों जो मॉडल तैनाती को अनुकूलित करना चाहते हैं, एक DevOps इंजीनियर जो AI संचालन को लागू कर रहा है, या एक तकनीकी नेता जो अपने संगठन के लिए SLMOps का मूल्यांकन कर रहा है, यह व्यापक मार्गदर्शिका छोटे भाषा मॉडल संचालन को सफलतापूर्वक लागू करने के लिए आवश्यक ज्ञान और उपकरण प्रदान करती है।

**शुरू करने के लिए तैयार हैं?** अध्याय 1 से शुरू करें ताकि SLMOps के मूलभूत सिद्धांतों को समझा जा सके और उन्नत कार्यान्वयन तकनीकों के लिए आधार तैयार किया जा सके, जो अगले अध्यायों में कवर किए गए हैं।

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।