<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T15:53:46+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "hi"
}
-->
# अनुभाग 3: फाइन-ट्यूनिंग - विशिष्ट कार्यों के लिए मॉडल को अनुकूलित करना

## सामग्री सूची
1. [फाइन-ट्यूनिंग का परिचय](../../../Module05)
2. [फाइन-ट्यूनिंग क्यों महत्वपूर्ण है](../../../Module05)
3. [फाइन-ट्यूनिंग के प्रकार](../../../Module05)
4. [Microsoft Olive के साथ फाइन-ट्यूनिंग](../../../Module05)
5. [व्यावहारिक उदाहरण](../../../Module05)
6. [सर्वोत्तम प्रथाएं और दिशानिर्देश](../../../Module05)
7. [उन्नत तकनीकें](../../../Module05)
8. [मूल्यांकन और निगरानी](../../../Module05)
9. [सामान्य चुनौतियां और समाधान](../../../Module05)
10. [निष्कर्ष](../../../Module05)

## फाइन-ट्यूनिंग का परिचय

**फाइन-ट्यूनिंग** एक शक्तिशाली मशीन लर्निंग तकनीक है, जिसमें पहले से प्रशिक्षित मॉडल को विशिष्ट कार्यों या विशेष डेटासेट के साथ काम करने के लिए अनुकूलित किया जाता है। मॉडल को शुरू से प्रशिक्षित करने के बजाय, फाइन-ट्यूनिंग पहले से प्रशिक्षित मॉडल द्वारा सीखे गए ज्ञान का उपयोग करता है और इसे आपके विशेष उपयोग के लिए समायोजित करता है।

### फाइन-ट्यूनिंग क्या है?

फाइन-ट्यूनिंग **ट्रांसफर लर्निंग** का एक रूप है, जिसमें आप:
- एक पहले से प्रशिक्षित मॉडल से शुरुआत करते हैं, जिसने बड़े डेटासेट से सामान्य पैटर्न सीखे हैं
- अपने विशेष डेटासेट का उपयोग करके मॉडल के आंतरिक पैरामीटर समायोजित करते हैं
- मूल्यवान ज्ञान को बनाए रखते हुए मॉडल को आपके कार्य के लिए विशेषज्ञ बनाते हैं

इसे ऐसे समझें जैसे एक कुशल शेफ को नई रसोई शैली सिखाना - वे पहले से ही खाना पकाने की मूल बातें समझते हैं, लेकिन उन्हें नई तकनीकों और स्वादों को सीखने की आवश्यकता होती है।

### मुख्य लाभ

- **समय की बचत**: शुरू से प्रशिक्षण की तुलना में काफी तेज़
- **डेटा की बचत**: अच्छे प्रदर्शन के लिए छोटे डेटासेट की आवश्यकता होती है
- **लागत प्रभावी**: कम कंप्यूटेशनल आवश्यकताएं
- **बेहतर प्रदर्शन**: अक्सर शुरू से प्रशिक्षण की तुलना में बेहतर परिणाम प्राप्त करता है
- **संसाधन अनुकूलन**: छोटे टीमों और संगठनों के लिए शक्तिशाली AI को सुलभ बनाता है

## फाइन-ट्यूनिंग क्यों महत्वपूर्ण है

### वास्तविक दुनिया में उपयोग

फाइन-ट्यूनिंग कई परिदृश्यों में आवश्यक है:

**1. डोमेन अनुकूलन**
- मेडिकल AI: सामान्य भाषा मॉडल को चिकित्सा शब्दावली और क्लिनिकल नोट्स के लिए अनुकूलित करना
- लीगल टेक: कानूनी दस्तावेजों के विश्लेषण और अनुबंध समीक्षा के लिए मॉडल को विशेषज्ञ बनाना
- वित्तीय सेवाएं: वित्तीय रिपोर्ट विश्लेषण और जोखिम आकलन के लिए मॉडल को अनुकूलित करना

**2. कार्य विशेषज्ञता**
- सामग्री निर्माण: विशिष्ट लेखन शैली या टोन के लिए फाइन-ट्यूनिंग
- कोड निर्माण: विशेष प्रोग्रामिंग भाषाओं या फ्रेमवर्क के लिए मॉडल को अनुकूलित करना
- अनुवाद: विशिष्ट भाषा जोड़ों या तकनीकी डोमेन के लिए प्रदर्शन सुधारना

**3. कॉर्पोरेट अनुप्रयोग**
- ग्राहक सेवा: चैटबॉट्स बनाना जो कंपनी-विशिष्ट शब्दावली को समझते हैं
- आंतरिक दस्तावेज़ीकरण: AI सहायक बनाना जो संगठनात्मक प्रक्रियाओं से परिचित हों
- उद्योग-विशिष्ट समाधान: ऐसे मॉडल विकसित करना जो क्षेत्र-विशिष्ट शब्दावली और वर्कफ़्लो को समझते हों

## फाइन-ट्यूनिंग के प्रकार

### 1. पूर्ण फाइन-ट्यूनिंग (इंस्ट्रक्शन फाइन-ट्यूनिंग)

पूर्ण फाइन-ट्यूनिंग में प्रशिक्षण के दौरान सभी मॉडल पैरामीटर अपडेट किए जाते हैं। यह दृष्टिकोण:
- अधिकतम लचीलापन और प्रदर्शन क्षमता प्रदान करता है
- महत्वपूर्ण कंप्यूटेशनल संसाधनों की आवश्यकता होती है
- मॉडल का पूरी तरह से नया संस्करण बनाता है
- उन परिदृश्यों के लिए सबसे अच्छा है जहां आपके पास पर्याप्त प्रशिक्षण डेटा और कंप्यूटेशनल संसाधन हैं

### 2. पैरामीटर-कुशल फाइन-ट्यूनिंग (PEFT)

PEFT विधियां केवल एक छोटे पैरामीटर सेट को अपडेट करती हैं, जिससे प्रक्रिया अधिक कुशल बनती है:

#### लो-रैंक अनुकूलन (LoRA)
- मौजूदा वज़न में छोटे ट्रेन योग्य रैंक डीकंपोज़िशन मैट्रिक्स जोड़ता है
- ट्रेन योग्य पैरामीटर की संख्या को नाटकीय रूप से कम करता है
- प्रदर्शन को पूर्ण फाइन-ट्यूनिंग के करीब बनाए रखता है
- विभिन्न अनुकूलनों के बीच आसानी से स्विच करने में सक्षम बनाता है

#### QLoRA (क्वांटाइज़्ड LoRA)
- LoRA को क्वांटाइज़ेशन तकनीकों के साथ जोड़ता है
- मेमोरी आवश्यकताओं को और कम करता है
- उपभोक्ता हार्डवेयर पर बड़े मॉडल का फाइन-ट्यूनिंग सक्षम करता है
- दक्षता और प्रदर्शन के बीच संतुलन बनाता है

#### एडॉप्टर्स
- मौजूदा लेयरों के बीच छोटे न्यूरल नेटवर्क डालता है
- बेस मॉडल को स्थिर रखते हुए लक्षित फाइन-ट्यूनिंग की अनुमति देता है
- मॉडल अनुकूलन के लिए मॉड्यूलर दृष्टिकोण सक्षम करता है

### 3. कार्य-विशिष्ट फाइन-ट्यूनिंग

विशिष्ट डाउनस्ट्रीम कार्यों के लिए मॉडल को अनुकूलित करने पर केंद्रित:
- **वर्गीकरण**: वर्गीकरण कार्यों के लिए मॉडल को समायोजित करना
- **निर्माण**: सामग्री निर्माण और टेक्स्ट जनरेशन के लिए अनुकूलन
- **निकालना**: जानकारी निकालने और नामित इकाई पहचान के लिए फाइन-ट्यूनिंग
- **सारांश**: दस्तावेज़ सारांश के लिए मॉडल को विशेषज्ञ बनाना

## Microsoft Olive के साथ फाइन-ट्यूनिंग

Microsoft Olive एक व्यापक मॉडल अनुकूलन टूलकिट है, जो फाइन-ट्यूनिंग प्रक्रिया को सरल बनाता है और एंटरप्राइज़-ग्रेड सुविधाएं प्रदान करता है।

### Microsoft Olive क्या है?

Microsoft Olive एक ओपन-सोर्स मॉडल अनुकूलन टूल है, जो:
- विभिन्न हार्डवेयर लक्ष्यों के लिए फाइन-ट्यूनिंग वर्कफ़्लो को सुव्यवस्थित करता है
- लोकप्रिय मॉडल आर्किटेक्चर (Llama, Phi, Qwen, Gemma) के लिए अंतर्निहित समर्थन प्रदान करता है
- क्लाउड और स्थानीय परिनियोजन विकल्प प्रदान करता है
- Azure ML और अन्य Microsoft AI सेवाओं के साथ सहजता से एकीकृत होता है
- स्वचालित अनुकूलन और क्वांटाइज़ेशन का समर्थन करता है

### मुख्य विशेषताएं

- **हार्डवेयर-अनुकूल अनुकूलन**: विशिष्ट हार्डवेयर (CPU, GPU, NPU) के लिए मॉडल को स्वचालित रूप से अनुकूलित करता है
- **मल्टी-फॉर्मेट समर्थन**: PyTorch, Hugging Face, और ONNX मॉडल के साथ काम करता है
- **स्वचालित वर्कफ़्लो**: मैनुअल कॉन्फ़िगरेशन और ट्रायल-एंड-एरर को कम करता है
- **एंटरप्राइज़ एकीकरण**: Azure ML और क्लाउड परिनियोजन के लिए अंतर्निहित समर्थन
- **विस्तार योग्य आर्किटेक्चर**: कस्टम अनुकूलन तकनीकों की अनुमति देता है

### इंस्टॉलेशन और सेटअप

#### बेसिक इंस्टॉलेशन

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### वैकल्पिक डिपेंडेंसी

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### इंस्टॉलेशन सत्यापित करें

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## व्यावहारिक उदाहरण

### उदाहरण 1: Olive CLI के साथ बेसिक फाइन-ट्यूनिंग

यह उदाहरण एक छोटे भाषा मॉडल को वाक्यांश वर्गीकरण के लिए फाइन-ट्यूनिंग का प्रदर्शन करता है:

#### चरण 1: अपना वातावरण तैयार करें

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### चरण 2: मॉडल को फाइन-ट्यून करें

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### चरण 3: परिनियोजन के लिए अनुकूलित करें

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### उदाहरण 2: कस्टम डेटासेट के साथ उन्नत कॉन्फ़िगरेशन

#### चरण 1: कस्टम डेटासेट तैयार करें

अपने प्रशिक्षण डेटा के साथ एक JSON फ़ाइल बनाएं:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### चरण 2: कॉन्फ़िगरेशन फ़ाइल बनाएं

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### चरण 3: फाइन-ट्यूनिंग निष्पादित करें

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### उदाहरण 3: मेमोरी दक्षता के लिए QLoRA फाइन-ट्यूनिंग

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## सर्वोत्तम प्रथाएं और दिशानिर्देश

### डेटा तैयारी

**1. गुणवत्ता मात्रा से अधिक**
- खराब डेटा की बड़ी मात्रा के बजाय उच्च गुणवत्ता और विविध उदाहरणों को प्राथमिकता दें
- सुनिश्चित करें कि डेटा आपके लक्षित उपयोग के मामले का प्रतिनिधित्व करता है
- डेटा को लगातार साफ और पूर्व-प्रक्रिया करें

**2. डेटा प्रारूप और टेम्पलेट**
- सभी प्रशिक्षण उदाहरणों में सुसंगत प्रारूप का उपयोग करें
- स्पष्ट इनपुट-आउटपुट टेम्पलेट बनाएं जो आपके उपयोग के मामले से मेल खाते हों
- इंस्ट्रक्शन-ट्यून किए गए मॉडल के लिए उपयुक्त इंस्ट्रक्शन प्रारूप शामिल करें

**3. डेटासेट विभाजन**
- मान्यता के लिए 10-20% डेटा आरक्षित करें
- ट्रेन/मान्यता विभाजनों में समान वितरण बनाए रखें
- वर्गीकरण कार्यों के लिए स्तरीकृत नमूनाकरण पर विचार करें

### प्रशिक्षण कॉन्फ़िगरेशन

**1. लर्निंग रेट चयन**
- फाइन-ट्यूनिंग के लिए छोटे लर्निंग रेट (1e-5 से 1e-4) से शुरुआत करें
- बेहतर अभिसरण के लिए लर्निंग रेट शेड्यूलिंग का उपयोग करें
- हानि वक्रों की निगरानी करें और दरों को तदनुसार समायोजित करें

**2. बैच आकार अनुकूलन**
- उपलब्ध मेमोरी के साथ बैच आकार को संतुलित करें
- बड़े प्रभावी बैच आकारों के लिए ग्रेडिएंट संचय का उपयोग करें
- बैच आकार और लर्निंग रेट के बीच संबंध पर विचार करें

**3. प्रशिक्षण अवधि**
- ओवरफिटिंग से बचने के लिए मान्यता मेट्रिक्स की निगरानी करें
- जब मान्यता प्रदर्शन स्थिर हो जाए तो जल्दी रोकें
- पुनर्प्राप्ति और विश्लेषण के लिए नियमित रूप से चेकपॉइंट सहेजें

### मॉडल चयन

**1. बेस मॉडल का चयन**
- जब संभव हो तो समान डोमेन पर पहले से प्रशिक्षित मॉडल का चयन करें
- अपने कंप्यूटेशनल बाधाओं के सापेक्ष मॉडल आकार पर विचार करें
- व्यावसायिक उपयोग के लिए लाइसेंसिंग आवश्यकताओं का मूल्यांकन करें

**2. फाइन-ट्यूनिंग विधि का चयन**
- संसाधन-सीमित वातावरण के लिए LoRA/QLoRA का उपयोग करें
- जब अधिकतम प्रदर्शन महत्वपूर्ण हो तो पूर्ण फाइन-ट्यूनिंग चुनें
- कई कार्य परिदृश्यों के लिए एडॉप्टर-आधारित दृष्टिकोण पर विचार करें

### संसाधन प्रबंधन

**1. हार्डवेयर अनुकूलन**
- अपने मॉडल आकार और विधि के लिए उपयुक्त हार्डवेयर चुनें
- ग्रेडिएंट चेकपॉइंटिंग के साथ GPU मेमोरी का कुशलता से उपयोग करें
- बड़े मॉडल के लिए क्लाउड-आधारित समाधान पर विचार करें

**2. मेमोरी प्रबंधन**
- उपलब्ध होने पर मिश्रित सटीकता प्रशिक्षण का उपयोग करें
- मेमोरी बाधाओं के लिए ग्रेडिएंट संचय लागू करें
- प्रशिक्षण के दौरान GPU मेमोरी उपयोग की निगरानी करें

## उन्नत तकनीकें

### मल्टी-एडॉप्टर प्रशिक्षण

मूल मॉडल को साझा करते हुए विभिन्न कार्यों के लिए कई एडॉप्टर प्रशिक्षित करें:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### हाइपरपैरामीटर अनुकूलन

संगठित हाइपरपैरामीटर ट्यूनिंग लागू करें:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### कस्टम लॉस फंक्शन

डोमेन-विशिष्ट लॉस फंक्शन लागू करें:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## मूल्यांकन और निगरानी

### मेट्रिक्स और मूल्यांकन

**1. मानक मेट्रिक्स**
- **सटीकता**: वर्गीकरण कार्यों के लिए समग्र शुद्धता
- **पर्प्लेक्सिटी**: भाषा मॉडलिंग गुणवत्ता माप
- **BLEU/ROUGE**: टेक्स्ट निर्माण और सारांश गुणवत्ता
- **F1 स्कोर**: वर्गीकरण के लिए संतुलित सटीकता और पुनर्प्राप्ति

**2. डोमेन-विशिष्ट मेट्रिक्स**
- **कार्य-विशिष्ट बेंचमार्क**: अपने डोमेन के लिए स्थापित बेंचमार्क का उपयोग करें
- **मानव मूल्यांकन**: व्यक्तिपरक कार्यों के लिए मानव आकलन शामिल करें
- **व्यावसायिक मेट्रिक्स**: वास्तविक व्यावसायिक उद्देश्यों के साथ संरेखित करें

**3. मूल्यांकन सेटअप**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### प्रशिक्षण प्रगति की निगरानी

**1. हानि ट्रैकिंग**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. मान्यता निगरानी**
- प्रशिक्षण हानि के साथ मान्यता हानि को ट्रैक करें
- ओवरफिटिंग के संकेतों की निगरानी करें (मान्यता हानि बढ़ती है जबकि प्रशिक्षण हानि घटती है)
- मान्यता मेट्रिक्स के आधार पर जल्दी रोकें

**3. संसाधन निगरानी**
- GPU/CPU उपयोग की निगरानी करें
- मेमोरी उपयोग पैटर्न ट्रैक करें
- प्रशिक्षण गति और थ्रूपुट की निगरानी करें

## सामान्य चुनौतियां और समाधान

### चुनौती 1: ओवरफिटिंग

**लक्षण:**
- प्रशिक्षण हानि घटती रहती है जबकि मान्यता हानि बढ़ती है
- प्रशिक्षण और मान्यता प्रदर्शन के बीच बड़ा अंतर
- नए डेटा पर खराब सामान्यीकरण

**समाधान:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### चुनौती 2: मेमोरी सीमाएं

**समाधान:**
- ग्रेडिएंट चेकपॉइंटिंग का उपयोग करें
- ग्रेडिएंट संचय लागू करें
- पैरामीटर-कुशल विधियां चुनें (LoRA, QLoRA)
- बड़े मॉडल के लिए मॉडल समानांतरता का उपयोग करें

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### चुनौती 3: धीमा प्रशिक्षण

**समाधान:**
- डेटा लोडिंग पाइपलाइनों को अनुकूलित करें
- मिश्रित सटीकता प्रशिक्षण का उपयोग करें
- कुशल बैचिंग रणनीतियां लागू करें
- बड़े डेटासेट के लिए वितरित प्रशिक्षण पर विचार करें

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### चुनौती 4: खराब प्रदर्शन

**निदान चरण:**
1. डेटा गुणवत्ता और प्रारूप सत्यापित करें
2. लर्निंग रेट और प्रशिक्षण अवधि की जांच करें
3. बेस मॉडल चयन का मूल्यांकन करें
4. पूर्व-प्रसंस्करण और टोकनाइज़ेशन की समीक्षा करें

**समाधान:**
- प्रशिक्षण डेटा विविधता बढ़ाएं
- लर्निंग रेट शेड्यूल समायोजित करें
- विभिन्न बेस मॉडल आज़माएं
- डेटा संवर्धन तकनीकों को लागू करें

## निष्कर्ष

फाइन-ट्यूनिंग एक शक्तिशाली तकनीक है, जो अत्याधुनिक AI क्षमताओं तक पहुंच को लोकतांत्रिक बनाती है। Microsoft Olive जैसे टूल का उपयोग करके, संगठन पहले से प्रशिक्षित मॉडल को अपनी विशिष्ट आवश्यकताओं के अनुसार कुशलतापूर्वक अनुकूलित कर सकते हैं, जबकि प्रदर्शन और संसाधन बाधाओं के लिए अनुकूलन कर सकते हैं।

### मुख्य बातें

1. **सही दृष्टिकोण चुनें**: अपने कंप्यूटेशनल संसाधनों और प्रदर्शन आवश्यकताओं के आधार पर फाइन-ट्यूनिंग विधियों का चयन करें
2. **डेटा गुणवत्ता महत्वपूर्ण है**: उच्च गुणवत्ता, प्रतिनिधि प्रशिक्षण डेटा में निवेश करें
3. **निगरानी और पुनरावृत्ति करें**: अपने मॉडलों का लगातार मूल्यांकन और सुधार करें
4. **टूल का उपयोग करें**: प्रक्रिया को सरल और अनुकूलित करने के लिए Olive जैसे फ्रेमवर्क का उपयोग करें
5. **परिनियोजन पर विचार करें**: शुरुआत से ही मॉडल अनुकूलन और परिनियोजन की योजना बनाएं

## ➡️ आगे क्या करें

- [04: परिनियोजन - उत्पादन-तैयार मॉडल कार्यान्वयन](./04.SLMOps.Deployment.md)

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।