<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-08T22:04:44+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "hi"
}
-->
# рд╡рд░реНрдХрд╢реЙрдк рдиреЛрдЯрдмреБрдХреНрд╕ - рддреНрд╡рд░рд┐рдд рдкреНрд░рд╛рд░рдВрдн рдЧрд╛рдЗрдб

## рд╕рд╛рдордЧреНрд░реА рддрд╛рд▓рд┐рдХрд╛

- [рдкреВрд░реНрд╡ рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдБ](../../../../Workshop/notebooks)
- [рдкреНрд░рд╛рд░рдВрднрд┐рдХ рд╕реЗрдЯрдЕрдк](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ 04: рдореЙрдбрд▓ рддреБрд▓рдирд╛](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ 05: рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрдЯрд░](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ 06: рдЗрд░рд╛рджреЗ-рдЖрдзрд╛рд░рд┐рдд рдореЙрдбрд▓ рд░реВрдЯрд┐рдВрдЧ](../../../../Workshop/notebooks)
- [рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░](../../../../Workshop/notebooks)
- [рд╕рд╛рдорд╛рдиреНрдп рдХрдорд╛рдВрдбреНрд╕](../../../../Workshop/notebooks)

---

## рдкреВрд░реНрд╡ рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдБ

### 1. Foundry Local рдЗрдВрд╕реНрдЯреЙрд▓ рдХрд░реЗрдВ

**Windows:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**рдЗрдВрд╕реНрдЯреЙрд▓реЗрд╢рди рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ:**
```bash
foundry --version
```

### 2. Python рдбрд┐рдкреЗрдВрдбреЗрдВрд╕реА рдЗрдВрд╕реНрдЯреЙрд▓ рдХрд░реЗрдВ

```bash
cd Workshop
pip install -r requirements.txt
```

рдпрд╛ рд╡реНрдпрдХреНрддрд┐рдЧрдд рд░реВрдк рд╕реЗ рдЗрдВрд╕реНрдЯреЙрд▓ рдХрд░реЗрдВ:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## рдкреНрд░рд╛рд░рдВрднрд┐рдХ рд╕реЗрдЯрдЕрдк

### Foundry Local рд╕реЗрд╡рд╛ рд╢реБрд░реВ рдХрд░реЗрдВ

**рдХрд┐рд╕реА рднреА рдиреЛрдЯрдмреБрдХ рдХреЛ рдЪрд▓рд╛рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдЖрд╡рд╢реНрдпрдХ:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ:
```
тЬЕ Service started successfully
Endpoint: http://localhost:59959
```

### рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдФрд░ рд▓реЛрдб рдХрд░реЗрдВ

рдиреЛрдЯрдмреБрдХреНрд╕ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ рдЗрди рдореЙрдбрд▓реЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### рд╕реЗрдЯрдЕрдк рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## рд╕рддреНрд░ 04: рдореЙрдбрд▓ рддреБрд▓рдирд╛

### рдЙрджреНрджреЗрд╢реНрдп
рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLM) рдФрд░ рдмрдбрд╝реЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (LLM) рдХреЗ рдкреНрд░рджрд░реНрд╢рди рдХреА рддреБрд▓рдирд╛ рдХрд░реЗрдВред

### рддреНрд╡рд░рд┐рдд рд╕реЗрдЯрдЕрдк

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдирд╛

1. **рдЦреЛрд▓реЗрдВ** `session04_model_compare.ipynb` VS Code рдпрд╛ Jupyter рдореЗрдВ
2. **рдХрд░реНрдиреЗрд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░реЗрдВ** (Kernel тЖТ Restart Kernel)
3. **рд╕рднреА рд╕реЗрд▓реНрд╕ рдХреНрд░рдо рдореЗрдВ рдЪрд▓рд╛рдПрдБ**

### рдореБрдЦреНрдп рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

**рдбрд┐рдлрд╝реЙрд▓реНрдЯ рдореЙрдбрд▓реНрд╕:**
- **SLM:** `phi-4-mini` (~4GB RAM, рддреЗрдЬрд╝)
- **LLM:** `qwen2.5-3b` (~3GB RAM, рдореЗрдореЛрд░реА-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб)

**рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░ (рд╡реИрдХрд▓реНрдкрд┐рдХ):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

ЁЯТб SLM is 1.99x faster than LLM for this prompt
```

### рдЕрдиреБрдХреВрд▓рди

**рд╡рд┐рднрд┐рдиреНрди рдореЙрдбрд▓реНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**рдХрд╕реНрдЯрдо рдкреНрд░реЙрдореНрдкреНрдЯ:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### рд╕рддреНрдпрд╛рдкрди рдЪреЗрдХрд▓рд┐рд╕реНрдЯ

- [ ] рд╕реЗрд▓ 12 рд╕рд╣реА рдореЙрдбрд▓реНрд╕ рджрд┐рдЦрд╛рддрд╛ рд╣реИ (phi-4-mini, qwen2.5-3b)
- [ ] рд╕реЗрд▓ 12 рд╕рд╣реА рдПрдВрдбрдкреЙрдЗрдВрдЯ рджрд┐рдЦрд╛рддрд╛ рд╣реИ (рдкреЛрд░реНрдЯ 59959)
- [ ] рд╕реЗрд▓ 16 рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рдкрд╛рд╕ рдХрд░рддрд╛ рд╣реИ (тЬЕ рд╕реЗрд╡рд╛ рдЪрд▓ рд░рд╣реА рд╣реИ)
- [ ] рд╕реЗрд▓ 20 рдкреНрд░реА-рдлреНрд▓рд╛рдЗрдЯ рдЪреЗрдХ рдкрд╛рд╕ рдХрд░рддрд╛ рд╣реИ (рджреЛрдиреЛрдВ рдореЙрдбрд▓реНрд╕ рдареАрдХ рд╣реИрдВ)
- [ ] рд╕реЗрд▓ 22 рддреБрд▓рдирд╛ рдкреВрд░реА рд╣реЛрддреА рд╣реИ рд▓реЗрдЯреЗрдВрд╕реА рдорд╛рдиреЛрдВ рдХреЗ рд╕рд╛рде
- [ ] рд╕реЗрд▓ 24 рд╕рддреНрдпрд╛рдкрди рджрд┐рдЦрд╛рддрд╛ рд╣реИ ЁЯОЙ рд╕рднреА рдЪреЗрдХ рдкрд╛рд╕ рд╣реБрдП!

### рд╕рдордп рдЕрдиреБрдорд╛рди
- **рдкрд╣рд▓реА рдмрд╛рд░ рдЪрд▓рд╛рдирд╛:** 5-10 рдорд┐рдирдЯ (рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рд╕рд╣рд┐рдд)
- **рдЕрдЧрд▓реА рдмрд╛рд░ рдЪрд▓рд╛рдирд╛:** 1-2 рдорд┐рдирдЯ

---

## рд╕рддреНрд░ 05: рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрдЯрд░

### рдЙрджреНрджреЗрд╢реНрдп
Foundry Local SDK рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рд╕рд╣рдпреЛрдЧ рдкреНрд░рджрд░реНрд╢рд┐рдд рдХрд░реЗрдВ - рдПрдЬреЗрдВрдЯреНрд╕ рдорд┐рд▓рдХрд░ рдкрд░рд┐рд╖реНрдХреГрдд рдЖрдЙрдЯрдкреБрдЯ рддреИрдпрд╛рд░ рдХрд░рддреЗ рд╣реИрдВред

### рддреНрд╡рд░рд┐рдд рд╕реЗрдЯрдЕрдк

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдирд╛

1. **рдЦреЛрд▓реЗрдВ** `session05_agents_orchestrator.ipynb`
2. **рдХрд░реНрдиреЗрд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░реЗрдВ**
3. **рд╕рднреА рд╕реЗрд▓реНрд╕ рдХреНрд░рдо рдореЗрдВ рдЪрд▓рд╛рдПрдБ**

### рдореБрдЦреНрдп рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

**рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╕реЗрдЯрдЕрдк (рджреЛрдиреЛрдВ рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рд▓рд┐рдП рд╕рдорд╛рди рдореЙрдбрд▓):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**рдЙрдиреНрдирдд рд╕реЗрдЯрдЕрдк (рд╡рд┐рднрд┐рдиреНрди рдореЙрдбрд▓реНрд╕):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░

```
User Question
    тЖУ
Researcher Agent (phi-4-mini)
  тЖТ Gathers bullet points
    тЖУ
Editor Agent (phi-4-mini or qwen2.5-7b)
  тЖТ Refines into executive summary
    тЖУ
Final Output
```

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: тАв Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### рдПрдХреНрд╕рдЯреЗрдВрд╢рди

**рдЕрдзрд┐рдХ рдПрдЬреЗрдВрдЯреНрд╕ рдЬреЛрдбрд╝реЗрдВ:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**рдмреИрдЪ рдкрд░реАрдХреНрд╖рдг:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### рд╕рдордп рдЕрдиреБрдорд╛рди
- **рдкрд╣рд▓реА рдмрд╛рд░ рдЪрд▓рд╛рдирд╛:** 3-5 рдорд┐рдирдЯ
- **рдЕрдЧрд▓реА рдмрд╛рд░ рдЪрд▓рд╛рдирд╛:** рдкреНрд░рддрд┐ рдкреНрд░рд╢реНрди 1-2 рдорд┐рдирдЯ

---

## рд╕рддреНрд░ 06: рдЗрд░рд╛рджреЗ-рдЖрдзрд╛рд░рд┐рдд рдореЙрдбрд▓ рд░реВрдЯрд┐рдВрдЧ

### рдЙрджреНрджреЗрд╢реНрдп
рдкрддрд╛ рд▓рдЧрд╛рдП рдЧрдП рдЗрд░рд╛рджреЗ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдкреНрд░реЙрдореНрдкреНрдЯреНрд╕ рдХреЛ рд╡рд┐рд╢реЗрд╖ рдореЙрдбрд▓реНрд╕ рдХреА рдУрд░ рдмреБрджреНрдзрд┐рдорд╛рдиреА рд╕реЗ рд░реВрдЯ рдХрд░реЗрдВред

### рддреНрд╡рд░рд┐рдд рд╕реЗрдЯрдЕрдк

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**рдиреЛрдЯ:** рд╕рддреНрд░ 06 рдЕрдзрд┐рдХрддрдо рд╕рдВрдЧрддрддрд╛ рдХреЗ рд▓рд┐рдП CPU рдореЙрдбрд▓реНрд╕ рдкрд░ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╣реИред

### рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдирд╛

1. **рдЦреЛрд▓реЗрдВ** `session06_models_router.ipynb`
2. **рдХрд░реНрдиреЗрд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░реЗрдВ**
3. **рд╕рднреА рд╕реЗрд▓реНрд╕ рдХреНрд░рдо рдореЗрдВ рдЪрд▓рд╛рдПрдБ**

### рдореБрдЦреНрдп рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

**рдбрд┐рдлрд╝реЙрд▓реНрдЯ рдХреИрдЯрд▓реЙрдЧ (CPU рдореЙрдбрд▓реНрд╕):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**рд╡реИрдХрд▓реНрдкрд┐рдХ (GPU рдореЙрдбрд▓реНрд╕):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### рдЗрд░рд╛рджрд╛ рдкрд╣рдЪрд╛рди

рд░рд╛рдЙрдЯрд░ рдЗрд░рд╛рджреЗ рдХрд╛ рдкрддрд╛ рд▓рдЧрд╛рдиреЗ рдХреЗ рд▓рд┐рдП regex рдкреИрдЯрд░реНрди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ:

| рдЗрд░рд╛рджрд╛ | рдкреИрдЯрд░реНрди рдЙрджрд╛рд╣рд░рдг | рд░реВрдЯ рдХрд┐рдпрд╛ рдЧрдпрд╛ |
|-------|---------------|-------------|
| `code` | "refactor", "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize", "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize", "tl;dr" | phi-4-mini-cpu |
| `general` | рдЕрдиреНрдп рд╕рднреА | phi-4-mini-cpu |

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
тЬУ Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

тЬУ Success! All prompts routed correctly.
```

### рдЕрдиреБрдХреВрд▓рди

**рдХрд╕реНрдЯрдо рдЗрд░рд╛рджрд╛ рдЬреЛрдбрд╝реЗрдВ:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ч┐╗шпС', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**рдЯреЛрдХрди рдЯреНрд░реИрдХрд┐рдВрдЧ рд╕рдХреНрд╖рдо рдХрд░реЗрдВ:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### GPU рдореЙрдбрд▓реНрд╕ рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░рдирд╛

рдпрджрд┐ рдЖрдкрдХреЗ рдкрд╛рд╕ 8GB+ VRAM рд╣реИ:

1. **рд╕реЗрд▓ #6** рдореЗрдВ, CPU рдХреИрдЯрд▓реЙрдЧ рдХреЛ рдХрдореЗрдВрдЯ рдХрд░реЗрдВ
2. GPU рдХреИрдЯрд▓реЙрдЧ рдХреЛ рдЕрдирдХрдореЗрдВрдЯ рдХрд░реЗрдВ
3. GPU рдореЙрдбрд▓реНрд╕ рд▓реЛрдб рдХрд░реЗрдВ:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. рдХрд░реНрдиреЗрд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░реЗрдВ рдФрд░ рдиреЛрдЯрдмреБрдХ рдлрд┐рд░ рд╕реЗ рдЪрд▓рд╛рдПрдБ

### рд╕рдордп рдЕрдиреБрдорд╛рди
- **рдкрд╣рд▓реА рдмрд╛рд░ рдЪрд▓рд╛рдирд╛:** 5-10 рдорд┐рдирдЯ (рдореЙрдбрд▓ рд▓реЛрдбрд┐рдВрдЧ)
- **рдЕрдЧрд▓реА рдмрд╛рд░ рдЪрд▓рд╛рдирд╛:** рдкреНрд░рддрд┐ рдкрд░реАрдХреНрд╖рдг 30-60 рд╕реЗрдХрдВрдб

---

## рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░

### рд╡реИрд╢реНрд╡рд┐рдХ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

Jupyter/VS Code рд╢реБрд░реВ рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рд╕реЗрдЯ рдХрд░реЗрдВ:

**Windows (Command Prompt):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**Windows (PowerShell):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### рдиреЛрдЯрдмреБрдХ рдореЗрдВ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

рдХрд┐рд╕реА рднреА рдиреЛрдЯрдмреБрдХ рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ рд╕реЗрдЯ рдХрд░реЗрдВ:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## рд╕рд╛рдорд╛рдиреНрдп рдХрдорд╛рдВрдбреНрд╕

### рд╕реЗрд╡рд╛ рдкреНрд░рдмрдВрдзрди

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### рдореЙрдбрд▓ рдкреНрд░рдмрдВрдзрди

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### рдПрдВрдбрдкреЙрдЗрдВрдЯ рдкрд░реАрдХреНрд╖рдг

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рдХрдорд╛рдВрдбреНрд╕

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## рд╕рд░реНрд╡реЛрддреНрддрдо рдкреНрд░рдерд╛рдПрдБ

### рдХрд┐рд╕реА рднреА рдиреЛрдЯрдмреБрдХ рдХреЛ рд╢реБрд░реВ рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ

1. **рдЬрд╛рдБрдЪреЗрдВ рдХрд┐ рд╕реЗрд╡рд╛ рдЪрд▓ рд░рд╣реА рд╣реИ:**
   ```bash
   foundry service status
   ```

2. **рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдореЙрдбрд▓реНрд╕ рд▓реЛрдб рд╣реЛ рдЪреБрдХреЗ рд╣реИрдВ:**
   ```bash
   foundry model ls
   ```

3. **рдиреЛрдЯрдмреБрдХ рдХрд░реНрдиреЗрд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░реЗрдВ** рдпрджрд┐ рдлрд┐рд░ рд╕реЗ рдЪрд▓рд╛ рд░рд╣реЗ рд╣реИрдВ

4. **рд╕рднреА рдЖрдЙрдЯрдкреБрдЯ рд╕рд╛рдлрд╝ рдХрд░реЗрдВ** рдПрдХ рд╕рд╛рдлрд╝ рд░рди рдХреЗ рд▓рд┐рдП

### рд╕рдВрд╕рд╛рдзрди рдкреНрд░рдмрдВрдзрди

1. **рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ CPU рдореЙрдбрд▓реНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ** рд╕рдВрдЧрддрддрд╛ рдХреЗ рд▓рд┐рдП
2. **GPU рдореЙрдбрд▓реНрд╕ рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░реЗрдВ** рдХреЗрд╡рд▓ рдпрджрд┐ рдЖрдкрдХреЗ рдкрд╛рд╕ 8GB+ VRAM рд╣реИ
3. **GPU рдПрдкреНрд▓рд┐рдХреЗрд╢рди рдмрдВрдж рдХрд░реЗрдВ** рдЪрд▓рд╛рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ
4. **рд╕реЗрд╡рд╛ рдЪрд╛рд▓реВ рд░рдЦреЗрдВ** рдиреЛрдЯрдмреБрдХ рд╕рддреНрд░реЛрдВ рдХреЗ рдмреАрдЪ
5. **рд╕рдВрд╕рд╛рдзрди рдЙрдкрдпреЛрдЧ рдХреА рдирд┐рдЧрд░рд╛рдиреА рдХрд░реЗрдВ** Task Manager / nvidia-smi рдХреЗ рд╕рд╛рде

### рд╕рдорд╕реНрдпрд╛ рдирд┐рд╡рд╛рд░рдг

1. **рдХреЛрдб рдбрд┐рдмрдЧ рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рд╣рдореЗрд╢рд╛ рд╕реЗрд╡рд╛ рдХреА рдЬрд╛рдБрдЪ рдХрд░реЗрдВ**
2. **рдХрд░реНрдиреЗрд▓ рд░реАрд╕реНрдЯрд╛рд░реНрдЯ рдХрд░реЗрдВ** рдпрджрд┐ рдкреБрд░рд╛рдиреА рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рджрд┐рдЦрддреА рд╣реИ
3. **рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рд╕реЗрд▓реНрд╕ рдлрд┐рд░ рд╕реЗ рдЪрд▓рд╛рдПрдБ** рдХрд┐рд╕реА рднреА рдмрджрд▓рд╛рд╡ рдХреЗ рдмрд╛рдж
4. **рдореЙрдбрд▓ рдирд╛рдо рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ** рдЬреЛ рд▓реЛрдб рд╣реЛ рдЪреБрдХреЗ рд╣реИрдВ
5. **рдПрдВрдбрдкреЙрдЗрдВрдЯ рдкреЛрд░реНрдЯ рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ** рдЬреЛ рд╕реЗрд╡рд╛ рд╕реНрдерд┐рддрд┐ рд╕реЗ рдореЗрд▓ рдЦрд╛рддрд╛ рд╣реИ

---

## рддреНрд╡рд░рд┐рдд рд╕рдВрджрд░реНрдн: рдореЙрдбрд▓ рдЙрдкрдирд╛рдо

### рд╕рд╛рдорд╛рдиреНрдп рдореЙрдбрд▓реНрд╕

| рдЙрдкрдирд╛рдо | рдЖрдХрд╛рд░ | рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рдЙрдкрдпреЛрдЧ | RAM/VRAM | рд╡реЗрд░рд┐рдПрдВрдЯреНрд╕ |
|-------|------|------------------|----------|-----------|
| `phi-4-mini` | ~4B | рд╕рд╛рдорд╛рдиреНрдп рдЪреИрдЯ, рд╕рд╛рд░рд╛рдВрд╢ | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | рдХреЛрдб рдЬрдирд░реЗрд╢рди, рд░рд┐рдлреИрдХреНрдЯрд░рд┐рдВрдЧ | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | рд╕рд╛рдорд╛рдиреНрдп рдХрд╛рд░реНрдп, рдХреБрд╢рд▓ | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | рддреЗрдЬрд╝, рдХрдо рд╕рдВрд╕рд╛рдзрди | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | рд╡рд░реНрдЧреАрдХрд░рдг, рдиреНрдпреВрдирддрдо рд╕рдВрд╕рд╛рдзрди | 1-2GB | `-cpu`, `-cuda-gpu` |

### рд╡реЗрд░рд┐рдПрдВрдЯ рдирд╛рдордХрд░рдг

- **рдмреЗрд╕ рдирд╛рдо** (рдЬреИрд╕реЗ, `phi-4-mini`): рдЖрдкрдХреЗ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХреЗ рд▓рд┐рдП рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рд╡реЗрд░рд┐рдПрдВрдЯ рдХреЛ рдСрдЯреЛ-рдЪреБрдирддрд╛ рд╣реИ
- **`-cpu`**: CPU-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб, рд╣рд░ рдЬрдЧрд╣ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ
- **`-cuda-gpu`**: NVIDIA GPU рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб, 8GB+ VRAM рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛
- **`-npu`**: Qualcomm NPU рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб, NPU рдбреНрд░рд╛рдЗрд╡рд░реНрд╕ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛

**рд╕рд┐рдлрд╛рд░рд┐рд╢:** рдмреЗрд╕ рдирд╛рдо (рдмрд┐рдирд╛ рдЙрдкрд╕рд░реНрдЧ) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ рдФрд░ Foundry Local рдХреЛ рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рд╡реЗрд░рд┐рдПрдВрдЯ рдСрдЯреЛ-рдЪреБрдирдиреЗ рджреЗрдВред

---

## рд╕рдлрд▓рддрд╛ рд╕рдВрдХреЗрддрдХ

рдЖрдк рддреИрдпрд╛рд░ рд╣реИрдВ рдЬрдм рдЖрдк рджреЗрдЦреЗрдВ:

тЬЕ `foundry service status` "running" рджрд┐рдЦрд╛рддрд╛ рд╣реИ  
тЬЕ `foundry model ls` рдЖрдкрдХреЗ рдЖрд╡рд╢реНрдпрдХ рдореЙрдбрд▓реНрд╕ рджрд┐рдЦрд╛рддрд╛ рд╣реИ  
тЬЕ рд╕реЗрд╡рд╛ рд╕рд╣реА рдПрдВрдбрдкреЙрдЗрдВрдЯ рдкрд░ рд╕реБрд▓рдн рд╣реИ  
тЬЕ рд╣реЗрд▓реНрде рдЪреЗрдХ 200 OK рд▓реМрдЯрд╛рддрд╛ рд╣реИ  
тЬЕ рдиреЛрдЯрдмреБрдХ рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рд╕реЗрд▓реНрд╕ рдкрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ  
тЬЕ рдЖрдЙрдЯрдкреБрдЯ рдореЗрдВ рдХреЛрдИ рдХрдиреЗрдХреНрд╢рди рддреНрд░реБрдЯрд┐ рдирд╣реАрдВ рд╣реИ  

---

## рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рд╛рдкреНрдд рдХрд░рдирд╛

### рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реАрдХрд░рдг
- **рдореБрдЦреНрдп рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/Foundry-Local
- **Python SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **CLI рд╕рдВрджрд░реНрдн**: https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md
- **рд╕рдорд╕реНрдпрд╛ рдирд┐рд╡рд╛рд░рдг**: рдЗрд╕ рдирд┐рд░реНрджреЗрд╢рд┐рдХрд╛ рдореЗрдВ `troubleshooting.md` рджреЗрдЦреЗрдВ

### GitHub Issues
- https://github.com/microsoft/Foundry-Local/issues
- https://github.com/microsoft/edgeai-for-beginners/issues

---

**рдЕрдВрддрд┐рдо рдЕрдкрдбреЗрдЯ:** 8 рдЕрдХреНрдЯреВрдмрд░, 2025  
**рд╕рдВрд╕реНрдХрд░рдг:** рд╡рд░реНрдХрд╢реЙрдк рдиреЛрдЯрдмреБрдХреНрд╕ 2.0

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпрд╣ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдиреБрд╡рд╛рджрд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред рдЬрдмрдХрд┐ рд╣рдо рд╕рдЯреАрдХрддрд╛ рдХреЗ рд▓рд┐рдП рдкреНрд░рдпрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ, рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рдж рдореЗрдВ рддреНрд░реБрдЯрд┐рдпрд╛рдВ рдпрд╛ рдЕрд╢реБрджреНрдзрд┐рдпрд╛рдВ рд╣реЛ рд╕рдХрддреА рд╣реИрдВред рдореВрд▓ рднрд╛рд╖рд╛ рдореЗрдВ рдЙрдкрд▓рдмреНрдз рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЛ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд╛ рдЬрд╛рдирд╛ рдЪрд╛рд╣рд┐рдПред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП, рдкреЗрд╢реЗрд╡рд░ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢ рдХреА рдЬрд╛рддреА рд╣реИред рдЗрд╕ рдЕрдиреБрд╡рд╛рдж рдХреЗ рдЙрдкрдпреЛрдЧ рд╕реЗ рдЙрддреНрдкрдиреНрди рдХрд┐рд╕реА рднреА рдЧрд▓рддрдлрд╣рдореА рдпрд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛ рдХреЗ рд▓рд┐рдП рд╣рдо рдЙрддреНрддрд░рджрд╛рдпреА рдирд╣реАрдВ рд╣реИрдВред