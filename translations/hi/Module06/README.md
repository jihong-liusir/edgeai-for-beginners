<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-17T15:14:21+00:00",
  "source_file": "Module06/README.md",
  "language_code": "hi"
}
-->
# अध्याय 06 : SLM एजेंटिक सिस्टम्स: एक व्यापक अवलोकन

कृत्रिम बुद्धिमत्ता का परिदृश्य एक मौलिक परिवर्तन का अनुभव कर रहा है, जहाँ हम साधारण चैटबॉट्स से उन्नत AI एजेंट्स की ओर बढ़ रहे हैं, जो छोटे भाषा मॉडल्स (SLMs) द्वारा संचालित हैं। यह व्यापक मार्गदर्शिका आधुनिक SLM एजेंटिक सिस्टम्स के तीन महत्वपूर्ण पहलुओं की खोज करती है: बुनियादी अवधारणाएँ और तैनाती रणनीतियाँ, फंक्शन कॉलिंग क्षमताएँ, और क्रांतिकारी मॉडल कॉन्टेक्स्ट प्रोटोकॉल (MCP) का एकीकरण।

## [सेक्शन 1: AI एजेंट्स और छोटे भाषा मॉडल्स की नींव](./01.IntroduceAgent.md)

पहला सेक्शन AI एजेंट्स और छोटे भाषा मॉडल्स की बुनियादी समझ स्थापित करता है, जिसमें 2025 को AI एजेंट्स का वर्ष बताया गया है, जो 2023 के चैटबॉट युग और 2024 के कोपायलट उछाल के बाद आता है। इस सेक्शन में **एजेंटिक AI सिस्टम्स** का परिचय दिया गया है, जो सोचते हैं, तर्क करते हैं, योजना बनाते हैं, उपकरणों का उपयोग करते हैं, और न्यूनतम मानव हस्तक्षेप के साथ कार्यों को निष्पादित करते हैं।

### शामिल प्रमुख अवधारणाएँ:
- **एजेंट वर्गीकरण फ्रेमवर्क**: साधारण रिफ्लेक्स एजेंट्स से लेकर लर्निंग एजेंट्स तक, विभिन्न कंप्यूटिंग परिदृश्यों के लिए एक व्यापक वर्गीकरण प्रदान करना
- **SLM की मूल बातें**: छोटे भाषा मॉडल्स को परिभाषित करना, जिनमें 10 बिलियन से कम पैरामीटर होते हैं और जो उपभोक्ता उपकरणों पर व्यावहारिक इनफेरेंस कर सकते हैं
- **उन्नत अनुकूलन रणनीतियाँ**: GGUF फॉर्मेट तैनाती, क्वांटाइजेशन तकनीकें (Q4_K_M, Q5_K_S, Q8_0), और Llama.cpp और Apple MLX जैसे एज-ऑप्टिमाइज़्ड फ्रेमवर्क्स को कवर करना
- **SLM बनाम LLM ट्रेड-ऑफ्स**: SLMs के साथ 10-30× लागत में कमी दिखाना, जबकि 70-80% सामान्य एजेंट कार्यों के लिए प्रभावशीलता बनाए रखना

यह सेक्शन Ollama, VLLM, और Microsoft के एज समाधान का उपयोग करके व्यावहारिक तैनाती रणनीतियों के साथ समाप्त होता है, जो SLMs को लागत प्रभावी, गोपनीयता-संरक्षण एजेंटिक AI तैनाती का भविष्य स्थापित करता है।

## [सेक्शन 2: छोटे भाषा मॉडल्स में फंक्शन कॉलिंग](./02.FunctionCalling.md)

दूसरा सेक्शन **फंक्शन कॉलिंग क्षमताओं** पर गहराई से चर्चा करता है, जो स्थिर भाषा मॉडल्स को वास्तविक दुनिया के साथ इंटरैक्शन करने वाले गतिशील AI एजेंट्स में बदलने की प्रक्रिया है। यह तकनीकी गहराई से विश्लेषण इरादे की पहचान से लेकर प्रतिक्रिया एकीकरण तक की पूरी कार्यप्रणाली को कवर करता है।

### मुख्य कार्यान्वयन क्षेत्र:
- **संगठित कार्यप्रणाली**: टूल इंटीग्रेशन, फंक्शन परिभाषा, इरादे की पहचान, JSON आउटपुट जनरेशन, और बाहरी निष्पादन का विस्तृत अन्वेषण
- **प्लेटफ़ॉर्म-विशिष्ट कार्यान्वयन**: Phi-4-mini के साथ Ollama, Qwen3 फंक्शन कॉलिंग, और Microsoft Foundry Local इंटीग्रेशन के लिए व्यापक गाइड्स
- **उन्नत उदाहरण**: मल्टी-एजेंट सहयोग सिस्टम्स, डायनामिक टूल चयन, और व्यापक त्रुटि हैंडलिंग के साथ एंटरप्राइज़ इंटीग्रेशन पैटर्न
- **उत्पादन विचार**: रेट लिमिटिंग, ऑडिट लॉगिंग, सुरक्षा उपाय, और प्रदर्शन अनुकूलन रणनीतियाँ

यह सेक्शन सैद्धांतिक समझ और व्यावहारिक कार्यान्वयन पैटर्न दोनों प्रदान करता है, जिससे डेवलपर्स को मजबूत फंक्शन-कॉलिंग सिस्टम्स बनाने में सक्षम बनाया जा सके, जो साधारण API कॉल्स से लेकर जटिल मल्टी-स्टेप एंटरप्राइज़ वर्कफ़्लो तक सब कुछ संभाल सकते हैं।

## [सेक्शन 3: मॉडल कॉन्टेक्स्ट प्रोटोकॉल (MCP) का एकीकरण](./03.IntroduceMCP.md)

अंतिम सेक्शन **मॉडल कॉन्टेक्स्ट प्रोटोकॉल (MCP)** का परिचय देता है, जो एक क्रांतिकारी फ्रेमवर्क है जो भाषा मॉडल्स को बाहरी उपकरणों और सिस्टम्स के साथ इंटरैक्ट करने के तरीके को मानकीकृत करता है। यह सेक्शन दिखाता है कि MCP कैसे AI मॉडल्स और वास्तविक दुनिया के बीच एक पुल बनाता है, अच्छी तरह से परिभाषित प्रोटोकॉल्स के माध्यम से।

### एकीकरण मुख्य बिंदु:
- **प्रोटोकॉल आर्किटेक्चर**: एप्लिकेशन, LLM क्लाइंट, MCP क्लाइंट, और टूल प्रोसेसिंग लेयर्स को कवर करने वाला लेयर्ड सिस्टम डिज़ाइन
- **मल्टी-बैकएंड सपोर्ट**: Ollama (स्थानीय विकास) और vLLM (उत्पादन) बैकएंड्स दोनों का समर्थन करने वाला लचीला कार्यान्वयन
- **कनेक्शन प्रोटोकॉल्स**: STDIO मोड डायरेक्ट प्रोसेस कम्युनिकेशन के लिए और SSE मोड HTTP-आधारित स्ट्रीमिंग के लिए
- **वास्तविक दुनिया के अनुप्रयोग**: वेब ऑटोमेशन, डेटा प्रोसेसिंग, और API इंटीग्रेशन के उदाहरण व्यापक त्रुटि हैंडलिंग के साथ

MCP एकीकरण दिखाता है कि SLMs को बाहरी क्षमताओं के साथ कैसे बढ़ाया जा सकता है, उनके छोटे पैरामीटर काउंट की भरपाई करते हुए उन्नत कार्यक्षमता प्रदान करना, और स्थानीय तैनाती और संसाधन दक्षता के लाभ बनाए रखना।

## रणनीतिक प्रभाव

ये तीन सेक्शन मिलकर SLM एजेंटिक सिस्टम्स को समझने और लागू करने के लिए एक व्यापक फ्रेमवर्क प्रस्तुत करते हैं। बुनियादी अवधारणाओं से लेकर फंक्शन कॉलिंग और MCP एकीकरण तक का विकास एक स्पष्ट मार्ग दिखाता है, जो लोकतांत्रित AI तैनाती की ओर ले जाता है, जहाँ:

- **दक्षता और क्षमता का मेल** छोटे मॉडल्स के अनुकूलन के माध्यम से होता है
- **लागत प्रभावशीलता** व्यापक अपनाने को सक्षम बनाती है
- **मानकीकृत प्रोटोकॉल्स** इंटरऑपरेबिलिटी सुनिश्चित करते हैं
- **स्थानीय तैनाती** गोपनीयता बनाए रखती है और विलंबता को कम करती है

यह प्रगति केवल एक तकनीकी उन्नति नहीं है, बल्कि अधिक सुलभ, कुशल, और व्यावहारिक AI सिस्टम्स की ओर एक दृष्टिकोण परिवर्तन है, जो संसाधन-सीमित वातावरण में प्रभावी ढंग से संचालित हो सकते हैं और उद्योगों और अनुप्रयोगों में उन्नत एजेंटिक क्षमताएँ प्रदान कर सकते हैं।

SLMs को उन्नत तैनाती रणनीतियों, मजबूत फंक्शन कॉलिंग, और मानकीकृत टूल इंटीग्रेशन प्रोटोकॉल्स के साथ जोड़कर, ये सिस्टम्स AI एजेंट्स की अगली पीढ़ी के लिए आधार बनाते हैं, जो यह बदल देंगे कि हम कृत्रिम बुद्धिमत्ता के साथ कैसे इंटरैक्ट करते हैं और इससे कैसे लाभ उठाते हैं।

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।