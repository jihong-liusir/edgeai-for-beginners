<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-19T01:14:15+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "sr"
}
-->
# Одељак 3: Фино подешавање - Прилагођавање модела за специфичне задатке

## Садржај
1. [Увод у фино подешавање](../../../Module05)
2. [Зашто је фино подешавање важно](../../../Module05)
3. [Типови фино подешавања](../../../Module05)
4. [Фино подешавање са Microsoft Olive](../../../Module05)
5. [Практични примери](../../../Module05)
6. [Најбоље праксе и смернице](../../../Module05)
7. [Напредне технике](../../../Module05)
8. [Евалуација и праћење](../../../Module05)
9. [Уобичајени изазови и решења](../../../Module05)
10. [Закључак](../../../Module05)

## Увод у фино подешавање

**Фино подешавање** је моћна техника машинског учења која подразумева прилагођавање већ обученог модела за извршавање специфичних задатака или рад са специјализованим скуповима података. Уместо да се модел обучава од почетка, фино подешавање користи већ стечено знање обученог модела и прилагођава га за вашу конкретну употребу.

### Шта је фино подешавање?

Фино подешавање је облик **трансферног учења** где:
- Започињете са већ обученим моделом који је научио опште обрасце из великих скупова података
- Прилагођавате унутрашње параметре модела користећи ваш специфичан скуп података
- Задржавате вредно знање док специјализујете модел за ваш задатак

Замислите то као да обучавате вештог кувара да припрема нову кухињу - он већ разуме основе кувања, али треба да научи специфичне технике и укусе за нови стил.

### Кључне предности

- **Ефикасност времена**: Знатно брже од обуке од почетка
- **Ефикасност података**: Захтева мање скупове података за постизање добрих резултата
- **Исплативост**: Мањи захтеви за рачунарским ресурсима
- **Бољи резултати**: Често постиже супериорне резултате у поређењу са обуком од почетка
- **Оптимизација ресурса**: Омогућава приступ моћној вештачкој интелигенцији мањим тимовима и организацијама

## Зашто је фино подешавање важно

### Примена у стварном свету

Фино подешавање је неопходно у бројним сценаријима:

**1. Адаптација за домен**
- Медицинска вештачка интелигенција: Прилагођавање општих језичких модела за медицинску терминологију и клиничке белешке
- Правна технологија: Специјализација модела за анализу правних докумената и ревизију уговора
- Финансијске услуге: Прилагођавање модела за анализу финансијских извештаја и процену ризика

**2. Специјализација задатака**
- Генерисање садржаја: Фино подешавање за специфичне стилове или тонове писања
- Генерисање кода: Прилагођавање модела за одређене програмске језике или оквире
- Превод: Побољшање перформанси за специфичне језичке парове или техничке домене

**3. Корпоративна примена**
- Корисничка подршка: Креирање чатботова који разумеју терминологију специфичну за компанију
- Интерна документација: Изградња AI асистената упознатих са организационим процесима
- Решавања специфична за индустрију: Развој модела који разумеју жаргон и радне токове специфичне за сектор

## Типови фино подешавања

### 1. Потпуно фино подешавање (Instruction Fine-Tuning)

Код потпуног фино подешавања, сви параметри модела се ажурирају током обуке. Овај приступ:
- Пружа максималну флексибилност и потенцијал перформанси
- Захтева значајне рачунарске ресурсе
- Резултира потпуно новом верзијом модела
- Најбољи је за сценарије где имате обимне скупове података и рачунарске ресурсе

### 2. Ефикасно фино подешавање параметара (PEFT)

PEFT методе ажурирају само мали подскуп параметара, чинећи процес ефикаснијим:

#### Low-Rank Adaptation (LoRA)
- Додаје мале матрице за рангирање које се могу обучавати постојећим тежинама
- Драматично смањује број параметара који се могу обучавати
- Одржава перформансе близу потпуног фино подешавања
- Омогућава лако пребацивање између различитих адаптација

#### QLoRA (Quantized LoRA)
- Комбинује LoRA са техникама квантовања
- Додатно смањује захтеве за меморијом
- Омогућава фино подешавање већих модела на потрошачком хардверу
- Балансира ефикасност са перформансама

#### Адаптери
- Убацују мале неуронске мреже између постојећих слојева
- Омогућавају циљано фино подешавање док основни модел остаје непромењен
- Омогућавају модуларни приступ прилагођавању модела

### 3. Фино подешавање специфично за задатак

Фокусира се на прилагођавање модела за специфичне задатке:
- **Класификација**: Прилагођавање модела за задатке категоризације
- **Генерисање**: Оптимизација за креирање садржаја и генерисање текста
- **Екстракција**: Фино подешавање за екстракцију информација и препознавање именованих ентитета
- **Сажимање**: Специјализација модела за сажимање докумената

## Фино подешавање са Microsoft Olive

Microsoft Olive је свеобухватан алат за оптимизацију модела који поједностављује процес фино подешавања уз пружање функција на нивоу предузећа.

### Шта је Microsoft Olive?

Microsoft Olive је алат за оптимизацију модела отвореног кода који:
- Убрзава радне токове фино подешавања за различите хардверске циљеве
- Пружа уграђену подршку за популарне архитектуре модела (Llama, Phi, Qwen, Gemma)
- Нуди опције за облачно и локално распоређивање
- Интегрише се са Azure ML и другим Microsoft AI услугама
- Подржава аутоматску оптимизацију и квантовање

### Кључне карактеристике

- **Оптимизација прилагођена хардверу**: Аутоматски оптимизује моделе за специфичан хардвер (CPU, GPU, NPU)
- **Подршка за више формата**: Ради са PyTorch, Hugging Face и ONNX моделима
- **Аутоматизовани радни токови**: Смањује ручну конфигурацију и пробе и грешке
- **Интеграција за предузећа**: Уграђена подршка за Azure ML и облачно распоређивање
- **Проширива архитектура**: Омогућава прилагођене технике оптимизације

### Инсталација и подешавање

#### Основна инсталација

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Опционе зависности

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Провера инсталације

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Практични примери

### Пример 1: Основно фино подешавање са Olive CLI

Овај пример демонстрира фино подешавање малог језичког модела за класификацију фраза:

#### Корак 1: Припремите окружење

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Корак 2: Фино подесите модел

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Корак 3: Оптимизујте за распоређивање

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Пример 2: Напредна конфигурација са прилагођеним скупом података

#### Корак 1: Припремите прилагођени скуп података

Креирајте JSON датотеку са вашим подацима за обуку:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Корак 2: Креирајте конфигурациону датотеку

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Корак 3: Извршите фино подешавање

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Пример 3: QLoRA фино подешавање за ефикасност меморије

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Најбоље праксе и смернице

### Припрема података

**1. Квалитет података пре количине**
- Дајте предност висококвалитетним, разноврсним примерима у односу на велике количине лоших података
- Осигурајте да су подаци репрезентативни за вашу циљну употребу
- Конзистентно чистите и претходно обрађујте податке

**2. Формат и шаблони података**
- Користите конзистентно форматирање за све примере обуке
- Креирајте јасне шаблоне улаз-излаз који одговарају вашој употреби
- Укључите одговарајуће форматирање инструкција за моделе обучене на инструкцијама

**3. Подела скупа података**
- Резервишите 10-20% података за валидацију
- Одржавајте сличне дистрибуције између тренинг/валидационих делова
- Размотрите стратификовано узорковање за задатке класификације

### Конфигурација обуке

**1. Избор стопе учења**
- Започните са мањим стопама учења (1e-5 до 1e-4) за фино подешавање
- Користите планирање стопе учења за бољу конвергенцију
- Пратите криве губитка да бисте прилагодили стопе

**2. Оптимизација величине серије**
- Балансирајте величину серије са доступном меморијом
- Користите акумулацију градијента за веће ефективне величине серије
- Размотрите однос између величине серије и стопе учења

**3. Трајање обуке**
- Пратите метрике валидације да бисте избегли претренираност
- Користите рано заустављање када перформансе валидације стагнирају
- Редовно чувајте контролне тачке за опоравак и анализу

### Избор модела

**1. Избор основног модела**
- Изаберите моделе обучене на сличним доменима кад год је могуће
- Размотрите величину модела у односу на ваше рачунарске ограничења
- Процените захтеве за лиценцирање за комерцијалну употребу

**2. Избор методе фино подешавања**
- Користите LoRA/QLoRA за окружења са ограниченим ресурсима
- Изаберите потпуно фино подешавање када су максималне перформансе критичне
- Размотрите приступе засноване на адаптерима за сценарије са више задатака

### Управљање ресурсима

**1. Оптимизација хардвера**
- Изаберите одговарајући хардвер за величину модела и метод
- Ефикасно користите GPU меморију са контролом градијента
- Размотрите решења заснована на облаку за веће моделе

**2. Управљање меморијом**
- Користите обуку са мешовитом прецизношћу кад год је доступна
- Примените акумулацију градијента за ограничења меморије
- Пратите употребу GPU меморије током обуке

## Напредне технике

### Обука са више адаптера

Обучите више адаптера за различите задатке док делите основни модел:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Оптимизација хиперпараметара

Примените систематско подешавање хиперпараметара:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Прилагођене функције губитка

Примените функције губитка специфичне за домен:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Евалуација и праћење

### Метрике и евалуација

**1. Стандардне метрике**
- **Тачност**: Укупна исправност за задатке класификације
- **Перплексност**: Мера квалитета језичког моделирања
- **BLEU/ROUGE**: Квалитет генерисања текста и сажимања
- **F1 скор**: Балансирана прецизност и одзив за класификацију

**2. Метрике специфичне за домен**
- **Бенчмарци специфични за задатак**: Користите утврђене бенчмарке за ваш домен
- **Људска евалуација**: Укључите процену од стране људи за субјективне задатке
- **Пословне метрике**: Ускладите са стварним пословним циљевима

**3. Подешавање евалуације**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Праћење напретка обуке

**1. Праћење губитка**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Праћење валидације**
- Пратите губитак валидације заједно са губитком обуке
- Пратите знаке претренираности (губитак валидације расте док губитак обуке опада)
- Користите рано заустављање на основу метрика валидације

**3. Праћење ресурса**
- Пратите употребу GPU/CPU
- Пратите обрасце употребе меморије
- Пратите брзину и пропусност обуке

## Уобичајени изазови и решења

### Изазов 1: Претренираност

**Симптоми:**
- Губитак обуке наставља да опада док губитак валидације расте
- Велики јаз између перформанси обуке и валидације
- Лоша генерализација на нове податке

**Решења:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Изазов 2: Ограничења меморије

**Решења:**
- Користите контролу градијента
- Примените акумулацију градијента
- Изаберите методе ефикасне за параметре (LoRA, QLoRA)
- Користите паралелизам модела за велике моделе

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Изазов 3: Спора обука

**Решења:**
- Оптимизујте цевоводе за учитавање података
- Користите обуку са мешовитом прецизношћу
- Примените ефикасне стратегије серијског обрађивања
- Размотрите дистрибуирану обуку за велике скупове података

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Изазов 4: Лоше перформансе

**Кораци за дијагнозу:**
1. Проверите квалитет и форматирање података
2. Проверите стопу учења и трајање обуке
3. Процените избор основног модела
4. Прегледајте претходну обраду и токенизацију

**Решења:**
- Повећајте разноврсност података за обуку
- Прилагодите распоред стопе учења
- Испробај

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитативним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.