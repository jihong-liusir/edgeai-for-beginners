<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9b66db9742653af2dbeada08d98716e7",
  "translation_date": "2025-09-18T22:21:02+00:00",
  "source_file": "Module02/02.QwenFamily.md",
  "language_code": "sr"
}
-->
# Одељак 2: Основе породице Qwen

Моделска породица Qwen представља свеобухватан приступ Alibaba Cloud-а великим језичким моделима и мултимодалној вештачкој интелигенцији, показујући да модели отвореног кода могу постићи изузетне резултате уз приступачност у различитим сценаријима примене. Важно је разумети како породица Qwen омогућава моћне AI могућности уз флексибилне опције примене, истовремено одржавајући конкурентне перформансе у разноврсним задацима.

## Ресурси за програмере

### Репозиторијум модела на Hugging Face
Одабрани модели породице Qwen доступни су преко [Hugging Face](https://huggingface.co/models?search=qwen), пружајући приступ неким варијантама ових модела. Можете истражити доступне варијанте, прилагодити их за своје специфичне потребе и применити их кроз различите оквире.

### Алати за локални развој
За локални развој и тестирање, можете користити [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) за покретање доступних Qwen модела на вашем развојном рачунару уз оптимизоване перформансе.

### Ресурси за документацију
- [Документација модела Qwen](https://huggingface.co/docs/transformers/model_doc/qwen)
- [Оптимизација Qwen модела за примену на ивици](https://github.com/microsoft/olive)

## Увод

У овом туторијалу истражићемо породицу модела Qwen компаније Alibaba и њене основне концепте. Покрићемо еволуцију породице Qwen, иновативне методологије тренинга које чине Qwen моделе ефикасним, кључне варијанте у породици и практичне примене у различитим сценаријима.

## Циљеви учења

На крају овог туторијала, моћи ћете да:

- Разумете филозофију дизајна и еволуцију породице модела Qwen компаније Alibaba
- Идентификујете кључне иновације које омогућавају Qwen моделима да постигну високе перформансе у различитим величинама параметара
- Препознате предности и ограничења различитих варијанти Qwen модела
- Примените знање о Qwen моделима за избор одговарајућих варијанти за реалне сценарије

## Разумевање савременог пејзажа AI модела

Пејзаж AI модела значајно се развио, са различитим организацијама које следе различите приступе развоју језичких модела. Док се неке фокусирају на власничке моделе затвореног кода, друге наглашавају приступачност и транспарентност отвореног кода. Традиционални приступ укључује или масивне власничке моделе доступне само преко API-ја или моделе отвореног кода који могу заостајати у могућностима.

Овај парадигма ствара изазове за организације које траже моћне AI могућности уз задржавање контроле над својим подацима, трошковима и флексибилношћу примене. Традиционални приступ често захтева избор између врхунских перформанси и практичних разматрања примене.

## Изазов приступачне AI изврсности

Потреба за висококвалитетном, приступачном AI постала је све важнија у различитим сценаријима. Размотрите примене које захтевају флексибилне опције примене за различите организационе потребе, исплативе имплементације где трошкови API-ја могу постати значајни, мултијезичке могућности за глобалне примене или специјализовано доменско знање у областима као што су програмирање и математика.

### Кључни захтеви примене

Савремене AI примене суочавају се са неколико основних захтева који ограничавају практичну примену:

- **Приступачност**: Доступност отвореног кода за транспарентност и прилагођавање
- **Исплативост**: Разумни захтеви за рачунарске ресурсе за различите буџете
- **Флексибилност**: Више величина модела за различите сценарије примене
- **Глобални домет**: Јаке мултијезичке и међукултурне могућности
- **Специјализација**: Варијанте специфичне за домен за одређене случајеве употребе

## Филозофија модела Qwen

Породица модела Qwen представља свеобухватан приступ развоју AI модела, приоритетно стављајући приступачност отвореног кода, мултијезичке могућности и практичну примену уз одржавање конкурентних карактеристика перформанси. Qwen модели то постижу кроз различите величине модела, висококвалитетне методологије тренинга и специјализоване варијанте за различите домене.

Породица Qwen обухвата различите приступе дизајниране да пруже опције широм спектра перформанси и ефикасности, омогућавајући примену од мобилних уређаја до серверских система предузећа уз пружање значајних AI могућности. Циљ је демократизовати приступ висококвалитетној AI уз пружање флексибилности у избору примене.

### Основни принципи дизајна Qwen модела

Qwen модели су изграђени на неколико основних принципа који их разликују од других породица језичких модела:

- **Прво отворени код**: Потпуна транспарентност и приступачност за истраживање и комерцијалну употребу
- **Свеобухватан тренинг**: Тренинг на масивним, разноврсним скуповима података који покривају више језика и домена
- **Скалабилна архитектура**: Више величина модела за усклађивање са различитим рачунарским захтевима
- **Специјализована изврсност**: Варијанте специфичне за домен оптимизоване за одређене задатке

## Кључне технологије које омогућавају породицу Qwen

### Масивни тренинг

Један од дефинишућих аспеката породице Qwen је масивна скала података за тренинг и рачунарских ресурса уложених у развој модела. Qwen модели користе пажљиво одабране, мултијезичке скупове података који обухватају трилионе токена, дизајниране да пруже свеобухватно знање о свету и способности резоновања.

Овај приступ функционише комбиновањем висококвалитетног веб садржаја, академске литературе, репозиторијума кода и мултијезичких ресурса. Методологија тренинга наглашава и ширину знања и дубину разумевања у различитим доменима и језицима.

### Напредно резоновање и размишљање

Недавни Qwen модели укључују софистициране способности резоновања које омогућавају сложено решавање проблема у више корака:

**Режим размишљања (Qwen3)**: Модели могу да се ангажују у детаљном резоновању корак по корак пре него што пруже коначне одговоре, слично људским приступима решавању проблема.

**Двоструки режим рада**: Способност пребацивања између брзог режима одговора за једноставне упите и дубљег режима размишљања за сложене проблеме.

**Интеграција ланца мисли**: Природна интеграција корака резоновања који побољшавају транспарентност и тачност у сложеним задацима.

### Архитектонске иновације

Породица Qwen укључује неколико архитектонских оптимизација дизајнираних за перформансе и ефикасност:

**Скалабилни дизајн**: Конзистентна архитектура широм величина модела која омогућава лако скалирање и поређење.

**Мултимодална интеграција**: Беспрекорна интеграција обраде текста, визије и аудио садржаја унутар уједињених архитектура.

**Оптимизација примене**: Више опција квантовања и формата примене за различите хардверске конфигурације.

## Величина модела и опције примене

Савремена окружења примене имају користи од флексибилности Qwen модела у различитим рачунарским захтевима:

### Мали модели (0.5B-3B)

Qwen пружа ефикасне мале моделе погодне за примену на ивици, мобилне апликације и окружења са ограниченим ресурсима уз одржавање импресивних могућности.

### Средњи модели (7B-32B)

Модели средњег опсега нуде побољшане могућности за професионалне примене, пружајући одличан баланс између перформанси и рачунарских захтева.

### Велики модели (72B+)

Модели пуне скале пружају врхунске перформансе за захтевне примене, истраживање и примене у предузећима које захтевају максималне могућности.

## Предности породице Qwen модела

### Приступачност отвореног кода

Qwen модели пружају потпуну транспарентност и могућности прилагођавања, омогућавајући организацијама да разумеју, модификују и прилагоде моделе својим специфичним потребама без зависности од добављача.

### Флексибилност примене

Опсег величина модела омогућава примену у разноврсним хардверским конфигурацијама, од мобилних уређаја до врхунских сервера, пружајући организацијама флексибилност у избору AI инфраструктуре.

### Мултијезичка изврсност

Qwen модели се истичу у мултијезичком разумевању и генерисању, подржавајући десетине језика са посебном снагом у енглеском и кинеском, чинећи их погодним за глобалне примене.

### Конкурентне перформансе

Qwen модели доследно постижу конкурентне резултате на бенчмарковима уз пружање приступачности отвореног кода, показујући да модели отвореног кода могу парирати власничким алтернативама.

### Специјализоване могућности

Варијанте специфичне за домен, као што су Qwen-Coder и Qwen-Math, пружају специјализовано знање уз одржавање општих могућности разумевања језика.

## Практични примери и случајеви употребе

Пре него што се упустимо у техничке детаље, истражимо неке конкретне примере шта Qwen модели могу да постигну:

### Пример математичког резоновања

Qwen-Math се истиче у решавању математичких проблема корак по корак. На пример, када се затражи решење сложеног проблема из калкулуса:

```
User: Find the derivative of f(x) = x³ + 2x² - 5x + 3

Qwen-Math: I'll solve this step by step using the power rule for derivatives.

For f(x) = x³ + 2x² - 5x + 3, I need to find f'(x).

Using the power rule: d/dx(xⁿ) = n·xⁿ⁻¹

Breaking down each term:
- d/dx(x³) = 3x²
- d/dx(2x²) = 2 · 2x¹ = 4x  
- d/dx(-5x) = -5
- d/dx(3) = 0 (constant term)

Therefore: f'(x) = 3x² + 4x - 5
```

### Пример мултијезичке подршке

Qwen модели показују јаке мултијезичке могућности у различитим језицима:

```
User: Explain the concept of artificial intelligence in both English and Chinese.

Qwen: **English:**
Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding. AI enables machines to perform tasks that typically require human cognitive abilities.

**中文:**
人工智能（AI）是指机器（特别是计算机系统）对人类智能过程的模拟。这些过程包括学习、推理、解决问题、感知和语言理解。人工智能使机器能够执行通常需要人类认知能力的任务。
```

### Пример мултимодалних могућности

Qwen-VL може истовремено обрађивати текст и слике:

```
User: [Image of a chart showing sales data] What trends do you see in this sales chart?

Qwen-VL: Looking at this sales chart, I can identify several key trends:

1. **Seasonal Pattern**: There's a clear seasonal cycle with peaks typically occurring in Q4, likely due to holiday sales.

2. **Overall Growth**: Despite fluctuations, there's an upward trend over the time period shown, indicating business growth.

3. **Quarterly Variations**: Q1 and Q3 show consistently lower performance compared to Q2 and Q4.

4. **Recent Acceleration**: The most recent data points suggest accelerating growth, with steeper increases than historical averages.

5. **Volatility Changes**: Earlier periods show more stability, while recent periods display increased volatility, possibly indicating market expansion or increased competition.
```

### Пример генерисања кода

Qwen-Coder се истиче у генерисању и објашњавању кода у различитим програмским језицима:

```
User: Create a Python function to implement a binary search algorithm with detailed comments.

Qwen-Coder: Here's a Python implementation of binary search with comprehensive comments:

```python
def binary_search(arr, target):
    """
    Изврши бинарну претрагу на сортираном низу да би пронашао циљну вредност.
    
    Args:
        arr (list): Сортирана листа упоредивих елемената
        target: Вредност коју треба претражити
        
    Returns:
        int: Индекс циља ако је пронађен, -1 ако није пронађен
        
    Временска сложеност: O(log n)
    Просторна сложеност: O(1)
    """
    # Иницијализуј леви и десни показивач
    left, right = 0, len(arr) - 1
    
    # Настави претрагу док је простор претраге валидан
    while left <= right:
        # Израчунај средњи индекс да избегнеш преливање целих бројева
        mid = left + (right - left) // 2
        
        # Провери да ли смо пронашли циљ
        if arr[mid] == target:
            return mid
        
        # Ако је циљ мањи, претражи леву половину
        elif arr[mid] > target:
            right = mid - 1
        
        # Ако је циљ већи, претражи десну половину
        else:
            left = mid + 1
    
    # Циљ није пронађен
    return -1

# Пример употребе:
sorted_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
result = binary_search(sorted_list, 7)
print(f"Индекс 7: {result}")  # Излаз: Индекс 7: 3
```

This implementation follows best practices with clear variable names, comprehensive documentation, and efficient logic.
```

### Пример примене на ивици

Qwen модели могу бити примењени на различитим уређајима на ивици уз оптимизоване конфигурације:

```
# Example deployment on mobile device with quantization
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load quantized model for mobile deployment
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-1.5B-Instruct",
    torch_dtype=torch.float16,
    device_map="auto",
    load_in_8bit=True  # 8-bit quantization for efficiency
)

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")

# Mobile-optimized inference
def mobile_inference(prompt):
    inputs = tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=100,
            do_sample=True,
            temperature=0.7,
            pad_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.replace(prompt, "").strip()
```

## Еволуција породице Qwen

### Qwen 1.0 и 1.5: Основни модели

Рани Qwen модели успоставили су основне принципе свеобухватног тренинга и приступачности отвореног кода:

- **Qwen-7B (7B параметара)**: Почетно издање фокусирано на разумевање кинеског и енглеског језика
- **Qwen-14B (14B параметара)**: Побољшане могућности уз унапређено резоновање и знање
- **Qwen-72B (72B параметара)**: Модел велике скале који пружа врхунске перформансе
- **Серија Qwen1.5**: Проширена на више величина (0.5B до 110B) уз побољшано руковање дугим контекстом

### Породица Qwen2: Мултимодална експанзија

Серија Qwen2 означила је значајан напредак у језичким и мултимодалним могућностима:

- **Qwen2-0.5B до 72B**: Свеобухватан опсег језичких модела за различите потребе примене
- **Qwen2-57B-A14B (MoE)**: Архитектура мешавине експерата за ефикасно коришћење параметара
- **Qwen2-VL**: Напредне могућности визије и језика за разумевање слика
- **Qwen2-Audio**: Могућности обраде и разумевања аудио садржаја
- **Qwen2-Math**: Специјализовано математичко резоновање и решавање проблема

### Породица Qwen2.5: Побољшане перформансе

Серија Qwen2.5 донела је значајна побољшања у свим димензијама:

- **Проширен тренинг**: 18 трилиона токена података за тренинг за побољшане могућности
- **Проширен контекст**: До 128K токена дужине контекста, са Turbo варијантом која подржава 1M токена
- **Побољшана специјализација**: Унапређене варијанте Qwen2.5-Coder и Qwen2.5-M
Ево како да започнете са Qwen моделима користећи Hugging Face Transformers библиотеку:

### Коришћење Qwen2.5 модела

### Специјализована употреба модела

**Генерисање кода са Qwen-Coder:**

**Решавање математичких проблема:**

**Задаци визије и језика:**

### Режим размишљања (Qwen3)

### 📱 Мобилна и Edge имплементација

### Пример имплементације API-ја

## Перформансе и достигнућа

Породица Qwen модела постигла је изузетне резултате на различитим бенчмарковима, уз задржавање приступачности отвореног кода:

### Кључни моменти перформанси

**Изврсност у резоновању:**
- Qwen3-235B-A22B постиже конкурентне резултате у евалуацијама кодирања, математике и општих способности у поређењу са другим врхунским моделима као што су DeepSeek-R1, o1, o3-mini, Grok-3 и Gemini-2.5-Pro
- Qwen3-30B-A3B надмашује QwQ-32B са 10 пута више активираних параметара
- Qwen3-4B може парирати перформансама Qwen2.5-72B-Instruct

**Ефикасност:**
- Qwen3-MoE основни модели постижу сличне резултате као Qwen2.5 густо базни модели, уз коришћење само 10% активних параметара
- Значајна уштеда трошкова у тренингу и инференцији у поређењу са густим моделима

**Мултијезичне способности:**
- Qwen3 модели подржавају 119 језика и дијалеката
- Јаке перформансе у различитим језичким и културним контекстима

**Скала тренинга:**
- Qwen3 користи скоро дупло више, са приближно 36 трилиона токена који покривају 119 језика и дијалеката у поређењу са Qwen2.5 који има 18 трилиона токена

### Матрица поређења модела

| Серија модела | Опсег параметара | Дужина контекста | Кључне предности | Најбоље примене |
|---------------|------------------|------------------|------------------|-----------------|
| **Qwen2.5** | 0.5B-72B | 32K-128K | Уравнотежене перформансе, мултијезичност | Опште апликације, продукциона имплементација |
| **Qwen2.5-Coder** | 1.5B-32B | 128K | Генерисање кода, програмирање | Развој софтвера, помоћ у кодирању |
| **Qwen2.5-Math** | 1.5B-72B | 4K-128K | Математичко резоновање | Едукативне платформе, STEM апликације |
| **Qwen2.5-VL** | Различито | Променљиво | Разумевање визије и језика | Мултимодалне апликације, анализа слика |
| **Qwen3** | 0.6B-235B | Променљиво | Напредно резоновање, режим размишљања | Комплексно резоновање, истраживачке апликације |
| **Qwen3 MoE** | 30B-235B укупно | Променљиво | Ефикасне перформансе великог обима | Ентерпрајз апликације, потребе високих перформанси |

## Водич за избор модела

### За основне апликације
- **Qwen2.5-0.5B/1.5B**: Мобилне апликације, edge уређаји, апликације у реалном времену
- **Qwen2.5-3B/7B**: Општи четботови, генерисање садржаја, Q&A системи

### За математичке и резоновање задатке
- **Qwen2.5-Math**: Решавање математичких проблема и STEM едукација
- **Qwen3 са режимом размишљања**: Комплексно резоновање које захтева анализу корак по корак

### За програмирање и развој
- **Qwen2.5-Coder**: Генерисање кода, дебаговање, помоћ у програмирању
- **Qwen3**: Напредни програмски задаци са способностима резоновања

### За мултимодалне апликације
- **Qwen2.5-VL**: Разумевање слика, визуелно одговарање на питања
- **Qwen-Audio**: Обрада звука и разумевање говора

### За ентерпрајз имплементацију
- **Qwen2.5-32B/72B**: Разумевање језика високих перформанси
- **Qwen3-235B-A22B**: Максималне способности за захтевне апликације

## Платформе за имплементацију и приступачност
### Cloud платформе
- **Hugging Face Hub**: Свеобухватан репозиторијум модела са подршком заједнице
- **ModelScope**: Alibaba платформа модела са алатима за оптимизацију
- **Разни Cloud провајдери**: Подршка кроз стандардне ML платформе

### Локални развојни оквири
- **Transformers**: Стандардна Hugging Face интеграција за лаку имплементацију
- **vLLM**: Сервер високих перформанси за продукциона окружења
- **Ollama**: Поједностављена локална имплементација и управљање
- **ONNX Runtime**: Крос-платформска оптимизација за различит хардвер
- **llama.cpp**: Ефикасна C++ имплементација за различите платформе

### Ресурси за учење
- **Qwen документација**: Званична документација и картице модела
- **Hugging Face Model Hub**: Интерактивни демо и примери заједнице
- **Истраживачки радови**: Технички радови на arxiv за дубље разумевање
- **Форуми заједнице**: Активна подршка заједнице и дискусије

### Како започети са Qwen моделима

#### Платформе за развој
1. **Hugging Face Transformers**: Започните са стандардном Python интеграцијом
2. **ModelScope**: Истражите Alibaba алате за оптимизовану имплементацију
3. **Локална имплементација**: Користите Ollama или директне трансформере за локално тестирање

#### Пут учења
1. **Разумевање основних концепата**: Проучите архитектуру и способности породице Qwen
2. **Експериментисање са варијантама**: Испробајте различите величине модела да разумете компромисе у перформансама
3. **Практична имплементација**: Имплементирајте моделе у развојним окружењима
4. **Оптимизација имплементације**: Фино подесите за продукционе случајеве

#### Најбоље праксе
- **Започните са мањим моделима**: Почните са мањим моделима (1.5B-7B) за почетни развој
- **Користите шаблоне за чет**: Примените правилно форматирање за оптималне резултате
- **Пратите ресурсе**: Пратите употребу меморије и брзину инференције
- **Размотрите специјализацију**: Изаберите варијанте специфичне за домен када је то прикладно

## Напредни обрасци употребе

### Примери фино подешавања

### Специјализовано инжењерство промпта

**За сложене задатке резоновања:**

**За генерисање кода са контекстом:**

### Мултијезичне апликације

### 🔧 Шаблони продукционе имплементације

## Стратегије оптимизације перформанси

### Оптимизација меморије

### Оптимизација инференције

## Најбоље праксе и смернице

### Безбедност и приватност

### Праћење и евалуација

## Закључак

Породица Qwen модела представља свеобухватан приступ демократизацији AI технологије уз задржавање конкурентних перформанси у различитим апликацијама. Кроз посвећеност приступачности отвореног кода, мултијезичним способностима и флексибилним опцијама имплементације, Qwen омогућава организацијама и програмерима да искористе моћне AI способности без обзира на ресурсе или специфичне захтеве.

### Кључни закључци

**Изврсност отвореног кода**: Qwen показује да модели отвореног кода могу постићи перформансе конкурентне са власничким алтернативама уз пружање транспарентности, прилагођавања и контроле.

**Скалабилна архитектура**: Опсег од 0.5B до 235B параметара омогућава имплементацију у целом спектру рачунарских окружења, од мобилних уређаја до ентерпрајз кластера.

**Специјализоване способности**: Варијанте специфичне за домен као што су Qwen-Coder, Qwen-Math и Qwen-VL пружају специјализовану експертизу уз задржавање општег разумевања језика.

**Глобална приступачност**: Јака мултијезична подршка за 119+ језика чини Qwen погодним за међународне апликације и разноврсне корисничке базе.

**Континуирана иновација**: Еволуција од Qwen 1.0 до Qwen3 показује конзистентно побољшање способности, ефикасности и опција имплементације.

### Поглед у будућност

Како се породица Qwen модела наставља развијати, можемо очекивати:

- **Побољшану ефикасност**: Континуирана оптимизација за боље односе перформанси по параметру
- **Проширене мултимодалне способности**: Интеграцију софистицираније обраде визије, звука и текста
- **Унапређено резоновање**: Напредни механизми размишљања и способности решавања проблема у више корака
- **Бољи алати за имплементацију**: Побољшани оквири и алати за оптимизацију за различите сценарије имплементације
- **Раст заједнице**: Проширен екосистем алата, апликација и доприноса заједнице

### Следећи кораци

Без обзира да ли градите четбот, развијате едукативне алате, креирате асистенте за кодирање или радите на мултијезичним апликацијама, породица Qwen пружа скалабилна решења са јаком подршком заједнице и свеобухватном документацијом.

За најновије информације, издања модела и детаљну техничку документацију, посетите званичне Qwen репозиторијуме на Hugging Face и истражите активне дискусије и примере заједнице.

Будућност развоја AI лежи у приступачним, транспарентним и моћним алатима који омогућавају иновације у свим секторима и размерама. Породица Qwen представља ову визију, пружајући организацијама и програмерима основу за изградњу следеће генерације апликација заснованих на AI.

## Додатни ресурси

- **Званична документација**: [Qwen документација](https://qwen.readthedocs.io/)
- **Model Hub**: [Hugging Face Qwen Collections](https://huggingface.co/collections/Qwen/)
- **Технички радови**: [Qwen истраживачке публикације](https://arxiv.org/search/?query=Qwen&searchtype=all)
- **Заједница**: [GitHub дискусије и проблеми](https://github.com/QwenLM/)
- **ModelScope платформа**: [Alibaba ModelScope](https://modelscope.cn/models?page=1&tasks=natural-language-processing&type=1)

## Исходи учења

Након завршетка овог модула, моћи ћете да:

1. Објасните архитектонске предности породице Qwen модела и њен приступ отвореном коду
2. Изаберете одговарајућу Qwen варијанту на основу специфичних захтева апликације и ограничења ресурса
3. Имплементирате Qwen моделе у различитим сценаријима имплементације са оптимизованим конфигурацијама
4. Примените технике квантовања и оптимизације за побољшање перформанси Qwen модела
5. Евалуирате компромисе између величине модела, перформанси и способности у оквиру породице Qwen

## Шта следи

- [03: Основе породице Gemma](03.GemmaFamily.md)

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитативним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.