<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:43:58+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "sr"
}
-->
# Секција 1: Основе породице модела Microsoft Phi

Породица модела Microsoft Phi представља промену парадигме у вештачкој интелигенцији, показујући да компактни, ефикасни модели могу постићи изузетне резултате уз значајно мању потрошњу ресурса у поређењу са традиционалним великим језичким моделима. Важно је разумети како породица Phi омогућава моћне AI способности уз смањене рачунарске захтеве, истовремено одржавајући висок учинак у различитим задацима.

## Ресурси за програмере

### Azure AI Foundry Model Catalog
Модели из породице Phi (осим Phi-silica) доступни су преко [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), што програмерима олакшава приступ, фино подешавање и примену ових модела у њиховим апликацијама. Каталог пружа једноставан начин за експериментисање са различитим варијантама Phi модела и њихову интеграцију у пројекте.

### Azure AI Foundry
Можете применити и експериментисати са Phi моделима користећи [Azure AI Foundry](https://ai.azure.com), који пружа свеобухватно окружење за изградњу, тестирање и примену AI решења уз минималну конфигурацију.

### Foundry Local
За локални развој и примену, погледајте [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), који вам омогућава да покренете Phi моделе на вашем развојном рачунару уз оптимизоване конфигурације.

### Ресурси за документацију
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Увод

У овој лекцији истражићемо породицу модела Microsoft Phi и њене основне концепте. Покрићемо еволуцију породице Phi, иновативне методологије тренинга које чине Phi моделе ефикасним, кључне варијанте у породици и практичне примене у различитим сценаријима.

## Циљеви учења

До краја ове лекције, моћи ћете да:

- Разумете филозофију дизајна и еволуцију породице модела Microsoft Phi.
- Идентификујете кључне иновације које омогућавају Phi моделима да постигну висок учинак са мање параметара.
- Препознате предности и ограничења различитих варијанти Phi модела.
- Примените знање о Phi моделима за избор одговарајућих варијанти за сценарије из стварног света.

## Разумевање традиционалне парадигме AI модела

Традиционално, постизање високог учинка у обради природног језика захтевало је масивне језичке моделе са милијардама или стотинама милијарди параметара. Организације обично примењују ове моделе на моћним GPU кластерима, приступајући њиховим способностима преко API интерфејса или специјализоване хардверске инфраструктуре.

Овај приступ добро функционише за многе апликације, али има урођена ограничења када је реч о практичним сценаријима примене. Конвенционални метод подразумева коришћење модела који захтевају значајне рачунарске ресурсе, велике количине меморије и значајну потрошњу енергије. Иако овај приступ пружа приступ најсавременијим способностима, ствара зависност од скупог хардвера, уводи високе оперативне трошкове и ограничава флексибилност примене.

## Изазов ефикасне примене AI

Потреба за ефикаснијом AI постала је све важнија у различитим сценаријима. Размотрите апликације које захтевају локалну примену из разлога приватности, имплементације осетљиве на трошкове где трошкови cloud API-а постају неприхватљиви, сценарије edge computing-а са ограниченим хардверским ресурсима или апликације у реалном времену где је латенција критична.

### Кључна ограничења примене

Традиционалне примене великих модела суочавају се са неколико основних ограничења која ограничавају њихову практичну примену:

- **Ограничења трошкова**: Високи рачунарски трошкови чине континуирану примену скупом за многе организације.
- **Ограничења ресурса**: Ограничен приступ врхунској GPU инфраструктури ограничава опције примене.
- **Захтеви приватности**: Осетљиве апликације захтевају локалну обраду ради очувања приватности података.
- **Осетљивост на латенцију**: Апликације у реалном времену захтевају тренутне одговоре без кашњења услед cloud обраде.

## Филозофија модела Microsoft Phi

Породица модела Microsoft Phi представља фундаменталну промену у филозофији дизајна AI модела, приоритет даје ефикасности и практичној примени уз одржавање снажних карактеристика учинка. Phi модели то постижу кроз иновативне архитектуре, висококвалитетне методологије тренинга и специјализоване технике оптимизације.

Породица Phi обухвата различите приступе дизајниране да максимизирају учинак по параметру, омогућавајући примену на стандардном хардверу уз пружање значајних AI способности. Циљ је одржати конкурентан учинак уз драматично смањење рачунарских захтева, употребе меморије и оперативних трошкова.

### Основни принципи дизајна Phi модела

Phi модели су изграђени на неколико основних принципа који их разликују од традиционалних великих језичких модела:

- **Ефикасност на првом месту**: Оптимизовани за максимални учинак по параметру, а не за апсолутну величину.
- **Квалитет тренинга**: Фокус на висококвалитетним, курираним подацима за тренинг уместо на масивним скуповима података.
- **Флексибилност примене**: Дизајнирани да ефикасно раде на различитим хардверским конфигурацијама.
- **Специјализоване способности**: Често оптимизовани за специфичне задатке или домене ради максималне ефикасности.

## Кључне технологије које омогућавају породицу Phi

### Приступ тренингу "квалитет уџбеника"

Један од најреволуционарнијих аспеката породице Phi је методологија тренинга "квалитет уџбеника". Уместо тренинга на огромним количинама нефилтрираних интернет података, Phi модели користе пажљиво куриране, висококвалитетне образовне садржаје дизајниране да ефикасно подучавају резоновање, математику, програмирање и опште знање.

Овај приступ функционише креирањем синтетичког образовног садржаја који одражава висококвалитетне уџбенике и академске материјале. Подаци за тренинг су специјално дизајнирани да буду педагошки исправни, фокусирајући се на јасна објашњења, корак-по-корак резоновање и структурну презентацију знања.

### Напредни тренинг резоновања

Недавни Phi модели укључују софистициране методологије тренинга резоновања које омогућавају сложено решавање проблема у више корака. Ове технике укључују:

**Тренинг ланца размишљања**: Модели уче да разложе сложене проблеме на интермедијарне кораке резоновања, чинећи процес решавања проблема транспарентнијим и поузданијим.

**Скалирање током инференције**: Модели генеришу детаљне ланце резоновања који користе додатне рачунарске ресурсе током генерисања одговора ради побољшане тачности.

**Тренинг на граници способности**: Подаци за тренинг су пажљиво одабрани да изазову модел на граници његових тренутних способности, подстичући учење сложених образаца резоновања.

### Архитектонске иновације

Породица Phi укључује неколико архитектонских оптимизација дизајнираних посебно за ефикасност:

**Ефикасност параметара**: Пажљиве архитектонске одлуке које максимизирају утицај сваког параметра у моделу.

**Мултимодална интеграција**: Ефикасна интеграција обраде текста, слике и говора у компактне архитектуре.

**Оптимизација хардвера**: Специјализоване варијанте оптимизоване за специфичне хардверске платформе и сценарије примене.

## Оптимизација хардвера за Phi моделе

Модерна окружења примене користе предности ефикасности Phi модела на различитим хардверским конфигурацијама:

### Примена оптимизована за CPU

Phi модели су дизајнирани да ефикасно раде на хардверу који користи само CPU, чинећи их доступним за примену на стандардној рачунарској инфраструктури без потребе за специјализованим AI акцелераторима.

### GPU акцелерација

Иако не захтевају моћне GPU-ове, Phi модели могу искористити доступне GPU ресурсе за побољшани учинак, пружајући флексибилност у конфигурацијама примене.

### Интеграција у уређаје на ивици мреже

Специјализоване варијанте као што је Phi-3-Silica оптимизоване су за специфичне платформе edge computing-а, постижући изузетне метрике ефикасности као што је 650 токена у секунди уз потрошњу од само 1.5W снаге.

## Предности породице Phi модела

### Ефикасност трошкова

Phi модели драматично смањују оперативне трошкове захтевајући значајно мању рачунарску инфраструктуру уз одржавање конкурентног учинка. Ово чини AI доступним организацијама са ограниченим буџетима или апликацијама великог обима где је трошак по инференцији важан.

### Флексибилност примене

Ефикасност Phi модела омогућава примену на широком спектру хардверских конфигурација, од личних лаптопова до серверских инфраструктура, пружајући организацијама већу флексибилност у избору AI инфраструктуре.

### Приватност и сигурност

Ефикасност Phi модела омогућава локалну примену за апликације осетљиве на приватност, осигуравајући да осетљиви подаци никада не напуштају контролу организације, уз пружање моћних AI способности.

### Учинак у реалном времену

Смањени рачунарски захтеви преводе се у брже време инференције, омогућавајући апликације у реалном времену које захтевају тренутне одговоре без компромиса у квалитету AI способности.

### Доступан AI

Смањујући баријере за примену AI, Phi модели чине напредне AI способности доступним организацијама са ограниченим ресурсима, омогућавајући мањим тимовима и индивидуалним програмерима да искористе софистицирано разумевање језика.

## Практични примери и случајеви употребе

Пре него што се упустимо у техничку еволуцију, истражимо неке конкретне примере шта Phi модели могу да постигну:

### Пример математичког резоновања

Phi-4-mini-reasoning се истиче у корак-по-корак решавању математичких проблема. На пример, када се постави питање "Како решити 3*x^2+4*x+5=1?", модел пружа детаљне кораке резоновања:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Пример подршке за више језика

Phi-3.5-mini-instruct показује снажне мултијезичке способности у различитим језицима. Ево примера формата упита:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Пример мултимодалних способности

Phi-4-multimodal може истовремено обрађивати текст, слике и говор. Ево неких практичних апликација:

**Планирање путовања уз аудио унос:**
Погледајте како Phi-4 Multimodal анализира говорни језик како би помогао у планирању путовања у Сијетл, демонстрирајући своје напредне способности обраде аудио садржаја и препорука.

**Решавање математичких проблема из слика:**
Видите како Phi-4 Multimodal решава сложене математичке проблеме кроз визуелне уносе, демонстрирајући своју способност обраде и решавања једначина представљених у сликама.

**Пример позивања функција:**
Са позивањем функција, Phi-4-mini и Phi-4-multimodal могу проширити своје способности обраде текста интеграцијом претраживача, повезивањем различитих алата и још много тога. Као што је приказано, модел може добити информације о утакмицама Премијер лиге преко Phi-4-mini, показујући своју способност да беспрекорно интерагује са спољним изворима података.

### Пример генерисања кода

Phi-4-multimodal може генерисати структуриран код пројекта на основу садржаја слике и датих упита, као што је приказано у овом практичном току рада:

1. Отпремите слику жичаног оквира или дизајна
2. Пружите контекст о захтевима пројекта
3. Модел генерише комплетне, функционалне структуре кода
4. Код се може прилагодити на основу специфичних оквира или језика

### Пример примене на ивици мреже

Можемо применити квантовани модел на уређајима на ивици мреже. Комбинујући Microsoft Olive и ONNX GenAI Runtime, можемо применити Phi-4-mini на Windows, iPhone, Android и другим уређајима. Ово је пример који ради на iPhone 12 Pro.

Процес примене укључује:
- Квантовање модела за мобилну оптимизацију
- Интеграцију ONNX runtime-а за компатибилност на више платформи
- Локалну инференцију без интернет конекције
- Учинак у реалном времену уз минималну потрошњу енергије

## Еволуција породице Phi

### Phi-1 и Phi-2: Основни модели

Рани Phi модели успоставили су основне принципе висококвалитетних података за тренинг и ефикасних архитектура:

- **Phi-1 (1.3B параметара)**: Увео концепт курираних података за тренинг за основно разумевање језика и генерисање кода.
- **Phi-2 (2.7B параметара)**: Побољшао способности резоновања кроз синтетичке NLP податке и пажљиво филтрирани веб садржај.

### Phi-3 породица: Масовно усвајање

Серија Phi-3 означила је пробој у SLM способностима са више специјализованих варијанти:

- **Phi-3-mini (3.8B параметара)**: Општи језички задаци са изузетном ефикасношћу, надмашујући моделе двоструко веће величине.
- **Phi-3-small (7B параметара)**: Напредни учинак који надмашује GPT-3.5 Turbo на
Porodica Phi pokazuje da budućnost primene veštačke inteligencije ne leži samo u izgradnji većih modela, već u razvoju pametnijih, efikasnijih modela koji mogu uspešno raditi na različitim hardverskim platformama, uz održavanje visokih standarda performansi.

## Primeri razvoja i integracije

### Brzi početak sa Transformers bibliotekom

Evo kako da započnete rad sa Phi modelima koristeći Hugging Face Transformers biblioteku:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Primer fino podešavanja

Sledeći primer pokazuje kako fino podesiti Phi-4-mini-instruct za specifične zadatke:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specijalizovani formati upita

**Za zadatke zaključivanja (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Za matematičke zadatke (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobilna primena sa ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Performanse i dostignuća

Porodica Phi modela postigla je izvanredne rezultate na raznim testovima, često nadmašujući mnogo veće modele:

### Ključni rezultati performansi

**Izvrsnost u matematičkom zaključivanju:**
- Phi-4 postiže tačnost od 82,5% na AIME 2025 (kvalifikacioni test za Matematičku olimpijadu)
- Phi-4-reasoning (14B) nadmašuje DeepSeek-R1-Distill-70B (5x veći) na testovima zaključivanja
- Phi-4-mini-reasoning (3.8B) se takmiči sa modelima dvostruko većim u zadacima matematičkog zaključivanja

**Efikasnost:**
- Phi-3-Silica postiže 650 tokena u sekundi uz potrošnju od samo 1.5W
- Phi-4-mini (3.8B) postiže slične performanse kao mnogo veći modeli

**Performanse na testovima:**
- **MMLU (Masivno razumevanje više zadataka)**: Konkurentne performanse u 57 akademskih oblasti
- **HumanEval**: Snažne sposobnosti generisanja koda, posebno u Python-u
- **MGSM**: Višejezično rešavanje matematičkih problema osnovne škole
- **DROP**: Kompleksni zadaci razumevanja i zaključivanja
- **SimpleQA**: Tačnost odgovora na faktualna pitanja

### 📊 Matrica poređenja modela

| Model | Parametri | Dužina konteksta | Ključne prednosti | Najbolje primene |
|-------|-----------|------------------|-------------------|------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Opšta efikasnost | Mobilne aplikacije, osnovni chatbotovi |
| **Phi-3.5-mini** | 3.8B | 128K | Višejezična podrška | Međunarodne aplikacije |
| **Phi-4-mini** | 3.8B | 128K | Poboljšano zaključivanje, pozivanje funkcija | Poslovna automatizacija |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matematičko zaključivanje | Obrazovne platforme |
| **Phi-4** | 14B | 32K | Kompleksno zaključivanje | Istraživanje, napredna analiza |
| **Phi-4-reasoning** | 14B | 32K/64K | Višestepeno zaključivanje | Naučno računarstvo |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimalna tačnost u zaključivanju | Kritično donošenje odluka |
| **Phi-4-multimodal** | 5.6B | Varijabilno | Govor, vizija, tekst | Multimedijalne aplikacije |

## Vodič za izbor modela

### Za osnovne aplikacije
- **Phi-3-mini**: Jednostavno generisanje teksta, osnovna pitanja i odgovori, brzi odgovori
- **Phi-4-mini**: Poboljšano zaključivanje sa mogućnostima pozivanja funkcija

### Za matematičke i zadatke zaključivanja
- **Phi-4**: Kompleksno rešavanje matematičkih problema i zaključivanje
- **Phi-4-reasoning**: Višestepeno zaključivanje sa detaljnim objašnjenjima
- **Phi-4-reasoning-plus**: Maksimalna tačnost za kritične aplikacije zaključivanja
- **Phi-4-mini-reasoning**: Efikasno matematičko zaključivanje za okruženja sa ograničenim resursima

### Za multimodalne aplikacije
- **Phi-3-vision**: Kombinacija obrade slike i teksta
- **Phi-4-multimodal**: Sveobuhvatne mogućnosti govora, vizije i teksta

### Za primenu u preduzećima
- **Phi-3-medium**: Napredno razumevanje jezika za poslovne aplikacije
- **Phi-3-Silica**: Optimizovano za specifične hardverske platforme

## Platforme za primenu i dostupnost

### Cloud platforme
- **Azure AI Foundry**: Potpuna primena sa alatima za preduzeća
- **Hugging Face**: Repozitorijum otvorenog koda i resursi zajednice
- **NVIDIA API Catalog**: Opcije za primenu mikroservisa

### Okviri za lokalni razvoj
- **Ollama**: Lagan okvir za lokalnu primenu modela
- **ONNX Runtime**: Optimizovano za različite hardverske konfiguracije  
- **DirectML**: Optimizovane performanse za Windows
- **llama.cpp**: Mehanizam za inferenciju na više platformi

### Resursi za učenje
- **Phi Portal**: Zvanična Microsoft Phi dokumentacija
- **Phi Cookbook**: Sveobuhvatni primeri i tutorijali
- **Tehnički izveštaji**: Detaljni istraživački radovi na arxiv-u
- **Prostori zajednice**: Interaktivni demo sadržaji na Hugging Face-u

### Početak rada sa Phi modelima

#### Platforme za razvoj
1. **Azure AI Foundry**: Jednostavan lokalni CLI i upravljanje modelima.
2. **Hugging Face Transformers**: Brza lokalna eksperimentacija
3. **Ollama**: Jednostavna lokalna primena za testiranje

#### Put učenja
1. **Razumevanje osnovnih koncepata**: Proučite osnovne principe dizajna
2. **Eksperimentisanje sa varijantama**: Isprobajte različite Phi modele da biste razumeli njihove mogućnosti
3. **Praksa implementacije**: Primena modela u testnim okruženjima
4. **Širenje primene**: Postepeno povećanje upotrebe na osnovu uspešnih pilot projekata

#### Najbolje prakse
- **Počnite sa manjim modelima**: Započnite razvoj sa Phi-mini modelima
- **Optimizujte upite**: Koristite pravilno formatiranje za najbolje rezultate
- **Pratite performanse**: Pratite brzinu inferencije i metrike tačnosti
- **Razmotrite hardver**: Prilagodite veličinu modela dostupnim računalnim resursima

## Zaključak

Porodica Microsoft Phi modela predstavlja revolucionarni pristup dizajnu AI modela, pokazujući da manji, efikasniji modeli mogu postići izvanredne rezultate u raznim zadacima. Fokusiranjem na visokokvalitetne podatke za obuku i optimizacije arhitekture, porodica Phi pruža izuzetne mogućnosti uz značajno smanjene računalne zahteve u poređenju sa tradicionalnim velikim jezičkim modelima.

## Ključni ciljevi učenja

1. Razumevanje filozofije dizajna i evolucije porodice Microsoft Phi modela od Phi-1 do Phi-4
2. Identifikacija ključnih inovacija, uključujući obuku "kvaliteta udžbenika" i optimizacije arhitekture
3. Prepoznavanje prednosti i ograničenja različitih Phi varijanti u različitim scenarijima primene
4. Primena znanja za izbor odgovarajućih Phi modela za specifične slučajeve upotrebe i hardverska ograničenja
5. Implementacija tehnika optimizacije za primenu Phi modela na uređajima sa ograničenim resursima
6. Objašnjenje arhitektonskih prednosti porodice Phi modela u odnosu na tradicionalne velike jezičke modele
7. Izbor odgovarajuće Phi varijante na osnovu specifičnih zahteva aplikacije i hardverskih ograničenja
8. Implementacija Phi modela u scenarijima primene na oblaku i ivici sa optimizovanim konfiguracijama
9. Primena tehnika kvantizacije i optimizacije za poboljšanje performansi Phi modela na ciljnim uređajima
10. Procena kompromisa između veličine modela, performansi i mogućnosti u okviru porodice Phi modela

## Šta dalje

- [02: Osnove porodice Qwen](02.QwenFamily.md)

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.