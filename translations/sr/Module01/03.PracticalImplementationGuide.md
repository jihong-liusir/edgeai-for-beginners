<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c37dfe660161e652077f6b7b23bb2167",
  "translation_date": "2025-10-11T14:45:12+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "sr"
}
-->
# Секција 3: Практични водич за имплементацију

## Преглед

Овај свеобухватни водич ће вам помоћи да се припремите за курс EdgeAI, који се фокусира на изградњу практичних AI решења која ефикасно раде на уређајима на ивици. Курс наглашава практични развој користећи савремене оквире и најсавременије моделе оптимизоване за имплементацију на ивици.

## 1. Постављање развојног окружења

### Програмски језици и оквири

**Python окружење**
- **Верзија**: Python 3.10 или новија (препоручено: Python 3.11)
- **Менаџер пакета**: pip или conda
- **Виртуелно окружење**: Користите venv или conda окружења за изолацију
- **Кључне библиотеке**: Специфичне EdgeAI библиотеке ће бити инсталиране током курса

**Microsoft .NET окружење**
- **Верзија**: .NET 8 или новија
- **IDE**: Visual Studio 2022, Visual Studio Code или JetBrains Rider
- **SDK**: Уверите се да је .NET SDK инсталиран за развој на више платформи

### Развојни алати

**Едитори кода и IDE-ови**
- Visual Studio Code (препоручено за развој на више платформи)
- PyCharm или Visual Studio (за развој специфичан за језик)
- Jupyter Notebooks за интерактивни развој и прототипирање

**Контрола верзија**
- Git (најновија верзија)
- GitHub налог за приступ репозиторијумима и сарадњу

## 2. Хардверски захтеви и препоруке

### Минимални системски захтеви
- **CPU**: Вишекорни процесор (Intel i5/AMD Ryzen 5 или еквивалент)
- **RAM**: Минимум 8GB, препоручено 16GB
- **Складиште**: 50GB доступног простора за моделе и развојне алате
- **OS**: Windows 10/11, macOS 10.15+ или Linux (Ubuntu 20.04+)

### Стратегија за рачунарске ресурсе
Курс је дизајниран да буде доступан на различитим хардверским конфигурацијама:

**Локални развој (фокус на CPU/NPU)**
- Примарни развој ће користити CPU и NPU акцелерацију
- Погодно за већину модерних лаптопова и десктоп рачунара
- Фокус на ефикасност и практичне сценарије имплементације

**Облачни GPU ресурси (опционо)**
- **Azure Machine Learning**: За интензивну обуку и експериментисање
- **Google Colab**: Бесплатан ниво доступан за образовне сврхе
- **Kaggle Notebooks**: Алтернативна платформа за облачно рачунарство

### Разматрања за уређаје на ивици
- Разумевање процесора заснованих на ARM архитектури
- Познавање ограничења мобилног и IoT хардвера
- Упознавање са оптимизацијом потрошње енергије

## 3. Основне породице модела и ресурси

### Примарне породице модела

**Microsoft Phi-4 породица**
- **Опис**: Компактни, ефикасни модели дизајнирани за имплементацију на ивици
- **Предности**: Одличан однос перформанси и величине, оптимизовани за задатке резоновања
- **Ресурс**: [Phi-4 колекција на Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Примена**: Генерација кода, математичко резоновање, општа конверзација

**Qwen-3 породица**
- **Опис**: Најновија генерација мултијезичких модела компаније Alibaba
- **Предности**: Јаке мултијезичке способности, ефикасна архитектура
- **Ресурс**: [Qwen-3 колекција на Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **Примена**: Мултијезичке апликације, међукултурна AI решења

**Google Gemma-3n породица**
- **Опис**: Google-ови лагани модели оптимизовани за имплементацију на ивици
- **Предности**: Брза инференција, архитектура прилагођена мобилним уређајима
- **Ресурс**: [Gemma-3n колекција на Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **Примена**: Мобилне апликације, обрада у реалном времену

### Критеријуми за избор модела
- **Однос перформанси и величине**: Разумевање када изабрати мање или веће моделе
- **Оптимизација за специфичне задатке**: Усклађивање модела са специфичним случајевима употребе
- **Ограничења имплементације**: Меморија, кашњење и потрошња енергије

## 4. Алатке за квантовање и оптимизацију

### Llama.cpp оквир
- **Репозиторијум**: [Llama.cpp на GitHub](https://github.com/ggml-org/llama.cpp)
- **Намена**: Енджин за инференцију високих перформанси за LLM-ове
- **Кључне карактеристике**:
  - Оптимизована инференција за CPU
  - Више формата квантовања (Q4, Q5, Q8)
  - Компатибилност на више платформи
  - Ефикасно извршавање у меморији
- **Инсталација и основна употреба**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **Репозиторијум**: [Microsoft Olive на GitHub](https://github.com/microsoft/olive)
- **Намена**: Алат за оптимизацију модела за имплементацију на ивици
- **Кључне карактеристике**:
  - Аутоматизовани радни токови за оптимизацију модела
  - Оптимизација прилагођена хардверу
  - Интеграција са ONNX Runtime
  - Алатке за бенчмаркинг перформанси
- **Инсталација и основна употреба**:
  ```bash
  # Install Olive
  pip install olive-ai
  ```
  
  # Пример Python скрипте за оптимизацију модела
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (корисници macOS-а)
- **Репозиторијум**: [Apple MLX на GitHub](https://github.com/ml-explore/mlx)
- **Намена**: Оквир за машинско учење за Apple Silicon
- **Кључне карактеристике**:
  - Оптимизација за Apple Silicon
  - Ефикасне операције у меморији
  - API сличан PyTorch-у
  - Подршка за унифицирану меморијску архитектуру
- **Инсталација и основна употреба**:
  ```bash
  # Install MLX
  pip install mlx
  ```
  
  ```python
  # Example Python script for loading and optimizing a model
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **Репозиторијум**: [ONNX Runtime на GitHub](https://github.com/microsoft/onnxruntime)
- **Намена**: Убрзање инференције за ONNX моделе на више платформи
- **Кључне карактеристике**:
  - Оптимизације специфичне за хардвер (CPU, GPU, NPU)
  - Оптимизације графа за инференцију
  - Подршка за квантовање
  - Подршка за више језика (Python, C++, C#, JavaScript)
- **Инсталација и основна употреба**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. Препоручена литература и ресурси

### Основна документација
- **ONNX Runtime документација**: Разумевање инференције на више платформи
- **Hugging Face Transformers водич**: Учитавање модела и инференција
- **Edge AI дизајн шаблони**: Најбоље праксе за имплементацију на ивици

### Технички радови
- "Ефикасни Edge AI: Преглед техника квантовања"
- "Компресија модела за мобилне и уређаје на ивици"
- "Оптимизација трансформер модела за рачунарство на ивици"

### Ресурси за заједницу
- **EdgeAI Slack/Discord заједнице**: Подршка и дискусија са колегама
- **GitHub репозиторијуми**: Пример имплементација и туторијали
- **YouTube канали**: Технички дубински прегледи и туторијали

## 6. Процена и верификација

### Контролна листа пре курса
- [ ] Инсталиран и проверен Python 3.10+
- [ ] Инсталиран и проверен .NET 8+
- [ ] Конфигурисано развојно окружење
- [ ] Креиран Hugging Face налог
- [ ] Основно познавање циљних породица модела
- [ ] Инсталирани и тестирани алати за квантовање
- [ ] Испуњени хардверски захтеви
- [ ] Постављени налози за облачно рачунарство (ако је потребно)

## Кључни циљеви учења

До краја овог водича, бићете у могућности да:

1. Поставите комплетно развојно окружење за развој EdgeAI апликација
2. Инсталирате и конфигуришете неопходне алате и оквире за оптимизацију модела
3. Изаберете одговарајуће хардверске и софтверске конфигурације за своје EdgeAI пројекте
4. Разумете кључне аспекте имплементације AI модела на уређајима на ивици
5. Припремите свој систем за практичне вежбе у оквиру курса

## Додатни ресурси

### Званична документација
- **Python документација**: Званична документација за Python језик
- **Microsoft .NET документација**: Званични ресурси за .NET развој
- **ONNX Runtime документација**: Свеобухватни водич за ONNX Runtime
- **TensorFlow Lite документација**: Званична документација за TensorFlow Lite

### Развојни алати
- **Visual Studio Code**: Лаган едитор кода са екстензијама за AI развој
- **Jupyter Notebooks**: Интерактивно окружење за експериментисање са ML-ом
- **Docker**: Платформа за контејнеризацију ради конзистентних развојних окружења
- **Git**: Систем за контролу верзија за управљање кодом

### Ресурси за учење
- **EdgeAI истраживачки радови**: Најновија академска истраживања о ефикасним моделима
- **Онлајн курсеви**: Допунски материјали за учење о оптимизацији AI-а
- **Форуми за заједницу**: Платформе за питања и одговоре о изазовима у EdgeAI развоју
- **Бенчмарк скупови података**: Стандардни скупови података за процену перформанси модела

## Резултати учења

Након завршетка овог водича за припрему, бићете:

1. Имати потпуно конфигурисано развојно окружење спремно за EdgeAI развој
2. Разумети хардверске и софтверске захтеве за различите сценарије имплементације
3. Упознати са кључним оквирима и алатима који се користе током курса
4. Бити у могућности да изаберете одговарајуће моделе на основу ограничења уређаја и захтева
5. Имати основно знање о техникама оптимизације за имплементацију на ивици

## ➡️ Шта следи

- [04: EdgeAI хардвер и имплементација](04.EdgeDeployment.md)

---

**Одрицање од одговорности**:  
Овај документ је преведен помоћу услуге за превођење уз помоћ вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални превод од стране људског преводиоца. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу произаћи из коришћења овог превода.