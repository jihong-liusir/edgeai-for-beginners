<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8ccc4f76611daedf918e34460128fc21",
  "translation_date": "2025-10-01T01:36:18+00:00",
  "source_file": "Module08/04.CuttingEdgeModels.md",
  "language_code": "sr"
}
-->
# –°–µ—Å–∏—ò–∞ 4: –ò–∑–≥—Ä–∞–¥—ö–∞ –ø—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–∏—Ö –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ —É–∑ Chainlit

## –ü—Ä–µ–≥–ª–µ–¥

–û–≤–∞ —Å–µ—Å–∏—ò–∞ —ò–µ –ø–æ—Å–≤–µ—õ–µ–Ω–∞ –∏–∑–≥—Ä–∞–¥—ö–∏ –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ —Å–ø—Ä–µ–º–Ω–∏—Ö –∑–∞ –ø—Ä–æ–¥—É–∫—Ü–∏—ò—É —É–∑ –ø–æ–º–æ—õ Chainlit-–∞ –∏ Microsoft Foundry Local-–∞. –ù–∞—É—á–∏—õ–µ—Ç–µ –∫–∞–∫–æ –¥–∞ –∫—Ä–µ–∏—Ä–∞—Ç–µ –º–æ–¥–µ—Ä–Ω–µ –≤–µ–± –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å–µ –∑–∞ AI —Ä–∞–∑–≥–æ–≤–æ—Ä–µ, –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–∞—Ç–µ —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ–¥–≥–æ–≤–æ—Ä–∞ –∏ –ø–æ—Å—Ç–∞–≤–∏—Ç–µ —Ä–æ–±—É—Å–Ω–µ –∞–ø–ª–∏–∫–∞—Ü–∏—ò–µ –∑–∞ —õ–∞—Å–∫–∞—ö–µ —Å–∞ –ø—Ä–∞–≤–∏–ª–Ω–∏–º —Ä—É–∫–æ–≤–∞—ö–µ–º –≥—Ä–µ—à–∫–∞–º–∞ –∏ –¥–∏–∑–∞—ò–Ω–æ–º –∫–æ—Ä–∏—Å–Ω–∏—á–∫–æ–≥ –∏—Å–∫—É—Å—Ç–≤–∞.

**–®—Ç–∞ —õ–µ—Ç–µ –∏–∑–≥—Ä–∞–¥–∏—Ç–∏:**
- **Chainlit –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ**: –ú–æ–¥–µ—Ä–∞–Ω –≤–µ–± –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å —Å–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ–¥–≥–æ–≤–æ—Ä–∏–º–∞
- **WebGPU –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—ò–∞**: –ò–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—ò–∞ —É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É –∑–∞ –∞–ø–ª–∏–∫–∞—Ü–∏—ò–µ –∫–æ—ò–µ –ø—Ä–≤–µ–Ω—Å—Ç–≤–µ–Ω–æ –≤–æ–¥–µ —Ä–∞—á—É–Ω–∞ –æ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏  
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—ò–∞ Open WebUI**: –ü—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–Ω–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å –∑–∞ —õ–∞—Å–∫–∞—ö–µ —É–∑ Foundry Local
- **–ü—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–∏ –æ–±—Ä–∞—Å—Ü–∏**: –†—É–∫–æ–≤–∞—ö–µ –≥—Ä–µ—à–∫–∞–º–∞, –ø—Ä–∞—õ–µ—ö–µ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—ò–µ –∑–∞ –ø–æ—Å—Ç–∞–≤—ô–∞—ö–µ

## –¶–∏—ô–µ–≤–∏ —É—á–µ—ö–∞

- –ò–∑–≥—Ä–∞–¥—ö–∞ –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ —Å–ø—Ä–µ–º–Ω–∏—Ö –∑–∞ –ø—Ä–æ–¥—É–∫—Ü–∏—ò—É —É–∑ Chainlit
- –ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ–¥–≥–æ–≤–æ—Ä–∞ –∑–∞ –ø–æ–±–æ—ô—à–∞–Ω–æ –∫–æ—Ä–∏—Å–Ω–∏—á–∫–æ –∏—Å–∫—É—Å—Ç–≤–æ
- –°–∞–≤–ª–∞–¥–∞–≤–∞—ö–µ –æ–±—Ä–∞–∑–∞—Ü–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—ò–µ Foundry Local SDK-–∞
- –ü—Ä–∏–º–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª–Ω–æ–≥ —Ä—É–∫–æ–≤–∞—ö–∞ –≥—Ä–µ—à–∫–∞–º–∞ –∏ –≥—Ä–∞—Ü–∏–æ–∑–Ω–µ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—ò–µ
- –ü–æ—Å—Ç–∞–≤—ô–∞—ö–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Å–∞—ö–µ –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ –∑–∞ —Ä–∞–∑–ª–∏—á–∏—Ç–∞ –æ–∫—Ä—É–∂–µ—ö–∞
- –†–∞–∑—É–º–µ–≤–∞—ö–µ –º–æ–¥–µ—Ä–Ω–∏—Ö –≤–µ–± –æ–±—Ä–∞–∑–∞—Ü–∞ –∑–∞ –∫–æ—Ä–∏—Å–Ω–∏—á–∫–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å —É —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º AI-—É

## –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏

- **Foundry Local**: –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω –∏ –ø–æ–∫—Ä–µ–Ω—É—Ç ([–í–æ–¥–∏—á –∑–∞ –∏–Ω—Å—Ç–∞–ª–∞—Ü–∏—ò—É](https://learn.microsoft.com/azure/ai-foundry/foundry-local/))
- **Python**: –í–µ—Ä–∑–∏—ò–∞ 3.10 –∏–ª–∏ –Ω–æ–≤–∏—ò–∞ —Å–∞ –º–æ–≥—É—õ–Ω–æ—à—õ—É –≤–∏—Ä—Ç—É–µ–ª–Ω–æ–≥ –æ–∫—Ä—É–∂–µ—ö–∞
- **–ú–æ–¥–µ–ª**: –ù–∞—ò–º–∞—ö–µ —ò–µ–¥–∞–Ω —É—á–∏—Ç–∞–Ω –º–æ–¥–µ–ª (`foundry model run phi-4-mini`)
- **–ü—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á**: –ú–æ–¥–µ—Ä–∞–Ω –≤–µ–± –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á —Å–∞ –ø–æ–¥—Ä—à–∫–æ–º –∑–∞ WebGPU (Chrome/Edge)
- **Docker**: –ó–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—ò—É Open WebUI-–∞ (–æ–ø—Ü–∏–æ–Ω–æ)

## –î–µ–æ 1: –†–∞–∑—É–º–µ–≤–∞—ö–µ –º–æ–¥–µ—Ä–Ω–∏—Ö –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ

### –ü—Ä–µ–≥–ª–µ–¥ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ

```
User Browser ‚Üê‚Üí Chainlit UI ‚Üê‚Üí Python Backend ‚Üê‚Üí Foundry Local ‚Üê‚Üí AI Model
      ‚Üì              ‚Üì              ‚Üì              ‚Üì            ‚Üì
   Web UI      Event Handlers   OpenAI Client   HTTP API    Local GPU
```

### –ö—ô—É—á–Ω–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—ò–µ

**–û–±—Ä–∞—Å—Ü–∏ Foundry Local SDK-–∞:**
- `FoundryLocalManager(alias)`: –ê—É—Ç–æ–º–∞—Ç—Å–∫–æ —É–ø—Ä–∞–≤—ô–∞—ö–µ —Å–µ—Ä–≤–∏—Å–∏–º–∞
- `manager.endpoint` –∏ `manager.api_key`: –î–µ—Ç–∞—ô–∏ –∑–∞ –ø–æ–≤–µ–∑–∏–≤–∞—ö–µ
- `manager.get_model_info(alias).id`: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—ò–∞ –º–æ–¥–µ–ª–∞

**Chainlit –æ–∫–≤–∏—Ä:**
- `@cl.on_chat_start`: –ò–Ω–∏—Ü–∏—ò–∞–ª–∏–∑–∞—Ü–∏—ò–∞ —Å–µ—Å–∏—ò–∞ —õ–∞—Å–∫–∞—ö–∞
- `@cl.on_message`: –†—É–∫–æ–≤–∞—ö–µ –¥–æ–ª–∞–∑–Ω–∏–º –ø–æ—Ä—É–∫–∞–º–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫–∞  
- `cl.Message().stream_token()`: –°—Ç—Ä–∏–º–∏–Ω–≥ —É —Ä–µ–∞–ª–Ω–æ–º –≤—Ä–µ–º–µ–Ω—É
- –ê—É—Ç–æ–º–∞—Ç—Å–∫–æ –≥–µ–Ω–µ—Ä–∏—Å–∞—ö–µ UI-–∞ –∏ —É–ø—Ä–∞–≤—ô–∞—ö–µ WebSocket-–æ–º

## –î–µ–æ 2: –ú–∞—Ç—Ä–∏—Ü–∞ –æ–¥–ª—É–∫–µ –ª–æ–∫–∞–ª–Ω–æ vs –æ–±–ª–∞–∫

### –ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–µ –ø–µ—Ä—Ñ–æ—Ä–º–∞–Ω—Å–∏

| –ê—Å–ø–µ–∫—Ç | –õ–æ–∫–∞–ª–Ω–æ (Foundry) | –û–±–ª–∞–∫ (Azure OpenAI) |
|--------|-------------------|---------------------|
| **–ö–∞—à—ö–µ—ö–µ** | üöÄ 50-200ms (–±–µ–∑ –º—Ä–µ–∂–µ) | ‚è±Ô∏è 200-2000ms (–∑–∞–≤–∏—Å–Ω–æ –æ–¥ –º—Ä–µ–∂–µ) |
| **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç** | üîí –ü–æ–¥–∞—Ü–∏ –Ω–∏–∫–∞–¥–∞ –Ω–µ –Ω–∞–ø—É—à—Ç–∞—ò—É —É—Ä–µ—í–∞—ò | ‚ö†Ô∏è –ü–æ–¥–∞—Ü–∏ —Å–µ —à–∞—ô—É —É –æ–±–ª–∞–∫ |
| **–¶–µ–Ω–∞** | üí∞ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ –Ω–∞–∫–æ–Ω —Ö–∞—Ä–¥–≤–µ—Ä–∞ | üí∏ –ü–ª–∞—õ–∞—ö–µ –ø–æ —Ç–æ–∫–µ–Ω—É |
| **–û—Ñ–ª–∞—ò–Ω** | ‚úÖ –†–∞–¥–∏ –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ | ‚ùå –ó–∞—Ö—Ç–µ–≤–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç |
| **–í–µ–ª–∏—á–∏–Ω–∞ –º–æ–¥–µ–ª–∞** | ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ —Ö–∞—Ä–¥–≤–µ—Ä–æ–º | ‚úÖ –ü—Ä–∏—Å—Ç—É–ø –Ω–∞—ò–≤–µ—õ–∏–º –º–æ–¥–µ–ª–∏–º–∞ |
| **–°–∫–∞–ª–∞–±–∏–ª–Ω–æ—Å—Ç** | ‚ö†Ô∏è –ó–∞–≤–∏—Å–Ω–æ –æ–¥ —Ö–∞—Ä–¥–≤–µ—Ä–∞ | ‚úÖ –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ —Å–∫–∞–ª–∞–±–∏–ª–Ω–æ—Å—Ç |

### –û–±—Ä–∞—Å—Ü–∏ —Ö–∏–±—Ä–∏–¥–Ω–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—ò–µ

**–ü—Ä–≤–æ –ª–æ–∫–∞–ª–Ω–æ, —Å–∞ —Ä–µ–∑–µ—Ä–≤–æ–º:**
```python
async def hybrid_completion(prompt: str, complexity_threshold: int = 100):
    if len(prompt.split()) < complexity_threshold:
        return await local_completion(prompt)  # Fast, private
    else:
        return await cloud_completion(prompt)   # Complex reasoning
```

**–†—É—Ç–∏—Ä–∞—ö–µ –∑–∞—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∑–∞–¥–∞—Ü–∏–º–∞:**
```python
async def smart_routing(prompt: str, task_type: str):
    routing_rules = {
        "code_generation": "local",     # Privacy-sensitive
        "creative_writing": "cloud",    # Benefits from larger models
        "data_analysis": "local",       # Fast iteration needed
        "research": "cloud"             # Requires broad knowledge
    }
    
    if routing_rules.get(task_type) == "local":
        return await foundry_completion(prompt)
    else:
        return await azure_completion(prompt)
```

## –î–µ–æ 3: –ü—Ä–∏–º–µ—Ä 04 - Chainlit –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ

### –ë—Ä–∑–∏ –ø–æ—á–µ—Ç–∞–∫

```cmd
# Navigate to Module08 directory  
cd Module08

# Start your preferred model
foundry model run phi-4-mini

# Run the Chainlit application (avoiding port conflicts)
chainlit run samples\04\app.py -w --port 8080
```

–ê–ø–ª–∏–∫–∞—Ü–∏—ò–∞ —Å–µ –∞—É—Ç–æ–º–∞—Ç—Å–∫–∏ –æ—Ç–≤–∞—Ä–∞ –Ω–∞ `http://localhost:8080` —Å–∞ –º–æ–¥–µ—Ä–Ω–∏–º –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å–æ–º –∑–∞ —õ–∞—Å–∫–∞—ö–µ.

### –û—Å–Ω–æ–≤–Ω–∞ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—ò–∞

–ü—Ä–∏–º–µ—Ä 04 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞ –æ–±—Ä–∞—Å—Ü–µ —Å–ø—Ä–µ–º–Ω–µ –∑–∞ –ø—Ä–æ–¥—É–∫—Ü–∏—ò—É:

**–ê—É—Ç–æ–º–∞—Ç—Å–∫–æ –æ—Ç–∫—Ä–∏–≤–∞—ö–µ —Å–µ—Ä–≤–∏—Å–∞:**
```python
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

# Global variables for client and model
client = None
model_name = None

async def initialize_client():
    global client, model_name
    alias = os.environ.get("MODEL", "phi-4-mini")
    
    try:
        # Use FoundryLocalManager for proper service management
        manager = FoundryLocalManager(alias)
        model_info = manager.get_model_info(alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-required"
        )
        model_name = model_info.id if model_info else alias
        return True
    except Exception as e:
        # Fallback to manual configuration
        base_url = os.environ.get("BASE_URL", "http://localhost:51211")
        client = OpenAI(base_url=f"{base_url}/v1", api_key="not-required")
        model_name = alias
        return True
```

**–†—É–∫–æ–≤–∞—ö–µ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º —É —õ–∞—Å–∫–∞—ö—É:**
```python
@cl.on_message
async def main(message: cl.Message):
    # Create streaming response
    msg = cl.Message(content="")
    await msg.send()
    
    stream = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": message.content}
        ],
        stream=True
    )
    
    # Stream tokens in real-time
    for chunk in stream:
        if chunk.choices[0].delta.content:
            await msg.stream_token(chunk.choices[0].delta.content)
    
    await msg.update()
```

### –û–ø—Ü–∏—ò–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–µ

**–ï–Ω–≤–∏—Ä–æ–Ω–º–µ–Ω—Ç –ø—Ä–æ–º–µ–Ω—ô–∏–≤–µ:**

| –ü—Ä–æ–º–µ–Ω—ô–∏–≤–∞ | –û–ø–∏—Å | –ü–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–Ω–æ | –ü—Ä–∏–º–µ—Ä |
|------------|------|---------------|--------|
| `MODEL` | –ê–ª–∏—ò–∞—Å –º–æ–¥–µ–ª–∞ –∫–æ—ò–∏ —Å–µ –∫–æ—Ä–∏—Å—Ç–∏ | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Endpoint Foundry Local-–∞ | –ê—É—Ç–æ–º–∞—Ç—Å–∫–∏ –¥–µ—Ç–µ–∫—Ç–æ–≤–∞–Ω | `http://localhost:51211` |
| `API_KEY` | API –∫—ô—É—á (–æ–ø—Ü–∏–æ–Ω–æ –∑–∞ –ª–æ–∫–∞–ª–Ω–æ) | `""` | `your-api-key` |

**–ù–∞–ø—Ä–µ–¥–Ω–∞ —É–ø–æ—Ç—Ä–µ–±–∞:**
```cmd
# Use different model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Use different ports (avoid 51211 which is used by Foundry Local)
chainlit run samples\04\app.py -w --port 3000
chainlit run samples\04\app.py -w --port 5000
```

## –î–µ–æ 4: –ö—Ä–µ–∏—Ä–∞—ö–µ –∏ –∫–æ—Ä–∏—à—õ–µ—ö–µ Jupyter –Ω–æ—Ç–µ–±—É–∫–∞

### –ü—Ä–µ–≥–ª–µ–¥ –ø–æ–¥—Ä—à–∫–µ –∑–∞ –Ω–æ—Ç–µ–±—É–∫–µ

–ü—Ä–∏–º–µ—Ä 04 —É–∫—ô—É—á—É—ò–µ —Å–≤–µ–æ–±—É—Ö–≤–∞—Ç–∞–Ω Jupyter –Ω–æ—Ç–µ–±—É–∫ (`chainlit_app.ipynb`) –∫–æ—ò–∏ –ø—Ä—É–∂–∞:

- **üìö –ï–¥—É–∫–∞—Ç–∏–≤–Ω–∏ —Å–∞–¥—Ä–∂–∞—ò**: –ú–∞—Ç–µ—Ä–∏—ò–∞–ª–µ –∑–∞ —É—á–µ—ö–µ –∫–æ—Ä–∞–∫ –ø–æ –∫–æ—Ä–∞–∫
- **üî¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –∏—Å—Ç—Ä–∞–∂–∏–≤–∞—ö–µ**: –ü–æ–∫—Ä–µ—Ç–∞—ö–µ –∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Å–∞—ö–µ —Å–∞ –∫–æ–¥–Ω–∏–º —õ–µ–ª–∏—ò–∞–º–∞
- **üìä –í–∏–∑—É–µ–ª–Ω–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—ò–µ**: –ì—Ä–∞—Ñ–∏–∫–æ–Ω–∏, –¥–∏—ò–∞–≥—Ä–∞–º–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞ –∏–∑–ª–∞–∑–Ω–∏—Ö –ø–æ–¥–∞—Ç–∞–∫–∞
- **üõ†Ô∏è –ê–ª–∞—Ç–∫–µ –∑–∞ —Ä–∞–∑–≤–æ—ò**: –¢–µ—Å—Ç–∏—Ä–∞—ö–µ –∏ –æ—Ç–∫–ª–∞—ö–∞—ö–µ –≥—Ä–µ—à–∞–∫–∞

### –ö—Ä–µ–∏—Ä–∞—ö–µ —Å–æ–ø—Å—Ç–≤–µ–Ω–∏—Ö –Ω–æ—Ç–µ–±—É–∫–∞

#### –ö–æ—Ä–∞–∫ 1: –ü–æ—Å—Ç–∞–≤—ô–∞—ö–µ Jupyter –æ–∫—Ä—É–∂–µ—ö–∞

```cmd
# Ensure you're in the Module08 directory
cd Module08

# Activate your virtual environment
.venv\Scripts\activate

# Install Jupyter and dependencies
pip install jupyter notebook jupyterlab ipykernel
pip install -r requirements.txt

# Register the kernel for VS Code
python -m ipykernel install --user --name=foundry-local --display-name="Foundry Local"
```

#### –ö–æ—Ä–∞–∫ 2: –ö—Ä–µ–∏—Ä–∞—ö–µ –Ω–æ–≤–æ–≥ –Ω–æ—Ç–µ–±—É–∫–∞

**–ö–æ—Ä–∏—à—õ–µ—ö–µ VS Code-–∞:**
1. –û—Ç–≤–æ—Ä–∏—Ç–µ VS Code —É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—ò—É–º—É Module08
2. –ö—Ä–µ–∏—Ä–∞—ò—Ç–µ –Ω–æ–≤—É –¥–∞—Ç–æ—Ç–µ–∫—É —Å–∞ –µ–∫—Å—Ç–µ–Ω–∑–∏—ò–æ–º `.ipynb`
3. –ò–∑–∞–±–µ—Ä–∏—Ç–µ "Foundry Local" —ò–µ–∑–≥—Ä–æ –∫–∞–¥–∞ —Å–µ —Ç–æ –∑–∞—Ç—Ä–∞–∂–∏
4. –ü–æ—á–Ω–∏—Ç–µ —Å–∞ –¥–æ–¥–∞–≤–∞—ö–µ–º —õ–µ–ª–∏—ò–∞ —Å–∞ –≤–∞—à–∏–º —Å–∞–¥—Ä–∂–∞—ò–µ–º

**–ö–æ—Ä–∏—à—õ–µ—ö–µ Jupyter Lab-–∞:**
```cmd
# Start Jupyter Lab
jupyter lab

# Navigate to samples/04/ and create new notebook
# Choose Python 3 kernel
```

### –ù–∞—ò–±–æ—ô–µ –ø—Ä–∞–∫—Å–µ –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–æ—Ç–µ–±—É–∫–∞

#### –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—ò–∞ —õ–µ–ª–∏—ò–∞

```python
# Cell 1: Imports and Setup
import os
import sys
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

print("‚úÖ Libraries imported successfully")
```

```python
# Cell 2: Configuration and Client Setup
class FoundryClientManager:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.client = None
        
    def initialize_client(self):
        # Client initialization logic
        pass

# Initialize and test
client_manager = FoundryClientManager()
result = client_manager.initialize_client()
print(f"Client initialized: {result}")
```

### –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏ –ø—Ä–∏–º–µ—Ä–∏ –∏ –≤–µ–∂–±–µ

#### –í–µ–∂–±–∞ 1: –¢–µ—Å—Ç–∏—Ä–∞—ö–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–µ –∫–ª–∏—ò–µ–Ω—Ç–∞

```python
# Test different configuration methods
configurations = [
    {"method": "foundry_sdk", "model": "phi-4-mini"},
    {"method": "manual", "base_url": "http://localhost:51211", "model": "qwen2.5-7b"},
]

for config in configurations:
    print(f"\nüß™ Testing {config['method']} configuration...")
    # Implementation here
    result = test_configuration(config)
    print(f"Result: {'‚úÖ Success' if result['status'] == 'ok' else '‚ùå Failed'}")
```

#### –í–µ–∂–±–∞ 2: –°–∏–º—É–ª–∞—Ü–∏—ò–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ–¥–≥–æ–≤–æ—Ä–∞

```python
import asyncio

async def simulate_streaming_response(text, delay=0.1):
    """Simulate how streaming works in Chainlit."""
    print("üåä Simulating streaming response...")
    
    for char in text:
        print(char, end='', flush=True)
        await asyncio.sleep(delay)
    
    print("\n‚úÖ Streaming complete!")

# Test the simulation
sample_text = "This is how streaming responses work in Chainlit applications!"
await simulate_streaming_response(sample_text)
```

## –î–µ–æ 5: WebGPU –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—ò–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—ò–µ —É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É

### –ü—Ä–µ–≥–ª–µ–¥

WebGPU –æ–º–æ–≥—É—õ–∞–≤–∞ –ø–æ–∫—Ä–µ—Ç–∞—ö–µ AI –º–æ–¥–µ–ª–∞ –¥–∏—Ä–µ–∫—Ç–Ω–æ —É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω—É –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç –∏ –∏—Å–∫—É—Å—Ç–≤–∞ –±–µ–∑ –∏–Ω—Å—Ç–∞–ª–∞—Ü–∏—ò–µ. –û–≤–∞—ò –ø—Ä–∏–º–µ—Ä –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞ ONNX Runtime Web —Å–∞ WebGPU –∏–∑–≤—Ä—à–∞–≤–∞—ö–µ–º.

### –ö–æ—Ä–∞–∫ 1: –ü—Ä–æ–≤–µ—Ä–∞ –ø–æ–¥—Ä—à–∫–µ –∑–∞ WebGPU

**–ó–∞—Ö—Ç–µ–≤–∏ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á–∞:**
- Chrome/Edge 113+ —Å–∞ –æ–º–æ–≥—É—õ–µ–Ω–∏–º WebGPU-–æ–º
- –ü—Ä–æ–≤–µ—Ä–∞: `chrome://gpu` ‚Üí –ø–æ—Ç–≤—Ä–¥–∏—Ç–µ —Å—Ç–∞—Ç—É—Å "WebGPU"
- –ü—Ä–æ–≥—Ä–∞–º—Å–∫–∞ –ø—Ä–æ–≤–µ—Ä–∞: `if (!('gpu' in navigator)) { /* no WebGPU */ }`

### –ö–æ—Ä–∞–∫ 2: –ö—Ä–µ–∏—Ä–∞—ö–µ WebGPU –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—ò–µ

–ö—Ä–µ–∏—Ä–∞—ò—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—ò—É–º: `samples/04/webgpu-demo/`

**index.html:**
```html
<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WebGPU + ONNX Runtime Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
    <style>
        body { font-family: system-ui, sans-serif; margin: 2rem; }
        pre { background: #f5f5f5; padding: 1rem; overflow: auto; }
        .status { padding: 1rem; background: #e3f2fd; border-radius: 4px; }
    </style>
</head>
<body>
    <h1>üöÄ WebGPU + Foundry Local Integration</h1>
    <div id="status" class="status">Initializing...</div>
    <pre id="output"></pre>
    <script type="module" src="./main.js"></script>
</body>
</html>
```

**main.js:**
```javascript
const statusEl = document.getElementById('status');
const outputEl = document.getElementById('output');

function log(msg) {
    outputEl.textContent += `${msg}\n`;
    console.log(msg);
}

(async () => {
    try {
        if (!('gpu' in navigator)) {
            statusEl.textContent = '‚ùå WebGPU not available';
            return;
        }
        
        statusEl.textContent = 'üîç WebGPU detected. Loading model...';
        
        // Use a small ONNX model for demo
        const modelUrl = 'https://huggingface.co/onnx/models/resolve/main/vision/classification/mnist-12/mnist-12.onnx';
        
        const session = await ort.InferenceSession.create(modelUrl, {
            executionProviders: ['webgpu']
        });
        
        log('‚úÖ ONNX Runtime session created with WebGPU');
        log(`üìä Input names: ${session.inputNames.join(', ')}`);
        log(`üìä Output names: ${session.outputNames.join(', ')}`);
        
        // Create dummy input (MNIST expects 1x1x28x28)
        const inputData = new Float32Array(1 * 1 * 28 * 28).fill(0.1);
        const input = new ort.Tensor('float32', inputData, [1, 1, 28, 28]);
        
        const feeds = {};
        feeds[session.inputNames[0]] = input;
        
        const results = await session.run(feeds);
        const output = results[session.outputNames[0]];
        
        // Find prediction (argmax)
        let maxIdx = 0;
        for (let i = 1; i < output.data.length; i++) {
            if (output.data[i] > output.data[maxIdx]) maxIdx = i;
        }
        
        statusEl.textContent = '‚úÖ WebGPU inference complete!';
        log(`üéØ Predicted class: ${maxIdx}`);
        log(`üìà Confidence scores: [${Array.from(output.data).map(x => x.toFixed(3)).join(', ')}]`);
        
    } catch (error) {
        statusEl.textContent = `‚ùå Error: ${error.message}`;
        log(`Error: ${error.message}`);
        console.error(error);
    }
})();
```

### –ö–æ—Ä–∞–∫ 3: –ü–æ–∫—Ä–µ—Ç–∞—ö–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—ò–µ

```cmd
# Create demo directory
mkdir samples\04\webgpu-demo
cd samples\04\webgpu-demo

# Save HTML and JS files, then serve
python -m http.server 5173

# Open browser to http://localhost:5173
```

## –î–µ–æ 6: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—ò–∞ Open WebUI-–∞

### –ü—Ä–µ–≥–ª–µ–¥

Open WebUI –ø—Ä—É–∂–∞ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–Ω–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å —Å–ª–∏—á–∞–Ω ChatGPT-—É –∫–æ—ò–∏ —Å–µ –ø–æ–≤–µ–∑—É—ò–µ —Å–∞ OpenAI-–∫–æ–º–ø–∞—Ç–∏–±–∏–ª–Ω–∏–º API-—ò–µ–º Foundry Local-–∞.

### –ö–æ—Ä–∞–∫ 1: –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏

```cmd
# Verify Foundry Local is running
foundry service status

# Start a model
foundry model run phi-4-mini

# Confirm API endpoint is accessible
curl http://localhost:51211/v1/models
```

### –ö–æ—Ä–∞–∫ 2: Docker –ø–æ–¥–µ—à–∞–≤–∞—ö–µ (–ø—Ä–µ–ø–æ—Ä—É—á–µ–Ω–æ)

```cmd
# Pull Open WebUI image
docker pull ghcr.io/open-webui/open-webui:main

# Run with Foundry Local connection
docker run -d --name open-webui -p 3000:8080 ^
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 ^
  -e OPENAI_API_KEY=foundry-local-key ^
  -v open-webui-data:/app/backend/data ^
  ghcr.io/open-webui/open-webui:main
```

**–ù–∞–ø–æ–º–µ–Ω–∞:** `host.docker.internal` –æ–º–æ–≥—É—õ–∞–≤–∞ Docker –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä–∏–º–∞ –ø—Ä–∏—Å—Ç—É–ø —Ö–æ—Å—Ç –º–∞—à–∏–Ω–∏ –Ω–∞ Windows-—É.

### –ö–æ—Ä–∞–∫ 3: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞

1. **–û—Ç–≤–æ—Ä–∏—Ç–µ –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á:** –ò–¥–∏—Ç–µ –Ω–∞ `http://localhost:3000`
2. **–ü–æ—á–µ—Ç–Ω–æ –ø–æ–¥–µ—à–∞–≤–∞—ö–µ:** –ö—Ä–µ–∏—Ä–∞—ò—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—Å–∫–∏ –Ω–∞–ª–æ–≥
3. **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞ –º–æ–¥–µ–ª–∞:**
   - –ü–æ–¥–µ—à–∞–≤–∞—ö–∞ ‚Üí –ú–æ–¥–µ–ª–∏ ‚Üí OpenAI API  
   - –û—Å–Ω–æ–≤–Ω–∏ URL: `http://host.docker.internal:51211/v1`
   - API –∫—ô—É—á: `foundry-local-key` (–±–∏–ª–æ –∫–æ—ò–∞ –≤—Ä–µ–¥–Ω–æ—Å—Ç —Ä–∞–¥–∏)
4. **–¢–µ—Å—Ç–∏—Ä–∞—ò—Ç–µ –≤–µ–∑—É:** –ú–æ–¥–µ–ª–∏ –±–∏ —Ç—Ä–µ–±–∞–ª–æ –¥–∞ —Å–µ –ø–æ—ò–∞–≤–µ —É –ø–∞–¥–∞—ò—É—õ–µ–º –º–µ–Ω–∏—ò—É

### –û—Ç–∫–ª–∞—ö–∞—ö–µ –ø—Ä–æ–±–ª–µ–º–∞

**–ß–µ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏:**

1. **–í–µ–∑–∞ –æ–¥–±–∏—ò–µ–Ω–∞:**
   ```cmd
   # Check Foundry Local status
   foundry service ps
   netstat -ano | findstr :51211
   ```

2. **–ú–æ–¥–µ–ª–∏ —Å–µ –Ω–µ –ø–æ—ò–∞–≤—ô—É—ò—É:**
   - –ü–æ—Ç–≤—Ä–¥–∏—Ç–µ –¥–∞ —ò–µ –º–æ–¥–µ–ª —É—á–∏—Ç–∞–Ω: `foundry model list`
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç–µ API –æ–¥–≥–æ–≤–æ—Ä: `curl http://localhost:51211/v1/models`
   - –ü–æ–Ω–æ–≤–æ –ø–æ–∫—Ä–µ–Ω–∏—Ç–µ Open WebUI –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä

## –î–µ–æ 7: –†–∞–∑–º–∞—Ç—Ä–∞—ö–∞ –∑–∞ –ø—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–æ –ø–æ—Å—Ç–∞–≤—ô–∞—ö–µ

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞ –æ–∫—Ä—É–∂–µ—ö–∞

**–†–∞–∑–≤–æ—ò–Ω–æ –æ–∫—Ä—É–∂–µ—ö–µ:**
```cmd
# Development with auto-reload and debugging
chainlit run samples\04\app.py -w --port 8080 --debug
```

**–ü—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–æ –ø–æ—Å—Ç–∞–≤—ô–∞—ö–µ:**
```cmd
# Production mode with optimizations
chainlit run samples\04\app.py --host 0.0.0.0 --port 8080 --no-cache
```

### –ß–µ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏ —Å–∞ –ø–æ—Ä—Ç–æ–≤–∏–º–∞ –∏ —Ä–µ—à–µ—ö–∞

**–ü—Ä–µ–≤–µ–Ω—Ü–∏—ò–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –ø–æ—Ä—Ç–∞ 51211:**
```cmd
# Check what's using Foundry Local port
netstat -ano | findstr :51211

# Use different port for Chainlit
chainlit run samples\04\app.py -w --port 8080
```

### –ü—Ä–∞—õ–µ—ö–µ –ø–µ—Ä—Ñ–æ—Ä–º–∞–Ω—Å–∏

**–ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ –ø—Ä–æ–≤–µ—Ä–µ –∑–¥—Ä–∞–≤—ô–∞:**
```python
@cl.on_chat_start
async def health_check():
    try:
        # Test model availability
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1
        )
        return {"status": "healthy", "model": model_name}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

## –†–µ–∑–∏–º–µ

–°–µ—Å–∏—ò–∞ 4 —ò–µ –æ–±—É—Ö–≤–∞—Ç–∏–ª–∞ –∏–∑–≥—Ä–∞–¥—ö—É –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ —Å–ø—Ä–µ–º–Ω–∏—Ö –∑–∞ –ø—Ä–æ–¥—É–∫—Ü–∏—ò—É —É–∑ Chainlit –∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏ AI. –ù–∞—É—á–∏–ª–∏ —Å—Ç–µ –æ:

- ‚úÖ **Chainlit –æ–∫–≤–∏—Ä—É**: –ú–æ–¥–µ—Ä–∞–Ω UI –∏ –ø–æ–¥—Ä—à–∫–∞ –∑–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥ —É –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞–º–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ
- ‚úÖ **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—ò–∏ Foundry Local-–∞**: –£–ø–æ—Ç—Ä–µ–±–∞ SDK-–∞ –∏ –æ–±—Ä–∞—Å—Ü–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–µ  
- ‚úÖ **WebGPU –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—ò–∏**: AI —É –ø—Ä–µ—Ç—Ä–∞–∂–∏–≤–∞—á—É –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω—É –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç
- ‚úÖ **–ü–æ–¥–µ—à–∞–≤–∞—ö—É Open WebUI-–∞**: –ü–æ—Å—Ç–∞–≤—ô–∞—ö–µ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–Ω–æ–≥ –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ
- ‚úÖ **–ü—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–∏–º –æ–±—Ä–∞—Å—Ü–∏–º–∞**: –†—É–∫–æ–≤–∞—ö–µ –≥—Ä–µ—à–∫–∞–º–∞, –ø—Ä–∞—õ–µ—ö–µ –∏ —Å–∫–∞–ª–∞–±–∏–ª–Ω–æ—Å—Ç

–ü—Ä–∏–º–µ—Ä 04 –∞–ø–ª–∏–∫–∞—Ü–∏—ò–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞ –Ω–∞—ò–±–æ—ô–µ –ø—Ä–∞–∫—Å–µ –∑–∞ –∏–∑–≥—Ä–∞–¥—ö—É —Ä–æ–±—É—Å–Ω–∏—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ—ò—Å–∞ –∑–∞ —õ–∞—Å–∫–∞—ö–µ –∫–æ—ò–∏ –∫–æ—Ä–∏—Å—Ç–µ –ª–æ–∫–∞–ª–Ω–µ AI –º–æ–¥–µ–ª–µ –ø—Ä–µ–∫–æ Microsoft Foundry Local-–∞, —É–∑ –ø—Ä—É–∂–∞—ö–µ –æ–¥–ª–∏—á–Ω–æ–≥ –∫–æ—Ä–∏—Å–Ω–∏—á–∫–æ–≥ –∏—Å–∫—É—Å—Ç–≤–∞.

## –†–µ—Ñ–µ—Ä–µ–Ω—Ü–µ

- **[–ü—Ä–∏–º–µ—Ä 04: Chainlit –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞](samples/04/README.md)**: –ö–æ–º–ø–ª–µ—Ç–Ω–∞ –∞–ø–ª–∏–∫–∞—Ü–∏—ò–∞ —Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—ò–æ–º
- **[–ï–¥—É–∫–∞—Ç–∏–≤–Ω–∏ –Ω–æ—Ç–µ–±—É–∫ Chainlit](samples/04/chainlit_app.ipynb)**: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏ –º–∞—Ç–µ—Ä–∏—ò–∞–ª–∏ –∑–∞ —É—á–µ—ö–µ
- **[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ Foundry Local-–∞](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: –ö–æ–º–ø–ª–µ—Ç–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ
- **[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ Chainlit-–∞](https://docs.chainlit.io/)**: –ó–≤–∞–Ω–∏—á–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—ò–∞ –æ–∫–≤–∏—Ä–∞
- **[–í–æ–¥–∏—á –∑–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—ò—É Open WebUI-–∞](https://github.com/microsoft/foundry-local/blob/main/docs/tutorials/chat-application-with-open-web-ui.md)**: –ó–≤–∞–Ω–∏—á–Ω–∏ —Ç—É—Ç–æ—Ä–∏—ò–∞–ª

---

**–û–¥—Ä–∏—Ü–∞—ö–µ –æ–¥ –æ–¥–≥–æ–≤–æ—Ä–Ω–æ—Å—Ç–∏**:  
–û–≤–∞—ò –¥–æ–∫—É–º–µ–Ω—Ç —ò–µ –ø—Ä–µ–≤–µ–¥–µ–Ω –ø–æ–º–æ—õ—É —É—Å–ª—É–≥–µ –∑–∞ –ø—Ä–µ–≤–æ—í–µ—ö–µ —É–∑ –ø–æ–º–æ—õ –≤–µ—à—Ç–∞—á–∫–µ –∏–Ω—Ç–µ–ª–∏–≥–µ–Ω—Ü–∏—ò–µ [Co-op Translator](https://github.com/Azure/co-op-translator). –ò–∞–∫–æ –Ω–∞—Å—Ç–æ—ò–∏–º–æ –¥–∞ –æ–±–µ–∑–±–µ–¥–∏–º–æ —Ç–∞—á–Ω–æ—Å—Ç, –º–æ–ª–∏–º–æ –≤–∞—Å –¥–∞ –∏–º–∞—Ç–µ —É –≤–∏–¥—É –¥–∞ –∞—É—Ç–æ–º–∞—Ç—Å–∫–∏ –ø—Ä–µ–≤–æ–¥–∏ –º–æ–≥—É —Å–∞–¥—Ä–∂–∞—Ç–∏ –≥—Ä–µ—à–∫–µ –∏–ª–∏ –Ω–µ—Ç–∞—á–Ω–æ—Å—Ç–∏. –û—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —ö–µ–≥–æ–≤–æ–º –∏–∑–≤–æ—Ä–Ω–æ–º —ò–µ–∑–∏–∫—É —Ç—Ä–µ–±–∞ —Å–º–∞—Ç—Ä–∞—Ç–∏ –º–µ—Ä–æ–¥–∞–≤–Ω–∏–º –∏–∑–≤–æ—Ä–æ–º. –ó–∞ –∫—Ä–∏—Ç–∏—á–Ω–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–µ –ø—Ä–µ–ø–æ—Ä—É—á—É—ò–µ —Å–µ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–Ω–∏ –ø—Ä–µ–≤–æ–¥ –æ–¥ —Å—Ç—Ä–∞–Ω–µ —ô—É–¥—Å–∫–æ–≥ –ø—Ä–µ–≤–æ–¥–∏–æ—Ü–∞. –ù–µ –ø—Ä–µ—É–∑–∏–º–∞–º–æ –æ–¥–≥–æ–≤–æ—Ä–Ω–æ—Å—Ç –∑–∞ –±–∏–ª–æ –∫–∞–∫–≤–∞ –ø–æ–≥—Ä–µ—à–Ω–∞ —Ç—É–º–∞—á–µ—ö–∞ –∏–ª–∏ –Ω–µ—Å–ø–æ—Ä–∞–∑—É–º–µ –∫–æ—ò–∏ –º–æ–≥—É –Ω–∞—Å—Ç–∞—Ç–∏ —É—Å–ª–µ–¥ –∫–æ—Ä–∏—à—õ–µ—ö–∞ –æ–≤–æ–≥ –ø—Ä–µ–≤–æ–¥–∞.