<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1b09b5c867abbccfdbc826d857ae0c2",
  "translation_date": "2025-09-25T01:56:12+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "sr"
}
-->
# Сесија 3: Откривање и управљање моделима отвореног кода

## Преглед

Ова сесија се фокусира на практично откривање и управљање моделима уз Foundry Local. Научићете како да листате доступне моделе, тестирате различите опције и разумете основне карактеристике перформанси. Приступ наглашава практично истраживање уз помоћ foundry CLI-а како бисте одабрали праве моделе за ваше случајеве употребе.

## Циљеви учења

- Савладајте foundry CLI команде за откривање и управљање моделима
- Разумите кеш модела и обрасце локалног складиштења
- Научите како брзо тестирати и упоређивати различите моделе
- Успоставите практичне радне токове за избор модела и бенчмаркинг
- Истражите растући екосистем модела доступних кроз Foundry Local

## Предуслови

- Завршена Сесија 1: Увод у Foundry Local
- Инсталиран и доступан Foundry Local CLI
- Довољно простора за складиштење за преузимање модела (модели могу бити од 1GB до 20GB+)
- Основно разумевање типова модела и случајева употребе

## Преглед

Ова сесија истражује како довести моделе отвореног кода у Foundry Local.

## Део 6: Практична вежба

### Вежба: Откривање и поређење модела

Направите сопствени скрипт за евалуацију модела на основу Примера 03:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```


### Ваш задатак

1. **Покрените скрипт Пример 03**: `samples\03\list_and_bench.cmd`
2. **Испробајте различите моделе**: Тестирајте најмање 3 различита модела
3. **Упоредите перформансе**: Забележите разлике у брзини и квалитету одговора
4. **Документујте налазе**: Направите једноставну табелу поређења

### Пример формата поређења

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```


## Део 7: Решавање проблема и најбоље праксе

### Уобичајени проблеми и решења

**Модел се не покреће:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```


**Недовољно меморије:**
- Почните са мањим моделима (`phi-4-mini`)
- Затворите друге апликације
- Надоградите RAM ако често наилазите на ограничења

**Споре перформансе:**
- Уверите се да је модел у потпуности учитан (проверите детаљни излаз)
- Затворите непотребне апликације у позадини
- Размотрите брже складиштење (SSD)

### Најбоље праксе

1. **Почните са мањим моделима**: Користите `phi-4-mini` за проверу подешавања
2. **Један модел у исто време**: Зауставите претходне моделе пре покретања нових
3. **Пратите ресурсе**: Пратите употребу меморије
4. **Тестирајте доследно**: Користите исте упите за фер поређења
5. **Документујте резултате**: Водите белешке о перформансама модела за ваше случајеве употребе

## Део 8: Следећи кораци и референце

### Припрема за Сесију 4

- **Фокус Сесије 4**: Алатке и технике оптимизације
- **Предуслови**: Удобност са променом модела и основним тестирањем перформанси
- **Препоручено**: Идентификујте 2-3 омиљена модела из ове сесије

### Додатни ресурси

- **[Foundry Local документација](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Званична документација
- **[CLI референца](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Комплетна референца команди
- **[Model Mondays](https://aka.ms/model-mondays)**: Недељни прегледи модела
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Заједница и питања
- **[Пример 03: Откривање модела](samples/03/README.md)**: Практичан пример скрипте

### Кључни закључци

✅ **Откривање модела**: Користите `foundry model list` за истраживање доступних модела  
✅ **Брзо тестирање**: Шаблон `list_and_bench.cmd` за брзу евалуацију  
✅ **Праћење перформанси**: Основно мерење употребе ресурса и времена одговора  
✅ **Избор модела**: Практичне смернице за избор модела према случају употребе  
✅ **Управљање кешом**: Разумевање процедура складиштења и чишћења  

Сада имате практичне вештине за откривање, тестирање и избор одговарајућих модела за ваше AI апликације користећи једноставан CLI приступ Foundry Local-а.

## Циљеви учења

- Откријте и евалуирајте моделе отвореног кода за локалну инференцију
- Компилирајте и покрените одабране Hugging Face моделе у Foundry Local
- Примените стратегије избора модела за тачност, кашњење и потребе ресурса
- Управљајте моделима локално уз кеш и верзионисање

## Део 1: Откривање модела уз Foundry CLI

### Основне команде за управљање моделима

Foundry CLI пружа једноставне команде за откривање и управљање моделима:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```


### Покретање ваших првих модела

Почните са популарним, добро тестираним моделима како бисте разумели карактеристике перформанси:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b-instruct --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-distill-qwen-7b --verbose
```


**Напомена:** Ознака `--verbose` пружа детаљне информације о покретању, укључујући:
- Напредак преузимања модела (при првом покретању)
- Детаље о алокацији меморије
- Информације о повезивању услуга
- Метрике иницијализације перформанси

### Разумевање категорија модела

**Мали језички модели (SLMs):**
- `phi-4-mini`: Брз, ефикасан, одличан за општи разговор
- `phi-4`: Способнија верзија са бољим резоновањем

**Средњи модели:**
- `qwen2.5-7b-instruct`: Одлично резоновање и дужи контекст
- `deepseek-r1-distill-qwen-7b`: Оптимизован за генерисање кода

**Велики модели:**
- `llama-3.2`: Најновији модел отвореног кода од Meta
- `qwen2.5-14b-instruct`: Разоновање на нивоу предузећа

## Део 2: Брзо тестирање и поређење модела

### Приступ Пример 03: Једноставно листање и бенчмаркинг

На основу нашег шаблона Пример 03, ево минималног радног тока:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```


### Тестирање перформанси модела

Када је модел покренут, тестирајте га уз доследне упите:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```


### Алтернатива тестирању у PowerShell-у

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```


## Део 3: Управљање кешом и складиштењем модела

### Разумевање кеша модела

Foundry Local аутоматски управља преузимањем и кеширањем модела:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```


### Разматрања складиштења модела

**Типичне величине модела:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b-instruct`: ~4.1 GB  
- `deepseek-r1-distill-qwen-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b-instruct`: ~8.2 GB

**Најбоље праксе складиштења:**
- Држите 2-3 модела кеширана за брзу промену
- Уклоните неупотребљиве моделе ради ослобађања простора: `foundry cache clean`
- Пратите употребу диска, посебно на мањим SSD-овима
- Размотрите компромис између величине модела и његових способности

### Праћење перформанси модела

Док модели раде, пратите системске ресурсе:

**Windows Task Manager:**
- Пратите употребу меморије (модели остају учитани у RAM-у)
- Пратите употребу CPU-а током инференције
- Проверите I/O диска током иницијалног учитавања модела

**Праћење из командне линије:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```


## Део 4: Практичне смернице за избор модела

### Избор модела према случају употребе

**За општи разговор и Q&A:**
- Почните са: `phi-4-mini` (брз, ефикасан)
- Надоградите на: `phi-4` (боље резоновање)
- Напредно: `qwen2.5-7b-instruct` (дужи контекст)

**За генерисање кода:**
- Препоручено: `deepseek-r1-distill-qwen-7b`
- Алтернатива: `qwen2.5-7b-instruct` (такође добар за код)

**За сложено резоновање:**
- Најбоље: `qwen2.5-7b-instruct` или `qwen2.5-14b-instruct`
- Буџетска опција: `phi-4`

### Водич за хардверске захтеве

**Минимални системски захтеви:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```


**Препоручено за најбоље перформансе:**
- 32GB+ RAM за удобну промену више модела
- SSD складиштење за брже учитавање модела
- Модеран CPU са добрим перформансама једног језгра
- Подршка за NPU (Windows 11 Copilot+ рачунари) за убрзање

### Радни ток за промену модела

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b-instruct

REM Verify model is running
foundry service status
```


## Део 5: Једноставно бенчмаркирање модела

### Основно тестирање перформанси

Ево једноставног приступа за поређење перформанси модела:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b-instruct", "deepseek-r1-distill-qwen-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```


### Ручна процена квалитета

За сваки модел, тестирајте уз доследне упите и ручно процените:

**Тест упити:**
1. "Објасни квантно рачунарство на једноставан начин."
2. "Напиши Python функцију за сортирање листе."
3. "Које су предности и мане рада на даљину?"
4. "Сажми предности edge AI-а."

**Критеријуми процене:**
- **Тачност**: Да ли су информације исправне?
- **Јасноћа**: Да ли је објашњење лако разумљиво?
- **Потпуност**: Да ли одговара на цело питање?
- **Брзина**: Колико брзо одговара?

### Праћење употребе ресурса

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```


## Део 6: Следећи кораци

- Претплатите се на Model Mondays за нове моделе и савете: https://aka.ms/model-mondays
- Допринесите налазима у тимски `models.json`
- Припремите се за Сесију 4: поређење LLM-ова и SLM-ова, локална и cloud инференција, и практичне демонстрације

---

