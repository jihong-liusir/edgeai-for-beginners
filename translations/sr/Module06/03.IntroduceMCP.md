<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bd5b920b610665fd0462f6b5c2e134",
  "translation_date": "2025-09-18T23:52:36+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "sr"
}
-->
# Секција 03 - Интеграција Протокола Контекста Модела (MCP)

## Увод у MCP (Протокол Контекста Модела)

Протокол Контекста Модела (MCP) је револуционарни оквир који омогућава језичким моделима да комуницирају са спољашњим алатима и системима на стандардизован начин. За разлику од традиционалних приступа где су модели изоловани, MCP ствара мост између AI модела и стварног света кроз добро дефинисан протокол.

### Шта је MCP?

MCP служи као комуникациони протокол који омогућава језичким моделима да:
- Повезују се са спољашњим изворима података
- Извршавају алате и функције
- Комуницирају са API-јима и услугама
- Приступају информацијама у реалном времену
- Изводе сложене операције у више корака

Овај протокол трансформише статичне језичке моделе у динамичне агенте способне за обављање практичних задатака изван генерисања текста.

## Мали Језички Модели (SLMs) у MCP

Мали Језички Модели представљају ефикасан приступ примени AI-а, нудећи неколико предности:

### Предности SLM-ова
- **Ефикасност ресурса**: Мањи захтеви за рачунарским ресурсима
- **Брже време одзива**: Смањена латенција за апликације у реалном времену  
- **Исплативост**: Минимални инфраструктурни захтеви
- **Приватност**: Могу радити локално без преноса података
- **Прилагођавање**: Лакше прилагођавање за специфичне домене

### Зашто SLM-ови добро функционишу са MCP-ом

SLM-ови у комбинацији са MCP-ом стварају моћну комбинацију где се способности резоновања модела допуњују спољашњим алатима, надокнађујући мањи број параметара кроз побољшану функционалност.

## Преглед Python MCP SDK-а

Python MCP SDK пружа основу за изградњу апликација које подржавају MCP. SDK укључује:

- **Клијентске библиотеке**: За повезивање са MCP серверима
- **Оквир за сервере**: За креирање прилагођених MCP сервера
- **Руководиоце протокола**: За управљање комуникацијом
- **Интеграцију алата**: За извршавање спољашњих функција

## Практична имплементација: Phi-4 MCP Клијент

Хајде да истражимо имплементацију у стварном свету користећи Microsoft-ов Phi-4 мини модел интегрисан са MCP могућностима.

### Архитектура система

Имплементација прати слојевиту архитектуру:

```
┌─────────────────────────────────────┐
│        Application Layer           │
│  ├── Interactive Loop              │
│  ├── CLI Interface                 │
│  └── Configuration Management      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│         LLM Client Layer           │
│  ├── OllamaClient                  │
│  ├── VLLMClient                    │
│  └── LLMClient (Abstract)          │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│        MCP Client Layer            │
│  ├── Phi4MiniMCPClient (STDIO)     │
│  ├── Phi4MiniSSEMCPClient (SSE)    │
│  └── BaseMCPClient (Abstract)      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│      Tool Processing Layer         │
│  ├── ToolCallHandler               │
│  ├── Function Format Transformer   │
│  └── Tool Schema Management        │
└─────────────────────────────────────┘
```

### Основне компоненте

#### 1. MCP Клијентске класе

**BaseMCPClient**: Апстрактна основа која пружа заједничку функционалност
- Асинхрони протокол за управљање контекстом
- Дефиниција стандардног интерфејса
- Управљање ресурсима

**Phi4MiniMCPClient**: Имплементација заснована на STDIO
- Локална комуникација процеса
- Управљање стандардним улазом/излазом
- Управљање подпроцесима

**Phi4MiniSSEMCPClient**: Имплементација заснована на догађајима које шаље сервер
- HTTP стриминг комуникација
- Управљање догађајима у реалном времену
- Повезивање са серверима преко веба

#### 2. Интеграција LLM-а

**OllamaClient**: Локално хостовање модела
```python
class OllamaClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:11434/api/chat"
        self.model_id = "phi4-mini:3.8b-fp16"
```

**VLLMClient**: Високоперформансно сервирање
```python
class VLLMClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:8000/v1"
        self.model_id = "microsoft/Phi-4-mini-instruct"
```

#### 3. Цевовод за обраду алата

Цевовод за обраду алата трансформише MCP алате у формате компатибилне са језичким моделима:

```python
def transform_functions_format(input_data):
    """Convert MCP tool schemas to LLM-compatible formats"""
    # Maps OpenAPI schemas to function calling schemas
    # Handles parameter type conversion
    # Maintains required field information
```

## Почетак рада: Водич корак по корак

### Корак 1: Подешавање окружења

Инсталирајте потребне зависности:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Корак 2: Основна конфигурација

Подесите променљиве окружења:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Корак 3: Покретање вашег првог MCP клијента

**Основно Ollama подешавање:**
```bash
python ghmodel_mcp_demo.py
```

**Коришћење vLLM позадине:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Повезивање преко догађаја које шаље сервер:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Прилагођени MCP сервер:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Корак 4: Програмска употреба

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Напредне функције

### Подршка за више позадина

Имплементација подржава и Ollama и vLLM позадине, омогућавајући вам да изаберете на основу ваших потреба:

- **Ollama**: Боље за локални развој и тестирање
- **vLLM**: Оптимизовано за продукцију и сценарије са великим протоком

### Флексибилни протоколи за повезивање

Подржана су два режима повезивања:

**STDIO режим**: Директна комуникација процеса
- Мања латенција
- Погодно за локалне алате
- Једноставно подешавање

**SSE режим**: HTTP стриминг
- Мрежна способност
- Боље за дистрибуиране системе
- Ажурирања у реалном времену

### Могућности интеграције алата

Систем може интегрисати различите алате:
- Веб аутоматизација (Playwright)
- Операције са датотекама
- API интеракције
- Системске команде
- Прилагођене функције

## Управљање грешкама и најбоље праксе

### Свеобухватно управљање грешкама

Имплементација укључује робусно управљање грешкама за:

**Грешке у повезивању:**
- Неуспеси MCP сервера
- Мрежни тајмаути
- Проблеми са повезивањем

**Грешке у извршавању алата:**
- Недостајући алати
- Валидација параметара
- Неуспеси у извршавању

**Грешке у обради одговора:**
- Проблеми са JSON парсирањем
- Неконзистентности формата
- Аномалије у одговорима LLM-а

### Најбоље праксе

1. **Управљање ресурсима**: Користите асинхроне контекст менаџере
2. **Управљање грешкама**: Примените свеобухватне try-catch блокове
3. **Логовање**: Омогућите одговарајуће нивое логовања
4. **Безбедност**: Валидација уноса и санитизација излаза
5. **Перформансе**: Користите пулање веза и кеширање

## Примене у стварном свету

### Веб аутоматизација
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Обрада података
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### Интеграција API-ја
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Оптимизација перформанси

### Управљање меморијом
- Ефикасно управљање историјом порука
- Правилно чишћење ресурса
- Пулање веза

### Оптимизација мреже
- Асинхрони HTTP операције
- Конфигурабилни тајмаути
- Грациозно опорављање од грешака

### Конкурентна обрада
- Неблокирајући I/O
- Паралелно извршавање алата
- Ефикасни асинхрони обрасци

## Безбедносни аспекти

### Заштита података
- Сигурно управљање API кључевима
- Валидација уноса
- Санитизација излаза

### Мрежна безбедност
- Подршка за HTTPS
- Локални подразумевани крајњи тачке
- Сигурно управљање токенима

### Безбедност извршавања
- Филтрирање алата
- Песковита окружења
- Логовање ревизија

## Закључак

SLM-ови интегрисани са MCP-ом представљају промену парадигме у развоју AI апликација. Комбинујући ефикасност малих модела са снагом спољашњих алата, програмери могу креирати интелигентне системе који су истовремено ресурсно ефикасни и веома способни.

Имплементација Phi-4 MCP клијента показује како се ова интеграција може постићи у пракси, пружајући солидну основу за изградњу софистицираних апликација заснованих на AI-у.

Кључне тачке:
- MCP премошћује јаз између језичких модела и спољашњих система
- SLM-ови нуде ефикасност без жртвовања способности када се допуне алатима
- Модуларна архитектура омогућава лако проширење и прилагођавање
- Правилно управљање грешкама и безбедносне мере су неопходне за продукцијску употребу

Овај туторијал пружа основу за изградњу сопствених апликација заснованих на SLM-у и MCP-у, отварајући могућности за аутоматизацију, обраду података и интеграцију интелигентних система.

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитативним извором. За критичне информације препоручује се професионални превод од стране људског преводиоца. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.