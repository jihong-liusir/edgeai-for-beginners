<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cf6b1cba2ead9fb7fdc55f77232db067",
  "translation_date": "2025-10-11T11:15:51+00:00",
  "source_file": "Module01/03.PracticalImplementationGuide.md",
  "language_code": "ta"
}
-->
# பகுதி 3: நடைமுறை செயல்பாட்டு வழிகாட்டி

## கண்ணோட்டம்

இந்த விரிவான வழிகாட்டி EdgeAI பாடத்திற்கான தயாரிப்பில் உங்களை உதவுகிறது, இது எட்ஜ் சாதனங்களில் திறமையாக இயங்கும் நடைமுறை AI தீர்வுகளை உருவாக்குவதில் கவனம் செலுத்துகிறது. இந்த பாடம் நவீன கட்டமைப்புகள் மற்றும் எட்ஜ் பயன்பாட்டிற்காக மேம்படுத்தப்பட்ட முன்னணி மாதிரிகளை பயன்படுத்தி கையால் உருவாக்குவதில் முக்கியத்துவம் அளிக்கிறது.

## 1. மேம்பாட்டு சூழல் அமைப்பு

### நிரலாக்க மொழிகள் மற்றும் கட்டமைப்புகள்

**Python சூழல்**
- **பதிப்பு**: Python 3.10 அல்லது அதற்கு மேல் (பரிந்துரை: Python 3.11)
- **பேக்கேஜ் மேலாளர்**: pip அல்லது conda
- **மெய்நிகர் சூழல்**: தனிமைப்படுத்தலுக்காக venv அல்லது conda சூழல்களை பயன்படுத்தவும்
- **முக்கிய நூலகங்கள்**: EdgeAI நூலகங்களை பாடத்தின் போது நிறுவுவோம்

**Microsoft .NET சூழல்**
- **பதிப்பு**: .NET 8 அல்லது அதற்கு மேல்
- **IDE**: Visual Studio 2022, Visual Studio Code, அல்லது JetBrains Rider
- **SDK**: குறுக்குவெளி மேம்பாட்டிற்காக .NET SDK நிறுவப்பட்டிருக்க வேண்டும்

### மேம்பாட்டு கருவிகள்

**கோடு எடிட்டர்கள் மற்றும் IDEகள்**
- Visual Studio Code (குறுக்குவெளி மேம்பாட்டிற்காக பரிந்துரைக்கப்படுகிறது)
- PyCharm அல்லது Visual Studio (மொழி-குறிப்பிட்ட மேம்பாட்டிற்காக)
- Jupyter Notebooks பரிசோதனை மற்றும் இடைமுக மேம்பாட்டிற்காக

**பதிப்பு கட்டுப்பாடு**
- Git (சமீபத்திய பதிப்பு)
- GitHub கணக்கு சேமிப்பகங்களை அணுகவும் மற்றும் ஒத்துழைப்பிற்காக

## 2. ஹார்ட்வேரின் தேவைகள் மற்றும் பரிந்துரைகள்

### குறைந்தபட்ச அமைப்பு தேவைகள்
- **CPU**: பல-மைய செயலி (Intel i5/AMD Ryzen 5 அல்லது சமமானது)
- **RAM**: குறைந்தபட்சம் 8GB, பரிந்துரை: 16GB
- **சேமிப்பு**: மாதிரிகள் மற்றும் மேம்பாட்டு கருவிகளுக்காக 50GB கிடைக்கக்கூடிய இடம்
- **OS**: Windows 10/11, macOS 10.15+, அல்லது Linux (Ubuntu 20.04+)

### கணினி வளங்களுக்கான உத்தி
இந்த பாடம் பல்வேறு ஹார்ட்வேரின் அமைப்புகளில் அணுகக்கூடியதாக வடிவமைக்கப்பட்டுள்ளது:

**உள்ளூர் மேம்பாடு (CPU/NPU கவனம்)**
- முதன்மை மேம்பாடு CPU மற்றும் NPU வேகத்தை பயன்படுத்தும்
- பெரும்பாலான நவீன லேப்டாப்கள் மற்றும் டெஸ்க்டாப்களுக்கு ஏற்றது
- திறமையான மற்றும் நடைமுறை பயன்பாட்டு சூழல்களில் கவனம்

**கிளவுட் GPU வளங்கள் (விருப்பம்)**
- **Azure Machine Learning**: தீவிர பயிற்சி மற்றும் பரிசோதனைகளுக்காக
- **Google Colab**: கல்வி நோக்கங்களுக்கான இலவச நிலை
- **Kaggle Notebooks**: மாற்று கிளவுட் கணினி தளம்

### எட்ஜ் சாதனக் கருத்துக்கள்
- ARM அடிப்படையிலான செயலிகளைப் புரிந்துகொள்வது
- மொபைல் மற்றும் IoT ஹார்ட்வேரின் கட்டுப்பாடுகளைப் பற்றிய அறிவு
- மின்சார நுகர்வு மேம்படுத்தல் பற்றிய பரிச்சயம்

## 3. முக்கிய மாதிரி குடும்பங்கள் மற்றும் வளங்கள்

### முதன்மை மாதிரி குடும்பங்கள்

**Microsoft Phi-4 குடும்பம்**
- **விளக்கம்**: எட்ஜ் பயன்பாட்டிற்காக வடிவமைக்கப்பட்ட சுருக்கமான, திறமையான மாதிரிகள்
- **வலிமைகள்**: சிறந்த செயல்திறன்-அளவுத்தொகை விகிதம், காரணமறிதல் பணிகளுக்காக மேம்படுத்தப்பட்டது
- **வளம்**: [Phi-4 தொகுப்பு Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **பயன்பாட்டு வழக்குகள்**: கோடு உருவாக்கம், கணித காரணமறிதல், பொதுவான உரையாடல்

**Qwen-3 குடும்பம்**
- **விளக்கம்**: Alibaba-வின் சமீபத்திய தலைமுறை பன்மொழி மாதிரிகள்
- **வலிமைகள்**: வலுவான பன்மொழி திறன்கள், திறமையான கட்டமைப்பு
- **வளம்**: [Qwen-3 தொகுப்பு Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)
- **பயன்பாட்டு வழக்குகள்**: பன்மொழி பயன்பாடுகள், கலாச்சார இடைமுக AI தீர்வுகள்

**Google Gemma-3n குடும்பம்**
- **விளக்கம்**: எட்ஜ் பயன்பாட்டிற்காக Google-வின் இலகுவான மாதிரிகள்
- **வலிமைகள்**: வேகமான தீர்வு, மொபைல்-சூழல் நட்பு கட்டமைப்பு
- **வளம்**: [Gemma-3n தொகுப்பு Hugging Face](https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4)
- **பயன்பாட்டு வழக்குகள்**: மொபைல் பயன்பாடுகள், நேரடி செயலாக்கம்

### மாதிரி தேர்வு அளவுகோல்கள்
- **செயல்திறன் vs. அளவுத்தொகை சமநிலை**: சிறிய மாதிரிகளை அல்லது பெரிய மாதிரிகளை எப்போது தேர்வு செய்வது என்பதைப் புரிந்துகொள்வது
- **பணிக்குறிப்பிட்ட மேம்பாடு**: மாதிரிகளை குறிப்பிட்ட பயன்பாட்டு வழக்குகளுக்கு பொருத்துதல்
- **பயன்பாட்டு கட்டுப்பாடுகள்**: நினைவகம், தாமதம், மற்றும் மின்சார நுகர்வு கருத்துக்கள்

## 4. அளவீடு மற்றும் மேம்பாட்டு கருவிகள்

### Llama.cpp கட்டமைப்பு
- **சேமிப்பகம்**: [Llama.cpp GitHub](https://github.com/ggml-org/llama.cpp)
- **நோக்கம்**: LLMகளுக்கான உயர் செயல்திறன் தீர்வு இயந்திரம்
- **முக்கிய அம்சங்கள்**:
  - CPU-க்கு மேம்படுத்தப்பட்ட தீர்வு
  - பல அளவீட்டு வடிவங்கள் (Q4, Q5, Q8)
  - குறுக்குவெளி இணக்கத்தன்மை
  - நினைவக திறமையான செயல்பாடு
- **நிறுவல் மற்றும் அடிப்படை பயன்பாடு**:
  ```bash
  # Clone the repository
  git clone https://github.com/ggml-org/llama.cpp.git
  cd llama.cpp
  
  # Build the project with optimizations
  mkdir build && cd build
  cmake .. -DCMAKE_BUILD_TYPE=Release
  cmake --build . --config Release
  
  # Quantize a model (from GGUF format to 4-bit quantization)
  ./quantize ../models/original-model.gguf ../models/quantized-model-q4_0.gguf q4_0
  
  # Run inference with the quantized model
  ./main -m ../models/quantized-model-q4_0.gguf -n 512 -p "Write a function to calculate fibonacci numbers in Python:"
  ```

### Microsoft Olive
- **சேமிப்பகம்**: [Microsoft Olive GitHub](https://github.com/microsoft/olive)
- **நோக்கம்**: எட்ஜ் பயன்பாட்டிற்கான மாதிரி மேம்பாட்டு கருவி
- **முக்கிய அம்சங்கள்**:
  - தானியங்கி மாதிரி மேம்பாட்டு பணிகள்
  - ஹார்ட்வேரை கருத்தில் கொண்டு மேம்பாடு
  - ONNX Runtime உடன் ஒருங்கிணைப்பு
  - செயல்திறன் அளவீட்டு கருவிகள்
- **நிறுவல் மற்றும் அடிப்படை பயன்பாடு**:
  ```bash
  # Install Olive
  pip install olive-ai
  
  # Example Python script for model optimization
  ```python
  from olive.model import ONNXModel
  from olive.workflows import run_workflow
  
  # Define model and optimization config
  model = ONNXModel("original_model.onnx")
  config = {
      "input_model": model,
      "systems": {
          "local_system": {
              "type": "LocalSystem"
          }
      },
      "engine": {
          "log_severity_level": 0,
          "cache_dir": "cache"
      },
      "passes": {
          "quantization": {
              "type": "OrtQuantization",
              "config": {
                  "quant_mode": "static",
                  "activation_type": "int8",
                  "weight_type": "int8"
              }
          }
      }
  }
  
  # Run optimization workflow
  result = run_workflow(config)
  optimized_model = result.optimized_model
  
  # Save optimized model
  optimized_model.save("optimized_model.onnx")
  ```

### Apple MLX (macOS பயனர்கள்)
- **சேமிப்பகம்**: [Apple MLX GitHub](https://github.com/ml-explore/mlx)
- **நோக்கம்**: Apple Silicon-க்கு இயந்திர கற்றல் கட்டமைப்பு
- **முக்கிய அம்சங்கள்**:
  - Apple Silicon-க்கு சொந்தமான மேம்பாடு
  - நினைவக திறமையான செயல்பாடுகள்
  - PyTorch போன்ற API
  - ஒருங்கிணைந்த நினைவக கட்டமைப்பு ஆதரவு
- **நிறுவல் மற்றும் அடிப்படை பயன்பாடு**:
  ```bash
  # Install MLX
  pip install mlx
  
  # Example Python script for loading and optimizing a model
  ```python
  import mlx.core as mx
  import mlx.nn as nn
  from mlx.utils import tree_flatten
  
  # Load pre-trained weights (example with a simple MLP)
  class MLP(nn.Module):
      def __init__(self, dim=768, hidden_dim=3072):
          super().__init__()
          self.fc1 = nn.Linear(dim, hidden_dim)
          self.fc2 = nn.Linear(hidden_dim, dim)
          
      def __call__(self, x):
          return self.fc2(mx.maximum(0, self.fc1(x)))
  
  # Create model and load weights
  model = MLP()
  weights = mx.load("original_weights.npz")
  model.update(weights)
  
  # Quantize the model weights to FP16
  def quantize_weights(model):
      params = {}
      for k, v in tree_flatten(model.parameters()):
          params[k] = v.astype(mx.float16)
      model.update(params)
      return model
  
  quantized_model = quantize_weights(model)
  
  # Save quantized model
  mx.save("quantized_model.npz", quantized_model.parameters())
  
  # Run inference
  input_data = mx.random.normal((1, 768))
  output = quantized_model(input_data)
  ```

### ONNX Runtime
- **சேமிப்பகம்**: [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
- **நோக்கம்**: ONNX மாதிரிகளுக்கான குறுக்குவெளி தீர்வு வேகத்தை அதிகரித்தல்
- **முக்கிய அம்சங்கள்**:
  - ஹார்ட்வேரை கருத்தில் கொண்டு மேம்பாடுகள் (CPU, GPU, NPU)
  - தீர்வு செயல்பாட்டிற்கான வரைபட மேம்பாடுகள்
  - அளவீட்டு ஆதரவு
  - குறுக்குவெளி மொழி ஆதரவு (Python, C++, C#, JavaScript)
- **நிறுவல் மற்றும் அடிப்படை பயன்பாடு**:
  ```bash
  # Install ONNX Runtime
  pip install onnxruntime
  
  # For GPU support
  pip install onnxruntime-gpu
  ```
  
  ```python
  import onnxruntime as ort
  import numpy as np
  
  # Create inference session with optimizations
  sess_options = ort.SessionOptions()
  sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
  sess_options.enable_profiling = True  # Enable performance profiling
  
  # Create session with provider selection for hardware acceleration
  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']  # Use GPU if available
  session = ort.InferenceSession("model.onnx", sess_options, providers=providers)
  
  # Prepare input data
  input_name = session.get_inputs()[0].name
  input_shape = session.get_inputs()[0].shape
  input_data = np.random.rand(*input_shape).astype(np.float32)
  
  # Run inference
  outputs = session.run(None, {input_name: input_data})
  
  # Get profiling data
  prof_file = session.end_profiling()
  print(f"Profiling data saved to: {prof_file}")
  ```


## 5. பரிந்துரைக்கப்பட்ட வாசிப்பு மற்றும் வளங்கள்

### முக்கிய ஆவணங்கள்
- **ONNX Runtime ஆவணங்கள்**: குறுக்குவெளி தீர்வு பற்றிய புரிதல்
- **Hugging Face Transformers வழிகாட்டி**: மாதிரி ஏற்றுதல் மற்றும் தீர்வு
- **Edge AI வடிவமைப்பு முறை**: எட்ஜ் பயன்பாட்டிற்கான சிறந்த நடைமுறைகள்

### தொழில்நுட்ப ஆவணங்கள்
- "திறமையான எட்ஜ் AI: அளவீட்டு உத்திகள் பற்றிய ஆய்வு"
- "மொபைல் மற்றும் எட்ஜ் சாதனங்களுக்கான மாதிரி சுருக்கம்"
- "எட்ஜ் கணினிக்கான Transformer மாதிரிகளை மேம்படுத்துதல்"

### சமூக வளங்கள்
- **EdgeAI Slack/Discord சமூகங்கள்**: சக பயனர்கள் ஆதரவு மற்றும் விவாதம்
- **GitHub சேமிப்பகங்கள்**: உதாரண செயல்பாடுகள் மற்றும் பயிற்சிகள்
- **YouTube சேனல்கள்**: தொழில்நுட்ப ஆழமான விளக்கங்கள் மற்றும் பயிற்சிகள்

## 6. மதிப்பீடு மற்றும் சரிபார்ப்பு

### பாடத்திற்கு முன் சரிபார்ப்பு பட்டியல்
- [ ] Python 3.10+ நிறுவப்பட்டு சரிபார்க்கப்பட்டது
- [ ] .NET 8+ நிறுவப்பட்டு சரிபார்க்கப்பட்டது
- [ ] மேம்பாட்டு சூழல் அமைக்கப்பட்டது
- [ ] Hugging Face கணக்கு உருவாக்கப்பட்டது
- [ ] இலக்கு மாதிரி குடும்பங்களின் அடிப்படை பரிச்சயம்
- [ ] அளவீட்டு கருவிகள் நிறுவப்பட்டு சோதிக்கப்பட்டது
- [ ] ஹார்ட்வேரின் தேவைகள் பூர்த்தி செய்யப்பட்டது
- [ ] கிளவுட் கணினி கணக்குகள் அமைக்கப்பட்டது (தேவையானால்)

## முக்கிய கற்றல் நோக்கங்கள்

இந்த வழிகாட்டியை முடித்த பிறகு, நீங்கள்:

1. EdgeAI பயன்பாட்டு மேம்பாட்டிற்கான முழுமையான மேம்பாட்டு சூழலை அமைக்க முடியும்
2. மாதிரி மேம்பாட்டிற்கான தேவையான கருவிகள் மற்றும் கட்டமைப்புகளை நிறுவவும் மற்றும் அமைக்கவும்
3. உங்கள் EdgeAI திட்டங்களுக்கு ஏற்ற ஹார்ட்வேரின் மற்றும் மென்பொருள் அமைப்புகளை தேர்வு செய்ய முடியும்
4. எட்ஜ் சாதனங்களில் AI மாதிரிகளை பயன்படுத்துவதற்கான முக்கிய கருத்துக்களைப் புரிந்துகொள்ள முடியும்
5. பாடத்தில் உள்ள கையால் செய்யும் பயிற்சிகளுக்கான உங்கள் அமைப்பைத் தயாரிக்க முடியும்

## கூடுதல் வளங்கள்

### அதிகாரப்பூர்வ ஆவணங்கள்
- **Python ஆவணங்கள்**: அதிகாரப்பூர்வ Python மொழி ஆவணங்கள்
- **Microsoft .NET ஆவணங்கள்**: அதிகாரப்பூர்வ .NET மேம்பாட்டு வளங்கள்
- **ONNX Runtime ஆவணங்கள்**: ONNX Runtime பற்றிய விரிவான வழிகாட்டி
- **TensorFlow Lite ஆவணங்கள்**: அதிகாரப்பூர்வ TensorFlow Lite ஆவணங்கள்

### மேம்பாட்டு கருவிகள்
- **Visual Studio Code**: AI மேம்பாட்டு நீட்டிப்புகளுடன் இலகுவான கோடு எடிட்டர்
- **Jupyter Notebooks**: ML பரிசோதனைகளுக்கான இடைமுக கணினி சூழல்
- **Docker**: ஒரே மாதிரியான மேம்பாட்டு சூழல்களுக்கான கெண்டைனர் தளம்
- **Git**: கோடு மேலாண்மைக்கான பதிப்பு கட்டுப்பாட்டு அமைப்பு

### கற்றல் வளங்கள்
- **EdgeAI ஆராய்ச்சி ஆவணங்கள்**: திறமையான மாதிரிகள் பற்றிய சமீபத்திய கல்வி ஆராய்ச்சி
- **ஆன்லைன் பாடங்கள்**: AI மேம்பாட்டிற்கான கூடுதல் கற்றல் பொருட்கள்
- **சமூக மன்றங்கள்**: EdgeAI மேம்பாட்டு சவால்களுக்கு Q&A தளங்கள்
- **அளவீட்டு தரவுத்தொகுப்புகள்**: மாதிரி செயல்திறனை மதிப்பீடு செய்யும் தரநிலை தரவுத்தொகுப்புகள்

## கற்றல் முடிவுகள்

இந்த தயாரிப்பு வழிகாட்டியை முடித்த பிறகு, நீங்கள்:

1. EdgeAI மேம்பாட்டிற்கான முழுமையான சூழலை அமைத்திருப்பீர்கள்
2. பல்வேறு பயன்பாட்டு சூழல்களுக்கான ஹார்ட்வேரின் மற்றும் மென்பொருள் தேவைகளைப் புரிந்துகொள்வீர்கள்
3. பாடத்தின் முழு காலத்தில் பயன்படுத்தப்படும் முக்கிய கட்டமைப்புகள் மற்றும் கருவிகளைப் பரிச்சயமாக்குவீர்கள்
4. சாதன கட்டுப்பாடுகள் மற்றும் தேவைகளின் அடிப்படையில் பொருத்தமான மாதிரிகளைத் தேர்வு செய்ய முடியும்
5. எட்ஜ் பயன்பாட்டிற்கான மேம்பாட்டு உத்திகள் பற்றிய அடிப்படை அறிவைப் பெற்றிருப்பீர்கள்

## ➡️ அடுத்தது என்ன?

- [04: EdgeAI ஹார்ட்வேரின் மற்றும் பயன்பாடு](04.EdgeDeployment.md)

---

**குறிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியக்க மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறான தகவல்கள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளுங்கள். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.