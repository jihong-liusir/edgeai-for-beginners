<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6a574846c3919c56f1d02bf1de2003ca",
  "translation_date": "2025-10-11T12:51:46+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "ta"
}
-->
# роЕрооро░рпНро╡рпБ 1: Foundry Local-роР роЕро▒ро┐роорпБроХрокрпНрокроЯрпБродрпНродрпБродро▓рпН

## роорпЗро▓рпЛроЯрпНроЯроорпН

Microsoft Foundry Local, Azure AI Foundry родро┐ро▒ройрпНроХро│рпИ роирпЗро░роЯро┐ропро╛роХ роЙроЩрпНроХро│рпН Windows 11 роорпЗроорпНрокро╛роЯрпНроЯрпБ роЪрпВро┤ро▓рпБроХрпНроХрпБ роХрпКрогрпНроЯрпБ ро╡ро░рпБроХро┐ро▒родрпБ. роЗродрпБ родройро┐ропрпБро░ро┐роорпИропрпИ рокро╛родрпБроХро╛роХрпНроХрпБроорпН, роХрпБро▒рпИроирпНрод родро╛роородродрпНродрпБроЯройрпН роХрпВроЯро┐роп AI роорпЗроорпНрокро╛роЯрпНроЯрпИ роиро┐ро▒рпБро╡рой родро░рооро╛рой роХро░рпБро╡ро┐роХро│рпБроЯройрпН роЪрпЖропро▓рпНрокроЯрпБродрпНрод роЙродро╡рпБроХро┐ро▒родрпБ. роЗроирпНрод роЕрооро░рпНро╡ро┐ро▓рпН phi, qwen, deepseek, рооро▒рпНро▒рпБроорпН GPT-OSS-20B рокрпЛройрпНро▒ рокро┐ро░рокро▓рооро╛рой рооро╛родро┐ро░ро┐роХро│рпИ роорпБро┤рпБроорпИропро╛роХ роиро┐ро▒рпБро╡рпБродро▓рпН, роЕроорпИродрпНродро▓рпН рооро▒рпНро▒рпБроорпН роироЯрпИроорпБро▒рпИрокрпН рокропройрпНрокро╛роЯрпНроЯрпИ роЙро│рпНро│роЯроХрпНроХро┐ропродрпБ.

## роХро▒рпНро▒ро▓рпН роирпЛроХрпНроХроЩрпНроХро│рпН

роЗроирпНрод роЕрооро░рпНро╡ро┐ройрпН роорпБроЯро┐ро╡ро┐ро▓рпН, роирпАроЩрпНроХро│рпН:
- Windows 11-ро▓рпН Foundry Local-роР роиро┐ро▒рпБро╡ро┐ роЕроорпИрокрпНрокрпАроЯрпБ роЪрпЖропрпНро╡рпАро░рпНроХро│рпН
- CLI роХроЯрпНроЯро│рпИроХро│рпН рооро▒рпНро▒рпБроорпН роЕроорпИрокрпНрокрпАроЯрпНроЯрпБ ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпИ роХрпИропро╛ро│рпНро╡рпАро░рпНроХро│рпН
- роЪро┐ро▒роирпНрод роЪрпЖропро▓рпНродро┐ро▒ройрпБроХрпНроХро╛рой рооро╛родро┐ро░ро┐ роХро╛роЯрпНроЪро┐роЩрпН роЙродрпНродро┐роХро│рпИ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро╡рпАро░рпНроХро│рпН
- phi, qwen, deepseek, рооро▒рпНро▒рпБроорпН GPT-OSS-20B рооро╛родро┐ро░ро┐роХро│рпИ ро╡рпЖро▒рпНро▒ро┐роХро░рооро╛роХ роЗропроХрпНроХрпБро╡рпАро░рпНроХро│рпН
- Foundry Local-роР рокропройрпНрокроЯрпБродрпНродро┐ роЙроЩрпНроХро│рпН роорпБродро▓рпН AI рокропройрпНрокро╛роЯрпНроЯрпИ роЙро░рпБро╡ро╛роХрпНроХрпБро╡рпАро░рпНроХро│рпН

## роорпБройрпН родрпЗро╡рпИроХро│рпН

### роХрогро┐ройро┐ родрпЗро╡рпИроХро│рпН
- **Windows 11**: рокродро┐рокрпНрокрпБ 22H2 роЕро▓рпНро▓родрпБ роЕродро▒рпНроХрпБ роорпЗро▓рпН
- **RAM**: роХрпБро▒рпИроирпНродрокроЯрпНроЪроорпН 16GB, рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпБроорпН 32GB
- **роЪрпЗрооро┐рокрпНрокрпБ**: рооро╛родро┐ро░ро┐роХро│рпН рооро▒рпНро▒рпБроорпН роХро╛роЯрпНроЪро┐роЩрпНроХро┐ро▒рпНроХро╛роХ 50GB роХро╛ро▓ро┐ роЗроЯроорпН
- **ро╣ро╛ро░рпНроЯрпНро╡рпЗро░рпН**: NPU роЕро▓рпНро▓родрпБ GPU роХрпКрогрпНроЯ роЪро╛родройроорпН (Copilot+ PC роЕро▓рпНро▓родрпБ NVIDIA GPU рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ)
- **роЗрогрпИропроорпН**: рооро╛родро┐ро░ро┐роХро│рпИ рокродро┐ро╡ро┐ро▒роХрпНроХ роЙропро░рпН ро╡рпЗроХ роЗрогрпИропроорпН

### роорпЗроорпНрокро╛роЯрпНроЯрпБ роЪрпВро┤ро▓рпН
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## рокроХрпБродро┐ 1: роиро┐ро▒рпБро╡ро▓рпН рооро▒рпНро▒рпБроорпН роЕроорпИродрпНродро▓рпН

### рокроЯро┐ 1: Foundry Local-роР роиро┐ро▒рпБро╡рпБродро▓рпН

Winget-роР рокропройрпНрокроЯрпБродрпНродро┐ роЕро▓рпНро▓родрпБ GitHub-роЗро▓рпН роЗро░рпБроирпНродрпБ роиро┐ро▒рпБро╡ро▓рпН роХрпЛрокрпНрокрпИ рокродро┐ро╡ро┐ро▒роХрпНроХроорпН роЪрпЖропрпНродрпБ Foundry Local-роР роиро┐ро▒рпБро╡ро╡рпБроорпН:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### рокроЯро┐ 2: роиро┐ро▒рпБро╡ро▓рпИ роЪро░ро┐рокро╛ро░рпНроХрпНроХро╡рпБроорпН

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## рокроХрпБродро┐ 2: CLI-роР рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро╡родрпБ

### роорпБроХрпНроХро┐роп роХроЯрпНроЯро│рпИроХро│ро┐ройрпН роЕроорпИрокрпНрокрпБ

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## рокроХрпБродро┐ 3: рооро╛родро┐ро░ро┐ роХро╛роЯрпНроЪро┐роЩрпН рооро▒рпНро▒рпБроорпН роорпЗро▓ро╛рогрпНроорпИ

Foundry Local роЪрпЖропро▓рпНродро┐ро▒ройрпН рооро▒рпНро▒рпБроорпН роЪрпЗрооро┐рокрпНрокрпИ роорпЗроорпНрокроЯрпБродрпНрод роирпБрогрпНрогро▒ро┐ро╡рпБ рооро╛родро┐ро░ро┐ роХро╛роЯрпНроЪро┐роЩрпНроХрпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБроХро┐ро▒родрпБ:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## рокроХрпБродро┐ 4: роироЯрпИроорпБро▒рпИ рооро╛родро┐ро░ро┐ рокропройрпНрокро╛роЯрпБ

### Microsoft Phi рооро╛родро┐ро░ро┐роХро│рпИ роЗропроХрпНроХрпБродро▓рпН

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Qwen рооро╛родро┐ро░ро┐роХро│рпБроЯройрпН ро╡рпЗро▓рпИ роЪрпЖропрпНро╡родрпБ

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b
foundry model run qwen2.5-14b
```

### DeepSeek рооро╛родро┐ро░ро┐роХро│рпИ роЗропроХрпНроХрпБродро▓рпН

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-7b
```

### GPT-OSS-20B роЗропроХрпНроХрпБродро▓рпН

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## рокроХрпБродро┐ 5: роЙроЩрпНроХро│рпН роорпБродро▓рпН рокропройрпНрокро╛роЯрпНроЯрпИ роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН

### роиро╡рпАрой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБ (OpenAI SDK + Foundry Local)

Sample 01-роЗро▓рпН роЙро│рпНро│ роорпБро▒рпИроорпИроХро│рпИ рокро┐ройрпНрокро▒рпНро▒ро┐, Foundry Local роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБроЯройрпН OpenAI SDK-роР рокропройрпНрокроЯрпБродрпНродро┐ роЙро▒рпНрокродрпНродро┐ родро░рооро╛рой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпНроЯрпИ роЙро░рпБро╡ро╛роХрпНроХро╡рпБроорпН.

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("тЪая╕П Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"ЁЯМР Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"ЁЯПа Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"тЪая╕П Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"ЁЯФз Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпНроЯрпИ роЗропроХрпНроХро╡рпБроорпН

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## рокроХрпБродро┐ 6: рокро┐ро┤рпИродрпНродро┐ро░рпБродрпНродроорпН рооро▒рпНро▒рпБроорпН роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпН

### рокрпКродрпБро╡ро╛рой рокро┐ро░роЪрпНроЪро┐ройрпИроХро│рпН рооро▒рпНро▒рпБроорпН родрпАро░рпНро╡рпБроХро│рпН

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### роХрогро┐ройро┐ ро╡ро│роЩрпНроХро│рпИ роХрогрпНроХро╛рогро┐родрпНродро▓рпН (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### роЪрпВро┤ро▓рпН рооро╛ро▒ро┐роХро│рпН

| рооро╛ро▒ро┐ | ро╡ро┐ро│роХрпНроХроорпН | роЗропро▓рпНрокрпБроиро┐ро▓рпИ | родрпЗро╡рпИ |
|------|----------|------------|-------|
| `MODEL` | рооро╛родро┐ро░ро┐ роХрпБро▒ро┐ропрпАроЯрпБ роЕро▓рпНро▓родрпБ рокрпЖропро░рпН | `phi-4-mini` | роЗро▓рпНро▓рпИ |
| `BASE_URL` | Foundry Local роЕроЯро┐рокрпНрокроЯрпИ URL | `http://localhost:8000` | роЗро▓рпНро▓рпИ |
| `API_KEY` | API ро╡ро┐роЪрпИ (роЪро╛родро╛ро░рогрооро╛роХ роЙро│рпНро│рпВро░рпН рокропройрпНрокро╛роЯрпНроЯро┐ро▒рпНроХрпБ родрпЗро╡рпИропро┐ро▓рпНро▓рпИ) | `""` | роЗро▓рпНро▓рпИ |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI роорпБроЯрпБроХрпНроХрпБ | - | Azure роХрпНроХрпБ родрпЗро╡рпИ |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API ро╡ро┐роЪрпИ | - | Azure роХрпНроХрпБ родрпЗро╡рпИ |
| `AZURE_OPENAI_API_VERSION` | Azure API рокродро┐рокрпНрокрпБ | `2024-08-01-preview` | роЗро▓рпНро▓рпИ |

### роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпН

- **OpenAI SDK-роР рокропройрпНрокроЯрпБродрпНродро╡рпБроорпН**: рокро░ро╛рооро░ро┐роХрпНроХ роОро│ро┐родро╛ройродро▒рпНроХро╛роХ OpenAI SDK-роР роорпБроирпНродро┐роп HTTP роХрпЛро░ро┐роХрпНроХрпИроХро│рпБроХрпНроХрпБ рокродро┐ро▓ро╛роХ рокропройрпНрокроЯрпБродрпНродро╡рпБроорпН
- **FoundryLocalManager**: роЪрпЗро╡рпИ роорпЗро▓ро╛рогрпНроорпИроХрпНроХро╛рой роЕродро┐роХро╛ро░рокрпНрокрпВро░рпНро╡ SDK-роР рокропройрпНрокроЯрпБродрпНродро╡рпБроорпН
- **рокро┐ро┤рпИ роХрпИропро╛ро│рпБродро▓рпН**: роЙро▒рпНрокродрпНродро┐ рокропройрпНрокро╛роЯрпБроХро│рпБроХрпНроХрпБ роЪро░ро┐ропро╛рой рооро╛ро▒рпНро▒рпБ роЙродрпНродро┐роХро│рпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродро╡рпБроорпН
- **родрпКроЯро░рпНроирпНродрпБ роорпЗроорпНрокроЯрпБродрпНродро╡рпБроорпН**: рокрпБродро┐роп рооро╛родро┐ро░ро┐роХро│рпН рооро▒рпНро▒рпБроорпН родро┐ро░рпБродрпНродроЩрпНроХро│рпИ роЕрогрпБроХ Foundry Local-роР рокрпБродрпБрокрпНрокро┐роХрпНроХро╡рпБроорпН
- **роЪро┐ро▒ро┐ропродро╛роХ родрпКроЯроЩрпНроХро╡рпБроорпН**: роЪро┐ро▒ро┐роп рооро╛родро┐ро░ро┐роХро│рпБроЯройрпН (Phi mini, Qwen 7B) родрпКроЯроЩрпНроХро┐, рокро┐ройрпНройро░рпН ро╡ро┐ро░ро┐ро╡ро╛роХрпНроХро╡рпБроорпН
- **ро╡ро│роЩрпНроХро│рпИ роХрогрпНроХро╛рогро┐роХрпНроХро╡рпБроорпН**: CPU/GPU/роорпЖрооро░ро┐ропрпИ роХрогрпНроХро╛рогро┐родрпНродрпБ, роЙроХроирпНрод роЕроорпИрокрпНрокрпБроХро│рпИроЪрпН роЪро░ро┐роЪрпЖропрпНропро╡рпБроорпН

## рокроХрпБродро┐ 7: роироЯрпИроорпБро▒рпИ рокропро┐ро▒рпНроЪро┐роХро│рпН

### рокропро┐ро▒рпНроЪро┐ 1: ро╡ро┐ро░рпИро╡ро╛рой рокро▓-рооро╛родро┐ро░ро┐ роЪрпЛродройрпИ

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### рокропро┐ро▒рпНроЪро┐ 2: OpenAI SDK роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ роЪрпЛродройрпИ

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"тЬЕ {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"тЭМ {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b"]
for model in models_to_test:
    test_model_integration(model)
```

### рокропро┐ро▒рпНроЪро┐ 3: ро╡ро┐ро░ро┐ро╡ро╛рой роЪрпЗро╡рпИ роЖро░рпЛроХрпНроХро┐роп роЪрпЛродройрпИ

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"тЬЕ Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"тЬЕ {model_id}: Working")
            except Exception as e:
                print(f"тЭМ {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"тЭМ Service check failed: {e}")
        return False

comprehensive_health_check()
```

## роХрпБро▒ро┐рокрпНрокрпБроХро│рпН

- **Foundry Local-роР родрпКроЯроЩрпНроХро╡рпБроорпН**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **CLI роХрпБро▒ро┐рокрпНрокрпБ рооро▒рпНро▒рпБроорпН роХроЯрпНроЯро│рпИроХро│рпН роорпЗро▒рпНрокро╛ро░рпНро╡рпИ**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **OpenAI SDK роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **Hugging Face рооро╛родро┐ро░ро┐роХро│рпИ родрпКроХрпБроХрпНроХро╡рпБроорпН**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **Sample 01: OpenAI SDK роорпВро▓роорпН ро╡ро┐ро░рпИро╡ро╛рой роЙро░рпИропро╛роЯро▓рпН**: samples/01/README.md
- **Sample 02: роорпЗроорпНрокроЯрпНроЯ SDK роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ**: samples/02/README.md

---

**роХрпБро▒ро┐рокрпНрокрпБ**:  
роЗроирпНрод роЖро╡рогроорпН [Co-op Translator](https://github.com/Azure/co-op-translator) роОройрпНро▒ AI роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ роЪрпЗро╡рпИропрпИ рокропройрпНрокроЯрпБродрпНродро┐ роорпКро┤ро┐рокрпЖропро░рпНроХрпНроХрокрпНрокроЯрпНроЯрпБро│рпНро│родрпБ. роОроЩрпНроХро│рпН роирпЛроХрпНроХроорпН родрпБро▓рпНро▓ро┐ропрооро╛роХ роЗро░рпБроХрпНроХ ро╡рпЗрогрпНроЯрпБроорпН роОройрпНрокродрпБродро╛ройрпН, роЖройро╛ро▓рпН родро╛ройро┐ропроЩрпНроХро┐ роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБроХро│ро┐ро▓рпН рокро┐ро┤рпИроХро│рпН роЕро▓рпНро▓родрпБ родро╡ро▒рпБроХро│рпН роЗро░рпБроХрпНроХроХрпНроХрпВроЯрпБроорпН роОройрпНрокродрпИ родропро╡рпБроЪрпЖропрпНродрпБ роХро╡ройродрпНродро┐ро▓рпН роХрпКро│рпНро│ро╡рпБроорпН. роЕродройрпН родро╛ропрпНроорпКро┤ро┐ропро┐ро▓рпН роЙро│рпНро│ роорпВро▓ роЖро╡рогроорпН роЕродро┐роХро╛ро░рокрпНрокрпВро░рпНро╡ роЖродро╛ро░рооро╛роХ роХро░рпБродрокрпНрокроЯ ро╡рпЗрогрпНроЯрпБроорпН. роорпБроХрпНроХро┐ропрооро╛рой родроХро╡ро▓рпНроХро│рпБроХрпНроХрпБ, родрпКро┤ро┐ро▓рпНроорпБро▒рпИ рооройро┐род роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ. роЗроирпНрод роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпИрокрпН рокропройрпНрокроЯрпБродрпНродрпБро╡родро╛ро▓рпН роПро▒рпНрокроЯрпБроорпН роОроирпНрод родро╡ро▒ро╛рой рокрпБро░ро┐родро▓рпНроХро│рпН роЕро▓рпНро▓родрпБ родро╡ро▒ро╛рой ро╡ро┐ро│роХрпНроХроЩрпНроХро│рпБроХрпНроХрпБ роиро╛роЩрпНроХро│рпН рокрпКро▒рпБрокрпНрокро▓рпНро▓.