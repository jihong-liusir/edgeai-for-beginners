<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8ccc4f76611daedf918e34460128fc21",
  "translation_date": "2025-10-11T12:50:04+00:00",
  "source_file": "Module08/04.CuttingEdgeModels.md",
  "language_code": "ta"
}
-->
# роЕрооро░рпНро╡рпБ 4: Chainlit роорпВро▓роорпН роЙро▒рпНрокродрпНродро┐ родро░рооро╛рой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН

## роХрогрпНрогрпЛроЯрпНроЯроорпН

роЗроирпНрод роЕрооро░рпНро╡рпБ Chainlit рооро▒рпНро▒рпБроорпН Microsoft Foundry Local рокропройрпНрокроЯрпБродрпНродро┐ роЙро▒рпНрокродрпНродро┐ родро░рооро╛рой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБро╡родро┐ро▓рпН роХро╡ройроорпН роЪрпЖро▓рпБродрпНродрпБроХро┐ро▒родрпБ. AI роЙро░рпИропро╛роЯро▓рпНроХро│рпБроХрпНроХрпБ роиро╡рпАрой ро╡ро▓рпИ роЗроЯрпИроорпБроХроЩрпНроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБро╡родрпБ, ро╕рпНроЯрпНро░рпАрооро┐роЩрпН рокродро┐ро▓рпНроХро│рпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБро╡родрпБ, рооро▒рпНро▒рпБроорпН рокро┐ро┤рпИ роХрпИропро╛ро│рпБродро▓рпН рооро▒рпНро▒рпБроорпН рокропройро░рпН роЕройрпБрокро╡ ро╡роЯро┐ро╡роорпИрокрпНрокрпБроЯройрпН ро╡ро▓рпБро╡ро╛рой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпИ ро╡рпЖро│ро┐ропро┐роЯрпБро╡родрпБ роЖроХро┐ропро╡ро▒рпНро▒рпИ роирпАроЩрпНроХро│рпН роХро▒рпНро▒рпБроХрпНроХрпКро│рпНро╡рпАро░рпНроХро│рпН.

**роирпАроЩрпНроХро│рпН роЙро░рпБро╡ро╛роХрпНроХрокрпНрокрпЛроХро┐ро▒рпАро░рпНроХро│рпН:**
- **Chainlit Chat App**: ро╕рпНроЯрпНро░рпАрооро┐роЩрпН рокродро┐ро▓рпНроХро│рпБроЯройрпН роиро╡рпАрой ро╡ро▓рпИ UI
- **WebGPU роЯрпЖроорпЛ**: родройро┐ропрпБро░ро┐роорпИ роорпИропрооро╛рой рокропройрпНрокро╛роЯрпБроХро│рпБроХрпНроХро╛рой роЙро▓ро╛ро╡ро┐ роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓ро╛рой родрпАро░рпНрооро╛ройроорпН  
- **Open WebUI роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ**: Foundry Local роЙроЯройрпН родрпКро┤ро┐ро▓рпНроорпБро▒рпИ роЙро░рпИропро╛роЯро▓рпН роЗроЯрпИроорпБроХроорпН
- **роЙро▒рпНрокродрпНродро┐ роорпБро▒рпИроорпИроХро│рпН**: рокро┐ро┤рпИ роХрпИропро╛ро│рпБродро▓рпН, роХрогрпНроХро╛рогро┐рокрпНрокрпБ, рооро▒рпНро▒рпБроорпН ро╡рпЖро│ро┐ропрпАроЯрпНроЯрпБ роЙродрпНродро┐роХро│рпН

## роХро▒рпНро▒ро▓рпН роирпЛроХрпНроХроЩрпНроХро│рпН

- Chainlit роорпВро▓роорпН роЙро▒рпНрокродрпНродро┐ родро░рооро╛рой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН
- роорпЗроорпНрокроЯрпНроЯ рокропройро░рпН роЕройрпБрокро╡родрпНродро┐ро▒рпНроХро╛роХ ро╕рпНроЯрпНро░рпАрооро┐роЩрпН рокродро┐ро▓рпНроХро│рпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБродро▓рпН
- Foundry Local SDK роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ роорпБро▒рпИроорпИроХро│рпИ роХрпИропро╛ро│рпБродро▓рпН
- роЪро░ро┐ропро╛рой рокро┐ро┤рпИ роХрпИропро╛ро│рпБродро▓рпН рооро▒рпНро▒рпБроорпН роорпЖройрпНроорпИропро╛рой роЪрпЖропро▓ро┐ро┤рокрпНрокрпБ
- ро╡рпЖро╡рпНро╡рпЗро▒рпБ роЪрпВро┤ро▓рпНроХро│рпБроХрпНроХрпБ роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпИ ро╡рпЖро│ро┐ропро┐роЯрпБродро▓рпН рооро▒рпНро▒рпБроорпН роЕроорпИродрпНродро▓рпН
- роЙро░рпИропро╛роЯро▓рпН AI роХрпНроХро╛рой роиро╡рпАрой ро╡ро▓рпИ UI роорпБро▒рпИроорпИроХро│рпИ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│рпБродро▓рпН

## роорпБройрпН родрпЗро╡рпИроХро│рпН

- **Foundry Local**: роиро┐ро▒рпБро╡рокрпНрокроЯрпНроЯрпБ роЗропроЩрпНроХ ро╡рпЗрогрпНроЯрпБроорпН ([роиро┐ро▒рпБро╡ро▓рпН ро╡ро┤ро┐роХро╛роЯрпНроЯро┐](https://learn.microsoft.com/azure/ai-foundry/foundry-local/))
- **Python**: 3.10 роЕро▓рпНро▓родрпБ роЕродро▒рпНроХрпБ роорпЗро▓рпН, роорпЖропрпНроиро┐роХро░рпН роЪрпВро┤ро▓рпН родро┐ро▒ройрпБроЯройрпН
- **рооро╛родро┐ро░ро┐**: роХрпБро▒рпИроирпНродродрпБ роТро░рпБ рооро╛родро┐ро░ро┐ роПро▒рпНро▒рокрпНрокроЯрпНроЯро┐ро░рпБроХрпНроХ ро╡рпЗрогрпНроЯрпБроорпН (`foundry model run phi-4-mini`)
- **роЙро▓ро╛ро╡ро┐**: WebGPU роЖродро░ро╡рпБ роХрпКрогрпНроЯ роиро╡рпАрой ро╡ро▓рпИ роЙро▓ро╛ро╡ро┐ (Chrome/Edge)
- **Docker**: Open WebUI роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБроХрпНроХро╛роХ (ро╡ро┐ро░рпБрокрпНрокроорпН)

## рокроХрпБродро┐ 1: роиро╡рпАрой роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпИ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│рпБродро▓рпН

### роХроЯрпНроЯроорпИрокрпНрокрпБ роХрогрпНрогрпЛроЯрпНроЯроорпН

```
User Browser тЖРтЖТ Chainlit UI тЖРтЖТ Python Backend тЖРтЖТ Foundry Local тЖРтЖТ AI Model
      тЖУ              тЖУ              тЖУ              тЖУ            тЖУ
   Web UI      Event Handlers   OpenAI Client   HTTP API    Local GPU
```

### роорпБроХрпНроХро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрокроЩрпНроХро│рпН

**Foundry Local SDK роорпБро▒рпИроорпИроХро│рпН:**
- `FoundryLocalManager(alias)`: родро╛ройро┐ропроЩрпНроХро┐ роЪрпЗро╡рпИ роорпЗро▓ро╛рогрпНроорпИ
- `manager.endpoint` рооро▒рпНро▒рпБроорпН `manager.api_key`: роЗрогрпИрокрпНрокрпБ ро╡ро┐ро╡ро░роЩрпНроХро│рпН
- `manager.get_model_info(alias).id`: рооро╛родро┐ро░ро┐ роЕроЯрпИропро╛ро│роорпН

**Chainlit Framework:**
- `@cl.on_chat_start`: роЙро░рпИропро╛роЯро▓рпН роЕрооро░рпНро╡рпБроХро│рпИ родрпКроЯроЩрпНроХрпБродро▓рпН
- `@cl.on_message`: рокропройро░рпН роЪрпЖропрпНродро┐роХро│рпИ роХрпИропро╛ро│рпБродро▓рпН  
- `cl.Message().stream_token()`: роирпЗро░роЯро┐ ро╕рпНроЯрпНро░рпАрооро┐роЩрпН
- родро╛ройро┐ропроЩрпНроХро┐ UI роЙро░рпБро╡ро╛роХрпНроХроорпН рооро▒рпНро▒рпБроорпН WebSocket роорпЗро▓ро╛рогрпНроорпИ

## рокроХрпБродро┐ 2: роЙро│рпНро│рпВро░рпН рооро▒рпНро▒рпБроорпН роорпЗроХ родрпАро░рпНрооро╛рой роЕроЯрпНроЯро╡рогрпИ

### роЪрпЖропро▓рпНродро┐ро▒ройрпН рокрогрпНрокрпБроХро│рпН

| роЕроорпНроЪроорпН | роЙро│рпНро│рпВро░рпН (Foundry) | роорпЗроХроорпН (Azure OpenAI) |
|--------|-----------------|---------------------|
| **родро╛роородроорпН** | ЁЯЪА 50-200ms (роЗрогрпИропроорпН роЗро▓рпНро▓ро╛рооро▓рпН) | тП▒я╕П 200-2000ms (роЗрогрпИропроорпН роЪро╛ро░рпНроирпНрод) |
| **родройро┐ропрпБро░ро┐роорпИ** | ЁЯФТ родро░ро╡рпБроХро│рпН роЪро╛родройродрпНродрпИ ро╡ро┐роЯрпНроЯрпБ ро╡рпЖро│ро┐ропрпЗ роЪрпЖро▓рпНро▓ро╛родрпБ | тЪая╕П родро░ро╡рпБроХро│рпН роорпЗроХродрпНродро┐ро▒рпНроХрпБ роЕройрпБрокрпНрокрокрпНрокроЯрпБроорпН |
| **роЪрпЖро▓ро╡рпБ** | ЁЯТ░ ро╣ро╛ро░рпНроЯрпНро╡рпЗро░рпБроХрпНроХрпБрокрпН рокро┐ро▒роХрпБ роЗро▓ро╡роЪроорпН | ЁЯТ╕ роЯрпЛроХрпНроХройрпН роТройрпНро▒рпБроХрпНроХрпБ роЪрпЖро▓ро╡рпБ |
| **роЖроГрокрпНро▓рпИройрпН** | тЬЕ роЗрогрпИропроорпН роЗро▓рпНро▓ро╛рооро▓рпН роЪрпЖропро▓рпНрокроЯрпБроорпН | тЭМ роЗрогрпИропроорпН родрпЗро╡рпИ |
| **рооро╛родро┐ро░ро┐ роЕро│ро╡рпБ** | тЪая╕П ро╣ро╛ро░рпНроЯрпНро╡рпЗро░ро╛ро▓рпН роХроЯрпНроЯрпБрокрпНрокроЯрпБродрпНродрокрпНрокроЯрпНроЯродрпБ | тЬЕ рооро┐роХрокрпНрокрпЖро░ро┐роп рооро╛родро┐ро░ро┐роХро│рпБроХрпНроХрпБ роЕрогрпБроХро▓рпН |
| **рооро┐роХрпИрокрпНрокроЯрпБродрпНродро▓рпН** | тЪая╕П ро╣ро╛ро░рпНроЯрпНро╡рпЗро░рпИ роЪро╛ро░рпНроирпНродродрпБ | тЬЕ ро╡ро░роорпНрокро▒рпНро▒ рооро┐роХрпИрокрпНрокроЯрпБродрпНродро▓рпН |

### роХро▓рокрпНрокрпБ роЙродрпНродро┐роХро│рпН

**Local-First with Fallback:**
```python
async def hybrid_completion(prompt: str, complexity_threshold: int = 100):
    if len(prompt.split()) < complexity_threshold:
        return await local_completion(prompt)  # Fast, private
    else:
        return await cloud_completion(prompt)   # Complex reasoning
```

**Task-Based Routing:**
```python
async def smart_routing(prompt: str, task_type: str):
    routing_rules = {
        "code_generation": "local",     # Privacy-sensitive
        "creative_writing": "cloud",    # Benefits from larger models
        "data_analysis": "local",       # Fast iteration needed
        "research": "cloud"             # Requires broad knowledge
    }
    
    if routing_rules.get(task_type) == "local":
        return await foundry_completion(prompt)
    else:
        return await azure_completion(prompt)
```

## рокроХрпБродро┐ 3: рооро╛родро┐ро░ро┐ 04 - Chainlit роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБ

### ро╡ро┐ро░рпИро╡ро╛рой родрпКроЯроХрпНроХроорпН

```cmd
# Navigate to Module08 directory  
cd Module08

# Start your preferred model
foundry model run phi-4-mini

# Run the Chainlit application (avoiding port conflicts)
chainlit run samples\04\app.py -w --port 8080
```

рокропройрпНрокро╛роЯрпБ родро╛ройро╛роХро╡рпЗ `http://localhost:8080` роЗро▓рпН родро┐ро▒роХрпНроХро┐ро▒родрпБ, роиро╡рпАрой роЙро░рпИропро╛роЯро▓рпН роЗроЯрпИроорпБроХродрпНродрпБроЯройрпН.

### роорпБроХрпНроХро┐роп роЪрпЖропро▓рпНрокро╛роЯрпБ

рооро╛родро┐ро░ро┐ 04 рокропройрпНрокро╛роЯрпБ роЙро▒рпНрокродрпНродро┐ родро░рооро╛рой роорпБро▒рпИроорпИроХро│рпИ ро╡ро┐ро│роХрпНроХрпБроХро┐ро▒родрпБ:

**родро╛ройро┐ропроЩрпНроХро┐ роЪрпЗро╡рпИ роХрогрпНроЯро▒ро┐родро▓рпН:**
```python
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

# Global variables for client and model
client = None
model_name = None

async def initialize_client():
    global client, model_name
    alias = os.environ.get("MODEL", "phi-4-mini")
    
    try:
        # Use FoundryLocalManager for proper service management
        manager = FoundryLocalManager(alias)
        model_info = manager.get_model_info(alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-required"
        )
        model_name = model_info.id if model_info else alias
        return True
    except Exception as e:
        # Fallback to manual configuration
        base_url = os.environ.get("BASE_URL", "http://localhost:51211")
        client = OpenAI(base_url=f"{base_url}/v1", api_key="not-required")
        model_name = alias
        return True
```

**ро╕рпНроЯрпНро░рпАрооро┐роЩрпН роЙро░рпИропро╛роЯро▓рпН роХрпИропро╛ро│рпБродро▓рпН:**
```python
@cl.on_message
async def main(message: cl.Message):
    # Create streaming response
    msg = cl.Message(content="")
    await msg.send()
    
    stream = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": message.content}
        ],
        stream=True
    )
    
    # Stream tokens in real-time
    for chunk in stream:
        if chunk.choices[0].delta.content:
            await msg.stream_token(chunk.choices[0].delta.content)
    
    await msg.update()
```

### роХроЯрпНроЯроорпИрокрпНрокрпБ ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпН

**роЪрпВро┤ро▓рпН рооро╛ро▒ро┐роХро│рпН:**

| рооро╛ро▒ро┐ | ро╡ро┐ро│роХрпНроХроорпН | роЗропро▓рпНрокрпБроиро┐ро▓рпИ | роЙродро╛ро░рогроорпН |
|----------|-------------|---------|----------|
| `MODEL` | рокропройрпНрокроЯрпБродрпНрод ро╡рпЗрогрпНроЯро┐роп рооро╛родро┐ро░ро┐ рокрпЖропро░рпН | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Foundry Local роЗро▒рпБродро┐рокрпНрокрпБро│рпНро│ро┐ | родро╛ройро╛роХ роХрогрпНроЯро▒ро┐ропрокрпНрокроЯрпНроЯродрпБ | `http://localhost:51211` |
| `API_KEY` | API ро╡ро┐роЪрпИ (роЙро│рпНро│рпВро░рпБроХрпНроХрпБ ро╡ро┐ро░рпБрокрпНрокроорпН) | `""` | `your-api-key` |

**роорпЗроорпНрокроЯрпНроЯ рокропройрпНрокро╛роЯрпБ:**
```cmd
# Use different model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Use different ports (avoid 51211 which is used by Foundry Local)
chainlit run samples\04\app.py -w --port 3000
chainlit run samples\04\app.py -w --port 5000
```

## рокроХрпБродро┐ 4: Jupyter Notebooks роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН рооро▒рпНро▒рпБроорпН рокропройрпНрокроЯрпБродрпНродрпБродро▓рпН

### Notebook роЖродро░ро╡рпБ роХрогрпНрогрпЛроЯрпНроЯроорпН

рооро╛родро┐ро░ро┐ 04 роорпБро┤рпБроорпИропро╛рой Jupyter notebook (`chainlit_app.ipynb`) роР ро╡ро┤роЩрпНроХрпБроХро┐ро▒родрпБ, роЗродрпБ:

- **ЁЯУЪ роХро▓рпНро╡ро┐ роЙро│рпНро│роЯроХрпНроХроорпН**: рокроЯро┐рокрпНрокроЯро┐ропро╛роХ роХро▒рпНро▒ро▓рпН рокрпКро░рпБроЯрпНроХро│рпН
- **ЁЯФм роЗроЯрпИроорпБроХ роЖро░ро╛ропрпНроЪрпНроЪро┐**: роХрпБро▒ро┐ропрпАроЯрпНроЯрпБ роЪрпЖро▓рпНроХро│рпИ роЗропроХрпНроХро┐ рокро░ро┐роЪрпЛродро┐роХрпНроХро╡рпБроорпН
- **ЁЯУК роХро╛роЯрпНроЪро┐рокрпНрокроЯрпБродрпНродро▓рпН**: ро╡ро░рпИрокроЯроЩрпНроХро│рпН, ро╡ро░рпИрокроЯроЩрпНроХро│рпН, рооро▒рпНро▒рпБроорпН ро╡рпЖро│ро┐ропрпАроЯрпНроЯрпБ роХро╛роЯрпНроЪро┐рокрпНрокроЯрпБродрпНродро▓рпН
- **ЁЯЫая╕П роорпЗроорпНрокро╛роЯрпНроЯрпБ роХро░рпБро╡ро┐роХро│рпН**: роЪрпЛродройрпИ рооро▒рпНро▒рпБроорпН рокро┐ро┤рпИродро┐ро░рпБродрпНродроорпН

### роЙроЩрпНроХро│рпН роЪрпКроирпНрод Notebook роР роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН

#### рокроЯро┐ 1: Jupyter роЪрпВро┤ро▓рпИ роЕроорпИродрпНродро▓рпН

```cmd
# Ensure you're in the Module08 directory
cd Module08

# Activate your virtual environment
.venv\Scripts\activate

# Install Jupyter and dependencies
pip install jupyter notebook jupyterlab ipykernel
pip install -r requirements.txt

# Register the kernel for VS Code
python -m ipykernel install --user --name=foundry-local --display-name="Foundry Local"
```

#### рокроЯро┐ 2: рокрпБродро┐роп Notebook роР роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН

**VS Code рокропройрпНрокроЯрпБродрпНродрпБродро▓рпН:**
1. Module08 роХрпЛрокрпНрокроХродрпНродро┐ро▓рпН VS Code роР родро┐ро▒роХрпНроХро╡рпБроорпН
2. `.ipynb` роирпАроЯрпНроЯро┐рокрпНрокрпБроЯройрпН рокрпБродро┐роп роХрпЛрокрпНрокрпИ роЙро░рпБро╡ро╛роХрпНроХро╡рпБроорпН
3. "Foundry Local" роХро░рпНройро▓рпИ родрпЗро░рпНроирпНродрпЖроЯрпБроХрпНроХро╡рпБроорпН
4. роЙроЩрпНроХро│рпН роЙро│рпНро│роЯроХрпНроХродрпНродрпБроЯройрпН роЪрпЖро▓рпНроХро│рпИ роЪрпЗро░рпНроХрпНроХродрпН родрпКроЯроЩрпНроХро╡рпБроорпН

**Jupyter Lab рокропройрпНрокроЯрпБродрпНродрпБродро▓рпН:**
```cmd
# Start Jupyter Lab
jupyter lab

# Navigate to samples/04/ and create new notebook
# Choose Python 3 kernel
```

### Notebook роЕроорпИрокрпНрокрпБ роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпН

#### роЪрпЖро▓рпНроХро│рпН роЕроорпИрокрпНрокрпБ

```python
# Cell 1: Imports and Setup
import os
import sys
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

print("тЬЕ Libraries imported successfully")
```

```python
# Cell 2: Configuration and Client Setup
class FoundryClientManager:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.client = None
        
    def initialize_client(self):
        # Client initialization logic
        pass

# Initialize and test
client_manager = FoundryClientManager()
result = client_manager.initialize_client()
print(f"Client initialized: {result}")
```

### роЗроЯрпИроорпБроХ роЙродро╛ро░рогроЩрпНроХро│рпН рооро▒рпНро▒рпБроорпН рокропро┐ро▒рпНроЪро┐роХро│рпН

#### рокропро┐ро▒рпНроЪро┐ 1: роХро┐ро│рпИропройрпНроЯрпН роХроЯрпНроЯроорпИрокрпНрокрпБ роЪрпЛродройрпИ

```python
# Test different configuration methods
configurations = [
    {"method": "foundry_sdk", "model": "phi-4-mini"},
    {"method": "manual", "base_url": "http://localhost:51211", "model": "qwen2.5-7b"},
]

for config in configurations:
    print(f"\nЁЯзк Testing {config['method']} configuration...")
    # Implementation here
    result = test_configuration(config)
    print(f"Result: {'тЬЕ Success' if result['status'] == 'ok' else 'тЭМ Failed'}")
```

#### рокропро┐ро▒рпНроЪро┐ 2: ро╕рпНроЯрпНро░рпАрооро┐роЩрпН рокродро┐ро▓рпН роЪро┐роорпБро▓рпЗро╖ройрпН

```python
import asyncio

async def simulate_streaming_response(text, delay=0.1):
    """Simulate how streaming works in Chainlit."""
    print("ЁЯМК Simulating streaming response...")
    
    for char in text:
        print(char, end='', flush=True)
        await asyncio.sleep(delay)
    
    print("\nтЬЕ Streaming complete!")

# Test the simulation
sample_text = "This is how streaming responses work in Chainlit applications!"
await simulate_streaming_response(sample_text)
```

## рокроХрпБродро┐ 5: WebGPU роЙро▓ро╛ро╡ро┐ родрпАро░рпНрооро╛рой роЯрпЖроорпЛ

### роХрогрпНрогрпЛроЯрпНроЯроорпН

WebGPU AI рооро╛родро┐ро░ро┐роХро│рпИ роирпЗро░роЯро┐ропро╛роХ роЙро▓ро╛ро╡ро┐ропро┐ро▓рпН роЗропроХрпНроХ роЕройрпБроородро┐роХрпНроХро┐ро▒родрпБ, роЕродро┐роХрокроЯрпНроЪ родройро┐ропрпБро░ро┐роорпИ рооро▒рпНро▒рпБроорпН роиро┐ро▒рпБро╡ро▓рпН роЗро▓рпНро▓ро╛род роЕройрпБрокро╡роЩрпНроХро│рпИ ро╡ро┤роЩрпНроХрпБроХро┐ро▒родрпБ. роЗроирпНрод рооро╛родро┐ро░ро┐ ONNX Runtime Web роЙроЯройрпН WebGPU роЪрпЖропро▓рпНрокро╛роЯрпНроЯрпИ ро╡ро┐ро│роХрпНроХрпБроХро┐ро▒родрпБ.

### рокроЯро┐ 1: WebGPU роЖродро░ро╡рпИроЪрпН роЪро░ро┐рокро╛ро░рпНроХрпНроХро╡рпБроорпН

**роЙро▓ро╛ро╡ро┐ родрпЗро╡рпИроХро│рпН:**
- Chrome/Edge 113+ WebGPU роЗропроХрпНроХрокрпНрокроЯрпНроЯрпБ
- роЪро░ро┐рокро╛ро░рпНроХрпНроХро╡рпБроорпН: `chrome://gpu` тЖТ "WebGPU" роиро┐ро▓рпИропрпИ роЙро▒рпБродро┐рокрпНрокроЯрпБродрпНродро╡рпБроорпН
- роиро┐ро░ро▓рпНрокрпВро░рпНро╡ роЪро░ро┐рокро╛ро░рпНрокрпНрокрпБ: `if (!('gpu' in navigator)) { /* no WebGPU */ }`

### рокроЯро┐ 2: WebGPU роЯрпЖроорпЛ роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН

роХрпЛрокрпНрокроХродрпНродрпИ роЙро░рпБро╡ро╛роХрпНроХро╡рпБроорпН: `samples/04/webgpu-demo/`

**index.html:**
```html
<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WebGPU + ONNX Runtime Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
    <style>
        body { font-family: system-ui, sans-serif; margin: 2rem; }
        pre { background: #f5f5f5; padding: 1rem; overflow: auto; }
        .status { padding: 1rem; background: #e3f2fd; border-radius: 4px; }
    </style>
</head>
<body>
    <h1>ЁЯЪА WebGPU + Foundry Local Integration</h1>
    <div id="status" class="status">Initializing...</div>
    <pre id="output"></pre>
    <script type="module" src="./main.js"></script>
</body>
</html>
```

**main.js:**
```javascript
const statusEl = document.getElementById('status');
const outputEl = document.getElementById('output');

function log(msg) {
    outputEl.textContent += `${msg}\n`;
    console.log(msg);
}

(async () => {
    try {
        if (!('gpu' in navigator)) {
            statusEl.textContent = 'тЭМ WebGPU not available';
            return;
        }
        
        statusEl.textContent = 'ЁЯФН WebGPU detected. Loading model...';
        
        // Use a small ONNX model for demo
        const modelUrl = 'https://huggingface.co/onnx/models/resolve/main/vision/classification/mnist-12/mnist-12.onnx';
        
        const session = await ort.InferenceSession.create(modelUrl, {
            executionProviders: ['webgpu']
        });
        
        log('тЬЕ ONNX Runtime session created with WebGPU');
        log(`ЁЯУК Input names: ${session.inputNames.join(', ')}`);
        log(`ЁЯУК Output names: ${session.outputNames.join(', ')}`);
        
        // Create dummy input (MNIST expects 1x1x28x28)
        const inputData = new Float32Array(1 * 1 * 28 * 28).fill(0.1);
        const input = new ort.Tensor('float32', inputData, [1, 1, 28, 28]);
        
        const feeds = {};
        feeds[session.inputNames[0]] = input;
        
        const results = await session.run(feeds);
        const output = results[session.outputNames[0]];
        
        // Find prediction (argmax)
        let maxIdx = 0;
        for (let i = 1; i < output.data.length; i++) {
            if (output.data[i] > output.data[maxIdx]) maxIdx = i;
        }
        
        statusEl.textContent = 'тЬЕ WebGPU inference complete!';
        log(`ЁЯОп Predicted class: ${maxIdx}`);
        log(`ЁЯУИ Confidence scores: [${Array.from(output.data).map(x => x.toFixed(3)).join(', ')}]`);
        
    } catch (error) {
        statusEl.textContent = `тЭМ Error: ${error.message}`;
        log(`Error: ${error.message}`);
        console.error(error);
    }
})();
```

### рокроЯро┐ 3: роЯрпЖроорпЛро╡рпИ роЗропроХрпНроХро╡рпБроорпН

```cmd
# Create demo directory
mkdir samples\04\webgpu-demo
cd samples\04\webgpu-demo

# Save HTML and JS files, then serve
python -m http.server 5173

# Open browser to http://localhost:5173
```

## рокроХрпБродро┐ 6: Open WebUI роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ

### роХрогрпНрогрпЛроЯрпНроЯроорпН

Open WebUI Foundry Local роЗройрпН OpenAI-роЗройрпН роЗрогроХрпНроХрооро╛рой API-ропрпБроЯройрпН роЗрогрпИроХрпНроХрпБроорпН родрпКро┤ро┐ро▓рпНроорпБро▒рпИ ChatGPT рокрпЛройрпНро▒ роЗроЯрпИроорпБроХродрпНродрпИ ро╡ро┤роЩрпНроХрпБроХро┐ро▒родрпБ.

### рокроЯро┐ 1: роорпБройрпН родрпЗро╡рпИроХро│рпН

```cmd
# Verify Foundry Local is running
foundry service status

# Start a model
foundry model run phi-4-mini

# Confirm API endpoint is accessible
curl http://localhost:51211/v1/models
```

### рокроЯро┐ 2: Docker роЕроорпИрокрпНрокрпБ (рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ)

```cmd
# Pull Open WebUI image
docker pull ghcr.io/open-webui/open-webui:main

# Run with Foundry Local connection
docker run -d --name open-webui -p 3000:8080 ^
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 ^
  -e OPENAI_API_KEY=foundry-local-key ^
  -v open-webui-data:/app/backend/data ^
  ghcr.io/open-webui/open-webui:main
```

**роХрпБро▒ро┐рокрпНрокрпБ:** `host.docker.internal` Windows роЗро▓рпН Docker роХрпЖрогрпНроЯрпИройро░рпНроХро│рпИ ро╣рпЛро╕рпНроЯрпН роЗропроирпНродро┐ро░родрпНродрпИ роЕрогрпБроХ роЕройрпБроородро┐роХрпНроХро┐ро▒родрпБ.

### рокроЯро┐ 3: роХроЯрпНроЯроорпИрокрпНрокрпБ

1. **роЙро▓ро╛ро╡ро┐ропрпИ родро┐ро▒роХрпНроХро╡рпБроорпН:** `http://localhost:3000` роХрпНроХрпБ роЪрпЖро▓рпНро▓ро╡рпБроорпН
2. **роЖро░роорпНрок роЕроорпИрокрпНрокрпБ:** роиро┐ро░рпНро╡ро╛роХ роХрогроХрпНроХрпИ роЙро░рпБро╡ро╛роХрпНроХро╡рпБроорпН
3. **рооро╛родро┐ро░ро┐ роХроЯрпНроЯроорпИрокрпНрокрпБ:**
   - роЕроорпИрокрпНрокрпБроХро│рпН тЖТ рооро╛родро┐ро░ро┐роХро│рпН тЖТ OpenAI API  
   - роЕроЯро┐рокрпНрокроЯрпИ URL: `http://host.docker.internal:51211/v1`
   - API ро╡ро┐роЪрпИ: `foundry-local-key` (роОроирпНрод роородро┐рокрпНрокрпБроорпН ро╡рпЗро▓рпИ роЪрпЖропрпНроХро┐ро▒родрпБ)
4. **роЗрогрпИрокрпНрокрпИ роЪрпЛродро┐роХрпНроХро╡рпБроорпН:** рооро╛родро┐ро░ро┐роХро│рпН dropdown роЗро▓рпН родрпЛройрпНро▒ ро╡рпЗрогрпНроЯрпБроорпН

### рокро┐ро┤рпИродро┐ро░рпБродрпНродроорпН

**рокрпКродрпБро╡ро╛рой рокро┐ро░роЪрпНроЪро┐ройрпИроХро│рпН:**

1. **роЗрогрпИрокрпНрокрпБ рооро▒рпБроХрпНроХрокрпНрокроЯрпНроЯродрпБ:**
   ```cmd
   # Check Foundry Local status
   foundry service ps
   netstat -ano | findstr :51211
   ```

2. **рооро╛родро┐ро░ро┐роХро│рпН родрпЛройрпНро▒ро╡ро┐ро▓рпНро▓рпИ:**
   - рооро╛родро┐ро░ро┐ роПро▒рпНро▒рокрпНрокроЯрпНроЯродро╛ роОройрпНрокродрпИ роЙро▒рпБродро┐рокрпНрокроЯрпБродрпНродро╡рпБроорпН: `foundry model list`
   - API рокродро┐ро▓рпИроЪрпН роЪро░ро┐рокро╛ро░рпНроХрпНроХро╡рпБроорпН: `curl http://localhost:51211/v1/models`
   - Open WebUI роХрпЖрогрпНроЯрпИройро░рпИ роорпАрогрпНроЯрпБроорпН родрпКроЯроЩрпНроХро╡рпБроорпН

## рокроХрпБродро┐ 7: роЙро▒рпНрокродрпНродро┐ ро╡рпЖро│ро┐ропрпАроЯрпНроЯрпБ роХро░рпБродрпНродрпБроХрпНроХро│рпН

### роЪрпВро┤ро▓рпН роХроЯрпНроЯроорпИрокрпНрокрпБ

**роорпЗроорпНрокро╛роЯрпНроЯрпБ роЕроорпИрокрпНрокрпБ:**
```cmd
# Development with auto-reload and debugging
chainlit run samples\04\app.py -w --port 8080 --debug
```

**роЙро▒рпНрокродрпНродро┐ ро╡рпЖро│ро┐ропрпАроЯрпБ:**
```cmd
# Production mode with optimizations
chainlit run samples\04\app.py --host 0.0.0.0 --port 8080 --no-cache
```

### рокрпКродрпБро╡ро╛рой рокрпЛро░рпНроЯрпН рокро┐ро░роЪрпНроЪро┐ройрпИроХро│рпН рооро▒рпНро▒рпБроорпН родрпАро░рпНро╡рпБроХро│рпН

**51211 рокрпЛро░рпНроЯрпН роорпЛродро▓рпН родроЯрпБрокрпНрокрпБ:**
```cmd
# Check what's using Foundry Local port
netstat -ano | findstr :51211

# Use different port for Chainlit
chainlit run samples\04\app.py -w --port 8080
```

### роЪрпЖропро▓рпНродро┐ро▒ройрпН роХрогрпНроХро╛рогро┐рокрпНрокрпБ

**роЖро░рпЛроХрпНроХро┐роп роЪрпЛродройрпИ роЪрпЖропро▓рпНрокро╛роЯрпБ:**
```python
@cl.on_chat_start
async def health_check():
    try:
        # Test model availability
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1
        )
        return {"status": "healthy", "model": model_name}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

## роЪрпБро░рпБроХрпНроХроорпН

роЕрооро░рпНро╡рпБ 4 Chainlit роорпВро▓роорпН роЙро░рпИропро╛роЯро▓рпН AI роХрпНроХро╛рой роЙро▒рпНрокродрпНродро┐ родро░рооро╛рой рокропройрпНрокро╛роЯрпБроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБро╡родрпБ роХрпБро▒ро┐родрпНродрпБ роХро▒рпНро▒рпБроХрпНроХрпКроЯрпБродрпНродродрпБ. роирпАроЩрпНроХро│рпН роХро▒рпНро▒рпБроХрпНроХрпКрогрпНроЯродрпБ:

- тЬЕ **Chainlit Framework**: роЙро░рпИропро╛роЯро▓рпН рокропройрпНрокро╛роЯрпБроХро│рпБроХрпНроХро╛рой роиро╡рпАрой UI рооро▒рпНро▒рпБроорпН ро╕рпНроЯрпНро░рпАрооро┐роЩрпН роЖродро░ро╡рпБ
- тЬЕ **Foundry Local роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ**: SDK рокропройрпНрокро╛роЯрпБ рооро▒рпНро▒рпБроорпН роХроЯрпНроЯроорпИрокрпНрокрпБ роорпБро▒рпИроорпИроХро│рпН  
- тЬЕ **WebGPU родрпАро░рпНрооро╛ройроорпН**: роЕродро┐роХрокроЯрпНроЪ родройро┐ропрпБро░ро┐роорпИроХрпНроХро╛рой роЙро▓ро╛ро╡ро┐ роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓ро╛рой AI
- тЬЕ **Open WebUI роЕроорпИрокрпНрокрпБ**: родрпКро┤ро┐ро▓рпНроорпБро▒рпИ роЙро░рпИропро╛роЯро▓рпН роЗроЯрпИроорпБроХ ро╡рпЖро│ро┐ропрпАроЯрпБ
- тЬЕ **роЙро▒рпНрокродрпНродро┐ роорпБро▒рпИроорпИроХро│рпН**: рокро┐ро┤рпИ роХрпИропро╛ро│рпБродро▓рпН, роХрогрпНроХро╛рогро┐рокрпНрокрпБ, рооро▒рпНро▒рпБроорпН рооро┐роХрпИрокрпНрокроЯрпБродрпНродро▓рпН

рооро╛родро┐ро░ро┐ 04 рокропройрпНрокро╛роЯрпБ Microsoft Foundry Local роорпВро▓роорпН роЙро│рпНро│рпВро░рпН AI рооро╛родро┐ро░ро┐роХро│рпИ рокропройрпНрокроЯрпБродрпНродро┐ ро╡ро▓рпБро╡ро╛рой роЙро░рпИропро╛роЯро▓рпН роЗроЯрпИроорпБроХроЩрпНроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХ роЪро┐ро▒роирпНрод роироЯрпИроорпБро▒рпИроХро│рпИ ро╡ро┐ро│роХрпНроХрпБроХро┐ро▒родрпБ, роЕродрпЗроЪрооропроорпН роЪро┐ро▒роирпНрод рокропройро░рпН роЕройрпБрокро╡роЩрпНроХро│рпИ ро╡ро┤роЩрпНроХрпБроХро┐ро▒родрпБ.

## роХрпБро▒ро┐рокрпНрокрпБроХро│рпН

- **[рооро╛родро┐ро░ро┐ 04: Chainlit рокропройрпНрокро╛роЯрпБ](samples/04/README.md)**: роорпБро┤рпБроорпИропро╛рой рокропройрпНрокро╛роЯрпБ рооро▒рпНро▒рпБроорпН роЖро╡рогроорпН
- **[Chainlit роХро▓рпНро╡ро┐ Notebook](samples/04/chainlit_app.ipynb)**: роЗроЯрпИроорпБроХ роХро▒рпНро▒ро▓рпН рокрпКро░рпБроЯрпНроХро│рпН
- **[Foundry Local роЖро╡рогроорпН](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: роорпБро┤рпБроорпИропро╛рой родро│роорпН роЖро╡рогроорпН
- **[Chainlit роЖро╡рогроорпН](https://docs.chainlit.io/)**: роЕродро┐роХро╛ро░рокрпНрокрпВро░рпНро╡ Framework роЖро╡рогроорпН
- **[Open WebUI роТро░рпБроЩрпНроХро┐рогрпИрокрпНрокрпБ ро╡ро┤ро┐роХро╛роЯрпНроЯро┐](https://github.com/microsoft/foundry-local/blob/main/docs/tutorials/chat-application-with-open-web-ui.md)**: роЕродро┐роХро╛ро░рокрпНрокрпВро░рпНро╡ роЯрпБроЯрпЛро░ро┐ропро▓рпН

---

**роХрпБро▒ро┐рокрпНрокрпБ**:  
роЗроирпНрод роЖро╡рогроорпН [Co-op Translator](https://github.com/Azure/co-op-translator) роОройрпНро▒ AI роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ роЪрпЗро╡рпИропрпИрокрпН рокропройрпНрокроЯрпБродрпНродро┐ роорпКро┤ро┐рокрпЖропро░рпНроХрпНроХрокрпНрокроЯрпНроЯрпБро│рпНро│родрпБ. роиро╛роЩрпНроХро│рпН родрпБро▓рпНро▓ро┐ропродрпНродро┐ро▒рпНроХро╛роХ роорпБропро▒рпНроЪро┐роХрпНроХро┐ройрпНро▒рпЛроорпН, роЖройро╛ро▓рпН родро╛ройро┐ропроЩрпНроХро┐ роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБроХро│ро┐ро▓рпН рокро┐ро┤рпИроХро│рпН роЕро▓рпНро▓родрпБ родро╡ро▒рпБроХро│рпН роЗро░рпБроХрпНроХроХрпНроХрпВроЯрпБроорпН роОройрпНрокродрпИ родропро╡рпБроЪрпЖропрпНродрпБ роХро╡ройродрпНродро┐ро▓рпН роХрпКро│рпНро│рпБроЩрпНроХро│рпН. роЕродройрпН родро╛ропрпНроорпКро┤ро┐ропро┐ро▓рпН роЙро│рпНро│ роорпВро▓ роЖро╡рогроорпН роЕродро┐роХро╛ро░рокрпНрокрпВро░рпНро╡ роЖродро╛ро░рооро╛роХ роХро░рпБродрокрпНрокроЯ ро╡рпЗрогрпНроЯрпБроорпН. роорпБроХрпНроХро┐ропрооро╛рой родроХро╡ро▓рпНроХро│рпБроХрпНроХрпБ, родрпКро┤ро┐ро▓рпНроорпБро▒рпИ рооройро┐род роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ. роЗроирпНрод роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпИрокрпН рокропройрпНрокроЯрпБродрпНродрпБро╡родро╛ро▓рпН роПро▒рпНрокроЯрпБроорпН роОроирпНрод родро╡ро▒ро╛рой рокрпБро░ро┐родро▓рпНроХро│рпН роЕро▓рпНро▓родрпБ родро╡ро▒ро╛рой ро╡ро┐ро│роХрпНроХроЩрпНроХро│рпБроХрпНроХрпБ роиро╛роЩрпНроХро│рпН рокрпКро▒рпБрокрпНрокро▓рпНро▓.