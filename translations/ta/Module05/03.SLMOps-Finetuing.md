<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-10-11T11:20:42+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "ta"
}
-->
# பகுதி 3: நுண்ணிய அமைப்பு - குறிப்பிட்ட பணிகளுக்கான மாதிரிகளை தனிப்பயனாக்குதல்

## உள்ளடக்க அட்டவணை
1. [நுண்ணிய அமைப்புக்கான அறிமுகம்](../../../Module05)
2. [நுண்ணிய அமைப்பு ஏன் முக்கியம்](../../../Module05)
3. [நுண்ணிய அமைப்பின் வகைகள்](../../../Module05)
4. [Microsoft Olive உடன் நுண்ணிய அமைப்பு](../../../Module05)
5. [கைமுறையாக செய்யும் உதாரணங்கள்](../../../Module05)
6. [சிறந்த நடைமுறைகள் மற்றும் வழிகாட்டுதல்கள்](../../../Module05)
7. [மேம்பட்ட தொழில்நுட்பங்கள்](../../../Module05)
8. [மதிப்பீடு மற்றும் கண்காணிப்பு](../../../Module05)
9. [பொதுவான சவால்கள் மற்றும் தீர்வுகள்](../../../Module05)
10. [தீர்மானம்](../../../Module05)

## நுண்ணிய அமைப்புக்கான அறிமுகம்

**நுண்ணிய அமைப்பு** என்பது ஒரு சக்திவாய்ந்த இயந்திரக் கற்றல் தொழில்நுட்பமாகும், இது முன்கூட்டியே பயிற்சி பெற்ற மாதிரியை குறிப்பிட்ட பணிகளைச் செய்ய அல்லது சிறப்பு தரவுத்தொகுப்புகளுடன் வேலை செய்யத் தகுதியாக மாற்றுகிறது. ஒரு மாதிரியை ஆரம்பத்திலிருந்து பயிற்சி செய்யாமல், நுண்ணிய அமைப்பு முன்கூட்டியே பயிற்சி பெற்ற மாதிரியின் அறிவை பயன்படுத்தி, உங்கள் குறிப்பிட்ட பயன்பாட்டிற்காக அதைச் சரிசெய்கிறது.

### நுண்ணிய அமைப்பு என்றால் என்ன?

நுண்ணிய அமைப்பு என்பது **மாற்று கற்றல்** (transfer learning) என்ற ஒரு வடிவமாகும், இதில்:
- பெரிய தரவுத்தொகுப்புகளிலிருந்து பொதுவான முறைமைகளை கற்றுக்கொண்ட ஒரு முன்பயிற்சி செய்யப்பட்ட மாதிரியை நீங்கள் தொடங்குகிறீர்கள்
- உங்கள் குறிப்பிட்ட தரவுத்தொகுப்பைப் பயன்படுத்தி மாதிரியின் உள் அளவுருக்களை சரிசெய்கிறீர்கள்
- மதிப்புமிக்க அறிவைத் தக்கவைத்துக்கொண்டு, உங்கள் பணிக்காக மாதிரியை சிறப்பாக்குகிறீர்கள்

இதை ஒரு திறமையான சமையல்காரரை புதிய சமையல் முறையைச் செய்ய கற்றுக்கொடுக்குவது போல நினைக்கலாம் - அவர்கள் சமையலின் அடிப்படைத் திறன்களை ஏற்கனவே புரிந்துகொண்டுள்ளனர், ஆனால் புதிய பாணிக்கான குறிப்பிட்ட தொழில்நுட்பங்கள் மற்றும் சுவைகளை கற்றுக்கொள்ள வேண்டும்.

### முக்கிய நன்மைகள்

- **நேர திறன்**: ஆரம்பத்திலிருந்து பயிற்சி செய்வதை விட மிகவும் வேகமாக
- **தரவு திறன்**: சிறிய தரவுத்தொகுப்புகளைப் பயன்படுத்தி நல்ல செயல்திறனை அடைய முடியும்
- **செலவுக் குறைவு**: குறைந்த கணினி வளங்களை தேவைப்படும்
- **சிறந்த செயல்திறன்**: ஆரம்பத்திலிருந்து பயிற்சி செய்வதை விட அதிகமான முடிவுகளை அடைகிறது
- **வளங்களின் சிறந்த பயன்பாடு**: சிறிய குழுக்கள் மற்றும் நிறுவனங்களுக்கு சக்திவாய்ந்த AI-ஐ அணுகமுடிய செய்கிறது

## நுண்ணிய அமைப்பு ஏன் முக்கியம்

### நிஜ உலக பயன்பாடுகள்

நுண்ணிய அமைப்பு பல சூழல்களில் அவசியமாகும்:

**1. துறைக்கேற்ப மாற்றம்**
- மருத்துவ AI: மருத்துவ சொற்களஞ்சியம் மற்றும் மருத்துவ குறிப்புகளுக்கான பொதுவான மொழி மாதிரிகளை மாற்றுதல்
- சட்ட தொழில்நுட்பம்: சட்ட ஆவணங்களைப் பகுப்பாய்வு மற்றும் ஒப்பந்த மதிப்பீட்டுக்கான மாதிரிகளை சிறப்பாக்குதல்
- நிதி சேவைகள்: நிதி அறிக்கைகளைப் பகுப்பாய்வு மற்றும் அபாய மதிப்பீட்டுக்கான மாதிரிகளை தனிப்பயனாக்குதல்

**2. பணிக்கேற்ப சிறப்பாக்கம்**
- உள்ளடக்க உருவாக்கம்: குறிப்பிட்ட எழுத்து பாணிகள் அல்லது சுருக்கங்களுக்கான நுண்ணிய அமைப்பு
- குறியீடு உருவாக்கம்: குறிப்பிட்ட நிரலாக்க மொழிகள் அல்லது கட்டமைப்புகளுக்கான மாதிரிகளை மாற்றுதல்
- மொழிபெயர்ப்பு: குறிப்பிட்ட மொழி ஜோடிகள் அல்லது தொழில்நுட்ப துறைகளுக்கான செயல்திறனை மேம்படுத்துதல்

**3. நிறுவன பயன்பாடுகள்**
- வாடிக்கையாளர் சேவை: நிறுவன-குறிப்பான சொற்களஞ்சியத்தைப் புரிந்துகொள்ளும் chatbot-களை உருவாக்குதல்
- உள்துறை ஆவணங்கள்: நிறுவன செயல்முறைகளை அறிந்த AI உதவியாளர்களை உருவாக்குதல்
- துறை-குறிப்பான தீர்வுகள்: துறைக்கேற்ப சொற்களஞ்சியம் மற்றும் வேலைப்பாடுகளைப் புரிந்துகொள்ளும் மாதிரிகளை உருவாக்குதல்

## நுண்ணிய அமைப்பின் வகைகள்

### 1. முழுமையான நுண்ணிய அமைப்பு (Instruction Fine-Tuning)

முழுமையான நுண்ணிய அமைப்பில், பயிற்சியின் போது அனைத்து மாதிரி அளவுருக்களும் புதுப்பிக்கப்படுகின்றன. இந்த அணுகுமுறை:
- அதிகபட்ச நெகிழ்வுத்தன்மை மற்றும் செயல்திறன் சாத்தியத்தை வழங்குகிறது
- குறிப்பிடத்தக்க கணினி வளங்களை தேவைப்படும்
- முற்றிலும் புதிய பதிப்பு மாதிரியை உருவாக்குகிறது
- அதிக பயிற்சி தரவுகள் மற்றும் கணினி வளங்கள் உள்ள சூழல்களுக்கு சிறந்தது

### 2. அளவுரு திறனுள்ள நுண்ணிய அமைப்பு (PEFT)

PEFT முறைகள் குறைந்த அளவிலான அளவுருக்களை மட்டுமே புதுப்பிக்கின்றன, இது செயல்முறையை மேலும் திறனாக மாற்றுகிறது:

#### Low-Rank Adaptation (LoRA)
- உள்ளடக்க எடைகளுக்கு சிறிய பயிற்சி செய்யக்கூடிய தரவரிசை சிதைவுக் கோடுகளைச் சேர்க்கிறது
- பயிற்சி செய்யக்கூடிய அளவுருக்களின் எண்ணிக்கையை கணிசமாகக் குறைக்கிறது
- முழுமையான நுண்ணிய அமைப்புக்கு நெருக்கமான செயல்திறனை தக்கவைத்துக்கொள்கிறது
- பல்வேறு மாற்றங்களை எளிதாக மாற்றுவதற்கு அனுமதிக்கிறது

#### QLoRA (Quantized LoRA)
- LoRA-வை அளவீட்டு தொழில்நுட்பங்களுடன் இணைக்கிறது
- நினைவக தேவைகளை மேலும் குறைக்கிறது
- பயனர் தரவுத்தொகுதியில் பெரிய மாதிரிகளை நுண்ணிய அமைப்புக்கு அனுமதிக்கிறது
- திறன் மற்றும் செயல்திறனுக்கு இடையிலான சமநிலையை வழங்குகிறது

#### Adapters
- உள்ளடக்க அடுக்குகளுக்கு இடையில் சிறிய நரம்பியல் வலையமைப்புகளைச் சேர்க்கிறது
- அடிப்படை மாதிரியை உறைந்த நிலையில் வைத்துக்கொண்டு இலக்கை நோக்கி நுண்ணிய அமைப்பை அனுமதிக்கிறது
- மாதிரி தனிப்பயனாக்கத்திற்கு தொகுதி அணுகுமுறையை வழங்குகிறது

### 3. பணிக்கேற்ப நுண்ணிய அமைப்பு

கீழ்வரும் பணிகளுக்கான மாதிரிகளை மாற்றுவதில் கவனம் செலுத்துகிறது:
- **வகைப்படுத்தல்**: வகைப்படுத்தல் பணிகளுக்கான மாதிரிகளை சரிசெய்தல்
- **உருவாக்கம்**: உள்ளடக்க உருவாக்கம் மற்றும் உர உருவாக்கத்திற்கான மாதிரிகளை மேம்படுத்துதல்
- **தொகுப்பு**: தகவல் தொகுப்பு மற்றும் பெயரிடப்பட்ட பொருள் அடையாளத்திற்கான நுண்ணிய அமைப்பு
- **சுருக்கம்**: ஆவண சுருக்கத்திற்கான மாதிரிகளை சிறப்பாக்குதல்

## Microsoft Olive உடன் நுண்ணிய அமைப்பு

Microsoft Olive என்பது மாதிரி மேம்பாட்டு கருவிகளின் முழுமையான தொகுப்பாகும், இது நுண்ணிய அமைப்பு செயல்முறையை எளிமைப்படுத்தி, நிறுவன தரத்திலான அம்சங்களை வழங்குகிறது.

### Microsoft Olive என்றால் என்ன?

Microsoft Olive என்பது ஒரு திறந்த மூல மாதிரி மேம்பாட்டு கருவியாகும், இது:
- பல்வேறு ஹார்ட்வேருக்கு இலக்காக நுண்ணிய அமைப்பு வேலைப்பாடுகளை எளிமைப்படுத்துகிறது
- பிரபலமான மாதிரி கட்டமைப்புகளுக்கான உள்ளடக்க ஆதரவை வழங்குகிறது (Llama, Phi, Qwen, Gemma)
- மேக மற்றும் உள்ளூர் இடமாற்று விருப்பங்களை வழங்குகிறது
- Azure ML மற்றும் பிற Microsoft AI சேவைகளுடன் எளிதாக ஒருங்கிணைக்கிறது
- தானியங்கி மேம்பாடு மற்றும் அளவீட்டுக்கு ஆதரவு வழங்குகிறது

### முக்கிய அம்சங்கள்

- **ஹார்ட்வேரை நோக்கி மேம்பாடு**: குறிப்பிட்ட ஹார்ட்வேருக்கான மாதிரிகளை தானாகவே மேம்படுத்துகிறது (CPU, GPU, NPU)
- **பல வடிவமைப்பு ஆதரவு**: PyTorch, Hugging Face, மற்றும் ONNX மாதிரிகளுடன் வேலை செய்கிறது
- **தானியக்க வேலைப்பாடுகள்**: கையேடு அமைப்பு மற்றும் முயற்சி-தவறுகளை குறைக்கிறது
- **நிறுவன ஒருங்கிணைப்பு**: Azure ML மற்றும் மேக இடமாற்றுகளுக்கான உள்ளடக்க ஆதரவு
- **விரிவாக்கக்கூடிய கட்டமைப்பு**: தனிப்பயன் மேம்பாட்டு தொழில்நுட்பங்களை அனுமதிக்கிறது

### நிறுவல் மற்றும் அமைப்பு

#### அடிப்படை நிறுவல்

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### விருப்ப சார்ந்த சார்புகள்

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### நிறுவலை சரிபார்க்கவும்

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## கைமுறையாக செய்யும் உதாரணங்கள்

### உதாரணம் 1: Olive CLI உடன் அடிப்படை நுண்ணிய அமைப்பு

இந்த உதாரணம் ஒரு சிறிய மொழி மாதிரியை சொற்றொடர் வகைப்படுத்தலுக்காக நுண்ணிய அமைப்பை விளக்குகிறது:

#### படி 1: உங்கள் சூழலை தயாரிக்கவும்

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### படி 2: மாதிரியை நுண்ணிய அமைக்கவும்

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### படி 3: இடமாற்றுக்கான மேம்பாடு செய்யவும்

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### உதாரணம் 2: தனிப்பயன் தரவுத்தொகுப்புடன் மேம்பட்ட அமைப்பு

#### படி 1: தனிப்பயன் தரவுத்தொகுப்பை தயாரிக்கவும்

உங்கள் பயிற்சி தரவுடன் JSON கோப்பை உருவாக்கவும்:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### படி 2: கட்டமைப்பு கோப்பை உருவாக்கவும்

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### படி 3: நுண்ணிய அமைப்பை செயல்படுத்தவும்

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### உதாரணம் 3: நினைவக திறனுக்கான QLoRA நுண்ணிய அமைப்பு

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## சிறந்த நடைமுறைகள் மற்றும் வழிகாட்டுதல்கள்

### தரவுத் தயாரிப்பு

**1. தரவின் தரம் முக்கியம்**
- குறைந்த தரவின் பெரிய அளவுகளை விட, உயர்தர, பல்வகைமையான உதாரணங்களை முன்னுரிமை கொடுக்கவும்
- உங்கள் இலக்கு பயன்பாட்டை பிரதிநிதித்துவம் செய்யும் தரவை உறுதிப்படுத்தவும்
- தரவை சீராக சுத்தம் செய்து முன்கூட்டியே செயல்படுத்தவும்

**2. தரவின் வடிவமைப்பு மற்றும் வார்ப்புருக்கள்**
- அனைத்து பயிற்சி உதாரணங்களிலும் சீரான வடிவமைப்பைப் பயன்படுத்தவும்
- உங்கள் பயன்பாட்டை பொருத்தும் தெளிவான உள்ளீடு-வெளியீட்டு வார்ப்புருக்களை உருவாக்கவும்
- Instruction-tuned மாதிரிகளுக்கு பொருத்தமான வழிகாட்டுதலைச் சேர்க்கவும்

**3. தரவுத்தொகுப்பு பிரிப்பு**
- 10-20% தரவை சரிபார்ப்புக்காக ஒதுக்கவும்
- பயிற்சி/சரிபார்ப்பு பிரிப்புகளில் ஒரே மாதிரியான விநியோகங்களை பராமரிக்கவும்
- வகைப்படுத்தல் பணிகளுக்கு சீரமைக்கப்பட்ட மாதிரியைப் பரிசீலிக்கவும்

### பயிற்சி அமைப்பு

**1. கற்றல் வீதத்தைத் தேர்வு செய்யவும்**
- நுண்ணிய அமைப்புக்கான சிறிய கற்றல் வீதங்களுடன் (1e-5 முதல் 1e-4 வரை) தொடங்கவும்
- சிறந்த இணைச்சலுக்காக கற்றல் வீத அட்டவணையைப் பயன்படுத்தவும்
- இழப்புக் கோடுகளை கண்காணித்து வீதங்களை சரிசெய்யவும்

**2. தொகுதி அளவின் மேம்பாடு**
- கிடைக்கும் நினைவகத்துடன் தொகுதி அளவை சமநிலைப்படுத்தவும்
- பெரிய செயல்திறன் தொகுதி அளவுகளுக்கு சாய்வு சேர்க்கையைப் பயன்படுத்தவும்
- தொகுதி அளவு மற்றும் கற்றல் வீதத்திற்கிடையிலான உறவைப் பரிசீலிக்கவும்

**3. பயிற்சி காலம்**
- சரிபார்ப்பு அளவுகோல்களை கண்காணித்து overfitting-ஐ தவிர்க்கவும்
- சரிபார்ப்பு செயல்திறன் சமநிலைப்படுத்தும் போது ஆரம்ப நிறுத்தத்தைப் பயன்படுத்தவும்
- மீட்பு மற்றும் பகுப்பாய்வுக்காக அடுக்குகளை அடிக்கடி சேமிக்கவும்

### மாதிரி தேர்வு

**1. அடிப்படை மாதிரி தேர்வு**
- சாத்தியமான போது ஒரே துறையில் முன்பயிற்சி செய்யப்பட்ட மாதிரிகளைத் தேர்ந்தெடுக்கவும்
- உங்கள் கணினி கட்டுப்பாடுகளுக்கு ஒப்பான மாதிரி அளவைக் கருத்தில் கொள்ளவும்
- வணிக பயன்பாட்டுக்கான உரிமம் தேவைகளை மதிப்பீடு செய்யவும்

**2. நுண்ணிய அமைப்பு முறையின் தேர்வு**
- வளக் குறைபாடுள்ள சூழல்களுக்கு LoRA/QLoRA-ஐப் பயன்படுத்தவும்
- அதிகபட்ச செயல்திறன் முக்கியமான போது முழுமையான நுண்ணிய அமைப்பைத் தேர்ந்தெடுக்கவும்
- பல பணிகளுக்கான Adapter அடிப்படையிலான அணுகுமுறைகளைப் பரிசீலிக்கவும்

### வள மேலாண்மை

**1. ஹார்ட்வேர மேம்பாடு**
- உங்கள் மாதிரி அளவு மற்றும் முறைக்கு பொருத்தமான ஹார்ட்வேரைத் தேர்ந்தெடுக்கவும்
- சாய்வு சோதனைக்கான GPU நினைவகத்தை திறமையாக பயன்படுத்தவும்
- பெரிய மாதிரிகளுக்கு மேக அடிப்படையிலான தீர்வுகளைப் பரிசீலிக்கவும்

**2. நினைவக மேலாண்மை**
- கிடைக்கும் போது கலந்த துல்லிய பயிற்சியைப் பயன்படுத்தவும்
- நினைவகக் கட்டுப்பாடுகளுக்கு சாய்வு சேர்க்கையைச் செயல்படுத்தவும்
- பயிற்சியின் முழு காலத்தில் GPU நினைவக பயன்பாட்டை கண்காணிக்கவும்

## மேம்பட்ட தொழில்நுட்பங்கள்

### பல Adapter பயிற்சி

அடிப்படை மாதிரியைப் பகிர்ந்து கொண்டு பல Adapter-களைப் பயிற்சி செய்யவும்:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparameter மேம்பாடு

முறைமையான Hyperparameter அமைப்பைச் செயல்படுத்தவும்:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### தனிப்பயன் இழப்பு செயல்பாடுகள்

துறைக்கேற்ப இழப்பு செயல்பாடுகளைச் செயல்படுத்தவும்:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## மதிப்பீடு மற்றும் கண்காணிப்பு

### அளவுகோல்கள் மற்றும் மதிப்பீடு

**1. நிலையான அளவுகோல்கள்**
- **துல்லியம்**: வகைப்படுத்தல் பணிகளுக்கான மொத்த சரியானது
- **Perplexity**: மொழி மாதிரி தரத்தை அளவிடும் அளவுகோல்
- **BLEU/ROUGE**: உர உருவாக்கம் மற்றும் சுருக்கம் தரத்தை அளவிடும் அளவுகோல்கள்
- **F1 Score**: வகைப்படுத்தலுக்கான சமநிலை துல்லியம் மற்றும் மீட்பு

**2. துறைக்கேற்ப அளவுகோல்கள்**
- **பணிக்கேற்ப தரவுத்தொகுப்புகள்**: உங்கள் துறைக்கேற்ப நிறுவப்பட்ட தரவுத்தொகுப்புகளைப் பயன்படுத்தவும்
- **மனித மதிப்பீடு**: கருத்து சார்ந்த பணிகளுக்கு மனித மதிப்பீட்டைச் சேர்க்கவும்
- **வணிக அளவுகோல்கள்**: உண்மையான வணிக இலக்குகளுடன் ஒத்துப்போகவும்

**3. மதிப்பீட்டு அமைப்பு**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### பயிற்சி முன்னேற்றத்தை கண்காணித்தல்

**1. இழப்பு கண்காணிப்பு**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. சரிபார்ப்பு கண்காணிப்பு**
- பயிற்சி இழப்புடன் சரிபார்ப்பு இழப்பை கண்காணிக்கவும்
- overfitting அறிகுறிகளை கண்காணிக்கவும் (பயிற்சி இழப்பு குறையும்போது சரிபார்ப்பு இழப்பு அதிகரிக்கிறது)
- சரிபார்ப்பு அளவுகோல்களை அடிப்படையாகக் கொண்டு ஆரம்ப நிறுத்தத்தைப் பயன்படுத்தவும்

**3. வள கண்காணிப்பு**
- GPU/CPU பயன்பாட்டை கண்காணிக்கவும்
- நினைவக பயன்பாட்டின் முறைமைகளை கண்காணிக்கவும்
- பயிற்சி வேகம் மற்றும் திறனைக் கண்காணிக்கவும்

## பொதுவான சவால்கள் மற்றும் தீர்வுகள்

### சவால் 1: Overfitting

**அறிகுறிகள்:**
- பயிற்சி இழப்பு தொடர்ந்து குறைகிறது, ஆனால் சரிபார்ப்பு இழப்பு அதிகரிக்கிறது
- பயிற்சி மற்றும் சரிபார்ப்பு செயல்திறனுக்கு இடையிலான பெரிய இடைவெளி
- புதிய தரவுக்கு மோசமான பொதுமைப்படுத்தல்

**தீர்வுகள்:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### சவால் 2: நினைவகக் கட்டுப்பாடுகள்

**தீர்வுகள்:**
- சாய்வு சோதனைக்கான சாய்வு சோதனைக்கான சாய்வு சேர்க்கையைச் செயல்படுத்தவும்
- நினைவகக் கட்டுப்பாடுகளுக்கு சாய்வு சேர்க்கையைச் செயல்படுத்தவும்
- LoRA, QLoRA

---

**அறிவிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் சொந்த மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்களுக்கும் அல்லது தவறான விளக்கங்களுக்கும் நாங்கள் பொறுப்பல்ல.