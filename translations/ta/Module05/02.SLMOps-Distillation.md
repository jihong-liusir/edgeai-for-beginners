<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "00583bdd288194f0c4e7d71363e4c48a",
  "translation_date": "2025-10-11T11:22:38+00:00",
  "source_file": "Module05/02.SLMOps-Distillation.md",
  "language_code": "ta"
}
-->
# பகுதி 2: மாடல் சுருக்கம் - கோட்பாட்டிலிருந்து நடைமுறைக்கு

## உள்ளடக்க அட்டவணை
1. [மாடல் சுருக்கத்தின் அறிமுகம்](../../../Module05)
2. [சுருக்கம் ஏன் முக்கியம்](../../../Module05)
3. [சுருக்க செயல்முறை](../../../Module05)
4. [நடைமுறை செயல்படுத்தல்](../../../Module05)
5. [Azure ML சுருக்க உதாரணம்](../../../Module05)
6. [சிறந்த நடைமுறைகள் மற்றும் மேம்பாடு](../../../Module05)
7. [உலகளாவிய பயன்பாடுகள்](../../../Module05)
8. [தீர்மானம்](../../../Module05)

## மாடல் சுருக்கத்தின் அறிமுகம் {#introduction}

மாடல் சுருக்கம் என்பது சிறிய, திறன் வாய்ந்த மாடல்களை உருவாக்க உதவும் ஒரு சக்திவாய்ந்த தொழில்நுட்பமாகும், இது பெரிய, சிக்கலான மாடல்களின் செயல்திறனை பெரும்பாலும் பாதுகாக்கிறது. இந்த செயல்முறை ஒரு "ஆசிரியர்" மாடலின் நடத்தைப் பின்பற்ற ஒரு "மாணவர்" மாடலைப் பயிற்றுவிக்கிறது.

**முக்கிய நன்மைகள்:**
- **கணினி வள தேவைகள் குறைவு** தீர்மானத்திற்கு
- **குறைந்த நினைவக பயன்பாடு** மற்றும் சேமிப்பு தேவைகள்
- **வேகமான தீர்மான நேரங்கள்** சுமுகமான துல்லியத்துடன்
- **செலவுச்செலுத்தல் திறன்** வளக் குறைந்த சூழல்களில்

## சுருக்கம் ஏன் முக்கியம் {#why-distillation-matters}

பெரிய மொழி மாடல்கள் (LLMs) அதிக சக்திவாய்ந்ததாக மாறி வருகின்றன, ஆனால் அதிக வளங்களை தேவைப்படுத்துகின்றன. பில்லியன் அளவிலான அளவீடுகளைக் கொண்ட ஒரு மாடல் சிறந்த முடிவுகளை வழங்கினாலும், பல உலகளாவிய பயன்பாடுகளுக்கு இது நடைமுறையில் சிக்கலாக இருக்கலாம்:

### வளக் கட்டுப்பாடுகள்
- **கணினி சுமை**: பெரிய மாடல்கள் அதிக GPU நினைவகத்தையும் செயலாக்க சக்தியையும் தேவைப்படுத்துகின்றன
- **தீர்மான தாமதம்**: சிக்கலான மாடல்கள் பதில்களை உருவாக்க அதிக நேரம் எடுக்கின்றன
- **ஆற்றல் பயன்பாடு**: பெரிய மாடல்கள் அதிக மின்சாரத்தை பயன்படுத்தி செயல்பாட்டு செலவுகளை அதிகரிக்கின்றன
- **அமைப்பு செலவுகள்**: பெரிய மாடல்களை ஹோஸ்ட் செய்ய விலை உயர்ந்த ஹார்ட்வேரை தேவைப்படுத்துகின்றன

### நடைமுறை வரையறைகள்
- **மொபைல் பயன்பாடு**: பெரிய மாடல்கள் மொபைல் சாதனங்களில் திறமையாக இயங்க முடியாது
- **நேரடி பயன்பாடுகள்**: குறைந்த தாமதத்தை தேவைப்படுத்தும் பயன்பாடுகள் மெதுவான தீர்மானத்தை ஏற்க முடியாது
- **எட்ஜ் கணினி**: IoT மற்றும் எட்ஜ் சாதனங்கள் குறைந்த கணினி வளங்களை கொண்டுள்ளன
- **செலவுக் கருத்துகள்**: பல நிறுவனங்கள் பெரிய மாடல் பயன்பாட்டிற்கான அமைப்பை ஏற்க முடியாது

## சுருக்க செயல்முறை {#the-distillation-process}

மாடல் சுருக்கம் இரண்டு நிலை செயல்முறையை பின்பற்றுகிறது, இது ஆசிரியர் மாடலிலிருந்து மாணவர் மாடலுக்கு அறிவை மாற்றுகிறது:

### நிலை 1: செயற்கை தரவுத் தயாரிப்பு

ஆசிரியர் மாடல் உங்கள் பயிற்சி தரவுத்தொகுப்புக்கு பதில்களை உருவாக்குகிறது, இது ஆசிரியரின் அறிவு மற்றும் காரணமுடைய முறைகளைப் பதிவு செய்யும் உயர்தர செயற்கை தரவுகளை உருவாக்குகிறது.

```python
# Conceptual example of synthetic data generation
def generate_synthetic_data(teacher_model, training_dataset):
    synthetic_data = []
    for input_sample in training_dataset:
        teacher_response = teacher_model.generate(input_sample)
        synthetic_data.append({
            'input': input_sample,
            'teacher_output': teacher_response
        })
    return synthetic_data
```

**இந்த நிலையின் முக்கிய அம்சங்கள்:**
- ஆசிரியர் மாடல் ஒவ்வொரு பயிற்சி எடுத்துக்காட்டையும் செயல்படுத்துகிறது
- உருவாக்கப்பட்ட பதில்கள் மாணவர் பயிற்சிக்கான "உண்மையான தரவாக" மாறுகின்றன
- இந்த செயல்முறை ஆசிரியரின் முடிவெடுக்கும் முறைகளைப் பதிவு செய்கிறது
- செயற்கை தரவின் தரம் மாணவர் மாடலின் செயல்திறனை நேரடியாக பாதிக்கிறது

### நிலை 2: மாணவர் மாடல் நுணுக்கம்

மாணவர் மாடல் செயற்கை தரவுத்தொகுப்பில் பயிற்சியளிக்கப்படுகிறது, இது ஆசிரியரின் நடத்தை மற்றும் பதில்களைப் பின்பற்ற கற்றுக்கொள்கிறது.

```python
# Conceptual example of student training
def train_student_model(student_model, synthetic_data):
    for epoch in range(num_epochs):
        for batch in synthetic_data:
            student_output = student_model(batch['input'])
            loss = compute_loss(student_output, batch['teacher_output'])
            optimizer.step(loss.backward())
    return student_model
```

**பயிற்சி நோக்கங்கள்:**
- மாணவர் மற்றும் ஆசிரியர் வெளியீடுகளுக்கிடையிலான வேறுபாட்டை குறைக்க
- குறைந்த அளவீடுகளில் ஆசிரியரின் அறிவை பாதுகாக்க
- மாடல் சிக்கலினை குறைத்து செயல்திறனை பராமரிக்க

## நடைமுறை செயல்படுத்தல் {#practical-implementation}

### ஆசிரியர் மற்றும் மாணவர் மாடல்களைத் தேர்ந்தெடுப்பது

**ஆசிரியர் மாடல் தேர்வு:**
- உங்கள் குறிப்பிட்ட பணியில் நிரூபிக்கப்பட்ட செயல்திறனுடன் பெரிய அளவிலான LLMகளைத் தேர்ந்தெடுக்கவும் (100B+ அளவீடுகள்)
- பிரபலமான ஆசிரியர் மாடல்கள்:
  - **DeepSeek V3** (671B அளவீடுகள்) - காரணம் மற்றும் குறியீடு உருவாக்கத்திற்கு சிறந்தது
  - **Meta Llama 3.1 405B Instruct** - விரிவான பொதுப் பயன்பாட்டு திறன்கள்
  - **GPT-4** - பல்வேறு பணிகளில் வலுவான செயல்திறன்
  - **Claude 3.5 Sonnet** - சிக்கலான காரணமுடைய பணிகளுக்கு சிறந்தது
- உங்கள் துறைக்கு உரிய தரவுகளில் ஆசிரியர் மாடல் சிறப்பாக செயல்படுவதை உறுதிப்படுத்தவும்

**மாணவர் மாடல் தேர்வு:**
- மாடல் அளவு மற்றும் செயல்திறன் தேவைகளுக்கு இடையிலான சமநிலையைப் பராமரிக்க
- திறமையான, சிறிய மாடல்களை மையமாகக் கொண்டது:
  - **Microsoft Phi-4-mini** - காரணமுடைய திறன்களுடன் சமீபத்திய திறமையான மாடல்
  - Meta Llama 3.1 8B Instruct
  - Microsoft Phi-3 Mini (4K மற்றும் 128K மாறுபாடுகள்)
  - Microsoft Phi-3.5 Mini Instruct

### செயல்படுத்தல் படிகள்

1. **தரவு தயாரிப்பு**
   ```python
   # Prepare your training dataset
   training_data = load_dataset("your_training_data.jsonl")
   validation_data = load_dataset("your_validation_data.jsonl")
   ```

2. **ஆசிரியர் மாடல் அமைப்பு**
   ```python
   # Initialize large-scale teacher model (100B+ parameters)
   teacher_model = load_model("deepseek-ai/DeepSeek-V3")
   # Alternative: teacher_model = load_model("meta-llama/Llama-3.1-405B-Instruct")
   ```

3. **செயற்கை தரவுத் தயாரிப்பு**
   ```python
   # Generate responses from teacher model
   synthetic_training_data = generate_teacher_responses(
       teacher_model, 
       training_data
   )
   synthetic_validation_data = generate_teacher_responses(
       teacher_model, 
       validation_data
   )
   ```

4. **மாணவர் மாடல் பயிற்சி**
   ```python
   # Fine-tune Phi-4-mini as student model
   student_model = load_model("microsoft/Phi-4-mini")
   trained_student = fine_tune_student(
       student_model,
       synthetic_training_data,
       synthetic_validation_data
   )
   ```


## Azure ML சுருக்க உதாரணம் {#azure-ml-example}

Azure Machine Learning மாடல் சுருக்கத்தை செயல்படுத்துவதற்கான முழுமையான தளத்தை வழங்குகிறது. உங்கள் சுருக்க வேலைப்பாடுகளுக்கு Azure ML ஐ எவ்வாறு பயன்படுத்துவது என்பதை இங்கே காணலாம்:

### முன்பதிவுகள்

1. **Azure ML Workspace**: உங்கள் வேலைப்பகுதியை சரியான பிராந்தியத்தில் அமைக்கவும்
   - பெரிய அளவிலான ஆசிரியர் மாடல்களுக்கு அணுகலை உறுதிப்படுத்தவும் (DeepSeek V3, Llama 405B)
   - மாடல் கிடைக்கும் பிராந்தியங்களைப் பொறுத்து அமைக்கவும்

2. **கணினி வளங்கள்**: பயிற்சிக்கான சரியான கணினி நிகழ்வுகளை அமைக்கவும்
   - ஆசிரியர் மாடல் தீர்மானத்திற்கு உயர் நினைவக நிகழ்வுகள்
   - மாணவர் மாடல் நுணுக்கத்திற்கான GPU-இயக்கப்பட்ட கணினி

### ஆதரவு பணியின் வகைகள்

Azure ML பல்வேறு பணிகளுக்கான சுருக்கத்தை ஆதரிக்கிறது:

- **இயற்கை மொழி விளக்கம் (NLI)**
- **உரையாடல் AI**
- **கேள்வி மற்றும் பதில் (QA)**
- **கணித காரணம்**
- **உரை சுருக்கம்**

### மாதிரி செயல்படுத்தல்

```python
from azure.ai.ml import MLClient
from azure.ai.ml.entities import DistillationJob

# Initialize Azure ML client
ml_client = MLClient.from_config()

# Define distillation job with DeepSeek V3 as teacher and Phi-4-mini as student
distillation_job = DistillationJob(
    teacher_model="deepseek-v3",  # Large-scale teacher model (671B parameters)
    student_model="phi-4-mini",   # Efficient student model
    training_data="./training_data.jsonl",
    validation_data="./validation_data.jsonl",
    task_type="conversation",
    hyperparameters={
        "learning_rate": 2e-5,    # Lower learning rate for fine-tuning
        "batch_size": 2,          # Smaller batch size for memory efficiency
        "num_epochs": 3,
        "temperature": 0.7        # Teacher output softness
    }
)

# Submit distillation job
job = ml_client.jobs.create_or_update(distillation_job)
```

### கண்காணிப்பு மற்றும் மதிப்பீடு

```python
# Monitor training progress
job_status = ml_client.jobs.get(job.name)
print(f"Job status: {job_status.status}")

# Evaluate distilled Phi-4-mini model
evaluation_results = ml_client.models.evaluate(
    model_name="phi-4-mini-distilled",
    test_data="./test_data.jsonl",
    metrics=["accuracy", "bleu_score", "inference_time"]
)

# Compare with original Phi-4-mini baseline
baseline_results = ml_client.models.evaluate(
    model_name="phi-4-mini-baseline",
    test_data="./test_data.jsonl"
)

print(f"Distilled model accuracy: {evaluation_results['accuracy']}")
print(f"Baseline model accuracy: {baseline_results['accuracy']}")
print(f"Performance improvement: {evaluation_results['accuracy'] - baseline_results['accuracy']}")
```


## சிறந்த நடைமுறைகள் மற்றும் மேம்பாடு {#best-practices}

### தரவின் தரம்

**உயர் தரமான பயிற்சி தரவுகள் முக்கியம்:**
- பல்வகை மற்றும் பிரதிநிதித்துவமான பயிற்சி எடுத்துக்காட்டுகளை உறுதிப்படுத்தவும்
- துறைக்கு உரிய தரவுகளை பயன்படுத்தவும்
- ஆசிரியர் மாடல் வெளியீடுகளை மாணவர் பயிற்சிக்கு பயன்படுத்துவதற்கு முன் சரிபார்க்கவும்
- மாணவர் மாடல் கற்றலில் பாகுபாட்டைத் தவிர்க்க தரவுத்தொகுப்பை சமநிலைப்படுத்தவும்

### ஹைப்பர்பாராமீட்டர் அமைத்தல்

**மேம்படுத்த வேண்டிய முக்கிய அளவீடுகள்:**
- **கற்றல் வீதம்**: நுணுக்கத்திற்கான சிறிய வீதங்களுடன் தொடங்கவும் (1e-5 முதல் 5e-5 வரை)
- **தொகுப்பு அளவு**: நினைவக வரையறைகள் மற்றும் பயிற்சி நிலைத்தன்மைக்கு இடையிலான சமநிலையைப் பராமரிக்க
- **எபோக்களின் எண்ணிக்கை**: அதிக பயிற்சியை கண்காணிக்கவும்; பொதுவாக 2-5 எபோக்கள் போதுமானவை
- **வெப்பநிலை அளவீடு**: சிறந்த அறிவு மாற்றத்திற்காக ஆசிரியர் வெளியீட்டு மென்மையை சரிசெய்யவும்

### மாடல் கட்டமைப்பு கருத்துகள்

**ஆசிரியர்-மாணவர் இணக்கத்தன்மை:**
- ஆசிரியர் மற்றும் மாணவர் மாடல்களுக்கு இடையிலான கட்டமைப்பு இணக்கத்தன்மையை உறுதிப்படுத்தவும்
- சிறந்த அறிவு மாற்றத்திற்காக இடைநிலை அடுக்கு பொருத்தத்தைப் பரிசீலிக்கவும்
- பொருத்தம் மாற்று தொழில்நுட்பங்களைப் பயன்படுத்தவும்

### மதிப்பீட்டு உத்திகள்

**விரிவான மதிப்பீட்டு அணுகுமுறை:**
```python
# Multi-metric evaluation
evaluation_metrics = {
    'accuracy': evaluate_accuracy(student_model, test_data),
    'latency': measure_inference_time(student_model),
    'memory_usage': profile_memory_consumption(student_model),
    'task_specific_metrics': evaluate_task_performance(student_model, task_data)
}
```


## உலகளாவிய பயன்பாடுகள் {#real-world-applications}

### மொபைல் மற்றும் எட்ஜ் பயன்பாடு

சுருக்கப்பட்ட மாடல்கள் வளக் குறைந்த சாதனங்களில் AI திறன்களை இயக்குகின்றன:
- **ஸ்மார்ட்போன் பயன்பாடுகள்** நேரடி உரை செயலாக்கத்துடன்
- **IoT சாதனங்கள்** உள்ளூர் தீர்மானத்தை செயல்படுத்தும்
- **உட்பொதிக்கப்பட்ட அமைப்புகள்** குறைந்த கணினி வளங்களுடன்

### செலவுச்செலுத்தல் உற்பத்தி அமைப்புகள்

சுருக்கத்தை நிறுவனங்கள் செயல்பாட்டு செலவுகளை குறைக்க பயன்படுத்துகின்றன:
- **வாடிக்கையாளர் சேவை சாட்பாட்கள்** வேகமான பதிலளிப்பு நேரங்களுடன்
- **உள்ளடக்க கண்காணிப்பு அமைப்புகள்** அதிக அளவுகளை திறமையாக செயல்படுத்தும்
- **நேரடி மொழிபெயர்ப்பு சேவைகள்** குறைந்த தாமத தேவைகளுடன்

### துறைக்கு உரிய பயன்பாடுகள்

சுருக்கம் சிறப்பு மாடல்களை உருவாக்க உதவுகிறது:
- **மருத்துவ நோயறிதல் உதவி** தனியுரிமையைப் பாதுகாக்கும் உள்ளூர் தீர்மானத்துடன்
- **சட்ட ஆவண பகுப்பாய்வு** குறிப்பிட்ட சட்ட துறைகளுக்கு மேம்படுத்தப்பட்டது
- **நிதி அபாய மதிப்பீடு** வேகமான முடிவெடுக்கும் திறன்களுடன்

### வழக்குக் கதை: DeepSeek V3 → Phi-4-mini மூலம் வாடிக்கையாளர் ஆதரவு

ஒரு தொழில்நுட்ப நிறுவனம் தங்களின் வாடிக்கையாளர் ஆதரவு அமைப்பிற்காக சுருக்கத்தை செயல்படுத்தியது:

**செயல்படுத்தல் விவரங்கள்:**
- **ஆசிரியர் மாடல்**: DeepSeek V3 (671B அளவீடுகள்) - சிக்கலான வாடிக்கையாளர் கேள்விகளுக்கு சிறந்த காரணம்
- **மாணவர் மாடல்**: Phi-4-mini - வேகமான தீர்மானம் மற்றும் பயன்பாட்டிற்காக மேம்படுத்தப்பட்டது
- **பயிற்சி தரவுகள்**: 50,000 வாடிக்கையாளர் ஆதரவு உரையாடல்கள்
- **பணி**: பல முறை உரையாடல் ஆதரவு தொழில்நுட்ப பிரச்சினைகளைத் தீர்க்க

**செயல்திறன் முடிவுகள்:**
- **85% குறைவு** தீர்மான நேரத்தில் (3.2s இருந்து 0.48s வரை பதிலுக்கு)
- **95% குறைவு** நினைவக தேவைகளில் (1.2TB இருந்து 60GB வரை)
- **92% துல்லியத்தை பாதுகாத்தல்** ஆதரவு பணிகளில்
- **60% செலவுகள் குறைவு**
- **மேம்பட்ட அளவீடு** - தற்போது 10 மடங்கு அதிகமான ஒரே நேரத்தில் பயனர்களை கையாள முடியும்

**செயல்திறன் பகுப்பாய்வு:**
```python
# Comparison metrics
performance_comparison = {
    "DeepSeek V3 (Teacher)": {
        "parameters": "671B",
        "memory_usage": "1.2TB",
        "inference_time": "3.2s",
        "accuracy": "94.5%",
        "throughput": "50 queries/hour"
    },
    "Phi-4-mini (Distilled)": {
        "parameters": "14B",
        "memory_usage": "60GB", 
        "inference_time": "0.48s",
        "accuracy": "87.0%",
        "throughput": "500 queries/hour"
    }
}
```


## தீர்மானம் {#conclusion}

மாடல் சுருக்கம் மேம்பட்ட AI திறன்களை அனைவருக்கும் அணுகக்கூடியதாக மாற்றுவதற்கான முக்கிய தொழில்நுட்பமாகும். பெரிய மாடல்களின் செயல்திறனை பெரும்பாலும் பாதுகாக்கும் சிறிய, திறமையான மாடல்களை உருவாக்குவதன் மூலம், சுருக்கம் நடைமுறை AI பயன்பாட்டிற்கான வளர்ந்த தேவையைத் தீர்க்கிறது.

### முக்கிய எடுத்துக்காட்டுகள்

1. **சுருக்கம் இடைவெளியை நிரப்புகிறது** மாடல் செயல்திறன் மற்றும் நடைமுறை வரையறைகளுக்கு இடையில்
2. **இரு நிலை செயல்முறை** ஆசிரியரிலிருந்து மாணவருக்கு அறிவு மாற்றத்தை உறுதிப்படுத்துகிறது
3. **Azure ML வலுவான அமைப்பை வழங்குகிறது** சுருக்க வேலைப்பாடுகளை செயல்படுத்த
4. **சரியான மதிப்பீடு மற்றும் மேம்பாடு** வெற்றிகரமான சுருக்கத்திற்குத் தேவையானவை
5. **உலகளாவிய பயன்பாடுகள்** செலவு, வேகம் மற்றும் அணுகுமுறை ஆகியவற்றில் முக்கிய நன்மைகளை காட்டுகின்றன

### எதிர்கால திசைகள்

இந்த துறை தொடர்ந்து வளரும்போது, நாம் எதிர்பார்க்கலாம்:
- **மேம்பட்ட சுருக்க தொழில்நுட்பங்கள்** சிறந்த அறிவு மாற்ற முறைகளுடன்
- **பல ஆசிரியர் சுருக்கம்** மேம்பட்ட மாணவர் மாடல் திறன்களுக்காக
- **தானியங்கி மேம்பாடு** சுருக்க செயல்முறையின்
- **பெரிய மாடல் ஆதரவு** பல்வேறு கட்டமைப்புகள் மற்றும் துறைகளுக்கு

மாடல் சுருக்கம் நிறுவனங்களுக்கு மேம்பட்ட மொழி மாடல் திறன்களை வளக் குறைந்த சூழல்களில் பயன்படுத்த உதவுகிறது, இது பல்வேறு பயன்பாடுகள் மற்றும் சூழல்களில் மேம்பட்ட AI திறன்களை அணுகக்கூடியதாக மாற்றுகிறது.

## ➡️ அடுத்தது என்ன

- [03: நுணுக்கம் - குறிப்பிட்ட பணிகளுக்கான மாடல்களை தனிப்பயனாக்குதல்](./03.SLMOps-Finetuing.md)

---

**அறிவிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் சொந்த மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்களுக்கும் அல்லது தவறான விளக்கங்களுக்கும் நாங்கள் பொறுப்பல்ல.