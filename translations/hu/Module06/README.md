<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-18T16:31:08+00:00",
  "source_file": "Module06/README.md",
  "language_code": "hu"
}
-->
# 6. fejezet: SLM Agentikus Rendszerek: Átfogó Áttekintés

A mesterséges intelligencia világa alapvető átalakuláson megy keresztül, ahogy az egyszerű chatbotoktól a Small Language Models (SLM) által működtetett kifinomult AI ügynökök felé haladunk. Ez az átfogó útmutató három kritikus aspektust vizsgál a modern SLM agentikus rendszerek kapcsán: az alapvető fogalmakat és telepítési stratégiákat, a funkcióhívási képességeket, valamint a forradalmi Model Context Protocol (MCP) integrációt.

## [1. szakasz: AI ügynökök és Small Language Models alapjai](./01.IntroduceAgent.md)

Az első szakasz megalapozza az AI ügynökök és Small Language Models alapvető megértését, és 2025-öt az AI ügynökök évének pozícionálja, követve a 2023-as chatbot korszakot és a 2024-es copilot fellendülést. Ez a szakasz bemutatja azokat az **agentikus AI rendszereket**, amelyek gondolkodnak, érvelnek, terveznek, eszközöket használnak, és minimális emberi beavatkozással hajtanak végre feladatokat.

### Főbb tárgyalt fogalmak:
- **Ügynökök osztályozási keretrendszere**: Az egyszerű reflex ügynököktől a tanuló ügynökökig, átfogó taxonómiát nyújtva különböző számítástechnikai forgatókönyvekhez
- **SLM alapok**: A Small Language Models meghatározása olyan modellekként, amelyek kevesebb mint 10 milliárd paraméterrel képesek gyakorlati következtetéseket végezni fogyasztói eszközökön
- **Fejlett optimalizálási stratégiák**: GGUF formátumú telepítés, kvantálási technikák (Q4_K_M, Q5_K_S, Q8_0), és élre optimalizált keretrendszerek, mint a Llama.cpp és az Apple MLX
- **SLM vs LLM kompromisszumok**: Bemutatva a 10-30× költségcsökkentést SLM-ekkel, miközben a tipikus ügynöki feladatok 70-80%-ának hatékonyságát megőrzik

A szakasz gyakorlati telepítési stratégiákkal zárul, mint az Ollama, VLLM és a Microsoft élre optimalizált megoldásai, amelyek az SLM-eket a költséghatékony, adatvédelmet biztosító agentikus AI telepítés jövőjévé teszik.

## [2. szakasz: Funkcióhívás Small Language Models-ben](./02.FunctionCalling.md)

A második szakasz mélyrehatóan foglalkozik a **funkcióhívási képességekkel**, azzal a mechanizmussal, amely a statikus nyelvi modelleket dinamikus AI ügynökökké alakítja, amelyek képesek valós interakciókra. Ez a technikai mélymerülés bemutatja a teljes munkafolyamatot az intent felismeréstől a válasz integrációig.

### Főbb megvalósítási területek:
- **Rendszeres munkafolyamat**: Eszközintegráció, funkciódefiníció, intent felismerés, JSON kimenet generálás és külső végrehajtás részletes bemutatása
- **Platform-specifikus megvalósítások**: Átfogó útmutatók Phi-4-mini Ollama-val, Qwen3 funkcióhívás, és Microsoft Foundry Local integráció kapcsán
- **Haladó példák**: Több ügynök együttműködési rendszerei, dinamikus eszközválasztás, és vállalati integrációs minták átfogó hibakezeléssel
- **Gyártási szempontok**: Sebességkorlátozás, naplózás, biztonsági intézkedések és teljesítményoptimalizálási stratégiák

Ez a szakasz elméleti megértést és gyakorlati megvalósítási mintákat kínál, lehetővé téve a fejlesztők számára, hogy robusztus funkcióhívási rendszereket építsenek, amelyek egyszerű API-hívásoktól komplex, több lépéses vállalati munkafolyamatokig mindent kezelni tudnak.

## [3. szakasz: Model Context Protocol (MCP) integráció](./03.IntroduceMCP.md)

Az utolsó szakasz bemutatja a **Model Context Protocol (MCP)**-t, egy forradalmi keretrendszert, amely szabványosítja, hogyan lépnek kapcsolatba a nyelvi modellek külső eszközökkel és rendszerekkel. Ez a szakasz bemutatja, hogyan hoz létre MCP egy hidat az AI modellek és a valós világ között jól definiált protokollokon keresztül.

### Integrációs kiemelések:
- **Protokoll architektúra**: Rétegezett rendszertervezés, amely magában foglalja az alkalmazási, LLM kliens, MCP kliens és eszközfeldolgozási rétegeket
- **Több backend támogatás**: Rugalmas megvalósítás, amely támogatja az Ollama (helyi fejlesztés) és vLLM (gyártás) backendeket
- **Kapcsolódási protokollok**: STDIO mód közvetlen folyamatkommunikációhoz és SSE mód HTTP-alapú streaminghez
- **Valós alkalmazások**: Webautomatizálás, adatfeldolgozás és API integráció példák átfogó hibakezeléssel

Az MCP integráció bemutatja, hogyan lehet az SLM-eket külső képességekkel kiegészíteni, ellensúlyozva kisebb paraméterszámukat, miközben megőrzik a helyi telepítés és erőforrás-hatékonyság előnyeit.

## Stratégiai következmények

Együtt ez a három szakasz átfogó keretrendszert kínál az SLM agentikus rendszerek megértéséhez és megvalósításához. Az alapvető fogalmaktól a funkcióhíváson át az MCP integrációig tartó fejlődés egyértelmű utat mutat a demokratizált AI telepítés felé, ahol:

- **Hatékonyság találkozik képességgel** az optimalizált kis modellek révén
- **Költséghatékonyság** teszi lehetővé a széleskörű alkalmazást
- **Szabványosított protokollok** biztosítják az interoperabilitást
- **Helyi telepítés** megőrzi az adatvédelmet és csökkenti a késleltetést

Ez a fejlődés nem csupán technológiai előrelépést jelent, hanem egy paradigmaváltást is, amely hozzáférhetőbbé, hatékonyabbá és gyakorlatiasabbá teszi az AI rendszereket. Ezek a rendszerek képesek hatékonyan működni erőforrás-korlátozott környezetekben, miközben kifinomult agentikus képességeket nyújtanak.

Az SLM-ek kombinációja fejlett telepítési stratégiákkal, robusztus funkcióhívással és szabványosított eszközintegrációs protokollokkal megalapozza a következő generációs AI ügynökök alapját, amelyek átalakítják, hogyan lépünk kapcsolatba a mesterséges intelligenciával, és hogyan profitálunk belőle az iparágak és alkalmazások széles körében.

---

**Felelősség kizárása**:  
Ez a dokumentum az AI fordítási szolgáltatás, a [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével lett lefordítva. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelvén tekintendő hiteles forrásnak. Kritikus információk esetén javasolt professzionális emberi fordítást igénybe venni. Nem vállalunk felelősséget semmilyen félreértésért vagy téves értelmezésért, amely a fordítás használatából eredhet.