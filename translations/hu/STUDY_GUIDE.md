<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T23:23:34+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "hu"
}
-->
# EdgeAI kezdőknek: Tanulási útvonalak és tanulási ütemterv

### Koncentrált tanulási útvonal (1 hét)

| Nap | Fókusz | Becsült órák |
|------|-------|------------------|
| 1. nap | Modul 1: EdgeAI alapok | 3 óra |
| 2. nap | Modul 2: SLM alapok | 3 óra |
| 3. nap | Modul 3: SLM telepítés | 2 óra |
| 4-5. nap | Modul 4: Modell optimalizálás (6 keretrendszer) | 4 óra |
| 6. nap | Modul 5: SLMOps | 3 óra |
| 7. nap | Modul 6-7: AI ügynökök és fejlesztői eszközök | 5 óra |

### Koncentrált tanulási útvonal (2 hét)

| Nap | Fókusz | Becsült órák |
|------|-------|------------------|
| 1-2. nap | Modul 1: EdgeAI alapok | 3 óra |
| 3-4. nap | Modul 2: SLM alapok | 3 óra |
| 5-6. nap | Modul 3: SLM telepítés | 2 óra |
| 7-8. nap | Modul 4: Modell optimalizálás | 4 óra |
| 9-10. nap | Modul 5: SLMOps | 3 óra |
| 11-12. nap | Modul 6: AI ügynökök | 2 óra |
| 13-14. nap | Modul 7: Fejlesztői eszközök | 3 óra |

### Részmunkaidős tanulás (4 hét)

| Hét | Fókusz | Becsült órák |
|------|-------|------------------|
| 1. hét | Modul 1-2: Alapok és SLM alapok | 6 óra |
| 2. hét | Modul 3-4: Telepítés és optimalizálás | 6 óra |
| 3. hét | Modul 5-6: SLMOps és AI ügynökök | 5 óra |
| 4. hét | Modul 7: Fejlesztői eszközök és integráció | 3 óra |

| Nap | Fókusz | Becsült órák |
|------|-------|------------------|
| 1-2. nap | Modul 1: EdgeAI alapok | 3 óra |
| 3-4. nap | Modul 2: SLM alapok | 3 óra |
| 5-6. nap | Modul 3: SLM telepítés | 2 óra |
| 7-8. nap | Modul 4: Modell optimalizálás | 4 óra |
| 9-10. nap | Modul 5: SLMOps | 3 óra |
| 11-12. nap | Modul 6: SLM ügynöki rendszerek | 2 óra |
| 13-14. nap | Modul 7: EdgeAI implementációs minták | 2 óra |

| Modul | Befejezés dátuma | Ráfordított órák | Fő tanulságok |
|--------|----------------|-------------|--------------|
| Modul 1: EdgeAI alapok | | | |
| Modul 2: SLM alapok | | | |
| Modul 3: SLM telepítés | | | |
| Modul 4: Modell optimalizálás (6 keretrendszer) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM ügynöki rendszerek | | | |
| Modul 7: EdgeAI implementációs minták | | | |
| Gyakorlati feladatok | | | |
| Mini-projekt | | | |

### Részmunkaidős tanulás (4 hét)

| Hét | Fókusz | Becsült órák |
|------|-------|------------------|
| 1. hét | Modul 1-2: Alapok és SLM alapok | 6 óra |
| 2. hét | Modul 3-4: Telepítés és optimalizálás | 6 óra |
| 3. hét | Modul 5-6: SLMOps és AI ügynökök | 5 óra |
| 4. hét | Modul 7: Fejlesztői eszközök és integráció | 3 óra |

## Bevezetés

Üdvözlünk az EdgeAI kezdőknek szóló tanulmányi útmutatójában! Ez a dokumentum segít abban, hogy hatékonyan navigálj a tananyagok között, és maximalizáld a tanulási élményedet. Strukturált tanulási útvonalakat, javasolt tanulási ütemterveket, kulcsfogalmak összefoglalóit és kiegészítő forrásokat kínál, hogy mélyebb megértést szerezz az EdgeAI technológiákról.

Ez egy tömör, 20 órás kurzus, amely időhatékony formában nyújt alapvető ismereteket az EdgeAI-ról, így ideális elfoglalt szakemberek és diákok számára, akik gyorsan szeretnének gyakorlati készségeket szerezni ebben a feltörekvő területen.

## Kurzus áttekintése

A kurzus hét átfogó modulból áll:

1. **EdgeAI alapok és átalakulás** - A főbb fogalmak és technológiai váltás megértése
2. **Kis nyelvi modellek alapjai** - Különböző SLM családok és architektúráik felfedezése
3. **Kis nyelvi modellek telepítése** - Gyakorlati telepítési stratégiák megvalósítása
4. **Modell formátum konverzió és kvantálás** - Fejlett optimalizálás 6 keretrendszerrel, beleértve az OpenVINO-t
5. **SLMOps - Kis nyelvi modellek működtetése** - Gyártási életciklus menedzsment és telepítés
6. **SLM ügynöki rendszerek** - AI ügynökök, funkcióhívás és Model Context Protocol
7. **EdgeAI implementációs minták** - AI Toolkit, Windows fejlesztés és platform-specifikus implementációk
8. **Microsoft Foundry Local – Teljes fejlesztői eszköztár** - Lokális fejlesztés hibrid Azure integrációval (08. modul)

## Hogyan használd ezt az útmutatót

- **Fokozatos tanulás**: Kövesd a modulokat sorrendben a legkoherensebb tanulási élmény érdekében
- **Tudásellenőrzési pontok**: Használd az önértékelési kérdéseket minden szakasz után
- **Gyakorlati tapasztalat**: Végezd el az ajánlott gyakorlatokat az elméleti fogalmak megerősítésére
- **Kiegészítő források**: Fedezd fel a további anyagokat az érdeklődésednek megfelelő témákban

## Tanulási ütemterv ajánlások

### Koncentrált tanulási útvonal (1 hét)

| Nap | Fókusz | Becsült órák |
|------|-------|-----------------|
| 1-2. nap | Modul 1: EdgeAI alapok | 6 óra |
| 3-4. nap | Modul 2: SLM alapok | 8 óra |
| 5. nap | Modul 3: SLM telepítés | 3 óra |
| 6. nap | Modul 8: Foundry Local eszköztár | 3 óra |

### Részmunkaidős tanulás (3 hét)

| Hét | Fókusz | Becsült órák |
|------|-------|-----------------|
| 1. hét | Modul 1: EdgeAI alapok | 6-7 óra |
| 2. hét | Modul 2: SLM alapok | 7-8 óra |
| 3. hét | Modul 3: SLM telepítés (3 óra) + Modul 8: Foundry Local eszköztár (2-3 óra) | 5-6 óra |

## Modul 1: EdgeAI alapok és átalakulás

### Fő tanulási célok

- Értsd meg a különbségeket a felhőalapú és az edge-alapú AI között
- Sajátítsd el az erőforrás-korlátozott környezetekhez szükséges alapvető optimalizálási technikákat
- Elemezd az EdgeAI technológiák valós alkalmazásait
- Állítsd be a fejlesztési környezetet EdgeAI projektekhez

### Tanulmányi fókuszterületek

#### 1. szakasz: EdgeAI alapok
- **Elsődleges fogalmak**: 
  - Edge vs. felhő számítási paradigmák
  - Modell kvantálási technikák
  - Hardveres gyorsítási lehetőségek (NPU-k, GPU-k, CPU-k)
  - Adatvédelem és biztonsági előnyök

- **Kiegészítő anyagok**:
  - [TensorFlow Lite dokumentáció](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse dokumentáció](https://docs.edgeimpulse.com)

#### 2. szakasz: Valós esettanulmányok
- **Elsődleges fogalmak**: 
  - Microsoft Phi & Mu modell ökoszisztéma
  - Gyakorlati megvalósítások különböző iparágakban
  - Telepítési szempontok

#### 3. szakasz: Gyakorlati megvalósítási útmutató
- **Elsődleges fogalmak**: 
  - Fejlesztési környezet beállítása
  - Kvantálási és optimalizálási eszközök
  - Értékelési módszerek EdgeAI megvalósításokhoz

#### 4. szakasz: Edge telepítési hardver
- **Elsődleges fogalmak**: 
  - Hardver platform összehasonlítások
  - Optimalizálási stratégiák specifikus hardverekhez
  - Telepítési szempontok

### Önértékelési kérdések

1. Hasonlítsd össze a felhőalapú AI-t az edge-alapú AI megvalósításokkal.
2. Magyarázd el három kulcsfontosságú technikát a modellek edge telepítéshez való optimalizálására.
3. Mik az elsődleges előnyei az AI modellek edge-en történő futtatásának?
4. Írd le a modell kvantálásának folyamatát és annak hatását a teljesítményre.
5. Magyarázd el, hogyan befolyásolják a különböző hardveres gyorsítók (NPU-k, GPU-k, CPU-k) az EdgeAI telepítést.

### Gyakorlati feladatok

1. **Gyors környezetbeállítás**: Állítsd be a minimális fejlesztési környezetet az alapvető csomagokkal (30 perc)
2. **Modell felfedezése**: Tölts le és vizsgálj meg egy előre betanított kis nyelvi modellt (1 óra)
3. **Alapvető kvantálás**: Próbálj ki egyszerű kvantálást egy kis modellen (1 óra)

## Modul 2: Kis nyelvi modellek alapjai

### Fő tanulási célok

- Értsd meg a különböző SLM családok architekturális elveit
- Hasonlítsd össze a modellek képességeit különböző paraméter skálákon
- Értékeld a modelleket hatékonyság, képesség és telepítési követelmények alapján
- Ismerd fel a különböző modellcsaládok megfelelő alkalmazási területeit

### Tanulmányi fókuszterületek

#### 1. szakasz: Microsoft Phi modellcsalád
- **Elsődleges fogalmak**: 
  - Tervezési filozófia evolúciója
  - Hatékonyság-központú architektúra
  - Speciális képességek

#### 2. szakasz: Qwen család
- **Elsődleges fogalmak**: 
  - Nyílt forráskódú hozzájárulások
  - Skálázható telepítési lehetőségek
  - Fejlett érvelési architektúra

#### 3. szakasz: Gemma család
- **Elsődleges fogalmak**: 
  - Kutatásvezérelt innováció
  - Multimodális képességek
  - Mobil optimalizálás

#### 4. szakasz: BitNET család
- **Elsődleges fogalmak**: 
  - 1-bites kvantálási technológia
  - Inference optimalizálási keretrendszer
  - Fenntarthatósági szempontok

#### 5. szakasz: Microsoft Mu modell
- **Elsődleges fogalmak**: 
  - Eszköz-központú architektúra
  - Rendszerintegráció Windows-szal
  - Adatvédelem-központú működés

#### 6. szakasz: Phi-Silica
- **Elsődleges fogalmak**: 
  - NPU-optimalizált architektúra
  - Teljesítménymutatók
  - Fejlesztői integráció

### Önértékelési kérdések

1. Hasonlítsd össze a Phi és Qwen modellcsaládok architekturális megközelítéseit.
2. Magyarázd el, hogyan különbözik a BitNET kvantálási technológiája a hagyományos kvantálástól.
3. Mik a Mu modell egyedi előnyei a Windows integráció szempontjából?
4. Írd le, hogyan használja ki a Phi-Silica az NPU hardvert a teljesítmény optimalizálására.
5. Egy mobilalkalmazás esetén, amely korlátozott kapcsolattal rendelkezik, melyik modellcsalád lenne a legmegfelelőbb és miért?

### Gyakorlati feladatok

1. **Modell összehasonlítás**: Két különböző SLM modell gyors benchmarkja (1 óra)
2. **Egyszerű szöveg generálás**: Alapvető szöveg generálás megvalósítása egy kis modellel (1 óra)
3. **Gyors optimalizálás**: Alkalmazz egy optimalizálási technikát az inference sebességének javítására (1 óra)

## Modul 3: Kis nyelvi modellek telepítése

### Fő tanulási célok

- Válassz megfelelő modelleket a telepítési korlátok alapján
- Sajátítsd el az optimalizálási technikákat különböző telepítési forgatókönyvekhez
- Valósítsd meg az SLM-eket helyi és felhő környezetben
- Tervezd meg a gyártásra kész konfigurációkat EdgeAI alkalmazásokhoz

### Tanulmányi fókuszterületek

#### 1. szakasz: SLM fejlett tanulás
- **Elsődleges fogalmak**: 
  - Paraméter osztályozási keretrendszer
  - Fejlett optimalizálási technikák
  - Modell beszerzési stratégiák

#### 2. szakasz: Helyi környezet telepítése
- **Elsődleges fogalmak**: 
  - Ollama platform telepítése
  - Microsoft Foundry helyi megoldások
  - Keretrendszer összehasonlító elemzés

#### 3. szakasz: Konténerizált felhő telepítés
- **Elsődleges fogalmak**: 
  - vLLM nagy teljesítményű inference
  - Konténer orchestration
  - ONNX Runtime megvalósítás

### Önértékelési kérdések

1. Milyen tényezőket kell figyelembe venni a helyi telepítés és a felhő telepítés közötti választáskor?
2. Hasonlítsd össze az Ollama és a Microsoft Foundry Local telepítési lehetőségeit.
3. Magyarázd el a konténerizáció előnyeit az SLM telepítés szempontjából.
4. Mik a kulcsfontosságú teljesítménymutatók, amelyeket figyelni kell egy edge-en telepített SLM esetében?
5. Írd le egy teljes telepítési munkafolyamatot a modell kiválasztásától a gyártási megvalósításig.

### Gyakorlati feladatok

1. **Alapvető helyi telepítés**: Telepíts egy egyszerű SLM-et az Ollama segítségével (1 óra)
2. **Teljesítmény ellenőrzés**: Futtass egy gyors benchmarkot a telepített modellen (30 perc)
3. **Egyszer
- **Elsődleges Fogalmak**: 
  - Apple Silicon optimalizáció
  - Egységes memóriaarchitektúra
  - LoRA finomhangolási képességek

#### 6. szekció: Edge AI fejlesztési munkafolyamat szintézise
- **Elsődleges Fogalmak**: 
  - Egységes munkafolyamat-architektúra
  - Keretrendszer-választási döntési fák
  - Gyártási készség validálása
  - Jövőbiztos stratégiák

### Önértékelési Kérdések

1. Hasonlítsa össze a kvantálási stratégiákat különböző precíziós szinteken (1-bit-től 8-bit-ig).
2. Magyarázza el a GGUF formátum előnyeit az edge telepítéshez.
3. Hogyan javítja a Microsoft Olive hardver-tudatos optimalizációja a telepítési hatékonyságot?
4. Mik az OpenVINO NNCF kulcsfontosságú előnyei a modell tömörítésében?
5. Írja le, hogyan használja az Apple MLX az egységes memóriaarchitektúrát az optimalizációhoz.
6. Hogyan segíti a munkafolyamat szintézise az optimális optimalizációs keretrendszerek kiválasztását?

### Gyakorlati Feladatok

1. **Modell Kvantálás**: Alkalmazzon különböző kvantálási szinteket egy modellre, és hasonlítsa össze az eredményeket (1 óra)
2. **OpenVINO Optimalizáció**: Használja az NNCF-t egy modell tömörítésére Intel hardverhez (1 óra)
3. **Keretrendszer Összehasonlítás**: Tesztelje ugyanazt a modellt három különböző optimalizációs keretrendszerben (1 óra)
4. **Teljesítmény Benchmarking**: Mérje meg az optimalizáció hatását az inferencia sebességére és memóriahasználatra (1 óra)

## 5. modul: SLMOps - Kis Nyelvi Modell Műveletek

### Fő Tanulási Célok

- Értsék meg az SLMOps életciklus-kezelési elveit
- Sajátítsák el a desztillációs és finomhangolási technikákat az edge telepítéshez
- Valósítsanak meg gyártási telepítési stratégiákat monitorozással
- Építsenek vállalati szintű SLM műveleti és karbantartási munkafolyamatokat

### Tanulmányi Fókuszterületek

#### 1. szekció: Bevezetés az SLMOps-ba
- **Elsődleges Fogalmak**: 
  - Az SLMOps paradigmaváltása az AI műveletekben
  - Költséghatékonyság és adatvédelmi első architektúra
  - Stratégiai üzleti hatás és versenyelőnyök

#### 2. szekció: Modell Desztilláció
- **Elsődleges Fogalmak**: 
  - Tudásátadási technikák
  - Kétlépcsős desztillációs folyamat megvalósítása
  - Azure ML desztillációs munkafolyamatok

#### 3. szekció: Finomhangolási Stratégiák
- **Elsődleges Fogalmak**: 
  - Paraméter-hatékony finomhangolás (PEFT)
  - LoRA és QLoRA fejlett módszerek
  - Több adapteres képzés és hiperparaméter optimalizáció

#### 4. szekció: Gyártási Telepítés
- **Elsődleges Fogalmak**: 
  - Modell konverzió és kvantálás gyártásra
  - Foundry Local telepítési konfiguráció
  - Teljesítmény benchmarking és minőség validálás

### Önértékelési Kérdések

1. Miben különbözik az SLMOps a hagyományos MLOps-tól?
2. Magyarázza el a modell desztilláció előnyeit az edge telepítéshez.
3. Mik a kulcsfontosságú szempontok az SLM-ek finomhangolásához erőforrás-korlátozott környezetekben?
4. Írjon le egy teljes gyártási telepítési csővezetéket edge AI alkalmazásokhoz.

### Gyakorlati Feladatok

1. **Alap Desztilláció**: Hozzon létre egy kisebb modellt egy nagyobb tanármodellből (1 óra)
2. **Finomhangolási Kísérlet**: Finomhangoljon egy modellt egy adott területre (1 óra)
3. **Telepítési Csővezeték**: Állítson be egy alap CI/CD csővezetéket modell telepítéshez (1 óra)

## 6. modul: SLM Agentikus Rendszerek - AI Ügynökök és Funkcióhívás

### Fő Tanulási Célok

- Építsenek intelligens AI ügynököket edge környezetekhez Kis Nyelvi Modellek használatával
- Valósítsanak meg funkcióhívási képességeket szisztematikus munkafolyamatokkal
- Sajátítsák el a Model Context Protocol (MCP) integrációt szabványosított eszközinterakcióhoz
- Hozzanak létre kifinomult agentikus rendszereket minimális emberi beavatkozással

### Tanulmányi Fókuszterületek

#### 1. szekció: AI Ügynökök és SLM Alapok
- **Elsődleges Fogalmak**: 
  - Ügynök osztályozási keretrendszer (reflex, modell-alapú, cél-alapú, tanuló ügynökök)
  - SLM vs LLM kompromisszumok elemzése
  - Edge-specifikus ügynök tervezési minták
  - Erőforrás-optimalizáció ügynökök számára

#### 2. szekció: Funkcióhívás Kis Nyelvi Modellekben
- **Elsődleges Fogalmak**: 
  - Szisztematikus munkafolyamat megvalósítása (szándékfelismerés, JSON kimenet, külső végrehajtás)
  - Platform-specifikus megvalósítások (Phi-4-mini, kiválasztott Qwen modellek, Microsoft Foundry Local)
  - Fejlett példák (több ügynök együttműködése, dinamikus eszközválasztás)
  - Gyártási szempontok (sebességkorlátozás, naplózás, biztonsági intézkedések)

#### 3. szekció: Model Context Protocol (MCP) Integráció
- **Elsődleges Fogalmak**: 
  - Protokoll architektúra és rétegzett rendszertervezés
  - Több backend támogatás (Ollama fejlesztéshez, vLLM gyártáshoz)
  - Kapcsolódási protokollok (STDIO és SSE módok)
  - Valós alkalmazások (web automatizáció, adatfeldolgozás, API integráció)

### Önértékelési Kérdések

1. Mik a kulcsfontosságú architekturális szempontok edge AI ügynökökhöz?
2. Hogyan növeli a funkcióhívás az ügynök képességeit?
3. Magyarázza el a Model Context Protocol szerepét az ügynök kommunikációban.

### Gyakorlati Feladatok

1. **Egyszerű Ügynök**: Építsen egy alap AI ügynököt funkcióhívással (1 óra)
2. **MCP Integráció**: Valósítsa meg az MCP-t egy ügynök alkalmazásban (30 perc)

## 7. modul: EdgeAI Megvalósítási Minták

### Fő Tanulási Célok

- Sajátítsák el az AI Toolkit-et a Visual Studio Code-hoz átfogó EdgeAI fejlesztési munkafolyamatokhoz
- Szerezzenek szakértelmet a Windows AI Foundry platformon és NPU optimalizációs stratégiákban
- Valósítsanak meg EdgeAI-t több hardverplatformon és telepítési forgatókönyvben
- Építsenek gyártásra kész EdgeAI alkalmazásokat platform-specifikus optimalizációkkal

### Tanulmányi Fókuszterületek

#### 1. szekció: AI Toolkit a Visual Studio Code-hoz
- **Elsődleges Fogalmak**: 
  - Átfogó Edge AI fejlesztési környezet a VS Code-ban
  - Modell katalógus és felfedezés edge telepítéshez
  - Helyi tesztelés, optimalizáció és ügynök fejlesztési munkafolyamatok
  - Teljesítmény monitorozás és értékelés edge forgatókönyvekhez

#### 2. szekció: Windows EdgeAI Fejlesztési Útmutató
- **Elsődleges Fogalmak**: 
  - Windows AI Foundry platform átfogó áttekintése
  - Phi Silica API hatékony NPU inferenciához
  - Számítógépes látás API-k képfeldolgozáshoz és OCR-hez
  - Foundry Local CLI helyi fejlesztéshez és teszteléshez

#### 3. szekció: Platform-specifikus Megvalósítások
- **Elsődleges Fogalmak**: 
  - NVIDIA Jetson Orin Nano telepítés (67 TOPS AI teljesítmény)
  - Mobil alkalmazások .NET MAUI-val és ONNX Runtime GenAI-val
  - Azure EdgeAI megoldások felhő-edge hibrid architektúrával
  - Windows ML optimalizáció univerzális hardvertámogatással
  - Foundry Local alkalmazások adatvédelmi fókuszú RAG megvalósítással

### Önértékelési Kérdések

1. Hogyan egyszerűsíti az AI Toolkit az EdgeAI fejlesztési munkafolyamatot?
2. Hasonlítsa össze a telepítési stratégiákat különböző hardverplatformokon.
3. Mik az előnyei a Windows AI Foundry-nak az edge fejlesztéshez?
4. Magyarázza el az NPU optimalizáció szerepét a modern edge AI alkalmazásokban.
5. Hogyan használja a Phi Silica API az NPU hardvert a teljesítmény optimalizálásához?
6. Hasonlítsa össze a helyi és felhő telepítés előnyeit adatvédelmi érzékeny alkalmazások esetén.

### Gyakorlati Feladatok

1. **AI Toolkit Beállítás**: Konfigurálja az AI Toolkit-et és optimalizáljon egy modellt (1 óra)
2. **Windows AI Foundry**: Építsen egy egyszerű Windows AI alkalmazást a Phi Silica API-val (1 óra)
3. **Keresztplatform Telepítés**: Telepítse ugyanazt a modellt két különböző platformon (1 óra)
4. **NPU Optimalizáció**: Tesztelje az NPU teljesítményét a Windows AI Foundry eszközökkel (30 perc)

## 8. modul: Microsoft Foundry Local – Teljes Fejlesztői Eszköztár

### Fő Tanulási Célok

- Telepítse és konfigurálja a Foundry Local-t Windows-on
- Futtasson, fedezzen fel és kezeljen modelleket helyben a Foundry CLI segítségével
- Integráljon OpenAI-kompatibilis REST és SDK kliensekkel
- Építsen gyakorlati mintákat: Chainlit chat, ügynökök és modell router
- Értsék meg a hibrid mintákat az Azure AI Foundry-val

### Tanulmányi Fókuszterületek

- Telepítés és CLI alapok (modell, szolgáltatás, gyorsítótár)
- SDK integráció (OpenAI-kompatibilis kliensek és Azure OpenAI)
- Open WebUI gyors validálás
- Ügynökök és funkcióhívási minták
- Modellek mint eszközök (router és regisztrációs tervezés)

### Önértékelési Kérdések

1. Hogyan fedezheti fel a helyi végpontot és listázhatja az elérhető modelleket?
2. Mik a különbségek a Foundry Local REST és az Azure OpenAI használata között?
3. Hogyan tervezne egy egyszerű routert, amely modelleket választ eszközként?
4. Mely CLI kategóriák a legrelevánsabbak a napi fejlesztéshez?
5. Hogyan validálja a Foundry Local készenlétét alkalmazások futtatása előtt?

### Gyakorlati Feladatok

1. Telepítse/frissítse a Foundry Local-t, és futtassa a `phi-4-mini` modellt helyben (30 perc)
2. Hívja meg a `/v1/models` végpontot, és futtasson egy egyszerű chatet REST-en keresztül (30 perc)
3. Indítsa el a Chainlit alkalmazás mintát, és chateljen helyben (30 perc)
4. Futtassa a több ügynök koordinátort, és vizsgálja meg a kimeneteket (30 perc)
5. Próbálja ki a modellek mint eszközök routert környezet-alapú felülírásokkal (30 perc)

## Időbeosztási Útmutató

Hogy a legtöbbet hozza ki a 20 órás kurzus időkeretéből, itt egy javasolt bontás az idő elosztására:

| Tevékenység | Időbeosztás | Leírás |
|-------------|-------------|--------|
| Alapanyagok Olvasása | 9 óra | A lényeges fogalmakra koncentrálás minden modulban |
| Gyakorlati Feladatok | 6 óra | Kulcsfontosságú technikák gyakorlati megvalósítása |
| Önértékelés | 2 óra | Megértés tesztelése kérdésekkel és reflexióval |
| Mini-Projekt | 3 óra | Tudás alkalmazása egy kis gyakorlati megvalósításban |

### Fókuszterületek Időkorlátok Szerint

**Ha csak 10 órája van:**
- Fejezze be az 1., 2. és 3. modulokat (alapvető EdgeAI fogalmak)
- Végezzen el legalább egy gyakorlati feladatot modulonként
- Koncentráljon a fogalmak megértésére, ne a megvalósítás részleteire

**Ha teljes 20 órát tud szánni:**
- Fejezze be mind a hét modult
- Végezze el a kulcsfontosságú gyakorlati feladatokat minden modulból
- Fejezzen be egy mini-projektet a 7. modulból
- Fedezzen fel legalább 2-3 kiegészítő forrást

**Ha több mint 20 órája van:**
- Fejezze be az összes modult részletes feladatokkal
- Építsen több mini-projektet
- Fedezze fel a fejlett optimalizációs technikákat a 4. modulban
- Valósítson meg gyártási telepítést az 5. modulból

## Lényeges Források

Ezek a gondosan kiválasztott források nyújtják a legtöbb értéket a korlátozott tanulási idő alatt:

### Kötelező Olvasmányok
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - A leghatékonyabb modell optimalizációs eszköz
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - A leggyorsabb mód SLM-ek helyi telepítésére
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referencia egy vezető edge-optimalizált modellhez
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intel átfogó optimalizációs eszköztára
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrált EdgeAI fejlesztési környezet
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifikus EdgeAI fejlesztési platform

### Időtakarékos Eszközök
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Gyors modell hozzáférés és telepítés
- [Gradio](https://www.gradio.app/docs/interface) - Gyors UI fejlesztés AI demókhoz
- [Microsoft Olive](https://github.com/microsoft/Olive) - Egyszerűsített modell optimalizáció
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Hatékony CPU inferencia
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Neurális hálózat tömörítési keretrendszer
- [OpenVINO Gen
8. **OpenVINO Optimalizációs Folyamat**: Teljes modelloptimalizáció megvalósítása NNCF és GenAI eszközkészlet segítségével  
9. **SLMOps Folyamat**: Teljes modelléletciklus megvalósítása a tréningtől az edge telepítésig  
10. **Többmodellű Edge Rendszer**: Több specializált modell telepítése, amelyek együttműködnek edge hardveren  
11. **MCP Integrációs Rendszer**: Ügynöki rendszer építése Model Context Protocol segítségével az eszközök közötti interakcióhoz  

## Hivatkozások

- Microsoft Learn (Foundry Local)  
  - Áttekintés: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Első lépések: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI referencia: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integráció inference SDK-kkal: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI használati útmutató: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Hugging Face modellek fordítása: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Áttekintés: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Ügynökök (áttekintés): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimalizációs és inference eszközök  
  - Microsoft Olive (dokumentáció): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (első lépések): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive integráció: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (dokumentáció): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (dokumentáció): https://ml-explore.github.io/mlx/build/html/index.html  
- Telepítési keretrendszerek és modellek  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (dokumentáció): https://docs.vllm.ai/  
  - Ollama (gyors kezdés): https://github.com/ollama/ollama#get-started  
- Fejlesztői eszközök (Windows és VS Code)  
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (áttekintés): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Tanulóközösség

Csatlakozz a beszélgetéshez és lépj kapcsolatba más tanulókkal:  
- GitHub Discussions az [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions) oldalán  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Összegzés

Az EdgeAI az mesterséges intelligencia megvalósításának élvonalát képviseli, amely erőteljes képességeket hoz közvetlenül az eszközökre, miközben foglalkozik a magánélet, a késleltetés és a csatlakoztathatóság kritikus kérdéseivel. Ez a 20 órás kurzus biztosítja az alapvető tudást és gyakorlati készségeket, hogy azonnal elkezdhess dolgozni az EdgeAI technológiákkal.

A kurzus szándékosan tömör és a legfontosabb fogalmakra összpontosít, lehetővé téve, hogy gyorsan értékes szakértelmet szerezz túlzott időráfordítás nélkül. Ne feledd, hogy a gyakorlati tapasztalat, még egyszerű példákon keresztül is, kulcsfontosságú a tanultak megerősítéséhez.

Jó tanulást kívánunk!

---

