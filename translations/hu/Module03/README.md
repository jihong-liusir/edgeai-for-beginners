<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-18T17:15:27+00:00",
  "source_file": "Module03/README.md",
  "language_code": "hu"
}
-->
# 3. fejezet: Kis Nyelvi Modellek (SLM-ek) telepítése

Ez az átfogó fejezet bemutatja a Kis Nyelvi Modellek (SLM-ek) telepítésének teljes életciklusát, beleértve az elméleti alapokat, gyakorlati megvalósítási stratégiákat és a gyártásra kész konténeres megoldásokat. A fejezet három egymást követő szakaszra van osztva, amelyek az olvasókat az alapfogalmaktól a fejlett telepítési forgatókönyvekig vezetik.

## A fejezet felépítése és tanulási útja

### **[1. szakasz: SLM fejlett tanulás - Alapok és optimalizálás](./01.SLMAdvancedLearning.md)**
A nyitó szakasz lefekteti az elméleti alapokat a Kis Nyelvi Modellek megértéséhez és azok stratégiai fontosságához az edge AI telepítésekben. Ez a szakasz az alábbiakat tartalmazza:

- **Paraméterek osztályozási keretrendszere**: Részletes bemutató az SLM kategóriákról, a Mikro SLM-ekről (100M-1,4B paraméter) a Közepes SLM-ekig (14B-30B paraméter), különös tekintettel olyan modellekre, mint a Phi-4-mini-3.8B, Qwen3 sorozat és Google Gemma3, beleértve a hardverkövetelmények és memóriahasználat elemzését minden modell szinten
- **Fejlett optimalizálási technikák**: Átfogó ismertetés a kvantálási módszerekről, mint például a Llama.cpp, Microsoft Olive és Apple MLX keretrendszerek, beleértve a legmodernebb BitNET 1-bites kvantálást gyakorlati kódpéldákkal, amelyek bemutatják a kvantálási folyamatokat és a benchmarking eredményeket
- **Modellek beszerzési stratégiái**: Mélyreható elemzés a Hugging Face ökoszisztémáról és az Azure AI Foundry Model Catalog-ról vállalati szintű SLM telepítéshez, kódmintákkal a modellek programozott letöltéséhez, validálásához és formátumkonverziójához
- **Fejlesztői API-k**: Python, C++ és C# kódpéldák, amelyek bemutatják, hogyan lehet modelleket betölteni, következtetéseket végezni, és integrálni népszerű keretrendszerekkel, mint a PyTorch, TensorFlow és ONNX Runtime

Ez az alapozó szakasz hangsúlyozza az operatív hatékonyság, a telepítési rugalmasság és a költséghatékonyság egyensúlyát, amely ideálissá teszi az SLM-eket edge computing forgatókönyvekhez, gyakorlati kódpéldákkal, amelyeket a fejlesztők közvetlenül alkalmazhatnak projektjeikben.

### **[2. szakasz: Helyi környezet telepítése - Adatvédelem-központú megoldások](./02.DeployingSLMinLocalEnv.md)**
A második szakasz az elmélettől a gyakorlati megvalósítás felé halad, a helyi telepítési stratégiákra összpontosítva, amelyek prioritásként kezelik az adatfüggetlenséget és az operatív önállóságot. Főbb területek:

- **Ollama Universal Platform**: Átfogó bemutató a platformok közötti telepítésről, különös tekintettel a fejlesztőbarát munkafolyamatokra, a modellek életciklus-kezelésére és testreszabására Modelfile-ok segítségével, beleértve teljes REST API integrációs példákat és CLI automatizálási szkripteket
- **Microsoft Foundry Local**: Vállalati szintű telepítési megoldások ONNX-alapú optimalizálással, Windows ML integrációval és átfogó biztonsági funkciókkal, C# és Python kódpéldákkal a natív alkalmazásintegrációhoz
- **Összehasonlító elemzés**: Részletes keretrendszer-összehasonlítás, amely lefedi a technikai architektúrát, teljesítményjellemzőket és használati esetek optimalizálási irányelveit, benchmark kóddal a következtetési sebesség és memóriahasználat értékeléséhez különböző hardvereken
- **API integráció**: Mintapéldák, amelyek bemutatják, hogyan lehet webszolgáltatásokat, chat alkalmazásokat és adatfeldolgozó csatornákat építeni helyi SLM telepítésekkel, kódpéldákkal Node.js, Python Flask/FastAPI és ASP.NET Core környezetben
- **Tesztelési keretrendszerek**: Automatizált tesztelési megközelítések a modellek minőségbiztosításához, beleértve egység- és integrációs tesztpéldákat SLM megvalósításokhoz

Ez a szakasz gyakorlati útmutatást nyújt azoknak a szervezeteknek, amelyek adatvédelmet biztosító AI megoldásokat kívánnak megvalósítani, miközben teljes kontrollt tartanak fenn telepítési környezetük felett, kész kódmintákkal, amelyeket a fejlesztők saját igényeikhez igazíthatnak.

### **[3. szakasz: Konténeres felhőtelepítés - Gyártási méretű megoldások](./03.DeployingSLMinCloud.md)**
Az utolsó szakasz a fejlett konténeres telepítési stratégiákra összpontosít, a Microsoft Phi-4-mini-instruct modellt használva elsődleges esettanulmányként. Ez a szakasz az alábbiakat tartalmazza:

- **vLLM telepítés**: Nagy teljesítményű következtetési optimalizálás OpenAI-kompatibilis API-kkal, fejlett GPU-gyorsítással és gyártásra kész konfigurációval, beleértve teljes Dockerfile-okat, Kubernetes manifesteket és teljesítményhangolási paramétereket
- **Ollama konténeres orkestráció**: Egyszerűsített telepítési munkafolyamatok Docker Compose segítségével, modelloptimalizálási változatokkal és webes UI integrációval, CI/CD pipeline példákkal az automatizált telepítéshez és teszteléshez
- **ONNX Runtime megvalósítás**: Edge-optimalizált telepítés átfogó modellkonverzióval, kvantálási stratégiákkal és platformok közötti kompatibilitással, részletes kódmintákkal a modelloptimalizáláshoz és telepítéshez
- **Monitoring és megfigyelhetőség**: Prometheus/Grafana dashboardok megvalósítása egyedi metrikákkal az SLM teljesítményének monitorozásához, beleértve riasztási konfigurációkat és naplóaggregációt
- **Terheléselosztás és skálázás**: Gyakorlati példák horizontális és vertikális skálázási stratégiákra, automatikus skálázási konfigurációkkal CPU/GPU kihasználtság és kérésminták alapján
- **Biztonsági megerősítés**: Konténerbiztonsági legjobb gyakorlatok, beleértve a jogosultságcsökkentést, hálózati szabályzatokat és titkosításkezelést API kulcsokhoz és modellhozzáférési hitelesítő adatokhoz

Minden telepítési megközelítés teljes konfigurációs példákkal, tesztelési eljárásokkal, gyártásra kész ellenőrzőlistákkal és infrastruktúra-kód sablonokkal kerül bemutatásra, amelyeket a fejlesztők közvetlenül alkalmazhatnak telepítési munkafolyamataikban.

## Fő tanulási eredmények

A fejezet elvégzésével az olvasók elsajátítják:

1. **Stratégiai modellválasztás**: A paraméterhatárok megértése és megfelelő SLM-ek kiválasztása erőforrás-korlátok és teljesítménykövetelmények alapján
2. **Optimalizálási készségek**: Fejlett kvantálási technikák megvalósítása különböző keretrendszerekben az optimális teljesítmény-hatékonyság egyensúly eléréséhez
3. **Telepítési rugalmasság**: Helyi adatvédelem-központú megoldások és skálázható konténeres telepítések közötti választás szervezeti igények alapján
4. **Gyártásra kész megoldások**: Monitoring, biztonság és skálázási rendszerek konfigurálása vállalati szintű SLM telepítésekhez

## Gyakorlati fókusz és valós alkalmazások

A fejezet erős gyakorlati orientációt tart fenn, amely magában foglalja:

- **Gyakorlati példák**: Teljes konfigurációs fájlok, API tesztelési eljárások és telepítési szkriptek
- **Teljesítmény benchmarking**: Részletes összehasonlítások a következtetési sebesség, memóriahasználat és erőforrás-követelmények terén
- **Biztonsági megfontolások**: Vállalati szintű biztonsági gyakorlatok, megfelelőségi keretrendszerek és adatvédelmi stratégiák
- **Legjobb gyakorlatok**: Gyártásban bevált irányelvek monitorozáshoz, skálázáshoz és karbantartáshoz

## Jövőorientált perspektíva

A fejezet zárásként előremutató betekintést nyújt a feltörekvő trendekbe, beleértve:

- Fejlettebb modellarchitektúrák jobb hatékonysági arányokkal
- Mélyebb hardverintegráció speciális AI gyorsítókkal
- Az ökoszisztéma fejlődése a szabványosítás és interoperabilitás irányába
- Vállalati adaptációs minták, amelyeket az adatvédelem és megfelelőség követelményei vezérelnek

Ez az átfogó megközelítés biztosítja, hogy az olvasók felkészültek legyenek a jelenlegi SLM telepítési kihívásokra és a jövőbeli technológiai fejlesztésekre, lehetővé téve számukra, hogy megalapozott döntéseket hozzanak, amelyek összhangban vannak szervezeti igényeikkel és korlátaikkal.

A fejezet egyszerre szolgál gyakorlati útmutatóként az azonnali megvalósításhoz és stratégiai forrásként a hosszú távú AI telepítési tervezéshez, hangsúlyozva a képességek, hatékonyság és operatív kiválóság kritikus egyensúlyát, amely a sikeres SLM telepítéseket jellemzi.

---

**Felelősség kizárása**:  
Ez a dokumentum az AI fordítási szolgáltatás [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével lett lefordítva. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelvén tekintendő hiteles forrásnak. Kritikus információk esetén javasolt professzionális emberi fordítást igénybe venni. Nem vállalunk felelősséget semmilyen félreértésért vagy téves értelmezésért, amely a fordítás használatából eredhet.