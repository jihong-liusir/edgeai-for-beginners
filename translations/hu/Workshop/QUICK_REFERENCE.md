<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a887b7e85782dadd3fd1216cd63b6c23",
  "translation_date": "2025-10-09T21:37:35+00:00",
  "source_file": "Workshop/QUICK_REFERENCE.md",
  "language_code": "hu"
}
-->
# Workshop Mint√°k - Gyors Referencia K√°rtya

**Utols√≥ friss√≠t√©s**: 2025. okt√≥ber 8.

---

## üöÄ Gyors kezd√©s

```bash
# 1. Ensure Foundry Local is running
foundry service status
foundry model run phi-4-mini

# 2. Install dependencies
pip install -r Workshop/requirements.txt

# 3. Run a sample
cd Workshop/samples/session01
python chat_bootstrap.py "What is edge AI?"
```

---

## üìÇ Mint√°k √°ttekint√©se

| Szekci√≥ | Minta | C√©l | Id≈ë |
|---------|-------|-----|-----|
| 01 | `chat_bootstrap.py` | Alap chat + streaming | ~30s |
| 02 | `rag_pipeline.py` | RAG be√°gyaz√°sokkal | ~45s |
| 02 | `rag_eval_ragas.py` | RAG √©rt√©kel√©s | ~60s |
| 03 | `benchmark_oss_models.py` | Modell benchmarking | ~2m |
| 04 | `model_compare.py` | SLM vs LLM | ~45s |
| 05 | `agents_orchestrator.py` | T√∂bb√ºgyn√∂k√∂s rendszer | ~60s |
| 06 | `models_router.py` | Sz√°nd√©kir√°ny√≠t√°s | ~45s |
| 06 | `models_pipeline.py` | T√∂bbl√©pcs≈ës folyamat | ~60s |

---

## üõ†Ô∏è K√∂rnyezeti v√°ltoz√≥k

### Alapvet≈ë
```bash
# Choose model
set FOUNDRY_LOCAL_ALIAS=phi-4-mini

# Override endpoint (optional)
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Show token usage
set SHOW_USAGE=1
```

### Szekci√≥-specifikus
```bash
# Session 02: RAG
set RAG_QUESTION="What is local inference?"
set EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Session 03: Benchmarking
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
set BENCH_STREAM=1

# Session 04: Comparison
set SLM_ALIAS=phi-4-mini
set LLM_ALIAS=qwen2.5-7b

# Session 05: Agents
set AGENT_MODEL_PRIMARY=phi-4-mini
set AGENT_QUESTION="Why use edge AI?"

# Session 06: Pipeline
set PIPELINE_TASK="Your task here"
```

---

## ‚úÖ √ârv√©nyes√≠t√©s √©s tesztel√©s

```bash
# Validate syntax and imports
python scripts/validate_samples.py

# Validate specific session
python scripts/validate_samples.py --session 01

# Run smoke tests
python scripts/test_samples.py --quick

# Verbose testing
python scripts/test_samples.py --verbose
```

---

## üêõ Hibakeres√©s

### Kapcsol√≥d√°si hiba
```bash
# Check Foundry Local
foundry service status

# Start if needed
foundry service start
foundry model run phi-4-mini
```

### Import√°l√°si hiba
```bash
# Install missing dependencies
pip install sentence-transformers ragas datasets

# Or install all
pip install -r Workshop/requirements.txt
```

### Modell nem tal√°lhat√≥
```bash
# List available models
foundry model ls

# Download model
foundry model download phi-4-mini
```

### Lass√∫ teljes√≠tm√©ny
```bash
# Use smaller model
set FOUNDRY_LOCAL_ALIAS=qwen2.5-0.5b

# Reduce benchmark rounds
set BENCH_ROUNDS=1
```

---

## üìñ Gyakori mint√°k

### Alap chat
```python
from workshop_utils import chat_once

text, usage = chat_once(
    'phi-4-mini',
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100,
    temperature=0.7
)
```

### √úgyf√©l lek√©r√©se
```python
from workshop_utils import get_client

manager, client, model_id = get_client(
    alias='phi-4-mini',
    endpoint=None  # Auto-detect
)
```

### Hibakezel√©s
```python
try:
    manager, client, model_id = get_client(alias)
except Exception as e:
    print(f"[ERROR] Failed: {e}")
    print("[INFO] Check: foundry service status")
    sys.exit(1)
```

### Streaming
```python
stream = client.chat.completions.create(
    model=model_id,
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

---

## üìä Modellv√°laszt√°s

| Modell | M√©ret | Legjobb felhaszn√°l√°s | Sebess√©g |
|--------|-------|----------------------|---------|
| `qwen2.5-0.5b` | 0.5B | Gyors oszt√°lyoz√°s | ‚ö°‚ö°‚ö° |
| `qwen2.5-coder-0.5b` | 0.5B | Gyors k√≥dgener√°l√°s | ‚ö°‚ö°‚ö° |
| `gemma-2-2b` | 2B | Kreat√≠v √≠r√°s | ‚ö°‚ö° |
| `phi-3.5-mini` | 3.5B | K√≥d, refaktor√°l√°s | ‚ö°‚ö° |
| `phi-4-mini` | 4B | √Åltal√°nos, √∂sszegz√©s | ‚ö°‚ö° |
| `qwen2.5-7b` | 7B | √ñsszetett √©rvel√©s | ‚ö° |

---

## üîó Er≈ëforr√°sok

- **SDK Dokument√°ci√≥**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **Gyors Referencia**: `Workshop/FOUNDRY_SDK_QUICKREF.md`
- **Friss√≠t√©si √∂sszefoglal√≥**: `Workshop/SAMPLES_UPDATE_SUMMARY.md`
- **Migr√°ci√≥s jegyzetek**: `Workshop/SDK_MIGRATION_NOTES.md`

---

## üí° Tippek

1. **√úgyfelek gyors√≠t√≥t√°raz√°sa**: A `workshop_utils` automatikusan gyors√≠t√≥t√°raz
2. **Haszn√°lj kisebb modelleket**: Tesztel√©shez kezdj a `qwen2.5-0.5b` modellel
3. **Enged√©lyezd a haszn√°lati statisztik√°t**: √Åll√≠tsd be `SHOW_USAGE=1` a tokenek nyomon k√∂vet√©s√©hez
4. **T√∂meges feldolgoz√°s**: T√∂bb promptot dolgozz fel egym√°s ut√°n
5. **Cs√∂kkentsd a max_tokens √©rt√©ket**: Cs√∂kkenti a k√©sleltet√©st gyors v√°laszokhoz

---

## üéØ Mintafolyamatok

### Minden tesztel√©se
```bash
python scripts/validate_samples.py
python scripts/test_samples.py --quick
```

### Modellek benchmarkol√°sa
```bash
cd samples/session03
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b,gemma-2-2b
set BENCH_ROUNDS=3
python benchmark_oss_models.py
```

### RAG folyamat
```bash
cd samples/session02
set RAG_QUESTION="What is RAG?"
python rag_pipeline.py
```

### T√∂bb√ºgyn√∂k√∂s rendszer
```bash
cd samples/session05
set AGENT_QUESTION="Why edge AI for healthcare?"
python agents_orchestrator.py
```

---

**Gyors seg√≠ts√©g**: Futtass b√°rmely mint√°t `--help` opci√≥val, vagy n√©zd meg a docstringet:
```bash
python chat_bootstrap.py --help
# or
python -c "import chat_bootstrap; help(chat_bootstrap)"
```

---

**Minden minta friss√≠tve 2025 okt√≥ber√©ben a Foundry Local SDK legjobb gyakorlataival** ‚ú®

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel ker√ºlt leford√≠t√°sra. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.