<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e3d7e45c04a9946ff6f9a3358db9ba74",
  "translation_date": "2025-10-01T01:13:35+00:00",
  "source_file": "Module08/03.OpenSourceModels.md",
  "language_code": "hu"
}
-->
# 3. szekció: Nyílt forráskódú modellek felfedezése és kezelése

## Áttekintés

Ebben a szekcióban a Foundry Local gyakorlati modellfelfedezésére és kezelésére koncentrálunk. Megtanulhatod, hogyan listázd a rendelkezésre álló modelleket, teszteld a különböző opciókat, és megértsd az alapvető teljesítményjellemzőket. Az oktatás hangsúlyt fektet a Foundry CLI gyakorlati használatára, hogy segítsen kiválasztani a megfelelő modelleket az adott felhasználási esetekhez.

## Tanulási célok

- A Foundry CLI parancsainak elsajátítása a modellek felfedezéséhez és kezeléséhez
- A modell gyorsítótár és helyi tárolási minták megértése
- Különböző modellek gyors tesztelése és összehasonlítása
- Gyakorlati munkafolyamatok kialakítása a modellválasztáshoz és teljesítményértékeléshez
- A Foundry Local által kínált modellek növekvő ökoszisztémájának felfedezése

## Előfeltételek

- Az 1. szekció elvégzése: Bevezetés a Foundry Local használatába
- Telepített és elérhető Foundry Local CLI
- Elegendő tárhely a modellek letöltéséhez (a modellek mérete 1GB-tól akár 20GB+ is lehet)
- Alapvető ismeretek a modell típusokról és felhasználási esetekről

## Áttekintés

Ez a szekció bemutatja, hogyan integrálhatók nyílt forráskódú modellek a Foundry Local-ba, és hogyan alkalmazhatók a „hozd a saját modelledet” (BYOM) stratégiák. Felfedezheted a Model Mondays sorozatot is, amely folyamatos tanulást és modellfelfedezést kínál.

## 6. rész: Gyakorlati feladat

### Feladat: Modellek felfedezése és összehasonlítása

Hozz létre egy saját modellértékelő szkriptet a 03-as mintán alapulva:

```cmd
REM create_model_test.cmd
@echo off
echo Model Discovery and Testing Script
echo =====================================

echo.
echo Step 1: List available models
foundry model list

echo.
echo Step 2: Check what's cached
foundry cache list

echo.
echo Step 3: Start phi-4-mini for testing
foundry model run phi-4-mini --verbose

echo.
echo Step 4: Test with a simple prompt
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello, please introduce yourself.\"}],\"max_tokens\":100}"

echo.
echo Model test complete!
```

### Feladatod

1. **Futtasd a 03-as minta szkriptet**: `samples\03\list_and_bench.cmd`
2. **Próbálj ki különböző modelleket**: Tesztelj legalább 3 különböző modellt
3. **Hasonlítsd össze a teljesítményt**: Jegyezd fel a sebesség és válaszminőség közötti különbségeket
4. **Dokumentáld az eredményeket**: Készíts egy egyszerű összehasonlító táblázatot

### Példa összehasonlítási formátum

```
Model Comparison Results:
========================
phi-4-mini:        Fast (~2s), good for general chat
qwen2.5-7b:       Slower (~5s), better reasoning  
deepseek-r1:      Medium (~3s), excellent for code

Recommendation: Start with phi-4-mini for development, 
switch to qwen2.5-7b for production reasoning tasks.
```

## 7. rész: Hibakeresés és legjobb gyakorlatok

### Gyakori problémák és megoldások

**A modell nem indul el:**
```cmd
REM Check service status
foundry service status

REM Restart service if needed
foundry service stop
foundry service start

REM Try with verbose output
foundry model run phi-4-mini --verbose
```

**Elégtelen memória:**
- Kezdd kisebb modellekkel (`phi-4-mini`)
- Zárd be a többi alkalmazást
- Frissítsd a RAM-ot, ha gyakran elérsz korlátokat

**Lassú teljesítmény:**
- Győződj meg róla, hogy a modell teljesen betöltődött (ellenőrizd a részletes kimenetet)
- Zárd be a felesleges háttéralkalmazásokat
- Fontold meg gyorsabb tároló használatát (SSD)

### Legjobb gyakorlatok

1. **Kezdd kicsiben**: Használd a `phi-4-mini` modellt a beállítás ellenőrzéséhez
2. **Egyszerre egy modell**: Állítsd le az előző modellt, mielőtt újat indítasz
3. **Erőforrások figyelése**: Kövesd nyomon a memóriahasználatot
4. **Konzisztens tesztelés**: Ugyanazokat a promptokat használd a tisztességes összehasonlításhoz
5. **Eredmények dokumentálása**: Jegyezd fel a modellek teljesítményét az adott felhasználási esetekhez

## 8. rész: Következő lépések és hivatkozások

### Felkészülés a 4. szekcióra

- **A 4. szekció fókusza**: Optimalizációs eszközök és technikák
- **Előfeltételek**: Magabiztos modellváltás és alapvető teljesítménytesztelés
- **Ajánlott**: Azonosíts 2-3 kedvenc modellt ebből a szekcióból

### További források

- **[Foundry Local dokumentáció](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: Hivatalos dokumentáció
- **[CLI referencia](https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli)**: Teljes parancsreferencia
- **[Model Mondays](https://aka.ms/model-mondays)**: Heti modellbemutatók
- **[Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)**: Közösség és problémák
- **[03-as minta: Modellfelfedezés](samples/03/README.md)**: Gyakorlati példa szkript

### Főbb tanulságok

✅ **Modellfelfedezés**: Használd a `foundry model list` parancsot a modellek felfedezéséhez  
✅ **Gyors tesztelés**: A `list_and_bench.cmd` mintázat gyors értékeléshez  
✅ **Teljesítményfigyelés**: Alapvető erőforráshasználat és válaszidő mérése  
✅ **Modellválasztás**: Gyakorlati irányelvek a modellek kiválasztásához felhasználási esetek alapján  
✅ **Gyorsítótár kezelés**: Tárolási és tisztítási eljárások megértése  

Most már rendelkezel a gyakorlati készségekkel, hogy felfedezd, teszteld és kiválaszd a megfelelő modelleket AI alkalmazásaidhoz a Foundry Local egyszerű CLI megközelítésével.

Hivatkozások:
- Foundry Local dokumentáció: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Hugging Face modellek fordítása: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Model Mondays: https://aka.ms/model-mondays
- Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

## Tanulási célok
- Nyílt forráskódú modellek felfedezése és értékelése helyi inferenciához
- Hugging Face modellek fordítása és futtatása a Foundry Local-ban
- Modellválasztási stratégiák alkalmazása pontosság, késleltetés és erőforrásigény alapján
- Modellek helyi kezelése gyorsítótárral és verziókezeléssel

## 1. rész: Modellfelfedezés a Foundry CLI segítségével

### Alapvető modellkezelési parancsok

A Foundry CLI egyszerű parancsokat kínál a modellek felfedezéséhez és kezeléséhez:

```cmd
REM List all available models in the catalog
foundry model list

REM List cached (downloaded) models
foundry cache list

REM Check cache directory location
foundry cache ls
```

### Első modellek futtatása

Kezdd népszerű, jól tesztelt modellekkel, hogy megértsd a teljesítményjellemzőket:

```cmd
REM Run Phi-4-Mini (lightweight, fast)
foundry model run phi-4-mini --verbose

REM Run Qwen 2.5 7B (larger, more capable)
foundry model run qwen2.5-7b --verbose

REM Run DeepSeek (specialized for coding)
foundry model run deepseek-r1-7b --verbose
```

**Megjegyzés:** A `--verbose` kapcsoló részletes indítási információkat nyújt, beleértve:
- Modellletöltési folyamatot (első futtatáskor)
- Memóriaallokáció részleteit
- Szolgáltatás-hozzárendelési információkat
- Teljesítmény-inicializációs metrikákat

### Modellkategóriák megértése

**Kis nyelvi modellek (SLM-ek):**
- `phi-4-mini`: Gyors, hatékony, általános csevegéshez kiváló
- `phi-4`: Fejlettebb verzió, jobb érvelési képességekkel

**Közepes modellek:**
- `qwen2.5-7b`: Kiváló érvelés és hosszabb kontextus
- `deepseek-r1-7b`: Kódgenerálásra optimalizált

**Nagyobb modellek:**
- `llama-3.2`: A Meta legújabb nyílt forráskódú modellje
- `qwen2.5-14b`: Vállalati szintű érvelés

## 2. rész: Gyors modelltesztelés és összehasonlítás

### 03-as minta megközelítés: Egyszerű lista és teszt

A 03-as minta alapján itt van a minimális munkafolyamat:

```cmd
@echo off
REM Sample 03 - List and bench pattern
echo Listing available models...
foundry model list

echo.
echo Checking cached models...
foundry cache list

echo.
echo Starting phi-4-mini with verbose output...
foundry model run phi-4-mini --verbose
```

### Modell teljesítményének tesztelése

Amint egy modell fut, teszteld konzisztens promptokkal:

```cmd
REM Test via curl (Windows Command Prompt)
curl -X POST http://localhost:8000/v1/chat/completions ^
  -H "Content-Type: application/json" ^
  -d "{\"model\":\"phi-4-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain edge AI in one sentence.\"}],\"max_tokens\":50}"
```

### PowerShell tesztelési alternatíva

```powershell
# PowerShell approach for testing
$body = @{
    model = "phi-4-mini"
    messages = @(
        @{
            role = "user"
            content = "Explain edge AI in one sentence."
        }
    )
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/v1/chat/completions" -Method Post -Body $body -ContentType "application/json"
```

## 3. rész: Modell gyorsítótár és tárolás kezelése

### A modell gyorsítótár megértése

A Foundry Local automatikusan kezeli a modellletöltéseket és gyorsítótárazást:

```cmd
REM Check cache directory and contents
foundry cache ls

REM View cache location
foundry cache cd

REM Clean up unused models (if needed)
foundry cache clean
```

### Modell tárolási szempontok

**Tipikus modellméretek:**
- `phi-4-mini`: ~2.5 GB
- `qwen2.5-7b`: ~4.1 GB  
- `deepseek-r1-7b`: ~4.3 GB
- `llama-3.2`: ~4.9 GB
- `qwen2.5-14b`: ~8.2 GB

**Tárolási legjobb gyakorlatok:**
- Tarts 2-3 modellt gyorsítótárban a gyors váltáshoz
- Távolítsd el a nem használt modelleket hely felszabadításához: `foundry cache clean`
- Figyeld a lemezhasználatot, különösen kisebb SSD-k esetén
- Fontold meg a modellméret és képesség közötti kompromisszumokat

### Modell teljesítményfigyelés

Amíg a modellek futnak, figyeld a rendszer erőforrásait:

**Windows Feladatkezelő:**
- Figyeld a memóriahasználatot (a modellek RAM-ban maradnak betöltve)
- Kövesd a CPU kihasználtságot inferencia közben
- Ellenőrizd a lemez I/O-t a modell betöltésekor

**Parancssoros figyelés:**
```cmd
REM Check memory usage (PowerShell)
Get-Process | Where-Object {$_.ProcessName -like "*foundry*"} | Select-Object ProcessName, WorkingSet64

REM Monitor running models
foundry service ps
```

## 4. rész: Gyakorlati modellválasztási irányelvek

### Modellek kiválasztása felhasználási esetek szerint

**Általános csevegéshez és kérdés-válaszhoz:**
- Kezdés: `phi-4-mini` (gyors, hatékony)
- Frissítés: `phi-4` (jobb érvelés)
- Haladó: `qwen2.5-7b` (hosszabb kontextus)

**Kódgeneráláshoz:**
- Ajánlott: `deepseek-r1-7b`
- Alternatíva: `qwen2.5-7b` (kódhoz is jó)

**Komplex érveléshez:**
- Legjobb: `qwen2.5-7b` vagy `qwen2.5-14b`
- Költséghatékony opció: `phi-4`

### Hardverkövetelmények útmutatója

**Minimális rendszerkövetelmények:**
```
phi-4-mini:     8GB RAM,  entry-level CPU
phi-4:         12GB RAM,  mid-range CPU
qwen2.5-7b:    16GB RAM,  mid-range CPU
deepseek-r1:   16GB RAM,  mid-range CPU
qwen2.5-14b:   24GB RAM,  high-end CPU
```

**Ajánlott a legjobb teljesítményhez:**
- 32GB+ RAM a kényelmes többmodell váltáshoz
- SSD tárolás a gyorsabb modellbetöltéshez
- Modern CPU jó egyszálas teljesítménnyel
- NPU támogatás (Windows 11 Copilot+ PC-k) gyorsításhoz

### Modellváltási munkafolyamat

```cmd
REM Stop current model (if needed)
foundry service stop

REM Start different model
foundry model run qwen2.5-7b

REM Verify model is running
foundry service status
```

## 5. rész: Egyszerű modellértékelés

### Alapvető teljesítménytesztelés

Itt van egy egyszerű megközelítés a modell teljesítményének összehasonlításához:

```python
# simple_bench.py - Based on Sample 03 patterns
import time
import requests
import json

def test_model_response(model_name, prompt="Explain edge AI in one sentence."):
    """Test a single model with a prompt and measure response time."""
    start_time = time.time()
    
    try:
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 64
            },
            timeout=30
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            return {
                "model": model_name,
                "latency_sec": round(elapsed, 3),
                "response": result["choices"][0]["message"]["content"],
                "status": "success"
            }
        else:
            return {
                "model": model_name,
                "status": "error",
                "error": f"HTTP {response.status_code}"
            }
            
    except Exception as e:
        return {
            "model": model_name,
            "status": "error", 
            "error": str(e)
        }

# Test the currently running model
if __name__ == "__main__":
    # Test with different models (start each model first)
    test_models = ["phi-4-mini", "qwen2.5-7b", "deepseek-r1-7b"]
    
    print("Model Performance Test")
    print("=" * 50)
    
    for model in test_models:
        print(f"\nTesting {model}...")
        print("Note: Make sure this model is running first with 'foundry model run {model}'")
        
        result = test_model_response(model)
        
        if result["status"] == "success":
            print(f"✅ {model}: {result['latency_sec']}s")
            print(f"   Response: {result['response'][:100]}...")
        else:
            print(f"❌ {model}: {result['error']}")
```

### Manuális minőségértékelés

Minden modell esetében tesztelj konzisztens promptokkal, és értékeld manuálisan:

**Teszt promptok:**
1. "Magyarázd el a kvantumszámítást egyszerűen."
2. "Írj egy Python függvényt lista rendezésére."
3. "Mik az otthoni munkavégzés előnyei és hátrányai?"
4. "Foglalj össze az edge AI előnyeit."

**Értékelési kritériumok:**
- **Pontosság**: Helyes az információ?
- **Érthetőség**: Könnyen érthető a magyarázat?
- **Teljesség**: Teljesen válaszol a kérdésre?
- **Sebesség**: Milyen gyorsan válaszol?

### Erőforrás-használat figyelése

```cmd
REM Monitor while testing different models
REM Start model
foundry model run phi-4-mini

REM In another terminal, monitor resources
foundry service status
foundry service ps

REM Check system resources (PowerShell)
Get-Process | Where-Object ProcessName -Like "*foundry*" | Format-Table ProcessName, WorkingSet64, CPU
```

## 6. rész: Következő lépések
- Iratkozz fel a Model Mondays-re új modellekért és tippekért: https://aka.ms/model-mondays
- Oszd meg eredményeidet a csapatod `models.json` fájljában
- Készülj a 4. szekcióra: LLM-ek és SLM-ek összehasonlítása, helyi és felhő alapú inferencia, valamint gyakorlati bemutatók

---

**Felelősség kizárása**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI fordítási szolgáltatás segítségével került lefordításra. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelvén tekintendő hiteles forrásnak. Kritikus információk esetén javasolt professzionális emberi fordítást igénybe venni. Nem vállalunk felelősséget semmilyen félreértésért vagy téves értelmezésért, amely a fordítás használatából eredhet.