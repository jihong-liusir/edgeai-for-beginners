<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T13:41:35+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "de"
}
-->
# Abschnitt 3: Fine-Tuning - Modelle für spezifische Aufgaben anpassen

## Inhaltsverzeichnis
1. [Einführung in Fine-Tuning](../../../Module05)
2. [Warum Fine-Tuning wichtig ist](../../../Module05)
3. [Arten des Fine-Tunings](../../../Module05)
4. [Fine-Tuning mit Microsoft Olive](../../../Module05)
5. [Praktische Beispiele](../../../Module05)
6. [Best Practices und Richtlinien](../../../Module05)
7. [Fortgeschrittene Techniken](../../../Module05)
8. [Evaluierung und Überwachung](../../../Module05)
9. [Häufige Herausforderungen und Lösungen](../../../Module05)
10. [Fazit](../../../Module05)

## Einführung in Fine-Tuning

**Fine-Tuning** ist eine leistungsstarke Technik des maschinellen Lernens, bei der ein vortrainiertes Modell angepasst wird, um spezifische Aufgaben zu erfüllen oder mit spezialisierten Datensätzen zu arbeiten. Anstatt ein Modell von Grund auf neu zu trainieren, nutzt Fine-Tuning das bereits erlernte Wissen eines vortrainierten Modells und passt es an Ihren spezifischen Anwendungsfall an.

### Was ist Fine-Tuning?

Fine-Tuning ist eine Form des **Transfer-Learnings**, bei der Sie:
- Mit einem vortrainierten Modell beginnen, das allgemeine Muster aus großen Datensätzen gelernt hat
- Die internen Parameter des Modells mit Ihrem spezifischen Datensatz anpassen
- Das wertvolle Wissen beibehalten und das Modell für Ihre Aufgabe spezialisieren

Stellen Sie sich vor, Sie bringen einem erfahrenen Koch bei, eine neue Küche zu kochen – er versteht bereits die Grundlagen des Kochens, muss aber spezifische Techniken und Geschmacksrichtungen für den neuen Stil lernen.

### Hauptvorteile

- **Zeitersparnis**: Deutlich schneller als ein Training von Grund auf
- **Effiziente Datennutzung**: Benötigt kleinere Datensätze, um gute Ergebnisse zu erzielen
- **Kosteneffektiv**: Geringere Anforderungen an Rechenleistung
- **Bessere Leistung**: Erzielt oft bessere Ergebnisse im Vergleich zum Training von Grund auf
- **Ressourcenoptimierung**: Macht leistungsstarke KI für kleinere Teams und Organisationen zugänglich

## Warum Fine-Tuning wichtig ist

### Anwendungen in der Praxis

Fine-Tuning ist in zahlreichen Szenarien unverzichtbar:

**1. Domänenanpassung**
- Medizinische KI: Anpassung allgemeiner Sprachmodelle an medizinische Terminologie und klinische Notizen
- Legal Tech: Spezialisierung von Modellen für die Analyse von juristischen Dokumenten und Vertragsprüfung
- Finanzdienstleistungen: Anpassung von Modellen für die Analyse von Finanzberichten und Risikobewertung

**2. Aufgaben-Spezialisierung**
- Inhaltserstellung: Fine-Tuning für spezifische Schreibstile oder Tonalitäten
- Code-Generierung: Anpassung von Modellen für bestimmte Programmiersprachen oder Frameworks
- Übersetzung: Verbesserung der Leistung für spezifische Sprachpaare oder technische Domänen

**3. Unternehmensanwendungen**
- Kundenservice: Erstellung von Chatbots, die unternehmensspezifische Terminologie verstehen
- Interne Dokumentation: Aufbau von KI-Assistenten, die mit organisatorischen Prozessen vertraut sind
- Branchenspezifische Lösungen: Entwicklung von Modellen, die branchenspezifischen Jargon und Workflows verstehen

## Arten des Fine-Tunings

### 1. Vollständiges Fine-Tuning (Instruction Fine-Tuning)

Beim vollständigen Fine-Tuning werden alle Modellparameter während des Trainings aktualisiert. Dieser Ansatz:
- Bietet maximale Flexibilität und Leistungspotenzial
- Erfordert erhebliche Rechenressourcen
- Führt zu einer komplett neuen Version des Modells
- Ist ideal für Szenarien mit umfangreichen Trainingsdaten und Rechenkapazitäten

### 2. Parameter-Effizientes Fine-Tuning (PEFT)

PEFT-Methoden aktualisieren nur einen kleinen Teil der Parameter, wodurch der Prozess effizienter wird:

#### Low-Rank Adaptation (LoRA)
- Fügt kleine trainierbare Rangzerlegungsmatrizen zu bestehenden Gewichten hinzu
- Reduziert die Anzahl der trainierbaren Parameter erheblich
- Erhält die Leistung nahe am vollständigen Fine-Tuning
- Ermöglicht einfaches Umschalten zwischen verschiedenen Anpassungen

#### QLoRA (Quantized LoRA)
- Kombiniert LoRA mit Quantisierungstechniken
- Reduziert den Speicherbedarf weiter
- Ermöglicht das Fine-Tuning größerer Modelle auf Consumer-Hardware
- Balanciert Effizienz und Leistung

#### Adapter
- Fügt kleine neuronale Netzwerke zwischen bestehende Schichten ein
- Ermöglicht gezieltes Fine-Tuning, während das Basismodell eingefroren bleibt
- Unterstützt einen modularen Ansatz zur Modellanpassung

### 3. Aufgaben-Spezifisches Fine-Tuning

Konzentriert sich auf die Anpassung von Modellen für spezifische Downstream-Aufgaben:
- **Klassifikation**: Anpassung von Modellen für Kategorisierungsaufgaben
- **Generierung**: Optimierung für Inhaltserstellung und Textgenerierung
- **Extraktion**: Fine-Tuning für Informationsgewinnung und Named Entity Recognition
- **Zusammenfassung**: Spezialisierung von Modellen für Dokumentzusammenfassungen

## Fine-Tuning mit Microsoft Olive

Microsoft Olive ist ein umfassendes Toolkit zur Modelloptimierung, das den Fine-Tuning-Prozess vereinfacht und gleichzeitig Funktionen auf Unternehmensniveau bietet.

### Was ist Microsoft Olive?

Microsoft Olive ist ein Open-Source-Tool zur Modelloptimierung, das:
- Fine-Tuning-Workflows für verschiedene Hardware-Ziele vereinfacht
- Eingebaute Unterstützung für beliebte Modellarchitekturen bietet (Llama, Phi, Qwen, Gemma)
- Sowohl Cloud- als auch lokale Bereitstellungsoptionen bietet
- Nahtlos mit Azure ML und anderen Microsoft AI-Diensten integriert ist
- Automatische Optimierung und Quantisierung unterstützt

### Hauptfunktionen

- **Hardware-Bewusste Optimierung**: Optimiert Modelle automatisch für spezifische Hardware (CPU, GPU, NPU)
- **Multi-Format-Unterstützung**: Funktioniert mit PyTorch-, Hugging Face- und ONNX-Modellen
- **Automatisierte Workflows**: Reduziert manuelle Konfiguration und Trial-and-Error
- **Unternehmensintegration**: Eingebaute Unterstützung für Azure ML und Cloud-Bereitstellungen
- **Erweiterbare Architektur**: Ermöglicht benutzerdefinierte Optimierungstechniken

### Installation und Einrichtung

#### Basisinstallation

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Optionale Abhängigkeiten

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Installation überprüfen

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Praktische Beispiele

### Beispiel 1: Einfaches Fine-Tuning mit Olive CLI

Dieses Beispiel zeigt das Fine-Tuning eines kleinen Sprachmodells für die Phrasenkategorisierung:

#### Schritt 1: Umgebung vorbereiten

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Schritt 2: Modell feinabstimmen

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Schritt 3: Für die Bereitstellung optimieren

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Beispiel 2: Erweiterte Konfiguration mit benutzerdefiniertem Datensatz

#### Schritt 1: Benutzerdefinierten Datensatz vorbereiten

Erstellen Sie eine JSON-Datei mit Ihren Trainingsdaten:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Schritt 2: Konfigurationsdatei erstellen

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Schritt 3: Fine-Tuning ausführen

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Beispiel 3: QLoRA Fine-Tuning für Speicher-Effizienz

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Best Practices und Richtlinien

### Datenvorbereitung

**1. Qualität vor Quantität**
- Priorisieren Sie hochwertige, vielfältige Beispiele gegenüber großen Mengen schlechter Daten
- Stellen Sie sicher, dass die Daten repräsentativ für Ihren Anwendungsfall sind
- Reinigen und verarbeiten Sie die Daten konsistent

**2. Datenformat und Vorlagen**
- Verwenden Sie einheitliche Formatierung für alle Trainingsbeispiele
- Erstellen Sie klare Input-Output-Vorlagen, die zu Ihrem Anwendungsfall passen
- Integrieren Sie geeignete Instruktionsformatierungen für instruktionsabgestimmte Modelle

**3. Datensatzaufteilung**
- Reservieren Sie 10-20 % der Daten für die Validierung
- Halten Sie ähnliche Verteilungen über Trainings-/Validierungssplits hinweg aufrecht
- Ziehen Sie eine stratifizierte Stichprobenziehung für Klassifikationsaufgaben in Betracht

### Trainingskonfiguration

**1. Auswahl der Lernrate**
- Beginnen Sie mit kleineren Lernraten (1e-5 bis 1e-4) für das Fine-Tuning
- Verwenden Sie Lernraten-Scheduling für bessere Konvergenz
- Überwachen Sie Verlustkurven, um die Raten entsprechend anzupassen

**2. Optimierung der Batch-Größe**
- Balancieren Sie die Batch-Größe mit verfügbarem Speicher
- Verwenden Sie Gradientenakkumulation für größere effektive Batch-Größen
- Berücksichtigen Sie die Beziehung zwischen Batch-Größe und Lernrate

**3. Trainingsdauer**
- Überwachen Sie Validierungsmetriken, um Überanpassung zu vermeiden
- Verwenden Sie Early Stopping, wenn die Validierungsleistung stagniert
- Speichern Sie regelmäßig Checkpoints zur Wiederherstellung und Analyse

### Modellauswahl

**1. Wahl des Basismodells**
- Wählen Sie Modelle, die auf ähnlichen Domänen vortrainiert wurden, wenn möglich
- Berücksichtigen Sie die Modellgröße im Verhältnis zu Ihren Rechenkapazitäten
- Bewerten Sie Lizenzanforderungen für kommerzielle Nutzung

**2. Auswahl der Fine-Tuning-Methode**
- Verwenden Sie LoRA/QLoRA für ressourcenbeschränkte Umgebungen
- Wählen Sie vollständiges Fine-Tuning, wenn maximale Leistung entscheidend ist
- Ziehen Sie adapterbasierte Ansätze für mehrere Aufgaben in Betracht

### Ressourcenmanagement

**1. Hardware-Optimierung**
- Wählen Sie geeignete Hardware für Ihre Modellgröße und Methode
- Nutzen Sie GPU-Speicher effizient mit Gradienten-Checkpointing
- Ziehen Sie Cloud-basierte Lösungen für größere Modelle in Betracht

**2. Speicherverwaltung**
- Verwenden Sie Mixed-Precision-Training, wenn verfügbar
- Implementieren Sie Gradientenakkumulation bei Speicherbeschränkungen
- Überwachen Sie die GPU-Speichernutzung während des Trainings

## Fortgeschrittene Techniken

### Multi-Adapter-Training

Trainieren Sie mehrere Adapter für verschiedene Aufgaben, während das Basismodell geteilt wird:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparameter-Optimierung

Führen Sie systematische Hyperparameter-Tuning durch:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Benutzerdefinierte Verlustfunktionen

Implementieren Sie domänenspezifische Verlustfunktionen:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluierung und Überwachung

### Metriken und Evaluierung

**1. Standardmetriken**
- **Genauigkeit**: Gesamte Korrektheit für Klassifikationsaufgaben
- **Perplexität**: Qualitätsmaß für Sprachmodellierung
- **BLEU/ROUGE**: Qualität der Textgenerierung und Zusammenfassung
- **F1-Score**: Ausgewogene Präzision und Recall für Klassifikation

**2. Domänenspezifische Metriken**
- **Aufgabenspezifische Benchmarks**: Verwenden Sie etablierte Benchmarks für Ihre Domäne
- **Menschliche Bewertung**: Einschließen menschlicher Bewertungen für subjektive Aufgaben
- **Geschäftsmetriken**: Abstimmung mit tatsächlichen Geschäftszielen

**3. Evaluierungssetup**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Überwachung des Trainingsfortschritts

**1. Verlustverfolgung**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validierungsüberwachung**
- Verfolgen Sie Validierungsverlust parallel zum Trainingsverlust
- Überwachen Sie Anzeichen von Überanpassung (Validierungsverlust steigt, während Trainingsverlust sinkt)
- Verwenden Sie Early Stopping basierend auf Validierungsmetriken

**3. Ressourcenüberwachung**
- Überwachen Sie GPU-/CPU-Auslastung
- Verfolgen Sie Speicherverbrauchsmuster
- Überwachen Sie Trainingsgeschwindigkeit und Durchsatz

## Häufige Herausforderungen und Lösungen

### Herausforderung 1: Überanpassung

**Symptome:**
- Trainingsverlust sinkt weiter, während Validierungsverlust steigt
- Große Lücke zwischen Trainings- und Validierungsleistung
- Schlechte Generalisierung auf neue Daten

**Lösungen:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Herausforderung 2: Speicherbeschränkungen

**Lösungen:**
- Verwenden Sie Gradienten-Checkpointing
- Implementieren Sie Gradientenakkumulation
- Wählen Sie parameter-effiziente Methoden (LoRA, QLoRA)
- Nutzen Sie Modellparallelismus für große Modelle

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Herausforderung 3: Langsames Training

**Lösungen:**
- Optimieren Sie Datenladepipelines
- Verwenden Sie Mixed-Precision-Training
- Implementieren Sie effiziente Batch-Strategien
- Ziehen Sie verteiltes Training für große Datensätze in Betracht

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Herausforderung 4: Schlechte Leistung

**Diagnoseschritte:**
1. Überprüfen Sie Datenqualität und Formatierung
2. Überprüfen Sie Lernrate und Trainingsdauer
3. Bewerten Sie die Wahl des Basismodells
4. Überprüfen Sie Vorverarbeitung und Tokenisierung

**Lösungen:**
- Erhöhen Sie die Vielfalt der Trainingsdaten
- Passen Sie den Lernratenplan an
- Probieren Sie verschiedene Basismodelle aus
- Implementieren Sie Datenaugmentierungstechniken

## Fazit

Fine-Tuning ist eine leistungsstarke Technik, die den Zugang zu modernsten KI-Fähigkeiten demokratisiert. Mit Tools wie Microsoft Olive können Organisationen vortrainierte Modelle effizient an ihre spezifischen Bedürfnisse anpassen und gleichzeitig Leistung und Ressourcen optimieren.

### Wichtige Erkenntnisse

1. **Wählen Sie den richtigen Ansatz**: Wählen Sie Fine-Tuning-Methoden basierend auf Ihren Rechenressourcen und Leistungsanforderungen
2. **Datenqualität zählt**: Investieren Sie in hochwertige, repräsentative Trainingsdaten
3. **Überwachen und iterieren**: Evaluieren und verbessern Sie Ihre Modelle kontinuierlich
4. **Nutzen Sie Tools**: Verwenden Sie Frameworks wie Olive, um den Prozess zu vereinfachen und zu optimieren
5. **Bereitstellung berücksichtigen**: Planen Sie Modelloptimierung und Bereitstellung von Anfang an

## ➡️ Was kommt als Nächstes?

- [04: Bereitstellung - Produktionsreife Modellimplementierung](./04.SLMOps.Deployment.md)

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für kritische Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.