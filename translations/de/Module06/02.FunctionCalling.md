<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-17T13:05:06+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "de"
}
-->
# Abschnitt02: Funktionsaufrufe in Small Language Models (SLMs)

## Inhaltsverzeichnis
1. [Was ist ein Funktionsaufruf?](../../../Module06)
2. [Wie Funktionsaufrufe funktionieren](../../../Module06)
3. [Anwendungsszenarien](../../../Module06)
4. [Einrichtung von Funktionsaufrufen mit Phi-4-mini und Ollama](../../../Module06)
5. [Arbeiten mit Qwen3-Funktionsaufrufen](../../../Module06)
6. [Foundry Local Integration](../../../Module06)
7. [Best Practices und Fehlerbehebung](../../../Module06)
8. [Erweiterte Beispiele](../../../Module06)

## Was ist ein Funktionsaufruf?

Ein Funktionsaufruf ist eine leistungsstarke Fähigkeit, die es Small Language Models (SLMs) ermöglicht, mit externen Tools, APIs und Diensten zu interagieren. Anstatt auf ihre Trainingsdaten beschränkt zu sein, können SLMs nun:

- **Mit externen APIs verbinden** (Wetterdienste, Datenbanken, Suchmaschinen)
- **Spezifische Funktionen ausführen**, basierend auf Benutzeranfragen
- **Echtzeitinformationen abrufen** aus verschiedenen Quellen
- **Rechenaufgaben durchführen** mithilfe spezialisierter Tools
- **Mehrere Operationen verketten**, um komplexe Workflows zu erstellen

Diese Fähigkeit verwandelt SLMs von statischen Textgeneratoren in dynamische KI-Agenten, die reale Aufgaben ausführen können.

## Wie Funktionsaufrufe funktionieren

Der Prozess eines Funktionsaufrufs folgt einem systematischen Workflow:

### 1. Tool-Integration
- **Externe Tools**: SLMs können sich mit Wetter-APIs, Datenbanken, Webdiensten und anderen externen Systemen verbinden.
- **Funktionsdefinitionen**: Jedes Tool wird mit spezifischen Parametern, Ein-/Ausgabeformaten und Beschreibungen definiert.
- **API-Kompatibilität**: Tools werden über standardisierte Schnittstellen (REST-APIs, SDKs usw.) integriert.

### 2. Funktionsdefinition
Funktionen werden mit drei Hauptkomponenten definiert:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Intent-Erkennung
- **Natürliche Sprachverarbeitung**: Das SLM analysiert Benutzereingaben, um die Absicht zu verstehen.
- **Funktionszuordnung**: Bestimmt, welche Funktion(en) benötigt werden, um die Anfrage zu erfüllen.
- **Parameterextraktion**: Identifiziert und extrahiert die erforderlichen Parameter aus der Nachricht des Benutzers.

### 4. JSON-Ausgabeerstellung
Das SLM generiert eine strukturierte JSON-Datei, die Folgendes enthält:
- Den Namen der aufzurufenden Funktion
- Erforderliche Parameter mit entsprechenden Werten
- Ausführungskontext und Metadaten

### 5. Externe Ausführung
- **Parameterüberprüfung**: Stellt sicher, dass alle erforderlichen Parameter vorhanden und korrekt formatiert sind.
- **Funktionsausführung**: Die Anwendung führt die angegebene Funktion mit den bereitgestellten Parametern aus.
- **Fehlerbehandlung**: Verarbeitet Fehler, Zeitüberschreitungen und ungültige Antworten.

### 6. Antwortintegration
- **Ergebnisverarbeitung**: Die Ausgabe der Funktion wird an das SLM zurückgegeben.
- **Kontextintegration**: Das SLM integriert die Ergebnisse in seine Antwort.
- **Benutzerkommunikation**: Präsentiert die Informationen in einem natürlichen, konversationellen Format.

## Anwendungsszenarien

### Datenabruf
Natürliche Sprachabfragen in strukturierte API-Aufrufe umwandeln:
- **"Zeige meine letzten Bestellungen"** → Datenbankabfrage mit Benutzer-ID und Datumsfiltern
- **"Wie ist das Wetter in Tokio?"** → Wetter-API-Aufruf mit Standortparameter
- **"Finde E-Mails von John letzte Woche"** → E-Mail-Dienstabfrage mit Absender- und Datumsfiltern

### Ausführung von Operationen
Benutzeranfragen in spezifische Funktionsaufrufe umwandeln:
- **"Plane ein Meeting für morgen um 14 Uhr"** → Kalender-API-Integration
- **"Sende eine Nachricht an das Team"** → Kommunikationsplattform-API
- **"Erstelle ein Backup meiner Dateien"** → Dateisystemoperation

### Rechenaufgaben
Komplexe mathematische oder logische Operationen durchführen:
- **"Berechne den Zinseszins für 10.000 $ bei 5 % für 10 Jahre"** → Finanzberechnungsfunktion
- **"Analysiere diesen Datensatz auf Trends"** → Statistische Analysetools
- **"Optimiere diese Route für die Lieferung"** → Routenoptimierungsalgorithmen

### Datenverarbeitungs-Workflows
Mehrere Funktionsaufrufe für komplexe Operationen verketten:
1. **Daten abrufen** aus mehreren Quellen
2. **Informationen analysieren und validieren**
3. **Daten in das erforderliche Format umwandeln**
4. **Ergebnisse speichern** in geeigneten Systemen
5. **Berichte oder Visualisierungen erstellen**

### UI/UX-Integration
Dynamische Schnittstellenaktualisierungen ermöglichen:
- **"Zeige Verkaufsdaten im Dashboard"** → Diagrammerstellung und Anzeige
- **"Aktualisiere die Karte mit neuen Standorten"** → Geodatenintegration
- **"Aktualisiere die Bestandsanzeige"** → Echtzeit-Datensynchronisation

## Einrichtung von Funktionsaufrufen mit Phi-4-mini und Ollama

Microsofts Phi-4-mini unterstützt sowohl einzelne als auch parallele Funktionsaufrufe über Ollama. So richten Sie es ein:

### Voraussetzungen
- Ollama Version 0.5.13 oder höher
- Phi-4-mini-Modell (empfohlen: `phi4-mini:3.8b-fp16`)

### Installationsschritte

#### 1. Phi-4-mini installieren und ausführen
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Benutzerdefinierte ModelFile-Vorlage erstellen
Aufgrund aktueller Einschränkungen in Ollamas Standardvorlagen müssen Sie eine benutzerdefinierte ModelFile mit der folgenden Vorlage erstellen:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Benutzerdefiniertes Modell erstellen
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Beispiel für einen einzelnen Funktionsaufruf

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Beispiel für parallele Funktionsaufrufe

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Arbeiten mit Qwen3-Funktionsaufrufen

Qwen3 bietet fortschrittliche Funktionsaufrufmöglichkeiten mit hervorragender Leistung und Flexibilität. So implementieren Sie es:

### Verwendung des Qwen-Agent-Frameworks

Qwen-Agent bietet ein High-Level-Framework, das die Implementierung von Funktionsaufrufen vereinfacht:

#### Installation
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Grundlegende Einrichtung

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Benutzerdefinierte Funktionsimplementierung

Sie können auch benutzerdefinierte Funktionen für Qwen3 definieren:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Erweiterte Qwen3-Funktionen

#### Steuerung des Denkmodus
Qwen3 unterstützt das dynamische Umschalten zwischen Denk- und Nicht-Denk-Modus:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Mehrstufige Funktionsaufrufe
Qwen3 ist hervorragend darin, mehrere Funktionsaufrufe zu verketten:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Foundry Local Integration

Microsofts Foundry Local bietet eine OpenAI-kompatible API, um Modelle lokal mit verbesserter Privatsphäre und Leistung auszuführen.

### Einrichtung und Installation

#### Windows
Laden Sie den Installer von der [Foundry Local Releases-Seite](https://github.com/microsoft/Foundry-Local/releases) herunter und folgen Sie den Installationsanweisungen.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Grundlegende Nutzung

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Erweiterte Foundry Local-Funktionen

#### Modellverwaltung
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Leistungsoptimierung
Foundry Local wählt automatisch die beste Modellvariante für Ihre Hardware aus:
- **CUDA GPU**: Lädt GPU-optimierte Modelle herunter
- **Qualcomm NPU**: Verwendet NPU-beschleunigte Varianten
- **Nur CPU**: Wählt CPU-optimierte Modelle

## Best Practices und Fehlerbehebung

### Best Practices für Funktionsdefinitionen

#### 1. Klare und beschreibende Benennung
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Umfassende Parameterdefinitionen
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Eingabevalidierung und Fehlerbehandlung
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Häufige Probleme und Lösungen

#### Problem 1: Funktion wird nicht aufgerufen
**Symptome**: Modell antwortet mit Text statt die Funktion aufzurufen

**Lösungen**:
1. **Funktionsbeschreibung überprüfen**: Sicherstellen, dass sie klar zur Benutzerabsicht passt
2. **Parameterdefinitionen überprüfen**: Sicherstellen, dass alle erforderlichen Parameter korrekt definiert sind
3. **Systemaufforderung überprüfen**: Klare Anweisungen hinzufügen, wann Funktionen verwendet werden sollen
4. **Mit expliziten Anfragen testen**: Versuchen Sie "Bitte verwenden Sie die Wetterfunktion, um Daten für London abzurufen"

#### Problem 2: Falsche Parameter
**Symptome**: Funktion wird mit falschen oder fehlenden Parametern aufgerufen

**Lösungen**:
1. **Parameterbeispiele hinzufügen**: Beispielwerte in Parameterbeschreibungen einfügen
2. **Enum-Einschränkungen verwenden**: Parameterwerte auf spezifische Optionen beschränken, wenn möglich
3. **Fallback-Werte implementieren**: Sinnvolle Standardwerte für optionale Parameter bereitstellen

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Problem 3: Fehler bei parallelen Funktionsaufrufen
**Symptome**: Nur eine Funktion wird ausgeführt, obwohl mehrere ausgeführt werden sollten

**Lösungen**:
1. **Modellunterstützung überprüfen**: Sicherstellen, dass Ihr Modell parallele Funktionsaufrufe unterstützt
2. **Systemaufforderung aktualisieren**: "Einige Tools" oder "mehrere Tools" in die Systemnachricht aufnehmen
3. **Geeignete Modellversionen verwenden**: Phi-4-mini:3.8b-fp16 wird für Ollama empfohlen

#### Problem 4: Vorlagenprobleme mit Ollama
**Symptome**: Funktionsaufrufe funktionieren nicht mit der Standard-Ollama-Einrichtung

**Lösungen**:
1. **Benutzerdefinierte ModelFile verwenden**: Die in diesem Tutorial bereitgestellte korrigierte Vorlage anwenden
2. **Ollama aktualisieren**: Sicherstellen, dass Sie Version 0.5.13 oder höher verwenden
3. **Modellquantisierung überprüfen**: Höhere Quantisierungsstufen (Q8_0, fp16) funktionieren besser als stark quantisierte Versionen

### Leistungsoptimierung

#### 1. Effizientes Funktionsdesign
- **Funktionen fokussiert halten**: Jede Funktion sollte einen einzigen, klaren Zweck haben
- **Externe Abhängigkeiten minimieren**: API-Aufrufe und Netzwerkanforderungen reduzieren, wo möglich
- **Ergebnisse zwischenspeichern**: Häufig angeforderte Daten speichern, um Antwortzeiten zu verbessern

#### 2. Batch- und asynchrone Operationen
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Ressourcenmanagement
- **Verbindungs-Pooling**: Datenbank- und API-Verbindungen wiederverwenden
- **Rate-Limiting**: Angemessene Rate-Limits für externe APIs implementieren
- **Timeout-Behandlung**: Angemessene Timeouts für alle externen Aufrufe festlegen

## Erweiterte Beispiele

### Multi-Agent-Kollaborationssystem

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Dynamisches Tool-Auswahlsystem

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Standardergebnisformat für alle Funktionsaufrufe"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Produktionsbereiter KI-Agent mit umfassenden Funktionsaufrufmöglichkeiten"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Kernfunktionen initialisieren
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Alle verfügbaren Kernfunktionen registrieren"""
        
        # CRM-Funktionen
        self.register_function(
            name="get_customer_info",
            description="Kundeninformationen aus dem CRM abrufen",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # Aufrufe pro Minute
        )
        
        # Verkaufsfunktionen
        self.register_function(
            name="create_sales_opportunity",
            description="Neue Verkaufschance erstellen",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Analysefunktionen
        self.register_function(
            name="generate_sales_report",
            description="Verkaufsleistungsbericht erstellen",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Benachrichtigungsfunktionen
        self.register_function(
            name="send_notification",
            description="Benachrichtigung an Teammitglieder senden",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Neue Funktion beim Agenten registrieren"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Please provide the markdown file content you'd like me to translate into German.
"""Führe eine Funktion mit umfassender Fehlerbehandlung und Protokollierung aus"""
start_time = datetime.now()

try:
    # Überprüfen, ob die Funktion existiert
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Funktion '{function_name}' nicht gefunden",
            timestamp=start_time
        )
    
    # Überprüfen der Ratenbegrenzung
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Ratenbegrenzung für Funktion '{function_name}' überschritten",
            timestamp=start_time
        )
    
    # Validierung der Parameter
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Funktion ausführen
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Erfolgreiche Ausführung protokollieren
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Fehlgeschlagene Ausführung protokollieren
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Überprüfen, ob der Funktionsaufruf innerhalb der Ratenbegrenzung liegt"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Zähler zurücksetzen, wenn eine Minute vergangen ist
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Überprüfen, ob die Begrenzung eingehalten wird
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Validierung der Funktionsparameter"""
    func_params = self.functions[function_name]['parameters']
    
    # Überprüfen der erforderlichen Parameter
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Erforderlicher Parameter fehlt: {param_name}"
            )
    
    # Validierung der Parametertypen und Einschränkungen
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Typvalidierung
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' muss ein String sein"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' muss eine Zahl sein"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' muss ein Boolean sein"
                )
            
            # Enum-Validierung
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Parameter '{param_name}' muss einer der folgenden Werte sein: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Protokollierung des Funktionsaufrufs zu Audit-Zwecken"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Optionales Schreiben in ein externes Protokollierungssystem
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Schreiben des Protokolleintrags in ein externes Protokollierungssystem"""
    # Die Implementierung hängt von Ihrer Protokollierungsinfrastruktur ab
    # z. B. Senden an ELK-Stack, CloudWatch usw.
    pass

# Implementierungen von Geschäftslogikfunktionen
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Abrufen von Kundeninformationen aus dem CRM-System"""
    # Datenbank-/API-Aufruf simulieren
    await asyncio.sleep(0.1)  # Netzwerkverzögerung simulieren
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Produkt A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Produkt B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """Erstellen einer neuen Verkaufschance"""
    # CRM-API-Aufruf simulieren
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """Erstellen eines umfassenden Verkaufsberichts"""
    # Datenaggregation simulieren
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'medium', channel: str = 'email') -> Dict:
    """Senden einer Benachrichtigung über den angegebenen Kanal"""
    # Aufruf des Benachrichtigungsdienstes simulieren
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Abrufen von OpenAI-kompatiblen Funktionsdefinitionen für alle registrierten Funktionen"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Beispiel für die Nutzung in der Unternehmensintegration
async def enterprise_demo():
    """Demonstration der Fähigkeiten eines Unternehmens-AI-Agenten"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Beispiel 1: Bearbeitung von Kundenanfragen
    print("=== Bearbeitung von Kundenanfragen ===")
    
    # Abrufen von Kundeninformationen
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Kundeninformationen abgerufen: {result.data['name']}")
        print(f"Ausführungszeit: {result.execution_time:.3f}s")
    
    # Beispiel 2: Erstellung einer Verkaufschance
    print("\n=== Erstellung einer Verkaufschance ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Verkaufschance erstellt: {result.data['opportunity_id']}")
    
    # Beispiel 3: Batch-Operationen
    print("\n=== Batch-Operationen ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Neue Verkaufschance erstellt',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Aufgabe {i+1} erfolgreich abgeschlossen")
        else:
            print(f"Aufgabe {i+1} fehlgeschlagen: {result.error}")
    
    # Audit-Log anzeigen
    print(f"\n=== Audit-Log ({len(agent.audit_log)} Einträge) ===")
    for entry in agent.audit_log[-3:]:  # Zeige die letzten 3 Einträge
        print(f"{entry['timestamp']}: {entry['function_name']} - {'ERFOLG' if entry['success'] else 'FEHLGESCHLAGEN'}")

# Unternehmens-Demo ausführen
# asyncio.run(enterprise_demo())

## Fazit

Das Aufrufen von Funktionen in Small Language Models stellt einen Paradigmenwechsel dar: von statischen KI-Assistenten hin zu dynamischen, leistungsfähigen Agenten, die mit der realen Welt interagieren können. Dieses Tutorial hat behandelt:

### Wichtige Erkenntnisse

1. **Grundlagen verstehen**: Das Aufrufen von Funktionen ermöglicht es SLMs, über ihre Trainingsdaten hinauszugehen, indem sie sich mit externen Tools und Diensten verbinden.

2. **Flexibilität bei der Implementierung**: Es gibt verschiedene Ansätze, von Low-Level-Implementierungen mit benutzerdefinierten Vorlagen bis hin zu High-Level-Frameworks wie Qwen-Agent und Foundry Local.

3. **Produktionsrelevante Überlegungen**: Unternehmensbereitstellungen erfordern Aufmerksamkeit für Fehlerbehandlung, Ratenbegrenzung, Sicherheit und Audit-Protokollierung.

4. **Leistungsoptimierung**: Eine durchdachte Funktionsgestaltung, effiziente Ausführung und intelligentes Caching können die Antwortzeiten erheblich verbessern.

### Zukünftige Entwicklungen

Mit der Weiterentwicklung der SLM-Technologie können wir erwarten:

- **Verbesserte Genauigkeit beim Funktionsaufruf**: Bessere Erkennung von Absichten und Parameterextraktion
- **Erweiterte Parallelverarbeitung**: Anspruchsvollere Orchestrierung mehrerer Funktionen
- **Bessere Integrationsstandards**: Standardisierte Protokolle für die Tool-Integration
- **Fortschrittliche Sicherheitsfunktionen**: Verbesserte Authentifizierungs- und Autorisierungsmechanismen
- **Erweitertes Ökosystem**: Wachsende Bibliothek vorgefertigter Funktionen und Integrationen

### Erste Schritte

Um mit der Implementierung von Funktionsaufrufen in Ihren Projekten zu beginnen:

1. **Einfach anfangen**: Beginnen Sie mit grundlegenden Szenarien mit einer einzigen Funktion.
2. **Wählen Sie Ihr Framework**: Entscheiden Sie sich zwischen direkter Implementierung (Ollama/Phi-4) oder Framework-gestützter (Qwen-Agent).
3. **Funktionen sorgfältig gestalten**: Konzentrieren Sie sich auf klare, gut dokumentierte Funktionsdefinitionen.
4. **Fehlerbehandlung implementieren**: Bauen Sie von Anfang an eine robuste Fehlerbehandlung ein.
5. **Schrittweise skalieren**: Gehen Sie von einfachen zu komplexen Szenarien über, sobald Sie Erfahrung gesammelt haben.

Das Aufrufen von Funktionen verwandelt SLMs von beeindruckenden Textgeneratoren in praktische KI-Agenten, die reale Probleme lösen können. Indem Sie die in diesem Tutorial beschriebenen Muster und Praktiken befolgen, können Sie leistungsstarke, zuverlässige KI-Systeme entwickeln, die weit über traditionelle Chat-Oberflächen hinausgehen.

### Ressourcen und Referenzen
- **Phi-4 Modelle**: [Hugging Face Sammlung](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Qwen3 Dokumentation**: [Offizielle Qwen Dokumentation](https://qwen.readthedocs.io/)
- **Ollama**: [Offizielle Webseite](https://ollama.com/)
- **Foundry Local**: [GitHub Repository](https://github.com/microsoft/Foundry-Local)
- **Best Practices für Funktionsaufrufe**: [Hugging Face Leitfaden](https://huggingface.co/docs/hugs/en/guides/function-calling)

Denken Sie daran, dass Funktionsaufrufe ein sich entwickelndes Feld sind. Wenn Sie sich über die neuesten Entwicklungen in Ihren bevorzugten Frameworks und Modellen auf dem Laufenden halten, können Sie effektivere KI-Agenten entwickeln.


## ➡️ Was kommt als Nächstes

- [03: Integration des Model Context Protocol (MCP)](./03.IntroduceMCP.md)

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für kritische Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.