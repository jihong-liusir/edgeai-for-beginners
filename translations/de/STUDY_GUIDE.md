<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-17T12:28:55+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "de"
}
-->
# EdgeAI für Anfänger: Lernpfade und Studienplan

### Intensiver Lernpfad (1 Woche)

| Tag | Schwerpunkt | Geschätzte Stunden |
|------|------------|--------------------|
| Tag 1 | Modul 1: EdgeAI Grundlagen | 3 Stunden |
| Tag 2 | Modul 2: SLM Grundlagen | 3 Stunden |
| Tag 3 | Modul 3: SLM Bereitstellung | 2 Stunden |
| Tag 4-5 | Modul 4: Modelloptimierung (6 Frameworks) | 4 Stunden |
| Tag 6 | Modul 5: SLMOps | 3 Stunden |
| Tag 7 | Modul 6-7: KI-Agenten & Entwicklungstools | 5 Stunden |

### Intensiver Lernpfad (2 Wochen)

| Tag | Schwerpunkt | Geschätzte Stunden |
|------|------------|--------------------|
| Tag 1-2 | Modul 1: EdgeAI Grundlagen | 3 Stunden |
| Tag 3-4 | Modul 2: SLM Grundlagen | 3 Stunden |
| Tag 5-6 | Modul 3: SLM Bereitstellung | 2 Stunden |
| Tag 7-8 | Modul 4: Modelloptimierung | 4 Stunden |
| Tag 9-10 | Modul 5: SLMOps | 3 Stunden |
| Tag 11-12 | Modul 6: KI-Agenten | 2 Stunden |
| Tag 13-14 | Modul 7: Entwicklungstools | 3 Stunden |

### Teilzeitstudium (4 Wochen)

| Woche | Schwerpunkt | Geschätzte Stunden |
|-------|------------|--------------------|
| Woche 1 | Modul 1-2: Grundlagen & SLM Grundlagen | 6 Stunden |
| Woche 2 | Modul 3-4: Bereitstellung & Optimierung | 6 Stunden |
| Woche 3 | Modul 5-6: SLMOps & KI-Agenten | 5 Stunden |
| Woche 4 | Modul 7: Entwicklungstools & Integration | 3 Stunden |

| Tag | Schwerpunkt | Geschätzte Stunden |
|------|------------|--------------------|
| Tag 1-2 | Modul 1: EdgeAI Grundlagen | 3 Stunden |
| Tag 3-4 | Modul 2: SLM Grundlagen | 3 Stunden |
| Tag 5-6 | Modul 3: SLM Bereitstellung | 2 Stunden |
| Tag 7-8 | Modul 4: Modelloptimierung | 4 Stunden |
| Tag 9-10 | Modul 5: SLMOps | 3 Stunden |
| Tag 11-12 | Modul 6: SLM Agentensysteme | 2 Stunden |
| Tag 13-14 | Modul 7: EdgeAI Implementierungsbeispiele | 2 Stunden |

| Modul | Abschlussdatum | Verbrachte Stunden | Wichtige Erkenntnisse |
|-------|----------------|--------------------|-----------------------|
| Modul 1: EdgeAI Grundlagen | | | |
| Modul 2: SLM Grundlagen | | | |
| Modul 3: SLM Bereitstellung | | | |
| Modul 4: Modelloptimierung (6 Frameworks) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentensysteme | | | |
| Modul 7: EdgeAI Implementierungsbeispiele | | | |
| Praktische Übungen | | | |
| Mini-Projekt | | | |

### Teilzeitstudium (4 Wochen)

| Woche | Schwerpunkt | Geschätzte Stunden |
|-------|------------|--------------------|
| Woche 1 | Modul 1-2: Grundlagen & SLM Grundlagen | 6 Stunden |
| Woche 2 | Modul 3-4: Bereitstellung & Optimierung | 6 Stunden |
| Woche 3 | Modul 5-6: SLMOps & KI-Agenten | 5 Stunden |
| Woche 4 | Modul 7: Entwicklungstools & Integration | 3 Stunden |

## Einführung

Willkommen beim Studienleitfaden für EdgeAI für Anfänger! Dieses Dokument soll Ihnen helfen, die Kursmaterialien effektiv zu nutzen und Ihr Lernerlebnis zu maximieren. Es bietet strukturierte Lernpfade, empfohlene Studienpläne, Zusammenfassungen wichtiger Konzepte und ergänzende Ressourcen, um Ihr Verständnis von EdgeAI-Technologien zu vertiefen.

Dies ist ein kompakter 20-Stunden-Kurs, der essenzielles Wissen über EdgeAI in einem zeiteffizienten Format vermittelt – ideal für vielbeschäftigte Fachleute und Studierende, die schnell praktische Fähigkeiten in diesem aufstrebenden Bereich erwerben möchten.

## Kursübersicht

Der Kurs ist in sieben umfassende Module unterteilt:

1. **EdgeAI Grundlagen und Transformation** – Verständnis der Kernkonzepte und des technologischen Wandels
2. **Grundlagen kleiner Sprachmodelle (SLM)** – Erforschung verschiedener SLM-Familien und ihrer Architekturen
3. **Bereitstellung kleiner Sprachmodelle** – Implementierung praktischer Bereitstellungsstrategien
4. **Modellformatkonvertierung und Quantisierung** – Fortgeschrittene Optimierung mit 6 Frameworks, einschließlich OpenVINO
5. **SLMOps – Betrieb kleiner Sprachmodelle** – Produktionslebenszyklusmanagement und Bereitstellung
6. **SLM Agentensysteme** – KI-Agenten, Funktionsaufrufe und Modellkontextprotokoll
7. **EdgeAI Implementierungsbeispiele** – KI-Toolkit, Windows-Entwicklung und plattformspezifische Implementierungen

## So nutzen Sie diesen Studienleitfaden

- **Progressives Lernen**: Folgen Sie den Modulen der Reihe nach für ein kohärentes Lernerlebnis.
- **Wissenscheckpunkte**: Nutzen Sie die Selbstbewertungsfragen nach jedem Abschnitt.
- **Praktische Übungen**: Schließen Sie die vorgeschlagenen Übungen ab, um theoretische Konzepte zu festigen.
- **Ergänzende Ressourcen**: Erkunden Sie zusätzliche Materialien zu Themen, die Sie besonders interessieren.

## Empfehlungen für den Studienplan

### Intensiver Lernpfad (1 Woche)

| Tag | Schwerpunkt | Geschätzte Stunden |
|------|------------|--------------------|
| Tag 1-2 | Modul 1: EdgeAI Grundlagen | 6 Stunden |
| Tag 3-4 | Modul 2: SLM Grundlagen | 8 Stunden |
| Tag 5-6 | Modul 3: SLM Bereitstellung | 6 Stunden |

### Teilzeitstudium (3 Wochen)

| Woche | Schwerpunkt | Geschätzte Stunden |
|-------|------------|--------------------|
| Woche 1 | Modul 1: EdgeAI Grundlagen | 6-7 Stunden |
| Woche 2 | Modul 2: SLM Grundlagen | 7-8 Stunden |
| Woche 3 | Modul 3: SLM Bereitstellung | 5-6 Stunden |

## Modul 1: EdgeAI Grundlagen und Transformation

### Wichtige Lernziele

- Unterschiede zwischen cloudbasiertem und edgebasiertem KI verstehen
- Kernoptimierungstechniken für ressourcenbeschränkte Umgebungen beherrschen
- Analyse von realen Anwendungen von EdgeAI-Technologien
- Einrichtung einer Entwicklungsumgebung für EdgeAI-Projekte

### Studienfokusbereiche

#### Abschnitt 1: EdgeAI Grundlagen
- **Priorisierte Konzepte**: 
  - Paradigmen von Edge- vs. Cloud-Computing
  - Modellquantisierungstechniken
  - Hardware-Beschleunigungsoptionen (NPUs, GPUs, CPUs)
  - Vorteile in Bezug auf Datenschutz und Sicherheit

- **Ergänzende Materialien**:
  - [TensorFlow Lite Dokumentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentation](https://docs.edgeimpulse.com)

#### Abschnitt 2: Fallstudien aus der Praxis
- **Priorisierte Konzepte**: 
  - Microsoft Phi- & Mu-Modellökosystem
  - Praktische Implementierungen in verschiedenen Branchen
  - Bereitstellungsüberlegungen

#### Abschnitt 3: Praktischer Implementierungsleitfaden
- **Priorisierte Konzepte**: 
  - Einrichtung der Entwicklungsumgebung
  - Quantisierungs- und Optimierungstools
  - Bewertungsmethoden für EdgeAI-Implementierungen

#### Abschnitt 4: Edge-Bereitstellungshardware
- **Priorisierte Konzepte**: 
  - Vergleich von Hardwareplattformen
  - Optimierungsstrategien für spezifische Hardware
  - Bereitstellungsüberlegungen

### Selbstbewertungsfragen

1. Vergleichen Sie cloudbasierte KI mit edgebasierter KI-Implementierung.
2. Erklären Sie drei Schlüsseltechniken zur Optimierung von Modellen für die Edge-Bereitstellung.
3. Was sind die Hauptvorteile der Ausführung von KI-Modellen am Edge?
4. Beschreiben Sie den Prozess der Modellquantisierung und wie er die Leistung beeinflusst.
5. Erklären Sie, wie verschiedene Hardware-Beschleuniger (NPUs, GPUs, CPUs) die EdgeAI-Bereitstellung beeinflussen.

### Praktische Übungen

1. **Schnelle Einrichtung der Umgebung**: Konfigurieren Sie eine minimale Entwicklungsumgebung mit den wesentlichen Paketen (30 Minuten).
2. **Modelluntersuchung**: Laden Sie ein vortrainiertes kleines Sprachmodell herunter und untersuchen Sie es (1 Stunde).
3. **Einfache Quantisierung**: Probieren Sie eine einfache Quantisierung an einem kleinen Modell aus (1 Stunde).
- Entscheidungsbäume zur Auswahl des Frameworks  
- Validierung der Produktionsbereitschaft  
- Strategien zur Zukunftssicherung  

### Selbstbewertungsfragen  

1. Vergleichen Sie Quantisierungsstrategien über verschiedene Präzisionsstufen (1-Bit bis 8-Bit).  
2. Erklären Sie die Vorteile des GGUF-Formats für Edge-Deployments.  
3. Wie verbessert hardwarebewusste Optimierung in Microsoft Olive die Effizienz der Bereitstellung?  
4. Was sind die Hauptvorteile von OpenVINOs NNCF für die Modellkompression?  
5. Beschreiben Sie, wie Apple MLX die einheitliche Speicherarchitektur für Optimierungen nutzt.  
6. Wie hilft die Synthese von Workflows bei der Auswahl optimaler Optimierungs-Frameworks?  

### Praktische Übungen  

1. **Modellquantisierung**: Wenden Sie verschiedene Quantisierungsstufen auf ein Modell an und vergleichen Sie die Ergebnisse (1 Stunde).  
2. **OpenVINO-Optimierung**: Verwenden Sie NNCF, um ein Modell für Intel-Hardware zu komprimieren (1 Stunde).  
3. **Framework-Vergleich**: Testen Sie dasselbe Modell in drei verschiedenen Optimierungs-Frameworks (1 Stunde).  
4. **Leistungs-Benchmarking**: Messen Sie den Einfluss der Optimierung auf die Inferenzgeschwindigkeit und den Speicherverbrauch (1 Stunde).  

## Modul 5: SLMOps - Betrieb von kleinen Sprachmodellen  

### Wichtige Lernziele  

- Verstehen der Prinzipien des Lebenszyklusmanagements von SLMOps  
- Beherrschen von Distillations- und Feinabstimmungstechniken für Edge-Deployments  
- Implementieren von Produktionsbereitstellungsstrategien mit Monitoring  
- Aufbau von unternehmensgerechten Workflows für Betrieb und Wartung von SLMs  

### Studienfokusbereiche  

#### Abschnitt 1: Einführung in SLMOps  
- **Prioritätskonzepte**:  
  - Paradigmenwechsel von SLMOps in der KI-Betriebsführung  
  - Kostenersparnis und datenschutzorientierte Architektur  
  - Strategische Geschäftsauswirkungen und Wettbewerbsvorteile  

#### Abschnitt 2: Modell-Distillation  
- **Prioritätskonzepte**:  
  - Techniken des Wissenstransfers  
  - Implementierung des zweistufigen Distillationsprozesses  
  - Distillations-Workflows in Azure ML  

#### Abschnitt 3: Feinabstimmungsstrategien  
- **Prioritätskonzepte**:  
  - Parameter-effiziente Feinabstimmung (PEFT)  
  - Fortgeschrittene Methoden wie LoRA und QLoRA  
  - Multi-Adapter-Training und Hyperparameter-Optimierung  

#### Abschnitt 4: Produktionsbereitstellung  
- **Prioritätskonzepte**:  
  - Modellkonvertierung und Quantisierung für die Produktion  
  - Konfiguration der Foundry Local-Bereitstellung  
  - Leistungs-Benchmarking und Qualitätsvalidierung  

### Selbstbewertungsfragen  

1. Wie unterscheidet sich SLMOps von traditionellem MLOps?  
2. Erklären Sie die Vorteile der Modell-Distillation für Edge-Deployments.  
3. Was sind die wichtigsten Überlegungen zur Feinabstimmung von SLMs in ressourcenbeschränkten Umgebungen?  
4. Beschreiben Sie eine vollständige Produktionsbereitstellungspipeline für Edge-KI-Anwendungen.  

### Praktische Übungen  

1. **Grundlegende Distillation**: Erstellen Sie ein kleineres Modell aus einem größeren Lehrermodell (1 Stunde).  
2. **Feinabstimmungsexperiment**: Feinabstimmung eines Modells für einen spezifischen Anwendungsbereich (1 Stunde).  
3. **Bereitstellungspipeline**: Einrichten einer grundlegenden CI/CD-Pipeline für die Modellbereitstellung (1 Stunde).  

## Modul 6: SLM Agentensysteme - KI-Agenten und Funktionsaufrufe  

### Wichtige Lernziele  

- Aufbau intelligenter KI-Agenten für Edge-Umgebungen mit kleinen Sprachmodellen  
- Implementierung von Funktionsaufruf-Fähigkeiten mit systematischen Workflows  
- Beherrschen der Integration des Model Context Protocol (MCP) für standardisierte Werkzeuginteraktion  
- Erstellung fortschrittlicher agentischer Systeme mit minimaler menschlicher Intervention  

### Studienfokusbereiche  

#### Abschnitt 1: KI-Agenten und SLM-Grundlagen  
- **Prioritätskonzepte**:  
  - Klassifikationsrahmen für Agenten (Reflex-, modellbasierte, zielbasierte, lernende Agenten)  
  - Analyse der Kompromisse zwischen SLMs und LLMs  
  - Edge-spezifische Designmuster für Agenten  
  - Ressourcenoptimierung für Agenten  

#### Abschnitt 2: Funktionsaufrufe in kleinen Sprachmodellen  
- **Prioritätskonzepte**:  
  - Implementierung systematischer Workflows (Absichtserkennung, JSON-Ausgabe, externe Ausführung)  
  - Plattform-spezifische Implementierungen (Phi-4-mini, ausgewählte Qwen-Modelle, Microsoft Foundry Local)  
  - Fortgeschrittene Beispiele (Zusammenarbeit mehrerer Agenten, dynamische Werkzeugauswahl)  
  - Produktionsüberlegungen (Ratenbegrenzung, Audit-Logging, Sicherheitsmaßnahmen)  

#### Abschnitt 3: Integration des Model Context Protocol (MCP)  
- **Prioritätskonzepte**:  
  - Protokollarchitektur und schichtbasiertes Systemdesign  
  - Unterstützung mehrerer Backends (Ollama für Entwicklung, vLLM für Produktion)  
  - Verbindungsprotokolle (STDIO- und SSE-Modi)  
  - Anwendungen in der Praxis (Web-Automatisierung, Datenverarbeitung, API-Integration)  

### Selbstbewertungsfragen  

1. Was sind die wichtigsten architektonischen Überlegungen für Edge-KI-Agenten?  
2. Wie verbessern Funktionsaufrufe die Fähigkeiten von Agenten?  
3. Erklären Sie die Rolle des Model Context Protocol in der Agentenkommunikation.  

### Praktische Übungen  

1. **Einfacher Agent**: Erstellen Sie einen grundlegenden KI-Agenten mit Funktionsaufrufen (1 Stunde).  
2. **MCP-Integration**: Implementieren Sie MCP in einer Agentenanwendung (30 Minuten).  

## Modul 7: EdgeAI-Implementierungsbeispiele  

### Wichtige Lernziele  

- Beherrschen des AI Toolkit für Visual Studio Code für umfassende EdgeAI-Entwicklungs-Workflows  
- Expertise in der Windows AI Foundry-Plattform und NPU-Optimierungsstrategien gewinnen  
- Implementierung von EdgeAI auf verschiedenen Hardwareplattformen und Bereitstellungsszenarien  
- Erstellung produktionsreifer EdgeAI-Anwendungen mit plattformspezifischen Optimierungen  

### Studienfokusbereiche  

#### Abschnitt 1: AI Toolkit für Visual Studio Code  
- **Prioritätskonzepte**:  
  - Umfassende EdgeAI-Entwicklungsumgebung innerhalb von VS Code  
  - Modellkatalog und -entdeckung für Edge-Deployments  
  - Lokale Tests, Optimierung und Agentenentwicklungs-Workflows  
  - Leistungsüberwachung und Bewertung für Edge-Szenarien  

#### Abschnitt 2: Windows EdgeAI-Entwicklungsleitfaden  
- **Prioritätskonzepte**:  
  - Umfassender Überblick über die Windows AI Foundry-Plattform  
  - Phi Silica API für effiziente NPU-Inferenz  
  - Computer Vision APIs für Bildverarbeitung und OCR  
  - Foundry Local CLI für lokale Entwicklung und Tests  

#### Abschnitt 3: Plattform-spezifische Implementierungen  
- **Prioritätskonzepte**:  
  - NVIDIA Jetson Orin Nano-Bereitstellung (67 TOPS KI-Leistung)  
  - Mobile Anwendungen mit .NET MAUI und ONNX Runtime GenAI  
  - Azure EdgeAI-Lösungen mit Cloud-Edge-Hybridarchitektur  
  - Windows ML-Optimierung mit universeller Hardwareunterstützung  
  - Foundry Local-Anwendungen mit datenschutzorientierter RAG-Implementierung  

### Selbstbewertungsfragen  

1. Wie vereinfacht das AI Toolkit den EdgeAI-Entwicklungs-Workflow?  
2. Vergleichen Sie Bereitstellungsstrategien auf verschiedenen Hardwareplattformen.  
3. Was sind die Vorteile der Windows AI Foundry für die Edge-Entwicklung?  
4. Erklären Sie die Rolle der NPU-Optimierung in modernen Edge-KI-Anwendungen.  
5. Wie nutzt die Phi Silica API NPU-Hardware für Leistungsoptimierung?  
6. Vergleichen Sie die Vorteile von lokaler und Cloud-Bereitstellung für datenschutzsensible Anwendungen.  

### Praktische Übungen  

1. **AI Toolkit Setup**: Konfigurieren Sie das AI Toolkit und optimieren Sie ein Modell (1 Stunde).  
2. **Windows AI Foundry**: Erstellen Sie eine einfache Windows-KI-Anwendung mit der Phi Silica API (1 Stunde).  
3. **Cross-Plattform-Bereitstellung**: Bereitstellung desselben Modells auf zwei verschiedenen Plattformen (1 Stunde).  
4. **NPU-Optimierung**: Testen Sie die NPU-Leistung mit Windows AI Foundry-Tools (30 Minuten).  

## Zeitplan für die Kursdauer  

Um das Beste aus den 20 Stunden Kurszeit herauszuholen, hier eine empfohlene Zeitaufteilung:  

| Aktivität | Zeitaufteilung | Beschreibung |  
|-----------|----------------|--------------|  
| Lesen der Kernmaterialien | 9 Stunden | Fokus auf die wesentlichen Konzepte in jedem Modul |  
| Praktische Übungen | 6 Stunden | Praktische Umsetzung der wichtigsten Techniken |  
| Selbstbewertung | 2 Stunden | Testen des Verständnisses durch Fragen und Reflexion |  
| Mini-Projekt | 3 Stunden | Anwendung des Wissens in einer kleinen praktischen Umsetzung |  

### Wichtige Fokusbereiche je nach Zeitrahmen  

**Wenn Sie nur 10 Stunden haben:**  
- Abschließen der Module 1, 2 und 3 (Kernkonzepte von EdgeAI)  
- Mindestens eine praktische Übung pro Modul durchführen  
- Fokus auf das Verständnis der Kernkonzepte statt auf Details der Implementierung  

**Wenn Sie die vollen 20 Stunden nutzen können:**  
- Alle sieben Module abschließen  
- Wichtige praktische Übungen aus jedem Modul durchführen  
- Ein Mini-Projekt aus Modul 7 abschließen  
- Mindestens 2-3 ergänzende Ressourcen erkunden  

**Wenn Sie mehr als 20 Stunden haben:**  
- Alle Module mit detaillierten Übungen abschließen  
- Mehrere Mini-Projekte erstellen  
- Fortgeschrittene Optimierungstechniken in Modul 4 erkunden  
- Produktionsbereitstellung aus Modul 5 implementieren  

## Wichtige Ressourcen  

Diese sorgfältig ausgewählten Ressourcen bieten den größten Nutzen für Ihre begrenzte Lernzeit:  

### Unbedingt zu lesende Dokumentationen  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Das effizienteste Werkzeug zur Modelloptimierung  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Schnellster Weg zur lokalen Bereitstellung von SLMs  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referenz für ein führendes Edge-optimiertes Modell  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels umfassendes Optimierungstoolkit  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrierte EdgeAI-Entwicklungsumgebung  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-spezifische EdgeAI-Entwicklungsplattform  

### Zeitersparende Tools  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Schneller Zugriff auf Modelle und Bereitstellung  
- [Gradio](https://www.gradio.app/docs/interface) - Schnelle UI-Entwicklung für KI-Demos  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Vereinfachte Modelloptimierung  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effiziente CPU-Inferenz  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework zur Kompression neuronaler Netze  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit zur Bereitstellung großer Sprachmodelle  

## Fortschritts-Tracking-Vorlage  

Nutzen Sie diese vereinfachte Vorlage, um Ihren Lernfortschritt im 20-Stunden-Kurs zu verfolgen:  

| Modul | Abschlussdatum | Verbrachte Stunden | Wichtige Erkenntnisse |  
|-------|----------------|--------------------|-----------------------|  
| Modul 1: EdgeAI-Grundlagen | | | |  
| Modul 2: SLM-Grundlagen | | | |  
| Modul 3: SLM-Bereitstellung | | | |  
| Modul 4: Modelloptimierung | | | |  
| Modul 5: SLMOps | | | |  
| Modul 6: KI-Agenten | | | |  
| Modul 7: Entwicklungstools | | | |  
| Praktische Übungen | | | |  
| Mini-Projekt | | | |  

## Mini-Projektideen  

Erwägen Sie, eines dieser Projekte abzuschließen, um EdgeAI-Konzepte zu üben (jedes ist für 2-4 Stunden ausgelegt):  

### Anfängerprojekte (jeweils 2-3 Stunden)  
1. **Edge-Textassistent**: Erstellen Sie ein einfaches Offline-Textvervollständigungstool mit einem kleinen Sprachmodell.  
2. **Modellvergleichs-Dashboard**: Erstellen Sie eine grundlegende Visualisierung von Leistungsmetriken verschiedener SLMs.  
3. **Optimierungsexperiment**: Messen Sie die Auswirkungen verschiedener Quantisierungsstufen auf dasselbe Basismodell.  

### Mittelstufenprojekte (jeweils 3-4 Stunden)  
4. **AI Toolkit Workflow**: Verwenden Sie das VS Code AI Toolkit, um ein Modell von Anfang bis Ende zu optimieren und bereitzustellen.  
5. **Windows AI Foundry-Anwendung**: Erstellen Sie eine Windows-App mit der Phi Silica API und NPU-Optimierung.  
6. **Cross-Plattform-Bereitstellung**: Bereitstellung desselben optimierten Modells auf Windows (OpenVINO) und Mobilgeräten (.NET MAUI).  
7. **Funktionsaufruf-Agent**: Erstellen Sie einen KI-Agenten mit Funktionsaufruf-Fähigkeiten für Edge-Szenarien.  

### Fortgeschrittene Integrationsprojekte (jeweils 4-5 Stunden)  
8. **OpenVINO-Optimierungspipeline**: Implementieren Sie eine vollständige Modelloptimierung mit NNCF und GenAI-Toolkit.  
9. **SLMOps-Pipeline**: Implementieren Sie einen vollständigen Modelllebenszyklus von Training bis Edge-Bereitstellung.  
10. **Multi-Modell-Edge-System**: Bereitstellung mehrerer spezialisierter Modelle, die auf Edge-Hardware zusammenarbeiten.  
11. **MCP-Integrationssystem**: Erstellen Sie ein agentisches System mit Model Context Protocol für Werkzeuginteraktion.  

## Lern-Community  

Treten Sie der Diskussion bei und vernetzen Sie sich mit anderen Lernenden:  
- GitHub-Diskussionen im [EdgeAI for Beginners Repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Fazit  

EdgeAI repräsentiert die Zukunft der Implementierung künstlicher Intelligenz, indem leistungsstarke Fähigkeiten direkt auf Geräte gebracht werden und gleichzeitig wichtige Anliegen wie Datenschutz, Latenz und Konnektivität adressiert werden. Dieser 20-Stunden-Kurs vermittelt Ihnen das wesentliche Wissen und die praktischen Fähigkeiten, um sofort mit EdgeAI-Technologien zu arbeiten.  

Der Kurs ist bewusst prägnant und konzentriert sich auf die wichtigsten Konzepte, sodass Sie schnell wertvolle Expertise gewinnen können, ohne eine überwältigende Zeitinvestition zu leisten. Denken Sie daran, dass praktische Übungen, selbst mit einfachen Beispielen, der Schlüssel zur Festigung des Gelernten sind.  

Viel Erfolg beim Lernen!  

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, weisen wir darauf hin, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für kritische Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die aus der Nutzung dieser Übersetzung entstehen.