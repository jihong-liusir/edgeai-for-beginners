<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a189d7d9d47816a518ca119d79dc19b",
  "translation_date": "2025-09-22T12:44:21+00:00",
  "source_file": "README.md",
  "language_code": "de"
}
-->
# EdgeAI f√ºr Anf√§nger

![Kurs-Coverbild](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.de.png)

[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![GitHub issues](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![GitHub forks](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![GitHub stars](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Folgen Sie diesen Schritten, um mit diesen Ressourcen zu beginnen:

1. **Repository forken**: Klicken Sie hier [![GitHub forks](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Repository klonen**: `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Treten Sie dem Azure AI Foundry Discord bei und treffen Sie Experten und andere Entwickler**](https://discord.com/invite/ByRwuEEgH4)

### üåê Mehrsprachige Unterst√ºtzung

#### Unterst√ºtzt durch GitHub Action (Automatisiert & Immer aktuell)

[Arabisch](../ar/README.md) | [Bengalisch](../bn/README.md) | [Bulgarisch](../bg/README.md) | [Birmanisch (Myanmar)](../my/README.md) | [Chinesisch (vereinfacht)](../zh/README.md) | [Chinesisch (traditionell, Hongkong)](../hk/README.md) | [Chinesisch (traditionell, Macau)](../mo/README.md) | [Chinesisch (traditionell, Taiwan)](../tw/README.md) | [Kroatisch](../hr/README.md) | [Tschechisch](../cs/README.md) | [D√§nisch](../da/README.md) | [Niederl√§ndisch](../nl/README.md) | [Finnisch](../fi/README.md) | [Franz√∂sisch](../fr/README.md) | [Deutsch](./README.md) | [Griechisch](../el/README.md) | [Hebr√§isch](../he/README.md) | [Hindi](../hi/README.md) | [Ungarisch](../hu/README.md) | [Indonesisch](../id/README.md) | [Italienisch](../it/README.md) | [Japanisch](../ja/README.md) | [Koreanisch](../ko/README.md) | [Malaiisch](../ms/README.md) | [Marathi](../mr/README.md) | [Nepalesisch](../ne/README.md) | [Norwegisch](../no/README.md) | [Persisch (Farsi)](../fa/README.md) | [Polnisch](../pl/README.md) | [Portugiesisch (Brasilien)](../br/README.md) | [Portugiesisch (Portugal)](../pt/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Rum√§nisch](../ro/README.md) | [Russisch](../ru/README.md) | [Serbisch (kyrillisch)](../sr/README.md) | [Slowakisch](../sk/README.md) | [Slowenisch](../sl/README.md) | [Spanisch](../es/README.md) | [Swahili](../sw/README.md) | [Schwedisch](../sv/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Thai](../th/README.md) | [T√ºrkisch](../tr/README.md) | [Ukrainisch](../uk/README.md) | [Urdu](../ur/README.md) | [Vietnamesisch](../vi/README.md)

**Falls Sie zus√§tzliche √úbersetzungen w√ºnschen, finden Sie unterst√ºtzte Sprachen [hier](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Einf√ºhrung

Willkommen bei **EdgeAI f√ºr Anf√§nger** ‚Äì Ihre umfassende Reise in die transformative Welt der Edge-K√ºnstlichen Intelligenz. Dieser Kurs schl√§gt die Br√ºcke zwischen leistungsstarken KI-F√§higkeiten und praktischen, realen Anwendungen auf Edge-Ger√§ten, sodass Sie die M√∂glichkeiten der KI direkt dort nutzen k√∂nnen, wo Daten generiert und Entscheidungen getroffen werden m√ºssen.

### Was Sie lernen werden

Dieser Kurs f√ºhrt Sie von den grundlegenden Konzepten bis hin zu produktionsreifen Implementierungen und behandelt:
- **Kleine Sprachmodelle (SLMs)**, die f√ºr Edge-Eins√§tze optimiert sind  
- **Hardware-optimierte L√∂sungen** f√ºr verschiedene Plattformen  
- **Echtzeit-Inferenz** mit datenschutzfreundlichen Funktionen  
- **Produktionsstrategien** f√ºr Unternehmensanwendungen  

### Warum EdgeAI wichtig ist

Edge AI stellt einen Paradigmenwechsel dar, der moderne Herausforderungen adressiert:
- **Datenschutz & Sicherheit**: Verarbeitung sensibler Daten lokal, ohne Cloud-Exposition  
- **Echtzeit-Leistung**: Vermeidung von Netzwerkverz√∂gerungen f√ºr zeitkritische Anwendungen  
- **Kostenersparnis**: Reduzierung von Bandbreiten- und Cloud-Computing-Kosten  
- **Robuste Funktionalit√§t**: Betrieb auch bei Netzwerkausf√§llen  
- **Regulatorische Anforderungen**: Einhaltung von Datenschutzbestimmungen  

### Edge AI

Edge AI bezieht sich auf die Ausf√ºhrung von KI-Algorithmen und Sprachmodellen lokal auf Hardware ‚Äì nahe an der Datenquelle ‚Äì ohne auf Cloud-Ressourcen f√ºr die Inferenz angewiesen zu sein. Es reduziert Latenzzeiten, verbessert den Datenschutz und erm√∂glicht Echtzeit-Entscheidungen.

### Kernprinzipien:
- **On-Device-Inferenz**: KI-Modelle laufen auf Edge-Ger√§ten (Handys, Router, Mikrocontroller, Industrie-PCs)  
- **Offline-F√§higkeit**: Funktioniert ohne st√§ndige Internetverbindung  
- **Niedrige Latenz**: Sofortige Antworten f√ºr Echtzeitsysteme  
- **Datensouver√§nit√§t**: Sensible Daten bleiben lokal, was Sicherheit und Compliance verbessert  

### Kleine Sprachmodelle (SLMs)

SLMs wie Phi-4, Mistral-7B und Gemma sind optimierte Versionen gr√∂√üerer LLMs ‚Äì trainiert oder destilliert f√ºr:
- **Reduzierter Speicherbedarf**: Effiziente Nutzung begrenzter Edge-Ger√§te-Ressourcen  
- **Geringere Rechenanforderungen**: Optimiert f√ºr CPU- und Edge-GPU-Leistung  
- **Schnellere Startzeiten**: Schnelle Initialisierung f√ºr reaktionsschnelle Anwendungen  

Sie bieten leistungsstarke NLP-Funktionen und erf√ºllen gleichzeitig die Anforderungen von:
- **Eingebetteten Systemen**: IoT-Ger√§te und industrielle Steuerungen  
- **Mobilger√§ten**: Smartphones und Tablets mit Offline-F√§higkeiten  
- **IoT-Ger√§ten**: Sensoren und intelligente Ger√§te mit begrenzten Ressourcen  
- **Edge-Servern**: Lokale Verarbeitungseinheiten mit begrenzten GPU-Ressourcen  
- **Personal Computern**: Einsatzszenarien f√ºr Desktops und Laptops  

## Kursstruktur

### [Modul 01: Grundlagen und Transformation von EdgeAI](./Module01/README.md)
**Thema**: Der transformative Wandel durch Edge-AI-Einsatz  

#### Kapitelstruktur:
- [**Abschnitt 1: Grundlagen von EdgeAI**](./Module01/01.EdgeAIFundamentals.md)  
  - Vergleich von traditioneller Cloud-KI und Edge-KI  
  - Herausforderungen und Einschr√§nkungen des Edge-Computings  
  - Schl√ºsseltechnologien: Modell-Quantisierung, Kompressionsoptimierung, Kleine Sprachmodelle (SLMs)  
  - Hardware-Beschleunigung: NPUs, GPU-Optimierung, CPU-Optimierung  
  - Vorteile: Datenschutz, niedrige Latenz, Offline-F√§higkeiten, Kosteneffizienz  

- [**Abschnitt 2: Fallstudien aus der Praxis**](./Module01/02.RealWorldCaseStudies.md)  
  - Microsoft Phi & Mu Modell-√ñkosystem  
  - Fallstudie: Japan Airlines AI-Berichtssystem  
  - Markteinfluss und zuk√ºnftige Entwicklungen  
  - Einsatz√ºberlegungen und Best Practices  

- [**Abschnitt 3: Praktischer Implementierungsleitfaden**](./Module01/03.PracticalImplementationGuide.md)  
  - Einrichtung der Entwicklungsumgebung (Python 3.10+, .NET 8+)  
  - Hardwareanforderungen und empfohlene Konfigurationen  
  - Ressourcen der Kernmodellfamilie  
  - Quantisierungs- und Optimierungstools (Llama.cpp, Microsoft Olive, Apple MLX)  
  - Bewertungs- und Verifizierungscheckliste  

- [**Abschnitt 4: Hardwareplattformen f√ºr Edge-AI-Einsatz**](./Module01/04.EdgeDeployment.md)  
  - √úberlegungen und Anforderungen f√ºr Edge-AI-Eins√§tze  
  - Intel Edge-AI-Hardware und Optimierungstechniken  
  - Qualcomm AI-L√∂sungen f√ºr mobile und eingebettete Systeme  
  - NVIDIA Jetson und Edge-Computing-Plattformen  
  - Windows AI-PC-Plattformen mit NPU-Beschleunigung  
  - Hardware-spezifische Optimierungsstrategien  

---

### [Modul 02: Grundlagen kleiner Sprachmodelle](./Module02/README.md)
**Thema**: Theoretische Prinzipien, Implementierungsstrategien und produktionsreife Eins√§tze von SLMs  

#### Kapitelstruktur:
- [**Abschnitt 1: Grundlagen der Microsoft Phi Modellfamilie**](./Module02/01.PhiFamily.md)  
  - Entwicklung der Designphilosophie (Phi-1 bis Phi-4)  
  - Architekturdesign mit Fokus auf Effizienz  
  - Spezialisierte F√§higkeiten (Schlussfolgerungen, multimodal, Edge-Einsatz)  

- [**Abschnitt 2: Grundlagen der Qwen Modellfamilie**](./Module02/02.QwenFamily.md)  
  - Open-Source-Exzellenz (Qwen 1.0 bis Qwen3) ‚Äì verf√ºgbar √ºber Hugging Face  
  - Fortschrittliche Architektur f√ºr Schlussfolgerungen mit Denkmodus-F√§higkeiten  
  - Skalierbare Einsatzoptionen (0,5B-235B Parameter)  

- [**Abschnitt 3: Grundlagen der Gemma Modellfamilie**](./Module02/03.GemmaFamily.md)  
  - Forschungsgetriebene Innovation (Gemma 3 & 3n)  
  - Multimodale Exzellenz  
  - Mobile-first-Architektur  

- [**Abschnitt 4: Grundlagen der BitNET Modellfamilie**](./Module02/04.BitNETFamily.md)  
  - Revolution√§re Quantisierungstechnologie (1,58-Bit)  
  - Spezielles Inferenz-Framework von https://github.com/microsoft/BitNet  
  - Nachhaltige KI-F√ºhrung durch extreme Effizienz  

- [**Abschnitt 5: Grundlagen des Microsoft Mu Modells**](./Module02/05.mumodel.md)  
  - Ger√§teorientierte Architektur, integriert in Windows 11  
  - Systemintegration mit Windows 11 Einstellungen  
  - Datenschutzfreundlicher Offline-Betrieb  

- [**Abschnitt 6: Grundlagen von Phi-Silica**](./Module02/06.phisilica.md)  
  - NPU-optimierte Architektur, integriert in Windows 11 Copilot+ PCs  
  - Au√üergew√∂hnliche Effizienz (650 Tokens/Sekunde bei 1,5W)  
  - Entwicklerintegration mit Windows App SDK  

---

### [Modul 03: Einsatz kleiner Sprachmodelle](./Module03/README.md)
**Thema**: Vollst√§ndiger Lebenszyklus von SLMs, von Theorie bis Produktionsumgebung  

#### Kapitelstruktur:
- [**Abschnitt 1: Fortgeschrittenes Lernen von SLMs**](./Module03/01.SLMAdvancedLearning.md)  
  - Parameterklassifizierungsrahmen (Micro SLM 100M-1,4B, Medium SLM 14B-30B)  
  - Fortgeschrittene Optimierungstechniken (Quantisierungsmethoden, BitNET 1-Bit-Quantisierung)  
  - Strategien zur Modellbeschaffung (Azure AI Foundry f√ºr Phi-Modelle, Hugging Face f√ºr ausgew√§hlte Modelle)  

- [**Abschnitt 2: Einsatz in lokaler Umgebung**](./Module03/02.DeployingSLMinLocalEnv.md)  
  - Ollama universelle Plattformbereitstellung  
  - Microsoft Foundry lokale Unternehmensl√∂sungen  
  - Vergleich von Frameworks  

- [**Abschnitt 3: Containerisierte Cloud-Bereitstellung**](./Module03/03.DeployingSLMinCloud.md)  
  - vLLM Hochleistungs-Inferenzbereitstellung  
  - Ollama Container-Orchestrierung  
  - ONNX Runtime edge-optimierte Implementierung  

---

### [Modul 04: Modellformatkonvertierung und Quantisierung](./Module04/README.md)
**Thema**: Vollst√§ndiges Toolkit zur Modelloptimierung f√ºr Edge-Eins√§tze auf verschiedenen Plattformen  

#### Kapitelstruktur:
- [**Abschnitt 1: Grundlagen der Modellformatkonvertierung und Quantisierung**](./Module04/01.Introduce.md)  
  - Pr√§zisionsklassifizierungsrahmen (ultra-niedrig, niedrig, mittlere Pr√§zision)  
  - Vorteile und Anwendungsf√§lle von GGUF- und ONNX-Formaten  
  - Vorteile der Quantisierung f√ºr betriebliche Effizienz  
  - Leistungsbenchmarks und Speicherbedarfsvergleiche  
- [**Abschnitt 2: Llama.cpp Implementierungsleitfaden**](./Module04/02.Llamacpp.md)
  - Plattform√ºbergreifende Installation (Windows, macOS, Linux)
  - GGUF-Formatkonvertierung und Quantisierungsstufen (Q2_K bis Q8_0)
  - Hardwarebeschleunigung (CUDA, Metal, OpenCL, Vulkan)
  - Python-Integration und REST-API-Bereitstellung

- [**Abschnitt 3: Microsoft Olive Optimierungssuite**](./Module04/03.MicrosoftOlive.md)
  - Hardwarebewusste Modelloptimierung mit √ºber 40 integrierten Komponenten
  - Automatische Optimierung mit dynamischer und statischer Quantisierung
  - Unternehmensintegration mit Azure ML-Workflows
  - Unterst√ºtzung beliebter Modelle (Llama, Phi, ausgew√§hlte Qwen-Modelle, Gemma)

- [**Abschnitt 4: OpenVINO Toolkit Optimierungssuite**](./Module04/04.openvino.md)
  - Intels Open-Source-Toolkit f√ºr plattform√ºbergreifende KI-Bereitstellung
  - Neural Network Compression Framework (NNCF) f√ºr fortgeschrittene Optimierung
  - OpenVINO GenAI f√ºr den Einsatz gro√üer Sprachmodelle
  - Hardwarebeschleunigung f√ºr CPU, GPU, VPU und KI-Beschleuniger

- [**Abschnitt 5: Apple MLX Framework im Detail**](./Module04/05.AppleMLX.md)
  - Einheitliche Speicherarchitektur f√ºr Apple Silicon
  - Unterst√ºtzung f√ºr LLaMA, Mistral, Phi, ausgew√§hlte Qwen-Modelle
  - LoRA-Feinabstimmung und Modellanpassung
  - Integration mit Hugging Face und 4-Bit/8-Bit-Quantisierung

- [**Abschnitt 6: Synthese des Edge AI Entwicklungsworkflows**](./Module04/06.workflow-synthesis.md)
  - Einheitliche Workflow-Architektur mit Integration mehrerer Optimierungsframeworks
  - Entscheidungsb√§ume zur Framework-Auswahl und Analyse von Leistungsabstrichen
  - Validierung der Produktionsbereitschaft und umfassende Bereitstellungsstrategien
  - Zukunftssichere Strategien f√ºr neue Hardware- und Modellarchitekturen

---

### [Modul 05: SLMOps - Betrieb kleiner Sprachmodelle](./Module05/README.md)
**Thema**: Vollst√§ndige SLM-Lebenszyklusoperationen von Destillation bis zur Produktionsbereitstellung

#### Kapitelstruktur:
- [**Abschnitt 1: Einf√ºhrung in SLMOps**](./Module05/01.IntroduceSLMOps.md)
  - Paradigmenwechsel in der KI-Betriebsf√ºhrung durch SLMOps
  - Kostenersparnis und datenschutzorientierte Architektur
  - Strategische Gesch√§ftsauswirkungen und Wettbewerbsvorteile
  - Herausforderungen und L√∂sungen bei der Implementierung in der Praxis

- [**Abschnitt 2: Modelldestillation - Von der Theorie zur Praxis**](./Module05/02.SLMOps-Distillation.md)
  - Wissenstransfer von Lehrer- zu Sch√ºlermodellen
  - Implementierung des zweistufigen Destillationsprozesses
  - Azure ML-Destillationsworkflows mit praktischen Beispielen
  - 85 % Reduktion der Inferenzzeit bei 92 % Genauigkeitsbeibehaltung

- [**Abschnitt 3: Feinabstimmung - Anpassung von Modellen f√ºr spezifische Aufgaben**](./Module05/03.SLMOps-Finetuing.md)
  - Parameter-effiziente Feinabstimmungstechniken (PEFT)
  - Fortgeschrittene Methoden wie LoRA und QLoRA
  - Implementierung der Feinabstimmung mit Microsoft Olive
  - Multi-Adapter-Training und Hyperparameter-Optimierung

- [**Abschnitt 4: Bereitstellung - Produktionsreife Implementierung**](./Module05/04.SLMOps.Deployment.md)
  - Modellkonvertierung und Quantisierung f√ºr die Produktion
  - Konfiguration der Foundry Local-Bereitstellung
  - Leistungsbenchmarking und Qualit√§tsvalidierung
  - 75 % Gr√∂√üenreduktion mit Produktions√ºberwachung

---

### [Modul 06: SLM Agentensysteme - KI-Agenten und Funktionsaufrufe](./Module06/README.md)
**Thema**: Implementierung von SLM-Agentensystemen von der Basis bis zu fortgeschrittenen Funktionsaufrufen und Integration des Model Context Protocols

#### Kapitelstruktur:
- [**Abschnitt 1: KI-Agenten und Grundlagen kleiner Sprachmodelle**](./Module06/01.IntroduceAgent.md)
  - Klassifizierungsrahmen f√ºr Agenten (Reflex-, modellbasierte, zielbasierte, lernende Agenten)
  - Grundlagen und Optimierungsstrategien f√ºr SLMs (GGUF, Quantisierung, Edge-Frameworks)
  - Analyse der Abw√§gungen zwischen SLM und LLM (10-30√ó Kostenreduktion, 70-80 % Aufgabenwirksamkeit)
  - Praktische Bereitstellung mit Ollama, VLLM und Microsoft Edge-L√∂sungen

- [**Abschnitt 2: Funktionsaufrufe in kleinen Sprachmodellen**](./Module06/02.FunctionCalling.md)
  - Systematische Workflow-Implementierung (Absichtserkennung, JSON-Ausgabe, externe Ausf√ºhrung)
  - Plattform-spezifische Implementierungen (Phi-4-mini, ausgew√§hlte Qwen-Modelle, Microsoft Foundry Local)
  - Fortgeschrittene Beispiele (Zusammenarbeit mehrerer Agenten, dynamische Werkzeugauswahl)
  - Produktions√ºberlegungen (Ratenbegrenzung, Protokollierung, Sicherheitsma√ünahmen)

- [**Abschnitt 3: Integration des Model Context Protocol (MCP)**](./Module06/03.IntroduceMCP.md)
  - Protokollarchitektur und gestufte Systemgestaltung
  - Unterst√ºtzung mehrerer Backends (Ollama f√ºr Entwicklung, vLLM f√ºr Produktion)
  - Verbindungsprotokolle (STDIO- und SSE-Modi)
  - Anwendungen in der Praxis (Web-Automatisierung, Datenverarbeitung, API-Integration)

---

### [Modul 07: EdgeAI Implementierungsbeispiele](./Module07/README.md)
**Thema**: Umfassende EdgeAI-Implementierungen auf verschiedenen Plattformen und Frameworks

#### Kapitelstruktur:
- [**AI-Toolkit f√ºr Visual Studio Code**](./Module07/aitoolkit.md)
  - Umfassende Edge AI-Entwicklungsumgebung innerhalb von VS Code
  - Modellkatalog und -entdeckung f√ºr Edge-Bereitstellung
  - Lokale Tests, Optimierung und Agentenentwicklungsworkflows
  - Leistungs√ºberwachung und Bewertung f√ºr Edge-Szenarien

- [**Windows EdgeAI Entwicklungsleitfaden**](./Module07/windowdeveloper.md)
  - Umfassender √úberblick √ºber die Windows AI Foundry-Plattform
  - Phi Silica API f√ºr effiziente NPU-Inferenz
  - Computer Vision APIs f√ºr Bildverarbeitung und OCR
  - Foundry Local CLI f√ºr lokale Entwicklung und Tests

- [**EdgeAI auf NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - 67 TOPS KI-Leistung in einer kreditkartengro√üen Form
  - Unterst√ºtzung generativer KI-Modelle (Vision-Transformer, LLMs, Vision-Language-Modelle)
  - Anwendungen in Robotik, Drohnen, intelligenten Kameras, autonomen Ger√§ten
  - Erschwingliche Plattform f√ºr 249 $ zur Demokratisierung der KI-Entwicklung

- [**EdgeAI in mobilen Anwendungen mit .NET MAUI und ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - Plattform√ºbergreifende mobile KI mit einer einzigen C#-Codebasis
  - Unterst√ºtzung f√ºr Hardwarebeschleunigung (CPU, GPU, mobile KI-Prozessoren)
  - Plattform-spezifische Optimierungen (CoreML f√ºr iOS, NNAPI f√ºr Android)
  - Vollst√§ndige Implementierung des generativen KI-Zyklus

- [**EdgeAI in Azure mit Small Language Models Engine**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Hybridarchitektur f√ºr Cloud-Edge-Bereitstellung
  - Integration von Azure AI-Diensten mit ONNX Runtime
  - Bereitstellung im Unternehmensma√üstab und kontinuierliches Modellmanagement
  - Hybride KI-Workflows f√ºr intelligente Dokumentenverarbeitung

- [**EdgeAI mit Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Grundlage der Windows AI Foundry f√ºr leistungsstarke On-Device-Inferenz
  - Universelle Hardwareunterst√ºtzung (AMD, Intel, NVIDIA, Qualcomm-Silizium)
  - Automatische Hardwareabstraktion und Optimierung
  - Einheitliches Framework f√ºr das vielf√§ltige Windows-Hardware-√ñkosystem

- [**EdgeAI mit Foundry Local Anwendungen**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Datenschutzorientierte RAG-Implementierung mit lokalen Ressourcen
  - Integration des Phi-4 Sprachmodells mit semantischer Suche (nur Phi-Modelle)
  - Unterst√ºtzung lokaler Vektordatenbanken (SQLite, Qdrant)
  - Datenhoheit und Offline-Betriebsf√§higkeit

### [Modul 08: Microsoft Foundry Local ‚Äì Komplettes Entwickler-Toolkit](./Module08/README.md)
**Thema**: KI lokal mit Foundry Local entwickeln, ausf√ºhren und integrieren; skalieren und hybridisieren mit Azure AI Foundry

#### Kapitelstruktur:
- [**1: Erste Schritte mit Foundry Local**](./Module08/01.FoundryLocalSetup.md)
- [**2: KI-L√∂sungen mit Azure AI Foundry entwickeln**](./Module08/02.AzureAIFoundryIntegration.md)
- [**3: Open-Source-Modelle in Foundry Local**](./Module08/03.OpenSourceModels.md)
- [**4: Spitzentechnologie-Modelle und On-Device-Inferenz**](./Module08/04.CuttingEdgeModels.md)
- [**5: KI-gest√ºtzte Agenten mit Foundry Local**](./Module08/05.AIPoweredAgents.md)
- [**6: Modelle als Werkzeuge**](./Module08/06.ModelsAsTools.md)

## Kurslernziele

Durch den Abschluss dieses umfassenden EdgeAI-Kurses entwickeln Sie die Expertise, um produktionsreife EdgeAI-L√∂sungen zu entwerfen, zu implementieren und bereitzustellen. Unser strukturierter Ansatz stellt sicher, dass Sie sowohl theoretische Grundlagen als auch praktische Implementierungsf√§higkeiten meistern.

### Technische Kompetenzen

**Grundlagenwissen**
- Verstehen der grundlegenden Unterschiede zwischen cloudbasierten und edgebasierten KI-Architekturen
- Beherrschen der Prinzipien der Modellquantisierung, -kompression und -optimierung f√ºr ressourcenbeschr√§nkte Umgebungen
- Verst√§ndnis der Optionen zur Hardwarebeschleunigung (NPUs, GPUs, CPUs) und deren Auswirkungen auf die Bereitstellung

**Implementierungsf√§higkeiten**
- Bereitstellung kleiner Sprachmodelle auf verschiedenen Edge-Plattformen (mobil, eingebettet, IoT, Edge-Server)
- Anwendung von Optimierungsframeworks wie Llama.cpp, Microsoft Olive, ONNX Runtime und Apple MLX
- Implementierung von Echtzeit-Inferenzsystemen mit Anforderungen an sub-sekunden Reaktionszeiten

**Produktionskompetenz**
- Entwurf skalierbarer EdgeAI-Architekturen f√ºr Unternehmensanwendungen
- Implementierung von √úberwachungs-, Wartungs- und Aktualisierungsstrategien f√ºr bereitgestellte Systeme
- Anwendung von Sicherheitsbest Practices f√ºr datenschutzfreundliche EdgeAI-Implementierungen

### Strategische F√§higkeiten

**Entscheidungsrahmen**
- Bewertung von EdgeAI-M√∂glichkeiten und Identifizierung geeigneter Anwendungsf√§lle f√ºr Gesch√§ftsanwendungen
- Abw√§gung zwischen Modellgenauigkeit, Inferenzgeschwindigkeit, Stromverbrauch und Hardwarekosten
- Auswahl geeigneter SLM-Familien und Konfigurationen basierend auf spezifischen Bereitstellungsanforderungen

**Systemarchitektur**
- Entwurf von End-to-End-EdgeAI-L√∂sungen, die in bestehende Infrastrukturen integriert werden
- Planung hybrider Edge-Cloud-Architekturen f√ºr optimale Leistung und Kosteneffizienz
- Implementierung von Datenfluss- und Verarbeitungspipelines f√ºr Echtzeit-KI-Anwendungen

### Branchenanwendungen

**Praktische Bereitstellungsszenarien**
- **Fertigung**: Qualit√§tssicherungssysteme, vorausschauende Wartung und Prozessoptimierung
- **Gesundheitswesen**: Datenschutzfreundliche Diagnosetools und Patienten√ºberwachungssysteme
- **Transport**: Entscheidungsfindung f√ºr autonome Fahrzeuge und Verkehrsmanagement
- **Smart Cities**: Intelligente Infrastruktur- und Ressourcenmanagementsysteme
- **Verbraucherelektronik**: KI-gest√ºtzte mobile Anwendungen und Smart-Home-Ger√§te

## √úberblick √ºber die Lernergebnisse

### Modul 01 Lernergebnisse:
- Verst√§ndnis der grundlegenden Unterschiede zwischen Cloud- und Edge-KI-Architekturen
- Beherrschen grundlegender Optimierungstechniken f√ºr Edge-Bereitstellungen
- Erkennen von Anwendungen und Erfolgsgeschichten aus der Praxis
- Erwerb praktischer F√§higkeiten zur Implementierung von EdgeAI-L√∂sungen

### Modul 02 Lernergebnisse:
- Tiefes Verst√§ndnis verschiedener SLM-Designphilosophien und deren Auswirkungen auf die Bereitstellung
- Beherrschen strategischer Entscheidungsf√§higkeiten basierend auf Rechenbeschr√§nkungen und Leistungsanforderungen
- Verst√§ndnis der Flexibilit√§tsabstriche bei der Bereitstellung
- Zukunftsorientierte Einblicke in effiziente KI-Architekturen besitzen

### Modul 03 Lernergebnisse:
- Strategische Modellwahlf√§higkeiten
- Beherrschen von Optimierungstechniken
- Beherrschen der Flexibilit√§t bei der Bereitstellung
- Produktionsreife Konfigurationsf√§higkeiten

### Modul 04 Lernergebnisse:
- Tiefes Verst√§ndnis der Grenzen der Quantisierung und deren praktische Anwendungen
- Praktische Erfahrung mit mehreren Optimierungsframeworks (Llama.cpp, Olive, OpenVINO, MLX)
- Beherrschen der Intel-Hardwareoptimierung mit OpenVINO und NNCF
- Hardwarebewusste Auswahl von Optimierungen auf verschiedenen Plattformen
- Produktionsbereitstellungskompetenzen f√ºr plattform√ºbergreifende Edge-Computing-Umgebungen
- Strategische Auswahl von Frameworks und Synthese von Workflows f√ºr optimale EdgeAI-L√∂sungen

### Modul 05 Lernergebnisse:
- Beherrschen des SLMOps-Paradigmas und der Betriebsprinzipien
- Implementierung der Modelldestillation f√ºr Wissenstransfer und Effizienzoptimierung
- Anwendung von Feinabstimmungstechniken f√ºr dom√§nenspezifische Modellanpassung
- Bereitstellung produktionsreifer SLM-L√∂sungen mit √úberwachungs- und Wartungsstrategien

### Modul 06 Lernergebnisse:
- Verst√§ndnis der grundlegenden Konzepte von KI-Agenten und der Architektur kleiner Sprachmodelle
- Beherrschen der Implementierung von Funktionsaufrufen auf verschiedenen Plattformen und Frameworks
- Integration des Model Context Protocol (MCP) f√ºr standardisierte Interaktion mit externen Werkzeugen
- Aufbau fortschrittlicher Agentensysteme mit minimalen Anforderungen an menschliche Eingriffe

### Modul 07 Lernergebnisse:
- Beherrschen des AI-Toolkits f√ºr Visual Studio Code f√ºr umfassende EdgeAI-Entwicklungsworkflows
- Expertise in der Windows AI Foundry-Plattform und NPU-Optimierungsstrategien
- Praktische Erfahrung mit verschiedenen EdgeAI-Plattformen und Implementierungsstrategien
- Beherrschen hardware-spezifischer Optimierungstechniken auf NVIDIA-, mobilen-, Azure- und Windows-Plattformen
- Verst√§ndnis der Abw√§gungen zwischen Leistung, Kosten und Datenschutzanforderungen bei der Bereitstellung
- Entwicklung praktischer F√§higkeiten f√ºr den Aufbau realer EdgeAI-Anwendungen in verschiedenen √ñkosystemen

## Erwartete Kursziele

Nach erfolgreichem Abschluss dieses Kurses sind Sie mit dem Wissen, den F√§higkeiten und dem Selbstvertrauen ausgestattet, um EdgeAI-Initiativen in professionellen Umgebungen zu leiten.

### Berufliche Einsatzbereitschaft

**Technische F√ºhrung**
- **L√∂sungsarchitektur**: Entwurf umfassender EdgeAI-Systeme, die Unternehmensanforderungen erf√ºllen
- **Leistungsoptimierung**: Erreichen eines optimalen Gleichgewichts zwischen Genauigkeit, Geschwindigkeit und Ressourcenverbrauch
- **Plattform√ºbergreifende Bereitstellung**: Implementierung von L√∂sungen auf Windows-, Linux-, mobilen- und eingebetteten Plattformen
- **Produktionsbetrieb**: Wartung und Skalierung von EdgeAI-Systemen mit unternehmensgerechter Zuverl√§ssigkeit

**Branchenexpertise**
- **Technologiebewertung**: Bewertung und Empfehlung von EdgeAI-L√∂sungen f√ºr spezifische gesch√§ftliche Herausforderungen
- **Implementierungsplanung**: Entwicklung realistischer Zeitpl√§ne und Ressourcenanforderungen f√ºr EdgeAI-Projekte
- **Risikomanagement**: Identifizieren und mindern technischer und operativer Risiken bei EdgeAI-Eins√§tzen  
- **ROI-Optimierung**: Nachweis des messbaren Gesch√§ftswerts von EdgeAI-Implementierungen  

### Karrierechancen  

**Berufliche Rollen**  
- EdgeAI Solutions Architect  
- Machine Learning Engineer (Edge-Spezialisierung)  
- IoT AI Developer  
- Mobile AI Application Developer  
- Enterprise AI Consultant  

**Industriesektoren**  
- Intelligente Fertigung und Industrie 4.0  
- Autonome Fahrzeuge und Transportwesen  
- Gesundheitstechnologie und medizinische Ger√§te  
- Finanztechnologie und Sicherheit  
- Unterhaltungselektronik und mobile Anwendungen  

### Zertifizierung und Validierung  

**Portfolioentwicklung**  
- Abschlie√üen von End-to-End-EdgeAI-Projekten, die praktische Kompetenz demonstrieren  
- Bereitstellung produktionsreifer L√∂sungen auf verschiedenen Hardwareplattformen  
- Dokumentation von Optimierungsstrategien und erzielten Leistungsverbesserungen  

**Kontinuierlicher Lernpfad**  
- Grundlage f√ºr fortgeschrittene AI-Spezialisierungen  
- Vorbereitung auf Cloud-Edge-Hybridarchitekturen  
- Einstieg in aufkommende AI-Technologien und Frameworks  

Dieser Kurs positioniert Sie an der Spitze der AI-Technologie-Eins√§tze, bei denen intelligente Funktionen nahtlos in die Ger√§te und Systeme integriert werden, die das moderne Leben antreiben.  

## Dateistruktur-Baumdiagramm  

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.openvino.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.AppleMLX.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.workflow-synthesis.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îú‚îÄ‚îÄ aitoolkit.md
‚îÇ   ‚îú‚îÄ‚îÄ windowdeveloper.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module08/ (Hands on with Foundry Local)
‚îÇ   ‚îú‚îÄ‚îÄ 01.FoundryLocalSetup.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.AzureAIFoundryIntegration.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.OpenSourceModels.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.CuttingEdgeModels.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.AIPoweredAgents.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.ModelsAsTools.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```
  

## Kursmerkmale  

- **Progressives Lernen**: Schrittweise Weiterentwicklung von grundlegenden Konzepten bis hin zu fortgeschrittenen Eins√§tzen  
- **Integration von Theorie und Praxis**: Jedes Modul enth√§lt sowohl theoretische Grundlagen als auch praktische Anwendungen  
- **Echte Fallstudien**: Basierend auf tats√§chlichen F√§llen von Microsoft, Alibaba, Google und anderen  
- **Praktische √úbungen**: Vollst√§ndige Konfigurationsdateien, API-Testverfahren und Bereitstellungsskripte  
- **Leistungsbenchmarks**: Detaillierte Vergleiche von Inferenzgeschwindigkeit, Speicherverbrauch und Ressourcenanforderungen  
- **Unternehmensgerechte √úberlegungen**: Sicherheitspraktiken, Compliance-Frameworks und Datenschutzstrategien  

## Erste Schritte  

Empfohlener Lernpfad:  
1. Beginnen Sie mit **Module01**, um ein grundlegendes Verst√§ndnis von EdgeAI aufzubauen  
2. Fahren Sie mit **Module02** fort, um verschiedene SLM-Modellfamilien eingehend zu verstehen  
3. Lernen Sie **Module03**, um praktische Einsatzf√§higkeiten zu meistern  
4. Weiter mit **Module04** f√ºr fortgeschrittene Modelloptimierung, Formatkonvertierung und Framework-Synthese  
5. Schlie√üen Sie **Module05** ab, um SLMOps f√ºr produktionsreife Implementierungen zu beherrschen  
6. Erkunden Sie **Module06**, um SLM-agentische Systeme und Funktionalit√§ten zu verstehen  
7. Beenden Sie mit **Module07**, um praktische Erfahrungen mit dem AI Toolkit und verschiedenen EdgeAI-Implementierungsbeispielen zu sammeln  
8. Erkunden Sie **Module08** f√ºr ein vollst√§ndiges Foundry Local Entwickler-Toolkit (lokale Entwicklung mit hybrider Azure-Integration)  

Jedes Modul ist eigenst√§ndig abgeschlossen, aber ein sequenzielles Lernen liefert die besten Ergebnisse.  

## Studienleitfaden  

Ein umfassender [Studienleitfaden](STUDY_GUIDE.md) steht zur Verf√ºgung, um Ihnen zu helfen, das Beste aus Ihrem Lernerlebnis herauszuholen. Der Studienleitfaden bietet:  

- **Strukturierte Lernpfade**: Optimierte Zeitpl√§ne f√ºr den Abschluss des Kurses in 20 Stunden  
- **Zeitmanagement-Empfehlungen**: Spezifische Vorschl√§ge zur Balance zwischen Lesen, √úbungen und Projekten  
- **Schwerpunkt auf Schl√ºsselkonzepten**: Priorisierte Lernziele f√ºr jedes Modul  
- **Selbstbewertungswerkzeuge**: Fragen und √úbungen zur √úberpr√ºfung Ihres Verst√§ndnisses  
- **Mini-Projektideen**: Praktische Anwendungen zur Vertiefung Ihres Lernens  

Der Studienleitfaden ist sowohl f√ºr intensives Lernen (1 Woche) als auch f√ºr Teilzeitstudium (3 Wochen) konzipiert und bietet klare Anleitungen, wie Sie Ihre Zeit effektiv nutzen k√∂nnen, selbst wenn Sie nur 10 Stunden f√ºr den Kurs aufbringen k√∂nnen.  

---  

**Die Zukunft von EdgeAI liegt in der kontinuierlichen Verbesserung von Modellarchitekturen, Quantisierungstechniken und Einsatzstrategien, die Effizienz und Spezialisierung gegen√ºber allgemeinen F√§higkeiten priorisieren. Organisationen, die diesen Paradigmenwechsel annehmen, werden gut positioniert sein, um das transformative Potenzial von AI zu nutzen und gleichzeitig die Kontrolle √ºber ihre Daten und Abl√§ufe zu behalten.**  

## Weitere Kurse  

Unser Team bietet weitere Kurse an! Schauen Sie sich folgende an:  

- [MCP f√ºr Anf√§nger](https://github.com/microsoft/mcp-for-beginners)  
- [AI Agents f√ºr Anf√§nger](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [Generative AI f√ºr Anf√§nger mit .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)  
- [Generative AI f√ºr Anf√§nger mit JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)  
- [Generative AI f√ºr Anf√§nger](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [ML f√ºr Anf√§nger](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)  
- [Data Science f√ºr Anf√§nger](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)  
- [AI f√ºr Anf√§nger](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)  
- [Cybersecurity f√ºr Anf√§nger](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)  
- [Webentwicklung f√ºr Anf√§nger](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)  
- [IoT f√ºr Anf√§nger](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)  
- [XR-Entwicklung f√ºr Anf√§nger](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [GitHub Copilot meistern f√ºr AI Pair Programming](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)  
- [GitHub Copilot meistern f√ºr C#/.NET-Entwickler](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)  
- [W√§hlen Sie Ihr eigenes Copilot-Abenteuer](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)  

---

