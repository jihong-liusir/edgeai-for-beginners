<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2305e750e93ad4bd79898cf149e01b49",
  "translation_date": "2025-10-03T05:35:55+00:00",
  "source_file": "Module07/windowdeveloper.md",
  "language_code": "mo"
}
-->
# Windows Edge AI 開發指南

## 簡介

歡迎來到 Windows Edge AI 開發指南！這是一份全面的指南，幫助您使用 Microsoft 的 Windows AI Foundry 平台構建智能應用程式，充分利用設備上的 AI 能力。本指南專為希望將尖端的 Edge AI 功能整合到應用程式中的 Windows 開發者設計，同時充分利用 Windows 硬體加速的優勢。

### Windows AI 的優勢

Windows AI Foundry 提供了一個統一、可靠且安全的平台，支持完整的 AI 開發生命周期——從模型選擇和微調到優化和部署，涵蓋 CPU、GPU、NPU 和混合雲架構。此平台通過以下方式使 AI 開發更加普及：

- **硬體抽象**：無縫部署於 AMD、Intel、NVIDIA 和 Qualcomm 晶片
- **設備端智能**：完全在本地硬體上運行，保護隱私的 AI
- **性能優化**：針對 Windows 硬體配置預先優化的模型
- **企業級準備**：生產級安全性和合規功能

### Windows ML
Windows 機器學習 (ML) 使 C#、C++ 和 Python 開發者能夠通過 ONNX Runtime 在 Windows PC 上本地運行 ONNX AI 模型，並自動管理不同硬體（CPU、GPU、NPU）的執行提供者。[ONNX Runtime](https://onnxruntime.ai/docs/) 可與 PyTorch、Tensorflow/Keras、TFLite、scikit-learn 和其他框架的模型一起使用。

![WindowsML 一個圖表展示 ONNX 模型通過 Windows ML 到達 NPU、GPU 和 CPU 的過程。](https://learn.microsoft.com/en-us/windows/ai/images/winml-diagram.png)

Windows ML 提供了一個共享的 Windows 範圍內的 ONNX Runtime 副本，以及動態下載執行提供者 (EPs) 的能力。

### 為什麼選擇 Windows 作為 Edge AI 平台？

**通用硬體支持**  
Windows ML 提供自動硬體優化，覆蓋整個 Windows 生態系統，確保您的 AI 應用程式無論底層晶片架構如何都能最佳運行。

**集成 AI 運行時**  
內建的 Windows ML 推理引擎消除了複雜的設置需求，使開發者能專注於應用程式邏輯而非基礎設施問題。

**Copilot+ PC 優化**  
專為配備專用神經處理單元 (NPU) 的下一代 Windows 設備設計的 API，提供卓越的性能與功耗比。

**開發者生態系統**  
豐富的工具，包括 Visual Studio 集成、全面的文檔和示例應用程式，加速開發周期。

## 學習目標

完成此 Windows Edge AI 開發指南後，您將掌握在 Windows 平台上構建生產級 AI 應用程式的必要技能。

### 核心技術能力

**Windows AI Foundry 精通**  
- 理解 Windows AI Foundry 平台的架構和組件  
- 掌握 Windows 生態系統中的完整 AI 開發生命周期  
- 實施設備端 AI 應用程式的安全最佳實踐  
- 優化應用程式以適應不同的 Windows 硬體配置  

**API 集成專業知識**  
- 精通 Windows AI API，用於文本、視覺和多模態應用程式  
- 實現 Phi Silica 語言模型集成，用於文本生成和推理  
- 使用內建的圖像處理 API 部署計算機視覺功能  
- 使用 LoRA（低秩適應）技術定制預訓練模型  

**Foundry Local 實施**  
- 使用 Foundry Local CLI 瀏覽、評估和部署開源語言模型  
- 理解模型優化和量化以進行本地部署  
- 實現無需網路連接的離線 AI 功能  
- 管理生產環境中的模型生命周期和更新  

**Windows ML 部署**  
- 使用 Windows ML 將自定義 ONNX 模型引入 Windows 應用程式  
- 利用 CPU、GPU 和 NPU 架構的自動硬體加速  
- 實現資源利用率最佳化的實時推理  
- 為多樣化的 Windows 設備類別設計可擴展的 AI 應用程式  

### 應用程式開發技能

**跨平台 Windows 開發**  
- 使用 .NET MAUI 構建 AI 驅動的應用程式，實現通用 Windows 部署  
- 將 AI 功能整合到 Win32、UWP 和漸進式 Web 應用程式中  
- 實現適應 AI 處理狀態的響應式 UI 設計  
- 使用適當的用戶體驗模式處理異步 AI 操作  

**性能優化**  
- 在不同硬體配置中分析和優化 AI 推理性能  
- 為大型語言模型實現高效的內存管理  
- 設計能根據可用硬體能力優雅降級的應用程式  
- 為常用的 AI 操作應用緩存策略  

**生產準備**  
- 實施全面的錯誤處理和回退機制  
- 設計 AI 應用程式性能的遙測和監控  
- 為本地 AI 模型存儲和執行應用安全最佳實踐  
- 為企業和消費者應用程式規劃部署策略  

### 商業和戰略理解

**AI 應用程式架構**  
- 設計在本地和雲端 AI 處理之間優化的混合架構  
- 評估模型大小、準確性和推理速度之間的權衡  
- 規劃在保持隱私的同時實現智能的數據流架構  
- 實施隨著用戶需求擴展的成本效益 AI 解決方案  

**市場定位**  
- 理解 Windows 原生 AI 應用程式的競爭優勢  
- 識別設備端 AI 提供卓越用戶體驗的使用案例  
- 為 AI 增強的 Windows 應用程式制定市場策略  
- 將應用程式定位於利用 Windows 生態系統的優勢  

## Windows App SDK AI 示例

Windows App SDK 提供了全面的示例，展示了 AI 在多個框架和部署場景中的集成。這些示例是理解 Windows AI 開發模式的重要參考。

### Windows AI Foundry 示例

| 示例 | 框架 | 重點領域 | 主要功能 |
|------|------|----------|----------|
| [cs-winui](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsAIFoundry/cs-winui) | C# WinUI 3 | Windows AI API 集成 | 完整的 WinUI 應用程式，展示 Windows AI API、ARM64 優化、打包部署 |

**主要技術：**  
- Windows AI API  
- WinUI 3 框架  
- ARM64 平台優化  
- Copilot+ PC 兼容性  
- 打包應用程式部署  

**先決條件：**  
- 建議使用 Windows 11 和 Copilot+ PC  
- Visual Studio 2022  
- ARM64 構建配置  
- Windows App SDK 1.8.1+  

### Windows ML 示例

#### C++ 示例

| 示例 | 類型 | 重點領域 | 主要功能 |
|------|------|----------|----------|
| [CppConsoleDesktop](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cpp) | 控制台應用程式 | 基本 Windows ML | EP 探索、命令行選項、模型編譯 |
| [CppConsoleDesktop.FrameworkDependent](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cpp) | 控制台應用程式 | 框架部署 | 共享運行時、更小的部署足跡 |
| [CppConsoleDesktop.SelfContained](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cpp) | 控制台應用程式 | 自包含部署 | 獨立部署，無運行時依賴 |
| [CppConsoleDll](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cpp) | DLL | 庫使用 | WindowsML 在共享庫中的使用，內存管理 |
| [CppResnetBuildDemo](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cpp) | 演示 | ResNet 教程 | 模型轉換、EP 編譯、Build 2025 教程 |

#### C# 示例

**控制台應用程式**

| 示例 | 類型 | 重點領域 | 主要功能 |
|------|------|----------|----------|
| [CSharpConsoleDesktop](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cs) | 控制台應用程式 | 基本 C# 集成 | 共享助手使用、命令行界面 |
| [ResnetBuildDemoCS](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cs) | 演示 | ResNet 教程 | 模型轉換、EP 編譯、Build 2025 教程 |

**GUI 應用程式**

| 示例 | 框架 | 重點領域 | 主要功能 |
|------|------|----------|----------|
| [cs-wpf](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cs-wpf) | WPF | 桌面 GUI | 使用 WPF 界面的圖像分類 |
| [cs-winforms](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cs-winforms) | Windows Forms | 傳統 GUI | 使用 Windows Forms 的圖像分類 |
| [cs-winui](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/cs-winui) | WinUI 3 | 現代 GUI | 使用 WinUI 3 界面的圖像分類 |

#### Python 示例

| 示例 | 語言 | 重點領域 | 主要功能 |
|------|------|----------|----------|
| [SqueezeNetPython](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML/python) | Python | 圖像分類 | WinML Python 綁定，批量圖像處理 |

### 示例先決條件

**系統要求：**  
- 運行版本 24H2（build 26100）或更高版本的 Windows 11 PC  
- Visual Studio 2022，包含 C++ 和 .NET 工作負載  
- Windows App SDK 1.8.1 或更高版本  
- 適用於 x64 和 ARM64 設備的 Python 3.10-3.13  

**Windows AI Foundry 特定要求：**  
- 建議使用 Copilot+ PC 以獲得最佳性能  
- Windows AI 示例的 ARM64 構建配置  
- 需要包身份（不再支持未打包的應用程式）  

### 常見示例工作流程

大多數 Windows ML 示例遵循以下標準模式：

1. **初始化環境** - 創建 ONNX Runtime 環境  
2. **註冊執行提供者** - 探索並註冊可用的硬體加速器（CPU、GPU、NPU）  
3. **加載模型** - 加載 ONNX 模型，可選擇為目標硬體編譯  
4. **預處理輸入** - 將圖像/數據轉換為模型輸入格式  
5. **運行推理** - 執行模型並獲得預測結果  
6. **處理結果** - 應用 softmax 並顯示最高預測結果  

### 使用的模型文件

| 模型 | 用途 | 是否包含 | 備註 |
|------|------|----------|------|
| SqueezeNet | 輕量級圖像分類 | ✅ 包含 | 預訓練，隨時可用 |
| ResNet-50 | 高準確度圖像分類 | ❌ 需要轉換 | 使用 [AI 工具包](https://code.visualstudio.com/docs/intelligentapps/modelconversion) 進行轉換 |

### 硬體支持

所有示例都能自動檢測並利用可用硬體：  
- **CPU** - 所有 Windows 設備的通用支持  
- **GPU** - 自動檢測並優化可用的圖形硬體  
- **NPU** - 在支持的設備（Copilot+ PC）上利用神經處理單元  

## Windows AI Foundry 平台組件

### 1. Windows AI API

Windows AI API 提供即用型 AI 功能，由設備端模型驅動，針對 Copilot+ PC 設備進行效率和性能優化，且設置需求極低。

#### 核心 API 類別

**Phi Silica 語言模型**  
- 小型但功能強大的語言模型，用於文本生成和推理  
- 針對實時推理進行優化，功耗極低  
- 支持使用 LoRA 技術進行自定義微調  
- 與 Windows 語義搜索和知識檢索集成  

**計算機視覺 API**  
- **文本識別 (OCR)**：高準確度提取圖像中的文本  
- **圖像超分辨率**：使用本地 AI 模型提升圖像質量  
- **圖像分割**：識別並隔離圖像中的特定對象  
- **圖像描述**：為視覺內容生成詳細的文本描述  
- **對象擦除**：使用 AI 驅動的修補技術移除圖像中的不需要對象  

**多模態功能**  
- **視覺-語言集成**：結合文本和圖像理解  
- **語義搜索**：支持自然語言查詢多媒體內容  
- **知識檢索**：使用本地數據構建智能搜索體驗  

### 2. Foundry Local

Foundry Local 為開發者提供快速訪問 Windows Silicon 上即用型開源語言模型的能力，支持瀏覽、測試、交互和在本地應用程式中部署模型。

#### Foundry Local 示例應用程式

[Foundry Local 存儲庫](https://github.com/microsoft/Foundry-Local/tree/main/samples) 提供了多種編程語言和框架的全面示例，展示了各種集成模式和使用案例。

| 示例 | 語言/框架 | 重點領域 | 主要功能 |
|------|----------|----------|----------|
| [dotNET/rag](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag) | C# / .NET | RAG 實現 | 語義內核集成、Qdrant 向量存儲、JINA 嵌入、文檔攝取、流式聊天 |
| [electron/foundry-chat](https://github.com/microsoft/Foundry-Local/tree/main/samples/electron/foundry-chat) | JavaScript / Electron | 桌面聊天應用程式 | 跨平台聊天、本地/雲模型切換、OpenAI SDK 集成、實時流式 |
| [js/hello-foundry-local](https://github.com/microsoft/Foundry-Local/tree/main/samples/js/hello-foundry-local) | JavaScript / Node.js | 基本集成 | 簡單 SDK 使用、模型初始化、基本聊天功能 |
| [python/hello-foundry-local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local) | Python | 基本集成 | Python SDK 使用、流式響應、OpenAI 兼容 API |
| [rust/hello-foundry-local](https://github.com/microsoft/Foundry-Local/tree/main/samples/rust/hello-foundry-local) | Rust | 系統整合 | 低層級 SDK 使用、非同步操作、reqwest HTTP 客戶端 |

#### 根據使用案例分類的範例

**RAG (檢索增強生成)**
- **dotNET/rag**: 使用 Semantic Kernel、Qdrant 向量資料庫和 JINA 嵌入的完整 RAG 實現
- **架構**: 文件導入 → 文本分塊 → 向量嵌入 → 相似性搜索 → 上下文感知回應
- **技術**: Microsoft.SemanticKernel、Qdrant.Client、BERT ONNX 嵌入、串流聊天完成

**桌面應用程式**
- **electron/foundry-chat**: 可投入生產的聊天應用程式，支援本地/雲端模型切換
- **功能**: 模型選擇器、串流回應、錯誤處理、跨平台部署
- **架構**: Electron 主進程、IPC 通訊、安全預載腳本

**SDK 整合範例**
- **JavaScript (Node.js)**: 基本模型互動和串流回應
- **Python**: 使用 OpenAI 兼容 API 的非同步串流
- **Rust**: 使用 reqwest 和 tokio 進行非同步操作的低層級整合

#### Foundry Local 範例的先決條件

**系統需求:**
- 安裝 Foundry Local 的 Windows 11
- JavaScript/Electron 範例需要 Node.js v16+
- C# 範例需要 .NET 8.0+
- Python 範例需要 Python 3.10+
- Rust 範例需要 Rust 1.70+

**安裝:**
```powershell
# Install Foundry Local
winget install Microsoft.FoundryLocal

# Verify installation
foundry --version
foundry model list
```

#### 特定範例的設置

**dotNET RAG 範例:**
```powershell
# Install required packages via NuGet
# Microsoft.SemanticKernel.Connectors.Onnx
# Microsoft.SemanticKernel.Connectors.Qdrant
# Qdrant.Client

# Start Qdrant vector database
docker run -p 6333:6333 qdrant/qdrant

# Run Jupyter notebook
jupyter notebook rag_foundrylocal_demo.ipynb
```

**Electron 聊天範例:**
```powershell
# Set environment variables for cloud fallback
$env:YOUR_API_KEY="your-cloud-api-key"
$env:YOUR_ENDPOINT="your-cloud-endpoint"
$env:YOUR_MODEL_NAME="your-cloud-model"

# Install dependencies and run
npm install
npm start
```

**JavaScript/Python/Rust 範例:**
```powershell
# Download model (example with phi-3.5-mini)
foundry model run phi-3.5-mini

# Run respective sample
node src/app.js          # JavaScript
python src/app.py        # Python
cargo run               # Rust
```

#### 主要功能

**模型目錄**
- 全面收集預優化的開源模型
- 模型在 CPU、GPU 和 NPU 上進行優化，可立即部署
- 支援流行的模型系列，包括 Llama、Mistral、Phi，以及專業領域模型

**CLI 整合**
- 用於模型管理和部署的命令列介面
- 自動化優化和量化工作流程
- 與流行的開發環境和 CI/CD 管道整合

**本地部署**
- 完全離線操作，無需雲端依賴
- 支援自定義模型格式和配置
- 高效的模型服務，具備自動硬體優化功能

### 3. Windows ML

Windows ML 是 Windows 上的核心 AI 平台和整合推理運行時，允許開發者高效地在廣泛的 Windows 硬體生態系統中部署自定義模型。

#### 架構優勢

**通用硬體支援**
- 自動優化 AMD、Intel、NVIDIA 和 Qualcomm 矽晶片
- 支援 CPU、GPU 和 NPU 執行，並可透明切換
- 硬體抽象層消除平台特定的優化工作

**模型靈活性**
- 支援 ONNX 模型格式，並可從流行框架自動轉換
- 使用生產級性能部署自定義模型
- 與現有的 Windows 應用程式架構整合

**企業整合**
- 與 Windows 安全性和合規框架兼容
- 支援企業部署和管理工具
- 與 Windows 設備管理和監控系統整合

## 開發工作流程

### 階段 1: 環境設置和工具配置

**開發環境準備**
1. 安裝 Visual Studio 2022，包含 C++ 和 .NET 工作負載
2. 安裝 Windows App SDK 1.8.1 或更高版本
3. 配置 Windows AI Foundry CLI 工具
4. 設置 Visual Studio Code 的 AI Toolkit 擴展
5. 建立性能分析和監控工具
6. 確保 ARM64 構建配置以優化 Copilot+ PC

**範例庫設置**
1. 克隆 [Windows App SDK Samples repository](https://github.com/microsoft/WindowsAppSDK-Samples)
2. 導航至 `Samples/WindowsAIFoundry/cs-winui` 以獲取 Windows AI API 範例
3. 導航至 `Samples/WindowsML` 以獲取全面的 Windows ML 範例
4. 查看目標平台的 [構建要求](https://learn.microsoft.com/windows/apps/windows-app-sdk/system-requirements)

**AI 開發畫廊探索**
- 探索範例應用程式和參考實現
- 測試 Windows AI API 的互動演示
- 查看源代碼以了解最佳實踐和模式
- 確定與您的特定使用案例相關的範例

### 階段 2: 模型選擇和整合

**需求分析**
- 定義 AI 功能的需求
- 建立性能約束和優化目標
- 評估隱私和安全需求
- 計劃部署架構和擴展策略

**模型評估**
- 使用 Foundry Local 測試適合您的使用案例的開源模型
- 根據自定義模型需求對 Windows AI API 進行基準測試
- 評估模型大小、準確性和推理速度之間的權衡
- 使用選定模型原型化整合方法

### 階段 3: 應用程式開發

**核心整合**
- 實現 Windows AI API 整合，並正確處理錯誤
- 設計適應 AI 處理工作流程的用戶界面
- 實施模型推理的緩存和優化策略
- 添加 AI 操作性能的遙測和監控

**測試和驗證**
- 在不同的 Windows 硬體配置上測試應用程式
- 在各種負載條件下驗證性能指標
- 為 AI 功能可靠性實施自動化測試
- 使用 AI 增強功能進行用戶體驗測試

### 階段 4: 優化和部署

**性能優化**
- 在目標硬體配置上分析應用程式性能
- 優化內存使用和模型加載策略
- 根據可用硬體能力實施自適應行為
- 為不同性能場景微調用戶體驗

**生產部署**
- 打包應用程式，包含正確的 AI 模型依賴項
- 實施模型和應用程式邏輯的更新機制
- 配置生產環境的監控和分析
- 計劃企業和消費者部署的推出策略

## 實際實現範例

### 範例 1: 智能文件處理應用程式

構建一個使用多種 AI 功能處理文件的 Windows 應用程式：

**使用技術:**
- Phi Silica 用於文件摘要和問題回答
- OCR API 用於從掃描文件中提取文本
- 圖像描述 API 用於圖表和圖形分析
- 自定義 ONNX 模型用於文件分類

**實現方法:**
- 設計具有可插拔 AI 組件的模塊化架構
- 為大型文件批次實現非同步處理
- 添加進度指示器和長時間運行操作的取消支持
- 包括敏感文件處理的離線功能

### 範例 2: 零售庫存管理系統

創建一個 AI 驅動的零售應用庫存系統：

**使用技術:**
- 圖像分割用於產品識別
- 自定義視覺模型用於品牌和類別分類
- Foundry Local 部署的專業零售語言模型
- 與現有 POS 和庫存系統整合

**實現方法:**
- 構建相機整合以進行實時產品掃描
- 實現條形碼和視覺產品識別
- 使用本地語言模型添加自然語言庫存查詢
- 設計可擴展的架構以支持多店部署

### 範例 3: 醫療文檔助手

開發一個保護隱私的醫療文檔工具：

**使用技術:**
- Phi Silica 用於醫療筆記生成和臨床決策支持
- OCR 用於數字化手寫醫療記錄
- 通過 Windows ML 部署的自定義醫療語言模型
- 本地向量存儲用於醫療知識檢索

**實現方法:**
- 確保完全離線操作以保護患者隱私
- 實現醫療術語驗證和建議
- 添加審計日誌以符合監管要求
- 設計與現有電子病歷系統的整合

## 性能優化策略

### 硬體感知開發

**NPU 優化**
- 設計應用程式以利用 Copilot+ PC 上的 NPU 功能
- 在無 NPU 的設備上實現優雅回退至 GPU/CPU
- 優化模型格式以支持 NPU 特定加速
- 監控 NPU 利用率和熱特性

**內存管理**
- 實現高效的模型加載和緩存策略
- 使用內存映射減少大型模型的啟動時間
- 為資源受限設備設計內存友好的應用程式
- 實施模型量化以優化內存使用

**電池效率**
- 優化 AI 操作以最小化功耗
- 根據電池狀態實施自適應處理
- 設計高效的背景處理以支持持續 AI 操作
- 使用功率分析工具優化能量使用

### 可擴展性考量

**多線程**
- 設計線程安全的 AI 操作以支持並行處理
- 實現高效的工作分配以利用可用核心
- 使用非阻塞的 async/await 模式進行 AI 操作
- 計劃針對不同硬體配置的線程池優化

**緩存策略**
- 為常用的 AI 操作實現智能緩存
- 設計模型更新的緩存失效策略
- 為昂貴的預處理操作使用持久緩存
- 為多用戶場景實現分佈式緩存

## 安全性和隱私最佳實踐

### 數據保護

**本地處理**
- 確保敏感數據永不離開本地設備
- 為 AI 模型和臨時數據實施安全存儲
- 使用 Windows 安全功能進行應用程式沙盒化
- 為存儲的模型和中間處理結果應用加密

**模型安全性**
- 在加載和執行之前驗證模型完整性
- 實施安全的模型更新機制
- 使用簽名模型防止篡改
- 為模型文件和配置應用訪問控制

### 合規考量

**監管對齊**
- 設計應用程式以符合 GDPR、HIPAA 和其他監管要求
- 為 AI 決策過程實施審計日誌
- 提供 AI 生成結果的透明性功能
- 允許用戶控制 AI 數據處理

**企業安全**
- 與 Windows 企業安全政策整合
- 支援通過企業管理工具進行托管部署
- 為 AI 功能實施基於角色的訪問控制
- 提供 AI 功能的管理控制

## 疑難排解和調試

### 常見開發挑戰

**構建配置問題**
- 確保 Windows AI API 範例的 ARM64 平台配置
- 驗證 Windows App SDK 版本兼容性（需要 1.8.1+）
- 檢查包身份是否正確配置（Windows AI API 必需）
- 驗證構建工具是否支持目標框架版本

**模型加載問題**
- 驗證 ONNX 模型與 Windows ML 的兼容性
- 檢查模型文件完整性和格式要求
- 驗證特定模型的硬體能力要求
- 調試模型加載期間的內存分配問題
- 確保硬體加速的執行提供者註冊

**部署模式考量**
- **自包含模式**: 完全支援，但部署大小較大
- **依賴框架模式**: 體積較小，但需要共享運行時
- **未打包應用程式**: 不再支援 Windows AI API
- 使用 `dotnet run -p:Platform=ARM64 -p:SelfContained=true` 進行自包含 ARM64 部署

**性能問題**
- 在不同硬體配置上分析應用程式性能
- 識別 AI 處理管道中的瓶頸
- 優化數據預處理和後處理操作
- 實施性能監控和警報

**整合困難**
- 使用正確的錯誤處理調試 API 整合問題
- 驗證輸入數據格式和預處理要求
- 徹底測試邊界情況和錯誤條件
- 實施全面的日誌記錄以調試生產問題

### 調試工具和技術

**Visual Studio 整合**
- 使用 AI Toolkit 調試器進行模型執行分析
- 實施 AI 操作的性能分析
- 使用正確的異常處理調試非同步 AI 操作
- 使用內存分析工具進行優化

**Windows AI Foundry 工具**
- 利用 Foundry Local CLI 進行模型測試和驗證
- 使用 Windows AI API 測試工具進行整合驗證
- 實施自定義日誌記錄以監控 AI 操作
- 創建 AI 功能可靠性的自動化測試

## 為應用程式未來做好準備

### 新興技術

**下一代硬體**
- 設計應用程式以利用未來的 NPU 功能
- 計劃支持更大的模型尺寸和複雜性
- 實施自適應架構以應對硬體的演變
- 考慮量子就緒算法以支持未來兼容性

**高級 AI 功能**
- 為跨更多數據類型的多模態 AI 整合做好準備
- 計劃支持多設備之間的實時協作 AI
- 設計支持聯邦學習功能
- 考慮邊緣-雲混合智能架構

### 持續學習和適應

**模型更新**
- 實施無縫的模型更新機制
- 設計應用程式以適應改進的模型功能
- 計劃支持現有模型的向後兼容性
- 實施 A/B 測試以評估模型性能

**功能演進**
- 設計可容納新 AI 功能的模塊化架構
- 計劃整合新興的 Windows AI API
- 實施功能標誌以逐步推出能力
- 設計可適應增強 AI 功能的用戶界面

## 結論

Windows Edge AI 開發代表了強大 AI 功能與穩健、安全且可擴展的 Windows 平台的融合。通過掌握 Windows AI Foundry 生態系統，開發者可以創建智能應用程式，提供卓越的用戶體驗，同時保持最高標準的隱私、安全和性能。

Windows AI API、Foundry Local 和 Windows ML 的結合提供了無與倫比的基礎，用於構建下一代智能 Windows 應用程式。隨著 AI 的不斷發展，Windows 平台確保您的應用程式能夠隨著新興技術擴展，同時在多樣化的 Windows 硬體生態系統中保持兼容性和性能。

無論您是在構建消費者應用程式、企業解決方案還是專業行業工具，Windows Edge AI 開發都能幫助您創建智能、響應迅速且深度整合的體驗，充分利用現代 Windows 設備的潛力。

## 附加資源

### 文件和學習
- [Windows AI Foundry 文件](https://learn.microsoft.com/windows/ai/)
- [Windows AI API 參考](https://learn.microsoft.com/windows/ai/apis/)
- [開始使用 Windows AI API 構建應用程式](https://learn.microsoft.com/windows/ai/apis/model-setup)
- [Foundry Local 入門](https://learn.microsoft.com/windows/ai/foundry-local/get-started/)
- [Windows ML 概述](https://learn.microsoft.com/windows/ai/new-windows-ml/overview/)
- [Windows App SDK 系統需求](https://docs.microsoft.com/windows/apps/windows-app-sdk/system-requirements)
- [Windows App SDK 開發環境設置](https://docs.microsoft.com/windows/apps/windows-app-sdk/set-up-your-development-environment)
- 

### 範例倉庫與程式碼
- [Windows App SDK 範例 - Windows AI Foundry](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsAIFoundry)
- [Windows App SDK 範例 - Windows ML](https://github.com/microsoft/WindowsAppSDK-Samples/tree/main/Samples/WindowsML)
- [ONNX Runtime 推論範例](https://github.com/microsoft/onnxruntime-inference-examples)
- [Windows App SDK 範例倉庫](https://github.com/microsoft/WindowsAppSDK-Samples)

### 開發工具
- [Visual Studio Code 的 AI 工具包](https://learn.microsoft.com/windows/ai/toolkit/)
- [AI 開發者畫廊](https://learn.microsoft.com/windows/ai/ai-dev-gallery/)
- [Windows AI 範例](https://learn.microsoft.com/windows/ai/samples/)
- [模型轉換工具](https://code.visualstudio.com/docs/intelligentapps/modelconversion)

### 技術支援
- [Windows ML 文件](https://learn.microsoft.com/windows/ai/new-windows-ml/overview)
- [ONNX Runtime 文件](https://onnxruntime.ai/docs/)
- [Windows App SDK 文件](https://docs.microsoft.com/windows/apps/windows-app-sdk/)
- [回報問題 - Windows App SDK 範例](https://github.com/microsoft/WindowsAppSDK-Samples/issues)

### 社群與支援
- [Windows 開發者社群](https://developer.microsoft.com/en-us/windows/)
- [Windows AI Foundry 部落格](https://blogs.windows.com/windowsdeveloper/)
- [Microsoft Learn AI 訓練](https://learn.microsoft.com/training/browse/?products=windows&subjects=artificial-intelligence)

---

*本指南旨在隨著快速發展的 Windows AI 生態系統不斷演進。定期更新以確保與最新平台功能和開發最佳實踐保持一致。*

[08. 探索 Microsoft Foundry Local - 完整開發者工具包](../Module08/README.md)

---

**免責聲明**：  
本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而產生的任何誤解或錯誤解釋不承擔責任。