<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T16:50:39+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "mo"
}
-->
# EdgeAI 初學者指南：學習路徑與學習計劃

### 集中學習路徑 (1週)

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第一天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第二天 | 模組2：SLM 基礎 | 3小時 |
| 第三天 | 模組3：SLM 部署 | 2小時 |
| 第四至五天 | 模組4：模型優化 (6個框架) | 4小時 |
| 第六天 | 模組5：SLMOps | 3小時 |
| 第七天 | 模組6-7：AI代理與開發工具 | 5小時 |

### 集中學習路徑 (2週)

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：AI代理 | 2小時 |
| 第13-14天 | 模組7：開發工具 | 3小時 |

### 兼職學習 (4週)

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：SLM代理系統 | 2小時 |
| 第13-14天 | 模組7：EdgeAI 實作範例 | 2小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|--------|----------------|-------------|--------------|
| 模組1：EdgeAI 基礎 | | | |
| 模組2：SLM 基礎 | | | |
| 模組3：SLM 部署 | | | |
| 模組4：模型優化 (6個框架) | | | |
| 模組5：SLMOps | | | |
| 模組6：SLM代理系統 | | | |
| 模組7：EdgeAI 實作範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習 (4週)

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

## 簡介

歡迎使用 EdgeAI 初學者學習指南！本文件旨在幫助您有效地學習課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，幫助您深入了解 EdgeAI 技術。

這是一門精簡的20小時課程，提供關於 EdgeAI 的基本知識，適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概述

本課程分為七個全面的模組：

1. **EdgeAI 基礎與轉型** - 理解核心概念與技術轉變
2. **小型語言模型 (SLM) 基礎** - 探索各種SLM家族及其架構
3. **小型語言模型部署** - 實現實際部署策略
4. **模型格式轉換與量化** - 使用6個框架進行高級優化，包括OpenVINO
5. **SLMOps - 小型語言模型運營** - 生產生命周期管理與部署
6. **SLM代理系統** - AI代理、函數調用與模型上下文協議
7. **EdgeAI 實作範例** - AI工具包、Windows開發與平台特定實作
8. **Microsoft Foundry Local – 完整開發工具包** - 本地優先開發與混合Azure整合 (模組08)

## 如何使用本學習指南

- **循序漸進學習**：按順序學習模組，獲得最連貫的學習體驗
- **知識檢查點**：使用每節後的自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑 (1週)

| 天數 | 重點 | 預估時數 |
|------|-------|-----------------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 6小時 |
| 第3-4天 | 模組2：SLM 基礎 | 8小時 |
| 第5天 | 模組3：SLM 部署 | 3小時 |
| 第6天 | 模組8：Foundry Local 工具包 | 3小時 |

### 兼職學習 (3週)

| 週數 | 重點 | 預估時數 |
|------|-------|-----------------|
| 第1週 | 模組1：EdgeAI 基礎 | 6-7小時 |
| 第2週 | 模組2：SLM 基礎 | 7-8小時 |
| 第3週 | 模組3：SLM 部署 (3小時) + 模組8：Foundry Local 工具包 (2-3小時) | 5-6小時 |

## 模組1：EdgeAI 基礎與轉型

### 主要學習目標

- 理解基於雲端與基於邊緣的AI之間的差異
- 掌握資源受限環境的核心優化技術
- 分析EdgeAI技術的實際應用
- 設置EdgeAI專案的開發環境

### 學習重點區域

#### 第一節：EdgeAI 基礎
- **重點概念**：
  - 邊緣與雲端計算範式
  - 模型量化技術
  - 硬體加速選項 (NPUs, GPUs, CPUs)
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文件](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文件](https://docs.edgeimpulse.com)

#### 第二節：實際案例研究
- **重點概念**：
  - Microsoft Phi & Mu 模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第三節：實際實作指南
- **重點概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI實作的評估方法

#### 第四節：邊緣部署硬體
- **重點概念**：
  - 硬體平台比較
  - 特定硬體的優化策略
  - 部署考量

### 自我評估問題

1. 比較基於雲端的AI與基於邊緣的AI實作。
2. 解釋三種優化模型以進行邊緣部署的關鍵技術。
3. 在邊緣運行AI模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬體加速器 (NPUs, GPUs, CPUs) 如何影響EdgeAI部署。

### 實作練習

1. **快速環境設置**：配置包含基本套件的最小開發環境 (30分鐘)
2. **模型探索**：下載並檢查一個預訓練的小型語言模型 (1小時)
3. **基本量化**：嘗試對一個小型模型進行簡單量化 (1小時)

## 模組2：小型語言模型 (SLM) 基礎

### 主要學習目標

- 理解不同SLM家族的架構原則
- 比較不同參數規模的模型能力
- 根據效率、能力和部署需求評估模型
- 辨識不同模型家族的適用場景

### 學習重點區域

#### 第一節：Microsoft Phi 模型家族
- **重點概念**：
  - 設計理念演變
  - 效率優先架構
  - 專業化能力

#### 第二節：Qwen 家族
- **重點概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第三節：Gemma 家族
- **重點概念**：
  - 研究驅動創新
  - 多模態能力
  - 移動優化

#### 第四節：BitNET 家族
- **重點概念**：
  - 1位元量化技術
  - 推理優化框架
  - 可持續性考量

#### 第五節：Microsoft Mu 模型
- **重點概念**：
  - 設備優先架構
  - 與Windows的系統整合
  - 隱私保護運作

#### 第六節：Phi-Silica
- **重點概念**：
  - NPU優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較Phi與Qwen模型家族的架構方法。
2. 解釋BitNET的量化技術與傳統量化的不同之處。
3. Mu模型在Windows整合方面的獨特優勢是什麼？
4. 描述Phi-Silica如何利用NPU硬體進行性能優化。
5. 對於一個有限連接的移動應用，哪個模型家族最適合？為什麼？

### 實作練習

1. **模型比較**：快速基準測試兩個不同的SLM模型 (1小時)
2. **簡單文本生成**：使用小型模型進行基本文本生成實作 (1小時)
3. **快速優化**：應用一種優化技術以提高推理速度 (1小時)

## 模組3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實作SLM
- 設計適合生產的EdgeAI應用配置

### 學習重點區域

#### 第一節：SLM 高級學習
- **重點概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第二節：本地環境部署
- **重點概念**：
  - Ollama平台部署
  - Microsoft Foundry本地解決方案
  - 框架比較分析

#### 第三節：容器化雲端部署
- **重點概念**：
  - vLLM高性能推理
  - 容器編排
  - ONNX Runtime實作

### 自我評估問題

1. 選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較Ollama與Microsoft Foundry Local作為部署選項。
3. 解釋容器化對SLM部署的好處。
4. 邊緣部署SLM的關鍵性能指標是什麼？
5. 描述從模型選擇到生產實作的完整部署工作流程。

### 實作練習

1. **基本本地部署**：使用Ollama部署一個簡單的SLM (1小時)
2. **性能檢查**：對已部署的模型進行快速基準測試 (30分鐘)
3. **簡單整合**：創建一個使用已部署模型的最小應用 (1小時)

## 模組4：模型格式轉換與量化

### 主要學習目標

- 掌握從1位元到8位元精度的高級量化技術
- 理解格式轉換策略 (GGUF, ONNX)
- 在六個框架中實作優化 (Llama.cpp, Olive, OpenVINO, MLX, 工作流程合成)
- 部署優化模型至Intel、Apple及跨平台硬體的生產邊緣環境

### 學習重點區域

#### 第一節：量化基礎
- **重點概念**：
  - 精度分類框架
  - 性能與準確性權衡
  - 記憶體占用優化

#### 第二節：Llama.cpp 實作
- **重點概念**：
  - 跨平台部署
  - GGUF格式優化
  - 硬體加速技術

#### 第三節：Microsoft Olive 套件
- **重點概念**：
  - 硬體感知優化
  - 企業級部署
  - 自動化優化工作流程

#### 第四節：OpenVINO 工具包
- **重點概念**：
  - Intel硬體優化
  - 神經網絡壓縮框架 (NNCF)
  - 跨平台推理部署
  - OpenVINO GenAI 用於LLM部署

#### 第五節：Apple MLX 框架
- **重點概念**:  
  - Apple Silicon 優化  
  - 統一記憶體架構  
  - LoRA 微調功能  

#### 第六章：邊緣 AI 開發工作流程綜合  
- **重點概念**:  
  - 統一工作流程架構  
  - 框架選擇決策樹  
  - 生產準備驗證  
  - 未來適應性策略  

### 自我評估問題  

1. 比較不同精度級別（1-bit 至 8-bit）的量化策略。  
2. 解釋 GGUF 格式在邊緣部署中的優勢。  
3. Microsoft Olive 的硬體感知優化如何提升部署效率？  
4. OpenVINO 的 NNCF 在模型壓縮方面的主要優勢是什麼？  
5. Apple MLX 如何利用統一記憶體架構進行優化？  
6. 工作流程綜合如何幫助選擇最佳的優化框架？  

### 實作練習  

1. **模型量化**: 對模型應用不同的量化級別並比較結果（1 小時）  
2. **OpenVINO 優化**: 使用 NNCF 壓縮模型以適配 Intel 硬體（1 小時）  
3. **框架比較**: 在三個不同的優化框架中測試同一模型（1 小時）  
4. **效能基準測試**: 測量優化對推理速度和記憶體使用的影響（1 小時）  

## 第五章：SLMOps - 小型語言模型操作  

### 核心學習目標  

- 理解 SLMOps 生命週期管理原則  
- 掌握針對邊緣部署的蒸餾和微調技術  
- 實施具有監控功能的生產部署策略  
- 建立企業級 SLM 操作和維護工作流程  

### 學習重點領域  

#### 第一節：SLMOps 簡介  
- **重點概念**:  
  - SLMOps 在 AI 操作中的範式轉變  
  - 成本效益和隱私優先架構  
  - 戰略商業影響和競爭優勢  

#### 第二節：模型蒸餾  
- **重點概念**:  
  - 知識轉移技術  
  - 雙階段蒸餾過程實施  
  - Azure ML 蒸餾工作流程  

#### 第三節：微調策略  
- **重點概念**:  
  - 參數高效微調（PEFT）  
  - LoRA 和 QLoRA 高級方法  
  - 多適配器訓練和超參數優化  

#### 第四節：生產部署  
- **重點概念**:  
  - 生產模型轉換和量化  
  - Foundry Local 部署配置  
  - 效能基準測試和品質驗證  

### 自我評估問題  

1. SLMOps 與傳統 MLOps 有何不同？  
2. 解釋模型蒸餾在邊緣部署中的優勢。  
3. 微調 SLMs 在資源受限環境中的主要考量是什麼？  
4. 描述完整的邊緣 AI 應用生產部署管道。  

### 實作練習  

1. **基礎蒸餾**: 從較大的教師模型創建較小的模型（1 小時）  
2. **微調實驗**: 為特定領域微調模型（1 小時）  
3. **部署管道**: 設置基本的 CI/CD 管道以進行模型部署（1 小時）  

## 第六章：SLM Agentic Systems - AI 代理與函數調用  

### 核心學習目標  

- 使用小型語言模型為邊緣環境構建智能 AI 代理  
- 實施具有系統化工作流程的函數調用功能  
- 掌握模型上下文協議（MCP）集成以標準化工具交互  
- 創建高級代理系統，減少人為干預  

### 學習重點領域  

#### 第一節：AI 代理與 SLM 基礎  
- **重點概念**:  
  - 代理分類框架（反射型、基於模型、目標導向型、學習型代理）  
  - SLM 與 LLM 的權衡分析  
  - 邊緣特定代理設計模式  
  - 代理資源優化  

#### 第二節：小型語言模型中的函數調用  
- **重點概念**:  
  - 系統化工作流程實施（意圖檢測、JSON 輸出、外部執行）  
  - 平台特定實施（Phi-4-mini、選定的 Qwen 模型、Microsoft Foundry Local）  
  - 高級示例（多代理協作、動態工具選擇）  
  - 生產考量（速率限制、審計記錄、安全措施）  

#### 第三節：模型上下文協議（MCP）集成  
- **重點概念**:  
  - 協議架構和分層系統設計  
  - 多後端支持（Ollama 用於開發，vLLM 用於生產）  
  - 連接協議（STDIO 和 SSE 模式）  
  - 實際應用（網頁自動化、數據處理、API 集成）  

### 自我評估問題  

1. 邊緣 AI 代理的主要架構考量是什麼？  
2. 函數調用如何增強代理功能？  
3. 解釋模型上下文協議在代理通信中的角色。  

### 實作練習  

1. **簡單代理**: 構建具有函數調用功能的基本 AI 代理（1 小時）  
2. **MCP 集成**: 在代理應用中實施 MCP（30 分鐘）  

## 第七章：邊緣 AI 實施範例  

### 核心學習目標  

- 掌握 Visual Studio Code 的 AI Toolkit，實現全面的邊緣 AI 開發工作流程  
- 精通 Windows AI Foundry 平台和 NPU 優化策略  
- 在多個硬體平台和部署場景中實施邊緣 AI  
- 使用平台特定的優化構建生產就緒的邊緣 AI 應用  

### 學習重點領域  

#### 第一節：Visual Studio Code 的 AI Toolkit  
- **重點概念**:  
  - 在 VS Code 中的全面邊緣 AI 開發環境  
  - 用於邊緣部署的模型目錄和發現  
  - 本地測試、優化和代理開發工作流程  
  - 邊緣場景的效能監控和評估  

#### 第二節：Windows 邊緣 AI 開發指南  
- **重點概念**:  
  - Windows AI Foundry 平台全面概述  
  - Phi Silica API 用於高效 NPU 推理  
  - 用於影像處理和 OCR 的電腦視覺 API  
  - Foundry Local CLI 用於本地開發和測試  

#### 第三節：平台特定實施  
- **重點概念**:  
  - NVIDIA Jetson Orin Nano 部署（67 TOPS AI 性能）  
  - 使用 .NET MAUI 和 ONNX Runtime GenAI 的移動應用  
  - Azure EdgeAI 解決方案與雲-邊緣混合架構  
  - Windows ML 優化與通用硬體支持  
  - Foundry Local 應用與隱私專注的 RAG 實施  

### 自我評估問題  

1. AI Toolkit 如何簡化邊緣 AI 開發工作流程？  
2. 比較不同硬體平台的部署策略。  
3. Windows AI Foundry 在邊緣開發中的優勢是什麼？  
4. NPU 優化在現代邊緣 AI 應用中的角色是什麼？  
5. Phi Silica API 如何利用 NPU 硬體進行性能優化？  
6. 比較本地部署與雲端部署在隱私敏感應用中的優勢。  

### 實作練習  

1. **AI Toolkit 設置**: 配置 AI Toolkit 並優化模型（1 小時）  
2. **Windows AI Foundry**: 使用 Phi Silica API 構建簡單的 Windows AI 應用（1 小時）  
3. **跨平台部署**: 在兩個不同平台上部署相同模型（1 小時）  
4. **NPU 優化**: 使用 Windows AI Foundry 工具測試 NPU 性能（30 分鐘）  

## 第八章：Microsoft Foundry Local – 完整開發者工具包  

### 核心學習目標  

- 在 Windows 上安裝和配置 Foundry Local  
- 通過 Foundry CLI 本地運行、發現和管理模型  
- 與 OpenAI 兼容的 REST 和 SDK 客戶端集成  
- 構建實用範例：Chainlit 聊天、代理和模型路由器  
- 理解 Azure AI Foundry 的混合模式  

### 學習重點領域  

- 安裝和 CLI 基本知識（模型、服務、緩存）  
- SDK 集成（OpenAI 兼容客戶端和 Azure OpenAI）  
- Open WebUI 快速驗證  
- 代理和函數調用模式  
- 模型作為工具（路由器和註冊設計）  

### 自我評估問題  

1. 如何發現本地端點並列出可用模型？  
2. Foundry Local REST 與 Azure OpenAI 使用有何不同？  
3. 如何設計簡單的路由器以選擇模型作為工具？  
4. 哪些 CLI 類別與日常開發最相關？  
5. 在運行應用之前如何驗證 Foundry Local 的準備狀態？  

### 實作練習  

1. 安裝/升級 Foundry Local 並本地運行 `phi-4-mini`（30 分鐘）  
2. 調用 `/v1/models` 並通過 REST 運行簡單聊天（30 分鐘）  
3. 啟動 Chainlit 應用範例並進行本地聊天（30 分鐘）  
4. 運行多代理協調器並檢查輸出（30 分鐘）  
5. 使用基於環境的覆蓋嘗試模型作為工具的路由器（30 分鐘）  

## 時間分配指南  

為幫助您充分利用 20 小時的課程時間，以下是建議的時間分配：  

| 活動 | 時間分配 | 描述 |  
|------|----------|------|  
| 閱讀核心材料 | 9 小時 | 專注於每章的基本概念 |  
| 實作練習 | 6 小時 | 關鍵技術的實際應用 |  
| 自我評估 | 2 小時 | 通過問題和反思測試理解 |  
| 小型專案 | 3 小時 | 將知識應用於小型實際實施 |  

### 根據時間限制的重點領域  

**如果您只有 10 小時：**  
- 完成第 1、2 和 3 章（核心邊緣 AI 概念）  
- 每章至少完成一個實作練習  
- 專注於理解核心概念，而非實施細節  

**如果您可以投入完整的 20 小時：**  
- 完成所有七章  
- 每章進行關鍵實作練習  
- 完成第七章的一個小型專案  
- 探索至少 2-3 個補充資源  

**如果您有超過 20 小時：**  
- 詳細完成所有章節和練習  
- 建立多個小型專案  
- 探索第四章中的高級優化技術  
- 實施第五章中的生產部署  

## 必備資源  

以下精選資源能為您的有限學習時間提供最大價值：  

### 必讀文件  
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型優化工具  
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快的本地部署 SLM 方法  
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考  
- [OpenVINO 文件](https://docs.openvino.ai/2025/index.html) - Intel 的全面優化工具包  
- [VS Code 的 AI Toolkit](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成邊緣 AI 開發環境  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 特定的邊緣 AI 開發平台  

### 節省時間的工具  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問和部署  
- [Gradio](https://www.gradio.app/docs/interface) - 快速開發 AI 演示的 UI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化模型優化  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的 CPU 推理  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網絡壓縮框架  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包  

## 進度追蹤模板  

使用此簡化模板追蹤您在 20 小時課程中的學習進度：  

| 模組 | 完成日期 | 花費時間 | 主要收穫 |  
|------|----------|----------|----------|  
| 第 1 章：邊緣 AI 基礎 | | | |  
| 第 2 章：SLM 基礎 | | | |  
| 第 3 章：SLM 部署 | | | |  
| 第 4 章：模型優化 | | | |  
| 第 5 章：SLMOps | | | |  
| 第 6 章：AI 代理 | | | |  
| 第 7 章：開發工具 | | | |  
| 第 8 章：Foundry Local 工具包 | | | |  
| 實作練習 | | | |  
| 小型專案 | | | |  

## 小型專案構想  

考慮完成以下專案以練習邊緣 AI 概念（每個設計為 2-4 小時完成）：  

### 初學者專案（2-3 小時）  
1. **邊緣文字助手**: 使用小型語言模型創建簡單的離線文字補全工具  
2. **模型比較儀表板**: 構建基本的性能指標可視化工具，對比不同 SLMs  
3. **優化實驗**: 測量不同量化級別對同一基礎模型的影響  

### 中級專案（3-4 小時）  
4. **AI Toolkit 工作流程**: 使用 VS Code 的 AI Toolkit 從頭到尾優化並部署模型  
5. **Windows AI Foundry 應用**: 使用 Phi Silica API 和 NPU 優化創建 Windows 應用  
6. **跨平台部署**: 在 Windows（OpenVINO）和移動端（.NET MAUI）部署相同的優化模型  
7. **函數調用代理**: 為邊緣場景構建具有函數調用功能的 AI 代理  

### 高級整合專案（4-5 小時）  
8. **OpenVINO 優化流程**：使用 NNCF 和 GenAI 工具包完成模型優化  
9. **SLMOps 流程**：實現從模型訓練到邊緣部署的完整生命周期  
10. **多模型邊緣系統**：在邊緣硬件上部署多個專用模型協同工作  
11. **MCP 整合系統**：使用模型上下文協議（Model Context Protocol）構建工具交互的代理系統  

## 參考資料

- Microsoft Learn (Foundry Local)  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - 入門指南：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI 參考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - 與推理 SDK 整合：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - 開啟 WebUI 教學：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - 編譯 Hugging Face 模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agents（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- 優化與推理工具  
  - Microsoft Olive（文檔）：https://microsoft.github.io/Olive/  
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive  
  - ONNX Runtime（入門指南）：https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive 整合：https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO（文檔）：https://docs.openvino.ai/2025/index.html  
  - Apple MLX（文檔）：https://ml-explore.github.io/mlx/build/html/index.html  
- 部署框架與模型  
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index  
  - vLLM（文檔）：https://docs.vllm.ai/  
  - Ollama（快速入門）：https://github.com/ollama/ollama#get-started  
- 開發者工具（Windows 和 VS Code）  
  - VS Code 的 AI 工具包：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## 學習社群

加入討論並與其他學習者交流：  
- [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions) 的 GitHub 討論區  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 結論

EdgeAI 代表了人工智能應用的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等重要問題。本課程為期 20 小時，提供了必要的知識和實用技能，讓您能夠立即開始使用 EdgeAI 技術。

課程內容精簡且專注於最重要的概念，讓您能快速獲得寶貴的專業知識，而不需要投入過多的時間。請記住，動手練習，即使是簡單的例子，也是鞏固所學的關鍵。

祝學習愉快！

---

