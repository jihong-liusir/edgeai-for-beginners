<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-09T07:56:51+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "mo"
}
-->
# 初學者的 EdgeAI：學習路徑與學習計劃

### 集中學習路徑（一週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI簡介 | 1-2小時 |
| 第1天 | 模組1：EdgeAI基礎 | 3小時 |
| 第2天 | 模組2：SLM基礎 | 3小時 |
| 第3天 | 模組3：SLM部署 | 2小時 |
| 第4-5天 | 模組4：模型優化（6個框架） | 4小時 |
| 第6天 | 模組5：SLMOps | 3小時 |
| 第7天 | 模組6-7：AI代理與開發工具 | 4小時 |
| 第8天 | 模組8：Foundry Local工具包（現代實現） | 1小時 |

### 集中學習路徑（兩週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1-2天 | 模組1：EdgeAI基礎 | 3小時 |
| 第3-4天 | 模組2：SLM基礎 | 3小時 |
| 第5-6天 | 模組3：SLM部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：AI代理 | 2小時 |
| 第13-14天 | 模組7：開發工具 | 3小時 |

### 兼職學習（四週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI基礎 | 3小時 |
| 第3-4天 | 模組2：SLM基礎 | 3小時 |
| 第5-6天 | 模組3：SLM部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：SLM代理系統 | 2小時 |
| 第13-14天 | 模組7：EdgeAI實現範例 | 2小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|--------|----------------|-------------|--------------|
| 模組0：EdgeAI簡介 | | | |
| 模組1：EdgeAI基礎 | | | |
| 模組2：SLM基礎 | | | |
| 模組3：SLM部署 | | | |
| 模組4：模型優化（6個框架） | | | |
| 模組5：SLMOps | | | |
| 模組6：SLM代理系統 | | | |
| 模組7：EdgeAI實現範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習（四週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

## 簡介

歡迎使用初學者的 EdgeAI 學習指南！本文件旨在幫助您有效地掌握課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，幫助您深入了解 EdgeAI 技術。

這是一門精簡的20小時課程，旨在以高效的方式傳授有關 EdgeAI 的基本知識，非常適合忙碌的專業人士和希望快速掌握此新興領域實用技能的學生。

## 課程概述

本課程分為八個全面的模組：

0. **EdgeAI簡介** - 建立基礎並提供行業應用與學習目標
1. **EdgeAI基礎與轉型** - 理解核心概念與技術變革
2. **小型語言模型基礎** - 探索各種SLM家族及其架構
3. **小型語言模型部署** - 實現實際部署策略
4. **模型格式轉換與量化** - 使用包括OpenVINO在內的6個框架進行高級優化
5. **SLMOps - 小型語言模型運營** - 生產生命周期管理與部署
6. **SLM代理系統** - AI代理、函數調用與模型上下文協議
7. **EdgeAI實現範例** - AI工具包、Windows開發與平台特定實現
8. **Microsoft Foundry Local – 完整開發工具包** - 本地優先開發與混合Azure整合（模組08）

## 如何使用本學習指南

- **漸進式學習**：按順序學習模組以獲得最連貫的學習體驗
- **知識檢查點**：使用每部分後的自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑（一週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI基礎 | 6小時 |
| 第3-4天 | 模組2：SLM基礎 | 8小時 |
| 第5天 | 模組3：SLM部署 | 3小時 |
| 第6天 | 模組8：Foundry Local工具包 | 3小時 |

### 兼職學習（三週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組0：簡介 + 模組1：EdgeAI基礎 | 7-9小時 |
| 第2週 | 模組2：SLM基礎 | 7-8小時 |
| 第3週 | 模組3：SLM部署（3小時）+ 模組8：Foundry Local工具包（2-3小時） | 5-6小時 |

## 模組0：EdgeAI簡介

### 主要學習目標

- 了解什麼是EdgeAI以及它在當今技術領域的重要性
- 識別被EdgeAI改變的主要行業及其具體應用案例
- 理解小型語言模型（SLM）在邊緣部署中的優勢
- 為整個課程建立清晰的學習期望與成果
- 認識EdgeAI領域的職業機會與技能需求

### 學習重點區域

#### 第一部分：EdgeAI範式與定義
- **優先概念**：
  - EdgeAI與傳統雲端AI處理的區別
  - 硬體、模型優化與商業需求的融合
  - 實時、隱私保護與成本效益的AI部署

#### 第二部分：行業應用
- **優先概念**：
  - 製造業與工業4.0：預測性維護與品質控制
  - 醫療保健：診斷影像與患者監測
  - 自主系統：自駕車與交通運輸
  - 智慧城市：交通管理與公共安全
  - 消費技術：智能手機、穿戴設備與智能家居

#### 第三部分：小型語言模型基礎
- **優先概念**：
  - SLM特徵與性能比較
  - 參數效率與能力的權衡
  - 邊緣部署限制與優化策略

#### 第四部分：學習框架與職業路徑
- **優先概念**：
  - 課程架構與漸進掌握方法
  - 技術技能與實際實現目標
  - 職業發展機會與行業應用

### 自我評估問題

1. 哪三個主要技術趨勢促成了EdgeAI的發展？
2. 比較EdgeAI與基於雲端的AI的優勢與挑戰。
3. 列出三個EdgeAI提供關鍵商業價值的行業並解釋原因。
4. 小型語言模型如何使EdgeAI在實際部署中更具可行性？
5. 在整個課程中您將學到哪些關鍵技術技能？
6. 描述本課程使用的四階段學習方法。

### 實作練習

1. **行業研究**：選擇一個行業應用並研究一個真實的EdgeAI實現案例（30分鐘）
2. **模型探索**：瀏覽Hugging Face上的小型語言模型，並比較其參數數量與能力（30分鐘）
3. **學習計劃**：查看完整課程結構並制定個人學習計劃（15分鐘）

### 補充材料

- [Edge AI市場概述 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [小型語言模型概述 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [邊緣計算基礎](https://www.edgecomputing.org/)

## 模組1：EdgeAI基礎與轉型

### 主要學習目標

- 了解基於雲端的AI與基於邊緣的AI的差異
- 掌握資源受限環境的核心優化技術
- 分析EdgeAI技術的真實應用案例
- 設置EdgeAI項目的開發環境

### 學習重點區域

#### 第一部分：EdgeAI基礎
- **優先概念**：
  - 邊緣與雲端計算範式
  - 模型量化技術
  - 硬體加速選項（NPU、GPU、CPU）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite文檔](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse文檔](https://docs.edgeimpulse.com)

#### 第二部分：真實案例研究
- **優先概念**：
  - Microsoft Phi與Mu模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第三部分：實際實現指南
- **優先概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI實現的評估方法

#### 第四部分：邊緣部署硬體
- **優先概念**：
  - 硬體平台比較
  - 特定硬體的優化策略
  - 部署考量

### 自我評估問題

1. 比較基於雲端的AI與基於邊緣的AI實現。
2. 解釋三個優化模型以進行邊緣部署的關鍵技術。
3. 在邊緣運行AI模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬體加速器（NPU、GPU、CPU）如何影響EdgeAI部署。

### 實作練習

1. **快速環境設置**：配置包含基本套件的最小開發環境（30分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1小時）
3. **基本量化**：嘗試對一個小型模型進行簡單的量化（1小時）

## 模組2：小型語言模型基礎

### 主要學習目標

- 理解不同SLM家族的架構原理
- 比較不同參數規模模型的能力
- 根據效率、能力和部署需求評估模型
- 識別不同模型家族的適用場景

### 學習重點區域

#### 第一部分：Microsoft Phi模型家族
- **優先概念**：
  - 設計理念演變
  - 效率優先架構
  - 專業化能力

#### 第二部分：Qwen家族
- **優先概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第三部分：Gemma家族
- **優先概念**：
  - 以研究為驅動的創新
  - 多模態能力
  - 移動優化

#### 第四部分：BitNET家族
- **優先概念**：
  - 1位元量化技術
  - 推理優化框架
  - 可持續性考量

#### 第五部分：Microsoft Mu模型
- **優先概念**：
  - 設備優先架構
  - 與Windows的系統整合
  - 隱私保護操作

#### 第六部分：Phi-Silica
- **優先概念**：
  - NPU優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較Phi與Qwen模型家族的架構方法。
2. 解釋BitNET的量化技術與傳統量化的不同之處。
3. Mu 模型在 Windows 整合方面有哪些獨特優勢？
4. Phi-Silica 如何利用 NPU 硬體進行效能優化？
5. 對於一個連線有限的行動應用程式，哪個模型系列最適合？為什麼？

### 實作練習

1. **模型比較**：快速對比兩個不同的 SLM 模型（1 小時）
2. **簡單文本生成**：使用小型模型進行基本文本生成實作（1 小時）
3. **快速優化**：應用一種優化技術以提升推理速度（1 小時）

## 模組 3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇適合的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實作 SLM
- 設計適用於 EdgeAI 應用的生產級配置

### 學習重點領域

#### 第一部分：SLM 高階學習
- **優先概念**：
  - 參數分類框架
  - 高階優化技術
  - 模型獲取策略

#### 第二部分：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第三部分：容器化雲端部署
- **優先概念**：
  - vLLM 高效能推理
  - 容器編排
  - ONNX Runtime 實作

### 自我評估問題

1. 在選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 邊緣部署的 SLM 需要監控哪些關鍵效能指標？
5. 描述從模型選擇到生產實作的完整部署工作流程。

### 實作練習

1. **基本本地部署**：使用 Ollama 部署一個簡單的 SLM（1 小時）
2. **效能檢查**：對已部署的模型進行快速基準測試（30 分鐘）
3. **簡單整合**：創建一個使用已部署模型的最小應用程式（1 小時）

## 模組 4：模型格式轉換與量化

### 主要學習目標

- 掌握從 1-bit 到 8-bit 精度的高階量化技術
- 理解格式轉換策略（GGUF、ONNX）
- 在六個框架中實作優化（Llama.cpp、Olive、OpenVINO、MLX、工作流程綜合）
- 為 Intel、Apple 和跨平台硬體部署生產級優化模型

### 學習重點領域

#### 第一部分：量化基礎
- **優先概念**：
  - 精度分類框架
  - 效能與準確性權衡
  - 記憶體占用優化

#### 第二部分：Llama.cpp 實作
- **優先概念**：
  - 跨平台部署
  - GGUF 格式優化
  - 硬體加速技術

#### 第三部分：Microsoft Olive 套件
- **優先概念**：
  - 硬體感知優化
  - 企業級部署
  - 自動化優化工作流程

#### 第四部分：OpenVINO 工具包
- **優先概念**：
  - Intel 硬體優化
  - 神經網路壓縮框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI 用於 LLM 部署

#### 第五部分：Apple MLX 框架
- **優先概念**：
  - Apple Silicon 優化
  - 統一記憶體架構
  - LoRA 微調能力

#### 第六部分：邊緣 AI 開發工作流程綜合
- **優先概念**：
  - 統一工作流程架構
  - 框架選擇決策樹
  - 生產準備驗證
  - 未來適應性策略

### 自我評估問題

1. 比較不同精度級別（1-bit 到 8-bit）的量化策略。
2. 解釋 GGUF 格式在邊緣部署中的優勢。
3. Microsoft Olive 的硬體感知優化如何提升部署效率？
4. OpenVINO 的 NNCF 在模型壓縮方面有哪些主要優勢？
5. 描述 Apple MLX 如何利用統一記憶體架構進行優化。
6. 工作流程綜合如何幫助選擇最佳優化框架？

### 實作練習

1. **模型量化**：對模型應用不同的量化級別並比較結果（1 小時）
2. **OpenVINO 優化**：使用 NNCF 壓縮模型以適配 Intel 硬體（1 小時）
3. **框架比較**：在三個不同的優化框架中測試同一模型（1 小時）
4. **效能基準測試**：測量優化對推理速度和記憶體使用的影響（1 小時）

## 模組 5：SLMOps - 小型語言模型運營

### 主要學習目標

- 理解 SLMOps 生命周期管理原則
- 掌握邊緣部署的蒸餾和微調技術
- 實作具有監控功能的生產部署策略
- 建立企業級 SLM 運營和維護工作流程

### 學習重點領域

#### 第一部分：SLMOps 簡介
- **優先概念**：
  - SLMOps 在 AI 運營中的範式轉變
  - 成本效率和隱私優先架構
  - 戰略性商業影響和競爭優勢

#### 第二部分：模型蒸餾
- **優先概念**：
  - 知識轉移技術
  - 雙階段蒸餾流程實作
  - Azure ML 蒸餾工作流程

#### 第三部分：微調策略
- **優先概念**：
  - 參數高效微調（PEFT）
  - LoRA 和 QLoRA 高階方法
  - 多適配器訓練和超參數優化

#### 第四部分：生產部署
- **優先概念**：
  - 生產級模型轉換與量化
  - Foundry Local 部署配置
  - 效能基準測試與品質驗證

### 自我評估問題

1. SLMOps 與傳統 MLOps 有何不同？
2. 解釋模型蒸餾對邊緣部署的好處。
3. 在資源有限的環境中微調 SLM 時需要考慮哪些關鍵因素？
4. 描述邊緣 AI 應用的完整生產部署管道。

### 實作練習

1. **基本蒸餾**：從較大的教師模型創建較小的模型（1 小時）
2. **微調實驗**：針對特定領域微調模型（1 小時）
3. **部署管道**：設置基本的 CI/CD 管道以進行模型部署（1 小時）

## 模組 6：SLM Agentic 系統 - AI 代理與函數調用

### 主要學習目標

- 使用小型語言模型構建適用於邊緣環境的智能 AI 代理
- 實作具有系統化工作流程的函數調用功能
- 掌握模型上下文協議（MCP）整合以實現標準化工具交互
- 創建高級代理系統，減少人工干預

### 學習重點領域

#### 第一部分：AI 代理與 SLM 基礎
- **優先概念**：
  - 代理分類框架（反射型、基於模型、基於目標、學習型代理）
  - SLM 與 LLM 的權衡分析
  - 邊緣特定代理設計模式
  - 代理的資源優化

#### 第二部分：小型語言模型中的函數調用
- **優先概念**：
  - 系統化工作流程實作（意圖檢測、JSON 輸出、外部執行）
  - 平台特定實作（Phi-4-mini、選定的 Qwen 模型、Microsoft Foundry Local）
  - 高階範例（多代理協作、動態工具選擇）
  - 生產考量（速率限制、審計記錄、安全措施）

#### 第三部分：模型上下文協議（MCP）整合
- **優先概念**：
  - 協議架構與分層系統設計
  - 多後端支持（Ollama 用於開發，vLLM 用於生產）
  - 連接協議（STDIO 和 SSE 模式）
  - 實際應用（網頁自動化、數據處理、API 整合）

### 自我評估問題

1. 邊緣 AI 代理的關鍵架構考量是什麼？
2. 函數調用如何增強代理功能？
3. 解釋模型上下文協議在代理通信中的角色。

### 實作練習

1. **簡單代理**：構建具有函數調用功能的基本 AI 代理（1 小時）
2. **MCP 整合**：在代理應用中實作 MCP（30 分鐘）

## 工作坊：實作學習路徑

### 主要學習目標

- 使用 Foundry Local SDK 和最佳實踐構建生產級 AI 應用
- 實作全面的錯誤處理和用戶反饋模式
- 創建 RAG 管道並進行品質評估與效能監控
- 開發具有協調模式的多代理系統
- 掌握智能模型路由以進行基於任務的模型選擇
- 部署以隱私保護架構為核心的本地優先 AI 解決方案

### 學習重點領域

#### 第一節：使用 Foundry Local 入門
- **優先概念**：
  - FoundryLocalManager SDK 整合與自動服務發現
  - 基本與串流聊天實作
  - 錯誤處理模式與用戶反饋
  - 基於環境的配置

#### 第二節：使用 RAG 構建 AI 解決方案
- **優先概念**：
  - 使用 sentence-transformers 的內存向量嵌入
  - RAG 管道實作（檢索 → 生成）
  - 使用 RAGAS 指標進行品質評估
  - 可選依賴項的導入安全性

#### 第三節：開源模型
- **優先概念**：
  - 多模型基準測試策略
  - 延遲與吞吐量測量
  - 優雅降級與錯誤恢復
  - 模型系列間的效能比較

#### 第四節：尖端模型
- **優先概念**：
  - SLM 與 LLM 比較方法論
  - 類型提示與全面的輸出格式化
  - 每模型錯誤處理
  - 結構化結果以進行分析

#### 第五節：AI 驅動代理
- **優先概念**：
  - 使用協調模式進行多代理編排
  - 代理記憶管理與狀態追蹤
  - 管道錯誤處理與階段記錄
  - 效能監控與統計

#### 第六節：模型作為工具
- **優先概念**：
  - 意圖檢測與模式匹配
  - 基於關鍵字的模型路由算法
  - 多步管道（計劃 → 執行 → 優化）
  - 全面的函數文檔

### 自我評估問題

1. FoundryLocalManager 如何簡化服務管理，相較於手動 REST 調用？
2. 解釋可選依賴項（如 sentence-transformers）的導入保護的重要性。
3. 哪些策略能確保多模型基準測試中的優雅降級？
4. 協調模式如何編排多個專家代理？
5. 描述智能模型路由器的組成部分。
6. 生產級錯誤處理的關鍵要素是什麼？

### 實作練習

1. **聊天應用**：實作具有錯誤處理功能的串流聊天（45 分鐘）
2. **RAG 管道**：構建具有品質評估的最小 RAG（1 小時）
3. **模型基準測試**：比較 3 個以上模型的效能（1 小時）
4. **多代理系統**：創建具有 2 個專家代理的協調器（1.5 小時）
5. **智能路由器**：構建基於任務的模型選擇（1 小時）
6. **生產部署**：添加監控與全面的錯誤處理（45 分鐘）

### 時間分配

**集中學習（1 週）**：
- 第一天：第一節至第二節（聊天 + RAG）- 3 小時
- 第二天：第三節至第四節（基準測試 + 比較）- 3 小時
- 第三天：第五節至第六節（代理 + 路由）- 3 小時
- 第四天：實作練習與驗證 - 2 小時

**兼職學習（2 週）**：
- 第一週：第一至第三節（共 6 小時）
- 第二週：第四至第六節 + 實作練習（共 5 小時）

## 模組 7：EdgeAI 實作範例

### 主要學習目標

- 掌握 Visual Studio Code 的 AI 工具包以進行全面的 EdgeAI 開發工作流程
- 精通 Windows AI Foundry 平台與 NPU 優化策略
- 在多個硬體平台和部署場景中實作 EdgeAI
- 使用平台特定的優化構建生產級 EdgeAI 應用

### 學習重點領域

#### 第一部分：Visual Studio Code 的 AI 工具包
- **優先概念**：
  - 在 VS Code 中進行全面的 Edge AI 開發環境
  - 用於邊緣部署的模型目錄與發現
  - 本地測試、優化與代理開發工作流程
  - 邊緣場景的效能監控與評估

#### 第二部分：Windows EdgeAI 開發指南
- **優先概念**：
  - Windows AI Foundry 平台全面概述
  - Phi Silica API 用於高效 NPU 推理
  - 用於影像處理與 OCR 的電腦視覺 API
  - Foundry Local CLI 用於本地開發與測試

#### 第三部分：平台特定實作
- **優先概念**：
  - NVIDIA Jetson Orin Nano 部署（67 TOPS AI 效能）
  - 使用 .NET MAUI 和 ONNX Runtime GenAI 的行動應用
  - Azure EdgeAI 解決方案與雲端-邊緣混合架構
  - Windows ML 優化與通用硬體支持
  - Foundry Local 應用與隱私聚焦的 RAG 實作

### 自我評估問題

1. AI 工具包如何簡化 EdgeAI 開發工作流程？
2. 比較不同硬體平台的部署策略。
3. Windows AI Foundry 在邊緣開發方面有哪些優勢？
4. 解釋 NPU 優化在現代邊緣 AI 應用中的角色  
5. Phi Silica API 如何利用 NPU 硬體進行效能優化？  
6. 比較本地部署與雲端部署在隱私敏感應用中的優勢。  

### 實作練習  

1. **AI 工具包設置**：配置 AI 工具包並優化模型（1 小時）  
2. **Windows AI Foundry**：使用 Phi Silica API 建立一個簡單的 Windows AI 應用程式（1 小時）  
3. **跨平台部署**：將相同模型部署於兩個不同平台（1 小時）  
4. **NPU 優化**：使用 Windows AI Foundry 工具測試 NPU 效能（30 分鐘）  

## 模組 8：Microsoft Foundry Local – 完整開發者工具包（現代化）  

### 主要學習目標  

- 安裝並配置 Foundry Local，整合現代 SDK  
- 實現使用協調器模式的進階多代理系統  
- 建立具備自動任務選擇的智慧模型路由器  
- 部署具備全面監控的生產級 AI 解決方案  
- 整合 Azure AI Foundry 以實現混合部署場景  
- 掌握 FoundryLocalManager 和 OpenAI 客戶端的現代 SDK 模式  

### 學習重點區域  

#### 第一部分：現代化安裝與配置  
- **優先概念**：  
  - FoundryLocalManager SDK 整合  
  - 自動服務發現與健康監控  
  - 基於環境的配置模式  
  - 生產部署考量  

#### 第二部分：進階多代理系統  
- **優先概念**：  
  - 使用專家代理的協調器模式  
  - 檢索、推理與執行代理的專業化  
  - 用於改進的反饋迴路機制  
  - 效能監控與統計追蹤  

#### 第三部分：智慧模型路由  
- **優先概念**：  
  - 基於關鍵字的模型選擇演算法  
  - 支援多模型（通用、推理、程式碼、創意）  
  - 環境變數配置的靈活性  
  - 服務健康檢查與錯誤處理  

#### 第四部分：生產級實現  
- **優先概念**：  
  - 全面的錯誤處理與備援機制  
  - 請求監控與效能追蹤  
  - 使用帶有基準測試的互動式 Jupyter 筆記本範例  
  - 與現有應用程式的整合模式  

### 自我評估問題  

1. 現代 FoundryLocalManager 方法與手動 REST 呼叫有何不同？  
2. 解釋協調器模式及其如何協調專家代理。  
3. 智慧路由器如何根據查詢內容選擇適當的模型？  
4. 生產級 AI 代理系統的關鍵組成部分是什麼？  
5. 如何為 Foundry Local 服務實現全面的健康監控？  
6. 比較現代化方法與傳統實現模式的優勢。  

### 實作練習  

1. **現代 SDK 設置**：配置 FoundryLocalManager，實現自動服務發現（30 分鐘）  
2. **多代理系統**：運行帶有專家代理的進階協調器（30 分鐘）  
3. **智慧路由**：測試模型路由器處理不同查詢類型（30 分鐘）  
4. **互動探索**：使用 Jupyter 筆記本探索進階功能（45 分鐘）  
5. **生產部署**：實現監控與錯誤處理模式（30 分鐘）  
6. **混合整合**：配置 Azure AI Foundry 備援場景（30 分鐘）  

## 時間分配指南  

為幫助您充分利用這個 30 小時的課程時間（包括工作坊），以下是建議的時間分配：  

| 活動 | 時間分配 | 描述 |  
|----------|----------------|-------------|  
| 閱讀核心材料 | 12 小時 | 專注於每個模組中的基本概念 |  
| 實作練習 | 10 小時 | 實踐關鍵技術（包括工作坊） |  
| 自我評估 | 3 小時 | 通過問題和反思測試理解 |  
| 小型專案 | 5 小時 | 將知識應用於小型實踐實現 |  

### 根據時間限制的重點區域  

**如果您只有 10 小時：**  
- 完成模組 0（介紹）以及模組 1、2 和 3（核心 EdgeAI 概念）  
- 每個模組至少完成一個實作練習  
- 專注於理解核心概念，而非實現細節  

**如果您可以投入完整的 20 小時：**  
- 完成所有八個模組（包括介紹）  
- 執行每個模組的關鍵實作練習  
- 完成模組 7 的一個小型專案  
- 探索至少 2-3 個補充資源  

**如果您有超過 20 小時：**  
- 完成所有模組（包括介紹）並進行詳細練習  
- 建立多個小型專案  
- 探索模組 4 的進階優化技術  
- 實現模組 5 的生產部署  

## 必備資源  

這些精心挑選的資源能為您的有限學習時間提供最大價值：  

### 必讀文件  
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最有效的模型優化工具  
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快速的本地部署 SLM 方法  
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考  
- [OpenVINO 文件](https://docs.openvino.ai/2025/index.html) - Intel 的全面優化工具包  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - 整合式 EdgeAI 開發環境  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 專屬的 EdgeAI 開發平台  

### 節省時間的工具  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問與部署  
- [Gradio](https://www.gradio.app/docs/interface) - 快速建立 AI 演示的 UI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化的模型優化工具  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的 CPU 推理工具  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網路壓縮框架  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包  

## 進度追蹤模板  

使用此簡化模板追蹤您在 20 小時課程中的學習進度：  

| 模組 | 完成日期 | 花費時間 | 主要收穫 |  
|--------|----------------|-------------|---------------|  
| 模組 0：EdgeAI 介紹 | | | |  
| 模組 1：EdgeAI 基礎 | | | |  
| 模組 2：SLM 基礎 | | | |  
| 模組 3：SLM 部署 | | | |  
| 模組 4：模型優化 | | | |  
| 模組 5：SLMOps | | | |  
| 模組 6：AI 代理 | | | |  
| 模組 7：開發工具 | | | |  
| 工作坊：實作學習 | | | |  
| 模組 8：Foundry Local 工具包 | | | |  
| 實作練習 | | | |  
| 小型專案 | | | |  

## 小型專案點子  

考慮完成以下專案之一來練習 EdgeAI 概念（每個設計為 2-4 小時）：  

### 初學者專案（每個 2-3 小時）  
1. **邊緣文字助手**：使用小型語言模型創建一個簡單的離線文字補全工具  
2. **模型比較儀表板**：建立一個基本的視覺化工具，展示不同 SLM 的效能指標  
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響  

### 中級專案（每個 3-4 小時）  
4. **AI 工具包工作流程**：使用 VS Code AI 工具包從頭到尾優化並部署一個模型  
5. **Windows AI Foundry 應用程式**：使用 Phi Silica API 和 NPU 優化創建一個 Windows 應用程式  
6. **跨平台部署**：將相同的優化模型部署於 Windows（OpenVINO）和行動裝置（.NET MAUI）  
7. **函數調用代理**：建立一個具備函數調用能力的 AI 代理，用於邊緣場景  

### 進階整合專案（每個 4-5 小時）  
8. **OpenVINO 優化管道**：使用 NNCF 和 GenAI 工具包實現完整的模型優化  
9. **SLMOps 管道**：實現從訓練到邊緣部署的完整模型生命週期  
10. **多模型邊緣系統**：在邊緣硬體上部署多個專業化模型協同工作  
11. **MCP 整合系統**：使用模型上下文協議（Model Context Protocol）構建一個代理系統進行工具交互  

## 參考資料  

- Microsoft Learn (Foundry Local)  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - 入門：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI 參考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - 與推理 SDK 整合：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - 開啟 WebUI 教學：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - 編譯 Hugging Face 模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - 代理（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- 優化與推理工具  
  - Microsoft Olive（文件）：https://microsoft.github.io/Olive/  
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive  
  - ONNX Runtime（入門）：https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive 整合：https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO（文件）：https://docs.openvino.ai/2025/index.html  
  - Apple MLX（文件）：https://ml-explore.github.io/mlx/build/html/index.html  
- 部署框架與模型  
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index  
  - vLLM（文件）：https://docs.vllm.ai/  
  - Ollama（快速入門）：https://github.com/ollama/ollama#get-started  
- 開發工具（Windows 和 VS Code）  
  - AI Toolkit for VS Code：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## 學習社群  

加入討論並與其他學員交流：  
- GitHub 上的 [EdgeAI for Beginners 討論區](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft 技術社群](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 結論  

EdgeAI 代表了人工智慧應用的前沿，將強大的能力直接帶到設備端，同時解決隱私、延遲和連接性等關鍵問題。本課程提供了必要的知識和實踐技能，讓您能立即開始使用 EdgeAI 技術。  

課程內容精簡且專注於最重要的概念，讓您能快速獲得寶貴的專業知識，而不會感到時間壓力。請記住，即使是簡單的實作練習，也能有效鞏固您的學習成果。  

祝學習愉快！  

---

**免責聲明**：  
此文件使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。應以原始語言的文件作為權威來源。對於關鍵資訊，建議尋求專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。