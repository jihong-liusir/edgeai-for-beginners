<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49e18143f97a802a8647f4be28355348",
  "translation_date": "2025-09-17T17:59:55+00:00",
  "source_file": "Module04/01.Introduce.md",
  "language_code": "ur"
}
-->
# سیکشن 1: ماڈل فارمیٹ کنورژن اور کوانٹائزیشن کی بنیادیں

ماڈل فارمیٹ کنورژن اور کوانٹائزیشن EdgeAI میں اہم پیش رفت کی نمائندگی کرتے ہیں، جو محدود وسائل والے آلات پر جدید مشین لرننگ کی صلاحیتوں کو ممکن بناتے ہیں۔ ماڈلز کو مؤثر طریقے سے تبدیل، بہتر اور تعینات کرنے کا طریقہ سمجھنا عملی ایج پر مبنی AI حل بنانے کے لیے ضروری ہے۔

## تعارف

اس ٹیوٹوریل میں، ہم ماڈل فارمیٹ کنورژن اور کوانٹائزیشن تکنیکوں اور ان کے جدید نفاذ کی حکمت عملیوں کا جائزہ لیں گے۔ ہم ماڈل کمپریشن کے بنیادی تصورات، فارمیٹ کنورژن کی حدود اور درجہ بندی، اصلاحی تکنیکوں، اور ایج کمپیوٹنگ ماحول کے لیے عملی تعیناتی کی حکمت عملیوں کا احاطہ کریں گے۔

## سیکھنے کے مقاصد

اس ٹیوٹوریل کے اختتام تک، آپ درج ذیل کو سمجھ سکیں گے:

- 🔢 مختلف پریسیژن لیولز کی کوانٹائزیشن حدود اور درجہ بندی کو سمجھنا۔
- 🛠️ ایج ڈیوائسز پر ماڈل تعیناتی کے لیے اہم فارمیٹ کنورژن تکنیکوں کی شناخت۔
- 🚀 بہتر انفرنس کے لیے جدید کوانٹائزیشن اور کمپریشن حکمت عملیوں کو سیکھنا۔

## ماڈل کوانٹائزیشن کی حدود اور درجہ بندی کو سمجھنا

ماڈل کوانٹائزیشن ایک تکنیک ہے جو نیورل نیٹ ورک کے پیرامیٹرز کی پریسیژن کو کم کرنے کے لیے ڈیزائن کی گئی ہے، جو مکمل پریسیژن ماڈلز کے مقابلے میں نمایاں طور پر کم بٹس استعمال کرتی ہے۔ مکمل پریسیژن ماڈلز 32-بٹ فلوٹنگ پوائنٹ ریپریزنٹیشنز استعمال کرتے ہیں، جبکہ کوانٹائزڈ ماڈلز خاص طور پر کارکردگی اور ایج تعیناتی کے لیے ڈیزائن کیے گئے ہیں۔

پریسیژن درجہ بندی کا فریم ورک ہمیں کوانٹائزیشن لیولز کی مختلف اقسام اور ان کے مناسب استعمال کے کیسز کو سمجھنے میں مدد دیتا ہے۔ یہ درجہ بندی ایج کمپیوٹنگ کے مخصوص منظرناموں کے لیے صحیح پریسیژن لیول منتخب کرنے کے لیے اہم ہے۔

### پریسیژن درجہ بندی کا فریم ورک

پریسیژن کی حدود کو سمجھنا مختلف ایج کمپیوٹنگ منظرناموں کے لیے مناسب کوانٹائزیشن لیولز کے انتخاب میں مدد دیتا ہے:

- **🔬 انتہائی کم پریسیژن**: 1-بٹ سے 2-بٹ کوانٹائزیشن (خصوصی ہارڈویئر کے لیے انتہائی کمپریشن)
- **📱 کم پریسیژن**: 3-بٹ سے 4-بٹ کوانٹائزیشن (کارکردگی اور مؤثریت کا متوازن امتزاج)
- **⚖️ درمیانی پریسیژن**: 5-بٹ سے 8-بٹ کوانٹائزیشن (مکمل پریسیژن کی صلاحیتوں کے قریب پہنچنا جبکہ مؤثریت برقرار رکھنا)

تحقیقاتی کمیونٹی میں حدود لچکدار رہتی ہیں، لیکن زیادہ تر ماہرین 8-بٹ اور اس سے کم کو "کوانٹائزڈ" سمجھتے ہیں، جبکہ کچھ ذرائع مختلف ہارڈویئر اہداف کے لیے خصوصی حدیں مقرر کرتے ہیں۔

### ماڈل کوانٹائزیشن کے اہم فوائد

ماڈل کوانٹائزیشن کئی بنیادی فوائد پیش کرتا ہے جو اسے ایج کمپیوٹنگ ایپلیکیشنز کے لیے مثالی بناتے ہیں:

**آپریشنل مؤثریت**: کوانٹائزڈ ماڈلز کم کمپیوٹیشنل پیچیدگی کی وجہ سے تیز انفرنس وقت فراہم کرتے ہیں، جو انہیں ریئل ٹائم ایپلیکیشنز کے لیے مثالی بناتے ہیں۔ یہ کم کمپیوٹیشنل وسائل کی ضرورت رکھتے ہیں، محدود وسائل والے آلات پر تعیناتی کو ممکن بناتے ہیں، کم توانائی استعمال کرتے ہیں، اور کاربن فٹ پرنٹ کو کم رکھتے ہیں۔

**تعیناتی کی لچک**: یہ ماڈلز انٹرنیٹ کنیکٹیویٹی کی ضرورت کے بغیر آن ڈیوائس AI صلاحیتوں کو ممکن بناتے ہیں، مقامی پروسیسنگ کے ذریعے پرائیویسی اور سیکیورٹی کو بڑھاتے ہیں، ڈومین مخصوص ایپلیکیشنز کے لیے حسب ضرورت بنائے جا سکتے ہیں، اور مختلف ایج کمپیوٹنگ ماحول کے لیے موزوں ہیں۔

**لاگت کی مؤثریت**: کوانٹائزڈ ماڈلز مکمل پریسیژن ماڈلز کے مقابلے میں لاگت مؤثر تربیت اور تعیناتی پیش کرتے ہیں، آپریشنل اخراجات کو کم کرتے ہیں، اور ایج ایپلیکیشنز کے لیے کم بینڈوڈتھ کی ضرورت رکھتے ہیں۔

## جدید ماڈل فارمیٹ حاصل کرنے کی حکمت عملی

### GGUF (جنرل GGML یونیورسل فارمیٹ)

GGUF کوانٹائزڈ ماڈلز کو CPU اور ایج ڈیوائسز پر تعینات کرنے کے لیے بنیادی فارمیٹ کے طور پر کام کرتا ہے۔ یہ فارمیٹ ماڈل کنورژن اور تعیناتی کے لیے جامع وسائل فراہم کرتا ہے:

**فارمیٹ دریافت کی خصوصیات**: فارمیٹ مختلف کوانٹائزیشن لیولز، لائسنس مطابقت، اور کارکردگی کی اصلاح کے لیے جدید سپورٹ پیش کرتا ہے۔ صارفین کراس پلیٹ فارم مطابقت، ریئل ٹائم کارکردگی کے بینچ مارکس، اور براؤزر پر مبنی تعیناتی کے لیے WebGPU سپورٹ تک رسائی حاصل کر سکتے ہیں۔

**کوانٹائزیشن لیول کلیکشنز**: مقبول کوانٹائزیشن فارمیٹس میں Q4_K_M شامل ہیں جو متوازن کمپریشن فراہم کرتے ہیں، Q5_K_S سیریز جو معیار پر مرکوز ایپلیکیشنز کے لیے موزوں ہیں، Q8_0 جو اصل پریسیژن کے قریب ہے، اور تجرباتی فارمیٹس جیسے Q2_K جو انتہائی کم پریسیژن تعیناتی کے لیے ہیں۔ فارمیٹ میں کمیونٹی سے چلنے والی مختلف حالتیں بھی شامل ہیں جو مخصوص ڈومینز کے لیے خصوصی کنفیگریشنز کے ساتھ ہیں اور عام مقصد اور انسٹرکشن ٹونڈ ویریئنٹس مختلف استعمال کے کیسز کے لیے بہتر بنائے گئے ہیں۔

### ONNX (اوپن نیورل نیٹ ورک ایکسچینج)

ONNX فارمیٹ کوانٹائزڈ ماڈلز کے لیے کراس فریم ورک مطابقت فراہم کرتا ہے، جس میں بہتر انضمام کی صلاحیتیں شامل ہیں:

**انٹرپرائز انضمام**: فارمیٹ میں انٹرپرائز گریڈ سپورٹ اور اصلاحی صلاحیتوں کے ساتھ ماڈلز شامل ہیں، جس میں متحرک کوانٹائزیشن شامل ہے جو موافق پریسیژن فراہم کرتا ہے اور جامد کوانٹائزیشن جو پروڈکشن تعیناتی کے لیے موزوں ہے۔ یہ مختلف فریم ورک سے ماڈلز کو معیاری کوانٹائزیشن طریقوں کے ساتھ سپورٹ کرتا ہے۔

**انٹرپرائز فوائد**: مختلف انفرنس انجنز میں بلٹ ان ٹولز کے ذریعے اصلاح، کراس پلیٹ فارم تعیناتی، اور ہارڈویئر ایکسیلیریشن کو مربوط کیا گیا ہے۔ معیاری APIs کے ساتھ براہ راست فریم ورک سپورٹ، مربوط اصلاحی خصوصیات، اور جامع تعیناتی ورک فلو انٹرپرائز تجربے کو بہتر بناتے ہیں۔

## جدید کوانٹائزیشن اور اصلاحی تکنیکیں

### Llama.cpp اصلاحی فریم ورک

Llama.cpp ایج تعیناتی میں زیادہ سے زیادہ مؤثریت کے لیے جدید کوانٹائزیشن تکنیکیں فراہم کرتا ہے:

**کوانٹائزیشن کے طریقے**: فریم ورک مختلف کوانٹائزیشن لیولز کو سپورٹ کرتا ہے، جن میں Q4_0 (4-بٹ کوانٹائزیشن جو سائز میں بہترین کمی فراہم کرتا ہے - موبائل تعیناتی کے لیے مثالی)، Q5_1 (5-بٹ کوانٹائزیشن جو معیار اور کمپریشن کو متوازن کرتا ہے - ایج انفرنس کے لیے موزوں)، اور Q8_0 (8-بٹ کوانٹائزیشن جو اصل معیار کے قریب ہے - پروڈکشن استعمال کے لیے تجویز کردہ) شامل ہیں۔ جدید فارمیٹس جیسے Q2_K انتہائی منظرناموں کے لیے جدید کمپریشن کی نمائندگی کرتے ہیں۔

**نفاذ کے فوائد**: SIMD ایکسیلیریشن کے ساتھ CPU-آپٹمائزڈ انفرنس میموری مؤثر ماڈل لوڈنگ اور عملدرآمد فراہم کرتا ہے۔ x86، ARM، اور Apple Silicon آرکیٹیکچرز کے درمیان کراس پلیٹ فارم مطابقت ہارڈویئر سے آزاد تعیناتی کی صلاحیتوں کو ممکن بناتی ہے۔

**میموری فٹ پرنٹ کا موازنہ**: مختلف کوانٹائزیشن لیولز ماڈل سائز اور معیار کے درمیان مختلف سمجھوتے پیش کرتے ہیں۔ Q4_0 تقریباً 75% سائز میں کمی فراہم کرتا ہے، Q5_1 70% کمی کے ساتھ بہتر معیار برقرار رکھتا ہے، اور Q8_0 50% کمی حاصل کرتا ہے جبکہ اصل کارکردگی کو برقرار رکھتا ہے۔

### Microsoft Olive اصلاحی سوٹ

Microsoft Olive پروڈکشن ماحول کے لیے جامع ماڈل اصلاحی ورک فلو فراہم کرتا ہے:

**اصلاحی تکنیکیں**: سوٹ میں متحرک کوانٹائزیشن شامل ہے جو خودکار پریسیژن انتخاب فراہم کرتا ہے، گراف اصلاح اور آپریٹر فیوژن جو مؤثریت کو بہتر بناتے ہیں، CPU، GPU، اور NPU تعیناتی کے لیے ہارڈویئر مخصوص اصلاحات، اور ملٹی اسٹیج اصلاحی پائپ لائنز شامل ہیں۔ مختلف پریسیژن لیولز کے لیے خصوصی کوانٹائزیشن ورک فلو 8-بٹ سے لے کر تجرباتی 1-بٹ کنفیگریشنز تک سپورٹ فراہم کرتے ہیں۔

**ورک فلو آٹومیشن**: اصلاحی مختلف حالتوں کے درمیان خودکار بینچ مارکنگ معیار میٹرکس کو محفوظ رکھتے ہوئے اصلاح کو یقینی بناتی ہے۔ PyTorch اور ONNX جیسے مقبول ML فریم ورک کے ساتھ انضمام کلاؤڈ اور ایج تعیناتی کی اصلاحی صلاحیتیں فراہم کرتا ہے۔

### Apple MLX فریم ورک

Apple MLX خاص طور پر Apple Silicon آلات کے لیے ڈیزائن کردہ مقامی اصلاحی صلاحیتیں فراہم کرتا ہے:

**Apple Silicon اصلاح**: فریم ورک متحد میموری آرکیٹیکچر کے ساتھ Metal Performance Shaders انضمام، خودکار مکسڈ پریسیژن انفرنس، اور بہتر میموری بینڈوڈتھ استعمال فراہم کرتا ہے۔ ماڈلز M سیریز چپس پر بہترین کارکردگی دکھاتے ہیں، مختلف Apple ڈیوائسز کی تعیناتی کے لیے مثالی توازن فراہم کرتے ہیں۔

**ترقیاتی خصوصیات**: Python اور Swift API سپورٹ کے ساتھ NumPy کے مطابق ایریے آپریشنز، خودکار تفریق کی صلاحیتیں، اور Apple ترقیاتی ٹولز کے ساتھ ہموار انضمام ایک جامع ترقیاتی ماحول فراہم کرتے ہیں۔

## پروڈکشن تعیناتی اور انفرنس کی حکمت عملی

### Ollama: مقامی تعیناتی کو آسان بنانا

Ollama ایج اور مقامی ماحول کے لیے انٹرپرائز تیار خصوصیات کے ساتھ ماڈل تعیناتی کو آسان بناتا ہے:

**تعیناتی کی صلاحیتیں**: ایک کمانڈ ماڈل انسٹالیشن اور عملدرآمد کے ساتھ خودکار ماڈل پلنگ اور کیشنگ۔ مختلف کوانٹائزڈ فارمیٹس کے لیے سپورٹ، REST API ایپلیکیشن انضمام کے لیے، اور ملٹی ماڈل مینجمنٹ اور سوئچنگ کی صلاحیتیں۔ جدید کوانٹائزیشن لیولز کے لیے بہترین تعیناتی کے لیے مخصوص کنفیگریشن کی ضرورت ہوتی ہے۔

**جدید خصوصیات**: حسب ضرورت ماڈل فائن ٹیوننگ سپورٹ، کنٹینرائزڈ تعیناتی کے لیے Dockerfile جنریشن، GPU ایکسیلیریشن کے ساتھ خودکار ڈیٹیکشن، اور ماڈل کوانٹائزیشن اور اصلاحی اختیارات جامع تعیناتی کی لچک فراہم کرتے ہیں۔

### VLLM: اعلی کارکردگی انفرنس

VLLM اعلی throughput منظرناموں کے لیے پروڈکشن گریڈ انفرنس اصلاح فراہم کرتا ہے:

**کارکردگی کی اصلاحات**: PagedAttention میموری مؤثر توجہ کی کمپیوٹیشن کے لیے، throughput کی اصلاح کے لیے متحرک بیچنگ، ملٹی-GPU اسکیلنگ کے لیے ٹینسر پیراللزم، اور لیٹنسی کو کم کرنے کے لیے speculative decoding۔ جدید کوانٹائزیشن فارمیٹس کے لیے بہترین کارکردگی کے لیے خصوصی انفرنس کرنلز کی ضرورت ہوتی ہے۔

**انٹرپرائز انضمام**: OpenAI کے مطابق API اینڈپوائنٹس، Kubernetes تعیناتی سپورٹ، مانیٹرنگ اور مشاہداتی انضمام، اور خودکار اسکیلنگ کی صلاحیتیں انٹرپرائز گریڈ تعیناتی کے حل فراہم کرتی ہیں۔

### Microsoft کے ایج حل

Microsoft انٹرپرائز ماحول کے لیے جامع ایج تعیناتی کی صلاحیتیں فراہم کرتا ہے:

**ایج کمپیوٹنگ خصوصیات**: آف لائن فرسٹ آرکیٹیکچر ڈیزائن کے ساتھ وسائل کی پابندی کی اصلاح، مقامی ماڈل رجسٹری مینجمنٹ، اور ایج سے کلاؤڈ ہم آہنگی کی صلاحیتیں قابل اعتماد ایج تعیناتی کو یقینی بناتی ہیں۔

**سیکیورٹی اور تعمیل**: پرائیویسی کو محفوظ رکھنے کے لیے مقامی ڈیٹا پروسیسنگ، انٹرپرائز سیکیورٹی کنٹرولز، آڈٹ لاگنگ اور تعمیل کی رپورٹنگ، اور رول پر مبنی رسائی مینجمنٹ ایج تعیناتیوں کے لیے جامع سیکیورٹی فراہم کرتے ہیں۔

## ماڈل کوانٹائزیشن کے نفاذ کے لیے بہترین طریقے

### کوانٹائزیشن لیول کے انتخاب کے رہنما اصول

ایج تعیناتی کے لیے کوانٹائزیشن لیولز کا انتخاب کرتے وقت درج ذیل عوامل پر غور کریں:

**پریسیژن کی گنتی کے تحفظات**: انتہائی موبائل ایپلیکیشنز کے لیے Q2_K جیسے انتہائی کم پریسیژن کا انتخاب کریں، متوازن کارکردگی کے منظرناموں کے لیے Q4_K_M جیسے کم پریسیژن کا انتخاب کریں، اور مکمل پریسیژن کی صلاحیتوں کے قریب پہنچنے کے لیے Q8_0 جیسے درمیانی پریسیژن کا انتخاب کریں جبکہ مؤثریت برقرار رکھیں۔ تجرباتی فارمیٹس مخصوص تحقیقی ایپلیکیشنز کے لیے خصوصی کمپریشن فراہم کرتے ہیں۔

**استعمال کے کیس کے مطابق**: کوانٹائزیشن کی صلاحیتوں کو مخصوص ایپلیکیشن کی ضروریات کے مطابق بنائیں، جیسے کہ درستگی کا تحفظ، انفرنس کی رفتار، میموری کی پابندیاں، اور آف لائن آپریشن کی ضروریات۔

### اصلاحی حکمت عملی کا انتخاب

**کوانٹائزیشن کا طریقہ**: معیار کی ضروریات اور ہارڈویئر کی پابندیوں کی بنیاد پر مناسب کوانٹائزیشن لیولز کا انتخاب کریں۔ زیادہ سے زیادہ کمپریشن کے لیے Q4_0 پر غور کریں، معیار-کمپریشن کے متوازن امتزاج کے لیے Q5_1 پر غور کریں، اور اصل معیار کے تحفظ کے لیے Q8_0 پر غور کریں۔ تجرباتی فارمیٹس مخصوص ایپلیکیشنز کے لیے انتہائی کمپریشن کی حد کی نمائندگی کرتے ہیں۔

**فریم ورک کا انتخاب**: ہدف ہارڈویئر اور تعیناتی کی ضروریات کی بنیاد پر اصلاحی فریم ورک کا انتخاب کریں۔ CPU-آپٹمائزڈ تعیناتی کے لیے Llama.cpp استعمال کریں، جامع اصلاحی ورک فلو کے لیے Microsoft Olive استعمال کریں، اور Apple Silicon آلات کے لیے Apple MLX استعمال کریں۔

## عملی فارمیٹ کنورژن اور استعمال کے کیسز

### حقیقی دنیا کے تعیناتی منظرنامے

**موبائل ایپلیکیشنز**: Q4_K فارمیٹس اسمارٹ فون ایپلیکیشنز میں کم میموری فٹ پرنٹ کے ساتھ بہترین کارکردگی دکھاتے ہیں، جبکہ Q8_0 ٹیبلٹ پر مبنی ایپلیکیشنز کے لیے متوازن کارکردگی فراہم کرتا ہے۔ Q5_K فارمیٹس موبائل پروڈکٹیویٹی ایپلیکیشنز کے لیے اعلیٰ معیار فراہم کرتے ہیں۔

**ڈیسک ٹاپ اور ایج کمپیوٹنگ**: Q5_K ڈیسک ٹاپ ایپلیکیشنز کے لیے بہترین کارکردگی فراہم کرتا ہے، Q8_0 ورک سٹیشن ماحول کے لیے اعلیٰ معیار کا انفرنس فراہم کرتا ہے، اور Q4_K ایج ڈیوائسز پر مؤثر پروسیسنگ کو ممکن بناتا ہے۔

**تحقیق اور تجرباتی**: جدید کوانٹائزیشن فارمیٹس انتہائی کم پریسیژن انفرنس کی تلاش کے لیے تعلیمی تحقیق اور پروف آف کانسیپٹ ایپلیکیشنز کے لیے انتہائی وسائل کی پابندیوں کے ساتھ ممکن بناتے ہیں۔

### کارکردگی کے بینچ مارکس اور موازنہ

**انفرنس کی رفتار**: Q4_K موبائل CPUs پر تیز ترین انفرنس وقت حاصل کرتا ہے، Q5_K عمومی ایپلیکیشنز کے لیے رفتار-معیار تناسب کو متوازن کرتا ہے، Q8_0 پیچیدہ کاموں کے لیے اعلیٰ معیار فراہم کرتا ہے، اور تجرباتی فارمیٹس خصوصی ہارڈویئر کے ساتھ نظریاتی زیادہ سے زیادہ throughput فراہم کرتے ہیں۔

**میموری کی ضروریات**: کوانٹائزیشن لیولز Q2_K (چھوٹے ماڈلز کے لیے 500MB سے کم) سے لے کر Q8_0 (اصل سائز کا تقریباً 50%) تک مختلف ہوتے ہیں، جبکہ تجرباتی کنفیگریشنز زیادہ سے زیادہ کمپریشن تناسب حاصل کرتے ہیں۔

## چیلنجز اور تحفظات

### کارکردگی کے سمجھوتے

کوانٹائزیشن تعیناتی ماڈل سائز، انفرنس کی رفتار، اور آؤٹ پٹ معیار کے درمیان سمجھ

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔