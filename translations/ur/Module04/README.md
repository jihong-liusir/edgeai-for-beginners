<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c0cb9f7bcff2bc170532d8870a891f38",
  "translation_date": "2025-09-17T17:48:28+00:00",
  "source_file": "Module04/README.md",
  "language_code": "ur"
}
-->
# باب 04: ماڈل فارمیٹ کنورژن اور کوانٹائزیشن - باب کا جائزہ

ایج اے آئی کی ترقی نے ماڈل فارمیٹ کنورژن اور کوانٹائزیشن کو اہم ٹیکنالوجیز بنا دیا ہے، جو محدود وسائل والے آلات پر جدید مشین لرننگ صلاحیتوں کو نافذ کرنے کے لیے ضروری ہیں۔ یہ جامع باب ایج ڈپلائمنٹ کے منظرناموں کے لیے ماڈلز کو سمجھنے، نافذ کرنے، اور بہتر بنانے کے لیے مکمل رہنمائی فراہم کرتا ہے۔

## 📚 باب کی ساخت اور سیکھنے کا راستہ

یہ باب چھ ترقی پسند حصوں میں منظم ہے، ہر حصہ پچھلے حصے پر مبنی ہے تاکہ ایج کمپیوٹنگ کے لیے ماڈل کی اصلاح کو مکمل طور پر سمجھا جا سکے:

---

## [حصہ 1: ماڈل فارمیٹ کنورژن اور کوانٹائزیشن کی بنیادیں](./01.Introduce.md)

### 🎯 جائزہ
یہ بنیادی حصہ ایج کمپیوٹنگ ماحول میں ماڈل کی اصلاح کے لیے نظریاتی فریم ورک قائم کرتا ہے، جس میں کوانٹائزیشن کی حدود 1-بٹ سے 8-بٹ پریسیژن لیولز تک اور اہم فارمیٹ کنورژن حکمت عملی شامل ہیں۔

**اہم موضوعات:**
- پریسیژن کی درجہ بندی کا فریم ورک (انتہائی کم، کم، درمیانی پریسیژن)
- GGUF اور ONNX فارمیٹ کے فوائد اور استعمال کے کیسز
- آپریشنل کارکردگی اور ڈپلائمنٹ کی لچک کے لیے کوانٹائزیشن کے فوائد
- کارکردگی کے بینچ مارکس اور میموری کے استعمال کے موازنات

**سیکھنے کے نتائج:**
- کوانٹائزیشن کی حدود اور درجہ بندی کو سمجھیں
- مناسب فارمیٹ کنورژن تکنیک کی شناخت کریں
- ایج ڈپلائمنٹ کے لیے جدید اصلاحی حکمت عملی سیکھیں

---

## [حصہ 2: Llama.cpp کے نفاذ کی رہنمائی](./02.Llamacpp.md)

### 🎯 جائزہ
Llama.cpp کے نفاذ کے لیے ایک جامع ٹیوٹوریل، ایک طاقتور C++ فریم ورک جو مختلف ہارڈویئر کنفیگریشنز پر کم سے کم سیٹ اپ کے ساتھ بڑے لینگویج ماڈل کی مؤثر انفرنس کو ممکن بناتا ہے۔

**اہم موضوعات:**
- ونڈوز، میک او ایس، اور لینکس پلیٹ فارمز پر انسٹالیشن
- GGUF فارمیٹ کنورژن اور مختلف کوانٹائزیشن لیولز (Q2_K سے Q8_0)
- CUDA، Metal، OpenCL، اور Vulkan کے ساتھ ہارڈویئر ایکسیلیریشن
- Python انٹیگریشن اور پروڈکشن ڈپلائمنٹ کی حکمت عملی

**سیکھنے کے نتائج:**
- کراس پلیٹ فارم انسٹالیشن اور سورس سے بلڈنگ میں مہارت حاصل کریں
- ماڈل کوانٹائزیشن اور اصلاحی تکنیک نافذ کریں
- REST API انٹیگریشن کے ساتھ سرور موڈ میں ماڈلز کو ڈپلائے کریں

---

## [حصہ 3: Microsoft Olive Optimization Suite](./03.MicrosoftOlive.md)

### 🎯 جائزہ
Microsoft Olive کا جائزہ، ایک ہارڈویئر سے آگاہ ماڈل اصلاحی ٹول کٹ جس میں 40+ بلٹ ان اصلاحی اجزاء شامل ہیں، جو مختلف ہارڈویئر پلیٹ فارمز پر انٹرپرائز گریڈ ماڈل ڈپلائمنٹ کے لیے ڈیزائن کیا گیا ہے۔

**اہم موضوعات:**
- ڈائنامک اور اسٹیٹک کوانٹائزیشن کے ساتھ آٹو-آپٹیمائزیشن فیچرز
- CPU، GPU، اور NPU ڈپلائمنٹ کے لیے ہارڈویئر سے آگاہ انٹیلیجنس
- مشہور ماڈلز (Llama، Phi، Qwen، Gemma) کے لیے آؤٹ آف دی باکس سپورٹ
- Azure ML اور پروڈکشن ورک فلو کے ساتھ انٹرپرائز انٹیگریشن

**سیکھنے کے نتائج:**
- مختلف ماڈل آرکیٹیکچرز کے لیے خودکار اصلاحی حکمت عملیوں کا فائدہ اٹھائیں
- کراس پلیٹ فارم ڈپلائمنٹ کی حکمت عملی نافذ کریں
- انٹرپرائز کے لیے تیار اصلاحی پائپ لائنز قائم کریں

---

## [حصہ 4: OpenVINO Toolkit Optimization Suite](./04.openvino.md)

### 🎯 جائزہ
Intel کے OpenVINO ٹول کٹ کا جامع جائزہ، ایک اوپن سورس پلیٹ فارم جو کلاؤڈ، آن-پریمیس، اور ایج ماحول میں مؤثر AI حلوں کو ڈپلائے کرنے کے لیے جدید Neural Network Compression Framework (NNCF) صلاحیتوں کے ساتھ فراہم کرتا ہے۔

**اہم موضوعات:**
- ہارڈویئر ایکسیلیریشن کے ساتھ کراس پلیٹ فارم ڈپلائمنٹ (CPU، GPU، VPU، AI ایکسیلیریٹرز)
- Neural Network Compression Framework (NNCF) کے ذریعے جدید کوانٹائزیشن اور پروننگ
- OpenVINO GenAI کے ذریعے بڑے لینگویج ماڈل کی اصلاح اور ڈپلائمنٹ
- انٹرپرائز گریڈ ماڈل سرور کی صلاحیتیں اور اسکیل ایبل ڈپلائمنٹ کی حکمت عملی

**سیکھنے کے نتائج:**
- OpenVINO ماڈل کنورژن اور اصلاحی ورک فلو میں مہارت حاصل کریں
- NNCF کے ساتھ جدید کوانٹائزیشن تکنیک نافذ کریں
- مختلف ہارڈویئر پلیٹ فارمز پر ماڈلز کو ڈپلائے کریں

---

## [حصہ 5: Apple MLX Framework کی گہرائی میں تحقیق](./05.AppleMLX.md)

### 🎯 جائزہ
Apple MLX کا جامع جائزہ، ایک انقلابی فریم ورک جو خاص طور پر Apple Silicon پر مؤثر مشین لرننگ کے لیے ڈیزائن کیا گیا ہے، جس میں بڑے لینگویج ماڈل کی صلاحیتوں اور مقامی ڈپلائمنٹ پر زور دیا گیا ہے۔

**اہم موضوعات:**
- متحد میموری آرکیٹیکچر کے فوائد اور Metal Performance Shaders
- LLaMA، Mistral، Phi-3، Qwen، اور Code Llama ماڈلز کے لیے سپورٹ
- LoRA فائن ٹیوننگ کے ذریعے مؤثر ماڈل حسب ضرورت
- Hugging Face انٹیگریشن اور کوانٹائزیشن سپورٹ (4-بٹ اور 8-بٹ)

**سیکھنے کے نتائج:**
- Apple Silicon کے لیے LLM ڈپلائمنٹ کی اصلاح میں مہارت حاصل کریں
- فائن ٹیوننگ اور ماڈل حسب ضرورت تکنیک نافذ کریں
- بہتر پرائیویسی فیچرز کے ساتھ انٹرپرائز AI ایپلیکیشنز بنائیں

---

## [حصہ 6: Edge AI Development Workflow Synthesis](./06.workflow-synthesis.md)

### 🎯 جائزہ
تمام اصلاحی فریم ورک کو متحد ورک فلو، فیصلہ سازی کے میٹرکس، اور پروڈکشن کے لیے تیار ایج AI ڈپلائمنٹ کے بہترین طریقوں میں جامع طور پر یکجا کرنے کا جائزہ۔

**اہم موضوعات:**
- متعدد اصلاحی فریم ورک کو یکجا کرنے والا ورک فلو آرکیٹیکچر
- فریم ورک کے انتخاب کے فیصلہ سازی کے درخت اور کارکردگی کے تجزیے
- پروڈکشن کی تیاری کی توثیق اور جامع ڈپلائمنٹ کی حکمت عملی
- ابھرتے ہوئے ہارڈویئر اور ماڈل آرکیٹیکچرز کے لیے مستقبل کی حکمت عملی

**سیکھنے کے نتائج:**
- ضروریات اور پابندیوں کی بنیاد پر منظم فریم ورک کے انتخاب میں مہارت حاصل کریں
- جامع مانیٹرنگ کے ساتھ پروڈکشن گریڈ ایج AI پائپ لائنز نافذ کریں
- ابھرتی ہوئی ٹیکنالوجیز اور ضروریات کے ساتھ ترقی پذیر ورک فلو ڈیزائن کریں

---

## 🎯 باب کے سیکھنے کے نتائج

اس جامع باب کو مکمل کرنے کے بعد، قارئین درج ذیل حاصل کریں گے:

### **تکنیکی مہارت**
- کوانٹائزیشن کی حدود اور عملی اطلاق کی گہری سمجھ
- متعدد اصلاحی فریم ورک کے ساتھ عملی تجربہ
- ایج کمپیوٹنگ ماحول کے لیے پروڈکشن ڈپلائمنٹ کی مہارت

### **اسٹریٹجک سمجھ**
- ہارڈویئر سے آگاہ اصلاحی انتخاب کی صلاحیتیں
- کارکردگی کے تجزیے پر مبنی فیصلہ سازی
- انٹرپرائز کے لیے تیار ڈپلائمنٹ اور مانیٹرنگ کی حکمت عملی

### **کارکردگی کے بینچ مارکس**

| فریم ورک | کوانٹائزیشن | میموری کا استعمال | رفتار میں بہتری | استعمال کا کیس |
|-----------|-------------|--------------------|------------------|----------------|
| Llama.cpp | Q4_K_M | ~4GB | 2-3x | کراس پلیٹ فارم ڈپلائمنٹ |
| Olive | INT4 | 60-75% کمی | 2-6x | انٹرپرائز ورک فلو |
| OpenVINO | INT8/INT4 | 50-75% کمی | 2-5x | Intel ہارڈویئر کی اصلاح |
| MLX | 4-bit | ~4GB | 2-4x | Apple Silicon کی اصلاح |

## 🚀 اگلے مراحل اور جدید اطلاقات

یہ باب مکمل بنیاد فراہم کرتا ہے:
- مخصوص ڈومینز کے لیے حسب ضرورت ماڈل کی ترقی
- ایج AI اصلاح میں تحقیق
- کمرشل AI ایپلیکیشن کی ترقی
- بڑے پیمانے پر انٹرپرائز ایج AI ڈپلائمنٹ

ان چھ حصوں سے حاصل کردہ علم ایج AI ماڈل کی اصلاح اور ڈپلائمنٹ کے تیزی سے ترقی پذیر منظرنامے کو نیویگیٹ کرنے کے لیے ایک جامع ٹول کٹ فراہم کرتا ہے۔

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔