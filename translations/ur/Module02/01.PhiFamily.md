<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T17:12:26+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "ur"
}
-->
# سیکشن 1: مائیکروسافٹ فی ماڈل فیملی کے بنیادی اصول

مائیکروسافٹ فی ماڈل فیملی مصنوعی ذہانت میں ایک نیا رجحان پیش کرتی ہے، یہ ظاہر کرتے ہوئے کہ چھوٹے اور مؤثر ماڈلز شاندار کارکردگی حاصل کر سکتے ہیں جبکہ روایتی بڑے زبان ماڈلز کے مقابلے میں وسائل کا استعمال کم کرتے ہیں۔ یہ سمجھنا ضروری ہے کہ فی فیملی کس طرح کم کمپیوٹیشنل ضروریات کے ساتھ طاقتور AI صلاحیتیں فراہم کرتی ہے اور مختلف کاموں میں اعلیٰ کارکردگی برقرار رکھتی ہے۔

## ڈویلپرز کے لیے وسائل

### Azure AI Foundry Model Catalog
فی ماڈلز (سوائے Phi-silica) [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi) کے ذریعے دستیاب ہیں، جو ڈویلپرز کے لیے ان ماڈلز کو اپنی ایپلیکیشنز میں استعمال، بہتر اور نافذ کرنا آسان بناتا ہے۔ کیٹلاگ مختلف فی ویریئنٹس کے ساتھ تجربہ کرنے اور انہیں اپنے پروجیکٹس میں شامل کرنے کا ایک آسان طریقہ فراہم کرتا ہے۔

### Azure AI Foundry
آپ [Azure AI Foundry](https://ai.azure.com) کا استعمال کرتے ہوئے فی ماڈلز کو نافذ اور تجربہ کر سکتے ہیں، جو AI حل بنانے، جانچنے اور نافذ کرنے کے لیے ایک جامع ماحول فراہم کرتا ہے۔

### Foundry Local
مقامی ترقی اور نفاذ کے لیے، [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) کو دیکھیں، جو آپ کو اپنی ترقیاتی مشین پر فی ماڈلز کو بہتر ترتیب کے ساتھ چلانے کی اجازت دیتا ہے۔

### دستاویزی وسائل
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## تعارف

اس سبق میں، ہم مائیکروسافٹ کے فی ماڈل فیملی اور اس کے بنیادی تصورات کا جائزہ لیں گے۔ ہم فی فیملی کی ترقی، انقلابی تربیتی طریقوں، اہم ویریئنٹس، اور مختلف منظرناموں میں عملی اطلاقات پر بات کریں گے۔

## سیکھنے کے مقاصد

اس سبق کے اختتام تک، آپ:

- مائیکروسافٹ کے فی ماڈل فیملی کے ڈیزائن فلسفہ اور ارتقاء کو سمجھ سکیں گے۔
- ان اہم جدتوں کی شناخت کر سکیں گے جو فی ماڈلز کو کم پیرامیٹرز کے ساتھ اعلیٰ کارکردگی حاصل کرنے کے قابل بناتی ہیں۔
- مختلف فی ماڈل ویریئنٹس کے فوائد اور حدود کو پہچان سکیں گے۔
- حقیقی دنیا کے منظرناموں کے لیے مناسب ویریئنٹس کا انتخاب کرنے کے لیے فی ماڈلز کے علم کو لاگو کر سکیں گے۔

## روایتی AI ماڈل کے رجحان کو سمجھنا

روایتی طور پر، قدرتی زبان کی پروسیسنگ میں اعلیٰ کارکردگی حاصل کرنے کے لیے اربوں یا سینکڑوں اربوں پیرامیٹرز والے بڑے زبان ماڈلز کی ضرورت ہوتی تھی۔ تنظیمیں عام طور پر ان ماڈلز کو طاقتور GPU کلسٹرز پر نافذ کرتی ہیں، ان کی صلاحیتوں تک API انٹرفیس یا مخصوص ہارڈویئر انفراسٹرکچر کے ذریعے رسائی حاصل کرتی ہیں۔

یہ طریقہ بہت سی ایپلیکیشنز کے لیے اچھا کام کرتا ہے لیکن عملی نفاذ کے منظرناموں میں کچھ حدود رکھتا ہے۔ روایتی طریقہ ایسے ماڈلز کا استعمال شامل کرتا ہے جو کافی کمپیوٹیشنل وسائل، بڑی مقدار میں میموری، اور قابل ذکر توانائی کی کھپت کی ضرورت رکھتے ہیں۔ اگرچہ یہ طریقہ جدید ترین صلاحیتوں تک رسائی فراہم کرتا ہے، یہ مہنگے ہارڈویئر پر انحصار پیدا کرتا ہے، اعلیٰ آپریشنل اخراجات متعارف کراتا ہے، اور نفاذ کی لچک کو محدود کرتا ہے۔

## مؤثر AI نفاذ کا چیلنج

مختلف منظرناموں میں زیادہ مؤثر AI کی ضرورت بڑھتی جا رہی ہے۔ ان ایپلیکیشنز پر غور کریں جنہیں رازداری کی وجوہات کی بنا پر مقامی نفاذ کی ضرورت ہوتی ہے، لاگت کے حساس نفاذ جہاں کلاؤڈ API کے اخراجات ممنوع ہو جاتے ہیں، محدود ہارڈویئر وسائل والے ایج کمپیوٹنگ منظرنامے، یا حقیقی وقت کی ایپلیکیشنز جہاں تاخیر اہم ہے۔

### اہم نفاذ کی حدود

روایتی بڑے ماڈل کے نفاذ کئی بنیادی حدود کا سامنا کرتے ہیں جو ان کی عملی اطلاق کو محدود کرتے ہیں:

- **لاگت کی حدود**: اعلیٰ کمپیوٹیشنل اخراجات بہت سی تنظیموں کے لیے مسلسل نفاذ کو مہنگا بنا دیتے ہیں۔
- **وسائل کی حدود**: اعلیٰ درجے کے GPU انفراسٹرکچر تک محدود رسائی نفاذ کے اختیارات کو محدود کرتی ہے۔
- **رازداری کی ضروریات**: حساس ایپلیکیشنز کو ڈیٹا کی رازداری برقرار رکھنے کے لیے مقامی پروسیسنگ کی ضرورت ہوتی ہے۔
- **تاخیر کی حساسیت**: حقیقی وقت کی ایپلیکیشنز کو کلاؤڈ کے چکر کی تاخیر کے بغیر فوری ردعمل کی ضرورت ہوتی ہے۔

## مائیکروسافٹ فی ماڈل فلسفہ

مائیکروسافٹ فی ماڈل فیملی AI ماڈل ڈیزائن فلسفہ میں ایک بنیادی تبدیلی کی نمائندگی کرتی ہے، مؤثریت اور عملی نفاذ کو ترجیح دیتے ہوئے مضبوط کارکردگی کی خصوصیات کو برقرار رکھتی ہے۔ فی ماڈلز جدید آرکیٹیکچرز، اعلیٰ معیار کی تربیتی طریقوں، اور مخصوص اصلاحی تکنیکوں کے ذریعے یہ حاصل کرتے ہیں۔

فی فیملی مختلف طریقوں کو شامل کرتی ہے جو پیرامیٹرز کے مطابق کارکردگی کو زیادہ سے زیادہ کرنے کے لیے ڈیزائن کیے گئے ہیں، معیاری ہارڈویئر پر نفاذ کو قابل بناتے ہوئے معنی خیز AI صلاحیتیں فراہم کرتی ہیں۔ مقصد یہ ہے کہ کمپیوٹیشنل ضروریات، میموری کے استعمال، اور آپریشنل اخراجات کو ڈرامائی طور پر کم کرتے ہوئے مسابقتی کارکردگی کو برقرار رکھا جائے۔

### فی کے بنیادی ڈیزائن اصول

فی ماڈلز کئی بنیادی اصولوں پر مبنی ہیں جو انہیں روایتی بڑے زبان ماڈلز سے ممتاز کرتے ہیں:

- **مؤثریت پہلے**: زیادہ سے زیادہ کارکردگی کے لیے پیرامیٹرز کے مطابق بہتر بنایا گیا۔
- **معیاری تربیت**: بڑے ڈیٹا سیٹس کے بجائے اعلیٰ معیار، منتخب تربیتی ڈیٹا پر توجہ۔
- **نفاذ کی لچک**: مختلف ہارڈویئر ترتیبوں پر مؤثر طریقے سے چلنے کے لیے ڈیزائن کیا گیا۔
- **خصوصی صلاحیتیں**: مخصوص کاموں یا ڈومینز کے لیے اکثر بہتر بنایا گیا تاکہ مؤثریت کو زیادہ سے زیادہ کیا جا سکے۔

## فی فیملی کو فعال کرنے والی اہم ٹیکنالوجیز

### "ٹیکسٹ بک" تربیتی طریقہ

فی فیملی کے سب سے انقلابی پہلوؤں میں سے ایک "ٹیکسٹ بک کوالٹی" تربیتی طریقہ ہے۔ انٹرنیٹ کے غیر فلٹر شدہ ڈیٹا کی بڑی مقدار پر تربیت کرنے کے بجائے، فی ماڈلز احتیاط سے منتخب، اعلیٰ معیار کے تعلیمی مواد کا استعمال کرتے ہیں جو مؤثر طریقے سے استدلال، ریاضی، کوڈنگ، اور عمومی علم سکھانے کے لیے ڈیزائن کیا گیا ہے۔

یہ طریقہ مصنوعی تعلیمی مواد تخلیق کرکے کام کرتا ہے جو اعلیٰ معیار کی نصابی کتابوں اور تعلیمی مواد کی عکاسی کرتا ہے۔ تربیتی ڈیٹا خاص طور پر تعلیمی طور پر درست ہونے کے لیے ڈیزائن کیا گیا ہے، واضح وضاحتوں، مرحلہ وار استدلال، اور منظم علم کی پیشکش پر توجہ مرکوز کرتا ہے۔

### جدید استدلال کی تربیت

حالیہ فی ماڈلز پیچیدہ کثیر مرحلہ مسئلہ حل کرنے کے قابل بنانے کے لیے نفیس استدلال کی تربیتی طریقوں کو شامل کرتے ہیں۔ ان تکنیکوں میں شامل ہیں:

**چین آف تھوٹ تربیت**: ماڈلز پیچیدہ مسائل کو درمیانی استدلال کے مراحل میں تقسیم کرنا سیکھتے ہیں، جس سے ان کے مسئلہ حل کرنے کے عمل کو زیادہ شفاف اور قابل اعتماد بنایا جاتا ہے۔

**انفرنس ٹائم اسکیلنگ**: ماڈلز تفصیلی استدلال کی زنجیریں پیدا کرتے ہیں جو جواب کی درستگی کو بہتر بنانے کے لیے اضافی کمپیوٹیشنل وسائل کا فائدہ اٹھاتے ہیں۔

**ایج آف کیپبیلٹی تربیت**: تربیتی ڈیٹا خاص طور پر ماڈل کو اس کی موجودہ صلاحیتوں کی حد پر چیلنج کرنے کے لیے منتخب کیا جاتا ہے، پیچیدہ استدلال کے نمونوں کو سیکھنے کو فروغ دیتا ہے۔

### آرکیٹیکچرل جدتیں

فی فیملی کئی آرکیٹیکچرل اصلاحات کو شامل کرتی ہے جو خاص طور پر مؤثریت کے لیے ڈیزائن کی گئی ہیں:

**پیرامیٹر مؤثریت**: آرکیٹیکچرل انتخاب جو ماڈل کے ہر پیرامیٹر کے اثر کو زیادہ سے زیادہ کرتے ہیں۔

**ملٹی موڈل انضمام**: کمپیکٹ آرکیٹیکچرز کے اندر متن، وژن، اور تقریر کی پروسیسنگ صلاحیتوں کا مؤثر انضمام۔

**ہارڈویئر اصلاح**: مخصوص ہارڈویئر پلیٹ فارمز اور نفاذ کے منظرناموں کے لیے بہتر ویریئنٹس۔

## فی ماڈلز کے لیے ہارڈویئر اصلاح

جدید نفاذ کے ماحول فی ماڈلز کی مؤثریت سے مختلف ہارڈویئر ترتیبوں میں فائدہ اٹھاتے ہیں:

### CPU-Optimized نفاذ

فی ماڈلز کو CPU-Only ہارڈویئر پر مؤثر طریقے سے چلانے کے لیے ڈیزائن کیا گیا ہے، انہیں معیاری کمپیوٹنگ انفراسٹرکچر پر نافذ کرنے کے قابل بناتا ہے بغیر مخصوص AI ایکسیلیریٹرز کی ضرورت کے۔

### GPU ایکسیلیریشن

طاقتور GPUs کی ضرورت نہ ہونے کے باوجود، فی ماڈلز دستیاب GPU وسائل کا فائدہ اٹھا سکتے ہیں تاکہ کارکردگی کو بہتر بنایا جا سکے، نفاذ کی ترتیب میں لچک فراہم کرتے ہوئے۔

### ایج ڈیوائس انضمام

خصوصی ویریئنٹس جیسے Phi-3-Silica مخصوص ایج کمپیوٹنگ پلیٹ فارمز کے لیے بہتر بنائے گئے ہیں، 1.5W پاور کے ساتھ 650 ٹوکنز فی سیکنڈ جیسے شاندار مؤثریت میٹرکس حاصل کرتے ہیں۔

## فی ماڈل فیملی کے فوائد

### لاگت کی مؤثریت

فی ماڈلز آپریشنل اخراجات کو ڈرامائی طور پر کم کرتے ہیں، کیونکہ انہیں نمایاں طور پر کم کمپیوٹیشنل انفراسٹرکچر کی ضرورت ہوتی ہے جبکہ مسابقتی کارکردگی کو برقرار رکھتے ہیں۔ یہ AI کو ان تنظیموں کے لیے قابل رسائی بناتا ہے جن کے بجٹ محدود ہیں یا جہاں ہر انفرنس کی لاگت اہم ہے۔

### نفاذ کی لچک

فی ماڈلز کی مؤثریت مختلف ہارڈویئر ترتیبوں پر نفاذ کو قابل بناتی ہے، ذاتی لیپ ٹاپ سے لے کر انٹرپرائز سرورز تک، تنظیموں کو ان کے AI انفراسٹرکچر کے انتخاب میں زیادہ لچک فراہم کرتی ہے۔

### رازداری اور سیکیورٹی

فی ماڈلز کی مؤثریت رازداری کے حساس ایپلیکیشنز کے لیے مقامی نفاذ کو قابل بناتی ہے، یہ یقینی بناتے ہوئے کہ حساس ڈیٹا تنظیم کے کنٹرول سے باہر نہ جائے جبکہ طاقتور AI صلاحیتیں فراہم کی جائیں۔

### حقیقی وقت کی کارکردگی

کم کمپیوٹیشنل ضروریات تیز انفرنس اوقات میں ترجمہ کرتی ہیں، حقیقی وقت کی ایپلیکیشنز کو قابل بناتی ہیں جنہیں فوری ردعمل کی ضرورت ہوتی ہے بغیر AI صلاحیت کے معیار پر سمجھوتہ کیے۔

### قابل رسائی AI

نفاذ کی رکاوٹوں کو کم کرکے، فی ماڈلز جدید AI صلاحیتوں کو محدود وسائل والی تنظیموں کے لیے قابل رسائی بناتے ہیں، چھوٹی ٹیموں اور انفرادی ڈویلپرز کو پیچیدہ زبان کی سمجھ بوجھ سے فائدہ اٹھانے کے قابل بناتے ہیں۔

## عملی مثالیں اور استعمال کے کیسز

تکنیکی ارتقاء میں جانے سے پہلے، آئیے کچھ ٹھوس مثالوں کا جائزہ لیں کہ فی ماڈلز کیا حاصل کر سکتے ہیں:

### ریاضیاتی استدلال کی مثال

Phi-4-mini-reasoning مرحلہ وار ریاضیاتی مسئلہ حل کرنے میں مہارت رکھتا ہے۔ مثال کے طور پر، جب پوچھا گیا "3*x^2+4*x+5=1 کو کیسے حل کریں؟"، ماڈل تفصیلی استدلال کے مراحل فراہم کرتا ہے:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### کثیر لسانی سپورٹ کی مثال

Phi-3.5-mini-instruct مختلف زبانوں میں مضبوط کثیر لسانی صلاحیتوں کا مظاہرہ کرتا ہے۔ یہاں ایک مثال پرامپٹ فارمیٹ ہے:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### ملٹی موڈل صلاحیتوں کی مثال

Phi-4-multimodal ایک ساتھ متن، تصاویر، اور تقریر کو پروسیس کر سکتا ہے۔ یہاں کچھ عملی اطلاقات ہیں:

**آڈیو ان پٹ کے ساتھ سفر کی منصوبہ بندی:**
دیکھیں کہ Phi-4 Multimodal کس طرح بولی گئی زبان کا تجزیہ کرتا ہے تاکہ سیئٹل کے سفر کی منصوبہ بندی میں مدد فراہم کرے، اس کی جدید آڈیو پروسیسنگ اور سفارش کی صلاحیتوں کا مظاہرہ کرتے ہوئے۔

**تصاویر سے ریاضیاتی مسئلہ حل کرنا:**
دیکھیں کہ Phi-4 Multimodal کس طرح پیچیدہ ریاضیاتی مسائل کو بصری ان پٹ کے ذریعے حل کرتا ہے، اس کی صلاحیت کو مساوات کو پروسیس اور حل کرنے کا مظاہرہ کرتے ہوئے۔

**فنکشن کالنگ کی مثال:**
فنکشن کالنگ کے ساتھ، Phi-4-mini اور Phi-4-multimodal اپنے متن پروسیسنگ کی صلاحیتوں کو سرچ انجنز کو مربوط کرکے، مختلف ٹولز کو جوڑ کر، اور مزید بڑھا سکتے ہیں۔ جیسا کہ دکھایا گیا ہے، ماڈل Phi-4-mini کے ذریعے پریمیئر لیگ میچ کی معلومات حاصل کر سکتا ہے، اس کی بیرونی ڈیٹا ذرائع کے ساتھ بغیر کسی رکاوٹ کے تعامل کی صلاحیت کو ظاہر کرتے ہوئے۔

### کوڈ جنریشن کی مثال

Phi-4-multimodal فراہم کردہ پرامپٹس اور تصویری مواد کی بنیاد پر منظم پروجیکٹ کوڈ تیار کر سکتا ہے، جیسا کہ اس عملی ورک فلو میں دکھایا گیا ہے:

1. وائر فریم یا ڈیزائن کی تصویر اپ لوڈ کریں
2. پروجیکٹ کی ضروریات کے بارے میں سیاق و سباق فراہم کریں
3. ماڈل مکمل، فعال کوڈ ڈھانچے تیار کرتا ہے
4. کوڈ مخصوص فریم ورک یا زبانوں کی بنیاد پر حسب ضرورت بنایا جا سکتا ہے

### ایج نفاذ کی مثال

ہم کوانٹائزڈ ماڈل کو ایج ڈیوائسز پر نافذ کر سکتے ہیں۔ مائیکروسافٹ اولیو اور ONNX GenAI Runtime کو یکجا کرکے، ہم Phi-4-mini کو ونڈوز، آئی فون، اینڈرائیڈ اور دیگر ڈیوائسز پر نافذ کر سکتے ہیں۔ یہ ایک مثال ہے جو آئی فون 12 پرو پر چل رہی ہے۔

نفاذ کا عمل شامل ہے:
- موبائل اصلاح کے لیے ماڈل کوانٹائزیشن
- کراس پلیٹ فارم مطابقت کے لیے ONNX رن ٹائم انضمام
- انٹرنیٹ کنیکٹیویٹی کے بغیر مقامی انفرنس
- کم سے کم پاور کھپت کے ساتھ حقیقی وقت کی کارکردگی

## فی فیملی کا ارتقاء

### Phi-1 اور Phi-2: بنیادی ماڈلز

ابتدائی فی ماڈلز نے اعلیٰ معیار کے تربیتی ڈیٹا اور مؤثر آرکیٹیکچرز کے بنیادی اصول قائم کیے:

- **Phi-1 (1.3B پیرامیٹرز)**: بنیادی زبان کی سمجھ بوجھ اور کوڈ جنریشن کے لیے منتخب تربیتی ڈیٹا کے تصور کو متعارف کرایا۔
- **Phi-2 (2.7B پیرامیٹرز)**: مصنوعی NLP ڈیٹا اور احتیاط سے فلٹر شدہ ویب مواد کے ذریعے استدلال کی صلاحیتوں کو بہتر بنایا۔

### Phi-3 فیملی: مرکزی دھارے میں اپنانا

Phi-3 سیریز نے متعدد خصوصی ویریئنٹس کے ساتھ SLM صلاحیتوں میں ایک پیش رفت کی نشاندہی کی:

- **Phi-3-mini (3.8B پیرامیٹرز)**: غیر معمولی مؤثریت کے ساتھ عمومی زبان کے کام، اپنے سائز سے دوگنا ماڈلز کو پیچھے چھوڑتے ہوئے۔
- **Phi-3-small (7B پیرامیٹرز)**: مختلف بینچ مارکس پر GPT-3.5 Turbo کو شکست دیتے ہوئے اعلیٰ کارکردگی۔
- **Phi-3-medium (14B پیرامیٹرز)**: انٹرپرائز گریڈ کارکردگی Gemini 1.0 Pro کو پیچھے چھوڑتے ہوئے۔
- **Phi-3-vision (4.2B پیرامیٹرز)**: ملٹی موڈل صلاحیتیں تصویر اور متن پروسیسنگ کے لیے۔
- **Phi-3-Silica (3.3B پیرامیٹرز)**: ونڈوز 11 بلٹ ان نفاذ کے لیے خصوصی اصلاح۔

### Phi-4 فیملی: جدید استدلال

تازہ ترین نسل استدلال کی صلاحیتوں کی حدود کو آگے بڑھاتی ہے:

- **Phi-4 (14B پیرامیٹرز)**: خاص طور پر ریاضی میں پیچیدہ استدلال کی مہارت۔
- **Phi-4-mini (3.8B پیرامیٹرز)**: فنکشن کالنگ اور طویل سیاق و سباق کی حمایت کے ساتھ بہتر استدلال۔
- **Phi-4-multimodal**: تقریر، وژن، اور متن پروسیسنگ کی صلاحیتیں ایک
Phi خاندان یہ ظاہر کرتا ہے کہ AI کے مستقبل کی تعیناتی صرف بڑے ماڈلز بنانے میں نہیں بلکہ زیادہ ذہین اور مؤثر ماڈلز بنانے میں ہے جو مختلف ہارڈویئر ماحول میں مؤثر طریقے سے کام کر سکیں اور اعلیٰ کارکردگی کے معیار کو برقرار رکھ سکیں۔

## ترقی اور انضمام کی مثالیں

### ٹرانسفارمرز کے ساتھ جلدی آغاز

یہاں بتایا گیا ہے کہ Hugging Face Transformers لائبریری کا استعمال کرتے ہوئے Phi ماڈلز کے ساتھ کیسے شروع کریں:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### فائن ٹیوننگ کی مثال

یہ مثال دکھاتی ہے کہ Phi-4-mini-instruct کو مخصوص کاموں کے لیے کیسے فائن ٹیون کیا جائے:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### خصوصی پرامپٹ فارمیٹس

**منطق کے کاموں کے لیے (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**ریاضیاتی کاموں کے لیے (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### موبائل تعیناتی ONNX کے ساتھ

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## کارکردگی کے بینچ مارکس اور کامیابیاں

Phi ماڈل خاندان نے مختلف بینچ مارکس پر شاندار کارکردگی حاصل کی ہے، اکثر بہت بڑے ماڈلز کو پیچھے چھوڑتے ہوئے:

### اہم کارکردگی کی جھلکیاں

**ریاضیاتی منطق میں مہارت:**
- Phi-4 نے AIME 2025 (Math Olympiad qualifier) پر 82.5% درستگی حاصل کی
- Phi-4-reasoning (14B) نے reasoning benchmarks پر DeepSeek-R1-Distill-70B (5x بڑا) کو پیچھے چھوڑ دیا
- Phi-4-mini-reasoning (3.8B) نے ریاضیاتی منطق کے کاموں میں دوگنے سائز کے ماڈلز کا مقابلہ کیا

**موثریت کی کامیابیاں:**
- Phi-3-Silica نے صرف 1.5W پاور کے ساتھ 650 ٹوکن فی سیکنڈ حاصل کیے
- Phi-4-mini (3.8B) نے بہت بڑے ماڈلز کے برابر کارکردگی حاصل کی

**بینچ مارک کارکردگی:**
- **MMLU (Massive Multitask Language Understanding)**: 57 تعلیمی مضامین میں مسابقتی کارکردگی
- **HumanEval**: کوڈ جنریشن کی مضبوط صلاحیتیں، خاص طور پر Python میں
- **MGSM**: کثیر لسانی گریڈ اسکول ریاضی کے مسائل حل کرنا
- **DROP**: پیچیدہ تفہیم اور منطق کے کام
- **SimpleQA**: حقائق پر مبنی جوابات کی درستگی

### 📊 ماڈل موازنہ میٹرکس

| ماڈل | پیرامیٹرز | کانٹیکسٹ لمبائی | اہم طاقتیں | بہترین استعمال کے کیسز |
|-------|------------|----------------|---------------|----------------|
| **Phi-3-mini** | 3.8B | 4K/128K | عمومی موثریت | موبائل ایپس، بنیادی چیٹ بوٹس |
| **Phi-3.5-mini** | 3.8B | 128K | کثیر لسانی حمایت | بین الاقوامی ایپلیکیشنز |
| **Phi-4-mini** | 3.8B | 128K | بہتر منطق، فنکشن کالنگ | کاروباری خودکار نظام |
| **Phi-4-mini-reasoning** | 3.8B | 128K | ریاضیاتی منطق | تعلیمی پلیٹ فارمز |
| **Phi-4** | 14B | 32K | پیچیدہ منطق | تحقیق، اعلیٰ تجزیہ |
| **Phi-4-reasoning** | 14B | 32K/64K | کثیر مرحلہ منطق | سائنسی کمپیوٹنگ |
| **Phi-4-reasoning-plus** | 14B | 32K | زیادہ سے زیادہ درستگی منطق | اہم فیصلہ سازی |
| **Phi-4-multimodal** | 5.6B | متغیر | تقریر، وژن، متن | ملٹی میڈیا ایپلیکیشنز |

## ماڈل انتخاب گائیڈ

### بنیادی ایپلیکیشنز کے لیے
- **Phi-3-mini**: سادہ متن جنریشن، بنیادی سوال و جواب، فوری جوابات
- **Phi-4-mini**: بہتر منطق کے ساتھ فنکشن کالنگ کی صلاحیتیں

### ریاضیاتی اور منطق کے کاموں کے لیے
- **Phi-4**: پیچیدہ ریاضیاتی مسئلہ حل کرنا اور منطق
- **Phi-4-reasoning**: کثیر مرحلہ منطق کے ساتھ تفصیلی وضاحتیں
- **Phi-4-reasoning-plus**: اہم منطق کے لیے زیادہ سے زیادہ درستگی
- **Phi-4-mini-reasoning**: وسائل محدود ماحول کے لیے مؤثر ریاضیاتی منطق

### ملٹی موڈل ایپلیکیشنز کے لیے
- **Phi-3-vision**: تصویر اور متن پروسیسنگ کے امتزاج
- **Phi-4-multimodal**: جامع تقریر، وژن، اور متن کی صلاحیتیں

### انٹرپرائز تعیناتی کے لیے
- **Phi-3-medium**: کاروباری ایپلیکیشنز کے لیے اعلیٰ زبان کی تفہیم
- **Phi-3-Silica**: مخصوص ہارڈویئر پلیٹ فارمز کے لیے بہتر

## تعیناتی پلیٹ فارمز اور رسائی

### کلاؤڈ پلیٹ فارمز
- **Azure AI Foundry**: مکمل خصوصیات کے ساتھ تعیناتی اور انٹرپرائز ٹولز
- **Hugging Face**: اوپن سورس ماڈل ریپوزٹری اور کمیونٹی وسائل
- **NVIDIA API Catalog**: مائیکرو سروس تعیناتی کے اختیارات

### مقامی ترقیاتی فریم ورک
- **Ollama**: مقامی ماڈل تعیناتی کے لیے ہلکا فریم ورک
- **ONNX Runtime**: مختلف ہارڈویئر کنفیگریشنز کے لیے بہتر  
- **DirectML**: ونڈوز کے لیے بہتر کارکردگی
- **llama.cpp**: کراس پلیٹ فارم انفرنس انجن

### سیکھنے کے وسائل
- **Phi Portal**: Microsoft Phi کی آفیشل دستاویزات کا مرکز
- **Phi Cookbook**: جامع مثالیں اور ٹیوٹوریلز
- **Technical Reports**: arxiv پر تفصیلی تحقیقی مقالے
- **Community Spaces**: Hugging Face کے انٹرایکٹو ڈیموز

### Phi ماڈلز کے ساتھ آغاز

#### ترقیاتی پلیٹ فارمز
1. **Azure AI Foundry**: سادہ مقامی CLI اور ماڈل مینجمنٹ۔
2. **Hugging Face Transformers**: مقامی تجربات کے لیے جلدی آغاز
3. **Ollama**: ٹیسٹنگ کے لیے سادہ مقامی تعیناتی

#### سیکھنے کا راستہ
1. **بنیادی تصورات کو سمجھیں**: بنیادی ڈیزائن اصولوں کا مطالعہ کریں
2. **مختلف ورژنز کے ساتھ تجربہ کریں**: مختلف Phi ماڈلز آزمائیں تاکہ صلاحیتوں کو سمجھ سکیں
3. **عملی نفاذ کریں**: ماڈلز کو ٹیسٹ ماحول میں تعینات کریں
4. **تعیناتی کو وسعت دیں**: کامیاب پائلٹس کی بنیاد پر استعمال کو بتدریج بڑھائیں

#### بہترین طریقے
- **چھوٹے سے شروع کریں**: ابتدائی ترقی کے لیے Phi-mini ماڈلز سے آغاز کریں
- **پرامپٹس کو بہتر بنائیں**: بہترین نتائج کے لیے مناسب چیٹ فارمیٹنگ استعمال کریں
- **کارکردگی کی نگرانی کریں**: انفرنس کی رفتار اور درستگی کے میٹرکس کو ٹریک کریں
- **ہارڈویئر پر غور کریں**: دستیاب کمپیوٹیشنل وسائل کے مطابق ماڈل سائز کا انتخاب کریں

## نتیجہ

Microsoft Phi ماڈل خاندان AI ماڈل ڈیزائن کے لیے ایک انقلابی نقطہ نظر کی نمائندگی کرتا ہے، یہ ظاہر کرتے ہوئے کہ چھوٹے، زیادہ مؤثر ماڈلز مختلف کاموں میں شاندار کارکردگی حاصل کر سکتے ہیں۔ اعلیٰ معیار کے تربیتی ڈیٹا اور آرکیٹیکچرل اصلاحات پر توجہ مرکوز کرتے ہوئے، Phi خاندان روایتی بڑے زبان ماڈلز کے مقابلے میں نمایاں طور پر کم کمپیوٹیشنل ضروریات کے ساتھ غیر معمولی صلاحیتیں فراہم کرتا ہے۔

## کلیدی سیکھنے کے مقاصد

1. Microsoft کے Phi ماڈل خاندان کی ڈیزائن فلسفہ اور ارتقاء کو سمجھیں، Phi-1 سے Phi-4 تک
2. کلیدی جدتوں کی شناخت کریں، بشمول "ٹیکسٹ بک کوالٹی" تربیت اور آرکیٹیکچرل اصلاحات
3. مختلف تعیناتی منظرناموں میں مختلف Phi ورژنز کے فوائد اور حدود کو پہچانیں
4. مخصوص استعمال کے کیسز اور ہارڈویئر کی حدود کے لیے مناسب Phi ماڈلز کا انتخاب کریں
5. وسائل محدود آلات پر Phi ماڈلز کی تعیناتی کے لیے اصلاحی تکنیکوں کو نافذ کریں
6. روایتی بڑے زبان ماڈلز کے مقابلے میں Phi ماڈل خاندان کے آرکیٹیکچرل فوائد کی وضاحت کریں
7. مخصوص ایپلیکیشن ضروریات اور ہارڈویئر کی حدود کی بنیاد پر مناسب Phi ورژن کا انتخاب کریں
8. کلاؤڈ اور ایج تعیناتی منظرناموں میں بہتر کنفیگریشنز کے ساتھ Phi ماڈلز کو نافذ کریں
9. ہدف آلات پر Phi ماڈل کی کارکردگی کو بہتر بنانے کے لیے کوانٹائزیشن اور اصلاحی تکنیکوں کو نافذ کریں
10. Phi خاندان کے ماڈلز کے سائز، کارکردگی، اور صلاحیتوں کے درمیان تجارتی تعلقات کا جائزہ لیں

## آگے کیا ہے

- [02: Qwen Family Fundamentals](02.QwenFamily.md)

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔