<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-17T18:08:05+00:00",
  "source_file": "Module03/README.md",
  "language_code": "ur"
}
-->
# باب 03: چھوٹے زبان ماڈلز (SLMs) کی تعیناتی

یہ جامع باب چھوٹے زبان ماڈلز (SLMs) کی تعیناتی کے مکمل زندگی کے مراحل کو دریافت کرتا ہے، جس میں نظریاتی بنیادیں، عملی نفاذ کی حکمت عملیاں، اور پروڈکشن کے لیے تیار کنٹینرائزڈ حل شامل ہیں۔ یہ باب تین ترقی پسند حصوں میں تقسیم ہے جو قارئین کو بنیادی تصورات سے لے کر اعلیٰ درجے کی تعیناتی کے منظرناموں تک لے جاتے ہیں۔

## باب کی ساخت اور سیکھنے کا سفر

### **[حصہ 1: SLM اعلیٰ درجے کی تعلیم - بنیادیں اور اصلاح](./01.SLMAdvancedLearning.md)**
ابتدائی حصہ چھوٹے زبان ماڈلز کو سمجھنے کے لیے نظریاتی بنیادیں قائم کرتا ہے اور ایج AI تعیناتیوں میں ان کی اسٹریٹجک اہمیت کو اجاگر کرتا ہے۔ اس حصے میں شامل ہیں:

- **پیرامیٹر درجہ بندی کا فریم ورک**: Micro SLMs (100M-1.4B پیرامیٹرز) سے لے کر Medium SLMs (14B-30B پیرامیٹرز) تک SLM کی اقسام کا تفصیلی جائزہ، خاص طور پر ماڈلز جیسے Phi-4-mini-3.8B، Qwen3 سیریز، اور Google Gemma3، ہر ماڈل درجے کے لیے ہارڈویئر ضروریات اور میموری کے استعمال کا تجزیہ
- **اعلیٰ درجے کی اصلاح کی تکنیکیں**: Llama.cpp، Microsoft Olive، اور Apple MLX فریم ورک کے ذریعے کوانٹائزیشن کے طریقوں کا جامع احاطہ، جدید BitNET 1-bit کوانٹائزیشن کے ساتھ عملی کوڈ مثالیں جو کوانٹائزیشن پائپ لائنز اور بینچ مارکنگ کے نتائج دکھاتی ہیں
- **ماڈل حاصل کرنے کی حکمت عملیاں**: Hugging Face ایکو سسٹم اور Azure AI Foundry Model Catalog کا تفصیلی تجزیہ، انٹرپرائز گریڈ SLM تعیناتی کے لیے، کوڈ نمونے کے ساتھ پروگراماتی ماڈل ڈاؤن لوڈنگ، توثیق اور فارمیٹ تبدیلی
- **ڈویلپر APIs**: Python، C++، اور C# میں کوڈ مثالیں جو دکھاتی ہیں کہ ماڈلز کو کیسے لوڈ کریں، انفرینس کریں، اور PyTorch، TensorFlow، اور ONNX Runtime جیسے مشہور فریم ورک کے ساتھ انضمام کریں

یہ بنیادی حصہ آپریشنل کارکردگی، تعیناتی کی لچک، اور لاگت کی تاثیر کے درمیان توازن پر زور دیتا ہے جو SLMs کو ایج کمپیوٹنگ کے منظرناموں کے لیے مثالی بناتا ہے، عملی کوڈ مثالوں کے ساتھ جو ڈویلپرز اپنے پروجیکٹس میں براہ راست نافذ کر سکتے ہیں۔

### **[حصہ 2: مقامی ماحول میں تعیناتی - پرائیویسی فرسٹ حل](./02.DeployingSLMinLocalEnv.md)**
دوسرا حصہ نظریہ سے عملی نفاذ کی طرف منتقلی کرتا ہے، مقامی تعیناتی کی حکمت عملیوں پر توجہ مرکوز کرتا ہے جو ڈیٹا کی خودمختاری اور آپریشنل آزادی کو ترجیح دیتی ہیں۔ اہم شعبے شامل ہیں:

- **Ollama یونیورسل پلیٹ فارم**: کراس پلیٹ فارم تعیناتی کا جامع جائزہ، ڈویلپر دوستانہ ورک فلو، ماڈل لائف سائیکل مینجمنٹ، اور Modelfiles کے ذریعے حسب ضرورت، مکمل REST API انضمام کی مثالوں اور CLI آٹومیشن اسکرپٹس کے ساتھ
- **Microsoft Foundry Local**: انٹرپرائز گریڈ تعیناتی کے حل ONNX پر مبنی اصلاح، Windows ML انضمام، اور جامع حفاظتی خصوصیات کے ساتھ، C# اور Python کوڈ مثالوں کے ساتھ مقامی ایپلیکیشن انضمام کے لیے
- **تقابلی تجزیہ**: تکنیکی فن تعمیر، کارکردگی کی خصوصیات، اور استعمال کے کیس کی اصلاح کے رہنما اصولوں کا تفصیلی فریم ورک موازنہ، مختلف ہارڈویئر پر انفرینس کی رفتار اور میموری کے استعمال کا جائزہ لینے کے لیے بینچ مارک کوڈ کے ساتھ
- **API انضمام**: مقامی SLM تعیناتیوں کا استعمال کرتے ہوئے ویب سروسز، چیٹ ایپلیکیشنز، اور ڈیٹا پروسیسنگ پائپ لائنز بنانے کا طریقہ دکھانے والے نمونہ ایپلیکیشنز، Node.js، Python Flask/FastAPI، اور ASP.NET Core میں کوڈ مثالوں کے ساتھ
- **ٹیسٹنگ فریم ورک**: ماڈل کوالٹی اشورنس کے لیے خودکار ٹیسٹنگ کے طریقے، SLM نفاذ کے لیے یونٹ اور انضمام ٹیسٹ کی مثالوں کے ساتھ

یہ حصہ ان تنظیموں کے لیے عملی رہنمائی فراہم کرتا ہے جو اپنی تعیناتی کے ماحول پر مکمل کنٹرول برقرار رکھتے ہوئے پرائیویسی کو محفوظ رکھنے والے AI حل نافذ کرنا چاہتے ہیں، تیار کوڈ نمونوں کے ساتھ جو ڈویلپرز اپنی مخصوص ضروریات کے مطابق ڈھال سکتے ہیں۔

### **[حصہ 3: کنٹینرائزڈ کلاؤڈ تعیناتی - پروڈکشن اسکیل حل](./03.DeployingSLMinCloud.md)**
آخری حصہ اعلیٰ درجے کی کنٹینرائزڈ تعیناتی کی حکمت عملیوں میں اختتام پذیر ہوتا ہے، جس میں Microsoft کے Phi-4-mini-instruct کو بنیادی کیس اسٹڈی کے طور پر پیش کیا جاتا ہے۔ اس حصے میں شامل ہیں:

- **vLLM تعیناتی**: OpenAI کے موافق APIs، اعلیٰ GPU ایکسیلریشن، اور پروڈکشن گریڈ کنفیگریشن کے ساتھ اعلیٰ کارکردگی انفرینس کی اصلاح، مکمل Dockerfiles، Kubernetes manifests، اور کارکردگی کو بہتر بنانے کے پیرامیٹرز کے ساتھ
- **Ollama کنٹینر آرکیسٹریشن**: Docker Compose کے ساتھ تعیناتی ورک فلو کو آسان بنانا، ماڈل کی اصلاح کے مختلف ورژن، اور ویب UI انضمام، CI/CD پائپ لائن کی مثالوں کے ساتھ خودکار تعیناتی اور ٹیسٹنگ کے لیے
- **ONNX Runtime نفاذ**: Edge پر بہتر تعیناتی، جامع ماڈل تبدیلی، کوانٹائزیشن کی حکمت عملیاں، اور کراس پلیٹ فارم مطابقت، ماڈل کی اصلاح اور تعیناتی کے لیے تفصیلی کوڈ نمونوں کے ساتھ
- **مانیٹرنگ اور مشاہدہ**: SLM کارکردگی کی نگرانی کے لیے Prometheus/Grafana ڈیش بورڈز کے نفاذ، کسٹم میٹرکس، الرٹ کنفیگریشنز، اور لاگ ایگریگیشن کے ساتھ
- **لوڈ بیلنسنگ اور اسکیلنگ**: افقی اور عمودی اسکیلنگ کی حکمت عملیوں کی عملی مثالیں، CPU/GPU کے استعمال اور درخواست کے پیٹرنز کی بنیاد پر آٹو اسکیلنگ کنفیگریشنز کے ساتھ
- **سیکیورٹی ہارڈننگ**: کنٹینر سیکیورٹی کے بہترین طریقے، جیسے پرائیویلیج میں کمی، نیٹ ورک پالیسیز، اور API کیز اور ماڈل تک رسائی کے لیے سیکریٹس مینجمنٹ

ہر تعیناتی کا طریقہ مکمل کنفیگریشن کی مثالوں، ٹیسٹنگ کے طریقہ کار، پروڈکشن ریڈی چیک لسٹس، اور انفراسٹرکچر-ایز-کوڈ ٹیمپلیٹس کے ساتھ پیش کیا گیا ہے جو ڈویلپرز اپنی تعیناتی کے ورک فلو میں براہ راست لاگو کر سکتے ہیں۔

## اہم سیکھنے کے نتائج

اس باب کو مکمل کرنے کے بعد، قارئین درج ذیل مہارت حاصل کریں گے:

1. **اسٹریٹجک ماڈل کا انتخاب**: پیرامیٹر کی حدود کو سمجھنا اور وسائل کی پابندیوں اور کارکردگی کی ضروریات کی بنیاد پر مناسب SLMs کا انتخاب کرنا
2. **اصلاح کی مہارت**: مختلف فریم ورک کے ذریعے اعلیٰ درجے کی کوانٹائزیشن تکنیکوں کو نافذ کرنا تاکہ کارکردگی اور تاثیر کے درمیان بہترین توازن حاصل کیا جا سکے
3. **تعیناتی کی لچک**: تنظیمی ضروریات کی بنیاد پر مقامی پرائیویسی پر مبنی حل اور اسکیل ایبل کنٹینرائزڈ تعیناتیوں کے درمیان انتخاب کرنا
4. **پروڈکشن ریڈی نیس**: انٹرپرائز گریڈ SLM تعیناتیوں کے لیے مانیٹرنگ، سیکیورٹی، اور اسکیلنگ سسٹمز کو ترتیب دینا

## عملی توجہ اور حقیقی دنیا کی ایپلیکیشنز

باب پورے وقت ایک مضبوط عملی رجحان برقرار رکھتا ہے، جس میں شامل ہیں:

- **ہینڈز آن مثالیں**: مکمل کنفیگریشن فائلز، API ٹیسٹنگ کے طریقہ کار، اور تعیناتی اسکرپٹس
- **کارکردگی کی بینچ مارکنگ**: انفرینس کی رفتار، میموری کے استعمال، اور وسائل کی ضروریات کے تفصیلی موازنہ
- **سیکیورٹی کے تحفظات**: انٹرپرائز گریڈ سیکیورٹی کے طریقے، تعمیل کے فریم ورک، اور ڈیٹا کے تحفظ کی حکمت عملیاں
- **بہترین طریقے**: مانیٹرنگ، اسکیلنگ، اور دیکھ بھال کے لیے پروڈکشن سے ثابت شدہ رہنما اصول

## مستقبل کے لیے تیار نقطہ نظر

باب اختتامی بصیرت کے ساتھ ختم ہوتا ہے، جس میں ابھرتے ہوئے رجحانات شامل ہیں:

- بہتر کارکردگی کے تناسب کے ساتھ جدید ماڈل آرکیٹیکچرز
- خصوصی AI ایکسیلریٹرز کے ساتھ گہری ہارڈویئر انضمام
- معیاری اور انٹرآپریبلٹی کی طرف ایکو سسٹم کا ارتقاء
- پرائیویسی اور تعمیل کی ضروریات سے چلنے والے انٹرپرائز اپنانے کے نمونے

یہ جامع نقطہ نظر یقینی بناتا ہے کہ قارئین موجودہ SLM تعیناتی کے چیلنجز اور مستقبل کی تکنیکی ترقیات دونوں کو نیویگیٹ کرنے کے لیے اچھی طرح سے تیار ہیں، اور ایسے فیصلے کرتے ہیں جو ان کی مخصوص تنظیمی ضروریات اور پابندیوں کے مطابق ہوں۔

یہ باب فوری نفاذ کے لیے ایک عملی رہنما اور طویل مدتی AI تعیناتی کی منصوبہ بندی کے لیے ایک اسٹریٹجک وسیلہ کے طور پر کام کرتا ہے، قابلیت، تاثیر، اور آپریشنل عمدگی کے درمیان اہم توازن پر زور دیتا ہے جو کامیاب SLM تعیناتیوں کی وضاحت کرتا ہے۔

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔