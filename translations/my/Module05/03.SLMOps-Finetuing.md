<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-19T01:17:03+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "my"
}
-->
# အပိုင်း ၃: Fine-Tuning - မော်ဒယ်များကို အထူးလုပ်ငန်းများအတွက် Customize လုပ်ခြင်း

## အကြောင်းအရာများ
1. [Fine-Tuning အကြောင်းအကျဉ်း](../../../Module05)
2. [Fine-Tuning အရေးကြီးတဲ့အကြောင်း](../../../Module05)
3. [Fine-Tuning အမျိုးအစားများ](../../../Module05)
4. [Microsoft Olive ဖြင့် Fine-Tuning](../../../Module05)
5. [လက်တွေ့ နမူနာများ](../../../Module05)
6. [အကောင်းဆုံး လုပ်နည်းလမ်းများနှင့် လမ်းညွှန်ချက်များ](../../../Module05)
7. [အဆင့်မြင့်နည်းလမ်းများ](../../../Module05)
8. [အကဲဖြတ်ခြင်းနှင့် ကြည့်ရှုခြင်း](../../../Module05)
9. [ရိုးရိုးတွေ့ရတဲ့ စိန်ခေါ်မှုများနှင့် ဖြေရှင်းနည်းများ](../../../Module05)
10. [နိဂုံး](../../../Module05)

## Fine-Tuning အကြောင်းအကျဉ်း

**Fine-tuning** ဆိုတာ မော်ဒယ်တစ်ခုကို အထူးလုပ်ငန်းများအတွက် သို့မဟုတ် အထူး Dataset များနှင့်အတူ အလျင်အမြန် ပြင်ဆင်အသုံးပြုနိုင်စေတဲ့ အင်အားကြီးတဲ့ Machine Learning နည်းလမ်းတစ်ခုဖြစ်ပါတယ်။ မော်ဒယ်ကို အစမှ Training လုပ်ရန်မလိုဘဲ၊ Pre-trained မော်ဒယ်၏ ရှိပြီးသား အသိပညာကို အသုံးချပြီး သင့်ရဲ့ အထူးလိုအပ်ချက်အတွက် ပြင်ဆင်ပေးနိုင်ပါတယ်။

### Fine-Tuning ဆိုတာဘာလဲ?

Fine-tuning ဟာ **Transfer Learning** အမျိုးအစားတစ်ခုဖြစ်ပြီး:
- Pre-trained မော်ဒယ်တစ်ခုကို စတင်အသုံးပြုပြီး၊ အကြီးမားတဲ့ Dataset များမှ အထွေထွေ Pattern များကို သင်ယူထားသည်။
- သင့်ရဲ့ အထူး Dataset ကို အသုံးပြုပြီး မော်ဒယ်၏ Internal Parameters များကို ပြင်ဆင်သည်။
- ရှိပြီးသား အသိပညာကို ထိန်းသိမ်းထားပြီး၊ သင့်ရဲ့ လုပ်ငန်းအတွက် အထူးပြုစေသည်။

ဉပမာအားဖြင့် ကျွမ်းကျင်တဲ့ Chef တစ်ဦးကို အသစ်သော အစားအစာပုံစံကို သင်ပေးရသလိုပဲ - သူတို့မှာ အခြေခံချက်များကို နားလည်ပြီးသားဖြစ်ပေမယ့် အသစ်သော နည်းလမ်းများနှင့် အရသာများကို သင်ယူရန်လိုအပ်သည်။

### အဓိက အကျိုးကျေးဇူးများ

- **အချိန်သက်သာမှု**: အစမှ Training လုပ်ခြင်းထက် အလွန်မြန်ဆန်သည်
- **ဒေတာသက်သာမှု**: Dataset အနည်းငယ်သာလိုအပ်ပြီး ကောင်းမွန်သော Performance ရရှိနိုင်သည်
- **ကုန်ကျစရိတ်သက်သာမှု**: Computational Requirement အနည်းငယ်သာလိုအပ်သည်
- **ပိုမိုကောင်းမွန်သော Performance**: အစမှ Training လုပ်ခြင်းထက် ပိုမိုကောင်းမွန်သော ရလဒ်ရရှိနိုင်သည်
- **အရင်းအမြစ်များကို ထိရောက်စွာ အသုံးချခြင်း**: AI အင်အားကြီးများကို အသေးစားအဖွဲ့များနှင့် အဖွဲ့အစည်းများအတွက် ရရှိနိုင်စေသည်

## Fine-Tuning အရေးကြီးတဲ့အကြောင်း

### အမှန်တကယ် လုပ်ငန်းအသုံးချမှုများ

Fine-tuning ဟာ အမျိုးမျိုးသော အခြေအနေများတွင် အရေးကြီးပါတယ်:

**1. Domain Adaptation**
- ဆေးဘက် AI: အထွေထွေ Language Model များကို ဆေးဘက်အကြောင်းအရာများနှင့် Clinical Notes များအတွက် ပြင်ဆင်ခြင်း
- ဥပဒေနည်းပညာ: ဥပဒေစာရွက်များကို ခွဲခြမ်းစိတ်ဖြာခြင်းနှင့် စာချုပ်များကို ပြန်လည်သုံးသပ်ခြင်းအတွက် မော်ဒယ်များကို အထူးပြုခြင်း
- ဘဏ္ဍာရေးဝန်ဆောင်မှု: ဘဏ္ဍာရေးအစီရင်ခံစာများကို ခွဲခြမ်းစိတ်ဖြာခြင်းနှင့် အန္တရာယ်အကဲဖြတ်ခြင်းအတွက် မော်ဒယ်များကို Customize လုပ်ခြင်း

**2. Task Specialization**
- အကြောင်းအရာ ဖန်တီးခြင်း: အထူးရေးသားပုံစံများ သို့မဟုတ် အသံအလှအပများအတွက် Fine-Tuning
- ကုဒ် ဖန်တီးခြင်း: အထူး Programming Language များ သို့မဟုတ် Framework များအတွက် မော်ဒယ်များကို ပြင်ဆင်ခြင်း
- ဘာသာပြန်ခြင်း: အထူးဘာသာစကားစုံ သို့မဟုတ် နည်းပညာဆိုင်ရာအကြောင်းအရာများအတွက် Performance တိုးတက်စေခြင်း

**3. ကုမ္ပဏီအသုံးချမှုများ**
- ဖောက်သည်ဝန်ဆောင်မှု: ကုမ္ပဏီအထူး Terminology ကို နားလည်သော Chatbot များဖန်တီးခြင်း
- အတွင်းရေးရာစာရွက်စာတမ်းများ: အဖွဲ့အစည်းလုပ်ငန်းစဉ်များကို နားလည်သော AI အကူအညီများတည်ဆောက်ခြင်း
- စက်မှုလုပ်ငန်းအထူးပြုဖြေရှင်းနည်းများ: စက်မှုလုပ်ငန်းအထူး Jargon နှင့် Workflow များကို နားလည်သော မော်ဒယ်များဖွံ့ဖြိုးခြင်း

## Fine-Tuning အမျိုးအစားများ

### 1. Full Fine-Tuning (Instruction Fine-Tuning)

Full Fine-Tuning တွင် မော်ဒယ်၏ Parameter အားလုံးကို Training လုပ်စဉ်အတွင်း ပြင်ဆင်သည်။ ဒီနည်းလမ်း:
- အ flexibilty အများဆုံးနှင့် Performance အမြင့်ဆုံးကို ပေးစွမ်းနိုင်သည်
- Computational Resource အများကြီးလိုအပ်သည်
- မော်ဒယ်၏ Version အသစ်တစ်ခုကို ဖန်တီးပေးသည်
- Training Data အများကြီးနှင့် Computational Resource ရှိသောအခြေအနေများအတွက် အကောင်းဆုံးဖြစ်သည်

### 2. Parameter-Efficient Fine-Tuning (PEFT)

PEFT နည်းလမ်းများသည် Parameter အနည်းငယ်သာ Update လုပ်ပြီး Fine-Tuning ကို ပိုမိုထိရောက်စေသည်:

#### Low-Rank Adaptation (LoRA)
- ရှိပြီးသား Weight များတွင် Trainable Rank Decomposition Matrix များထည့်သွင်းသည်
- Trainable Parameter အရေအတွက်ကို အလွန်လျှော့ချနိုင်သည်
- Full Fine-Tuning နှင့် Performance အနီးစပ်ဆုံးကို ထိန်းသိမ်းထားနိုင်သည်
- အခြား Adaptation များအကြား အလွယ်တကူ ပြောင်းလဲနိုင်သည်

#### QLoRA (Quantized LoRA)
- LoRA ကို Quantization နည်းလမ်းများနှင့် ပေါင်းစပ်သည်
- Memory Requirement ကို ပိုမိုလျှော့ချနိုင်သည်
- Consumer Hardware ပေါ်တွင် မော်ဒယ်အကြီးစားများကို Fine-Tuning လုပ်နိုင်သည်
- Efficiency နှင့် Performance အကြား Balance လုပ်ပေးသည်

#### Adapters
- ရှိပြီးသား Layer များအကြား Neural Network အငယ်များထည့်သွင်းသည်
- Base Model ကို Freeze လုပ်ထားပြီး Targeted Fine-Tuning လုပ်နိုင်သည်
- မော်ဒယ်ကို Customize လုပ်ရန် Modular နည်းလမ်းကို ပေးစွမ်းသည်

### 3. Task-Specific Fine-Tuning

Downstream Task အထူးပြုမော်ဒယ်များကို ပြင်ဆင်ခြင်း:
- **Classification**: Categorization Task များအတွက် မော်ဒယ်များကို ပြင်ဆင်ခြင်း
- **Generation**: အကြောင်းအရာဖန်တီးခြင်းနှင့် Text Generation အတွက် Optimize လုပ်ခြင်း
- **Extraction**: အချက်အလက်ထုတ်ယူခြင်းနှင့် Named Entity Recognition အတွက် Fine-Tuning
- **Summarization**: စာရွက်စာတမ်းအကျဉ်းချုပ်ရေးသားခြင်းအတွက် မော်ဒယ်များကို အထူးပြုခြင်း

## Microsoft Olive ဖြင့် Fine-Tuning

Microsoft Olive သည် မော်ဒယ် Fine-Tuning လုပ်ငန်းစဉ်ကို လွယ်ကူစွာ ပြုလုပ်နိုင်စေပြီး Enterprise-Grade Feature များကို ပေးစွမ်းသော Model Optimization Toolkit တစ်ခုဖြစ်သည်။

### Microsoft Olive ဆိုတာဘာလဲ?

Microsoft Olive သည် Open-Source Model Optimization Tool တစ်ခုဖြစ်ပြီး:
- Hardware Target များအတွက် Fine-Tuning Workflow များကို လွယ်ကူစွာ ပြုလုပ်နိုင်စေသည်
- Llama, Phi, Qwen, Gemma စတဲ့ Model Architecture များအတွက် Built-in Support ပေးသည်
- Cloud နှင့် Local Deployment Option များကို ပေးသည်
- Azure ML နှင့် Microsoft AI Service များနှင့် အလွယ်တကူ ပေါင်းစည်းနိုင်သည်
- Automatic Optimization နှင့် Quantization ကို Support ပေးသည်

### အဓိက အင်္ဂါရပ်များ

- **Hardware-Aware Optimization**: CPU, GPU, NPU စတဲ့ Hardware များအတွက် မော်ဒယ်များကို အလိုအလျောက် Optimize လုပ်ပေးသည်
- **Multi-Format Support**: PyTorch, Hugging Face, ONNX Model များနှင့် အလုပ်လုပ်နိုင်သည်
- **Automated Workflows**: Manual Configuration နှင့် Trial-and-Error ကို လျှော့ချပေးသည်
- **Enterprise Integration**: Azure ML နှင့် Cloud Deployment များအတွက် Built-in Support ပေးသည်
- **Extensible Architecture**: Custom Optimization နည်းလမ်းများကို ထည့်သွင်းနိုင်သည်

### Installation နှင့် Setup

#### Basic Installation

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Optional Dependencies

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Installation ကို Verify လုပ်ပါ

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## လက်တွေ့ နမူနာများ

### နမူနာ ၁: Olive CLI ဖြင့် Basic Fine-Tuning

ဒီနမူနာမှာ Phrase Classification အတွက် Language Model တစ်ခုကို Fine-Tuning လုပ်ပုံကို ပြသထားသည်:

#### အဆင့် ၁: သင့် Environment ကို ပြင်ဆင်ပါ

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### အဆင့် ၂: မော်ဒယ်ကို Fine-Tune လုပ်ပါ

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### အဆင့် ၃: Deployment အတွက် Optimize လုပ်ပါ

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### နမူနာ ၂: Custom Dataset ဖြင့် Advanced Configuration

#### အဆင့် ၁: Custom Dataset ကို ပြင်ဆင်ပါ

Training Data ပါဝင်တဲ့ JSON ဖိုင်တစ်ခု ဖန်တီးပါ:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### အဆင့် ၂: Configuration ဖိုင်တစ်ခု ဖန်တီးပါ

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### အဆင့် ၃: Fine-Tuning ကို Execute လုပ်ပါ

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### နမူနာ ၃: Memory Efficiency အတွက် QLoRA Fine-Tuning

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## အကောင်းဆုံး လုပ်နည်းလမ်းများနှင့် လမ်းညွှန်ချက်များ

### Data Preparation

**1. Data Quality ကို ဦးစားပေးပါ**
- အရည်အသွေးမြင့်ပြီး Diverse ဖြစ်သော နမူနာများကို ဦးစားပေးပါ
- သင့်ရဲ့ Target Use Case ကို ကိုယ်စားပြုသော Data ကို သေချာစွာ ရွေးချယ်ပါ
- Data ကို စနစ်တကျ သန့်စင်ပြီး Preprocess လုပ်ပါ

**2. Data Format နှင့် Template**
- Training Example များအတွင်း Format တစ်မျိုးတည်းကို အသုံးပြုပါ
- သင့် Use Case ကို ကိုက်ညီသော Input-Output Template များကို ဖန်တီးပါ
- Instruction-Tuned Model များအတွက် သင့်လျော်သော Instruction Format များကို ထည့်သွင်းပါ

**3. Dataset Splitting**
- Data ၁၀-၂၀% ကို Validation အတွက် ထားပါ
- Train/Validation Split များအတွင်း Distribution တူညီမှုကို ထိန်းသိမ်းပါ
- Classification Task များအတွက် Stratified Sampling ကို စဉ်းစားပါ

### Training Configuration

**1. Learning Rate ရွေးချယ်မှု**
- Fine-Tuning အတွက် Learning Rate သေးငယ်များ (1e-5 မှ 1e-4) ဖြင့် စတင်ပါ
- Convergence ပိုမိုကောင်းစေရန် Learning Rate Scheduling ကို အသုံးပြုပါ
- Loss Curve များကို ကြည့်ရှုပြီး Rate များကို လိုက်လျောညီထွေ ပြင်ဆင်ပါ

**2. Batch Size Optimization**
- Memory ရှိနိုင်မှုနှင့် Batch Size ကို Balance လုပ်ပါ
- Gradient Accumulation ကို အသုံးပြုပြီး Effective Batch Size ကို ကြီးမားစေပါ
- Batch Size နှင့် Learning Rate အကြား ဆက်စပ်မှုကို စဉ်းစားပါ

**3. Training အချိန်**
- Validation Metrics ကို ကြည့်ရှုပြီး Overfitting မဖြစ်အောင် လုပ်ပါ
- Validation Performance Plateau ဖြစ်သောအခါ Early Stopping ကို အသုံးပြုပါ
- Recovery နှင့် Analysis အတွက် Checkpoint များကို Regular Save လုပ်ပါ

### Model Selection

**1. Base Model ရွေးချယ်မှု**
- Domain တူသော Pre-Trained Model များကို ရွေးချယ်ပါ
- Computational Constraint နှင့် Model Size ကို စဉ်းစားပါ
- Commercial Use အတွက် Licensing Requirement များကို စစ်ဆေးပါ

**2. Fine-Tuning Method ရွေးချယ်မှု**
- Resource Constraint Environment များအတွက် LoRA/QLoRA ကို အသုံးပြုပါ
- Maximum Performance အရေးကြီးသောအခါ Full Fine-Tuning ကို ရွေးချယ်ပါ
- Task များစွာအတွက် Adapter-Based နည်းလမ်းများကို စဉ်းစားပါ

### Resource Management

**1. Hardware Optimization**
- Model Size နှင့် Method ကိုက်ညီသော Hardware ကို ရွေးချယ်ပါ
- Gradient Checkpointing ဖြင့် GPU Memory ကို ထိရောက်စွာ အသုံးပြုပါ
- Model ကြီးမားသောအခါ Cloud-Based Solution များကို စဉ်းစားပါ

**2. Memory Management**
- Mixed Precision Training ကို အသုံးပြုပါ
- Memory Constraint များအတွက် Gradient Accumulation ကို အသုံးပြုပါ
- Training အတွင်း GPU Memory Usage ကို ကြည့်ရှုပါ

## အဆင့်မြင့်နည်းလမ်းများ

### Multi-Adapter Training

Base Model ကို မျှဝေထားပြီး Task များအတွက် Adapter များစွာကို Training လုပ်ပါ:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparameter Optimization

Systematic Hyperparameter Tuning ကို အကောင်အထည်ဖော်ပါ:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Custom Loss Functions

Domain-Specific Loss Function များကို အကောင်အထည်ဖော်ပါ:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## အကဲဖြတ်ခြင်းနှင့် ကြည့်ရှုခြင်း

### Metrics နှင့် Evaluation

**1. Standard Metrics**
- **Accuracy**: Classification Task များအတွက် စုစုပေါင်း မှန်ကန်မှု
- **Perplexity**: Language Modeling Quality Measure
- **BLEU/ROUGE**: Text Generation နှင့် Summarization Quality
- **F1 Score**: Classification အတွက် Precision နှင့် Recall ကို Balance လုပ်ထားသော Measure

**2. Domain-Specific Metrics**
- **Task-Specific Benchmarks**: သင့် Domain အတွက် Established Benchmark များကို အသုံးပြုပါ
- **Human Evaluation**: Subjective Task များအတွက် လူသားအကဲဖြတ်မှုကို ထည့်သွင်းပါ
- **Business Metrics**: လုပ်ငန်းရည်မှန်းချက်များနှင့် ကိုက်ညီမှု

**3. Evaluation Setup**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Training Progress ကို ကြည့်ရှုခြင်း

**1. Loss Tracking**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validation Monitoring**
- Training Loss နှင့်အတူ Validation Loss ကို ကြည့်ရှုပါ
- Overfitting လက္ခဏာများ (Training Loss လျော့နည်းပြီး Validation Loss တိုးလာခြင်း) ကို စောင့်ကြည့်ပါ
- Validation Metrics အပေါ်မူတည်ပြီး Early Stopping ကို အသုံးပြုပါ

**3. Resource Monitoring**
- GPU/CPU Utilization ကို စောင့်ကြည့်ပါ
- Memory Usage Pattern များကို ကြည့်ရှုပါ
- Training Speed နှင့် Throughput ကို စောင့်ကြည့်ပါ

## ရိုးရိုးတွေ့ရတဲ့ စိန်ခေါ်မှုများနှင့် ဖြေရှင်းနည်းများ

### စိန်ခေါ်မှု ၁: Overfitting

**Symptoms:**
- Training Loss လျော့နည်းသော်လည်း Validation Loss တိုးလာခြင်း
- Training နှင့် Validation Performance အကြား Gap ကြီးခြင်း
- Data အသစ်များအပေါ် Generalization မကောင်းခြင်း

**Solutions:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

---

**အကြောင်းကြားချက်**:  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှုအတွက် ကြိုးစားနေပါသော်လည်း၊ အလိုအလျောက် ဘာသာပြန်မှုများတွင် အမှားများ သို့မဟုတ် မတိကျမှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းစာရွက်စာတမ်းကို ၎င်း၏ မူလဘာသာစကားဖြင့် အာဏာတရ အရင်းအမြစ်အဖြစ် ရှုပါရန် အကြံပြုပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်များမှ ပရော်ဖက်ရှင်နယ် ဘာသာပြန်မှုကို အကြံပြုပါသည်။ ဤဘာသာပြန်မှုကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာသော အလွဲအလွတ်များ သို့မဟုတ် အနားလွဲမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။