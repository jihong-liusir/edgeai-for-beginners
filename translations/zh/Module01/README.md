<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-07-22T02:59:27+00:00",
  "source_file": "Module01/README.md",
  "language_code": "zh"
}
-->
# 第01章：为边缘设备转型部署AI

EdgeAI（边缘人工智能）代表了一种人工智能部署的范式转变，将AI能力从基于云的处理转移到本地边缘设备。本章将探讨定义这一变革性AI实施方法的基本概念、关键技术和实际应用。

## 模块结构

### [第1节：EdgeAI基础](./01.EdgeAIFundamentals.md)
本节通过对比传统的云端AI与边缘AI部署模型，奠定了基础。我们将探讨关键的支持技术，包括模型量化、压缩优化以及克服边缘设备计算限制的小型语言模型（SLMs）。讨论重点在于这些创新如何提供更高的隐私保护、超低延迟以及强大的离线处理能力。

### [第2节：真实案例研究](./02.RealWorldCaseStudies.md)
通过微软的Phi和Mu模型生态系统以及日本航空的AI报告系统等具体案例，本节展示了EdgeAI在不同行业中的成功实施。这些案例验证了SLMs在特定任务中的卓越表现，并说明了边缘部署策略的实际优势。

### [第3节：实践实施指南](./03.PracticalImplementationGuide.md)
本节提供了全面的环境准备指南，涵盖了必要的开发工具、硬件需求、核心模型资源以及优化框架。它为学习者构建和部署自己的EdgeAI解决方案奠定了技术基础。

### [第4节：边缘AI部署硬件平台](./04.EdgeDeployment.md)
本节探讨了支持边缘AI部署的硬件生态系统，涵盖了来自Intel、Qualcomm、NVIDIA以及Windows AI PC的平台。内容包括硬件能力的详细比较、平台特定的优化技术以及在各种边缘计算场景中的实际部署考量。

## 关键学习成果

通过学习本章，读者将能够理解：
- 云端AI架构与边缘AI架构的基本区别
- 边缘部署的核心优化技术
- 真实应用案例及成功经验
- 实现EdgeAI解决方案的实践技能
- 硬件平台选择及平台特定的优化方法
- 性能基准测试及部署最佳实践

## 未来展望

EdgeAI作为一种关键趋势，正在塑造AI部署的未来。它为分布式、高效且注重隐私保护的AI系统铺平了道路，这些系统能够在无需云连接的情况下独立运行，同时保持高性能标准。

**免责声明**：  
本文档使用AI翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。应以原始语言的文档作为权威来源。对于关键信息，建议使用专业人工翻译。我们不对因使用此翻译而产生的任何误解或误读承担责任。