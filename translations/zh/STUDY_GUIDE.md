<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-15T16:36:28+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "zh"
}
-->
# 初学者的EdgeAI学习路径与学习计划

### 集中学习路径（1周）

| 天数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1天 | 模块1：EdgeAI基础知识 | 3小时 |
| 第2天 | 模块2：SLM基础 | 3小时 |
| 第3天 | 模块3：SLM部署 | 2小时 |
| 第4-5天 | 模块4：模型优化（6种框架） | 4小时 |
| 第6天 | 模块5：SLMOps | 3小时 |
| 第7天 | 模块6-7：AI代理与开发工具 | 5小时 |

### 集中学习路径（2周）

| 天数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1-2天 | 模块1：EdgeAI基础知识 | 3小时 |
| 第3-4天 | 模块2：SLM基础 | 3小时 |
| 第5-6天 | 模块3：SLM部署 | 2小时 |
| 第7-8天 | 模块4：模型优化 | 4小时 |
| 第9-10天 | 模块5：SLMOps | 3小时 |
| 第11-12天 | 模块6：AI代理 | 2小时 |
| 第13-14天 | 模块7：开发工具 | 3小时 |

### 兼职学习（4周）

| 周数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1周 | 模块1-2：基础知识与SLM基础 | 6小时 |
| 第2周 | 模块3-4：部署与优化 | 6小时 |
| 第3周 | 模块5-6：SLMOps与AI代理 | 5小时 |
| 第4周 | 模块7：开发工具与集成 | 3小时 |

| 天数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1-2天 | 模块1：EdgeAI基础知识 | 3小时 |
| 第3-4天 | 模块2：SLM基础 | 3小时 |
| 第5-6天 | 模块3：SLM部署 | 2小时 |
| 第7-8天 | 模块4：模型优化 | 4小时 |
| 第9-10天 | 模块5：SLMOps | 3小时 |
| 第11-12天 | 模块6：SLM代理系统 | 2小时 |
| 第13-14天 | 模块7：EdgeAI实施示例 | 2小时 |

| 模块 | 完成日期 | 花费时间 | 关键收获 |
|--------|----------------|-------------|--------------|
| 模块1：EdgeAI基础知识 | | | |
| 模块2：SLM基础 | | | |
| 模块3：SLM部署 | | | |
| 模块4：模型优化（6种框架） | | | |
| 模块5：SLMOps | | | |
| 模块6：SLM代理系统 | | | |
| 模块7：EdgeAI实施示例 | | | |
| 实践练习 | | | |
| 小型项目 | | | |

### 兼职学习（4周）

| 周数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1周 | 模块1-2：基础知识与SLM基础 | 6小时 |
| 第2周 | 模块3-4：部署与优化 | 6小时 |
| 第3周 | 模块5-6：SLMOps与AI代理 | 5小时 |
| 第4周 | 模块7：开发工具与集成 | 3小时 |

## 简介

欢迎使用《初学者的EdgeAI学习指南》！本文件旨在帮助您有效地学习课程内容并最大化您的学习体验。它提供了结构化的学习路径、建议的学习计划、关键概念摘要以及补充资源，以加深您对EdgeAI技术的理解。

这是一个简洁的20小时课程，能够以高效的方式传授EdgeAI的核心知识，非常适合希望快速掌握这一新兴领域实用技能的忙碌专业人士和学生。

## 课程概览

本课程分为七个全面的模块：

1. **EdgeAI基础与转型** - 理解核心概念与技术变革
2. **小型语言模型（SLM）基础** - 探索各种SLM家族及其架构
3. **小型语言模型部署** - 实施实际部署策略
4. **模型格式转换与量化** - 使用包括OpenVINO在内的6种框架进行高级优化
5. **SLMOps - 小型语言模型操作** - 生产生命周期管理与部署
6. **SLM代理系统** - AI代理、函数调用与模型上下文协议
7. **EdgeAI实施示例** - AI工具包、Windows开发与平台特定实现

## 如何使用本学习指南

- **循序渐进学习**：按顺序学习模块以获得最连贯的学习体验
- **知识检查点**：在每个部分后使用自我评估问题
- **实践练习**：完成建议的练习以巩固理论概念
- **补充资源**：探索您最感兴趣的主题的额外材料

## 学习计划建议

### 集中学习路径（1周）

| 天数 | 学习重点 | 预计时长 |
|------|-------|-----------------|
| 第1-2天 | 模块1：EdgeAI基础知识 | 6小时 |
| 第3-4天 | 模块2：SLM基础 | 8小时 |
| 第5-6天 | 模块3：SLM部署 | 6小时 |

### 兼职学习（3周）

| 周数 | 学习重点 | 预计时长 |
|------|-------|-----------------|
| 第1周 | 模块1：EdgeAI基础知识 | 6-7小时 |
| 第2周 | 模块2：SLM基础 | 7-8小时 |
| 第3周 | 模块3：SLM部署 | 5-6小时 |

## 模块1：EdgeAI基础与转型

### 关键学习目标

- 理解基于云的AI与基于边缘的AI的区别
- 掌握资源受限环境的核心优化技术
- 分析EdgeAI技术的实际应用
- 为EdgeAI项目设置开发环境

### 学习重点领域

#### 第1节：EdgeAI基础知识
- **重点概念**：
  - 边缘计算与云计算范式
  - 模型量化技术
  - 硬件加速选项（NPU、GPU、CPU）
  - 隐私与安全优势

- **补充材料**：
  - [TensorFlow Lite文档](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse文档](https://docs.edgeimpulse.com)

#### 第2节：实际案例研究
- **重点概念**：
  - Microsoft Phi & Mu模型生态系统
  - 各行业的实际应用
  - 部署注意事项

#### 第3节：实践实施指南
- **重点概念**：
  - 开发环境设置
  - 量化与优化工具
  - EdgeAI实施的评估方法

#### 第4节：边缘部署硬件
- **重点概念**：
  - 硬件平台比较
  - 针对特定硬件的优化策略
  - 部署注意事项

### 自我评估问题

1. 比较基于云的AI与基于边缘的AI实现。
2. 解释三种优化模型用于边缘部署的关键技术。
3. 在边缘运行AI模型的主要优势是什么？
4. 描述量化模型的过程及其对性能的影响。
5. 解释不同硬件加速器（NPU、GPU、CPU）如何影响EdgeAI部署。

### 实践练习

1. **快速环境设置**：配置一个包含基本软件包的最小开发环境（30分钟）
2. **模型探索**：下载并检查一个预训练的小型语言模型（1小时）
3. **基础量化**：尝试对一个小型模型进行简单量化（1小时）

## 模块2：小型语言模型基础

### 关键学习目标

- 理解不同SLM家族的架构原理
- 比较不同参数规模模型的能力
- 根据效率、能力和部署需求评估模型
- 识别不同模型家族的适用场景

### 学习重点领域

#### 第1节：Microsoft Phi模型家族
- **重点概念**：
  - 设计理念演变
  - 以效率为先的架构
  - 专业化能力

#### 第2节：Qwen家族
- **重点概念**：
  - 开源贡献
  - 可扩展部署选项
  - 高级推理架构

#### 第3节：Gemma家族
- **重点概念**：
  - 以研究为驱动的创新
  - 多模态能力
  - 移动优化

#### 第4节：BitNET家族
- **重点概念**：
  - 1位量化技术
  - 推理优化框架
  - 可持续性考虑

#### 第5节：Microsoft Mu模型
- **重点概念**：
  - 设备优先架构
  - 与Windows的系统集成
  - 隐私保护操作

#### 第6节：Phi-Silica
- **重点概念**：
  - 针对NPU优化的架构
  - 性能指标
  - 开发者集成

### 自我评估问题

1. 比较Phi和Qwen模型家族的架构方法。
2. 解释BitNET的量化技术与传统量化的不同之处。
3. Mu模型在Windows集成方面的独特优势是什么？
4. 描述Phi-Silica如何利用NPU硬件进行性能优化。
5. 对于一个有限连接的移动应用，哪个模型家族最适合？为什么？

### 实践练习

1. **模型比较**：快速对比两个不同的SLM模型（1小时）
2. **简单文本生成**：使用一个小型模型实现基本文本生成（1小时）
3. **快速优化**：应用一种优化技术以提高推理速度（1小时）

## 模块3：小型语言模型部署

### 关键学习目标

- 根据部署限制选择合适的模型
- 掌握各种部署场景的优化技术
- 在本地和云环境中实施SLM
- 为EdgeAI应用设计生产级配置

### 学习重点领域

#### 第1节：SLM高级学习
- **重点概念**：
  - 参数分类框架
  - 高级优化技术
  - 模型获取策略

#### 第2节：本地环境部署
- **重点概念**：
  - Ollama平台部署
  - Microsoft Foundry本地解决方案
  - 框架比较分析

#### 第3节：容器化云部署
- **重点概念**：
  - vLLM高性能推理
  - 容器编排
  - ONNX Runtime实施

### 自我评估问题

1. 在选择本地部署与云部署时应考虑哪些因素？
2. 比较Ollama和Microsoft Foundry Local作为部署选项。
3. 解释容器化对SLM部署的好处。
4. 边缘部署SLM的关键性能指标是什么？
5. 描述从模型选择到生产实施的完整部署工作流程。

### 实践练习

1. **基础本地部署**：使用Ollama部署一个简单的SLM（1小时）
2. **性能检查**：对已部署模型运行快速基准测试（30分钟）
3. **简单集成**：创建一个使用已部署模型的最小应用程序（1小时）

## 模块4：模型格式转换与量化

### 关键学习目标

- 掌握从1位到8位精度的高级量化技术
- 理解格式转换策略（GGUF、ONNX）
- 在六种框架（Llama.cpp、Olive、OpenVINO、MLX、工作流综合）中实施优化
- 为Intel、Apple及跨平台硬件的生产边缘环境部署优化模型

### 学习重点领域

#### 第1节：量化基础
- **重点概念**：
  - 精度分类框架
  - 性能与准确性权衡
  - 内存占用优化

#### 第2节：Llama.cpp实施
- **重点概念**：
  - 跨平台部署
  - GGUF格式优化
  - 硬件加速技术

#### 第3节：Microsoft Olive套件
- **重点概念**：
  - 硬件感知优化
  - 企业级部署
  - 自动化优化工作流

#### 第4节：OpenVINO工具包
- **重点概念**：
  - Intel硬件优化
  - 神经网络压缩框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI用于LLM部署

#### 第5节：Apple MLX框架
- **重点概念**：
  - Apple Silicon优化
  - 统一内存架构
  - LoRA微调能力

#### 第6节：EdgeAI开发工作流综合
- **重点概念**：
  - 统一工作流架构
- 框架选择决策树  
- 生产就绪验证  
- 面向未来的策略  

### 自我评估问题  

1. 比较不同精度级别（1位到8位）的量化策略。  
2. 解释GGUF格式在边缘部署中的优势。  
3. Microsoft Olive中的硬件感知优化如何提高部署效率？  
4. OpenVINO的NNCF在模型压缩方面的主要优势是什么？  
5. 描述Apple MLX如何利用统一内存架构进行优化。  
6. 工作流合成如何帮助选择最佳优化框架？  

### 实践练习  

1. **模型量化**：对模型应用不同的量化级别并比较结果（1小时）  
2. **OpenVINO优化**：使用NNCF压缩模型以适配Intel硬件（1小时）  
3. **框架比较**：在三个不同的优化框架中测试同一模型（1小时）  
4. **性能基准测试**：测量优化对推理速度和内存使用的影响（1小时）  

## 模块5：SLMOps - 小型语言模型操作  

### 关键学习目标  

- 理解SLMOps生命周期管理原则  
- 掌握用于边缘部署的蒸馏和微调技术  
- 实现带有监控的生产部署策略  
- 构建企业级SLM操作和维护工作流  

### 学习重点领域  

#### 第1节：SLMOps简介  
- **优先概念**：  
  - SLMOps在AI操作中的范式转变  
  - 成本效率和隐私优先架构  
  - 战略业务影响和竞争优势  

#### 第2节：模型蒸馏  
- **优先概念**：  
  - 知识转移技术  
  - 两阶段蒸馏过程的实施  
  - Azure ML蒸馏工作流  

#### 第3节：微调策略  
- **优先概念**：  
  - 参数高效微调（PEFT）  
  - LoRA和QLoRA高级方法  
  - 多适配器训练和超参数优化  

#### 第4节：生产部署  
- **优先概念**：  
  - 用于生产的模型转换和量化  
  - Foundry Local部署配置  
  - 性能基准测试和质量验证  

### 自我评估问题  

1. SLMOps与传统MLOps有何不同？  
2. 解释模型蒸馏在边缘部署中的优势。  
3. 在资源受限环境中微调SLM的关键考虑因素是什么？  
4. 描述一个完整的边缘AI应用生产部署管道。  

### 实践练习  

1. **基础蒸馏**：从一个较大的教师模型创建一个较小的模型（1小时）  
2. **微调实验**：针对特定领域微调一个模型（1小时）  
3. **部署管道**：设置一个基本的CI/CD管道用于模型部署（1小时）  

## 模块6：SLM代理系统 - AI代理和函数调用  

### 关键学习目标  

- 使用小型语言模型构建适用于边缘环境的智能AI代理  
- 实现具有系统化工作流的函数调用功能  
- 掌握模型上下文协议（MCP）集成以实现标准化工具交互  
- 创建复杂的代理系统，减少人工干预  

### 学习重点领域  

#### 第1节：AI代理与SLM基础  
- **优先概念**：  
  - 代理分类框架（反射型、基于模型、基于目标、学习型代理）  
  - SLM与LLM的权衡分析  
  - 边缘特定代理设计模式  
  - 代理的资源优化  

#### 第2节：小型语言模型中的函数调用  
- **优先概念**：  
  - 系统化工作流实施（意图检测、JSON输出、外部执行）  
  - 平台特定实现（Phi-4-mini、选定的Qwen模型、Microsoft Foundry Local）  
  - 高级示例（多代理协作、动态工具选择）  
  - 生产考虑（速率限制、审计日志、安全措施）  

#### 第3节：模型上下文协议（MCP）集成  
- **优先概念**：  
  - 协议架构和分层系统设计  
  - 多后端支持（Ollama用于开发，vLLM用于生产）  
  - 连接协议（STDIO和SSE模式）  
  - 实际应用（网页自动化、数据处理、API集成）  

### 自我评估问题  

1. 边缘AI代理的关键架构考虑因素是什么？  
2. 函数调用如何增强代理功能？  
3. 解释模型上下文协议在代理通信中的作用。  

### 实践练习  

1. **简单代理**：构建一个带有函数调用的基础AI代理（1小时）  
2. **MCP集成**：在代理应用中实现MCP（30分钟）  

## 模块7：EdgeAI实施示例  

### 关键学习目标  

- 掌握Visual Studio Code的AI工具包，用于全面的EdgeAI开发工作流  
- 熟悉Windows AI Foundry平台和NPU优化策略  
- 在多种硬件平台和部署场景中实施EdgeAI  
- 构建生产就绪的EdgeAI应用，结合平台特定优化  

### 学习重点领域  

#### 第1节：Visual Studio Code的AI工具包  
- **优先概念**：  
  - 在VS Code中构建全面的Edge AI开发环境  
  - 用于边缘部署的模型目录和发现  
  - 本地测试、优化和代理开发工作流  
  - 针对边缘场景的性能监控和评估  

#### 第2节：Windows EdgeAI开发指南  
- **优先概念**：  
  - Windows AI Foundry平台全面概述  
  - Phi Silica API用于高效NPU推理  
  - 计算机视觉API用于图像处理和OCR  
  - Foundry Local CLI用于本地开发和测试  

#### 第3节：平台特定实施  
- **优先概念**：  
  - NVIDIA Jetson Orin Nano部署（67 TOPS AI性能）  
  - 使用.NET MAUI和ONNX Runtime GenAI的移动应用  
  - Azure EdgeAI解决方案，结合云-边缘混合架构  
  - Windows ML优化，支持通用硬件  
  - Foundry Local应用，结合隐私优先的RAG实施  

### 自我评估问题  

1. AI工具包如何简化EdgeAI开发工作流？  
2. 比较不同硬件平台的部署策略。  
3. Windows AI Foundry在边缘开发中的优势是什么？  
4. NPU优化在现代边缘AI应用中的作用是什么？  
5. Phi Silica API如何利用NPU硬件进行性能优化？  
6. 比较本地部署与云部署在隐私敏感应用中的优势。  

### 实践练习  

1. **AI工具包设置**：配置AI工具包并优化一个模型（1小时）  
2. **Windows AI Foundry**：使用Phi Silica API构建一个简单的Windows AI应用（1小时）  
3. **跨平台部署**：在两个不同平台上部署同一个模型（1小时）  
4. **NPU优化**：使用Windows AI Foundry工具测试NPU性能（30分钟）  

## 时间分配指南  

为了帮助您充分利用20小时的课程时间，以下是建议的时间分配：  

| 活动 | 时间分配 | 描述 |  
|------|----------|------|  
| 阅读核心材料 | 9小时 | 专注于每个模块中的核心概念 |  
| 实践练习 | 6小时 | 关键技术的实际实施 |  
| 自我评估 | 2小时 | 通过问题和反思测试您的理解 |  
| 小型项目 | 3小时 | 将知识应用于小型实践实施 |  

### 按时间限制的重点领域  

**如果您只有10小时：**  
- 完成模块1、2和3（核心EdgeAI概念）  
- 每个模块至少完成一个实践练习  
- 专注于理解核心概念，而非实施细节  

**如果您可以投入完整的20小时：**  
- 完成所有七个模块  
- 执行每个模块的关键实践练习  
- 完成模块7中的一个小型项目  
- 探索至少2-3个补充资源  

**如果您有超过20小时：**  
- 详细完成所有模块和练习  
- 构建多个小型项目  
- 探索模块4中的高级优化技术  
- 实现模块5中的生产部署  

## 必备资源  

这些精心挑选的资源为您的有限学习时间提供最大价值：  

### 必读文档  
- [ONNX Runtime入门](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型优化工具  
- [Ollama快速入门](https://github.com/ollama/ollama#get-started) - 最快的本地部署SLM方法  
- [Microsoft Phi模型卡](https://huggingface.co/microsoft/phi-2) - 边缘优化模型的参考  
- [OpenVINO文档](https://docs.openvino.ai/2025/index.html) - Intel的全面优化工具包  
- [VS Code的AI工具包](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成的EdgeAI开发环境  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows特定的EdgeAI开发平台  

### 节省时间的工具  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型访问和部署  
- [Gradio](https://www.gradio.app/docs/interface) - 快速开发AI演示的UI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 简化的模型优化工具  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的CPU推理工具  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神经网络压缩框架  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型语言模型部署工具包  

## 进度跟踪模板  

使用此简化模板跟踪您在20小时课程中的学习进度：  

| 模块 | 完成日期 | 花费时间 | 关键收获 |  
|------|----------|----------|----------|  
| 模块1：EdgeAI基础 | | | |  
| 模块2：SLM基础 | | | |  
| 模块3：SLM部署 | | | |  
| 模块4：模型优化 | | | |  
| 模块5：SLMOps | | | |  
| 模块6：AI代理 | | | |  
| 模块7：开发工具 | | | |  
| 实践练习 | | | |  
| 小型项目 | | | |  

## 小型项目创意  

考虑完成以下项目之一以实践EdgeAI概念（每个设计为2-4小时）：  

### 初级项目（2-3小时）  
1. **边缘文本助手**：使用小型语言模型创建一个简单的离线文本补全工具  
2. **模型比较仪表盘**：构建一个基本的性能指标可视化工具，用于比较不同SLM  
3. **优化实验**：测量不同量化级别对同一基础模型的影响  

### 中级项目（3-4小时）  
4. **AI工具包工作流**：使用VS Code的AI工具包从头到尾优化并部署一个模型  
5. **Windows AI Foundry应用**：使用Phi Silica API和NPU优化创建一个Windows应用  
6. **跨平台部署**：在Windows（OpenVINO）和移动设备（.NET MAUI）上部署同一个优化模型  
7. **函数调用代理**：构建一个带有函数调用功能的AI代理，用于边缘场景  

### 高级集成项目（4-5小时）  
8. **OpenVINO优化管道**：使用NNCF和GenAI工具包实施完整的模型优化  
9. **SLMOps管道**：实施从训练到边缘部署的完整模型生命周期  
10. **多模型边缘系统**：在边缘硬件上部署多个协作的专业模型  
11. **MCP集成系统**：使用模型上下文协议构建一个工具交互的代理系统  

## 学习社区  

加入讨论并与其他学习者交流：  
- GitHub上的[EdgeAI for Beginners讨论区](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft技术社区](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 结论  

EdgeAI代表了人工智能实施的前沿，将强大的能力直接带到设备，同时解决隐私、延迟和连接性等关键问题。本课程通过20小时的学习，为您提供了开始使用EdgeAI技术所需的基本知识和实践技能。  

课程内容简洁明了，专注于最重要的概念，让您能够快速获得有价值的专业知识，而不会感到时间压力。请记住，即使是简单的实践示例，也能有效巩固您的学习成果。  

祝学习愉快！

---

**免责声明**：  
本文档使用AI翻译服务[Co-op Translator](https://github.com/Azure/co-op-translator)进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。原始语言的文档应被视为权威来源。对于关键信息，建议使用专业人工翻译。我们不对因使用此翻译而产生的任何误解或误读承担责任。