<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T11:26:19+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "zh"
}
-->
# 初学者的EdgeAI学习路径与学习计划

### 集中学习路径（1周）

| 天数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1天 | 模块1：EdgeAI基础知识 | 3小时 |
| 第2天 | 模块2：SLM基础 | 3小时 |
| 第3天 | 模块3：SLM部署 | 2小时 |
| 第4-5天 | 模块4：模型优化（6种框架） | 4小时 |
| 第6天 | 模块5：SLMOps | 3小时 |
| 第7天 | 模块6-7：AI代理与开发工具 | 5小时 |

### 集中学习路径（2周）

| 天数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1-2天 | 模块1：EdgeAI基础知识 | 3小时 |
| 第3-4天 | 模块2：SLM基础 | 3小时 |
| 第5-6天 | 模块3：SLM部署 | 2小时 |
| 第7-8天 | 模块4：模型优化 | 4小时 |
| 第9-10天 | 模块5：SLMOps | 3小时 |
| 第11-12天 | 模块6：AI代理 | 2小时 |
| 第13-14天 | 模块7：开发工具 | 3小时 |

### 兼职学习（4周）

| 周数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1周 | 模块1-2：基础知识与SLM基础 | 6小时 |
| 第2周 | 模块3-4：部署与优化 | 6小时 |
| 第3周 | 模块5-6：SLMOps与AI代理 | 5小时 |
| 第4周 | 模块7：开发工具与集成 | 3小时 |

| 天数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1-2天 | 模块1：EdgeAI基础知识 | 3小时 |
| 第3-4天 | 模块2：SLM基础 | 3小时 |
| 第5-6天 | 模块3：SLM部署 | 2小时 |
| 第7-8天 | 模块4：模型优化 | 4小时 |
| 第9-10天 | 模块5：SLMOps | 3小时 |
| 第11-12天 | 模块6：SLM代理系统 | 2小时 |
| 第13-14天 | 模块7：EdgeAI实施示例 | 2小时 |

| 模块 | 完成日期 | 花费时间 | 关键收获 |
|--------|----------------|-------------|--------------|
| 模块1：EdgeAI基础知识 | | | |
| 模块2：SLM基础 | | | |
| 模块3：SLM部署 | | | |
| 模块4：模型优化（6种框架） | | | |
| 模块5：SLMOps | | | |
| 模块6：SLM代理系统 | | | |
| 模块7：EdgeAI实施示例 | | | |
| 实践练习 | | | |
| 小型项目 | | | |

### 兼职学习（4周）

| 周数 | 学习重点 | 预计时长 |
|------|-------|------------------|
| 第1周 | 模块1-2：基础知识与SLM基础 | 6小时 |
| 第2周 | 模块3-4：部署与优化 | 6小时 |
| 第3周 | 模块5-6：SLMOps与AI代理 | 5小时 |
| 第4周 | 模块7：开发工具与集成 | 3小时 |

## 简介

欢迎使用《初学者的EdgeAI学习指南》！本指南旨在帮助您高效学习课程内容，最大化学习效果。它提供了结构化的学习路径、建议的学习计划、关键概念总结以及补充资源，以加深您对EdgeAI技术的理解。

这是一个简洁的20小时课程，专注于以时间高效的方式传授EdgeAI的核心知识，非常适合忙碌的专业人士和学生快速掌握这一新兴领域的实用技能。

## 课程概览

本课程分为七个全面的模块：

1. **EdgeAI基础知识与转型** - 理解核心概念与技术变革
2. **小型语言模型（SLM）基础** - 探索各种SLM家族及其架构
3. **小型语言模型部署** - 实施实际部署策略
4. **模型格式转换与量化** - 使用包括OpenVINO在内的6种框架进行高级优化
5. **SLMOps - 小型语言模型操作** - 生产生命周期管理与部署
6. **SLM代理系统** - AI代理、函数调用与模型上下文协议
7. **EdgeAI实施示例** - AI工具包、Windows开发与平台特定实现
8. **Microsoft Foundry Local – 完整开发工具包** - 本地优先开发与混合Azure集成（模块08）

## 如何使用本学习指南

- **循序渐进学习**：按顺序学习模块以获得最连贯的学习体验
- **知识检查点**：使用每节后的自我评估问题
- **实践练习**：完成建议的练习以巩固理论概念
- **补充资源**：探索您最感兴趣主题的额外材料

## 学习计划建议

### 集中学习路径（1周）

| 天数 | 学习重点 | 预计时长 |
|------|-------|-----------------|
| 第1-2天 | 模块1：EdgeAI基础知识 | 6小时 |
| 第3-4天 | 模块2：SLM基础 | 8小时 |
| 第5天 | 模块3：SLM部署 | 3小时 |
| 第6天 | 模块8：Foundry Local工具包 | 3小时 |

### 兼职学习（3周）

| 周数 | 学习重点 | 预计时长 |
|------|-------|-----------------|
| 第1周 | 模块1：EdgeAI基础知识 | 6-7小时 |
| 第2周 | 模块2：SLM基础 | 7-8小时 |
| 第3周 | 模块3：SLM部署（3小时）+ 模块8：Foundry Local工具包（2-3小时） | 5-6小时 |

## 模块1：EdgeAI基础知识与转型

### 关键学习目标

- 理解基于云的AI与基于边缘的AI的区别
- 掌握资源受限环境的核心优化技术
- 分析EdgeAI技术的实际应用案例
- 为EdgeAI项目设置开发环境

### 学习重点领域

#### 第1节：EdgeAI基础知识
- **重点概念**：
  - 边缘计算与云计算范式
  - 模型量化技术
  - 硬件加速选项（NPU、GPU、CPU）
  - 隐私与安全优势

- **补充材料**：
  - [TensorFlow Lite文档](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse文档](https://docs.edgeimpulse.com)

#### 第2节：实际案例研究
- **重点概念**：
  - Microsoft Phi & Mu模型生态系统
  - 各行业的实际应用
  - 部署注意事项

#### 第3节：实践实施指南
- **重点概念**：
  - 开发环境设置
  - 量化与优化工具
  - EdgeAI实施的评估方法

#### 第4节：边缘部署硬件
- **重点概念**：
  - 硬件平台比较
  - 针对特定硬件的优化策略
  - 部署注意事项

### 自我评估问题

1. 比较基于云的AI与基于边缘的AI实现。
2. 解释三种优化模型用于边缘部署的关键技术。
3. 在边缘运行AI模型的主要优势是什么？
4. 描述量化模型的过程及其对性能的影响。
5. 解释不同硬件加速器（NPU、GPU、CPU）如何影响EdgeAI部署。

### 实践练习

1. **快速环境设置**：配置一个包含基本软件包的最小开发环境（30分钟）
2. **模型探索**：下载并检查一个预训练的小型语言模型（1小时）
3. **基础量化**：尝试对一个小型模型进行简单量化（1小时）

## 模块2：小型语言模型基础

### 关键学习目标

- 理解不同SLM家族的架构原理
- 比较不同参数规模模型的能力
- 根据效率、能力和部署需求评估模型
- 识别不同模型家族的适用场景

### 学习重点领域

#### 第1节：Microsoft Phi模型家族
- **重点概念**：
  - 设计理念演变
  - 以效率为核心的架构
  - 专业化能力

#### 第2节：Qwen家族
- **重点概念**：
  - 开源贡献
  - 可扩展部署选项
  - 高级推理架构

#### 第3节：Gemma家族
- **重点概念**：
  - 以研究为驱动的创新
  - 多模态能力
  - 移动优化

#### 第4节：BitNET家族
- **重点概念**：
  - 1位量化技术
  - 推理优化框架
  - 可持续性考虑

#### 第5节：Microsoft Mu模型
- **重点概念**：
  - 设备优先架构
  - 与Windows的系统集成
  - 隐私保护操作

#### 第6节：Phi-Silica
- **重点概念**：
  - 针对NPU优化的架构
  - 性能指标
  - 开发者集成

### 自我评估问题

1. 比较Phi和Qwen模型家族的架构方法。
2. 解释BitNET的量化技术与传统量化的不同之处。
3. Mu模型在Windows集成方面的独特优势是什么？
4. 描述Phi-Silica如何利用NPU硬件进行性能优化。
5. 对于一个有限连接的移动应用，哪个模型家族最适合？为什么？

### 实践练习

1. **模型比较**：快速对两个不同SLM模型进行基准测试（1小时）
2. **简单文本生成**：使用一个小型模型实现基本的文本生成（1小时）
3. **快速优化**：应用一种优化技术以提高推理速度（1小时）

## 模块3：小型语言模型部署

### 关键学习目标

- 根据部署限制选择合适的模型
- 掌握各种部署场景的优化技术
- 在本地和云环境中实施SLM
- 为EdgeAI应用设计生产就绪的配置

### 学习重点领域

#### 第1节：SLM高级学习
- **重点概念**：
  - 参数分类框架
  - 高级优化技术
  - 模型获取策略

#### 第2节：本地环境部署
- **重点概念**：
  - Ollama平台部署
  - Microsoft Foundry本地解决方案
  - 框架比较分析

#### 第3节：容器化云部署
- **重点概念**：
  - vLLM高性能推理
  - 容器编排
  - ONNX Runtime实施

### 自我评估问题

1. 在选择本地部署与云部署时应考虑哪些因素？
2. 比较Ollama和Microsoft Foundry Local作为部署选项。
3. 解释容器化对SLM部署的好处。
4. 边缘部署SLM的关键性能指标是什么？
5. 描述从模型选择到生产实施的完整部署工作流程。

### 实践练习

1. **基础本地部署**：使用Ollama部署一个简单的SLM（1小时）
2. **性能检查**：对已部署的模型运行快速基准测试（30分钟）
3. **简单集成**：创建一个使用已部署模型的最小应用程序（1小时）

## 模块4：模型格式转换与量化

### 关键学习目标

- 掌握从1位到8位精度的高级量化技术
- 理解格式转换策略（GGUF、ONNX）
- 在六种框架中实施优化（Llama.cpp、Olive、OpenVINO、MLX、工作流合成）
- 为Intel、Apple及跨平台硬件的生产边缘环境部署优化模型

### 学习重点领域

#### 第1节：量化基础
- **重点概念**：
  - 精度分类框架
  - 性能与准确性权衡
  - 内存占用优化

#### 第2节：Llama.cpp实施
- **重点概念**：
  - 跨平台部署
  - GGUF格式优化
  - 硬件加速技术

#### 第3节：Microsoft Olive套件
- **重点概念**：
  - 硬件感知优化
  - 企业级部署
  - 自动化优化工作流

#### 第4节：OpenVINO工具包
- **重点概念**：
  - Intel硬件优化
  - 神经网络压缩框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI用于LLM部署

#### 第5节：Apple MLX框架
- **重点概念**:  
  - Apple Silicon优化  
  - 统一内存架构  
  - LoRA微调功能  

#### 第六节：边缘AI开发工作流程综合
- **重点概念**:  
  - 统一工作流程架构  
  - 框架选择决策树  
  - 生产准备验证  
  - 面向未来的策略  

### 自我评估问题

1. 比较不同精度级别（1位到8位）的量化策略。  
2. 解释GGUF格式在边缘部署中的优势。  
3. 硬件感知优化如何通过Microsoft Olive提高部署效率？  
4. OpenVINO的NNCF在模型压缩方面的主要优势是什么？  
5. Apple MLX如何利用统一内存架构进行优化？  
6. 工作流程综合如何帮助选择最佳优化框架？

### 实践练习

1. **模型量化**: 对模型应用不同的量化级别并比较结果（1小时）  
2. **OpenVINO优化**: 使用NNCF压缩模型以适配Intel硬件（1小时）  
3. **框架比较**: 在三个不同的优化框架中测试同一模型（1小时）  
4. **性能基准测试**: 测量优化对推理速度和内存使用的影响（1小时）  

## 模块5：SLMOps - 小型语言模型操作

### 关键学习目标

- 理解SLMOps生命周期管理原则  
- 掌握用于边缘部署的蒸馏和微调技术  
- 实施生产部署策略并进行监控  
- 构建企业级SLM操作和维护工作流程  

### 学习重点领域

#### 第一节：SLMOps简介
- **重点概念**:  
  - SLMOps在AI操作中的范式转变  
  - 成本效率和隐私优先架构  
  - 战略业务影响和竞争优势  

#### 第二节：模型蒸馏
- **重点概念**:  
  - 知识转移技术  
  - 两阶段蒸馏过程实施  
  - Azure ML蒸馏工作流程  

#### 第三节：微调策略
- **重点概念**:  
  - 参数高效微调（PEFT）  
  - LoRA和QLoRA高级方法  
  - 多适配器训练和超参数优化  

#### 第四节：生产部署
- **重点概念**:  
  - 模型转换和量化以适应生产需求  
  - Foundry Local部署配置  
  - 性能基准测试和质量验证  

### 自我评估问题

1. SLMOps与传统MLOps有何不同？  
2. 解释模型蒸馏在边缘部署中的优势。  
3. 在资源受限环境中微调SLM的关键考虑因素是什么？  
4. 描述一个完整的边缘AI应用生产部署管道。

### 实践练习

1. **基础蒸馏**: 从一个较大的教师模型创建一个较小的模型（1小时）  
2. **微调实验**: 针对特定领域微调一个模型（1小时）  
3. **部署管道**: 设置一个基本的CI/CD管道以进行模型部署（1小时）  

## 模块6：SLM代理系统 - AI代理和函数调用

### 关键学习目标

- 使用小型语言模型构建适用于边缘环境的智能AI代理  
- 实现具有系统化工作流程的函数调用功能  
- 掌握模型上下文协议（MCP）集成以实现标准化工具交互  
- 创建复杂的代理系统，减少人工干预  

### 学习重点领域

#### 第一节：AI代理和SLM基础
- **重点概念**:  
  - 代理分类框架（反射型、基于模型、基于目标、学习型代理）  
  - SLM与LLM的权衡分析  
  - 边缘特定代理设计模式  
  - 代理的资源优化  

#### 第二节：小型语言模型中的函数调用
- **重点概念**:  
  - 系统化工作流程实施（意图检测、JSON输出、外部执行）  
  - 平台特定实现（Phi-4-mini、选定的Qwen模型、Microsoft Foundry Local）  
  - 高级示例（多代理协作、动态工具选择）  
  - 生产考虑（速率限制、审计日志、安全措施）  

#### 第三节：模型上下文协议（MCP）集成
- **重点概念**:  
  - 协议架构和分层系统设计  
  - 多后端支持（Ollama用于开发，vLLM用于生产）  
  - 连接协议（STDIO和SSE模式）  
  - 实际应用（网页自动化、数据处理、API集成）  

### 自我评估问题

1. 边缘AI代理的关键架构考虑因素是什么？  
2. 函数调用如何增强代理功能？  
3. 解释模型上下文协议在代理通信中的作用。

### 实践练习

1. **简单代理**: 构建一个带有函数调用功能的基础AI代理（1小时）  
2. **MCP集成**: 在代理应用中实现MCP（30分钟）  

## 模块7：边缘AI实施示例

### 关键学习目标

- 掌握Visual Studio Code的AI工具包以实现全面的边缘AI开发工作流程  
- 熟悉Windows AI Foundry平台和NPU优化策略  
- 在多个硬件平台和部署场景中实施边缘AI  
- 构建生产就绪的边缘AI应用，结合平台特定优化  

### 学习重点领域

#### 第一节：Visual Studio Code的AI工具包
- **重点概念**:  
  - 在VS Code中构建全面的边缘AI开发环境  
  - 模型目录和边缘部署的发现功能  
  - 本地测试、优化和代理开发工作流程  
  - 针对边缘场景的性能监控和评估  

#### 第二节：Windows边缘AI开发指南
- **重点概念**:  
  - Windows AI Foundry平台全面概述  
  - Phi Silica API用于高效NPU推理  
  - 计算机视觉API用于图像处理和OCR  
  - Foundry Local CLI用于本地开发和测试  

#### 第三节：平台特定实施
- **重点概念**:  
  - NVIDIA Jetson Orin Nano部署（67 TOPS AI性能）  
  - 使用.NET MAUI和ONNX Runtime GenAI开发移动应用  
  - Azure EdgeAI解决方案结合云-边缘混合架构  
  - Windows ML优化，支持通用硬件  
  - Foundry Local应用结合隐私优先的RAG实施  

### 自我评估问题

1. AI工具包如何简化边缘AI开发工作流程？  
2. 比较不同硬件平台的部署策略。  
3. Windows AI Foundry在边缘开发中的优势是什么？  
4. NPU优化在现代边缘AI应用中的作用是什么？  
5. Phi Silica API如何利用NPU硬件进行性能优化？  
6. 比较本地部署与云部署在隐私敏感应用中的优势。

### 实践练习

1. **AI工具包设置**: 配置AI工具包并优化一个模型（1小时）  
2. **Windows AI Foundry**: 使用Phi Silica API构建一个简单的Windows AI应用（1小时）  
3. **跨平台部署**: 在两个不同平台上部署同一个模型（1小时）  
4. **NPU优化**: 使用Windows AI Foundry工具测试NPU性能（30分钟）  

## 模块8：Microsoft Foundry Local – 完整开发者工具包

### 关键学习目标

- 在Windows上安装和配置Foundry Local  
- 通过Foundry CLI本地运行、发现和管理模型  
- 与OpenAI兼容的REST和SDK客户端集成  
- 构建实用示例：Chainlit聊天、代理和模型路由器  
- 理解结合Azure AI Foundry的混合模式  

### 学习重点领域

- 安装和CLI基础知识（模型、服务、缓存）  
- SDK集成（OpenAI兼容客户端和Azure OpenAI）  
- 快速验证Open WebUI  
- 代理和函数调用模式  
- 模型即工具（路由器和注册表设计）  

### 自我评估问题

1. 如何发现本地端点并列出可用模型？  
2. Foundry Local REST与Azure OpenAI使用有何区别？  
3. 如何设计一个简单的路由器以选择模型作为工具？  
4. 哪些CLI类别与日常开发最相关？  
5. 如何在运行应用之前验证Foundry Local的准备情况？

### 实践练习

1. 安装/升级Foundry Local并本地运行`phi-4-mini`（30分钟）  
2. 调用`/v1/models`并通过REST运行一个简单的聊天（30分钟）  
3. 启动Chainlit应用示例并进行本地聊天（30分钟）  
4. 运行多代理协调器并检查输出（30分钟）  
5. 使用基于环境的覆盖尝试模型即工具路由器（30分钟）  

## 时间分配指南

为了帮助您充分利用20小时的课程时间线，以下是建议的时间分配：

| 活动 | 时间分配 | 描述 |
|------|----------|------|
| 阅读核心材料 | 9小时 | 专注于每个模块中的关键概念 |
| 实践练习 | 6小时 | 实现关键技术的实践操作 |
| 自我评估 | 2小时 | 通过问题和反思测试您的理解 |
| 小型项目 | 3小时 | 将知识应用于小型实践实施 |

### 根据时间限制的重点领域

**如果您只有10小时：**  
- 完成模块1、2和3（核心边缘AI概念）  
- 每个模块至少完成一个实践练习  
- 专注于理解核心概念而非实施细节  

**如果您可以投入完整的20小时：**  
- 完成所有七个模块  
- 执行每个模块的关键实践练习  
- 完成模块7中的一个小型项目  
- 探索至少2-3个补充资源  

**如果您有超过20小时：**  
- 详细完成所有模块和练习  
- 构建多个小型项目  
- 探索模块4中的高级优化技术  
- 实现模块5中的生产部署  

## 必备资源

以下精选资源为您的有限学习时间提供最大价值：

### 必读文档
- [ONNX Runtime入门](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型优化工具  
- [Ollama快速入门](https://github.com/ollama/ollama#get-started) - 最快的本地部署SLM方法  
- [Microsoft Phi模型卡](https://huggingface.co/microsoft/phi-2) - 边缘优化模型的参考  
- [OpenVINO文档](https://docs.openvino.ai/2025/index.html) - Intel的全面优化工具包  
- [VS Code的AI工具包](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成边缘AI开发环境  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows特定的边缘AI开发平台  

### 节省时间的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型访问和部署  
- [Gradio](https://www.gradio.app/docs/interface) - 快速开发AI演示的UI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 简化模型优化  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的CPU推理  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神经网络压缩框架  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型语言模型部署工具包  

## 进度跟踪模板

使用此简化模板跟踪您在20小时课程中的学习进度：

| 模块 | 完成日期 | 花费时间 | 关键收获 |
|------|----------|----------|----------|
| 模块1：边缘AI基础 | | | |
| 模块2：SLM基础 | | | |
| 模块3：SLM部署 | | | |
| 模块4：模型优化 | | | |
| 模块5：SLMOps | | | |
| 模块6：AI代理 | | | |
| 模块7：开发工具 | | | |
| 模块8：Foundry Local工具包 | | | |
| 实践练习 | | | |
| 小型项目 | | | |

## 小型项目创意

考虑完成以下项目之一以实践边缘AI概念（每个设计为2-4小时完成）：

### 初级项目（每个2-3小时）
1. **边缘文本助手**: 使用小型语言模型创建一个简单的离线文本补全工具  
2. **模型比较仪表盘**: 构建一个基本的性能指标可视化工具，用于比较不同SLM  
3. **优化实验**: 测量不同量化级别对同一基础模型的影响  

### 中级项目（每个3-4小时）
4. **AI工具包工作流程**: 使用VS Code AI工具包从头到尾优化并部署一个模型  
5. **Windows AI Foundry应用**: 使用Phi Silica API和NPU优化创建一个Windows应用  
6. **跨平台部署**: 在Windows（OpenVINO）和移动设备（.NET MAUI）上部署同一个优化模型  
7. **函数调用代理**: 构建一个具有函数调用功能的AI代理以适应边缘场景  

### 高级集成项目（每个4-5小时）
8. **OpenVINO优化流程**：使用NNCF和GenAI工具包实现完整的模型优化  
9. **SLMOps流程**：实现从训练到边缘部署的完整模型生命周期  
10. **多模型边缘系统**：在边缘硬件上部署多个协作的专业模型  
11. **MCP集成系统**：使用模型上下文协议构建一个工具交互的智能代理系统  

## 参考资料

- Microsoft Learn (Foundry Local)  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - 入门指南：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI参考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - 与推理SDK集成：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - 打开WebUI教程：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - 编译Hugging Face模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - 智能代理（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- 优化与推理工具  
  - Microsoft Olive（文档）：https://microsoft.github.io/Olive/  
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive  
  - ONNX Runtime（入门指南）：https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive集成：https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO（文档）：https://docs.openvino.ai/2025/index.html  
  - Apple MLX（文档）：https://ml-explore.github.io/mlx/build/html/index.html  
- 部署框架与模型  
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index  
  - vLLM（文档）：https://docs.vllm.ai/  
  - Ollama（快速入门）：https://github.com/ollama/ollama#get-started  
- 开发者工具（Windows和VS Code）  
  - VS Code的AI工具包：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## 学习社区

加入讨论，与其他学习者交流：  
- [EdgeAI for Beginners仓库](https://github.com/microsoft/edgeai-for-beginners/discussions)上的GitHub讨论  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 结论

EdgeAI代表了人工智能应用的前沿，将强大的能力直接带到设备端，同时解决隐私、延迟和连接性等关键问题。本课程为期20小时，提供了开始使用EdgeAI技术所需的基本知识和实践技能。

课程内容精简且专注于最重要的概念，让您能够快速掌握宝贵的专业知识，而不会占用过多时间。请记住，动手实践，即使是简单的例子，也是巩固所学知识的关键。

祝学习愉快！

---

