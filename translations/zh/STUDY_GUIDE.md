<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T09:32:33+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "zh"
}
-->
# 初学者的EdgeAI学习指南：学习路径与学习计划

### 集中学习路径（1周）

| 天数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1天 | 模块1：EdgeAI基础 | 3小时 |
| 第2天 | 模块2：SLM基础 | 3小时 |
| 第3天 | 模块3：SLM部署 | 2小时 |
| 第4-5天 | 模块4：模型优化（6种框架） | 4小时 |
| 第6天 | 模块5：SLMOps | 3小时 |
| 第7天 | 模块6-7：AI代理与开发工具 | 4小时 |
| 第8天 | 模块8：Foundry Local工具包（现代实现） | 1小时 |

### 集中学习路径（2周）

| 天数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1-2天 | 模块1：EdgeAI基础 | 3小时 |
| 第3-4天 | 模块2：SLM基础 | 3小时 |
| 第5-6天 | 模块3：SLM部署 | 2小时 |
| 第7-8天 | 模块4：模型优化 | 4小时 |
| 第9-10天 | 模块5：SLMOps | 3小时 |
| 第11-12天 | 模块6：AI代理 | 2小时 |
| 第13-14天 | 模块7：开发工具 | 3小时 |

### 兼职学习（4周）

| 周数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1周 | 模块1-2：基础与SLM基础 | 6小时 |
| 第2周 | 模块3-4：部署与优化 | 6小时 |
| 第3周 | 模块5-6：SLMOps与AI代理 | 5小时 |
| 第4周 | 模块7：开发工具与集成 | 3小时 |

| 天数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1-2天 | 模块1：EdgeAI基础 | 3小时 |
| 第3-4天 | 模块2：SLM基础 | 3小时 |
| 第5-6天 | 模块3：SLM部署 | 2小时 |
| 第7-8天 | 模块4：模型优化 | 4小时 |
| 第9-10天 | 模块5：SLMOps | 3小时 |
| 第11-12天 | 模块6：SLM代理系统 | 2小时 |
| 第13-14天 | 模块7：EdgeAI实现示例 | 2小时 |

| 模块 | 完成日期 | 花费时间 | 关键收获 |
|------|----------|----------|----------|
| 模块1：EdgeAI基础 | | | |
| 模块2：SLM基础 | | | |
| 模块3：SLM部署 | | | |
| 模块4：模型优化（6种框架） | | | |
| 模块5：SLMOps | | | |
| 模块6：SLM代理系统 | | | |
| 模块7：EdgeAI实现示例 | | | |
| 实践练习 | | | |
| 小型项目 | | | |

### 兼职学习（4周）

| 周数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1周 | 模块1-2：基础与SLM基础 | 6小时 |
| 第2周 | 模块3-4：部署与优化 | 6小时 |
| 第3周 | 模块5-6：SLMOps与AI代理 | 5小时 |
| 第4周 | 模块7：开发工具与集成 | 3小时 |

## 介绍

欢迎使用《初学者的EdgeAI学习指南》！本指南旨在帮助您高效学习课程内容，最大化学习效果。它提供了结构化的学习路径、推荐的学习计划、关键概念总结以及补充资源，帮助您深入理解EdgeAI技术。

这是一个简明的20小时课程，以高效的方式传授EdgeAI的核心知识，非常适合忙碌的专业人士和学生快速掌握这一新兴领域的实用技能。

## 课程概览

本课程分为七个全面的模块：

1. **EdgeAI基础与转型** - 理解核心概念和技术变革
2. **小型语言模型（SLM）基础** - 探索各种SLM家族及其架构
3. **小型语言模型部署** - 实现实际部署策略
4. **模型格式转换与量化** - 使用包括OpenVINO在内的6种框架进行高级优化
5. **SLMOps - 小型语言模型操作** - 生产生命周期管理与部署
6. **SLM代理系统** - AI代理、函数调用与模型上下文协议
7. **EdgeAI实现示例** - AI工具包、Windows开发及平台特定实现
8. **Microsoft Foundry Local – 完整开发工具包** - 本地优先开发与混合Azure集成（模块08）

## 如何使用本学习指南

- **循序渐进学习**：按顺序学习模块以获得最连贯的学习体验
- **知识检查点**：使用每节后的自测问题巩固知识
- **实践操作**：完成建议的练习以强化理论概念
- **补充资源**：深入探索您感兴趣的主题

## 学习计划推荐

### 集中学习路径（1周）

| 天数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1-2天 | 模块1：EdgeAI基础 | 6小时 |
| 第3-4天 | 模块2：SLM基础 | 8小时 |
| 第5天 | 模块3：SLM部署 | 3小时 |
| 第6天 | 模块8：Foundry Local工具包 | 3小时 |

### 兼职学习（3周）

| 周数 | 学习重点 | 预计时长 |
|------|----------|----------|
| 第1周 | 模块1：EdgeAI基础 | 6-7小时 |
| 第2周 | 模块2：SLM基础 | 7-8小时 |
| 第3周 | 模块3：SLM部署（3小时）+ 模块8：Foundry Local工具包（2-3小时） | 5-6小时 |

## 模块1：EdgeAI基础与转型

### 关键学习目标

- 理解基于云和基于边缘的AI之间的差异
- 掌握资源受限环境的核心优化技术
- 分析EdgeAI技术的实际应用
- 为EdgeAI项目设置开发环境

### 学习重点

#### 第1节：EdgeAI基础
- **优先概念**：
  - 边缘计算与云计算范式
  - 模型量化技术
  - 硬件加速选项（NPU、GPU、CPU）
  - 隐私与安全优势

- **补充材料**：
  - [TensorFlow Lite文档](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse文档](https://docs.edgeimpulse.com)

#### 第2节：实际案例研究
- **优先概念**：
  - Microsoft Phi & Mu模型生态系统
  - 各行业的实际应用
  - 部署注意事项

#### 第3节：实践实施指南
- **优先概念**：
  - 开发环境设置
  - 量化与优化工具
  - EdgeAI实施的评估方法

#### 第4节：边缘部署硬件
- **优先概念**：
  - 硬件平台比较
  - 针对特定硬件的优化策略
  - 部署注意事项

### 自测问题

1. 比较基于云的AI与基于边缘的AI实现。
2. 解释三种优化模型以适应边缘部署的关键技术。
3. 在边缘运行AI模型的主要优势是什么？
4. 描述量化模型的过程及其对性能的影响。
5. 解释不同硬件加速器（NPU、GPU、CPU）如何影响EdgeAI部署。

### 实践练习

1. **快速环境设置**：配置一个包含基本包的最小开发环境（30分钟）
2. **模型探索**：下载并检查一个预训练的小型语言模型（1小时）
3. **基础量化**：对一个小型模型尝试简单量化（1小时）

## 模块2：小型语言模型基础

### 关键学习目标

- 理解不同SLM家族的架构原理
- 比较不同参数规模下的模型能力
- 根据效率、能力和部署需求评估模型
- 识别不同模型家族的适用场景

### 学习重点

#### 第1节：Microsoft Phi模型家族
- **优先概念**：
  - 设计理念演变
  - 以效率为先的架构
  - 专业化能力

#### 第2节：Qwen家族
- **优先概念**：
  - 开源贡献
  - 可扩展部署选项
  - 高级推理架构

#### 第3节：Gemma家族
- **优先概念**：
  - 以研究为驱动的创新
  - 多模态能力
  - 移动优化

#### 第4节：BitNET家族
- **优先概念**：
  - 1位量化技术
  - 推理优化框架
  - 可持续性考量

#### 第5节：Microsoft Mu模型
- **优先概念**：
  - 设备优先架构
  - 与Windows的系统集成
  - 隐私保护操作

#### 第6节：Phi-Silica
- **优先概念**：
  - 针对NPU优化的架构
  - 性能指标
  - 开发者集成

### 自测问题

1. 比较Phi和Qwen模型家族的架构方法。
2. 解释BitNET的量化技术与传统量化的不同之处。
3. Mu模型在Windows集成方面的独特优势是什么？
4. 描述Phi-Silica如何利用NPU硬件进行性能优化。
5. 对于一个有限连接的移动应用，哪个模型家族最适合？为什么？

### 实践练习

1. **模型比较**：快速对比两个不同的SLM模型（1小时）
2. **简单文本生成**：使用一个小型模型实现基本的文本生成（1小时）
3. **快速优化**：应用一种优化技术提升推理速度（1小时）

## 模块3：小型语言模型部署

### 关键学习目标

- 根据部署限制选择合适的模型
- 掌握各种部署场景的优化技术
- 在本地和云环境中实现SLM部署
- 为EdgeAI应用设计生产就绪的配置

### 学习重点

#### 第1节：SLM高级学习
- **优先概念**：
  - 参数分类框架
  - 高级优化技术
  - 模型获取策略

#### 第2节：本地环境部署
- **优先概念**：
  - Ollama平台部署
  - Microsoft Foundry本地解决方案
  - 框架比较分析

#### 第3节：容器化云部署
- **优先概念**：
  - vLLM高性能推理
  - 容器编排
  - ONNX Runtime实现

### 自测问题

1. 在选择本地部署和云部署时应考虑哪些因素？
2. 比较Ollama和Microsoft Foundry Local作为部署选项。
3. 解释容器化对SLM部署的好处。
4. 边缘部署SLM时需要监控的关键性能指标是什么？
5. 描述从模型选择到生产实施的完整部署工作流程。

### 实践练习

1. **基础本地部署**：使用Ollama部署一个简单的SLM（1小时）
2. **性能检查**：对已部署的模型运行快速基准测试（30分钟）
3. **简单集成**：创建一个使用已部署模型的最小应用程序（1小时）

## 模块4：模型格式转换与量化

### 关键学习目标

- 掌握从1位到8位精度的高级量化技术
- 理解格式转换策略（GGUF、ONNX）
- 在六种框架（Llama.cpp、Olive、OpenVINO、MLX、工作流合成）中实现优化
- 为Intel、Apple及跨平台硬件的生产边缘环境部署优化模型

### 学习重点

#### 第1节：量化基础
- **优先概念**：
  - 精度分类框架
  - 性能与准确性权衡
  - 内存占用优化

#### 第2节：Llama.cpp实现
- **优先概念**：
  - 跨平台部署
  - GGUF格式优化
  - 硬件加速技术

#### 第3节：Microsoft Olive套件
- **优先概念**：
  - 硬件感知优化
  - 企业级部署
  - 自动化优化工作流

#### 第4节：OpenVINO工具包
- **优先概念**：
  - Intel硬件优化
  - 神经网络压缩框架（NNCF）
  - 跨平台推理部署
- OpenVINO GenAI 用于 LLM 部署

#### 第5节：Apple MLX 框架
- **重点概念**: 
  - Apple Silicon 优化
  - 统一内存架构
  - LoRA 微调能力

#### 第6节：边缘AI开发工作流综合
- **重点概念**: 
  - 统一的工作流架构
  - 框架选择决策树
  - 生产就绪性验证
  - 面向未来的策略

### 自我评估问题

1. 比较不同精度级别（1-bit到8-bit）的量化策略。
2. 解释GGUF格式在边缘部署中的优势。
3. 硬件感知优化在Microsoft Olive中如何提升部署效率？
4. OpenVINO的NNCF在模型压缩中的主要优势是什么？
5. Apple MLX如何利用统一内存架构进行优化？
6. 工作流综合如何帮助选择最佳优化框架？

### 实践练习

1. **模型量化**: 对模型应用不同的量化级别并比较结果（1小时）
2. **OpenVINO优化**: 使用NNCF对Intel硬件进行模型压缩（1小时）
3. **框架比较**: 在三个不同的优化框架中测试同一模型（1小时）
4. **性能基准测试**: 测量优化对推理速度和内存使用的影响（1小时）

## 模块5: SLMOps - 小型语言模型操作

### 关键学习目标

- 理解SLMOps生命周期管理原则
- 掌握用于边缘部署的蒸馏和微调技术
- 实现带有监控的生产部署策略
- 构建企业级SLM操作和维护工作流

### 学习重点领域

#### 第1节：SLMOps简介
- **重点概念**: 
  - SLMOps在AI操作中的范式转变
  - 成本效率和隐私优先架构
  - 战略性商业影响和竞争优势

#### 第2节：模型蒸馏
- **重点概念**: 
  - 知识迁移技术
  - 两阶段蒸馏过程的实施
  - Azure ML蒸馏工作流

#### 第3节：微调策略
- **重点概念**: 
  - 参数高效微调（PEFT）
  - LoRA和QLoRA高级方法
  - 多适配器训练和超参数优化

#### 第4节：生产部署
- **重点概念**: 
  - 生产中的模型转换和量化
  - Foundry Local部署配置
  - 性能基准测试和质量验证

### 自我评估问题

1. SLMOps与传统MLOps有何不同？
2. 模型蒸馏对边缘部署的好处是什么？
3. 在资源受限环境中微调SLM的关键考虑因素是什么？
4. 描述一个完整的边缘AI应用生产部署管道。

### 实践练习

1. **基础蒸馏**: 从一个较大的教师模型创建一个较小的模型（1小时）
2. **微调实验**: 针对特定领域微调一个模型（1小时）
3. **部署管道**: 设置一个基本的CI/CD管道用于模型部署（1小时）

## 模块6: SLM Agentic Systems - AI代理和函数调用

### 关键学习目标

- 使用小型语言模型构建适用于边缘环境的智能AI代理
- 实现具有系统化工作流的函数调用能力
- 掌握模型上下文协议（MCP）集成以实现标准化工具交互
- 创建复杂的代理系统，减少人为干预

### 学习重点领域

#### 第1节：AI代理和SLM基础
- **重点概念**: 
  - 代理分类框架（反射型、基于模型、基于目标、学习型代理）
  - SLM与LLM的权衡分析
  - 边缘特定的代理设计模式
  - 代理的资源优化

#### 第2节：小型语言模型中的函数调用
- **重点概念**: 
  - 系统化工作流实施（意图检测、JSON输出、外部执行）
  - 平台特定实现（Phi-4-mini、选定的Qwen模型、Microsoft Foundry Local）
  - 高级示例（多代理协作、动态工具选择）
  - 生产考虑（速率限制、审计日志、安全措施）

#### 第3节：模型上下文协议（MCP）集成
- **重点概念**: 
  - 协议架构和分层系统设计
  - 多后端支持（开发用Ollama，生产用vLLM）
  - 连接协议（STDIO和SSE模式）
  - 实际应用（网页自动化、数据处理、API集成）

### 自我评估问题

1. 边缘AI代理的关键架构考虑因素是什么？
2. 函数调用如何增强代理的能力？
3. 模型上下文协议在代理通信中起什么作用？

### 实践练习

1. **简单代理**: 构建一个带有函数调用的基础AI代理（1小时）
2. **MCP集成**: 在代理应用中实现MCP（30分钟）

## 模块7: 边缘AI实现示例

### 关键学习目标

- 掌握Visual Studio Code的AI工具包，用于全面的边缘AI开发工作流
- 熟悉Windows AI Foundry平台和NPU优化策略
- 在多种硬件平台和部署场景中实现边缘AI
- 构建生产就绪的边缘AI应用，结合平台特定优化

### 学习重点领域

#### 第1节：Visual Studio Code的AI工具包
- **重点概念**: 
  - 在VS Code中构建全面的边缘AI开发环境
  - 边缘部署的模型目录和发现
  - 本地测试、优化和代理开发工作流
  - 边缘场景的性能监控和评估

#### 第2节：Windows边缘AI开发指南
- **重点概念**: 
  - Windows AI Foundry平台全面概述
  - Phi Silica API用于高效NPU推理
  - 计算机视觉API用于图像处理和OCR
  - Foundry Local CLI用于本地开发和测试

#### 第3节：平台特定实现
- **重点概念**: 
  - NVIDIA Jetson Orin Nano部署（67 TOPS AI性能）
  - 使用.NET MAUI和ONNX Runtime GenAI开发移动应用
  - Azure边缘AI解决方案，结合云-边缘混合架构
  - Windows ML优化，支持通用硬件
  - Foundry Local应用，结合隐私优先的RAG实现

### 自我评估问题

1. AI工具包如何简化边缘AI开发工作流？
2. 比较不同硬件平台的部署策略。
3. Windows AI Foundry在边缘开发中的优势是什么？
4. NPU优化在现代边缘AI应用中起什么作用？
5. Phi Silica API如何利用NPU硬件进行性能优化？
6. 比较本地部署与云部署在隐私敏感应用中的优势。

### 实践练习

1. **AI工具包设置**: 配置AI工具包并优化一个模型（1小时）
2. **Windows AI Foundry**: 使用Phi Silica API构建一个简单的Windows AI应用（1小时）
3. **跨平台部署**: 在两个不同平台上部署同一模型（1小时）
4. **NPU优化**: 使用Windows AI Foundry工具测试NPU性能（30分钟）

## 模块8: Microsoft Foundry Local – 完整开发者工具包（现代化）

### 关键学习目标

- 安装和配置Foundry Local，结合现代SDK集成
- 使用协调器模式实现高级多代理系统
- 构建智能模型路由器，实现自动任务选择
- 部署生产就绪的AI解决方案，结合全面监控
- 与Azure AI Foundry集成，实现混合部署场景
- 掌握FoundryLocalManager和OpenAI客户端的现代SDK模式

### 学习重点领域

#### 第1节：现代化安装和配置
- **重点概念**: 
  - FoundryLocalManager SDK集成
  - 自动服务发现和健康监控
  - 基于环境的配置模式
  - 生产部署注意事项

#### 第2节：高级多代理系统
- **重点概念**: 
  - 使用专家代理的协调器模式
  - 检索、推理和执行代理的专业化
  - 用于优化的反馈循环机制
  - 性能监控和统计跟踪

#### 第3节：智能模型路由
- **重点概念**: 
  - 基于关键词的模型选择算法
  - 多模型支持（通用、推理、代码、创意）
  - 环境变量配置的灵活性
  - 服务健康检查和错误处理

#### 第4节：生产就绪实现
- **重点概念**: 
  - 全面的错误处理和回退机制
  - 请求监控和性能跟踪
  - 带有基准测试的交互式Jupyter笔记本示例
  - 与现有应用的集成模式

### 自我评估问题

1. 现代FoundryLocalManager方法与手动REST调用有何不同？
2. 解释协调器模式及其如何协调专家代理。
3. 智能路由器如何根据查询内容选择合适的模型？
4. 生产就绪的AI代理系统的关键组成部分是什么？
5. 如何为Foundry Local服务实现全面的健康监控？
6. 比较现代化方法与传统实现模式的优势。

### 实践练习

1. **现代SDK设置**: 配置FoundryLocalManager并实现自动服务发现（30分钟）
2. **多代理系统**: 运行带有专家代理的高级协调器（30分钟）
3. **智能路由**: 使用不同查询类型测试模型路由器（30分钟）
4. **交互式探索**: 使用Jupyter笔记本探索高级功能（45分钟）
5. **生产部署**: 实现监控和错误处理模式（30分钟）
6. **混合集成**: 配置Azure AI Foundry回退场景（30分钟）

## 时间分配指南

为了帮助您充分利用20小时的课程时间，以下是建议的时间分配：

| 活动 | 时间分配 | 描述 |
|----------|----------------|-------------|
| 阅读核心材料 | 9小时 | 专注于每个模块中的核心概念 |
| 实践练习 | 6小时 | 关键技术的实际应用 |
| 自我评估 | 2小时 | 通过问题和反思测试您的理解 |
| 小型项目 | 3小时 | 将知识应用于一个小型实践实现 |

### 按时间限制的重点领域

**如果您只有10小时:**
- 完成模块1、2和3（核心边缘AI概念）
- 每个模块至少完成一个实践练习
- 专注于理解核心概念，而非实现细节

**如果您可以投入完整的20小时:**
- 完成所有七个模块
- 执行每个模块的关键实践练习
- 完成模块7中的一个小型项目
- 探索至少2-3个补充资源

**如果您有超过20小时:**
- 详细完成所有模块和练习
- 构建多个小型项目
- 探索模块4中的高级优化技术
- 实现模块5中的生产部署

## 必备资源

以下精选资源为您的有限学习时间提供最大价值：

### 必读文档
- [ONNX Runtime 入门](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型优化工具
- [Ollama 快速入门](https://github.com/ollama/ollama#get-started) - 本地部署SLM的最快方式
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 边缘优化模型的参考
- [OpenVINO 文档](https://docs.openvino.ai/2025/index.html) - Intel的全面优化工具包
- [VS Code的AI工具包](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成的边缘AI开发环境
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows特定的边缘AI开发平台

### 节省时间的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型访问和部署
- [Gradio](https://www.gradio.app/docs/interface) - 快速开发AI演示的UI
- [Microsoft Olive](https://github.com/microsoft/Olive) - 简化的模型优化工具
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的CPU推理
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神经网络压缩框架
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型语言模型部署工具包

## 进度跟踪模板

使用此简化模板跟踪您在20小时课程中的学习进度：

| 模块 | 完成日期 | 花费时间 | 主要收获 |
|--------|----------------|-------------|---------------|
| 模块1: 边缘AI基础 | | | |
| 模块2: SLM基础 | | | |
| 模块3: SLM部署 | | | |
| 模块4: 模型优化 | | | |
| 模块5: SLMOps | | | |
| 模块6: AI代理 | | | |
| 模块7: 开发工具 | | | |
| 模块8: Foundry Local 工具包 | | | |
| 实践练习 | | | |
| 小项目 | | | |

## 小项目创意

考虑完成以下项目之一来练习 EdgeAI 概念（每个项目设计为耗时 2-4 小时）：

### 初级项目（每个 2-3 小时）
1. **边缘文本助手**：使用一个小型语言模型创建一个简单的离线文本补全工具  
2. **模型比较仪表板**：构建一个基本的可视化工具，用于展示不同 SLM 的性能指标  
3. **优化实验**：测量不同量化级别对同一基础模型的影响  

### 中级项目（每个 3-4 小时）
4. **AI 工具包工作流**：使用 VS Code AI 工具包从头到尾优化并部署一个模型  
5. **Windows AI Foundry 应用**：使用 Phi Silica API 和 NPU 优化创建一个 Windows 应用  
6. **跨平台部署**：将同一个优化模型部署到 Windows（OpenVINO）和移动端（.NET MAUI）  
7. **函数调用代理**：构建一个具有函数调用能力的 AI 代理，用于边缘场景  

### 高级集成项目（每个 4-5 小时）
8. **OpenVINO 优化流水线**：使用 NNCF 和 GenAI 工具包实现完整的模型优化  
9. **SLMOps 流水线**：实现从训练到边缘部署的完整模型生命周期  
10. **多模型边缘系统**：在边缘硬件上部署多个协作的专用模型  
11. **MCP 集成系统**：使用模型上下文协议构建一个工具交互的代理系统  

## 参考资料

- Microsoft Learn (Foundry Local)  
  - 概述: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - 入门: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI 参考: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - 与推理 SDK 集成: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - 打开 WebUI 教程: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - 编译 Hugging Face 模型: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - 概述: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - 代理（概述）: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- 优化和推理工具  
  - Microsoft Olive（文档）: https://microsoft.github.io/Olive/  
  - Microsoft Olive（GitHub）: https://github.com/microsoft/Olive  
  - ONNX Runtime（入门）: https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive 集成: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO（文档）: https://docs.openvino.ai/2025/index.html  
  - Apple MLX（文档）: https://ml-explore.github.io/mlx/build/html/index.html  
- 部署框架和模型  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM（文档）: https://docs.vllm.ai/  
  - Ollama（快速入门）: https://github.com/ollama/ollama#get-started  
- 开发者工具（Windows 和 VS Code）  
  - VS Code 的 AI 工具包: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML（概述）: https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## 学习社区

加入讨论，与其他学习者交流：  
- [EdgeAI for Beginners 仓库的 GitHub 讨论](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft 技术社区](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 结论

EdgeAI 代表了人工智能应用的前沿，将强大的能力直接带到设备端，同时解决隐私、延迟和连接性等关键问题。本课程为期 20 小时，为您提供了开始使用 EdgeAI 技术所需的基本知识和实践技能。

本课程内容简洁明了，专注于最重要的概念，让您能够快速获得宝贵的专业知识，而无需投入过多时间。请记住，即使是简单的实践练习，也是巩固所学知识的关键。

祝学习愉快！

---

