<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T23:10:17+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "da"
}
-->
# EdgeAI for Begyndere: Læringsforløb og Studieplan

### Koncentreret Læringsforløb (1 uge)

| Dag | Fokus | Estimerede Timer |
|------|-------|------------------|
| Dag 1 | Modul 1: EdgeAI Grundlæggende | 3 timer |
| Dag 2 | Modul 2: SLM Grundlag | 3 timer |
| Dag 3 | Modul 3: SLM Implementering | 2 timer |
| Dag 4-5 | Modul 4: Modeloptimering (6 frameworks) | 4 timer |
| Dag 6 | Modul 5: SLMOps | 3 timer |
| Dag 7 | Modul 6-7: AI-agenter & Udviklingsværktøjer | 4 timer |
| Dag 8 | Modul 8: Foundry Local Toolkit (Moderne Implementering) | 1 time |

### Koncentreret Læringsforløb (2 uger)

| Dag | Fokus | Estimerede Timer |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grundlæggende | 3 timer |
| Dag 3-4 | Modul 2: SLM Grundlag | 3 timer |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timer |
| Dag 7-8 | Modul 4: Modeloptimering | 4 timer |
| Dag 9-10 | Modul 5: SLMOps | 3 timer |
| Dag 11-12 | Modul 6: AI-agenter | 2 timer |
| Dag 13-14 | Modul 7: Udviklingsværktøjer | 3 timer |

### Deltidsstudie (4 uger)

| Uge | Fokus | Estimerede Timer |
|------|-------|------------------|
| Uge 1 | Modul 1-2: Grundlæggende & SLM Grundlag | 6 timer |
| Uge 2 | Modul 3-4: Implementering & Optimering | 6 timer |
| Uge 3 | Modul 5-6: SLMOps & AI-agenter | 5 timer |
| Uge 4 | Modul 7: Udviklingsværktøjer & Integration | 3 timer |

| Dag | Fokus | Estimerede Timer |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grundlæggende | 3 timer |
| Dag 3-4 | Modul 2: SLM Grundlag | 3 timer |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timer |
| Dag 7-8 | Modul 4: Modeloptimering | 4 timer |
| Dag 9-10 | Modul 5: SLMOps | 3 timer |
| Dag 11-12 | Modul 6: SLM Agentiske Systemer | 2 timer |
| Dag 13-14 | Modul 7: EdgeAI Implementerings Eksempler | 2 timer |

| Modul | Afslutningsdato | Brugte Timer | Vigtige Læringspunkter |
|--------|----------------|-------------|------------------------|
| Modul 1: EdgeAI Grundlæggende | | | |
| Modul 2: SLM Grundlag | | | |
| Modul 3: SLM Implementering | | | |
| Modul 4: Modeloptimering (6 frameworks) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiske Systemer | | | |
| Modul 7: EdgeAI Implementerings Eksempler | | | |
| Praktiske Øvelser | | | |
| Mini-projekt | | | |

### Deltidsstudie (4 uger)

| Uge | Fokus | Estimerede Timer |
|------|-------|------------------|
| Uge 1 | Modul 1-2: Grundlæggende & SLM Grundlag | 6 timer |
| Uge 2 | Modul 3-4: Implementering & Optimering | 6 timer |
| Uge 3 | Modul 5-6: SLMOps & AI-agenter | 5 timer |
| Uge 4 | Modul 7: Udviklingsværktøjer & Integration | 3 timer |

## Introduktion

Velkommen til EdgeAI for Begyndere studieguide! Dette dokument er designet til at hjælpe dig med at navigere i kursusmaterialet effektivt og maksimere din læringsoplevelse. Det giver strukturerede læringsforløb, foreslåede studieplaner, nøglebegrebssammendrag og supplerende ressourcer til at uddybe din forståelse af EdgeAI-teknologier.

Dette er et kortfattet 20-timers kursus, der leverer essentiel viden om EdgeAI i et tidsbesparende format, hvilket gør det perfekt for travle professionelle og studerende, der hurtigt vil opnå praktiske færdigheder inden for dette fremspirende felt.

## Kursusoversigt

Kurset er organiseret i syv omfattende moduler:

1. **EdgeAI Grundlæggende og Transformation** - Forståelse af kernekoncepter og teknologiskift
2. **Small Language Model Grundlag** - Udforskning af forskellige SLM-familier og deres arkitekturer
3. **Small Language Model Implementering** - Praktiske implementeringsstrategier
4. **Modelformatkonvertering og Kvantisering** - Avanceret optimering med 6 frameworks, herunder OpenVINO
5. **SLMOps - Small Language Model Operations** - Produktionslivscyklus og implementering
6. **SLM Agentiske Systemer** - AI-agenter, funktionskald og Model Context Protocol
7. **EdgeAI Implementerings Eksempler** - AI Toolkit, Windows-udvikling og platformspecifikke implementeringer
8. **Microsoft Foundry Local – Komplet Udviklerværktøj** - Lokal-først udvikling med hybrid Azure-integration (Modul 08)

## Sådan Bruger Du Denne Studieguide

- **Progressiv Læring**: Følg modulerne i rækkefølge for den mest sammenhængende læringsoplevelse
- **Videnscheckpunkter**: Brug selvvurderingsspørgsmålene efter hver sektion
- **Praktisk Øvelse**: Gennemfør de foreslåede øvelser for at styrke teoretiske koncepter
- **Supplerende Ressourcer**: Udforsk yderligere materialer for emner, der interesserer dig mest

## Studieplan Anbefalinger

### Koncentreret Læringsforløb (1 uge)

| Dag | Fokus | Estimerede Timer |
|------|-------|-----------------|
| Dag 1-2 | Modul 1: EdgeAI Grundlæggende | 6 timer |
| Dag 3-4 | Modul 2: SLM Grundlag | 8 timer |
| Dag 5 | Modul 3: SLM Implementering | 3 timer |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timer |

### Deltidsstudie (3 uger)

| Uge | Fokus | Estimerede Timer |
|------|-------|-----------------|
| Uge 1 | Modul 1: EdgeAI Grundlæggende | 6-7 timer |
| Uge 2 | Modul 2: SLM Grundlag | 7-8 timer |
| Uge 3 | Modul 3: SLM Implementering (3t) + Modul 8: Foundry Local Toolkit (2-3t) | 5-6 timer |

## Modul 1: EdgeAI Grundlæggende og Transformation

### Vigtige Læringsmål

- Forstå forskellene mellem cloud-baseret og edge-baseret AI
- Mestre kerneoptimeringsteknikker til ressourcebegrænsede miljøer
- Analysere virkelige anvendelser af EdgeAI-teknologier
- Opsætte et udviklingsmiljø til EdgeAI-projekter

### Studie Fokusområder

#### Sektion 1: EdgeAI Grundlæggende
- **Prioriterede Koncepter**: 
  - Edge vs. Cloud computing paradigmer
  - Modelkvantiseringsteknikker
  - Hardwareaccelerationsmuligheder (NPU'er, GPU'er, CPU'er)
  - Privatlivs- og sikkerhedsfordele

- **Supplerende Materialer**:
  - [TensorFlow Lite Dokumentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentation](https://docs.edgeimpulse.com)

#### Sektion 2: Virkelige Case Studies
- **Prioriterede Koncepter**: 
  - Microsoft Phi & Mu modeløkosystem
  - Praktiske implementeringer på tværs af industrier
  - Implementeringsovervejelser

#### Sektion 3: Praktisk Implementeringsguide
- **Prioriterede Koncepter**: 
  - Opsætning af udviklingsmiljø
  - Kvantisering og optimeringsværktøjer
  - Evalueringsmetoder for EdgeAI-implementeringer

#### Sektion 4: Edge Implementeringshardware
- **Prioriterede Koncepter**: 
  - Sammenligning af hardwareplatforme
  - Optimeringsstrategier for specifik hardware
  - Implementeringsovervejelser

### Selv-vurderingsspørgsmål

1. Sammenlign og kontrast cloud-baseret AI med edge-baseret AI-implementeringer.
2. Forklar tre nøgleteknikker til optimering af modeller til edge-implementering.
3. Hvad er de primære fordele ved at køre AI-modeller på kanten?
4. Beskriv processen med at kvantisere en model, og hvordan det påvirker ydeevnen.
5. Forklar, hvordan forskellige hardwareacceleratorer (NPU'er, GPU'er, CPU'er) påvirker EdgeAI-implementering.

### Praktiske Øvelser

1. **Hurtig Opsætning af Miljø**: Konfigurer et minimalt udviklingsmiljø med de nødvendige pakker (30 minutter)
2. **Modelundersøgelse**: Download og undersøg en forudtrænet lille sprogmodel (1 time)
3. **Grundlæggende Kvantisering**: Prøv simpel kvantisering på en lille model (1 time)

## Modul 2: Small Language Model Grundlag

### Vigtige Læringsmål

- Forstå de arkitektoniske principper for forskellige SLM-familier
- Sammenligne modelkapaciteter på tværs af forskellige parameterstørrelser
- Evaluere modeller baseret på effektivitet, kapacitet og implementeringskrav
- Genkende passende anvendelsestilfælde for forskellige modelfamilier

### Studie Fokusområder

#### Sektion 1: Microsoft Phi Modelfamilie
- **Prioriterede Koncepter**: 
  - Designfilosofiens udvikling
  - Effektivitet-først arkitektur
  - Specialiserede kapaciteter

#### Sektion 2: Qwen Familie
- **Prioriterede Koncepter**: 
  - Open source bidrag
  - Skalerbare implementeringsmuligheder
  - Avanceret ræsonnement arkitektur

#### Sektion 3: Gemma Familie
- **Prioriterede Koncepter**: 
  - Forskningsdrevet innovation
  - Multimodale kapaciteter
  - Mobiloptimering

#### Sektion 4: BitNET Familie
- **Prioriterede Koncepter**: 
  - 1-bit kvantiseringsteknologi
  - Optimeringsramme for inferens
  - Bæredygtighedsovervejelser

#### Sektion 5: Microsoft Mu Model
- **Prioriterede Koncepter**: 
  - Enheds-først arkitektur
  - Systemintegration med Windows
  - Privatlivsbevarende drift

#### Sektion 6: Phi-Silica
- **Prioriterede Koncepter**: 
  - NPU-optimeret arkitektur
  - Ydelsesmålinger
  - Udviklerintegration

### Selv-vurderingsspørgsmål

1. Sammenlign de arkitektoniske tilgange for Phi- og Qwen-modelfamilierne.
2. Forklar, hvordan BitNET's kvantiseringsteknologi adskiller sig fra traditionel kvantisering.
3. Hvad er de unikke fordele ved Mu-modellen til Windows-integration?
4. Beskriv, hvordan Phi-Silica udnytter NPU-hardware til ydelsesoptimering.
5. For en mobilapplikation med begrænset forbindelse, hvilken modelfamilie ville være mest passende og hvorfor?

### Praktiske Øvelser

1. **Model Sammenligning**: Hurtig benchmark af to forskellige SLM-modeller (1 time)
2. **Simpel Tekstgenerering**: Grundlæggende implementering af tekstgenerering med en lille model (1 time)
3. **Hurtig Optimering**: Anvend en optimeringsteknik for at forbedre inferenshastighed (1 time)

## Modul 3: Small Language Model Implementering

### Vigtige Læringsmål

- Vælg passende modeller baseret på implementeringsbegrænsninger
- Mestre optimeringsteknikker til forskellige implementeringsscenarier
- Implementer SLM'er i både lokale og cloud-miljøer
- Design produktionsklare konfigurationer til EdgeAI-applikationer

### Studie Fokusområder

#### Sektion 1: SLM Avanceret Læring
- **Prioriterede Koncepter**: 
  - Parameterklassifikationsramme
  - Avancerede optimeringsteknikker
  - Strategier for modelanskaffelse

#### Sektion 2: Lokal Implementering
- **Prioriterede Koncepter**: 
  - Ollama platform implementering
  - Microsoft Foundry lokale løsninger
  - Sammenligning af frameworks

#### Sektion 3: Containeriseret Cloud Implementering
- **Prioriterede Koncepter**: 
  - vLLM højtydende inferens
  - Container orkestrering
  - ONNX Runtime implementering

### Selv-vurderingsspørgsmål

1. Hvilke faktorer skal overvejes, når man vælger mellem lokal implementering og cloud-implementering?
2. Sammenlign Ollama og Microsoft Foundry Local som implementeringsmuligheder.
3. Forklar fordelene ved containerisering til SLM-implementering.
4. Hvad er de vigtigste ydelsesmålinger at overvåge for en edge-implementeret SLM?
5. Beskriv en komplet implementeringsworkflow fra modelvalg til produktionsimplementering.

### Praktiske Øvelser

1. **Grundlæggende Lokal Implementering**: Implementer en simpel SLM ved hjælp af Ollama (1 time)
2. **Ydelsestjek**: Kør en hurtig benchmark på din implementerede model (30 minutter)
3. **Simpel Integration**: Opret en minimal applikation, der bruger din implementerede model (1 time)

## Modul 4: Modelformatkonvertering og Kvantisering

### Vigtige Læringsmål

- Mestre avancerede kvantiseringsteknikker fra 1-bit til 8-bit præcision
- Forstå strategier for formatkonvertering (GGUF, ONNX)
- Implementere optimering på tværs af seks frameworks (Llama.cpp, Olive, OpenVINO, MLX, workflow-syntese)
- Implementere optimerede modeller til produktions-edge-miljøer på tværs af Intel, Apple og cross-platform hardware

### Studie Fokusområder

#### Sektion 1: Kvantisering Grundlag
- **Prioriterede Koncepter**: 
  - Præcisionsklassifikationsramme
  - Ydelse vs. nøjagtighed afvejninger
  - Optimering af hukommelsesforbrug

#### Sektion 2: Llama.cpp Implementering
- **Prioriterede Koncepter**: 
  - Cross-platform implementering
  - GGUF formatoptimering
  - Hardwareaccelerationsmetoder

#### Sektion 3: Microsoft Olive Suite
- **Prioriterede Koncepter**: 
  - Hardware-bevidst optimering
  - Implementering i virksomhedsklasse
  - Automatiserede optimeringsworkflows

#### Sektion 4: OpenVINO Toolkit
- **Prioriterede Koncepter**: 
  - Intel hardwareoptimering
  - Neural Network Compression Framework (NNCF)
  - Cross-platform inferens implementering
- OpenVINO GenAI til LLM-implementering

#### Sektion 5: Apple MLX Framework
- **Prioriterede begreber**: 
  - Optimering til Apple Silicon
  - Unified memory-arkitektur
  - LoRA finjusteringsmuligheder

#### Sektion 6: Workflow-syntese for Edge AI-udvikling
- **Prioriterede begreber**: 
  - Unified workflow-arkitektur
  - Beslutningstræer for valg af framework
  - Validering af produktionsparathed
  - Strategier for fremtidssikring

### Selv-evalueringsspørgsmål

1. Sammenlign kvantiseringsstrategier på tværs af forskellige præcisionsniveauer (1-bit til 8-bit).
2. Forklar fordelene ved GGUF-formatet til edge-implementering.
3. Hvordan forbedrer hardwarebevidst optimering i Microsoft Olive implementeringseffektiviteten?
4. Hvad er de vigtigste fordele ved OpenVINOs NNCF til modelkomprimering?
5. Beskriv, hvordan Apple MLX udnytter unified memory-arkitekturen til optimering.
6. Hvordan hjælper workflow-syntese med at vælge optimale optimeringsframeworks?

### Praktiske øvelser

1. **Modelkvantisering**: Anvend forskellige kvantiseringsniveauer på en model og sammenlign resultater (1 time)
2. **OpenVINO-optimering**: Brug NNCF til at komprimere en model til Intel-hardware (1 time)
3. **Framework-sammenligning**: Test den samme model på tre forskellige optimeringsframeworks (1 time)
4. **Performance-benchmarking**: Mål optimeringens effekt på inferenshastighed og hukommelsesforbrug (1 time)

## Modul 5: SLMOps - Small Language Model Operations

### Centrale læringsmål

- Forstå principperne for livscyklusstyring i SLMOps
- Mestre distillation og finjusteringsteknikker til edge-implementering
- Implementere produktionsstrategier med overvågning
- Opbygge workflows til SLM-drift og vedligeholdelse i virksomhedsklasse

### Fokusområder for studiet

#### Sektion 1: Introduktion til SLMOps
- **Prioriterede begreber**: 
  - Paradigmeskiftet i AI-drift med SLMOps
  - Omkostningseffektivitet og privatlivsfokuseret arkitektur
  - Strategisk forretningspåvirkning og konkurrencefordele

#### Sektion 2: Modeldistillation
- **Prioriterede begreber**: 
  - Teknikker til vidensoverførsel
  - Implementering af to-trins distillationsprocesser
  - Distillationsworkflows med Azure ML

#### Sektion 3: Finjusteringsstrategier
- **Prioriterede begreber**: 
  - Parameter-effektiv finjustering (PEFT)
  - Avancerede metoder som LoRA og QLoRA
  - Multi-adapter træning og optimering af hyperparametre

#### Sektion 4: Produktionsimplementering
- **Prioriterede begreber**: 
  - Modelkonvertering og kvantisering til produktion
  - Konfiguration af Foundry Local-implementering
  - Performance-benchmarking og kvalitetsvalidering

### Selv-evalueringsspørgsmål

1. Hvordan adskiller SLMOps sig fra traditionel MLOps?
2. Forklar fordelene ved modeldistillation til edge-implementering.
3. Hvad er de vigtigste overvejelser ved finjustering af SLM'er i ressourcebegrænsede miljøer?
4. Beskriv en komplet produktionspipeline til edge AI-applikationer.

### Praktiske øvelser

1. **Grundlæggende distillation**: Skab en mindre model fra en større lærer-model (1 time)
2. **Finjusteringseksperiment**: Finjuster en model til et specifikt domæne (1 time)
3. **Implementeringspipeline**: Opsæt en grundlæggende CI/CD-pipeline til modelimplementering (1 time)

## Modul 6: SLM Agentic Systems - AI-agenter og funktionkald

### Centrale læringsmål

- Byg intelligente AI-agenter til edge-miljøer ved hjælp af Small Language Models
- Implementer funktionkald med systematiske workflows
- Mestre Model Context Protocol (MCP) integration for standardiseret værktøjsinteraktion
- Skab avancerede agentiske systemer med minimal menneskelig indgriben

### Fokusområder for studiet

#### Sektion 1: AI-agenter og SLM-grundlag
- **Prioriterede begreber**: 
  - Klassifikationsramme for agenter (refleks, modelbaseret, målbaseret, læringsagenter)
  - Analyse af SLM vs LLM trade-offs
  - Designmønstre for edge-specifikke agenter
  - Ressourceoptimering for agenter

#### Sektion 2: Funktionkald i Small Language Models
- **Prioriterede begreber**: 
  - Implementering af systematiske workflows (intentiondetektion, JSON-output, ekstern eksekvering)
  - Platform-specifikke implementeringer (Phi-4-mini, udvalgte Qwen-modeller, Microsoft Foundry Local)
  - Avancerede eksempler (multi-agent samarbejde, dynamisk værktøjsvalg)
  - Produktionsovervejelser (ratebegrænsning, audit-logning, sikkerhedsforanstaltninger)

#### Sektion 3: Model Context Protocol (MCP) integration
- **Prioriterede begreber**: 
  - Protokolarkitektur og lagdelt systemdesign
  - Multi-backend support (Ollama til udvikling, vLLM til produktion)
  - Forbindelsesprotokoller (STDIO og SSE modes)
  - Virkelige anvendelser (webautomatisering, databehandling, API-integration)

### Selv-evalueringsspørgsmål

1. Hvad er de vigtigste arkitektoniske overvejelser for edge AI-agenter?
2. Hvordan forbedrer funktionkald agentens kapabiliteter?
3. Forklar rollen af Model Context Protocol i agentkommunikation.

### Praktiske øvelser

1. **Enkel agent**: Byg en grundlæggende AI-agent med funktionkald (1 time)
2. **MCP-integration**: Implementer MCP i en agentapplikation (30 minutter)

## Modul 7: EdgeAI Implementeringsprøver

### Centrale læringsmål

- Mestre AI Toolkit til Visual Studio Code for omfattende EdgeAI-udviklingsworkflows
- Opnå ekspertise i Windows AI Foundry-platformen og NPU-optimeringsstrategier
- Implementer EdgeAI på tværs af flere hardwareplatforme og implementeringsscenarier
- Byg produktionsklare EdgeAI-applikationer med platform-specifikke optimeringer

### Fokusområder for studiet

#### Sektion 1: AI Toolkit til Visual Studio Code
- **Prioriterede begreber**: 
  - Omfattende Edge AI-udviklingsmiljø i VS Code
  - Modelkatalog og opdagelse til edge-implementering
  - Lokal testning, optimering og agentudviklingsworkflows
  - Performance-overvågning og evaluering for edge-scenarier

#### Sektion 2: Windows EdgeAI Udviklingsguide
- **Prioriterede begreber**: 
  - Omfattende oversigt over Windows AI Foundry-platformen
  - Phi Silica API til effektiv NPU-inferens
  - Computer Vision API'er til billedbehandling og OCR
  - Foundry Local CLI til lokal udvikling og testning

#### Sektion 3: Platform-specifikke implementeringer
- **Prioriterede begreber**: 
  - NVIDIA Jetson Orin Nano implementering (67 TOPS AI-performance)
  - Mobilapplikationer med .NET MAUI og ONNX Runtime GenAI
  - Azure EdgeAI-løsninger med hybrid arkitektur mellem cloud og edge
  - Windows ML-optimering med universel hardwareunderstøttelse
  - Foundry Local-applikationer med privatlivsfokuseret RAG-implementering

### Selv-evalueringsspørgsmål

1. Hvordan strømliner AI Toolkit EdgeAI-udviklingsworkflowet?
2. Sammenlign implementeringsstrategier på tværs af forskellige hardwareplatforme.
3. Hvad er fordelene ved Windows AI Foundry til edge-udvikling?
4. Forklar rollen af NPU-optimering i moderne EdgeAI-applikationer.
5. Hvordan udnytter Phi Silica API NPU-hardware til performance-optimering?
6. Sammenlign fordelene ved lokal vs. cloud-implementering for privatlivsfølsomme applikationer.

### Praktiske øvelser

1. **AI Toolkit-opsætning**: Konfigurer AI Toolkit og optimer en model (1 time)
2. **Windows AI Foundry**: Byg en simpel Windows AI-applikation ved hjælp af Phi Silica API (1 time)
3. **Cross-platform implementering**: Implementer den samme model på to forskellige platforme (1 time)
4. **NPU-optimering**: Test NPU-performance med Windows AI Foundry-værktøjer (30 minutter)

## Modul 8: Microsoft Foundry Local – Komplet udviklerværktøjssæt (Moderniseret)

### Centrale læringsmål

- Installer og konfigurer Foundry Local med moderne SDK-integration
- Implementer avancerede multi-agent systemer med koordinator-mønstre
- Byg intelligente modelroutere med automatisk opgavebaseret valg
- Implementer produktionsklare AI-løsninger med omfattende overvågning
- Integrer med Azure AI Foundry til hybrid implementeringsscenarier
- Mestre moderne SDK-mønstre med FoundryLocalManager og OpenAI-klient

### Fokusområder for studiet

#### Sektion 1: Moderne installation og konfiguration
- **Prioriterede begreber**: 
  - FoundryLocalManager SDK-integration
  - Automatisk serviceopdagelse og sundhedsovervågning
  - Konfigurationsmønstre baseret på miljø
  - Overvejelser for produktionsimplementering

#### Sektion 2: Avancerede multi-agent systemer
- **Prioriterede begreber**: 
  - Koordinator-mønster med specialistagenter
  - Specialisering af agenter til hentning, ræsonnement og eksekvering
  - Feedback-loop mekanismer til forbedring
  - Performance-overvågning og statistiksporing

#### Sektion 3: Intelligent modelrouting
- **Prioriterede begreber**: 
  - Algoritmer til modelvalg baseret på nøgleord
  - Understøttelse af flere modeller (generel, ræsonnement, kode, kreativ)
  - Konfiguration af miljøvariabler for fleksibilitet
  - Sundhedstjek af tjenester og fejlhåndtering

#### Sektion 4: Produktionsklar implementering
- **Prioriterede begreber**: 
  - Omfattende fejlhåndtering og fallback-mekanismer
  - Overvågning af forespørgsler og performance-tracking
  - Interaktive Jupyter-notebook eksempler med benchmarks
  - Integrationsmønstre med eksisterende applikationer

### Selv-evalueringsspørgsmål

1. Hvordan adskiller den moderne FoundryLocalManager tilgang sig fra manuelle REST-kald?
2. Forklar koordinator-mønsteret og hvordan det orkestrerer specialistagenter.
3. Hvordan vælger den intelligente router passende modeller baseret på forespørgselsindhold?
4. Hvad er de vigtigste komponenter i et produktionsklart AI-agent system?
5. Hvordan implementerer du omfattende sundhedsovervågning for Foundry Local-tjenester?
6. Sammenlign fordelene ved den moderniserede tilgang vs. traditionelle implementeringsmønstre.

### Praktiske øvelser

1. **Moderne SDK-opsætning**: Konfigurer FoundryLocalManager med automatisk serviceopdagelse (30 minutter)
2. **Multi-agent system**: Kør den avancerede koordinator med specialistagenter (30 minutter)
3. **Intelligent routing**: Test modelrouteren med forskellige forespørgselstyper (30 minutter)
4. **Interaktiv udforskning**: Brug Jupyter-notebooks til at udforske avancerede funktioner (45 minutter)
5. **Produktionsimplementering**: Implementer overvågnings- og fejlhåndteringsmønstre (30 minutter)
6. **Hybrid integration**: Konfigurer fallback-scenarier med Azure AI Foundry (30 minutter)

## Tidsallokeringsguide

For at hjælpe dig med at få mest muligt ud af det 20-timers kursus, er her en foreslået tidsfordeling:

| Aktivitet | Tidsallokering | Beskrivelse |
|----------|----------------|-------------|
| Læsning af kernematerialer | 9 timer | Fokus på de essentielle begreber i hvert modul |
| Praktiske øvelser | 6 timer | Praktisk implementering af nøgleteknikker |
| Selv-evaluering | 2 timer | Test din forståelse gennem spørgsmål og refleksion |
| Mini-projekt | 3 timer | Anvend viden på en lille praktisk implementering |

### Fokusområder baseret på tidsbegrænsning

**Hvis du kun har 10 timer:**
- Gennemfør modulerne 1, 2 og 3 (centrale EdgeAI-begreber)
- Lav mindst én praktisk øvelse pr. modul
- Fokusér på at forstå de centrale begreber frem for implementeringsdetaljer

**Hvis du kan dedikere de fulde 20 timer:**
- Gennemfør alle syv moduler
- Udfør nøglepraktiske øvelser fra hvert modul
- Fuldfør et mini-projekt fra modul 7
- Udforsk mindst 2-3 supplerende ressourcer

**Hvis du har mere end 20 timer:**
- Gennemfør alle moduler med detaljerede øvelser
- Byg flere mini-projekter
- Udforsk avancerede optimeringsteknikker i modul 4
- Implementer produktionsimplementering fra modul 5

## Væsentlige ressourcer

Disse nøje udvalgte ressourcer giver mest værdi for din begrænsede studietid:

### Dokumentation, der skal læses
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektive værktøj til modeloptimering
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Hurtigste måde at implementere SLM'er lokalt
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Reference for en førende edge-optimeret model
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattende optimeringsværktøjssæt
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integreret EdgeAI-udviklingsmiljø
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifik EdgeAI-udviklingsplatform

### Tidsbesparende værktøjer
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Hurtig adgang til og implementering af modeller
- [Gradio](https://www.gradio.app/docs/interface) - Hurtig UI-udvikling til AI-demos
- [Microsoft Olive](https://github.com/microsoft/Olive) - Forenklet modeloptimering
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework til neural netværkskomprimering
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit til implementering af store sprogmodeller

## Fremgangssporingsskabelon

Brug denne forenklede skabelon til at spore din læringsfremgang gennem det 20-timers kursus:

| Modul | Afslutningsdato | Timer brugt | Vigtige pointer |
|--------|----------------|-------------|---------------|
| Modul 1: EdgeAI Fundamentals | | | |
| Modul 2: SLM Foundations | | | |
| Modul 3: SLM Deployment | | | |
| Modul 4: Model Optimization | | | |
| Modul 5: SLMOps | | | |
| Modul 6: AI Agents | | | |
| Modul 7: Development Tools | | | |
| Modul 8: Foundry Local Toolkit | | | |
| Praktiske Øvelser | | | |
| Mini-Projekt | | | |

## Ideer til Mini-Projekter

Overvej at gennemføre et af disse projekter for at øve EdgeAI-konceptet (hver designet til at tage 2-4 timer):

### Begynderprojekter (2-3 timer hver)
1. **Edge Tekstassistent**: Lav et simpelt offline tekstfuldførelsesværktøj ved hjælp af en lille sprogmodel
2. **Model Sammenligningsdashboard**: Byg en grundlæggende visualisering af præstationsmålinger på tværs af forskellige SLM'er
3. **Optimeringseksperiment**: Mål effekten af forskellige kvantiseringsniveauer på den samme basismodel

### Mellemprojekter (3-4 timer hver)
4. **AI Toolkit Workflow**: Brug VS Code AI Toolkit til at optimere og implementere en model fra start til slut
5. **Windows AI Foundry Applikation**: Lav en Windows-app ved hjælp af Phi Silica API og NPU-optimering
6. **Cross-Platform Implementering**: Implementer den samme optimerede model på Windows (OpenVINO) og mobil (.NET MAUI)
7. **Funktionskaldende Agent**: Byg en AI-agent med funktionskaldskapacitet til edge-scenarier

### Avancerede Integrationsprojekter (4-5 timer hver)
8. **OpenVINO Optimeringspipeline**: Implementer komplet modeloptimering ved hjælp af NNCF og GenAI toolkit
9. **SLMOps Pipeline**: Implementer en komplet modellivscyklus fra træning til edge-implementering
10. **Multi-Model Edge System**: Implementer flere specialiserede modeller, der arbejder sammen på edge-hardware
11. **MCP Integrationssystem**: Byg et agentbaseret system ved hjælp af Model Context Protocol til værktøjsinteraktion

## Referencer

- Microsoft Learn (Foundry Local)
  - Oversigt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Kom godt i gang: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI reference: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrer med inferens-SDK'er: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI vejledning: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompiler Hugging Face modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Oversigt: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agenter (oversigt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimerings- og inferensværktøjer
  - Microsoft Olive (dokumentation): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (kom godt i gang): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokumentation): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokumentation): https://ml-explore.github.io/mlx/build/html/index.html
- Implementeringsrammer og modeller
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokumentation): https://docs.vllm.ai/
  - Ollama (kom godt i gang): https://github.com/ollama/ollama#get-started
- Udviklerværktøjer (Windows og VS Code)
  - AI Toolkit til VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (oversigt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Læringsfællesskab

Deltag i diskussionen og forbind med andre lærende:
- GitHub Diskussioner på [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Konklusion

EdgeAI repræsenterer frontlinjen inden for implementering af kunstig intelligens, hvor kraftfulde funktioner bringes direkte til enheder, samtidig med at vigtige bekymringer om privatliv, latenstid og forbindelsesproblemer adresseres. Dette 20-timers kursus giver dig den nødvendige viden og praktiske færdigheder til straks at begynde at arbejde med EdgeAI-teknologier.

Kurset er bevidst kortfattet og fokuseret på de vigtigste koncepter, så du hurtigt kan opnå værdifuld ekspertise uden en overvældende tidsforpligtelse. Husk, at praktisk øvelse, selv med enkle eksempler, er nøglen til at styrke det, du har lært.

God læring!

---

