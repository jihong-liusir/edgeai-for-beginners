<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T08:57:16+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "sv"
}
-->
# EdgeAI för Nybörjare: Studievägar och Studieplan

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduktion till EdgeAI | 1-2 timmar |
| Dag 1 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 2 | Modul 2: SLM Grunder | 3 timmar |
| Dag 3 | Modul 3: SLM Implementering | 2 timmar |
| Dag 4-5 | Modul 4: Modelloptimering (6 ramverk) | 4 timmar |
| Dag 6 | Modul 5: SLMOps | 3 timmar |
| Dag 7 | Modul 6-7: AI-agenter & Utvecklingsverktyg | 4 timmar |
| Dag 8 | Modul 8: Foundry Local Toolkit (Modern Implementering) | 1 timme |

### Intensiv Studieväg (2 veckor)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: AI-agenter | 2 timmar |
| Dag 13-14 | Modul 7: Utvecklingsverktyg | 3 timmar |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM Grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Implementering & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduktion till EdgeAI | 1-2 timmar |
| Dag 1-2 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: SLM Agentiska System | 2 timmar |
| Dag 13-14 | Modul 7: EdgeAI Implementeringsprover | 2 timmar |

| Modul | Slutdatum | Timmar Spenderade | Viktiga Insikter |
|--------|----------------|-------------|--------------|
| Modul 0: Introduktion till EdgeAI | | | |
| Modul 1: EdgeAI Grunder | | | |
| Modul 2: SLM Grunder | | | |
| Modul 3: SLM Implementering | | | |
| Modul 4: Modelloptimering (6 ramverk) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiska System | | | |
| Modul 7: EdgeAI Implementeringsprover | | | |
| Praktiska Övningar | | | |
| Mini-projekt | | | |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM Grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Implementering & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

## Introduktion

Välkommen till studieguiden för EdgeAI för Nybörjare! Detta dokument är utformat för att hjälpa dig navigera kursmaterialet effektivt och maximera din lärandeupplevelse. Det innehåller strukturerade studievägar, föreslagna studieplaner, sammanfattningar av nyckelkoncept och kompletterande resurser för att fördjupa din förståelse av EdgeAI-teknologier.

Detta är en koncentrerad 20-timmars kurs som ger grundläggande kunskaper om EdgeAI i ett tidseffektivt format, vilket gör den perfekt för upptagna yrkesverksamma och studenter som snabbt vill få praktiska färdigheter inom detta framväxande område.

## Kursöversikt

Kursen är organiserad i åtta omfattande moduler:

0. **Introduktion till EdgeAI** - Grundläggande och kontext med branschapplikationer och lärandemål  
1. **EdgeAI Grunder och Transformation** - Förstå kärnkoncept och teknologiskift  
2. **Grunder för Små Språkmodeller (SLM)** - Utforska olika SLM-familjer och deras arkitekturer  
3. **Implementering av Små Språkmodeller** - Praktiska implementeringsstrategier  
4. **Modellformatkonvertering och Kvantisering** - Avancerad optimering med 6 ramverk inklusive OpenVINO  
5. **SLMOps - Drift av Små Språkmodeller** - Produktionslivscykelhantering och implementering  
6. **SLM Agentiska System** - AI-agenter, funktionsanrop och Model Context Protocol  
7. **EdgeAI Implementeringsprover** - AI Toolkit, Windows-utveckling och plattformspecifika implementeringar  
8. **Microsoft Foundry Local – Komplett Utvecklingsverktyg** - Lokal-först utveckling med hybrid Azure-integration (Modul 08)

## Hur du Använder Studieguiden

- **Progressivt Lärande**: Följ modulerna i ordning för den mest sammanhängande lärandeupplevelsen  
- **Kunskapskontroller**: Använd självbedömningsfrågorna efter varje avsnitt  
- **Praktisk Övning**: Slutför de föreslagna övningarna för att förstärka teoretiska koncept  
- **Kompletterande Resurser**: Utforska ytterligare material för ämnen som intresserar dig mest  

## Rekommenderade Studieplaner

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduktion till EdgeAI | 1-2 timmar |
| Dag 1-2 | Modul 1: EdgeAI Grunder | 6 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 8 timmar |
| Dag 5 | Modul 3: SLM Implementering | 3 timmar |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timmar |

### Deltidsstudier (3 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 0: Introduktion + Modul 1: EdgeAI Grunder | 7-9 timmar |
| Vecka 2 | Modul 2: SLM Grunder | 7-8 timmar |
| Vecka 3 | Modul 3: SLM Implementering (3h) + Modul 8: Foundry Local Toolkit (2-3h) | 5-6 timmar |

## Modul 0: Introduktion till EdgeAI

### Viktiga Lärandemål

- Förstå vad EdgeAI är och varför det är viktigt i dagens teknologilandskap  
- Identifiera stora industrier som har transformerats av EdgeAI och deras specifika användningsområden  
- Förstå fördelarna med Små Språkmodeller (SLM) för implementering vid kanten  
- Etablera tydliga lärandeförväntningar och resultat för hela kursen  
- Känna till karriärmöjligheter och kompetenskrav inom EdgeAI-området  

### Studieområden

#### Avsnitt 1: EdgeAI Paradigm och Definition
- **Prioriterade Koncept**:  
  - EdgeAI vs. traditionell molnbaserad AI-bearbetning  
  - Konvergensen av hårdvara, modelloptimering och affärsbehov  
  - Realtids-, integritetsbevarande och kostnadseffektiv AI-implementering  

#### Avsnitt 2: Industriella Applikationer
- **Prioriterade Koncept**:  
  - Tillverkning & Industri 4.0: Prediktivt underhåll och kvalitetskontroll  
  - Hälsovård: Diagnostisk bildbehandling och patientövervakning  
  - Autonoma System: Självkörande fordon och transport  
  - Smarta Städer: Trafikhantering och offentlig säkerhet  
  - Konsumentteknologi: Smartphones, wearables och smarta hem  

#### Avsnitt 3: Grunder för Små Språkmodeller
- **Prioriterade Koncept**:  
  - SLM-egenskaper och prestandajämförelser  
  - Effektivitet i parametrar kontra kapabilitet  
  - Begränsningar och optimeringsstrategier för implementering vid kanten  

#### Avsnitt 4: Lärandestruktur och Karriärväg
- **Prioriterade Koncept**:  
  - Kursarkitektur och progressiv mästringsmetod  
  - Tekniska färdigheter och praktiska implementeringsmål  
  - Karriärutvecklingsmöjligheter och industriella applikationer  

### Självbedömningsfrågor

1. Vilka är de tre huvudsakliga teknologiska trenderna som möjliggjort EdgeAI?  
2. Jämför fördelarna och utmaningarna med EdgeAI kontra molnbaserad AI.  
3. Nämn tre industrier där EdgeAI ger kritiskt affärsvärde och förklara varför.  
4. Hur gör Små Språkmodeller EdgeAI praktiskt för verkliga implementeringar?  
5. Vilka är de viktigaste tekniska färdigheterna du kommer att utveckla under kursen?  
6. Beskriv den fyrfasiga lärandemetoden som används i kursen.  

### Praktiska Övningar

1. **Industriell Forskning**: Välj en industriell applikation och undersök en verklig EdgeAI-implementering (30 minuter)  
2. **Modellutforskning**: Bläddra bland tillgängliga Små Språkmodeller på Hugging Face och jämför deras parameterantal och kapabiliteter (30 minuter)  
3. **Lärandeplanering**: Granska hela kursstrukturen och skapa din personliga studieplan (15 minuter)  

### Kompletterande Material

- [EdgeAI Marknadsöversikt - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Översikt över Små Språkmodeller - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Edge Computing Foundation](https://www.edgecomputing.org/)  

## Modul 1: EdgeAI Grunder och Transformation

### Viktiga Lärandemål

- Förstå skillnaderna mellan molnbaserad och kantbaserad AI  
- Bemästra kärnoptimeringstekniker för resursbegränsade miljöer  
- Analysera verkliga applikationer av EdgeAI-teknologier  
- Ställa in en utvecklingsmiljö för EdgeAI-projekt  

### Studieområden

#### Avsnitt 1: EdgeAI Grunder
- **Prioriterade Koncept**:  
  - Paradigmer för kant kontra molnbaserad databehandling  
  - Tekniker för modellkvantisering  
  - Hårdvaruaccelerationsalternativ (NPU, GPU, CPU)  
  - Fördelar med integritet och säkerhet  

- **Kompletterande Material**:  
  - [TensorFlow Lite Dokumentation](https://www.tensorflow.org/lite)  
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)  
  - [Edge Impulse Dokumentation](https://docs.edgeimpulse.com)  

#### Avsnitt 2: Verkliga Fallstudier
- **Prioriterade Koncept**:  
  - Microsoft Phi & Mu modell-ekosystem  
  - Praktiska implementeringar över industrier  
  - Implementeringsöverväganden  

#### Avsnitt 3: Praktisk Implementeringsguide
- **Prioriterade Koncept**:  
  - Inställning av utvecklingsmiljö  
  - Verktyg för kvantisering och optimering  
  - Bedömningsmetoder för EdgeAI-implementeringar  

#### Avsnitt 4: Hårdvara för Kantimplementering
- **Prioriterade Koncept**:  
  - Jämförelser av hårdvaruplattformar  
  - Optimeringsstrategier för specifik hårdvara  
  - Implementeringsöverväganden  

### Självbedömningsfrågor

1. Jämför och kontrastera molnbaserad AI med kantbaserade AI-implementeringar.  
2. Förklara tre nyckeltekniker för att optimera modeller för kantimplementering.  
3. Vilka är de primära fördelarna med att köra AI-modeller vid kanten?  
4. Beskriv processen för att kvantisera en modell och hur det påverkar prestanda.  
5. Förklara hur olika hårdvaruacceleratorer (NPU, GPU, CPU) påverkar EdgeAI-implementering.  

### Praktiska Övningar

1. **Snabb Miljöinställning**: Konfigurera en minimal utvecklingsmiljö med de nödvändiga paketen (30 minuter)  
2. **Modellutforskning**: Ladda ner och undersök en förtränad liten språkmodell (1 timme)  
3. **Grundläggande Kvantisering**: Testa enkel kvantisering på en liten modell (1 timme)  

## Modul 2: Grunder för Små Språkmodeller

### Viktiga Lärandemål

- Förstå de arkitektoniska principerna för olika SLM-familjer  
- Jämföra modellkapabiliteter över olika parameterstorlekar  
- Utvärdera modeller baserat på effektivitet, kapabilitet och implementeringskrav  
- Känna igen lämpliga användningsområden för olika modelfamiljer  

### Studieområden

#### Avsnitt 1: Microsoft Phi Modelfamilj
- **Prioriterade Koncept**:  
  - Designfilosofins utveckling  
  - Effektivitet-först arkitektur  
  - Specialiserade kapabiliteter  

#### Avsnitt 2: Qwen Familj
- **Prioriterade Koncept**:  
  - Öppen källkod bidrag  
  - Skalbara implementeringsalternativ  
  - Avancerad resonemangsarkitektur  

#### Avsnitt 3: Gemma Familj
- **Prioriterade Koncept**:  
  - Forskningsdriven innovation  
  - Multimodala kapabiliteter  
  - Optimering för mobila enheter  

#### Avsnitt 4: BitNET Familj
- **Prioriterade Koncept**:  
  - 1-bit kvantiseringsteknik  
  - Ramverk för optimering av inferens  
  - Hållbarhetsöverväganden  

#### Avsnitt 5: Microsoft Mu Modell
- **Prioriterade Koncept**:  
  - Enhets-först arkitektur  
  - Systemintegration med Windows  
  - Integritetsbevarande drift  

#### Avsnitt 6: Phi-Silica
- **Prioriterade Koncept**:  
  - NPU-optimerad arkitektur  
  - Prestandamått  
  - Utvecklarintegration  

### Självbedömningsfrågor

1. Jämför de arkitektoniska tillvägagångssätten för Phi och Qwen modelfamiljer.  
2. Förklara hur BitNET:s kvantiseringsteknik skiljer sig från traditionell kvantisering.  
3. Vilka unika fördelar har Mu-modellen för Windows-integration?  
4. Beskriv hur Phi-Silica utnyttjar NPU-hårdvara för att optimera prestanda.  
5. För en mobilapplikation med begränsad anslutning, vilken modellfamilj skulle vara mest lämplig och varför?  

### Praktiska övningar  

1. **Modelljämförelse**: Snabb benchmark av två olika SLM-modeller (1 timme)  
2. **Enkel textgenerering**: Grundläggande implementering av textgenerering med en liten modell (1 timme)  
3. **Snabb optimering**: Använd en optimeringsteknik för att förbättra inferenshastigheten (1 timme)  

## Modul 3: Implementering av små språkmodeller  

### Viktiga lärandemål  

- Välja lämpliga modeller baserat på implementeringsbegränsningar  
- Behärska optimeringstekniker för olika implementeringsscenarier  
- Implementera SLM:er i både lokala och molnbaserade miljöer  
- Designa produktionsklara konfigurationer för EdgeAI-applikationer  

### Fokusområden för studier  

#### Sektion 1: Avancerad SLM-lärande  
- **Prioriterade koncept**:  
  - Ramverk för parameterklassificering  
  - Avancerade optimeringstekniker  
  - Strategier för modellanskaffning  

#### Sektion 2: Lokal implementering  
- **Prioriterade koncept**:  
  - Implementering på Ollama-plattformen  
  - Microsoft Foundry lokala lösningar  
  - Jämförande analys av ramverk  

#### Sektion 3: Containerbaserad molnimplementering  
- **Prioriterade koncept**:  
  - vLLM för högpresterande inferens  
  - Orkestrering av containrar  
  - Implementering av ONNX Runtime  

### Självbedömningsfrågor  

1. Vilka faktorer bör beaktas vid val mellan lokal och molnbaserad implementering?  
2. Jämför Ollama och Microsoft Foundry Local som implementeringsalternativ.  
3. Förklara fördelarna med containerisering för SLM-implementering.  
4. Vilka är de viktigaste prestandamåtten att övervaka för en SLM som implementeras vid kanten?  
5. Beskriv en komplett implementeringsarbetsflöde från modellval till produktionsimplementering.  

### Praktiska övningar  

1. **Grundläggande lokal implementering**: Implementera en enkel SLM med Ollama (1 timme)  
2. **Prestandakontroll**: Kör en snabb benchmark på din implementerade modell (30 minuter)  
3. **Enkel integration**: Skapa en minimal applikation som använder din implementerade modell (1 timme)  

## Modul 4: Modellformatkonvertering och kvantisering  

### Viktiga lärandemål  

- Behärska avancerade kvantiseringstekniker från 1-bit till 8-bitars precision  
- Förstå strategier för formatkonvertering (GGUF, ONNX)  
- Implementera optimering över sex ramverk (Llama.cpp, Olive, OpenVINO, MLX, arbetsflödessyntes)  
- Implementera optimerade modeller för produktionsmiljöer vid kanten på Intel-, Apple- och plattformsoberoende hårdvara  

### Fokusområden för studier  

#### Sektion 1: Grunderna i kvantisering  
- **Prioriterade koncept**:  
  - Ramverk för precisionsklassificering  
  - Avvägning mellan prestanda och noggrannhet  
  - Optimering av minnesanvändning  

#### Sektion 2: Implementering med Llama.cpp  
- **Prioriterade koncept**:  
  - Plattformsoberoende implementering  
  - Optimering av GGUF-format  
  - Tekniker för hårdvaruacceleration  

#### Sektion 3: Microsoft Olive Suite  
- **Prioriterade koncept**:  
  - Hårdvaruoptimering  
  - Implementering för företagsklass  
  - Automatiserade optimeringsarbetsflöden  

#### Sektion 4: OpenVINO Toolkit  
- **Prioriterade koncept**:  
  - Optimering för Intel-hårdvara  
  - Neural Network Compression Framework (NNCF)  
  - Plattformsoberoende inferensimplementering  
  - OpenVINO GenAI för implementering av LLM  

#### Sektion 5: Apple MLX Framework  
- **Prioriterade koncept**:  
  - Optimering för Apple Silicon  
  - Enhetlig minnesarkitektur  
  - LoRA finjustering  

#### Sektion 6: Arbetsflödessyntes för Edge AI-utveckling  
- **Prioriterade koncept**:  
  - Enhetlig arbetsflödesarkitektur  
  - Beslutsträd för ramverksval  
  - Validering av produktionsberedskap  
  - Strategier för framtidssäkring  

### Självbedömningsfrågor  

1. Jämför kvantiseringstekniker över olika precisionsnivåer (1-bit till 8-bit).  
2. Förklara fördelarna med GGUF-format för implementering vid kanten.  
3. Hur förbättrar hårdvaruoptimering i Microsoft Olive implementeringseffektiviteten?  
4. Vilka är de viktigaste fördelarna med OpenVINOs NNCF för modellkomprimering?  
5. Beskriv hur Apple MLX utnyttjar enhetlig minnesarkitektur för optimering.  
6. Hur hjälper arbetsflödessyntes vid val av optimala optimeringsramverk?  

### Praktiska övningar  

1. **Modellkvantisering**: Använd olika kvantiseringstekniker på en modell och jämför resultaten (1 timme)  
2. **OpenVINO-optimering**: Använd NNCF för att komprimera en modell för Intel-hårdvara (1 timme)  
3. **Ramverksjämförelse**: Testa samma modell över tre olika optimeringsramverk (1 timme)  
4. **Prestandamätning**: Mäta optimeringens påverkan på inferenshastighet och minnesanvändning (1 timme)  

## Modul 5: SLMOps - Drift av små språkmodeller  

### Viktiga lärandemål  

- Förstå principerna för livscykelhantering inom SLMOps  
- Behärska distillation och finjusteringstekniker för implementering vid kanten  
- Implementera strategier för produktionsimplementering med övervakning  
- Bygga arbetsflöden för drift och underhåll av SLM:er på företagsnivå  

### Fokusområden för studier  

#### Sektion 1: Introduktion till SLMOps  
- **Prioriterade koncept**:  
  - Paradigmskiftet inom AI-drift med SLMOps  
  - Kostnadseffektivitet och integritetsfokuserad arkitektur  
  - Strategisk affärspåverkan och konkurrensfördelar  

#### Sektion 2: Modelldistillation  
- **Prioriterade koncept**:  
  - Tekniker för kunskapsöverföring  
  - Implementering av tvåstegs distillation  
  - Distillation-arbetsflöden med Azure ML  

#### Sektion 3: Finjusteringsstrategier  
- **Prioriterade koncept**:  
  - Parameter-effektiv finjustering (PEFT)  
  - Avancerade metoder med LoRA och QLoRA  
  - Multi-adapter träning och optimering av hyperparametrar  

#### Sektion 4: Produktionsimplementering  
- **Prioriterade koncept**:  
  - Modellkonvertering och kvantisering för produktion  
  - Konfiguration för Foundry Local-implementering  
  - Prestandamätning och kvalitetsvalidering  

### Självbedömningsfrågor  

1. Hur skiljer sig SLMOps från traditionell MLOps?  
2. Förklara fördelarna med modelldistillation för implementering vid kanten.  
3. Vilka är de viktigaste övervägandena för finjustering av SLM:er i resursbegränsade miljöer?  
4. Beskriv en komplett produktionsimplementeringspipeline för Edge AI-applikationer.  

### Praktiska övningar  

1. **Grundläggande distillation**: Skapa en mindre modell från en större lärarmodell (1 timme)  
2. **Finjusteringsexperiment**: Finjustera en modell för ett specifikt område (1 timme)  
3. **Implementeringspipeline**: Sätt upp en grundläggande CI/CD-pipeline för modellimplementering (1 timme)  

## Modul 6: SLM Agentiska system - AI-agenter och funktionsanrop  

### Viktiga lärandemål  

- Bygga intelligenta AI-agenter för Edge-miljöer med små språkmodeller  
- Implementera funktionsanropsmöjligheter med systematiska arbetsflöden  
- Behärska integration av Model Context Protocol (MCP) för standardiserad verktygsinteraktion  
- Skapa sofistikerade agentiska system med minimal mänsklig intervention  

### Fokusområden för studier  

#### Sektion 1: AI-agenter och SLM-grunder  
- **Prioriterade koncept**:  
  - Ramverk för agentklassificering (reflex, modellbaserade, målbaserade, lärande agenter)  
  - Analys av avvägningar mellan SLM och LLM  
  - Designmönster för agenter specifika för Edge-miljöer  
  - Resursoptimering för agenter  

#### Sektion 2: Funktionsanrop i små språkmodeller  
- **Prioriterade koncept**:  
  - Implementering av systematiska arbetsflöden (intentsdetektion, JSON-utdata, extern exekvering)  
  - Plattformsspecifika implementeringar (Phi-4-mini, utvalda Qwen-modeller, Microsoft Foundry Local)  
  - Avancerade exempel (samarbete mellan flera agenter, dynamiskt verktygsval)  
  - Produktionsöverväganden (hastighetsbegränsning, loggning för granskning, säkerhetsåtgärder)  

#### Sektion 3: Integration av Model Context Protocol (MCP)  
- **Prioriterade koncept**:  
  - Protokollarkitektur och lagerdesign  
  - Stöd för flera backend-system (Ollama för utveckling, vLLM för produktion)  
  - Anslutningsprotokoll (STDIO och SSE-lägen)  
  - Verkliga applikationer (webbautomatisering, databehandling, API-integration)  

### Självbedömningsfrågor  

1. Vilka är de viktigaste arkitektoniska övervägandena för AI-agenter vid kanten?  
2. Hur förbättrar funktionsanrop agentens kapabiliteter?  
3. Förklara rollen av Model Context Protocol i agentkommunikation.  

### Praktiska övningar  

1. **Enkel agent**: Bygg en grundläggande AI-agent med funktionsanrop (1 timme)  
2. **MCP-integration**: Implementera MCP i en agentapplikation (30 minuter)  

## Modul 7: EdgeAI-implementeringsprover  

### Viktiga lärandemål  

- Behärska AI Toolkit för Visual Studio Code för omfattande EdgeAI-utvecklingsarbetsflöden  
- Få expertis i Windows AI Foundry-plattformen och NPU-optimeringsstrategier  
- Implementera EdgeAI över flera hårdvaruplattformar och implementeringsscenarier  
- Bygga produktionsklara EdgeAI-applikationer med plattformsspecifika optimeringar  

### Fokusområden för studier  

#### Sektion 1: AI Toolkit för Visual Studio Code  
- **Prioriterade koncept**:  
  - Omfattande Edge AI-utvecklingsmiljö inom VS Code  
  - Modellkatalog och upptäckt för implementering vid kanten  
  - Lokal testning, optimering och utvecklingsarbetsflöden för agenter  
  - Prestandaövervakning och utvärdering för Edge-scenarier  

#### Sektion 2: Windows EdgeAI-utvecklingsguide  
- **Prioriterade koncept**:  
  - Omfattande översikt över Windows AI Foundry-plattformen  
  - Phi Silica API för effektiv NPU-inferens  
  - Datorvisions-API:er för bildbehandling och OCR  
  - Foundry Local CLI för lokal utveckling och testning  

#### Sektion 3: Plattformsspecifika implementeringar  
- **Prioriterade koncept**:  
  - Implementering på NVIDIA Jetson Orin Nano (67 TOPS AI-prestanda)  
  - Mobilapplikationer med .NET MAUI och ONNX Runtime GenAI  
  - Azure EdgeAI-lösningar med hybridarkitektur mellan moln och kant  
  - Optimering av Windows ML med universellt hårdvarustöd  
  - Foundry Local-applikationer med integritetsfokuserad RAG-implementering  

### Självbedömningsfrågor  

1. Hur effektiviserar AI Toolkit arbetsflödet för EdgeAI-utveckling?  
2. Jämför implementeringsstrategier över olika hårdvaruplattformar.  
3. Vilka är fördelarna med Windows AI Foundry för utveckling vid kanten?  
4. Förklara rollen av NPU-optimering i moderna Edge AI-applikationer.  
5. Hur utnyttjar Phi Silica API NPU-hårdvara för att optimera prestanda?  
6. Jämför fördelarna med lokal kontra molnbaserad implementering för integritetskänsliga applikationer.  

### Praktiska övningar  

1. **AI Toolkit-konfiguration**: Konfigurera AI Toolkit och optimera en modell (1 timme)  
2. **Windows AI Foundry**: Bygg en enkel Windows AI-applikation med Phi Silica API (1 timme)  
3. **Plattformsoberoende implementering**: Implementera samma modell på två olika plattformar (1 timme)  
4. **NPU-optimering**: Testa NPU-prestanda med Windows AI Foundry-verktyg (30 minuter)  

## Modul 8: Microsoft Foundry Local – Komplett utvecklingsverktyg (moderniserat)  

### Viktiga lärandemål  

- Installera och konfigurera Foundry Local med modern SDK-integration  
- Implementera avancerade multi-agent-system med koordinator-mönster  
- Bygga intelligenta modellroutrar med automatisk uppgiftsbaserad val  
- Implementera produktionsklara AI-lösningar med omfattande övervakning  
- Integrera med Azure AI Foundry för hybridimplementeringsscenarier  
- Behärska moderna SDK-mönster med FoundryLocalManager och OpenAI-klient  

### Fokusområden för studier  

#### Sektion 1: Modern installation och konfiguration  
- **Prioriterade koncept**:  
  - SDK-integration med FoundryLocalManager  
  - Automatisk tjänstupptäckt och hälsokontroll  
  - Konfigurationsmönster baserade på miljöer  
  - Överväganden för produktionsimplementering  

#### Sektion 2: Avancerade multi-agent-system  
- **Prioriterade koncept**:  
  - Koordinator-mönster med specialistagenter  
  - Specialisering för hämtning, resonemang och exekvering  
  - Mekanismer för feedback-loopar för förbättring  
  - Övervakning av prestanda och statistik  

#### Sektion 3: Intelligenta modellroutrar  
- **Prioriterade koncept**:  
  - Algoritmer för modellval baserade på nyckelord  
  - Stöd för flera modeller (generell, resonemang, kod, kreativ)  
  - Konfiguration med miljövariabler för flexibilitet  
  - Hälsokontroll av tjänster och felhantering  

#### Sektion 4: Produktionsklar implementering  
- **Prioriterade koncept**:  
  - Omfattande felhantering och fallback-mekanismer  
  - Övervakning av förfrågningar och prestandaspårning  
  - Interaktiva Jupyter-notebook-exempel med benchmarks  
  - Integrationsmönster med befintliga applikationer  

### Självbedömningsfrågor  

1. Hur skiljer sig det moderna tillvägagångssättet med FoundryLocalManager från manuella REST-anrop?  
2. Förklara koordinator-mönstret och hur det organiserar specialistagenter.  
3. Hur väljer den intelligenta routern lämpliga modeller baserat på frågeinnehåll?  
4. Vilka är de viktigaste komponenterna i ett produktionsklart AI-agent-system?  
5. Hur implementerar du omfattande hälsokontroll för Foundry Local-tjänster?  
6. Jämför fördelarna med det moderniserade tillvägagångssättet kontra traditionella implementeringsmönster.  

### Praktiska övningar  

1. **Modern SDK-konfiguration**: Konfigurera FoundryLocalManager med automatisk tjänstupptäckt (30 minuter)  
2. **Multi-agent-system**: Kör den avancerade koordinatorn med specialistagenter (30 minuter)  
3. **Intelligent routing**: Testa modellroutern med olika frågetyper (30 minuter)  
4. **Interaktiv utforskning**: Använd Jupyter-notebooks för att utforska avancerade funktioner (45 minuter)  
5. **Produktionsimplementering**: Implementera övervaknings- och felhanteringsmönster (30 minuter)  
6. **Hybridintegration**: Konfigurera fallback-scenarier med Azure AI Foundry (30 minuter)  

## Tidsallokeringsguide  

För att hjälpa dig att få ut det mesta av den 20-timmars kursen, här är en föreslagen fördelning av hur du kan fördela din tid:  

|
| Praktiska övningar | 6 timmar | Praktisk tillämpning av nyckeltekniker |
| Självbedömning | 2 timmar | Testa din förståelse genom frågor och reflektion |
| Mini-projekt | 3 timmar | Använd kunskap för en liten praktisk tillämpning |

### Viktiga fokusområden baserat på tidsbegränsning

**Om du bara har 10 timmar:**
- Slutför Modul 0 (Introduktion) och Modulerna 1, 2 och 3 (grundläggande EdgeAI-koncept)
- Gör minst en praktisk övning per modul
- Fokusera på att förstå kärnkoncepten snarare än detaljer kring implementering

**Om du kan avsätta hela 20 timmar:**
- Slutför alla åtta moduler (inklusive Introduktion)
- Utför viktiga praktiska övningar från varje modul
- Slutför ett mini-projekt från Modul 7
- Utforska minst 2-3 kompletterande resurser

**Om du har mer än 20 timmar:**
- Slutför alla moduler (inklusive Introduktion) med detaljerade övningar
- Bygg flera mini-projekt
- Utforska avancerade optimeringstekniker i Modul 4
- Implementera produktionsdistribution från Modul 5

## Viktiga resurser

Dessa noggrant utvalda resurser ger mest värde för din begränsade studietid:

### Obligatorisk dokumentation
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektiva verktyget för modelloptimering
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Snabbaste sättet att distribuera SLMs lokalt
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referens för en ledande edge-optimerad modell
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattande optimeringsverktyg
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrerad EdgeAI-utvecklingsmiljö
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifik EdgeAI-utvecklingsplattform

### Tidsbesparande verktyg
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Snabb åtkomst och distribution av modeller
- [Gradio](https://www.gradio.app/docs/interface) - Snabb UI-utveckling för AI-demonstrationer
- [Microsoft Olive](https://github.com/microsoft/Olive) - Förenklad modelloptimering
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Ramverk för komprimering av neurala nätverk
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Verktyg för distribution av stora språkmodeller

## Mall för att följa framsteg

Använd denna förenklade mall för att följa din inlärningsprogression genom den 20-timmars kursen:

| Modul | Slutförandedatum | Timmar spenderade | Viktiga insikter |
|-------|------------------|-------------------|------------------|
| Modul 0: Introduktion till EdgeAI | | | |
| Modul 1: EdgeAI-grunder | | | |
| Modul 2: SLM-grunder | | | |
| Modul 3: SLM-distribution | | | |
| Modul 4: Modelloptimering | | | |
| Modul 5: SLMOps | | | |
| Modul 6: AI-agenter | | | |
| Modul 7: Utvecklingsverktyg | | | |
| Modul 8: Foundry Local Toolkit | | | |
| Praktiska övningar | | | |
| Mini-projekt | | | |

## Idéer för mini-projekt

Överväg att slutföra ett av dessa projekt för att öva på EdgeAI-koncept (varje projekt är designat att ta 2-4 timmar):

### Nybörjarprojekt (2-3 timmar vardera)
1. **Edge Text Assistant**: Skapa ett enkelt offline-verktyg för textkomplettering med en liten språkmodell
2. **Dashboard för modelljämförelse**: Bygg en grundläggande visualisering av prestandamått för olika SLMs
3. **Optimeringsexperiment**: Mäta effekten av olika kvantiseringsnivåer på samma basmodell

### Mellannivåprojekt (3-4 timmar vardera)
4. **AI Toolkit Workflow**: Använd VS Code AI Toolkit för att optimera och distribuera en modell från början till slut
5. **Windows AI Foundry-applikation**: Skapa en Windows-app med Phi Silica API och NPU-optimering
6. **Plattformsoberoende distribution**: Distribuera samma optimerade modell på Windows (OpenVINO) och mobil (.NET MAUI)
7. **Agent för funktionsanrop**: Bygg en AI-agent med funktionsanropskapacitet för edge-scenarier

### Avancerade integrationsprojekt (4-5 timmar vardera)
8. **OpenVINO-optimeringspipeline**: Implementera komplett modelloptimering med NNCF och GenAI-verktyg
9. **SLMOps-pipeline**: Implementera en komplett modelllivscykel från träning till edge-distribution
10. **Multi-modell edge-system**: Distribuera flera specialiserade modeller som arbetar tillsammans på edge-hårdvara
11. **MCP-integrationssystem**: Bygg ett agentbaserat system med Model Context Protocol för verktygsinteraktion

## Referenser

- Microsoft Learn (Foundry Local)
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Kom igång: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI-referens: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrera med inferens-SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI hur man gör: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompilera Hugging Face-modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agenter (översikt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimerings- och inferensverktyg
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (kom igång): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html
- Distributionsramverk och modeller
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (docs): https://docs.vllm.ai/
  - Ollama (quick start): https://github.com/ollama/ollama#get-started
- Utvecklingsverktyg (Windows och VS Code)
  - AI Toolkit för VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (översikt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Lärande gemenskap

Gå med i diskussionen och anslut med andra lärande:
- GitHub Discussions på [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Slutsats

EdgeAI representerar frontlinjen för implementering av artificiell intelligens, vilket ger kraftfulla funktioner direkt till enheter samtidigt som viktiga frågor om integritet, latens och anslutning hanteras. Denna 20-timmars kurs ger dig den grundläggande kunskapen och praktiska färdigheter för att börja arbeta med EdgeAI-teknologier omedelbart.

Kursen är medvetet kortfattad och fokuserad på de viktigaste koncepten, vilket gör att du snabbt kan få värdefull expertis utan en överväldigande tidsåtgång. Kom ihåg att praktisk övning, även med enkla exempel, är nyckeln till att förstärka det du har lärt dig.

Lycka till med lärandet!

---

