<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-09T12:42:56+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "sv"
}
-->
# EdgeAI för Nybörjare: Studievägar och Studieplan

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduktion till EdgeAI | 1-2 timmar |
| Dag 1 | Modul 1: EdgeAI-grunder | 3 timmar |
| Dag 2 | Modul 2: SLM-grunder | 3 timmar |
| Dag 3 | Modul 3: SLM-distribution | 2 timmar |
| Dag 4-5 | Modul 4: Modelloptimering (6 ramverk) | 4 timmar |
| Dag 6 | Modul 5: SLMOps | 3 timmar |
| Dag 7 | Modul 6-7: AI-agenter & Utvecklingsverktyg | 4 timmar |
| Dag 8 | Modul 8: Foundry Local Toolkit (Modern Implementering) | 1 timme |

### Intensiv Studieväg (2 veckor)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI-grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM-grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM-distribution | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: AI-agenter | 2 timmar |
| Dag 13-14 | Modul 7: Utvecklingsverktyg | 3 timmar |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM-grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Distribution & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduktion till EdgeAI | 1-2 timmar |
| Dag 1-2 | Modul 1: EdgeAI-grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM-grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM-distribution | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: SLM Agentiska System | 2 timmar |
| Dag 13-14 | Modul 7: EdgeAI Implementeringsprover | 2 timmar |

| Modul | Slutförandedatum | Nedlagd Tid | Viktiga Insikter |
|--------|----------------|-------------|------------------|
| Modul 0: Introduktion till EdgeAI | | | |
| Modul 1: EdgeAI-grunder | | | |
| Modul 2: SLM-grunder | | | |
| Modul 3: SLM-distribution | | | |
| Modul 4: Modelloptimering (6 ramverk) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiska System | | | |
| Modul 7: EdgeAI Implementeringsprover | | | |
| Praktiska Övningar | | | |
| Mini-projekt | | | |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM-grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Distribution & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

## Introduktion

Välkommen till studieguiden "EdgeAI för Nybörjare"! Detta dokument är utformat för att hjälpa dig navigera kursmaterialet effektivt och maximera din inlärningsupplevelse. Det innehåller strukturerade studievägar, föreslagna studieplaner, sammanfattningar av nyckelkoncept och kompletterande resurser för att fördjupa din förståelse av EdgeAI-teknologier.

Detta är en koncentrerad 20-timmars kurs som ger dig grundläggande kunskaper om EdgeAI på ett tidseffektivt sätt, vilket gör den perfekt för upptagna yrkesverksamma och studenter som snabbt vill skaffa sig praktiska färdigheter inom detta framväxande område.

## Kursöversikt

Kursen är organiserad i åtta omfattande moduler:

0. **Introduktion till EdgeAI** - Grundläggande förståelse och kontext med branschtillämpningar och lärandemål  
1. **EdgeAI-grunder och Transformation** - Förstå kärnkoncept och teknologiskift  
2. **Grunder för Små Språkmodeller (SLM)** - Utforska olika SLM-familjer och deras arkitekturer  
3. **Distribution av Små Språkmodeller** - Implementera praktiska distributionsstrategier  
4. **Modellformatkonvertering och Kvantisering** - Avancerad optimering med 6 ramverk inklusive OpenVINO  
5. **SLMOps - Drift av Små Språkmodeller** - Produktionslivscykelhantering och distribution  
6. **SLM Agentiska System** - AI-agenter, funktionsanrop och Model Context Protocol  
7. **EdgeAI Implementeringsprover** - AI-verktyg, Windows-utveckling och plattformsspecifika implementationer  
8. **Microsoft Foundry Local – Komplett Utvecklingsverktyg** - Lokal-först utveckling med hybrid Azure-integration (Modul 08)

## Hur du Använder Denna Studievägledning

- **Progressiv Inlärning**: Följ modulerna i ordning för en sammanhängande inlärningsupplevelse  
- **Kunskapskontroller**: Använd självbedömningsfrågorna efter varje avsnitt  
- **Praktiska Övningar**: Slutför de föreslagna övningarna för att förstärka teoretiska koncept  
- **Kompletterande Resurser**: Utforska ytterligare material för ämnen som intresserar dig mest  

## Rekommendationer för Studieplan

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 0 | Modul 0: Introduktion till EdgeAI | 1-2 timmar |
| Dag 1-2 | Modul 1: EdgeAI-grunder | 6 timmar |
| Dag 3-4 | Modul 2: SLM-grunder | 8 timmar |
| Dag 5 | Modul 3: SLM-distribution | 3 timmar |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timmar |

### Deltidsstudier (3 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 0: Introduktion + Modul 1: EdgeAI-grunder | 7-9 timmar |
| Vecka 2 | Modul 2: SLM-grunder | 7-8 timmar |
| Vecka 3 | Modul 3: SLM-distribution (3h) + Modul 8: Foundry Local Toolkit (2-3h) | 5-6 timmar |

## Modul 0: Introduktion till EdgeAI

### Viktiga Lärandemål

- Förstå vad EdgeAI är och varför det är viktigt i dagens teknologilandskap  
- Identifiera stora industrier som transformerats av EdgeAI och deras specifika användningsområden  
- Förstå fördelarna med Små Språkmodeller (SLM) för distribution vid kanten  
- Etablera tydliga lärandeförväntningar och mål för hela kursen  
- Känna igen karriärmöjligheter och kompetenskrav inom EdgeAI-området  

### Fokusområden för Studier

#### Avsnitt 1: EdgeAI Paradigm och Definition
- **Prioriterade Koncept**:  
  - EdgeAI vs. traditionell molnbaserad AI-bearbetning  
  - Konvergensen mellan hårdvara, modelloptimering och affärsbehov  
  - Realtids-, integritetsbevarande och kostnadseffektiv AI-distribution  

#### Avsnitt 2: Branschtillämpningar
- **Prioriterade Koncept**:  
  - Tillverkning & Industri 4.0: Prediktivt underhåll och kvalitetskontroll  
  - Hälsovård: Diagnostisk bildbehandling och patientövervakning  
  - Autonoma System: Självkörande fordon och transport  
  - Smarta Städer: Trafikhantering och allmän säkerhet  
  - Konsumentteknologi: Smartphones, wearables och smarta hem  

#### Avsnitt 3: Grunder för Små Språkmodeller
- **Prioriterade Koncept**:  
  - SLM-egenskaper och prestandajämförelser  
  - Avvägningar mellan parameter-effektivitet och kapabilitet  
  - Begränsningar och optimeringsstrategier för distribution vid kanten  

#### Avsnitt 4: Läranderamverk och Karriärväg
- **Prioriterade Koncept**:  
  - Kursens struktur och progressiva inlärningsmetod  
  - Tekniska färdigheter och praktiska implementeringsmål  
  - Karriärutvecklingsmöjligheter och branschtillämpningar  

### Självbedömningsfrågor

1. Vilka är de tre huvudsakliga teknologiska trenderna som möjliggjort EdgeAI?  
2. Jämför fördelarna och utmaningarna med EdgeAI kontra molnbaserad AI.  
3. Nämn tre industrier där EdgeAI ger kritiskt affärsvärde och förklara varför.  
4. Hur gör Små Språkmodeller EdgeAI praktiskt för verkliga tillämpningar?  
5. Vilka är de viktigaste tekniska färdigheterna du kommer att utveckla under denna kurs?  
6. Beskriv den fyrfasiga inlärningsmetoden som används i kursen.  

### Praktiska Övningar

1. **Branschforskning**: Välj en branschtillämpning och undersök en verklig EdgeAI-implementering (30 minuter)  
2. **Modellutforskning**: Bläddra bland tillgängliga Små Språkmodeller på Hugging Face och jämför deras parameterantal och kapabiliteter (30 minuter)  
3. **Planering av Inlärning**: Granska kursens struktur och skapa din personliga studieplan (15 minuter)  

### Kompletterande Material

- [EdgeAI Marknadsöversikt - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Översikt över Små Språkmodeller - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Edge Computing Foundation](https://www.edgecomputing.org/)  

## Modul 1: EdgeAI-grunder och Transformation

### Viktiga Lärandemål

- Förstå skillnaderna mellan molnbaserad och kantbaserad AI  
- Bemästra kärnoptimeringstekniker för resursbegränsade miljöer  
- Analysera verkliga tillämpningar av EdgeAI-teknologier  
- Ställa in en utvecklingsmiljö för EdgeAI-projekt  

### Fokusområden för Studier

#### Avsnitt 1: EdgeAI-grunder
- **Prioriterade Koncept**:  
  - Edge vs. Moln-datorparadigm  
  - Tekniker för modellkvantisering  
  - Hårdvaruacceleration (NPUs, GPUs, CPUs)  
  - Fördelar med integritet och säkerhet  

- **Kompletterande Material**:  
  - [TensorFlow Lite Dokumentation](https://www.tensorflow.org/lite)  
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)  
  - [Edge Impulse Dokumentation](https://docs.edgeimpulse.com)  

#### Avsnitt 2: Verkliga Fallstudier
- **Prioriterade Koncept**:  
  - Microsoft Phi & Mu-modellens ekosystem  
  - Praktiska implementationer över olika industrier  
  - Distributionsöverväganden  

#### Avsnitt 3: Praktisk Implementeringsguide
- **Prioriterade Koncept**:  
  - Inställning av utvecklingsmiljö  
  - Verktyg för kvantisering och optimering  
  - Bedömningsmetoder för EdgeAI-implementationer  

#### Avsnitt 4: Hårdvara för Kantdistribution
- **Prioriterade Koncept**:  
  - Jämförelser mellan hårdvaruplattformar  
  - Optimeringsstrategier för specifik hårdvara  
  - Distributionsöverväganden  

### Självbedömningsfrågor

1. Jämför och kontrastera molnbaserad AI med kantbaserade AI-implementationer.  
2. Förklara tre nyckeltekniker för att optimera modeller för kantdistribution.  
3. Vilka är de primära fördelarna med att köra AI-modeller vid kanten?  
4. Beskriv processen för att kvantisera en modell och hur det påverkar prestandan.  
5. Förklara hur olika hårdvaruacceleratorer (NPUs, GPUs, CPUs) påverkar EdgeAI-distribution.  

### Praktiska Övningar

1. **Snabb Miljöinställning**: Konfigurera en minimal utvecklingsmiljö med nödvändiga paket (30 minuter)  
2. **Modellutforskning**: Ladda ner och undersök en förtränad liten språkmodell (1 timme)  
3. **Grundläggande Kvantisering**: Testa enkel kvantisering på en liten modell (1 timme)  

## Modul 2: Grunder för Små Språkmodeller

### Viktiga Lärandemål

- Förstå de arkitektoniska principerna för olika SLM-familjer  
- Jämföra modellkapabiliteter över olika parameterstorlekar  
- Utvärdera modeller baserat på effektivitet, kapabilitet och distributionskrav  
- Känna igen lämpliga användningsområden för olika modelfamiljer  

### Fokusområden för Studier

#### Avsnitt 1: Microsoft Phi-modellfamilj
- **Prioriterade Koncept**:  
  - Designfilosofins utveckling  
  - Effektivitet-först-arkitektur  
  - Specialiserade kapabiliteter  

#### Avsnitt 2: Qwen-familjen
- **Prioriterade Koncept**:  
  - Bidrag från öppen källkod  
  - Skalbara distributionsalternativ  
  - Avancerad resonemangsarkitektur  

#### Avsnitt 3: Gemma-familjen
- **Prioriterade Koncept**:  
  - Forskningsdriven innovation  
  - Multimodala kapabiliteter  
  - Mobiloptimering  

#### Avsnitt 4: BitNET-familjen
- **Prioriterade Koncept**:  
  - 1-bit kvantiseringsteknik  
  - Optimeringsramverk för inferens  
  - Hållbarhetsöverväganden  

#### Avsnitt 5: Microsoft Mu-modell
- **Prioriterade Koncept**:  
  - Enhets-först-arkitektur  
  - Systemintegration med Windows  
  - Integritetsbevarande drift  

#### Avsnitt 6: Phi-Silica
- **Prioriterade Koncept**:  
  - NPU-optimerad arkitektur  
  - Prestandamått  
  - Utvecklarintegration  

### Självbedömningsfrågor

1. Jämför de arkitektoniska tillvägagångssätten för Phi- och Qwen-modellfamiljerna.  
2. Förklara hur BitNET:s kvantiseringsteknik skiljer sig från traditionell kvantisering.  
3. Vilka är de unika fördelarna med Mu-modellen för Windows-integration?  
4. Beskriv hur Phi-Silica utnyttjar NPU-hårdvara för att optimera prestanda.  
5. För en mobilapplikation med begränsad uppkoppling, vilken modellfamilj skulle vara mest lämplig och varför?  

### Praktiska Övningar  

1. **Modelljämförelse**: Snabb benchmark av två olika SLM-modeller (1 timme)  
2. **Enkel Textgenerering**: Grundläggande implementering av textgenerering med en liten modell (1 timme)  
3. **Snabb Optimering**: Använd en optimeringsteknik för att förbättra inferenshastigheten (1 timme)  

## Modul 3: Implementering av Små Språkmodeller  

### Centrala Lärandemål  

- Välja lämpliga modeller baserat på implementeringsbegränsningar  
- Behärska optimeringstekniker för olika implementeringsscenarier  
- Implementera SLM:er både lokalt och i molnmiljöer  
- Designa produktionsklara konfigurationer för EdgeAI-applikationer  

### Studiemål  

#### Avsnitt 1: Avancerad Inlärning av SLM  
- **Prioriterade Koncept**:  
  - Ramverk för parameterklassificering  
  - Avancerade optimeringstekniker  
  - Strategier för modellanskaffning  

#### Avsnitt 2: Lokal Implementering  
- **Prioriterade Koncept**:  
  - Implementering på Ollama-plattformen  
  - Lokala lösningar med Microsoft Foundry  
  - Jämförande analys av ramverk  

#### Avsnitt 3: Containeriserad Molnimplementering  
- **Prioriterade Koncept**:  
  - vLLM högpresterande inferens  
  - Containerorkestrering  
  - Implementering av ONNX Runtime  

### Självutvärderingsfrågor  

1. Vilka faktorer bör beaktas vid val mellan lokal implementering och molnimplementering?  
2. Jämför Ollama och Microsoft Foundry Local som implementeringsalternativ.  
3. Förklara fördelarna med containerisering för SLM-implementering.  
4. Vilka är de viktigaste prestandamåtten att övervaka för en SLM som implementeras vid kanten?  
5. Beskriv ett komplett implementeringsflöde från modellval till produktionsimplementering.  

### Praktiska Övningar  

1. **Grundläggande Lokal Implementering**: Implementera en enkel SLM med Ollama (1 timme)  
2. **Prestandakontroll**: Kör en snabb benchmark på din implementerade modell (30 minuter)  
3. **Enkel Integration**: Skapa en minimal applikation som använder din implementerade modell (1 timme)  

## Modul 4: Modellformatkonvertering och Kvantisering  

### Centrala Lärandemål  

- Behärska avancerade kvantiseringstekniker från 1-bit till 8-bitars precision  
- Förstå strategier för formatkonvertering (GGUF, ONNX)  
- Implementera optimering över sex olika ramverk (Llama.cpp, Olive, OpenVINO, MLX, arbetsflödessyntes)  
- Implementera optimerade modeller för produktionsmiljöer vid kanten på Intel, Apple och plattformsoberoende hårdvara  

### Studiemål  

#### Avsnitt 1: Grunder i Kvantisering  
- **Prioriterade Koncept**:  
  - Ramverk för precisionsklassificering  
  - Avvägningar mellan prestanda och noggrannhet  
  - Optimering av minnesanvändning  

#### Avsnitt 2: Implementering av Llama.cpp  
- **Prioriterade Koncept**:  
  - Plattformsoberoende implementering  
  - Optimering av GGUF-format  
  - Tekniker för hårdvaruacceleration  

#### Avsnitt 3: Microsoft Olive Suite  
- **Prioriterade Koncept**:  
  - Hårdvaruanpassad optimering  
  - Implementering för företagsklass  
  - Automatiserade optimeringsarbetsflöden  

#### Avsnitt 4: OpenVINO Toolkit  
- **Prioriterade Koncept**:  
  - Optimering för Intel-hårdvara  
  - Neural Network Compression Framework (NNCF)  
  - Plattformsoberoende inferensimplementering  
  - OpenVINO GenAI för LLM-implementering  

#### Avsnitt 5: Apple MLX Framework  
- **Prioriterade Koncept**:  
  - Optimering för Apple Silicon  
  - Enhetlig minnesarkitektur  
  - LoRA finjustering  

#### Avsnitt 6: Arbetsflödessyntes för Edge AI-utveckling  
- **Prioriterade Koncept**:  
  - Enhetlig arbetsflödesarkitektur  
  - Beslutsträd för val av ramverk  
  - Validering av produktionsberedskap  
  - Strategier för framtidssäkring  

### Självutvärderingsfrågor  

1. Jämför kvantiseringstekniker över olika precisionsnivåer (1-bit till 8-bit).  
2. Förklara fördelarna med GGUF-format för implementering vid kanten.  
3. Hur förbättrar hårdvaruanpassad optimering i Microsoft Olive implementeringseffektiviteten?  
4. Vilka är de viktigaste fördelarna med OpenVINOs NNCF för modellkomprimering?  
5. Beskriv hur Apple MLX utnyttjar enhetlig minnesarkitektur för optimering.  
6. Hur hjälper arbetsflödessyntes till att välja optimala optimeringsramverk?  

### Praktiska Övningar  

1. **Modellkvantisering**: Använd olika kvantiseringsnivåer på en modell och jämför resultaten (1 timme)  
2. **OpenVINO Optimering**: Använd NNCF för att komprimera en modell för Intel-hårdvara (1 timme)  
3. **Ramverksjämförelse**: Testa samma modell över tre olika optimeringsramverk (1 timme)  
4. **Prestandabenchmarking**: Mät optimeringens påverkan på inferenshastighet och minnesanvändning (1 timme)  

## Modul 5: SLMOps - Drift av Små Språkmodeller  

### Centrala Lärandemål  

- Förstå principerna för livscykelhantering inom SLMOps  
- Behärska destillation och finjusteringstekniker för implementering vid kanten  
- Implementera strategier för produktionsimplementering med övervakning  
- Bygga företagsklassade arbetsflöden för drift och underhåll av SLM  

### Studiemål  

#### Avsnitt 1: Introduktion till SLMOps  
- **Prioriterade Koncept**:  
  - Paradigmskiftet SLMOps inom AI-drift  
  - Kostnadseffektivitet och integritetsfokuserad arkitektur  
  - Strategisk affärspåverkan och konkurrensfördelar  

#### Avsnitt 2: Modelldestillation  
- **Prioriterade Koncept**:  
  - Tekniker för kunskapsöverföring  
  - Implementering av tvåstegs destillationsprocess  
  - Destillationsarbetsflöden med Azure ML  

#### Avsnitt 3: Finjusteringsstrategier  
- **Prioriterade Koncept**:  
  - Parameter-effektiv finjustering (PEFT)  
  - Avancerade metoder som LoRA och QLoRA  
  - Multi-adapter träning och hyperparameteroptimering  

#### Avsnitt 4: Produktionsimplementering  
- **Prioriterade Koncept**:  
  - Modellkonvertering och kvantisering för produktion  
  - Konfiguration av Foundry Local-implementering  
  - Prestandabenchmarking och kvalitetsvalidering  

### Självutvärderingsfrågor  

1. Hur skiljer sig SLMOps från traditionell MLOps?  
2. Förklara fördelarna med modelldestillation för implementering vid kanten.  
3. Vilka är de viktigaste övervägandena för finjustering av SLM:er i resursbegränsade miljöer?  
4. Beskriv ett komplett produktionsimplementeringsflöde för EdgeAI-applikationer.  

### Praktiska Övningar  

1. **Grundläggande Destillation**: Skapa en mindre modell från en större lärarmodell (1 timme)  
2. **Finjusteringsexperiment**: Finjustera en modell för ett specifikt område (1 timme)  
3. **Implementeringspipeline**: Sätt upp en grundläggande CI/CD-pipeline för modellimplementering (1 timme)  

## Modul 6: SLM Agentiska System - AI-agenter och Funktionsanrop  

### Centrala Lärandemål  

- Bygga intelligenta AI-agenter för kantmiljöer med Små Språkmodeller  
- Implementera funktionsanropsmöjligheter med systematiska arbetsflöden  
- Behärska integration av Model Context Protocol (MCP) för standardiserad verktygsinteraktion  
- Skapa sofistikerade agentiska system med minimal mänsklig inblandning  

### Studiemål  

#### Avsnitt 1: AI-agenter och SLM-grunder  
- **Prioriterade Koncept**:  
  - Ramverk för agentklassificering (reflex, modellbaserade, målorienterade, lärande agenter)  
  - Analys av avvägningar mellan SLM och LLM  
  - Designmönster för kantanpassade agenter  
  - Resursoptimering för agenter  

#### Avsnitt 2: Funktionsanrop i Små Språkmodeller  
- **Prioriterade Koncept**:  
  - Implementering av systematiska arbetsflöden (avsiktsdetektering, JSON-utdata, extern exekvering)  
  - Plattformsspecifika implementeringar (Phi-4-mini, utvalda Qwen-modeller, Microsoft Foundry Local)  
  - Avancerade exempel (samarbete mellan flera agenter, dynamiskt verktygsval)  
  - Produktionsöverväganden (hastighetsbegränsning, loggning, säkerhetsåtgärder)  

#### Avsnitt 3: Integration av Model Context Protocol (MCP)  
- **Prioriterade Koncept**:  
  - Protokollarkitektur och lagerbaserad systemdesign  
  - Stöd för flera backend-lösningar (Ollama för utveckling, vLLM för produktion)  
  - Anslutningsprotokoll (STDIO och SSE-lägen)  
  - Verkliga tillämpningar (webbautomatisering, databehandling, API-integration)  

### Självutvärderingsfrågor  

1. Vilka är de viktigaste arkitektoniska övervägandena för kant-AI-agenter?  
2. Hur förbättrar funktionsanrop agenternas kapacitet?  
3. Förklara Model Context Protocols roll i agentkommunikation.  

### Praktiska Övningar  

1. **Enkel Agent**: Bygg en grundläggande AI-agent med funktionsanrop (1 timme)  
2. **MCP-integration**: Implementera MCP i en agentapplikation (30 minuter)  

## Workshop: Praktisk Inlärningsväg  

### Centrala Lärandemål  

- Bygga produktionsklara AI-applikationer med Foundry Local SDK och bästa praxis  
- Implementera omfattande felhantering och användarfeedbackmönster  
- Skapa RAG-pipelines med kvalitetsutvärdering och prestandaövervakning  
- Utveckla multi-agent-system med koordinator-mönster  
- Behärska intelligent modellroutning för uppgiftsbaserat modellval  
- Implementera lokala AI-lösningar med integritetsbevarande arkitekturer  

### Studiemål  

#### Session 01: Komma igång med Foundry Local  
- **Prioriterade Koncept**:  
  - Integration av FoundryLocalManager SDK och automatisk tjänstupptäckt  
  - Grundläggande och strömmande chattimplementeringar  
  - Felhanteringsmönster och användarfeedback  
  - Konfiguration baserad på miljö  

#### Session 02: Bygga AI-lösningar med RAG  
- **Prioriterade Koncept**:  
  - In-memory vektorinbäddningar med sentence-transformers  
  - Implementering av RAG-pipeline (hämta → generera)  
  - Kvalitetsutvärdering med RAGAS-mått  
  - Importskydd för valfria beroenden  

#### Session 03: Öppna Källkodsmodeller  
- **Prioriterade Koncept**:  
  - Strategier för benchmarking av flera modeller  
  - Mätning av latens och genomströmning  
  - Smidig nedgradering och felåterhämtning  
  - Prestandajämförelse mellan modellsfamiljer  

#### Session 04: Banbrytande Modeller  
- **Prioriterade Koncept**:  
  - Metodik för jämförelse mellan SLM och LLM  
  - Typindikationer och omfattande utdataformatering  
  - Felhantering per modell  
  - Strukturerade resultat för analys  

#### Session 05: AI-drivna Agenter  
- **Prioriterade Koncept**:  
  - Orkestrering av multi-agenter med koordinator-mönster  
  - Hantering av agentminne och spårning av tillstånd  
  - Felhantering i pipelines och loggning av steg  
  - Prestandaövervakning och statistik  

#### Session 06: Modeller som Verktyg  
- **Prioriterade Koncept**:  
  - Avsiktsdetektering och mönsterigenkänning  
  - Algoritmer för modellroutning baserat på nyckelord  
  - Flerstegspipelines (planera → utföra → förfina)  
  - Omfattande funktionsdokumentation  

### Självutvärderingsfrågor  

1. Hur förenklar FoundryLocalManager tjänstehantering jämfört med manuella REST-anrop?  
2. Förklara vikten av importskydd för valfria beroenden som sentence-transformers.  
3. Vilka strategier säkerställer smidig nedgradering vid benchmarking av flera modeller?  
4. Hur orkestrerar koordinator-mönstret flera specialistagenter?  
5. Beskriv komponenterna i en intelligent modellrouter.  
6. Vilka är de viktigaste elementen i produktionsklar felhantering?  

### Praktiska Övningar  

1. **Chattapplikation**: Implementera strömmande chatt med felhantering (45 minuter)  
2. **RAG Pipeline**: Bygg en minimal RAG med kvalitetsutvärdering (1 timme)  
3. **Modellbenchmarking**: Jämför 3+ modeller på prestanda (1 timme)  
4. **Multi-Agent System**: Skapa en koordinator med 2 specialistagenter (1,5 timmar)  
5. **Intelligent Router**: Bygg uppgiftsbaserat modellval (1 timme)  
6. **Produktionsimplementering**: Lägg till övervakning och omfattande felhantering (45 minuter)  

### Tidsallokering  

**Koncentrerad Inlärning (1 vecka)**:  
- Dag 1: Session 01-02 (Chatt + RAG) - 3 timmar  
- Dag 2: Session 03-04 (Benchmarking + Jämförelse) - 3 timmar  
- Dag 3: Session 05-06 (Agenter + Routing) - 3 timmar  
- Dag 4: Praktiska övningar och validering - 2 timmar  

**Deltidsstudier (2 veckor)**:  
- Vecka 1: Sessioner 01-03 (6 timmar totalt)  
- Vecka 2: Sessioner 04-06 + övningar (5 timmar totalt)  

## Modul 7: Exempel på EdgeAI-Implementeringar  

### Centrala Lärandemål  

- Behärska AI Toolkit för Visual Studio Code för omfattande arbetsflöden inom EdgeAI-utveckling  
- Få expertis i Windows AI Foundry-plattformen och NPU-optimeringsstrategier  
- Implementera EdgeAI över flera hårdvaruplattformar och implementeringsscenarier  
- Bygga produktionsklara EdgeAI-applikationer med plattformsspecifika optimeringar  

### Studiemål  

#### Avsnitt 1: AI Toolkit för Visual Studio Code  
- **Prioriterade Koncept**:  
  - Omfattande utvecklingsmiljö för EdgeAI inom VS Code  
  - Modellkatalog och upptäckt för implementering vid kanten  
  - Lokala tester, optimering och arbetsflöden för agentutveckling  
  - Prestandaövervakning och utvärdering för kantscenarier  

#### Avsnitt 2: Windows EdgeAI Utvecklingsguide  
- **Prioriterade Koncept**:  
  - Omfattande översikt av Windows AI Foundry-plattformen  
  - Phi Silica API för effektiv NPU-inferens  
  - Computer Vision API:er för bildbehandling och OCR  
  - Foundry Local CLI för lokal utveckling och testning  

#### Avsnitt 3: Plattformsspecifika Implementeringar  
- **Prioriterade Koncept**:  
  - Implementering på NVIDIA Jetson Orin Nano (67 TOPS AI-prestanda)  
  - Mobilapplikationer med .NET MAUI och ONNX Runtime GenAI  
  - Azure EdgeAI-lösningar med hybridarkitektur för moln och kant  
  - Optimering av Windows ML med universellt hårdvarustöd  
  - Foundry Local-applikationer med integritetsfokuserad RAG-implementering  


4. Förklara rollen av NPU-optimering i moderna Edge AI-applikationer.  
5. Hur utnyttjar Phi Silica API NPU-hårdvara för prestandaoptimering?  
6. Jämför fördelarna med lokal kontra molnbaserad distribution för integritetskänsliga applikationer.  

### Praktiska övningar  

1. **AI Toolkit Setup**: Konfigurera AI Toolkit och optimera en modell (1 timme)  
2. **Windows AI Foundry**: Bygg en enkel Windows AI-applikation med Phi Silica API (1 timme)  
3. **Plattformsoberoende distribution**: Distribuera samma modell på två olika plattformar (1 timme)  
4. **NPU-optimering**: Testa NPU-prestanda med Windows AI Foundry-verktyg (30 minuter)  

## Modul 8: Microsoft Foundry Local – Komplett utvecklarverktyg (Moderniserat)  

### Viktiga lärandemål  

- Installera och konfigurera Foundry Local med modern SDK-integration  
- Implementera avancerade multi-agent-system med koordinator-mönster  
- Bygg intelligenta modellroutrar med automatisk uppgiftsbaserad val  
- Distribuera produktionsklara AI-lösningar med omfattande övervakning  
- Integrera med Azure AI Foundry för hybriddistributionsscenarier  
- Bemästra moderna SDK-mönster med FoundryLocalManager och OpenAI-klient  

### Studiens fokusområden  

#### Sektion 1: Modern installation och konfiguration  
- **Prioriterade koncept**:  
  - FoundryLocalManager SDK-integration  
  - Automatisk tjänstupptäckt och hälsokontroll  
  - Miljöbaserade konfigurationsmönster  
  - Produktionsdistributionsöverväganden  

#### Sektion 2: Avancerade multi-agent-system  
- **Prioriterade koncept**:  
  - Koordinator-mönster med specialistagenter  
  - Specialisering av agenter för hämtning, resonemang och utförande  
  - Feedback-loop-mekanismer för förfining  
  - Prestandaövervakning och statistikspårning  

#### Sektion 3: Intelligent modellrouting  
- **Prioriterade koncept**:  
  - Algoritmer för nyckelordsbaserad modellval  
  - Stöd för flera modeller (generell, resonemang, kod, kreativ)  
  - Miljövariabelkonfiguration för flexibilitet  
  - Hälsokontroll av tjänster och felhantering  

#### Sektion 4: Produktionsklar implementering  
- **Prioriterade koncept**:  
  - Omfattande felhantering och fallback-mekanismer  
  - Begäranövervakning och prestandaspårning  
  - Interaktiva Jupyter-notebook-exempel med benchmarks  
  - Integrationsmönster med befintliga applikationer  

### Självbedömningsfrågor  

1. Hur skiljer sig det moderna FoundryLocalManager-ansatsen från manuella REST-anrop?  
2. Förklara koordinator-mönstret och hur det organiserar specialistagenter.  
3. Hur väljer den intelligenta routern lämpliga modeller baserat på frågeinnehåll?  
4. Vilka är de viktigaste komponenterna i ett produktionsklart AI-agent-system?  
5. Hur implementerar du omfattande hälsokontroll för Foundry Local-tjänster?  
6. Jämför fördelarna med det moderniserade tillvägagångssättet kontra traditionella implementeringsmönster.  

### Praktiska övningar  

1. **Modern SDK-setup**: Konfigurera FoundryLocalManager med automatisk tjänstupptäckt (30 minuter)  
2. **Multi-agent-system**: Kör den avancerade koordinatorn med specialistagenter (30 minuter)  
3. **Intelligent routing**: Testa modellroutern med olika frågetyper (30 minuter)  
4. **Interaktiv utforskning**: Använd Jupyter-notebooks för att utforska avancerade funktioner (45 minuter)  
5. **Produktionsdistribution**: Implementera övervaknings- och felhanteringsmönster (30 minuter)  
6. **Hybridintegration**: Konfigurera Azure AI Foundry fallback-scenarier (30 minuter)  

## Tidsfördelningsguide  

För att hjälpa dig att få ut det mesta av den utökade 30-timmars kursplanen (inklusive workshop), här är en föreslagen fördelning av din tid:  

| Aktivitet | Tidsfördelning | Beskrivning |  
|-----------|----------------|-------------|  
| Läsning av kärnmaterial | 12 timmar | Fokus på de viktigaste koncepten i varje modul |  
| Praktiska övningar | 10 timmar | Praktisk implementering av nyckeltekniker (inklusive workshop) |  
| Självbedömning | 3 timmar | Testa din förståelse genom frågor och reflektion |  
| Mini-projekt | 5 timmar | Tillämpa kunskap på en liten praktisk implementering |  

### Viktiga fokusområden baserat på tidsbegränsning  

**Om du bara har 10 timmar:**  
- Slutför Modul 0 (Introduktion) och Modulerna 1, 2 och 3 (grundläggande EdgeAI-koncept)  
- Gör minst en praktisk övning per modul  
- Fokusera på att förstå kärnkoncept snarare än implementeringsdetaljer  

**Om du kan avsätta hela 20 timmar:**  
- Slutför alla åtta moduler (inklusive introduktion)  
- Utför nyckelövningar från varje modul  
- Slutför ett mini-projekt från Modul 7  
- Utforska minst 2-3 kompletterande resurser  

**Om du har mer än 20 timmar:**  
- Slutför alla moduler (inklusive introduktion) med detaljerade övningar  
- Bygg flera mini-projekt  
- Utforska avancerade optimeringstekniker i Modul 4  
- Implementera produktionsdistribution från Modul 5  

## Viktiga resurser  

Dessa noggrant utvalda resurser ger mest värde för din begränsade studietid:  

### Måste-läsa dokumentation  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektiva verktyget för modelloptimering  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Snabbaste sättet att distribuera SLMs lokalt  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referens för en ledande edge-optimerad modell  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattande optimeringsverktyg  
- [AI Toolkit för VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrerad EdgeAI-utvecklingsmiljö  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifik EdgeAI-utvecklingsplattform  

### Tidsbesparande verktyg  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Snabb åtkomst och distribution av modeller  
- [Gradio](https://www.gradio.app/docs/interface) - Snabb UI-utveckling för AI-demos  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Förenklad modelloptimering  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Ramverk för neurala nätverkskompression  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit för distribution av stora språkmodeller  

## Framstegsspårningsmall  

Använd denna förenklade mall för att spåra din lärande framsteg genom den 20-timmars kursen:  

| Modul | Slutförandedatum | Timmar spenderade | Viktiga insikter |  
|-------|------------------|-------------------|------------------|  
| Modul 0: Introduktion till EdgeAI | | | |  
| Modul 1: EdgeAI-grunder | | | |  
| Modul 2: SLM-grunder | | | |  
| Modul 3: SLM-distribution | | | |  
| Modul 4: Modelloptimering | | | |  
| Modul 5: SLMOps | | | |  
| Modul 6: AI-agenter | | | |  
| Modul 7: Utvecklingsverktyg | | | |  
| Workshop: Praktiskt lärande | | | |  
| Modul 8: Foundry Local Toolkit | | | |  
| Praktiska övningar | | | |  
| Mini-projekt | | | |  

## Mini-projektidéer  

Överväg att slutföra ett av dessa projekt för att öva EdgeAI-koncept (varje designad att ta 2-4 timmar):  

### Nybörjarprojekt (2-3 timmar vardera)  
1. **Edge Text Assistant**: Skapa ett enkelt offline-verktyg för textkomplettering med en liten språkmodell  
2. **Modelljämförelsedashboard**: Bygg en grundläggande visualisering av prestandamått för olika SLMs  
3. **Optimeringsexperiment**: Mäta effekten av olika kvantiseringsnivåer på samma basmodell  

### Mellanliggande projekt (3-4 timmar vardera)  
4. **AI Toolkit Workflow**: Använd VS Code AI Toolkit för att optimera och distribuera en modell från början till slut  
5. **Windows AI Foundry-applikation**: Skapa en Windows-app med Phi Silica API och NPU-optimering  
6. **Plattformsoberoende distribution**: Distribuera samma optimerade modell på Windows (OpenVINO) och mobil (.NET MAUI)  
7. **Funktionskallande agent**: Bygg en AI-agent med funktionskallande kapacitet för edge-scenarier  

### Avancerade integrationsprojekt (4-5 timmar vardera)  
8. **OpenVINO-optimeringspipeline**: Implementera komplett modelloptimering med NNCF och GenAI-toolkit  
9. **SLMOps-pipeline**: Implementera en komplett modelllivscykel från träning till edge-distribution  
10. **Multi-modell edge-system**: Distribuera flera specialiserade modeller som arbetar tillsammans på edge-hårdvara  
11. **MCP-integrationssystem**: Bygg ett agentiskt system med Model Context Protocol för verktygsinteraktion  

## Referenser  

- Microsoft Learn (Foundry Local)  
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Kom igång: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI-referens: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrera med inferens-SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI hur-man-gör: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Kompilera Hugging Face-modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agenter (översikt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimering och inferensverktyg  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (kom igång): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive-integration: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Distributionsramverk och modeller  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (quick start): https://github.com/ollama/ollama#get-started  
- Utvecklarverktyg (Windows och VS Code)  
  - AI Toolkit för VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (översikt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Lärandegemenskap  

Gå med i diskussionen och anslut med andra elever:  
- GitHub-diskussioner på [EdgeAI för nybörjare-repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Slutsats  

EdgeAI representerar gränsen för implementering av artificiell intelligens och erbjuder kraftfulla funktioner direkt till enheter samtidigt som kritiska frågor om integritet, latens och anslutning hanteras. Denna 20-timmars kurs ger dig den grundläggande kunskapen och praktiska färdigheter för att börja arbeta med EdgeAI-teknologier omedelbart.  

Kursen är medvetet koncis och fokuserad på de viktigaste koncepten, vilket gör att du snabbt kan få värdefull expertis utan en överväldigande tidsåtgång. Kom ihåg att praktisk övning, även med enkla exempel, är nyckeln till att förstärka det du har lärt dig.  

Lycka till med lärandet!  

---

**Ansvarsfriskrivning**:  
Detta dokument har översatts med hjälp av AI-översättningstjänsten [Co-op Translator](https://github.com/Azure/co-op-translator). Även om vi strävar efter noggrannhet, vänligen notera att automatiska översättningar kan innehålla fel eller felaktigheter. Det ursprungliga dokumentet på dess originalspråk bör betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell mänsklig översättning. Vi ansvarar inte för eventuella missförstånd eller feltolkningar som uppstår vid användning av denna översättning.