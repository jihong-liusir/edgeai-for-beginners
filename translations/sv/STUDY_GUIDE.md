<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T19:09:56+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "sv"
}
-->
# EdgeAI för Nybörjare: Studievägar och Studieplan

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 2 | Modul 2: SLM Grunder | 3 timmar |
| Dag 3 | Modul 3: SLM Implementering | 2 timmar |
| Dag 4-5 | Modul 4: Modelloptimering (6 ramverk) | 4 timmar |
| Dag 6 | Modul 5: SLMOps | 3 timmar |
| Dag 7 | Modul 6-7: AI-agenter & Utvecklingsverktyg | 5 timmar |

### Intensiv Studieväg (2 veckor)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: AI-agenter | 2 timmar |
| Dag 13-14 | Modul 7: Utvecklingsverktyg | 3 timmar |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM Grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Implementering & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: SLM Agentiska System | 2 timmar |
| Dag 13-14 | Modul 7: EdgeAI Implementerings Exempel | 2 timmar |

| Modul | Slutdatum | Timmar Spenderade | Viktiga Lärdomar |
|--------|----------------|-------------|--------------|
| Modul 1: EdgeAI Grunder | | | |
| Modul 2: SLM Grunder | | | |
| Modul 3: SLM Implementering | | | |
| Modul 4: Modelloptimering (6 ramverk) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiska System | | | |
| Modul 7: EdgeAI Implementerings Exempel | | | |
| Praktiska Övningar | | | |
| Mini-projekt | | | |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM Grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Implementering & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

## Introduktion

Välkommen till studieguiden för EdgeAI för Nybörjare! Den här guiden är utformad för att hjälpa dig att navigera kursmaterialet effektivt och maximera din inlärningsupplevelse. Den innehåller strukturerade studievägar, föreslagna studieplaner, sammanfattningar av nyckelkoncept och kompletterande resurser för att fördjupa din förståelse av EdgeAI-teknologier.

Detta är en koncentrerad kurs på 20 timmar som ger grundläggande kunskaper om EdgeAI på ett tidseffektivt sätt, vilket gör den perfekt för upptagna yrkesverksamma och studenter som snabbt vill få praktiska färdigheter inom detta framväxande område.

## Kursöversikt

Kursen är organiserad i sju omfattande moduler:

1. **EdgeAI Grunder och Transformation** - Förstå kärnkoncept och teknologiskiftet
2. **Grunder för Små Språkmodeller (SLM)** - Utforska olika SLM-familjer och deras arkitekturer
3. **Implementering av Små Språkmodeller** - Praktiska strategier för implementering
4. **Modellformatkonvertering och Kvantisering** - Avancerad optimering med 6 ramverk inklusive OpenVINO
5. **SLMOps - Drift av Små Språkmodeller** - Hantering av produktionslivscykel och implementering
6. **SLM Agentiska System** - AI-agenter, funktionsanrop och Model Context Protocol
7. **EdgeAI Implementerings Exempel** - AI-verktyg, Windows-utveckling och plattformspecifika implementeringar
8. **Microsoft Foundry Local – Komplett Utvecklingsverktyg** - Lokal-först utveckling med hybrid Azure-integration (Modul 08)

## Hur du Använder Denna Studievägledning

- **Progressiv Inlärning**: Följ modulerna i ordning för den mest sammanhängande inlärningsupplevelsen
- **Kunskapskontroller**: Använd självbedömningsfrågorna efter varje avsnitt
- **Praktisk Övning**: Slutför de föreslagna övningarna för att förstärka teoretiska koncept
- **Kompletterande Resurser**: Utforska ytterligare material för ämnen som intresserar dig mest

## Rekommenderade Studieplaner

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|-----------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 6 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 8 timmar |
| Dag 5 | Modul 3: SLM Implementering | 3 timmar |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timmar |

### Deltidsstudier (3 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|-----------------|
| Vecka 1 | Modul 1: EdgeAI Grunder | 6-7 timmar |
| Vecka 2 | Modul 2: SLM Grunder | 7-8 timmar |
| Vecka 3 | Modul 3: SLM Implementering (3h) + Modul 8: Foundry Local Toolkit (2-3h) | 5-6 timmar |

## Modul 1: EdgeAI Grunder och Transformation

### Viktiga Lärandemål

- Förstå skillnaderna mellan molnbaserad och edge-baserad AI
- Behärska kärntekniker för optimering i resursbegränsade miljöer
- Analysera verkliga tillämpningar av EdgeAI-teknologier
- Ställ in en utvecklingsmiljö för EdgeAI-projekt

### Fokusområden för Studier

#### Avsnitt 1: EdgeAI Grunder
- **Prioriterade Koncept**: 
  - Edge vs. molnberäkningsparadigm
  - Tekniker för modellkvantisering
  - Alternativ för hårdvaruacceleration (NPU, GPU, CPU)
  - Fördelar med integritet och säkerhet

- **Kompletterande Material**:
  - [TensorFlow Lite Dokumentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentation](https://docs.edgeimpulse.com)

#### Avsnitt 2: Verkliga Fallstudier
- **Prioriterade Koncept**: 
  - Microsoft Phi & Mu modell-ekosystem
  - Praktiska implementeringar inom olika industrier
  - Implementeringsöverväganden

#### Avsnitt 3: Praktisk Implementeringsguide
- **Prioriterade Koncept**: 
  - Inställning av utvecklingsmiljö
  - Verktyg för kvantisering och optimering
  - Bedömningsmetoder för EdgeAI-implementeringar

#### Avsnitt 4: Edge Implementeringshårdvara
- **Prioriterade Koncept**: 
  - Jämförelser mellan hårdvaruplattformar
  - Optimeringsstrategier för specifik hårdvara
  - Implementeringsöverväganden

### Självbedömningsfrågor

1. Jämför och kontrastera molnbaserad AI med edge-baserad AI-implementering.
2. Förklara tre nyckeltekniker för att optimera modeller för edge-implementering.
3. Vilka är de primära fördelarna med att köra AI-modeller på edge?
4. Beskriv processen för att kvantisera en modell och hur det påverkar prestanda.
5. Förklara hur olika hårdvaruacceleratorer (NPU, GPU, CPU) påverkar EdgeAI-implementering.

### Praktiska Övningar

1. **Snabb Miljöinställning**: Konfigurera en minimal utvecklingsmiljö med nödvändiga paket (30 minuter)
2. **Modellutforskning**: Ladda ner och undersök en förtränad liten språkmodell (1 timme)
3. **Grundläggande Kvantisering**: Testa enkel kvantisering på en liten modell (1 timme)

## Modul 2: Grunder för Små Språkmodeller

### Viktiga Lärandemål

- Förstå de arkitektoniska principerna för olika SLM-familjer
- Jämför modellers kapabiliteter över olika parameterstorlekar
- Utvärdera modeller baserat på effektivitet, kapabilitet och implementeringskrav
- Identifiera lämpliga användningsområden för olika modelfamiljer

### Fokusområden för Studier

#### Avsnitt 1: Microsoft Phi Modelfamilj
- **Prioriterade Koncept**: 
  - Designfilosofins utveckling
  - Effektivitet-först arkitektur
  - Specialiserade kapabiliteter

#### Avsnitt 2: Qwen Familj
- **Prioriterade Koncept**: 
  - Bidrag från öppen källkod
  - Skalbara implementeringsalternativ
  - Avancerad resonemangsarkitektur

#### Avsnitt 3: Gemma Familj
- **Prioriterade Koncept**: 
  - Forskningsdriven innovation
  - Multimodala kapabiliteter
  - Optimering för mobila enheter

#### Avsnitt 4: BitNET Familj
- **Prioriterade Koncept**: 
  - 1-bit kvantiseringsteknik
  - Ramverk för optimering av inferens
  - Hållbarhetsöverväganden

#### Avsnitt 5: Microsoft Mu Modell
- **Prioriterade Koncept**: 
  - Enhets-först arkitektur
  - Systemintegration med Windows
  - Integritetsskyddande drift

#### Avsnitt 6: Phi-Silica
- **Prioriterade Koncept**: 
  - NPU-optimerad arkitektur
  - Prestandamått
  - Utvecklarintegration

### Självbedömningsfrågor

1. Jämför de arkitektoniska tillvägagångssätten för Phi och Qwen modelfamiljer.
2. Förklara hur BitNET:s kvantiseringsteknik skiljer sig från traditionell kvantisering.
3. Vilka är de unika fördelarna med Mu-modellen för Windows-integration?
4. Beskriv hur Phi-Silica utnyttjar NPU-hårdvara för prestandaoptimering.
5. För en mobilapplikation med begränsad anslutning, vilken modelfamilj skulle vara mest lämplig och varför?

### Praktiska Övningar

1. **Modelljämförelse**: Snabb benchmark av två olika SLM-modeller (1 timme)
2. **Enkel Textgenerering**: Grundläggande implementering av textgenerering med en liten modell (1 timme)
3. **Snabb Optimering**: Använd en optimeringsteknik för att förbättra inferenshastigheten (1 timme)

## Modul 3: Implementering av Små Språkmodeller

### Viktiga Lärandemål

- Välj lämpliga modeller baserat på implementeringsbegränsningar
- Behärska optimeringstekniker för olika implementeringsscenarier
- Implementera SLM:er i både lokala och molnbaserade miljöer
- Designa produktionsklara konfigurationer för EdgeAI-applikationer

### Fokusområden för Studier

#### Avsnitt 1: SLM Avancerad Inlärning
- **Prioriterade Koncept**: 
  - Ramverk för parameterklassificering
  - Avancerade optimeringstekniker
  - Strategier för modellanskaffning

#### Avsnitt 2: Lokal Miljö Implementering
- **Prioriterade Koncept**: 
  - Ollama plattformsimplementering
  - Microsoft Foundry lokala lösningar
  - Jämförande analys av ramverk

#### Avsnitt 3: Containeriserad Molnimplementering
- **Prioriterade Koncept**: 
  - vLLM högpresterande inferens
  - Containerorkestrering
  - ONNX Runtime implementering

### Självbedömningsfrågor

1. Vilka faktorer bör beaktas vid val mellan lokal implementering och molnimplementering?
2. Jämför Ollama och Microsoft Foundry Local som implementeringsalternativ.
3. Förklara fördelarna med containerisering för SLM-implementering.
4. Vilka är de viktigaste prestandamåtten att övervaka för en edge-implementerad SLM?
5. Beskriv ett komplett implementeringsarbetsflöde från modellval till produktionsimplementering.

### Praktiska Övningar

1. **Grundläggande Lokal Implementering**: Implementera en enkel SLM med Ollama (1 timme)
2. **Prestandakontroll**: Kör en snabb benchmark på din implementerade modell (30 minuter)
3. **Enkel Integration**: Skapa en minimal applikation som använder din implementerade modell (1 timme)

## Modul 4: Modellformatkonvertering och Kvantisering

### Viktiga Lärandemål

- Behärska avancerade kvantiseringstekniker från 1-bit till 8-bit precision
- Förstå strategier för formatkonvertering (GGUF, ONNX)
- Implementera optimering över sex ramverk (Llama.cpp, Olive, OpenVINO, MLX, arbetsflödessyntes)
- Implementera optimerade modeller för produktionsmiljöer på edge för Intel, Apple och plattformsoberoende hårdvara

### Fokusområden för Studier

#### Avsnitt 1: Grunder för Kvantisering
- **Prioriterade Koncept**: 
  - Ramverk för precisionsklassificering
  - Prestanda kontra noggrannhet avvägningar
  - Optimering av minnesanvändning

#### Avsnitt 2: Llama.cpp Implementering
- **Prioriterade Koncept**: 
  - Plattformsoberoende implementering
  - GGUF formatoptimering
  - Tekniker för hårdvaruacceleration

#### Avsnitt 3: Microsoft Olive Suite
- **Prioriterade Koncept**: 
  - Hårdvaruanpassad optimering
  - Implementering i företagsmiljöer
  - Automatiserade optimeringsarbetsflöden

#### Avsnitt 4: OpenVINO Toolkit
- **Prioriterade Koncept**: 
  - Optimering för Intel-hårdvara
  - Neural Network Compression Framework (NNCF)
  - Plattformsoberoende inferensimplementering
  - OpenVINO GenAI för LLM-implementering

#### Avsnitt 5: Apple MLX Ramverk
- **Prioriterade koncept**:  
  - Optimering för Apple Silicon  
  - Enhetlig minnesarkitektur  
  - LoRA-förmåga för finjustering  

#### Avsnitt 6: Sammanställning av arbetsflöde för Edge AI-utveckling  
- **Prioriterade koncept**:  
  - Enhetlig arbetsflödesarkitektur  
  - Beslutsträd för ramverksval  
  - Validering av produktionsberedskap  
  - Strategier för framtidssäkring  

### Självbedömningsfrågor  

1. Jämför kvantiseringsstrategier över olika precisionsnivåer (1-bit till 8-bit).  
2. Förklara fördelarna med GGUF-formatet för edge-distribution.  
3. Hur förbättrar hårdvaruanpassad optimering i Microsoft Olive distributionseffektiviteten?  
4. Vilka är de viktigaste fördelarna med OpenVINOs NNCF för modellkomprimering?  
5. Beskriv hur Apple MLX utnyttjar enhetlig minnesarkitektur för optimering.  
6. Hur hjälper arbetsflödessyntes vid val av optimala optimeringsramverk?  

### Praktiska övningar  

1. **Modellkvantisering**: Applicera olika kvantiseringsnivåer på en modell och jämför resultaten (1 timme)  
2. **OpenVINO-optimering**: Använd NNCF för att komprimera en modell för Intel-hårdvara (1 timme)  
3. **Ramverksjämförelse**: Testa samma modell över tre olika optimeringsramverk (1 timme)  
4. **Prestandamätning**: Mät optimeringens påverkan på inferenshastighet och minnesanvändning (1 timme)  

## Modul 5: SLMOps - Drift av små språkmodeller  

### Viktiga lärandemål  

- Förstå principerna för livscykelhantering inom SLMOps  
- Bemästra distillering och finjusteringstekniker för edge-distribution  
- Implementera strategier för produktionsdistribution med övervakning  
- Bygga arbetsflöden för drift och underhåll av SLM i företagsklass  

### Fokusområden för studier  

#### Avsnitt 1: Introduktion till SLMOps  
- **Prioriterade koncept**:  
  - Paradigmskiftet inom AI-drift med SLMOps  
  - Kostnadseffektivitet och integritetsfokuserad arkitektur  
  - Strategisk affärspåverkan och konkurrensfördelar  

#### Avsnitt 2: Modelldistillering  
- **Prioriterade koncept**:  
  - Tekniker för kunskapsöverföring  
  - Implementering av tvåstegs distilleringsprocess  
  - Distilleringsarbetsflöden med Azure ML  

#### Avsnitt 3: Strategier för finjustering  
- **Prioriterade koncept**:  
  - Parameter-effektiv finjustering (PEFT)  
  - Avancerade metoder med LoRA och QLoRA  
  - Multi-adapterträning och optimering av hyperparametrar  

#### Avsnitt 4: Produktionsdistribution  
- **Prioriterade koncept**:  
  - Modellkonvertering och kvantisering för produktion  
  - Konfiguration för Foundry Local-distribution  
  - Prestandamätning och kvalitetsvalidering  

### Självbedömningsfrågor  

1. Hur skiljer sig SLMOps från traditionell MLOps?  
2. Förklara fördelarna med modelldistillering för edge-distribution.  
3. Vilka är de viktigaste övervägandena vid finjustering av SLM i resursbegränsade miljöer?  
4. Beskriv en komplett produktionsdistributionspipeline för edge AI-applikationer.  

### Praktiska övningar  

1. **Grundläggande distillering**: Skapa en mindre modell från en större lärarmodell (1 timme)  
2. **Finjusteringsexperiment**: Finjustera en modell för ett specifikt område (1 timme)  
3. **Distributionspipeline**: Sätt upp en grundläggande CI/CD-pipeline för modelldistribution (1 timme)  

## Modul 6: SLM Agentiska system - AI-agenter och funktionsanrop  

### Viktiga lärandemål  

- Bygga intelligenta AI-agenter för edge-miljöer med små språkmodeller  
- Implementera funktionsanropsmöjligheter med systematiska arbetsflöden  
- Bemästra integration av Model Context Protocol (MCP) för standardiserad verktygsinteraktion  
- Skapa sofistikerade agentiska system med minimal mänsklig intervention  

### Fokusområden för studier  

#### Avsnitt 1: AI-agenter och SLM-grunder  
- **Prioriterade koncept**:  
  - Ramverk för klassificering av agenter (reflex, modellbaserade, målbaserade, lärande agenter)  
  - Analys av avvägningar mellan SLM och LLM  
  - Designmönster för edge-specifika agenter  
  - Resursoptimering för agenter  

#### Avsnitt 2: Funktionsanrop i små språkmodeller  
- **Prioriterade koncept**:  
  - Implementering av systematiska arbetsflöden (intentsdetektion, JSON-utdata, extern exekvering)  
  - Plattformsspecifika implementationer (Phi-4-mini, utvalda Qwen-modeller, Microsoft Foundry Local)  
  - Avancerade exempel (samarbete mellan flera agenter, dynamiskt verktygsval)  
  - Produktionsöverväganden (hastighetsbegränsning, loggning för granskning, säkerhetsåtgärder)  

#### Avsnitt 3: Integration av Model Context Protocol (MCP)  
- **Prioriterade koncept**:  
  - Protokollarkitektur och lagerdesign  
  - Stöd för flera backend-system (Ollama för utveckling, vLLM för produktion)  
  - Anslutningsprotokoll (STDIO och SSE-lägen)  
  - Verkliga applikationer (webbautomatisering, databehandling, API-integration)  

### Självbedömningsfrågor  

1. Vilka är de viktigaste arkitektoniska övervägandena för edge AI-agenter?  
2. Hur förbättrar funktionsanrop agentens kapabiliteter?  
3. Förklara rollen av Model Context Protocol i agentkommunikation.  

### Praktiska övningar  

1. **Enkel agent**: Bygg en grundläggande AI-agent med funktionsanrop (1 timme)  
2. **MCP-integration**: Implementera MCP i en agentapplikation (30 minuter)  

## Modul 7: Implementeringsprover för EdgeAI  

### Viktiga lärandemål  

- Bemästra AI Toolkit för Visual Studio Code för omfattande arbetsflöden inom EdgeAI-utveckling  
- Få expertis i Windows AI Foundry-plattformen och strategier för NPU-optimering  
- Implementera EdgeAI över flera hårdvaruplattformar och distributionsscenarier  
- Bygga produktionsklara EdgeAI-applikationer med plattformsspecifika optimeringar  

### Fokusområden för studier  

#### Avsnitt 1: AI Toolkit för Visual Studio Code  
- **Prioriterade koncept**:  
  - Omfattande utvecklingsmiljö för Edge AI inom VS Code  
  - Modellkatalog och upptäckt för edge-distribution  
  - Lokala test-, optimerings- och agentutvecklingsarbetsflöden  
  - Prestandaövervakning och utvärdering för edge-scenarier  

#### Avsnitt 2: Windows EdgeAI-utvecklingsguide  
- **Prioriterade koncept**:  
  - Omfattande översikt över Windows AI Foundry-plattformen  
  - Phi Silica API för effektiv NPU-inferens  
  - Datorvisions-API:er för bildbehandling och OCR  
  - Foundry Local CLI för lokal utveckling och testning  

#### Avsnitt 3: Plattformsspecifika implementationer  
- **Prioriterade koncept**:  
  - NVIDIA Jetson Orin Nano-distribution (67 TOPS AI-prestanda)  
  - Mobilapplikationer med .NET MAUI och ONNX Runtime GenAI  
  - Azure EdgeAI-lösningar med hybridarkitektur mellan moln och edge  
  - Optimering för Windows ML med universellt hårdvarustöd  
  - Foundry Local-applikationer med integritetsfokuserad RAG-implementation  

### Självbedömningsfrågor  

1. Hur effektiviserar AI Toolkit arbetsflödet för EdgeAI-utveckling?  
2. Jämför distributionsstrategier över olika hårdvaruplattformar.  
3. Vilka är fördelarna med Windows AI Foundry för edge-utveckling?  
4. Förklara rollen av NPU-optimering i moderna EdgeAI-applikationer.  
5. Hur utnyttjar Phi Silica API NPU-hårdvara för prestandaoptimering?  
6. Jämför fördelarna med lokal kontra molndistribution för integritetskänsliga applikationer.  

### Praktiska övningar  

1. **AI Toolkit-setup**: Konfigurera AI Toolkit och optimera en modell (1 timme)  
2. **Windows AI Foundry**: Bygg en enkel Windows AI-applikation med Phi Silica API (1 timme)  
3. **Plattformsövergripande distribution**: Distribuera samma modell på två olika plattformar (1 timme)  
4. **NPU-optimering**: Testa NPU-prestanda med Windows AI Foundry-verktyg (30 minuter)  

## Modul 8: Microsoft Foundry Local – Komplett utvecklarverktyg  

### Viktiga lärandemål  

- Installera och konfigurera Foundry Local på Windows  
- Köra, upptäcka och hantera modeller lokalt via Foundry CLI  
- Integrera med OpenAI-kompatibla REST- och SDK-klienter  
- Bygga praktiska exempel: Chainlit-chat, agenter och modellrouter  
- Förstå hybridmönster med Azure AI Foundry  

### Fokusområden för studier  

- Installation och CLI-grunder (modell, tjänst, cache)  
- SDK-integration (OpenAI-kompatibla klienter och Azure OpenAI)  
- Snabb validering med Open WebUI  
- Mönster för agenter och funktionsanrop  
- Modeller som verktyg (router- och registerdesign)  

### Självbedömningsfrågor  

1. Hur upptäcker du den lokala slutpunkten och listar tillgängliga modeller?  
2. Vilka är skillnaderna mellan Foundry Local REST och Azure OpenAI-användning?  
3. Hur skulle du designa en enkel router för att välja modeller som verktyg?  
4. Vilka CLI-kategorier är mest relevanta för daglig utveckling?  
5. Hur validerar du Foundry Local-beredskap innan du kör applikationer?  

### Praktiska övningar  

1. Installera/uppgradera Foundry Local och kör `phi-4-mini` lokalt (30 minuter)  
2. Anropa `/v1/models` och kör en enkel chat via REST (30 minuter)  
3. Starta Chainlit-app-exemplet och chatta lokalt (30 minuter)  
4. Kör multi-agentkoordinatorn och inspektera utdata (30 minuter)  
5. Testa router för modeller som verktyg med miljöbaserade överstyrningar (30 minuter)  

## Tidsallokeringsguide  

För att hjälpa dig att få ut det mesta av den 20-timmars kursen, här är en föreslagen fördelning av din tid:  

| Aktivitet | Tidsallokering | Beskrivning |  
|----------|----------------|-------------|  
| Läsa kärnmaterial | 9 timmar | Fokus på de viktigaste koncepten i varje modul |  
| Praktiska övningar | 6 timmar | Praktisk implementering av nyckeltekniker |  
| Självbedömning | 2 timmar | Testa din förståelse genom frågor och reflektion |  
| Mini-projekt | 3 timmar | Tillämpa kunskap i en liten praktisk implementation |  

### Fokusområden baserat på tidsbegränsning  

**Om du bara har 10 timmar:**  
- Slutför modulerna 1, 2 och 3 (grundläggande EdgeAI-koncept)  
- Gör minst en praktisk övning per modul  
- Fokusera på att förstå kärnkoncept snarare än implementeringsdetaljer  

**Om du kan avsätta hela 20 timmar:**  
- Slutför alla sju moduler  
- Utför viktiga praktiska övningar från varje modul  
- Slutför ett mini-projekt från modul 7  
- Utforska minst 2-3 kompletterande resurser  

**Om du har mer än 20 timmar:**  
- Slutför alla moduler med detaljerade övningar  
- Bygg flera mini-projekt  
- Utforska avancerade optimeringstekniker i modul 4  
- Implementera produktionsdistribution från modul 5  

## Viktiga resurser  

Dessa noggrant utvalda resurser ger mest värde för din begränsade studietid:  

### Måste-läsa dokumentation  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektiva verktyget för modelloptimering  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Snabbaste sättet att distribuera SLM lokalt  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referens för en ledande edge-optimerad modell  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattande optimeringsverktyg  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrerad utvecklingsmiljö för EdgeAI  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifik utvecklingsplattform för EdgeAI  

### Tidsbesparande verktyg  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Snabb åtkomst och distribution av modeller  
- [Gradio](https://www.gradio.app/docs/interface) - Snabb UI-utveckling för AI-demonstrationer  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Förenklad modelloptimering  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Ramverk för neurala nätverkskomprimering  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Verktyg för distribution av stora språkmodeller  

## Mall för framstegsspårning  

Använd denna förenklade mall för att spåra din lärande framsteg genom den 20-timmars kursen:  

| Modul | Slutförandedatum | Timmar spenderade | Viktiga insikter |  
|--------|----------------|-------------|---------------|  
| Modul 1: EdgeAI-grunder | | | |  
| Modul 2: SLM-grunder | | | |  
| Modul 3: SLM-distribution | | | |  
| Modul 4: Modelloptimering | | | |  
| Modul 5: SLMOps | | | |  
| Modul 6: AI-agenter | | | |  
| Modul 7: Utvecklingsverktyg | | | |  
| Modul 8: Foundry Local Toolkit | | | |  
| Praktiska övningar | | | |  
| Mini-projekt | | | |  

## Idéer för mini-projekt  

Överväg att slutföra ett av dessa projekt för att öva på EdgeAI-koncept (varje designad att ta 2-4 timmar):  

### Nybörjarprojekt (2-3 timmar vardera)  
1. **Edge Text Assistant**: Skapa ett enkelt offlineverktyg för textkomplettering med en liten språkmodell  
2. **Dashboard för modelljämförelse**: Bygg en grundläggande visualisering av prestandamått över olika SLM  
3. **Optimeringsexperiment**: Mät effekten av olika kvantiseringsnivåer på samma basmodell  

### Mellanliggande projekt (3-4 timmar vardera)  
4. **AI Toolkit-arbetsflöde**: Använd VS Code AI Toolkit för att optimera och distribuera en modell från början till slut  
5. **Windows AI Foundry-applikation**: Skapa en Windows-app med Phi Silica API och NPU-optimering  
6. **Plattformsövergripande distribution**: Distribuera samma optimerade modell på Windows (OpenVINO) och mobil (.NET MAUI)  
7. **Agent med funktionsanrop**: Bygg en AI-agent med funktionsanropsmöjligheter för edge-scenarier  

### Avancerade integrationsprojekt (4-5 timmar vardera)  
8. **OpenVINO-optimeringspipeline**: Implementera komplett modelloptimering med NNCF och GenAI-verktygssatsen  
9. **SLMOps-pipeline**: Implementera en komplett modelllivscykel från träning till edge-distribution  
10. **Multi-Model Edge System**: Distribuera flera specialiserade modeller som samarbetar på edge-hårdvara  
11. **MCP-integrationssystem**: Bygg ett agentbaserat system med Model Context Protocol för verktygsinteraktion  

## Referenser  

- Microsoft Learn (Foundry Local)  
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Kom igång: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI-referens: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrera med inferens-SDK: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Öppna WebUI-guide: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Kompilera Hugging Face-modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agenter (översikt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimerings- och inferensverktyg  
  - Microsoft Olive (dokumentation): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (kom igång): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive-integration: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (dokumentation): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (dokumentation): https://ml-explore.github.io/mlx/build/html/index.html  
- Distributionsramverk och modeller  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (dokumentation): https://docs.vllm.ai/  
  - Ollama (kom igång): https://github.com/ollama/ollama#get-started  
- Utvecklingsverktyg (Windows och VS Code)  
  - AI Toolkit för VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (översikt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Lärande Gemenskap  

Delta i diskussioner och anslut med andra lärande:  
- GitHub-diskussioner på [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Slutsats  

EdgeAI representerar den främsta utvecklingen inom implementering av artificiell intelligens, där kraftfulla funktioner tas direkt till enheter samtidigt som viktiga frågor om integritet, latens och anslutning hanteras. Denna 20-timmars kurs ger dig grundläggande kunskaper och praktiska färdigheter för att börja arbeta med EdgeAI-teknologier omedelbart.  

Kursen är medvetet kortfattad och fokuserad på de viktigaste koncepten, vilket gör att du snabbt kan få värdefull expertis utan en överväldigande tidsåtgång. Kom ihåg att praktisk övning, även med enkla exempel, är nyckeln till att förstärka det du har lärt dig.  

Lycka till med lärandet!  

---

