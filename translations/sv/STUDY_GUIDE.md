<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T22:43:59+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "sv"
}
-->
# EdgeAI för Nybörjare: Studievägar och Studieplan

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 2 | Modul 2: SLM Grunder | 3 timmar |
| Dag 3 | Modul 3: SLM Implementering | 2 timmar |
| Dag 4-5 | Modul 4: Modelloptimering (6 ramverk) | 4 timmar |
| Dag 6 | Modul 5: SLMOps | 3 timmar |
| Dag 7 | Modul 6-7: AI-agenter & Utvecklingsverktyg | 4 timmar |
| Dag 8 | Modul 8: Foundry Local Toolkit (Modern Implementering) | 1 timme |

### Intensiv Studieväg (2 veckor)

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: AI-agenter | 2 timmar |
| Dag 13-14 | Modul 7: Utvecklingsverktyg | 3 timmar |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM Grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Implementering & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

| Dag | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 3 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 3 timmar |
| Dag 5-6 | Modul 3: SLM Implementering | 2 timmar |
| Dag 7-8 | Modul 4: Modelloptimering | 4 timmar |
| Dag 9-10 | Modul 5: SLMOps | 3 timmar |
| Dag 11-12 | Modul 6: SLM Agentiska System | 2 timmar |
| Dag 13-14 | Modul 7: EdgeAI Implementerings Exempel | 2 timmar |

| Modul | Slutdatum | Timmar Spenderade | Viktiga Lärdomar |
|--------|----------------|-------------|--------------|
| Modul 1: EdgeAI Grunder | | | |
| Modul 2: SLM Grunder | | | |
| Modul 3: SLM Implementering | | | |
| Modul 4: Modelloptimering (6 ramverk) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: SLM Agentiska System | | | |
| Modul 7: EdgeAI Implementerings Exempel | | | |
| Praktiska Övningar | | | |
| Mini-projekt | | | |

### Deltidsstudier (4 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|------------------|
| Vecka 1 | Modul 1-2: Grunder & SLM Grunder | 6 timmar |
| Vecka 2 | Modul 3-4: Implementering & Optimering | 6 timmar |
| Vecka 3 | Modul 5-6: SLMOps & AI-agenter | 5 timmar |
| Vecka 4 | Modul 7: Utvecklingsverktyg & Integration | 3 timmar |

## Introduktion

Välkommen till studieguiden för EdgeAI för Nybörjare! Detta dokument är utformat för att hjälpa dig att navigera kursmaterialet effektivt och maximera din inlärningsupplevelse. Det innehåller strukturerade studievägar, föreslagna studieplaner, sammanfattningar av nyckelkoncept och kompletterande resurser för att fördjupa din förståelse av EdgeAI-teknologier.

Detta är en koncentrerad 20-timmars kurs som ger grundläggande kunskaper om EdgeAI i ett tidseffektivt format, vilket gör den perfekt för upptagna yrkesverksamma och studenter som snabbt vill få praktiska färdigheter inom detta framväxande område.

## Kursöversikt

Kursen är organiserad i sju omfattande moduler:

1. **EdgeAI Grunder och Transformation** - Förstå kärnkoncept och teknologiskiftet
2. **Små Språkmodeller (SLM) Grunder** - Utforska olika SLM-familjer och deras arkitekturer
3. **Små Språkmodeller Implementering** - Implementera praktiska strategier för implementering
4. **Modellformatkonvertering och Kvantisering** - Avancerad optimering med 6 ramverk inklusive OpenVINO
5. **SLMOps - Små Språkmodeller Operations** - Produktionslivscykelhantering och implementering
6. **SLM Agentiska System** - AI-agenter, funktionsanrop och Model Context Protocol
7. **EdgeAI Implementerings Exempel** - AI Toolkit, Windows-utveckling och plattformspecifika implementeringar
8. **Microsoft Foundry Local – Komplett Utvecklingsverktyg** - Lokal-först utveckling med hybrid Azure-integration (Modul 08)

## Hur du Använder Denna Studievägledning

- **Progressiv Inlärning**: Följ modulerna i ordning för den mest sammanhängande inlärningsupplevelsen
- **Kunskapskontroller**: Använd självbedömningsfrågorna efter varje avsnitt
- **Praktisk Övning**: Slutför de föreslagna övningarna för att förstärka teoretiska koncept
- **Kompletterande Resurser**: Utforska ytterligare material för ämnen som intresserar dig mest

## Rekommenderade Studieplaner

### Intensiv Studieväg (1 vecka)

| Dag | Fokus | Beräknade Timmar |
|------|-------|-----------------|
| Dag 1-2 | Modul 1: EdgeAI Grunder | 6 timmar |
| Dag 3-4 | Modul 2: SLM Grunder | 8 timmar |
| Dag 5 | Modul 3: SLM Implementering | 3 timmar |
| Dag 6 | Modul 8: Foundry Local Toolkit | 3 timmar |

### Deltidsstudier (3 veckor)

| Vecka | Fokus | Beräknade Timmar |
|------|-------|-----------------|
| Vecka 1 | Modul 1: EdgeAI Grunder | 6-7 timmar |
| Vecka 2 | Modul 2: SLM Grunder | 7-8 timmar |
| Vecka 3 | Modul 3: SLM Implementering (3h) + Modul 8: Foundry Local Toolkit (2-3h) | 5-6 timmar |

## Modul 1: EdgeAI Grunder och Transformation

### Viktiga Lärandemål

- Förstå skillnaderna mellan molnbaserad och edge-baserad AI
- Behärska kärnoptimeringstekniker för resursbegränsade miljöer
- Analysera verkliga tillämpningar av EdgeAI-teknologier
- Ställ in en utvecklingsmiljö för EdgeAI-projekt

### Fokusområden för Studier

#### Avsnitt 1: EdgeAI Grunder
- **Prioriterade Koncept**: 
  - Edge vs. Moln computing paradigmer
  - Modellkvantiseringstekniker
  - Hårdvaruaccelerationsalternativ (NPUs, GPUs, CPUs)
  - Integritets- och säkerhetsfördelar

- **Kompletterande Material**:
  - [TensorFlow Lite Dokumentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Dokumentation](https://docs.edgeimpulse.com)

#### Avsnitt 2: Verkliga Fallstudier
- **Prioriterade Koncept**: 
  - Microsoft Phi & Mu modell-ekosystem
  - Praktiska implementeringar inom olika industrier
  - Implementeringsöverväganden

#### Avsnitt 3: Praktisk Implementeringsguide
- **Prioriterade Koncept**: 
  - Utvecklingsmiljöinställning
  - Kvantisering och optimeringsverktyg
  - Bedömningsmetoder för EdgeAI-implementeringar

#### Avsnitt 4: Edge Implementeringshårdvara
- **Prioriterade Koncept**: 
  - Jämförelser mellan hårdvaruplattformar
  - Optimeringsstrategier för specifik hårdvara
  - Implementeringsöverväganden

### Självbedömningsfrågor

1. Jämför och kontrastera molnbaserad AI med edge-baserad AI-implementering.
2. Förklara tre nyckeltekniker för att optimera modeller för edge-implementering.
3. Vilka är de primära fördelarna med att köra AI-modeller på edge?
4. Beskriv processen för att kvantisera en modell och hur det påverkar prestanda.
5. Förklara hur olika hårdvaruacceleratorer (NPUs, GPUs, CPUs) påverkar EdgeAI-implementering.

### Praktiska Övningar

1. **Snabb Miljöinställning**: Konfigurera en minimal utvecklingsmiljö med de nödvändiga paketen (30 minuter)
2. **Modellutforskning**: Ladda ner och undersök en förtränad liten språkmodell (1 timme)
3. **Grundläggande Kvantisering**: Testa enkel kvantisering på en liten modell (1 timme)

## Modul 2: Små Språkmodeller Grunder

### Viktiga Lärandemål

- Förstå de arkitektoniska principerna för olika SLM-familjer
- Jämför modellkapaciteter över olika parameterstorlekar
- Utvärdera modeller baserat på effektivitet, kapacitet och implementeringskrav
- Identifiera lämpliga användningsområden för olika modelfamiljer

### Fokusområden för Studier

#### Avsnitt 1: Microsoft Phi Modelfamilj
- **Prioriterade Koncept**: 
  - Designfilosofins utveckling
  - Effektivitet-först arkitektur
  - Specialiserade kapaciteter

#### Avsnitt 2: Qwen Familj
- **Prioriterade Koncept**: 
  - Öppen källkod bidrag
  - Skalbara implementeringsalternativ
  - Avancerad resonemangsarkitektur

#### Avsnitt 3: Gemma Familj
- **Prioriterade Koncept**: 
  - Forskningsdriven innovation
  - Multimodala kapaciteter
  - Mobiloptimering

#### Avsnitt 4: BitNET Familj
- **Prioriterade Koncept**: 
  - 1-bit kvantiseringsteknik
  - Optimeringsramverk för inferens
  - Hållbarhetsöverväganden

#### Avsnitt 5: Microsoft Mu Modell
- **Prioriterade Koncept**: 
  - Enhets-först arkitektur
  - Systemintegration med Windows
  - Integritetsbevarande drift

#### Avsnitt 6: Phi-Silica
- **Prioriterade Koncept**: 
  - NPU-optimerad arkitektur
  - Prestandamått
  - Utvecklarintegration

### Självbedömningsfrågor

1. Jämför de arkitektoniska tillvägagångssätten för Phi och Qwen modelfamiljer.
2. Förklara hur BitNET:s kvantiseringsteknik skiljer sig från traditionell kvantisering.
3. Vilka är de unika fördelarna med Mu-modellen för Windows-integration?
4. Beskriv hur Phi-Silica utnyttjar NPU-hårdvara för prestandaoptimering.
5. För en mobilapplikation med begränsad anslutning, vilken modelfamilj skulle vara mest lämplig och varför?

### Praktiska Övningar

1. **Modelljämförelse**: Snabb benchmark av två olika SLM-modeller (1 timme)
2. **Enkel Textgenerering**: Grundläggande implementering av textgenerering med en liten modell (1 timme)
3. **Snabb Optimering**: Använd en optimeringsteknik för att förbättra inferenshastigheten (1 timme)

## Modul 3: Små Språkmodeller Implementering

### Viktiga Lärandemål

- Välj lämpliga modeller baserat på implementeringsbegränsningar
- Behärska optimeringstekniker för olika implementeringsscenarier
- Implementera SLMs i både lokala och molnbaserade miljöer
- Designa produktionsklara konfigurationer för EdgeAI-applikationer

### Fokusområden för Studier

#### Avsnitt 1: SLM Avancerad Inlärning
- **Prioriterade Koncept**: 
  - Parameterklassificeringsramverk
  - Avancerade optimeringstekniker
  - Strategier för modellanskaffning

#### Avsnitt 2: Lokal Miljö Implementering
- **Prioriterade Koncept**: 
  - Ollama plattformsimplementering
  - Microsoft Foundry lokala lösningar
  - Jämförande analys av ramverk

#### Avsnitt 3: Containeriserad Moln Implementering
- **Prioriterade Koncept**: 
  - vLLM högpresterande inferens
  - Containerorkestrering
  - ONNX Runtime implementering

### Självbedömningsfrågor

1. Vilka faktorer bör beaktas vid val mellan lokal implementering och molnimplementering?
2. Jämför Ollama och Microsoft Foundry Local som implementeringsalternativ.
3. Förklara fördelarna med containerisering för SLM-implementering.
4. Vilka är de viktigaste prestandamåtten att övervaka för en edge-implementerad SLM?
5. Beskriv ett komplett implementeringsarbetsflöde från modellval till produktionsimplementering.

### Praktiska Övningar

1. **Grundläggande Lokal Implementering**: Implementera en enkel SLM med Ollama (1 timme)
2. **Prestandakontroll**: Kör en snabb benchmark på din implementerade modell (30 minuter)
3. **Enkel Integration**: Skapa en minimal applikation som använder din implementerade modell (1 timme)

## Modul 4: Modellformatkonvertering och Kvantisering

### Viktiga Lärandemål

- Behärska avancerade kvantiseringstekniker från 1-bit till 8-bit precision
- Förstå strategier för formatkonvertering (GGUF, ONNX)
- Implementera optimering över sex ramverk (Llama.cpp, Olive, OpenVINO, MLX, arbetsflödessyntes)
- Implementera optimerade modeller för produktionsmiljöer på edge över Intel, Apple och plattformsoberoende hårdvara

### Fokusområden för Studier

#### Avsnitt 1: Kvantisering Grunder
- **Prioriterade Koncept**: 
  - Precisionklassificeringsramverk
  - Prestanda vs. noggrannhet avvägningar
  - Optimering av minnesanvändning

#### Avsnitt 2: Llama.cpp Implementering
- **Prioriterade Koncept**: 
  - Plattformsoberoende implementering
  - GGUF formatoptimering
  - Tekniker för hårdvaruacceleration

#### Avsnitt 3: Microsoft Olive Suite
- **Prioriterade Koncept**: 
  - Hårdvarumedveten optimering
  - Implementering i företagsmiljöer
  - Automatiserade optimeringsarbetsflöden

#### Avsnitt 4: OpenVINO Toolkit
- **Prioriterade Koncept**: 
  - Intel hårdvaruoptimering
  - Neural Network Compression Framework (NNCF)
  - Plattformsoberoende inferensimplementering
- OpenVINO GenAI för LLM-distribution

#### Sektion 5: Apple MLX Framework
- **Prioriterade koncept**: 
  - Optimering för Apple Silicon
  - Enhetlig minnesarkitektur
  - LoRA finjusteringsmöjligheter

#### Sektion 6: Arbetsflödessyntes för Edge AI-utveckling
- **Prioriterade koncept**: 
  - Enhetlig arbetsflödesarkitektur
  - Beslutsträd för ramverksval
  - Validering av produktionsberedskap
  - Strategier för framtidssäkring

### Självbedömningsfrågor

1. Jämför kvantiseringsstrategier över olika precisionsnivåer (1-bit till 8-bit).
2. Förklara fördelarna med GGUF-formatet för edge-distribution.
3. Hur förbättrar hårdvaruoptimering i Microsoft Olive distributionseffektiviteten?
4. Vilka är de viktigaste fördelarna med OpenVINOs NNCF för modellkomprimering?
5. Beskriv hur Apple MLX utnyttjar enhetlig minnesarkitektur för optimering.
6. Hur hjälper arbetsflödessyntes vid val av optimala optimeringsramverk?

### Praktiska övningar

1. **Modellkvantisering**: Applicera olika kvantiseringsnivåer på en modell och jämför resultaten (1 timme)
2. **OpenVINO-optimering**: Använd NNCF för att komprimera en modell för Intel-hårdvara (1 timme)
3. **Ramverksjämförelse**: Testa samma modell över tre olika optimeringsramverk (1 timme)
4. **Prestandamätning**: Mät optimeringens påverkan på inferenshastighet och minnesanvändning (1 timme)

## Modul 5: SLMOps - Små språkmodellers drift

### Viktiga lärandemål

- Förstå principerna för livscykelhantering inom SLMOps
- Bemästra destillation och finjusteringstekniker för edge-distribution
- Implementera produktionsdistributionsstrategier med övervakning
- Bygga arbetsflöden för drift och underhåll av SLM på företagsnivå

### Fokusområden för studier

#### Sektion 1: Introduktion till SLMOps
- **Prioriterade koncept**: 
  - Paradigmskiftet inom AI-drift med SLMOps
  - Kostnadseffektivitet och integritetsfokuserad arkitektur
  - Strategisk affärspåverkan och konkurrensfördelar

#### Sektion 2: Modelldestillation
- **Prioriterade koncept**: 
  - Tekniker för kunskapsöverföring
  - Implementering av tvåstegs destillationsprocess
  - Destillationsarbetsflöden med Azure ML

#### Sektion 3: Finjusteringsstrategier
- **Prioriterade koncept**: 
  - Parameter-effektiv finjustering (PEFT)
  - Avancerade metoder med LoRA och QLoRA
  - Multi-adapterträning och hyperparameteroptimering

#### Sektion 4: Produktionsdistribution
- **Prioriterade koncept**: 
  - Modellkonvertering och kvantisering för produktion
  - Konfiguration för Foundry Local-distribution
  - Prestandamätning och kvalitetsvalidering

### Självbedömningsfrågor

1. Hur skiljer sig SLMOps från traditionell MLOps?
2. Förklara fördelarna med modelldestillation för edge-distribution.
3. Vilka är de viktigaste övervägandena för finjustering av SLM i resursbegränsade miljöer?
4. Beskriv en komplett produktionsdistributionspipeline för edge AI-applikationer.

### Praktiska övningar

1. **Grundläggande destillation**: Skapa en mindre modell från en större lärarmodell (1 timme)
2. **Finjusteringsexperiment**: Finjustera en modell för ett specifikt område (1 timme)
3. **Distributionspipeline**: Sätt upp en grundläggande CI/CD-pipeline för modelldistribution (1 timme)

## Modul 6: SLM Agentiska system - AI-agenter och funktionsanrop

### Viktiga lärandemål

- Bygga intelligenta AI-agenter för edge-miljöer med små språkmodeller
- Implementera funktionsanropsmöjligheter med systematiska arbetsflöden
- Bemästra Model Context Protocol (MCP) för standardiserad verktygsinteraktion
- Skapa sofistikerade agentiska system med minimal mänsklig intervention

### Fokusområden för studier

#### Sektion 1: AI-agenter och SLM-grunder
- **Prioriterade koncept**: 
  - Ramverk för agentklassificering (reflex, modellbaserade, målbaserade, lärande agenter)
  - Analys av avvägningar mellan SLM och LLM
  - Designmönster för edge-specifika agenter
  - Resursoptimering för agenter

#### Sektion 2: Funktionsanrop i små språkmodeller
- **Prioriterade koncept**: 
  - Implementering av systematiska arbetsflöden (intentsdetektion, JSON-utdata, extern exekvering)
  - Plattformsspecifika implementationer (Phi-4-mini, utvalda Qwen-modeller, Microsoft Foundry Local)
  - Avancerade exempel (samarbete mellan flera agenter, dynamiskt verktygsval)
  - Produktionsöverväganden (hastighetsbegränsning, loggning för granskning, säkerhetsåtgärder)

#### Sektion 3: Integration av Model Context Protocol (MCP)
- **Prioriterade koncept**: 
  - Protokollarkitektur och lagerbaserad systemdesign
  - Stöd för flera backend-lösningar (Ollama för utveckling, vLLM för produktion)
  - Anslutningsprotokoll (STDIO och SSE-lägen)
  - Verkliga applikationer (webbautomatisering, databehandling, API-integration)

### Självbedömningsfrågor

1. Vilka är de viktigaste arkitektoniska övervägandena för edge AI-agenter?
2. Hur förbättrar funktionsanrop agentens kapabiliteter?
3. Förklara rollen av Model Context Protocol i agentkommunikation.

### Praktiska övningar

1. **Enkel agent**: Bygg en grundläggande AI-agent med funktionsanrop (1 timme)
2. **MCP-integration**: Implementera MCP i en agentapplikation (30 minuter)

## Modul 7: Implementeringsprover för EdgeAI

### Viktiga lärandemål

- Bemästra AI Toolkit för Visual Studio Code för omfattande EdgeAI-utvecklingsarbetsflöden
- Få expertis i Windows AI Foundry-plattformen och NPU-optimeringsstrategier
- Implementera EdgeAI över flera hårdvaruplattformar och distributionsscenarier
- Bygga produktionsklara EdgeAI-applikationer med plattformsspecifika optimeringar

### Fokusområden för studier

#### Sektion 1: AI Toolkit för Visual Studio Code
- **Prioriterade koncept**: 
  - Omfattande Edge AI-utvecklingsmiljö inom VS Code
  - Modellkatalog och upptäckt för edge-distribution
  - Lokala test-, optimerings- och agentutvecklingsarbetsflöden
  - Prestandaövervakning och utvärdering för edge-scenarier

#### Sektion 2: Windows EdgeAI-utvecklingsguide
- **Prioriterade koncept**: 
  - Översikt över Windows AI Foundry-plattformen
  - Phi Silica API för effektiv NPU-inferens
  - Datorvisions-API:er för bildbehandling och OCR
  - Foundry Local CLI för lokal utveckling och testning

#### Sektion 3: Plattformsspecifika implementationer
- **Prioriterade koncept**: 
  - NVIDIA Jetson Orin Nano-distribution (67 TOPS AI-prestanda)
  - Mobila applikationer med .NET MAUI och ONNX Runtime GenAI
  - Azure EdgeAI-lösningar med hybridarkitektur mellan moln och edge
  - Windows ML-optimering med universellt hårdvarustöd
  - Foundry Local-applikationer med integritetsfokuserad RAG-implementation

### Självbedömningsfrågor

1. Hur effektiviserar AI Toolkit EdgeAI-utvecklingsarbetsflödet?
2. Jämför distributionsstrategier över olika hårdvaruplattformar.
3. Vilka är fördelarna med Windows AI Foundry för edge-utveckling?
4. Förklara rollen av NPU-optimering i moderna EdgeAI-applikationer.
5. Hur utnyttjar Phi Silica API NPU-hårdvara för prestandaoptimering?
6. Jämför fördelarna med lokal kontra molndistribution för integritetskänsliga applikationer.

### Praktiska övningar

1. **AI Toolkit-setup**: Konfigurera AI Toolkit och optimera en modell (1 timme)
2. **Windows AI Foundry**: Bygg en enkel Windows AI-applikation med Phi Silica API (1 timme)
3. **Plattformsövergripande distribution**: Distribuera samma modell på två olika plattformar (1 timme)
4. **NPU-optimering**: Testa NPU-prestanda med Windows AI Foundry-verktyg (30 minuter)

## Modul 8: Microsoft Foundry Local – Komplett utvecklarverktyg (moderniserat)

### Viktiga lärandemål

- Installera och konfigurera Foundry Local med modern SDK-integration
- Implementera avancerade multi-agent-system med koordinator-mönster
- Bygga intelligenta modellroutrar med automatisk uppgiftsbaserad selektion
- Distribuera produktionsklara AI-lösningar med omfattande övervakning
- Integrera med Azure AI Foundry för hybriddistributionsscenarier
- Bemästra moderna SDK-mönster med FoundryLocalManager och OpenAI-klient

### Fokusområden för studier

#### Sektion 1: Modern installation och konfiguration
- **Prioriterade koncept**: 
  - SDK-integration med FoundryLocalManager
  - Automatisk tjänstupptäckt och hälsokontroll
  - Konfigurationsmönster baserade på miljöer
  - Överväganden för produktionsdistribution

#### Sektion 2: Avancerade multi-agent-system
- **Prioriterade koncept**: 
  - Koordinator-mönster med specialistagenter
  - Specialisering för hämtning, resonemang och exekvering
  - Feedback-loop-mekanismer för förfining
  - Prestandaövervakning och statistikspårning

#### Sektion 3: Intelligent modellrouting
- **Prioriterade koncept**: 
  - Algoritmer för modellval baserat på nyckelord
  - Stöd för flera modeller (generell, resonemang, kod, kreativ)
  - Konfiguration med miljövariabler för flexibilitet
  - Hälsokontroll av tjänster och felhantering

#### Sektion 4: Produktionsklar implementation
- **Prioriterade koncept**: 
  - Omfattande felhantering och fallback-mekanismer
  - Begäranövervakning och prestandaspårning
  - Interaktiva Jupyter-notebook-exempel med benchmarks
  - Integrationsmönster med befintliga applikationer

### Självbedömningsfrågor

1. Hur skiljer sig det moderna FoundryLocalManager-ansatsen från manuella REST-anrop?
2. Förklara koordinator-mönstret och hur det organiserar specialistagenter.
3. Hur väljer den intelligenta routern lämpliga modeller baserat på frågeinnehåll?
4. Vilka är de viktigaste komponenterna i ett produktionsklart AI-agent-system?
5. Hur implementerar du omfattande hälsokontroll för Foundry Local-tjänster?
6. Jämför fördelarna med den moderniserade ansatsen kontra traditionella implementeringsmönster.

### Praktiska övningar

1. **Modern SDK-setup**: Konfigurera FoundryLocalManager med automatisk tjänstupptäckt (30 minuter)
2. **Multi-agent-system**: Kör den avancerade koordinatorn med specialistagenter (30 minuter)
3. **Intelligent routing**: Testa modellroutern med olika frågetyper (30 minuter)
4. **Interaktiv utforskning**: Använd Jupyter-notebooks för att utforska avancerade funktioner (45 minuter)
5. **Produktionsdistribution**: Implementera övervaknings- och felhanteringsmönster (30 minuter)
6. **Hybridintegration**: Konfigurera fallback-scenarier med Azure AI Foundry (30 minuter)

## Tidsallokeringsguide

För att hjälpa dig att få ut det mesta av den 20-timmars kursen, här är en föreslagen fördelning av din tid:

| Aktivitet | Tidsallokering | Beskrivning |
|-----------|----------------|-------------|
| Läsning av kärnmaterial | 9 timmar | Fokus på de viktigaste koncepten i varje modul |
| Praktiska övningar | 6 timmar | Praktisk implementering av nyckeltekniker |
| Självbedömning | 2 timmar | Testa din förståelse genom frågor och reflektion |
| Mini-projekt | 3 timmar | Tillämpa kunskap på en liten praktisk implementation |

### Viktiga fokusområden baserat på tidsbegränsning

**Om du bara har 10 timmar:**
- Slutför modulerna 1, 2 och 3 (grundläggande EdgeAI-koncept)
- Gör minst en praktisk övning per modul
- Fokusera på att förstå kärnkoncept snarare än implementeringsdetaljer

**Om du kan avsätta hela 20 timmar:**
- Slutför alla sju moduler
- Utför nyckelövningar från varje modul
- Slutför ett mini-projekt från modul 7
- Utforska minst 2-3 kompletterande resurser

**Om du har mer än 20 timmar:**
- Slutför alla moduler med detaljerade övningar
- Bygg flera mini-projekt
- Utforska avancerade optimeringstekniker i modul 4
- Implementera produktionsdistribution från modul 5

## Viktiga resurser

Dessa noggrant utvalda resurser ger mest värde för din begränsade studietid:

### Måste-läsa dokumentation
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Det mest effektiva verktyget för modelloptimering
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Snabbaste sättet att distribuera SLM lokalt
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referens för en ledande edge-optimerad modell
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intels omfattande optimeringsverktyg
- [AI Toolkit för VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrerad EdgeAI-utvecklingsmiljö
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifik EdgeAI-utvecklingsplattform

### Tidsbesparande verktyg
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Snabb modellåtkomst och distribution
- [Gradio](https://www.gradio.app/docs/interface) - Snabb UI-utveckling för AI-demonstrationer
- [Microsoft Olive](https://github.com/microsoft/Olive) - Förenklad modelloptimering
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Effektiv CPU-inferens
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Ramverk för neurala nätverkskomprimering
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit för distribution av stora språkmodeller

## Mall för framstegsspårning

Använd denna förenklade mall för att spåra din inlärningsframgång genom den 20-timmars kursen:

| Modul | Slutförandedatum | Timmar spenderade | Viktiga insikter |
|-------|------------------|-------------------|------------------|
| Modul 1: EdgeAI-grunder | | | |
| Modul 2: SLM-grunder | | | |
| Modul 3: SLM-distribution | | | |
| Modul 4: Modelloptimering | | | |
| Modul 5: SLMOps | | | |
| Modul 6: AI-agenter | | | |
| Modul 7: Utvecklingsverktyg | | | |
| Modul 8: Foundry Local Toolkit | | | |
| Praktiska övningar | | | |
| Mini-projekt | | | |

## Idéer för mini-projekt

Överväg att genomföra ett av dessa projekt för att öva på EdgeAI-koncept (varje projekt är utformat att ta 2-4 timmar):

### Nybörjarprojekt (2-3 timmar vardera)
1. **Edge Text Assistant**: Skapa ett enkelt offline-verktyg för textkomplettering med hjälp av en liten språkmodell.
2. **Model Comparison Dashboard**: Bygg en grundläggande visualisering av prestandamått för olika SLM:er.
3. **Optimization Experiment**: Mäta effekten av olika kvantiseringsnivåer på samma basmodell.

### Mellannivåprojekt (3-4 timmar vardera)
4. **AI Toolkit Workflow**: Använd VS Code AI Toolkit för att optimera och distribuera en modell från början till slut.
5. **Windows AI Foundry Application**: Skapa en Windows-app med Phi Silica API och NPU-optimering.
6. **Cross-Platform Deployment**: Distribuera samma optimerade modell på Windows (OpenVINO) och mobil (.NET MAUI).
7. **Function Calling Agent**: Bygg en AI-agent med funktionella anropsmöjligheter för edge-scenarier.

### Avancerade integrationsprojekt (4-5 timmar vardera)
8. **OpenVINO Optimization Pipeline**: Implementera en komplett modelloptimering med NNCF och GenAI-verktyg.
9. **SLMOps Pipeline**: Implementera en komplett modelllivscykel från träning till edge-distribution.
10. **Multi-Model Edge System**: Distribuera flera specialiserade modeller som samarbetar på edge-hårdvara.
11. **MCP Integration System**: Bygg ett agentbaserat system med Model Context Protocol för verktygsinteraktion.

## Referenser

- Microsoft Learn (Foundry Local)
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Kom igång: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI-referens: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrera med inferens-SDK: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI hur man gör: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompilera Hugging Face-modeller: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Översikt: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agenter (översikt): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimerings- och inferensverktyg
  - Microsoft Olive (dokumentation): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (kom igång): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokumentation): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokumentation): https://ml-explore.github.io/mlx/build/html/index.html
- Distributionsramverk och modeller
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokumentation): https://docs.vllm.ai/
  - Ollama (kom igång): https://github.com/ollama/ollama#get-started
- Utvecklingsverktyg (Windows och VS Code)
  - AI Toolkit för VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (översikt): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Lärande gemenskap

Delta i diskussioner och anslut med andra lärande:
- GitHub-diskussioner på [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Slutsats

EdgeAI representerar frontlinjen för implementering av artificiell intelligens, och erbjuder kraftfulla funktioner direkt på enheter samtidigt som viktiga frågor om integritet, latens och anslutning hanteras. Denna 20-timmars kurs ger dig grundläggande kunskaper och praktiska färdigheter för att börja arbeta med EdgeAI-teknologier omedelbart.

Kursen är medvetet kortfattad och fokuserad på de viktigaste koncepten, vilket gör att du snabbt kan få värdefull expertis utan en överväldigande tidsåtgång. Kom ihåg att praktisk övning, även med enkla exempel, är nyckeln till att förstärka det du har lärt dig.

Lycka till med lärandet!

---

