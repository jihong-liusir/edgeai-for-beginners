<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "38b68a204a9621126d056b0e5b51ab7c",
  "translation_date": "2025-10-09T10:19:52+00:00",
  "source_file": "Module03/01.SLMAdvancedLearning.md",
  "language_code": "pa"
}
-->
# ри╕рйИриХри╕ри╝рии 1: SLM риЙрй▒риЪридрио ри╕ри┐рй▒риЦри┐риЖ - римрйБриири┐риЖрижри╛риВ риЕридрйЗ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии

риЫрйЛриЯрйЗ ринри╛ри╕ри╝ри╛ риори╛рибри▓ (SLMs) EdgeAI ри╡ри┐рй▒риЪ риЗрй▒риХ риори╣рй▒ридри╡рикрйВри░рии ридри░рй▒риХрйА рижри╛ рикрйНри░ридрйАриХ ри╣рии, риЬрйЛ ри╕рй░ри╕ри╛ризриири╛риВ рижрйА риШри╛риЯ ри╡ри╛ри▓рйЗ рибри┐ри╡ри╛риИри╕ри╛риВ 'ридрйЗ ри╕рйБризри╛ри░ри┐рид риХрйБрижри░ридрйА ринри╛ри╕ри╝ри╛ рикрйНри░риХри┐ри░ри┐риЖ ри╕риори░рй▒риери╛ри╡ри╛риВ риирйВрй░ рипрйЛриЧ римригри╛риЙриВрижрйЗ ри╣рииред SLMs риирйВрй░ рикрйНри░ринри╛ри╡ри╕ри╝ри╛ри▓рйА риврй░риЧ риири╛ри▓ ридри╛риЗриири╛рид, риЕрикриЯрйАриори╛риИриЬри╝ риЕридрйЗ ри╡ри░ридриг рижрйА ри╕риориЭ Edge-риЕризри╛ри░ри┐рид AI ри╣рй▒ри▓ри╛риВ римригри╛риЙриг ри▓риИ риЬри╝ри░рйВри░рйА ри╣рйИред

## рикри░ри┐риЪрип

риЗри╕ рикри╛риа ри╡ри┐рй▒риЪ, риЕри╕рйАриВ риЫрйЛриЯрйЗ ринри╛ри╕ри╝ри╛ риори╛рибри▓ри╛риВ (SLMs) риЕридрйЗ риЙриирйНри╣ри╛риВ рижрйЗ риЙрй▒риЪридрио риХри╛ри░риЬри╛риири╡ри╛риЗриг ри░ригриирйАридрйАриЖриВ рижрйА рикрйЬриЪрйЛри▓ риХри░ри╛риВриЧрйЗред риЕри╕рйАриВ SLMs рижрйЗ риорйБрй▒риври▓рйЗ ри╕рй░риХри▓рикри╛риВ, риЙриирйНри╣ри╛риВ рижрйА рикрйИри░ри╛риорйАриЯри░ ри╕рйАриори╛ри╡ри╛риВ риЕридрйЗ ри╡ри░риЧрйАриХри░рии, риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ридриХриирйАриХри╛риВ, риЕридрйЗ риРриЬ риХрй░рикри┐риКриЯри┐рй░риЧ ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри▓риИ ри╡ри┐ри╣ри╛ри░риХ ридри╛риЗриири╛ридрйА ри░ригриирйАридрйАриЖриВ риирйВрй░ риХри╡ри░ риХри░ри╛риВриЧрйЗред

## ри╕ри┐рй▒риЦриг рижрйЗ риЙрижрйЗри╕ри╝

риЗри╕ рикри╛риа рижрйЗ риЕрй░рид ридрй▒риХ, ридрйБри╕рйАриВ риЗри╣ риХри░рии рижрйЗ рипрйЛриЧ ри╣рйЛри╡рйЛриЧрйЗ:

- ЁЯФв риЫрйЛриЯрйЗ ринри╛ри╕ри╝ри╛ риори╛рибри▓ри╛риВ рижрйА рикрйИри░ри╛риорйАриЯри░ ри╕рйАриори╛ри╡ри╛риВ риЕридрйЗ ри╡ри░риЧрйАриХри░рии риирйВрй░ ри╕риориЭрйЛред
- ЁЯЫая╕П риРриЬ рибри┐ри╡ри╛риИри╕ри╛риВ 'ридрйЗ SLM ридри╛риЗриири╛ридрйА ри▓риИ риорйБрй▒риЦ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ридриХриирйАриХри╛риВ рижрйА рикриЫри╛риг риХри░рйЛред
- ЁЯЪА SLMs ри▓риИ риЙрй▒риЪридрио риори╛ридри░ри╛ риШриЯри╛риЙриг риЕридрйЗ ри╕рй░риХрйЛриЪрии ри░ригриирйАридрйАриЖриВ риирйВрй░ ри╕ри┐рй▒риЦрйЛред

## SLM рикрйИри░ри╛риорйАриЯри░ ри╕рйАриори╛ри╡ри╛риВ риЕридрйЗ ри╡ри░риЧрйАриХри░рии риирйВрй░ ри╕риориЭригри╛

риЫрйЛриЯрйЗ ринри╛ри╕ри╝ри╛ риори╛рибри▓ (SLMs) AI риори╛рибри▓ ри╣рии риЬрйЛ риХрйБрижри░ридрйА ринри╛ри╕ри╝ри╛ ри╕риорй▒риЧри░рйА риирйВрй░ рикрйНри░риХри┐ри░ри┐риЖ, ри╕риориЭриг риЕридрйЗ рикрйИрижри╛ риХри░рии ри▓риИ ридри┐риЖри░ риХрйАридрйЗ риЧриП ри╣рии, риЬри┐риирйНри╣ри╛риВ ри╡ри┐рй▒риЪ риЙриирйНри╣ри╛риВ рижрйЗ ри╡рй▒рибрйЗ ри╕риориХри╛ри▓рйА риори╛рибри▓ри╛риВ рижрйЗ риорйБриХри╛римри▓рйЗ риХри╛рилри╝рйА риШрй▒риЯ рикрйИри░ри╛риорйАриЯри░ ри╣рйБрй░рижрйЗ ри╣рииред риЬрижрйЛриВ риХри┐ ри╡рй▒рибрйЗ ринри╛ри╕ри╝ри╛ риори╛рибри▓ (LLMs) ри╕рйИриВриХрйЬрйЗ риЕри░рим ридрйЛриВ ри▓рйИ риХрйЗ риЦри░римри╛риВ рикрйИри░ри╛риорйАриЯри░ри╛риВ ридрй▒риХ ри╣рйБрй░рижрйЗ ри╣рии, SLMs риЦри╛ри╕ ридрйМри░ 'ридрйЗ риХрйБри╕ри╝ри▓ридри╛ риЕридрйЗ риРриЬ ридри╛риЗриири╛ридрйА ри▓риИ ридри┐риЖри░ риХрйАридрйЗ риЧриП ри╣рииред

рикрйИри░ри╛риорйАриЯри░ ри╡ри░риЧрйАриХри░рии рилри░рйЗриори╡ри░риХ ри╕ри╛риирйВрй░ SLMs рижрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ ри╕ри╝рйНри░рйЗригрйАриЖриВ риЕридрйЗ риЙриирйНри╣ри╛риВ рижрйЗ риЙриЪри┐рид ри╡ри░ридрйЛриВ рижрйЗ риХрйЗри╕ри╛риВ риирйВрй░ ри╕риориЭриг ри╡ри┐рй▒риЪ риорижриж риХри░рижри╛ ри╣рйИред риЗри╣ ри╡ри░риЧрйАриХри░рии риЦри╛ри╕ риРриЬ риХрй░рикри┐риКриЯри┐рй░риЧ рижрйНри░ри┐ри╕ри╝ри╛риВ ри▓риИ ри╕ри╣рйА риори╛рибри▓ риЪрйБригрии ри▓риИ риори╣рй▒ридри╡рикрйВри░рии ри╣рйИред

### рикрйИри░ри╛риорйАриЯри░ ри╡ри░риЧрйАриХри░рии рилри░рйЗриори╡ри░риХ

рикрйИри░ри╛риорйАриЯри░ ри╕рйАриори╛ри╡ри╛риВ риирйВрй░ ри╕риориЭригри╛ ри╡рй▒риЦ-ри╡рй▒риЦ риРриЬ риХрй░рикри┐риКриЯри┐рй░риЧ рижрйНри░ри┐ри╕ри╝ри╛риВ ри▓риИ риЙриЪри┐рид риори╛рибри▓ риЪрйБригрии ри╡ри┐рй▒риЪ риорижриж риХри░рижри╛ ри╣рйИ:

- **ЁЯФм риори╛риИриХри░рйЛ SLMs**: 100M - 1.4B рикрйИри░ри╛риорйАриЯри░ (риорйЛримри╛риИри▓ рибри┐ри╡ри╛риИри╕ри╛риВ ри▓риИ римри╣рйБрид ри╣рйА ри╣ри▓риХрйЗ)
- **ЁЯУ▒ риЫрйЛриЯрйЗ SLMs**: 1.5B - 13.9B рикрйИри░ри╛риорйАриЯри░ (ри╕рй░ридрйБри▓ри┐рид рикрйНри░рижри░ри╕ри╝рии риЕридрйЗ риХрйБри╕ри╝ри▓ридри╛)
- **тЪЦя╕П риорй▒ризрио SLMs**: 14B - 30B рикрйИри░ри╛риорйАриЯри░ (LLM ри╕риори░рй▒риери╛ри╡ри╛риВ рижрйЗ риирйЗрйЬрйЗ рикри╣рйБрй░риЪрижрйЗ ри╣рйЛриП риХрйБри╕ри╝ри▓ридри╛ риирйВрй░ римри░риХри░ри╛ри░ ри░рй▒риЦрижрйЗ ри╣рйЛриП)

риЗри╕рижрйА ри╕ри╣рйА ри╕рйАриори╛ риЦрйЛриЬ ринри╛риИриЪри╛ри░рйЗ ри╡ри┐рй▒риЪ ри▓риЪриХрйАри▓рйА ри░ри╣ри┐рй░рижрйА ри╣рйИ, рикри░ риЬри╝ри┐риЖрижри╛ридри░ ри╡ри┐рижри╡ри╛рии 30 римри┐ри▓рйАриЕрии рикрйИри░ри╛риорйАриЯри░ри╛риВ ридрйЛриВ риШрй▒риЯ риори╛рибри▓ри╛риВ риирйВрй░ "риЫрйЛриЯрйЗ" риорй░риирижрйЗ ри╣рии, риЬрижриХри┐ риХрйБриЭ ри╕ри░рйЛрид риЗри╕ ри╕рйАриори╛ риирйВрй░ 10 римри┐ри▓рйАриЕрии рикрйИри░ри╛риорйАриЯри░ри╛риВ ридрй▒риХ ри╡рйА риШриЯри╛ рижри┐рй░рижрйЗ ри╣рииред

### SLMs рижрйЗ риорйБрй▒риЦ рилри╛риЗрижрйЗ

SLMs риХриИ риорйБрй▒риври▓рйЗ рилри╛риЗрижрйЗ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии риЬрйЛ риЙриирйНри╣ри╛риВ риирйВрй░ риРриЬ риХрй░рикри┐риКриЯри┐рй░риЧ риРрикри▓рйАриХрйЗри╕ри╝риири╛риВ ри▓риИ риЖрижри░ри╕ри╝ римригри╛риЙриВрижрйЗ ри╣рии:

**риЪри╛ри▓рйВ риХрйБри╕ри╝ри▓ридри╛**: SLMs риШрй▒риЯ рикрйИри░ри╛риорйАриЯри░ри╛риВ риХри╛ри░рии ридрйЗриЬри╝ риЗрй░рилри░рйИриВри╕ ри╕риори╛риВ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии, риЬрйЛ риЙриирйНри╣ри╛риВ риирйВрй░ ри░рйАриЕри▓-риЯри╛риИрио риРрикри▓рйАриХрйЗри╕ри╝риири╛риВ ри▓риИ риЖрижри░ри╕ри╝ римригри╛риЙриВрижри╛ ри╣рйИред риЗри╣ риШрй▒риЯ риЧригриири╛ридриориХ ри╕рй░ри╕ри╛ризриири╛риВ рижрйА ри▓рйЛрйЬ риХри░рижрйЗ ри╣рии, риЬри┐ри╕ риири╛ри▓ ри╕рй░ри╕ри╛ризриири╛риВ рижрйА риШри╛риЯ ри╡ри╛ри▓рйЗ рибри┐ри╡ри╛риИри╕ри╛риВ 'ридрйЗ ридри╛риЗриири╛ридрйА ри╕рй░ринри╡ ри╣рйБрй░рижрйА ри╣рйИ, риШрй▒риЯ риКри░риЬри╛ рижрйА риЦрикрид ри╣рйБрй░рижрйА ри╣рйИ риЕридрйЗ риХри╛ри░римрии рилрйБрй▒риЯрикрйНри░ри┐рй░риЯ риШриЯрижри╛ ри╣рйИред

**ридри╛риЗриири╛ридрйА ри▓риЪриХридри╛**: риЗри╣ риори╛рибри▓ риЗрй░риЯри░риирйИриЯ риХриирйИриХриЯри┐ри╡ри┐риЯрйА рижрйА ри▓рйЛрйЬ ридрйЛриВ римри┐риири╛риВ рибри┐ри╡ри╛риИри╕ 'ридрйЗ AI ри╕риори░рй▒риери╛ри╡ри╛риВ рипрйЛриЧ римригри╛риЙриВрижрйЗ ри╣рии, ри╕риери╛риириХ рикрйНри░риХри┐ри░ри┐риЖ ри░ри╛ри╣рйАриВ риЧрйЛрикриирйАрипридри╛ риЕридрйЗ ри╕рйБри░рй▒риЦри┐риЖ риирйВрй░ ри╡ризри╛риЙриВрижрйЗ ри╣рии, риЦрйЗридри░-ри╡ри┐ри╕ри╝рйЗри╕ри╝ риРрикри▓рйАриХрйЗри╕ри╝риири╛риВ ри▓риИ риХри╕риЯриори╛риИриЬри╝ риХрйАридри╛ риЬри╛ ри╕риХрижри╛ ри╣рйИ, риЕридрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ риРриЬ риХрй░рикри┐риКриЯри┐рй░риЧ ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри▓риИ риЙриЪри┐рид ри╣рииред

**ри▓ри╛риЧрид рикрйНри░ринри╛ри╡ри╕ри╝рйАри▓ридри╛**: SLMs LLMs рижрйЗ риорйБриХри╛римри▓рйЗ риШрй▒риЯ ри▓ри╛риЧрид ри╡ри╛ри▓рйА ри╕ри┐риЦри▓ри╛риИ риЕридрйЗ ридри╛риЗриири╛ридрйА рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии, риРриЬ риРрикри▓рйАриХрйЗри╕ри╝риири╛риВ ри▓риИ риШрй▒риЯ риЪри╛ри▓рйВ ри▓ри╛риЧрид риЕридрйЗ риШрй▒риЯ римрйИриВрибри╡ри┐рибрие рижрйА ри▓рйЛрйЬ ри╣рйБрй░рижрйА ри╣рйИред

## риЙрй▒риЪридрио риори╛рибри▓ рикрйНри░ри╛рикридрйА ри░ригриирйАридрйАриЖриВ

### ри╣рй▒риЧри┐рй░риЧ рилрйЗри╕ рикри░ри┐ри╕ри░

ри╣рй▒риЧри┐рй░риЧ рилрйЗри╕ риЕризрйБриири┐риХ SLMs рижрйА риЦрйЛриЬ риЕридрйЗ рикрйНри░ри╛рикридрйА ри▓риИ риорйБрй▒риЦ риХрйЗриВрижри░ ри╡риЬрйЛриВ риХрй░рио риХри░рижри╛ ри╣рйИред риЗри╣ рикри▓рйЗриЯрилри╛ри░рио риори╛рибри▓ риЦрйЛриЬ риЕридрйЗ ридри╛риЗриири╛ридрйА ри▓риИ ри╡ри┐ри╕ри╝ри╛ри▓ ри╕рй░ри╕ри╛ризрии рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ:

**риори╛рибри▓ риЦрйЛриЬ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ**: рикри▓рйЗриЯрилри╛ри░рио рикрйИри░ри╛риорйАриЯри░ риЧри┐ригридрйА, ри▓ри╛риЗри╕рйИриВри╕ риХри┐ри╕рио, риЕридрйЗ рикрйНри░рижри░ри╕ри╝рии риори╛рикрижрй░рибри╛риВ рижрйБриЖри░ри╛ риЙрй▒риЪридрио рилри┐ри▓риЯри░ри┐рй░риЧ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИред рипрйВриЬри╝ри░ ри╕ри╛риИриб-римри╛риИ-ри╕ри╛риИриб риори╛рибри▓ ридрйБри▓риири╛ риЯрйВри▓, ри░рйАриЕри▓-риЯри╛риИрио рикрйНри░рижри░ри╕ри╝рии римрйИриВриЪриори╛ри░риХ риЕридрйЗ риорйБри▓ри╛риВриХриг рииридрйАриЬрйЗ, риЕридрйЗ ридрйБри░рй░рид риЯрйИри╕риЯри┐рй░риЧ ри▓риИ WebGPU рибрйИриорйЛриЬри╝ ридрй▒риХ рикри╣рйБрй░риЪ ри╕риХрижрйЗ ри╣рииред

**риЪрйБригрйЗ ри╣рйЛриП SLM ри╕рй░риЧрйНри░ри╣ри┐**: рикрйНри░ри╕ри┐рй▒риз риори╛рибри▓ри╛риВ ри╡ри┐рй▒риЪ Phi-4-mini-3.8B риЙрй▒риЪридрио ридри░риХри╕ри╝рйАри▓ риХри╛ри░риЬри╛риВ ри▓риИ, Qwen3 ри╕рйАри░рйАриЬри╝ (0.6B/1.7B/4B) римри╣рйБринри╛ри╕ри╝ри╛риИ риРрикри▓рйАриХрйЗри╕ри╝риири╛риВ ри▓риИ, Google Gemma3 риХрйБри╕ри╝ри▓ риЬриири░ри▓-рикри░рикриЬри╝ риХри╛ри░риЬри╛риВ ри▓риИ, риЕридрйЗ рикрйНри░рипрйЛриЧри╛ридриориХ риори╛рибри▓ риЬри┐ри╡рйЗриВ риХри┐ BitNET риЕридри┐-риШрй▒риЯ ри╕ри╣ри┐ригри╕ри╝рйАри▓ ридри╛риЗриири╛ридрйА ри▓риИ ри╕ри╝ри╛риори▓ ри╣рииред рикри▓рйЗриЯрилри╛ри░рио ри╡ри┐рй▒риЪ риЦрйЗридри░-ри╡ри┐ри╕ри╝рйЗри╕ри╝ риори╛рибри▓ри╛риВ ри▓риИ риХриори┐риКриири┐риЯрйА-риЪри▓ри┐рид ри╕рй░риЧрйНри░ри╣ри┐ ри╡рйА ри╕ри╝ри╛риори▓ ри╣рии, риЬрйЛ ри╡рй▒риЦ-ри╡рй▒риЦ ри╡ри░ридрйЛриВ рижрйЗ риХрйЗри╕ри╛риВ ри▓риИ риЕриирйБриХрйВри▓рид риЕридрйЗ ри╕ри┐рй▒риЦри▓ри╛риИ рикрйНри░ри╛рикрид ри░рйВрикри╛риВ ри╡ри┐рй▒риЪ риЙрикри▓римриз ри╣рииред

### риРриЬри╝ри░ AI рилри╛риЙриВрибри░рйА риори╛рибри▓ риХрйИриЯри╛ри▓рйМриЧ

риРриЬри╝ри░ AI рилри╛риЙриВрибри░рйА риори╛рибри▓ риХрйИриЯри╛ри▓рйМриЧ риЙрй▒риЪридрио риПриириЯри░рикрйНри░ри╛риИриЬри╝-риЧрйНри░рйЗриб SLMs ридрй▒риХ рикри╣рйБрй░риЪ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ, риЬри┐ри╕ ри╡ри┐рй▒риЪ ри╡ризрйЗри░рйЗ риЗрй░риЯри┐риЧрйНри░рйЗри╕ри╝рии ри╕риори░рй▒риери╛ри╡ри╛риВ ри╕ри╝ри╛риори▓ ри╣рии:

**риПриириЯри░рикрйНри░ри╛риИриЬри╝ риЗрй░риЯри┐риЧрйНри░рйЗри╕ри╝рии**: риХрйИриЯри╛ри▓рйМриЧ ри╡ри┐рй▒риЪ риРриЬри╝ри░ рижрйБриЖри░ри╛ ри╕ри┐рй▒ризрйЗ ри╡рйЗриЪрйЗ риЧриП риори╛рибри▓ ри╕ри╝ри╛риори▓ ри╣рии, риЬри┐риирйНри╣ри╛риВ ри╡ри┐рй▒риЪ риЙрй▒риЪридрио ридри░риХри╕ри╝рйАри▓ ри╕риори░рй▒риери╛ри╡ри╛риВ ри▓риИ Phi-4-mini-3.8B риЕридрйЗ риЙридрикри╛рижрии ридри╛риЗриири╛ридрйА ри▓риИ Llama 3-8B ри╕ри╝ри╛риори▓ ри╣рииред риЗри╕ ри╡ри┐рй▒риЪ ринри░рйЛри╕рйЗрипрйЛриЧ ридрйАриЬрйА рикрй▒риЦрйА риЦрйБрй▒ри▓рйЗ ри╕ри░рйЛрид риори╛рибри▓ри╛риВ ридрйЛриВ Qwen3 8B ри╡ри░риЧрйЗ риори╛рибри▓ ри╡рйА ри╕ри╝ри╛риори▓ ри╣рииред

**риПриириЯри░рикрйНри░ри╛риИриЬри╝ рилри╛риЗрижрйЗ**: риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ри╛риВ ри╡ри┐рй▒риЪ рилрй░риЧрйАримри▓ рикрйНри░рйЛри╡ри┐риЬри╝риириб риери░рйВрикрйБрй▒риЯ рижрйЗ риири╛ри▓ рилри╛риИрии-риЯри┐риКриири┐рй░риЧ, риири┐риЧри░ри╛риирйА, риЕридрйЗ риЬри╝ри┐рй░риорйЗри╡ри╛ри░ AI ри▓риИ римри┐ри▓риЯ-риЗрии риЯрйВри▓ ри╕ри╝ри╛риори▓ ри╣рииред риори╛риИриХри░рйЛри╕ри╛рилриЯ рижрйБриЖри░ри╛ ри╕ри┐рй▒ризрйА ри╕ри╣ри╛риЗридри╛, риПриириЯри░рикрйНри░ри╛риИриЬри╝ SLA, ри╕рйБри░рй▒риЦри┐риЖ риЕридрйЗ риЕриирйБриХрйВри▓ридри╛ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ, риЕридрйЗ ри╡ри┐ри╕ри╝ри╛ри▓ ридри╛риЗриири╛ридрйА ри╡ри░риХрилри▓рйЛриЬри╝ риПриириЯри░рикрйНри░ри╛риИриЬри╝ риЕриирйБринри╡ риирйВрй░ ри╡ризри╛риЙриВрижрйЗ ри╣рииред

## риЙрй▒риЪридрио риори╛ридри░ри╛ риШриЯри╛риЙриг риЕридрйЗ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ридриХриирйАриХри╛риВ

### Llama.cpp риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии рилри░рйЗриори╡ри░риХ

Llama.cpp риРриЬ ридри╛риЗриири╛ридрйА ри╡ри┐рй▒риЪ ри╡рй▒риз ридрйЛриВ ри╡рй▒риз риХрйБри╕ри╝ри▓ридри╛ ри▓риИ риЕризрйБриири┐риХ риори╛ридри░ри╛ риШриЯри╛риЙриг ридриХриирйАриХри╛риВ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ:

**риори╛ридри░ри╛ риШриЯри╛риЙриг рижрйЗ ридри░рйАриХрйЗ**: рилри░рйЗриори╡ри░риХ ри╡рй▒риЦ-ри╡рй▒риЦ риори╛ридри░ри╛ риШриЯри╛риЙриг рижрйЗ рикрй▒ризри░ри╛риВ рижри╛ ри╕риори░риерии риХри░рижри╛ ри╣рйИ, риЬри┐ри╡рйЗриВ риХри┐ Q4_0 (4-римри┐риЯ риори╛ридри░ри╛ риШриЯри╛риЙриг риири╛ри▓ ри╕ри╝ри╛риирижри╛ри░ риЖриХри╛ри░ риШриЯри╛риЙригри╛ - Qwen3-0.6B риорйЛримри╛риИри▓ ридри╛риЗриири╛ридрйА ри▓риИ риЖрижри░ри╕ри╝), Q5_1 (5-римри┐риЯ риори╛ридри░ри╛ риШриЯри╛риЙриг риЧрйБригри╡рй▒ридри╛ риЕридрйЗ ри╕рй░риХрйЛриЪрии рижри╛ ри╕рй░ридрйБри▓рии - Phi-4-mini-3.8B риРриЬ риЗрй░рилри░рйИриВри╕ ри▓риИ риЙриЪри┐рид), риЕридрйЗ Q8_0 (риорйВри▓ риЧрйБригри╡рй▒ридри╛ рижрйЗ риирйЗрйЬрйЗ - Google Gemma3 риЙридрикри╛рижрии ри╡ри░ридрйЛриВ ри▓риИ ри╕ри┐рилри╛ри░ри╕ри╝рйА)ред BitNET риЕридри┐-ри╕рй░риХрйЛриЪрии рижрйНри░ри┐ри╕ри╝ри╛риВ ри▓риИ 1-римри┐риЯ риори╛ридри░ри╛ риШриЯри╛риЙриг рижри╛ рикрйНри░ридрйАриХ ри╣рйИред

**риХри╛ри░риЬри╛риири╡ри╛риЗриг рижрйЗ рилри╛риЗрижрйЗ**: SIMD ридрйАри╡ри░ридри╛ рижрйЗ риири╛ри▓ CPU-риЕриирйБриХрйВри▓рид риЗрй░рилри░рйИриВри╕ риори╛рибри▓ риирйВрй░ рипри╛рижрижри╛ри╕ри╝рид-риХрйБри╕ри╝ри▓ ри▓рйЛрибри┐рй░риЧ риЕридрйЗ риХри╛ри░риЬриХри╛ри░рйА рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИред x86, ARM, риЕридрйЗ риРрикри▓ ри╕ри┐ри▓ри┐риХрии риЖри░риХрйАриЯрйИриХриЪри░ри╛риВ ри╡ри┐рй▒риЪ рикри▓рйЗриЯрилри╛ри░рио-риЕриЧриирйЛри╕риЯри┐риХ ридри╛риЗриири╛ридрйА ри╕риори░рй▒риери╛ри╡ри╛риВ рипрйЛриЧ римригри╛риЙриВрижри╛ ри╣рйИред

**ри╡ри┐ри╣ри╛ри░риХ риХри╛ри░риЬри╛риири╡ри╛риЗриг риЙрижри╛ри╣ри░рии**:

```bash
# Clone and build llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release

# Convert Phi-4-mini model from Hugging Face to GGUF format
# First, download the model from Hugging Face
cd ..
python convert.py --outtype f16 --outfile phi-4-mini.gguf /path/to/downloaded/phi-4-mini/model

# Quantize the model to 4-bit precision (Q4_0)
./build/bin/quantize phi-4-mini.gguf phi-4-mini-q4_0.gguf q4_0

# Benchmark the model to check performance
./build/bin/llama-bench -m phi-4-mini-q4_0.gguf -p "Write a function to calculate the Fibonacci sequence"

# Run inference with the quantized model
./build/bin/main -m phi-4-mini-q4_0.gguf -n 512 -p "Explain quantum computing in simple terms"
```

**рипри╛рижрижри╛ри╕ри╝рид рилрйБрй▒риЯрикрйНри░ри┐рй░риЯ ридрйБри▓риири╛**:

```python
# Python script to analyze model size differences
import os
import matplotlib.pyplot as plt
import numpy as np

# Model sizes (in GB)
models = ['Phi-4-mini', 'Qwen3-0.6B', 'Gemma3']
original_sizes = [7.6, 1.2, 4.8]  # F16 format
q4_0_sizes = [2.0, 0.35, 1.3]     # Q4_0 format
q8_0_sizes = [3.9, 0.68, 2.5]     # Q8_0 format

# Calculate reduction percentages
q4_reduction = [(orig - q4) / orig * 100 for orig, q4 in zip(original_sizes, q4_0_sizes)]
q8_reduction = [(orig - q8) / orig * 100 for orig, q8 in zip(original_sizes, q8_0_sizes)]

print("Model Size Reduction:")
for i, model in enumerate(models):
    print(f"{model}: Q4_0 reduces size by {q4_reduction[i]:.1f}%, Q8_0 reduces size by {q8_reduction[i]:.1f}%")

# Memory usage during inference will be approximately:
# - Original F16: ~2x model size
# - Q4_0: ~1.2x model size
# - Q8_0: ~1.5x model size
```

### риори╛риИриХри░рйЛри╕ри╛рилриЯ риУри▓ри┐ри╡ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ри╕рйВриЯ

риори╛риИриХри░рйЛри╕ри╛рилриЯ риУри▓ри┐ри╡ риЙридрикри╛рижрии ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри▓риИ ридри┐риЖри░ риХрйАридрйЗ риЧриП ри╡ри┐ри╕ри╝ри╛ри▓ риори╛рибри▓ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ри╡ри░риХрилри▓рйЛриЬри╝ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ:

**риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ридриХриирйАриХри╛риВ**: ри╕рйВриЯ ри╡ри┐рй▒риЪ риЧрйБригри╡рй▒ридри╛ риори╛рикрижрй░рибри╛риВ рижрйА ри░рй▒риЦри┐риЖ риХри░рижри┐риЖриВ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии рижрйЗ ри░рйВрикри╛риВ ри╡ри┐рй▒риЪ ри╕ри╡рйИриЪри╛ри▓ри┐рид римрйИриВриЪриори╛ри░риХри┐рй░риЧ ри╕ри╝ри╛риори▓ ри╣рйИред рикрйНри░ри╕ри┐рй▒риз ML рилри░рйЗриори╡ри░риХри╛риВ риЬри┐ри╡рйЗриВ риХри┐ PyTorch риЕридрйЗ ONNX риири╛ри▓ риЗрй░риЯри┐риЧрйНри░рйЗри╕ри╝рии риХри▓ри╛риЙриб риЕридрйЗ риРриЬ ридри╛риЗриири╛ридрйА риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ри╕риори░рй▒риери╛ри╡ри╛риВ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИред

**ри╡ри┐ри╣ри╛ри░риХ риХри╛ри░риЬри╛риири╡ри╛риЗриг риЙрижри╛ри╣ри░рии**:

```python
# Microsoft Olive optimization workflow for SLM
from olive.model import PyTorchModel, ONNXModel
from olive.workflows import run_workflow
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Define the workflow configuration
def create_olive_config(model_id="microsoft/phi-4-mini-instruct"):
    # Load model and create sample inputs
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)
    
    # Create sample inputs for tracing
    sample_text = "Explain the concept of edge computing"
    inputs = tokenizer(sample_text, return_tensors="pt")
    
    # Export to ONNX first
    model_path = f"{model_id.split('/')[-1]}.onnx"
    torch.onnx.export(
        model,
        (inputs["input_ids"],),
        model_path,
        input_names=["input_ids"],
        output_names=["logits"],
        dynamic_axes={
            "input_ids": {0: "batch", 1: "sequence"},
            "logits": {0: "batch", 1: "sequence"}
        },
        opset_version=15
    )
    
    # Create Olive optimization config
    config = {
        "input_model": ONNXModel(model_path),
        "systems": {
            "local_system": {
                "type": "LocalSystem"
            }
        },
        "passes": {
            # Graph optimization pass
            "graph_optimization": {
                "type": "OrtTransformersOptimization",
                "config": {
                    "optimization_options": {
                        "enable_gelu": True,
                        "enable_layer_norm": True,
                        "enable_attention": True,
                        "use_multi_head_attention": True
                    }
                }
            },
            # Quantization pass for INT8
            "quantization": {
                "type": "OrtQuantization",
                "config": {
                    "quant_mode": "static",
                    "activation_type": "int8",
                    "weight_type": "int8",
                    "op_types_to_quantize": ["MatMul", "Add", "Conv"]
                },
                "disable_search": True
            }
        },
        "engine": {
            "log_severity_level": 0,
            "cache_dir": "./cache"
        }
    }
    
    return config

# Run the optimization workflow
config = create_olive_config()
result = run_workflow(config)

# Save the optimized model
optimized_model = result.optimized_model
optimized_model.save("./optimized_phi4_mini")

# Benchmark performance comparison
print(f"Original model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
print(f"Optimized model size: {os.path.getsize('./optimized_phi4_mini/model.onnx') / (1024 * 1024):.2f} MB")
```

### риРрикри▓ MLX рилри░рйЗриори╡ри░риХ

риРрикри▓ MLX риЦри╛ри╕ ридрйМри░ 'ридрйЗ риРрикри▓ ри╕ри┐ри▓ри┐риХрии рибри┐ри╡ри╛риИри╕ри╛риВ ри▓риИ ридри┐риЖри░ риХрйАридрйЗ риЧриП риорйВри▓ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ:

**риРрикри▓ ри╕ри┐ри▓ри┐риХрии риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии**: рилри░рйЗриори╡ри░риХ рипрйВриири┐рилри╛риИриб риорйИриорйЛри░рйА риЖри░риХрйАриЯрйИриХриЪри░ рижрйЗ риири╛ри▓ риорйИриЯри▓ рикрйНри░рижри░ри╕ри╝рии ри╕ри╝рйЗрибри░риЬри╝ риЗрй░риЯри┐риЧрйНри░рйЗри╕ри╝рии, ри╕ри╡рйИриЪри╛ри▓ри┐рид риори┐ри▓рйА-ри╕ри╣ри┐ригри╕ри╝рйАри▓ риЗрй░рилри░рйИриВри╕ (риЦри╛ри╕ ридрйМри░ 'ридрйЗ Google Gemma3 риири╛ри▓ рикрйНри░ринри╛ри╡ри╕ри╝ри╛ри▓рйА), риЕридрйЗ рипри╛рижрижри╛ри╕ри╝рид римрйИриВрибри╡ри┐рибрие рижрйА риХрйБри╕ри╝ри▓ ри╡ри░ридрйЛриВ риХри░рижри╛ ри╣рйИред Phi-4-mini-3.8B M-ри╕рйАри░рйАриЬри╝ риЪри┐рикри╕ 'ридрйЗ ри╕ри╝ри╛риирижри╛ри░ рикрйНри░рижри░ри╕ри╝рии рижри┐риЦри╛риЙриВрижри╛ ри╣рйИ, риЬрижриХри┐ Qwen3-1.7B MacBook Air ридри╛риЗриири╛ридрйА ри▓риИ риЙриЪри┐рид ри╕рй░ридрйБри▓рии рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИред

**рибри┐ри╡рйИри▓рикриорйИриВриЯ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ**: Python риЕридрйЗ Swift API ри╕риори░риерии рижрйЗ риири╛ри▓ NumPy-риЕриирйБриХрйВри▓ риРри░рйЗ риХри╛ри░риЬ, ри╕ри╡рйИриЪри╛ри▓ри┐рид риЕрй░ридри░-риЕрй░ридри░ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ, риЕридрйЗ риРрикри▓ рибри┐ри╡рйИри▓рикриорйИриВриЯ риЯрйВри▓ри╛риВ риири╛ри▓ ри╕ри╣рйА риЗрй░риЯри┐риЧрйНри░рйЗри╕ри╝рии риЗрй▒риХ ри╡ри┐ри╕ри╝ри╛ри▓ ри╡ри┐риХри╛ри╕ ри╡ри╛ридри╛ри╡ри░риг рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИред

**ри╡ри┐ри╣ри╛ри░риХ риХри╛ри░риЬри╛риири╡ри╛риЗриг риЙрижри╛ри╣ри░рии**:

```python
# Apple MLX optimization for Phi-4-mini model
import mlx.core as mx
import mlx.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from mlx_lm import load, generate

# Install the required packages
# pip install mlx transformers mlx-lm

# Load the Phi-4-mini model with MLX optimization
model_path = "microsoft/phi-4-mini-instruct"
model, tokenizer = load(model_path)

# Convert to float16 for better performance on Apple Silicon
model.convert_to_float16()

# Sample inference
prompt = "Write a function to find prime numbers in Python"
results = generate(
    model, 
    tokenizer,
    prompt=prompt,
    max_tokens=512,
    temperature=0.7,
    top_p=0.9,
)

print(results[0]["generation"])

# Benchmark the model
import time

def benchmark_inference(model, tokenizer, prompt, runs=10):
    # Warmup
    generate(model, tokenizer, prompt=prompt, max_tokens=128)
    
    # Benchmark
    start_time = time.time()
    for _ in range(runs):
        generate(model, tokenizer, prompt=prompt, max_tokens=128)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / runs
    return avg_time

avg_inference_time = benchmark_inference(model, tokenizer, "Explain quantum computing")
print(f"Average inference time: {avg_inference_time:.4f} seconds")

# Save the optimized model for later use
model.save_weights("phi4_mini_optimized_mlx.npz")
```

## риЙридрикри╛рижрии ридри╛риЗриири╛ридрйА риЕридрйЗ риЗрй░рилри░рйИриВри╕ ри░ригриирйАридрйАриЖриВ

### Ollama: ри╕ризри╛ри░рии ри╕риери╛риириХ ридри╛риЗриири╛ридрйА

Ollama ри╕риери╛риириХ риЕридрйЗ риРриЬ ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри▓риИ риПриириЯри░рикрйНри░ри╛риИриЬри╝-ридри┐риЖри░ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ рижрйЗ риири╛ри▓ SLM ридри╛риЗриири╛ридрйА риирйВрй░ ри╕ризри╛ри░рии римригри╛риЙриВрижри╛ ри╣рйИ:

**ридри╛риЗриири╛ридрйА ри╕риори░рй▒риери╛ри╡ри╛риВ**: риЗрй▒риХ риХриори╛риВриб риори╛рибри▓ риЗрй░ри╕риЯри╛ри▓рйЗри╕ри╝рии риЕридрйЗ риХри╛ри░риЬриХри╛ри░рйА рижрйЗ риири╛ри▓ ри╕ри╡рйИриЪри╛ри▓ри┐рид риори╛рибри▓ риЦри┐рй▒риЪ риЕридрйЗ риХрйИри╕ри╝ри┐рй░риЧред Phi-4-mini-3.8B, рикрйВри░рйА Qwen3 ри╕рйАри░рйАриЬри╝ (0.6B/1.7B/4B), риЕридрйЗ Google Gemma3 ри▓риИ ри╕ри╣ри╛риЗридри╛ REST API рижрйЗ риири╛ри▓ риРрикри▓рйАриХрйЗри╕ри╝рии риЗрй░риЯри┐риЧрйНри░рйЗри╕ри╝рии риЕридрйЗ римри╣рйБ-риори╛рибри▓ рикрйНри░римрй░ризрии риЕридрйЗ ри╕ри╡ри┐рй▒риЪри┐рй░риЧ ри╕риори░рй▒риери╛ри╡ри╛риВ рикрйНри░рижри╛рии риХри░рижрйА ри╣рйИред BitNET риори╛рибри▓ри╛риВ ри▓риИ 1-римри┐риЯ риори╛ридри░ри╛ риШриЯри╛риЙриг ри╕риори░риерии ри▓риИ рикрйНри░рипрйЛриЧри╛ридриориХ римри┐ри▓риб ри╕рй░ри░риЪриири╛ри╡ри╛риВ рижрйА ри▓рйЛрйЬ ри╣рйБрй░рижрйА ри╣рйИред

**риЙрй▒риЪридрио ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ**: риХри╕риЯрио риори╛рибри▓ рилри╛риИрии-риЯри┐риКриири┐рй░риЧ ри╕риори░риерии, риХрй░риЯрйЗриири░ри╛риИриЬри╝риб ридри╛риЗриири╛ридрйА ри▓риИ Dockerfile риЬриири░рйЗри╕ри╝рии, GPU ридрйАри╡ри░ридри╛ рижрйЗ риири╛ри▓ ри╕ри╡рйИриЪри╛ри▓ри┐рид рикриЫри╛риг, риЕридрйЗ риори╛рибри▓ риори╛ридри░ри╛ риШриЯри╛риЙриг риЕридрйЗ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии ри╡ри┐риХри▓рик ри╡ри┐ри╕ри╝ри╛ри▓ ридри╛риЗриири╛ридрйА ри▓риЪриХридри╛ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред

### VLLM: риЙрй▒риЪ-рикрйНри░рижри░ри╕ри╝рии риЗрй░рилри░рйИриВри╕

VLLM риЙрй▒риЪ-риери░рйВрикрйБрй▒риЯ рижрйНри░ри┐ри╕ри╝ри╛риВ ри▓риИ риЙридрикри╛рижрии-риЧрйНри░рйЗриб риЗрй░рилри░рйИриВри╕ риЕрикриЯрйАриори╛риИриЬри╝рйЗри╕ри╝рии рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ:

**рикрйНри░рижри░ри╕ри╝рии риЕрикриЯрйАрио

---

**риЕри╕ри╡рйАриХри░ридрйА**:  
риЗри╣ рижри╕ридри╛ри╡рйЗриЬри╝ AI риЕриирйБри╡ри╛риж ри╕рйЗри╡ри╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рижрйА ри╡ри░ридрйЛриВ риХри░риХрйЗ риЕриирйБри╡ри╛риж риХрйАридри╛ риЧри┐риЖ ри╣рйИред риЬрижрйЛриВ риХри┐ риЕри╕рйАриВ ри╕ри╣рйА ри╣рйЛриг рижрйА риХрйЛри╕ри╝ри┐ри╕ри╝ риХри░рижрйЗ ри╣ри╛риВ, риХри┐ри░рикри╛ риХри░риХрйЗ ризри┐риЖрии рижри┐риУ риХри┐ ри╕ри╡рйИриЪри╛ри▓ри┐рид риЕриирйБри╡ри╛рижри╛риВ ри╡ри┐рй▒риЪ риЧри▓ридрйАриЖриВ риЬри╛риВ риЕри╕рйБриЪрйАридридри╛ри╡ри╛риВ ри╣рйЛ ри╕риХрижрйАриЖриВ ри╣рииред риЗри╕ рижрйА риорйВри▓ ринри╛ри╕ри╝ри╛ ри╡ри┐рй▒риЪ риорйВри▓ рижри╕ридри╛ри╡рйЗриЬри╝ риирйВрй░ риЕризри┐риХри╛ри░рид ри╕ри░рйЛрид риорй░риири┐риЖ риЬри╛ригри╛ риЪри╛ри╣рйАрижри╛ ри╣рйИред риори╣рй▒ридри╡рикрйВри░рии риЬри╛ригриХри╛ри░рйА ри▓риИ, рикрйЗри╕ри╝рйЗри╡ри░ риориирйБрй▒риЦрйА риЕриирйБри╡ри╛риж рижрйА ри╕ри┐рилри╛ри░ри╕ри╝ риХрйАридрйА риЬри╛риВрижрйА ри╣рйИред риЗри╕ риЕриирйБри╡ри╛риж рижрйА ри╡ри░ридрйЛриВ ридрйЛриВ рикрйИрижри╛ ри╣рйЛриг ри╡ри╛ри▓рйЗ риХри┐ри╕рйЗ ри╡рйА риЧри▓ридрилри╣ри┐риорйА риЬри╛риВ риЧри▓рид ри╡ри┐риЖриЦри┐риЖ ри▓риИ риЕри╕рйАриВ риЬри╝ри┐рй░риорйЗри╡ри╛ри░ риири╣рйАриВ ри╣ри╛риВред