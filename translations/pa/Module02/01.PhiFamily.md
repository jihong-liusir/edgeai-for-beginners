<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T22:40:20+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "pa"
}
-->
# ਸੈਕਸ਼ਨ 1: ਮਾਈਕਰੋਸਾਫਟ ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ ਦੇ ਮੂਲ ਸਿਧਾਂਤ

ਮਾਈਕਰੋਸਾਫਟ ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ ਕ੍ਰਿਤਰਿਮ ਬੁੱਧੀ ਵਿੱਚ ਇੱਕ ਨਵਾਂ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਪੇਸ਼ ਕਰਦਾ ਹੈ, ਜੋ ਦਿਖਾਉਂਦਾ ਹੈ ਕਿ ਛੋਟੇ ਅਤੇ ਕੁਸ਼ਲ ਮਾਡਲ ਪ੍ਰਚੰਡ ਪ੍ਰਦਰਸ਼ਨ ਹਾਸਲ ਕਰ ਸਕਦੇ ਹਨ, ਜਦੋਂ ਕਿ ਰਵਾਇਤੀ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨਾਲੋਂ ਕਾਫ਼ੀ ਵੱਧ ਸੰਸਾਧਨ-ਕੁਸ਼ਲ ਹੁੰਦੇ ਹਨ। ਇਹ ਸਮਝਣਾ ਮਹੱਤਵਪੂਰਨ ਹੈ ਕਿ ਫਾਈ ਪਰਿਵਾਰ ਘੱਟ ਗਣਨਾ ਦੀਆਂ ਲੋੜਾਂ ਨਾਲ ਸ਼ਕਤੀਸ਼ਾਲੀ AI ਸਮਰੱਥਾਵਾਂ ਕਿਵੇਂ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ, ਜਦੋਂ ਕਿ ਵੱਖ-ਵੱਖ ਕੰਮਾਂ ਵਿੱਚ ਉੱਚ ਪ੍ਰਦਰਸ਼ਨ ਨੂੰ ਕਾਇਮ ਰੱਖਦਾ ਹੈ।

## ਡਿਵੈਲਪਰਾਂ ਲਈ ਸਰੋਤ

### Azure AI Foundry Model Catalog
ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ (ਫਾਈ-ਸਿਲਿਕਾ ਨੂੰ ਛੱਡ ਕੇ) [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi) ਰਾਹੀਂ ਉਪਲਬਧ ਹੈ, ਜੋ ਡਿਵੈਲਪਰਾਂ ਲਈ ਆਪਣੇ ਐਪਲੀਕੇਸ਼ਨਾਂ ਵਿੱਚ ਇਹ ਮਾਡਲ ਪਹੁੰਚਾਉਣ, ਸੁਧਾਰਨ ਅਤੇ ਤੈਨਾਤ ਕਰਨ ਨੂੰ ਆਸਾਨ ਬਣਾਉਂਦਾ ਹੈ। ਕੈਟਾਲਾਗ ਵੱਖ-ਵੱਖ ਫਾਈ ਵੈਰੀਐਂਟਸ ਨਾਲ ਪ੍ਰਯੋਗ ਕਰਨ ਅਤੇ ਉਨ੍ਹਾਂ ਨੂੰ ਆਪਣੇ ਪ੍ਰੋਜੈਕਟਾਂ ਵਿੱਚ ਸ਼ਾਮਲ ਕਰਨ ਦਾ ਇੱਕ ਸਧਾਰਨ ਤਰੀਕਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।

### Azure AI Foundry
ਤੁਸੀਂ [Azure AI Foundry](https://ai.azure.com) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਫਾਈ ਮਾਡਲ ਤੈਨਾਤ ਅਤੇ ਪ੍ਰਯੋਗ ਕਰ ਸਕਦੇ ਹੋ, ਜੋ ਘੱਟ ਸੈਟਅੱਪ ਨਾਲ AI ਹੱਲ ਬਣਾਉਣ, ਟੈਸਟ ਕਰਨ ਅਤੇ ਤੈਨਾਤ ਕਰਨ ਲਈ ਇੱਕ ਵਿਸਤ੍ਰਿਤ ਵਾਤਾਵਰਣ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।

### Foundry Local
ਸਥਾਨਕ ਵਿਕਾਸ ਅਤੇ ਤੈਨਾਤ ਲਈ, [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) ਦੀ ਜਾਂਚ ਕਰੋ, ਜੋ ਤੁਹਾਡੇ ਵਿਕਾਸ ਮਸ਼ੀਨ 'ਤੇ ਫਾਈ ਮਾਡਲਾਂ ਨੂੰ ਅਨੁਕੂਲ ਸੰਰਚਨਾਵਾਂ ਨਾਲ ਚਲਾਉਣ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ।

### ਦਸਤਾਵੇਜ਼ ਸਰੋਤ
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## ਪਰਿਚਯ

ਇਸ ਪਾਠ ਵਿੱਚ, ਅਸੀਂ ਮਾਈਕਰੋਸਾਫਟ ਦੇ ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ ਅਤੇ ਇਸ ਦੇ ਮੂਲ ਸਿਧਾਂਤਾਂ ਦੀ ਪੜਚੋਲ ਕਰਾਂਗੇ। ਅਸੀਂ ਫਾਈ ਪਰਿਵਾਰ ਦੇ ਵਿਕਾਸ, ਉਹਨਾਂ ਨਵੋਨਮਾਤਮਿਕ ਤਰਬੀਬਾਂ ਨੂੰ ਕਵਰ ਕਰਾਂਗੇ ਜੋ ਫਾਈ ਮਾਡਲਾਂ ਨੂੰ ਕੁਸ਼ਲ ਬਣਾਉਂਦੀਆਂ ਹਨ, ਪਰਿਵਾਰ ਵਿੱਚ ਮੁੱਖ ਵੈਰੀਐਂਟਸ, ਅਤੇ ਵੱਖ-ਵੱਖ ਸਥਿਤੀਆਂ ਵਿੱਚ ਵਿਹਾਰਕ ਐਪਲੀਕੇਸ਼ਨਾਂ ਦੀ ਚਰਚਾ ਕਰਾਂਗੇ।

## ਸਿੱਖਣ ਦੇ ਉਦੇਸ਼

ਇਸ ਪਾਠ ਦੇ ਅੰਤ ਤੱਕ, ਤੁਸੀਂ ਯੋਗ ਹੋਵੋਗੇ:

- ਮਾਈਕਰੋਸਾਫਟ ਦੇ ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ ਦੇ ਡਿਜ਼ਾਈਨ ਫ਼ਲਸਫ਼ੇ ਅਤੇ ਵਿਕਾਸ ਨੂੰ ਸਮਝਣਾ।
- ਉਹ ਮੁੱਖ ਨਵੋਨਮਾਤਮਿਕ ਤੱਤਾਂ ਦੀ ਪਛਾਣ ਕਰਨਾ ਜੋ ਫਾਈ ਮਾਡਲਾਂ ਨੂੰ ਘੱਟ ਪੈਰਾਮੀਟਰਾਂ ਨਾਲ ਉੱਚ ਪ੍ਰਦਰਸ਼ਨ ਹਾਸਲ ਕਰਨ ਯੋਗ ਬਣਾਉਂਦੇ ਹਨ।
- ਵੱਖ-ਵੱਖ ਫਾਈ ਮਾਡਲ ਵੈਰੀਐਂਟਸ ਦੇ ਫਾਇਦੇ ਅਤੇ ਸੀਮਾਵਾਂ ਨੂੰ ਪਛਾਣਨਾ।
- ਅਸਲ-ਜਗਤ ਦੀਆਂ ਸਥਿਤੀਆਂ ਲਈ ਉਚਿਤ ਵੈਰੀਐਂਟਸ ਦੀ ਚੋਣ ਕਰਨ ਲਈ ਫਾਈ ਮਾਡਲਾਂ ਦੇ ਗਿਆਨ ਨੂੰ ਲਾਗੂ ਕਰਨਾ।

## ਰਵਾਇਤੀ AI ਮਾਡਲ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਨੂੰ ਸਮਝਣਾ

ਰਵਾਇਤੀ ਤੌਰ 'ਤੇ, ਕੁਦਰਤੀ ਭਾਸ਼ਾ ਪ੍ਰੋਸੈਸਿੰਗ ਵਿੱਚ ਉੱਚ ਪ੍ਰਦਰਸ਼ਨ ਹਾਸਲ ਕਰਨ ਲਈ ਅਰਬਾਂ ਜਾਂ ਸੌ ਅਰਬਾਂ ਪੈਰਾਮੀਟਰਾਂ ਵਾਲੇ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਦੀ ਲੋੜ ਹੁੰਦੀ ਸੀ। ਸੰਗਠਨ ਆਮ ਤੌਰ 'ਤੇ ਇਹ ਮਾਡਲ ਸ਼ਕਤੀਸ਼ਾਲੀ GPU ਕਲਸਟਰਾਂ 'ਤੇ ਤੈਨਾਤ ਕਰਦੇ ਹਨ, API ਇੰਟਰਫੇਸ ਜਾਂ ਵਿਸ਼ੇਸ਼ ਹਾਰਡਵੇਅਰ ਢਾਂਚੇ ਰਾਹੀਂ ਉਨ੍ਹਾਂ ਦੀ ਸਮਰੱਥਾ ਤੱਕ ਪਹੁੰਚ ਪ੍ਰਾਪਤ ਕਰਦੇ ਹਨ।

ਇਹ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਕਈ ਐਪਲੀਕੇਸ਼ਨਾਂ ਲਈ ਚੰਗਾ ਕੰਮ ਕਰਦਾ ਹੈ ਪਰ ਵਿਹਾਰਕ ਤੈਨਾਤ ਸਥਿਤੀਆਂ ਦੇ ਸੰਦਰਭ ਵਿੱਚ ਅੰਦਰੂਨੀ ਸੀਮਾਵਾਂ ਰੱਖਦਾ ਹੈ। ਰਵਾਇਤੀ ਤਰੀਕਾ ਉਹ ਮਾਡਲ ਵਰਤਦਾ ਹੈ ਜੋ ਵੱਡੇ ਗਣਨਾਤਮਕ ਸੰਸਾਧਨ, ਵੱਡੀ ਮੈਮਰੀ, ਅਤੇ ਮਹੱਤਵਪੂਰਨ ਊਰਜਾ ਖਪਤ ਦੀ ਲੋੜ ਕਰਦੇ ਹਨ। ਜਦੋਂ ਕਿ ਇਹ ਤਰੀਕਾ ਸਟੇਟ-ਆਫ-ਦ-ਆਰਟ ਸਮਰੱਥਾਵਾਂ ਤੱਕ ਪਹੁੰਚ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ, ਇਹ ਮਹਿੰਗੇ ਹਾਰਡਵੇਅਰ 'ਤੇ ਨਿਰਭਰਤਾ ਪੈਦਾ ਕਰਦਾ ਹੈ, ਉੱਚ ਓਪਰੇਸ਼ਨਲ ਲਾਗਤਾਂ ਪੈਦਾ ਕਰਦਾ ਹੈ, ਅਤੇ ਤੈਨਾਤ ਦੀ ਲਚੀਲਤਾ ਨੂੰ ਸੀਮਿਤ ਕਰਦਾ ਹੈ।

## ਕੁਸ਼ਲ AI ਤੈਨਾਤ ਦੀ ਚੁਣੌਤੀ

ਵੱਖ-ਵੱਖ ਸਥਿਤੀਆਂ ਵਿੱਚ ਵਧੇਰੇ ਕੁਸ਼ਲ AI ਦੀ ਲੋੜ ਬਹੁਤ ਮਹੱਤਵਪੂਰਨ ਹੋ ਗਈ ਹੈ। ਉਹ ਐਪਲੀਕੇਸ਼ਨ ਵਿਚਾਰੋ ਜੋ ਗੋਪਨੀਯਤਾ ਕਾਰਨਾਂ ਲਈ ਸਥਾਨਕ ਤੈਨਾਤ ਦੀ ਲੋੜ ਕਰਦੇ ਹਨ, ਲਾਗਤ-ਸੰਵੇਦਨਸ਼ੀਲ ਕਾਰਜਾਂ ਜਿੱਥੇ ਕਲਾਉਡ API ਲਾਗਤਾਂ ਰੁਕਾਵਟ ਬਣ ਜਾਂਦੀਆਂ ਹਨ, ਸੀਮਿਤ ਹਾਰਡਵੇਅਰ ਸੰਸਾਧਨਾਂ ਵਾਲੇ ਐਜ ਕੰਪਿਊਟਿੰਗ ਸਥਿਤੀਆਂ, ਜਾਂ ਰੀਅਲ-ਟਾਈਮ ਐਪਲੀਕੇਸ਼ਨ ਜਿੱਥੇ ਲੈਟੈਂਸੀ ਮਹੱਤਵਪੂਰਨ ਹੁੰਦੀ ਹੈ।

### ਮੁੱਖ ਤੈਨਾਤ ਸੀਮਾਵਾਂ

ਰਵਾਇਤੀ ਵੱਡੇ ਮਾਡਲ ਤੈਨਾਤ ਕਈ ਅਧਾਰਭੂਤ ਸੀਮਾਵਾਂ ਦਾ ਸਾਹਮਣਾ ਕਰਦੇ ਹਨ ਜੋ ਉਨ੍ਹਾਂ ਦੀ ਵਿਹਾਰਕ ਲਾਗੂਤਾ ਨੂੰ ਸੀਮਿਤ ਕਰਦੇ ਹਨ:

- **ਲਾਗਤ ਦੀਆਂ ਸੀਮਾਵਾਂ**: ਉੱਚ ਗਣਨਾਤਮਕ ਲਾਗਤਾਂ ਕਈ ਸੰਗਠਨਾਂ ਲਈ ਲਗਾਤਾਰ ਤੈਨਾਤ ਨੂੰ ਮਹਿੰਗਾ ਬਣਾਉਂਦੀਆਂ ਹਨ।
- **ਸੰਸਾਧਨ ਦੀਆਂ ਸੀਮਾਵਾਂ**: ਉੱਚ-ਅੰਤ GPU ਢਾਂਚੇ ਤੱਕ ਸੀਮਿਤ ਪਹੁੰਚ ਤੈਨਾਤ ਦੇ ਵਿਕਲਪਾਂ ਨੂੰ ਸੀਮਿਤ ਕਰਦੀ ਹੈ।
- **ਗੋਪਨੀਯਤਾ ਦੀਆਂ ਲੋੜਾਂ**: ਸੰਵੇਦਨਸ਼ੀਲ ਐਪਲੀਕੇਸ਼ਨਾਂ ਨੂੰ ਡਾਟਾ ਗੋਪਨੀਯਤਾ ਨੂੰ ਕਾਇਮ ਰੱਖਣ ਲਈ ਸਥਾਨਕ ਪ੍ਰੋਸੈਸਿੰਗ ਦੀ ਲੋੜ ਹੁੰਦੀ ਹੈ।
- **ਲੈਟੈਂਸੀ ਸੰਵੇਦਨਸ਼ੀਲਤਾ**: ਰੀਅਲ-ਟਾਈਮ ਐਪਲੀਕੇਸ਼ਨਾਂ ਨੂੰ ਕਲਾਉਡ ਰਾਊਂਡ-ਟ੍ਰਿਪ ਦੇਰੀ ਤੋਂ ਬਿਨਾਂ ਤੁਰੰਤ ਜਵਾਬ ਦੀ ਲੋੜ ਹੁੰਦੀ ਹੈ।

## ਮਾਈਕਰੋਸਾਫਟ ਫਾਈ ਮਾਡਲ ਫ਼ਲਸਫ਼ਾ

ਮਾਈਕਰੋਸਾਫਟ ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ AI ਮਾਡਲ ਡਿਜ਼ਾਈਨ ਫ਼ਲਸਫ਼ੇ ਵਿੱਚ ਇੱਕ ਮੂਲ ਬਦਲਾਅ ਦਾ ਪ੍ਰਤੀਕ ਹੈ, ਜੋ ਕੁਸ਼ਲਤਾ ਅਤੇ ਵਿਹਾਰਕ ਤੈਨਾਤ ਨੂੰ ਤਰਜੀਹ ਦਿੰਦਾ ਹੈ ਜਦੋਂ ਕਿ ਮਜ਼ਬੂਤ ਪ੍ਰਦਰਸ਼ਨ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ ਨੂੰ ਕਾਇਮ ਰੱਖਦਾ ਹੈ। ਫਾਈ ਮਾਡਲ ਨਵੋਨਮਾਤਮਿਕ ਸੰਰਚਨਾਵਾਂ, ਉੱਚ-ਗੁਣਵੱਤਾ ਵਾਲੀਆਂ ਤਰਬੀਬਾਂ, ਅਤੇ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ ਵਾਲੀਆਂ ਅਨੁਕੂਲਣ ਤਕਨੀਕਾਂ ਰਾਹੀਂ ਇਹ ਹਾਸਲ ਕਰਦੇ ਹਨ।

ਫਾਈ ਪਰਿਵਾਰ ਵੱਖ-ਵੱਖ ਦ੍ਰਿਸ਼ਟੀਕੋਣਾਂ ਨੂੰ ਸ਼ਾਮਲ ਕਰਦਾ ਹੈ ਜੋ ਪ੍ਰਦਰਸ਼ਨ ਪ੍ਰਤੀ ਪੈਰਾਮੀਟਰ ਨੂੰ ਵਧਾਉਣ ਲਈ ਡਿਜ਼ਾਈਨ ਕੀਤੇ ਗਏ ਹਨ, ਸਟੈਂਡਰਡ ਹਾਰਡਵੇਅਰ 'ਤੇ ਤੈਨਾਤ ਨੂੰ ਯੋਗ ਬਣਾਉਂਦੇ ਹਨ ਜਦੋਂ ਕਿ ਅਰਥਪੂਰਨ AI ਸਮਰੱਥਾਵਾਂ ਪ੍ਰਦਾਨ ਕਰਦੇ ਹਨ। ਉਦੇਸ਼ ਮੁਕਾਬਲੇਬਾਜ਼ ਪ੍ਰਦਰਸ਼ਨ ਨੂੰ ਕਾਇਮ ਰੱਖਣਾ ਹੈ ਜਦੋਂ ਕਿ ਗਣਨਾਤਮਕ ਲੋੜਾਂ, ਮੈਮਰੀ ਦੀ ਵਰਤੋਂ, ਅਤੇ ਓਪਰੇਸ਼ਨਲ ਲਾਗਤਾਂ ਨੂੰ ਨਾਘਾ ਘਟਾਉਣਾ ਹੈ।

### ਮੁੱਖ ਫਾਈ ਡਿਜ਼ਾਈਨ ਸਿਧਾਂਤ

ਫਾਈ ਮਾਡਲ ਕਈ ਅਧਾਰਭੂਤ ਸਿਧਾਂਤਾਂ 'ਤੇ ਬਣੇ ਹਨ ਜੋ ਉਨ੍ਹਾਂ ਨੂੰ ਰਵਾਇਤੀ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਤੋਂ ਵੱਖ ਕਰਦੇ ਹਨ:

- **ਕੁਸ਼ਲਤਾ ਪਹਿਲਾਂ**: ਪੈਮਾਨੇ ਦੀ ਬਜਾਏ ਪ੍ਰਦਰਸ਼ਨ ਪ੍ਰਤੀ ਪੈਰਾਮੀਟਰ ਲਈ ਅਨੁਕੂਲਿਤ।
- **ਗੁਣਵੱਤਾ ਵਾਲੀ ਤਰਬੀਬ**: ਵੱਡੇ ਡਾਟਾਸੈਟਾਂ ਦੀ ਬਜਾਏ ਉੱਚ-ਗੁਣਵੱਤਾ, ਚੁਣੀ ਗਈ ਤਰਬੀਬ ਡਾਟਾ 'ਤੇ ਧਿਆਨ।
- **ਤੈਨਾਤ ਦੀ ਲਚੀਲਤਾ**: ਵੱਖ-ਵੱਖ ਹਾਰਡਵੇਅਰ ਸੰਰਚਨਾਵਾਂ 'ਤੇ ਪ੍ਰਭਾਵਸ਼ਾਲੀ ਤੌਰ 'ਤੇ ਚਲਾਉਣ ਲਈ ਡਿਜ਼ਾਈਨ ਕੀਤਾ ਗਿਆ।
- **ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ ਵਾਲੀਆਂ ਸਮਰੱਥਾਵਾਂ**: ਵਿਸ਼ੇਸ਼ ਕੰਮਾਂ ਜਾਂ ਖੇਤਰਾਂ ਲਈ ਅਕਸਰ ਅਨੁਕੂਲਿਤ।

## ਫਾਈ ਪਰਿਵਾਰ ਦੇ ਵਿਕਾਸ ਦਾ ਭਵਿੱਖ

ਫਾਈ ਮਾਡਲ ਪਰਿਵਾਰ ਕੁਸ਼ਲ, ਵਿਹਾਰਕ AI ਤੈਨਾਤ ਵੱਲ ਇੱਕ ਵੱਡੇ ਰੁਝਾਨ ਦੀ ਸ਼ੁਰੂਆਤ ਦਾ ਪ੍ਰਤੀਕ ਹੈ। ਭਵਿੱਖ ਦੇ ਵਿਕਾਸ ਵਿੱਚ ਸੁਧਾਰਿਤ ਕੁਸ਼ਲਤਾ ਮਾਪਦੰਡ, ਵਧੇਰੇ ਮਲਟੀਮੋਡਲ ਸਮਰੱਥਾਵਾਂ, ਵਿਸ਼ੇਸ਼ ਉਦਯੋਗਾਂ ਲਈ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ ਵਾਲੇ ਵੈਰੀਐਂਟਸ, ਅਤੇ ਐਜ ਕੰਪਿਊਟਿੰਗ ਢਾਂਚੇ ਨਾਲ ਬਿਹਤਰ ਇਕੀਕਰਨ ਸ਼ਾਮਲ ਹਨ।

ਜਿਵੇਂ ਤਕਨੀਕ ਵਿਕਸਿਤ ਹੁੰਦੀ ਹੈ, ਅਸੀਂ ਉਮੀਦ ਕਰ ਸਕਦੇ ਹਾਂ ਕਿ ਫਾਈ ਮਾਡਲ ਵਧੇਰੇ ਸਮਰੱਥ ਹੋਣਗੇ ਜਦੋਂ ਕਿ ਉਨ੍ਹਾਂ ਦੇ ਕੁਸ਼ਲਤਾ ਫਾਇਦੇ ਨੂੰ ਕਾਇਮ ਰੱਖਦੇ ਹੋਏ, ਉਹਨਾਂ ਸਥਿਤੀਆਂ ਵਿੱਚ AI ਤੈਨਾਤ ਯੋਗ ਬਣਾਉਂਦੇ ਹੋਏ ਜਿੱਥੇ ਪਹਿਲਾਂ ਗਣਨਾਤਮਕ ਲੋੜਾਂ ਰੁਕਾਵਟ ਬਣਦੀਆਂ ਸਨ।
Phi ਪਰਿਵਾਰ ਦਿਖਾਉਂਦਾ ਹੈ ਕਿ AI ਨੂੰ ਤੈਨਾਤ ਕਰਨ ਦਾ ਭਵਿੱਖ ਸਿਰਫ ਵੱਡੇ ਮਾਡਲ ਬਣਾਉਣ ਵਿੱਚ ਨਹੀਂ ਹੈ, ਸਗੋਂ ਹੋਸ਼ਿਆਰ ਅਤੇ ਜ਼ਿਆਦਾ ਕੁਸ਼ਲ ਮਾਡਲ ਬਣਾਉਣ ਵਿੱਚ ਹੈ ਜੋ ਵੱਖ-ਵੱਖ ਹਾਰਡਵੇਅਰ ਵਾਤਾਵਰਣਾਂ ਵਿੱਚ ਪ੍ਰਭਾਵਸ਼ਾਲੀ ਤਰੀਕੇ ਨਾਲ ਕੰਮ ਕਰ ਸਕਦੇ ਹਨ ਜਦੋਂ ਕਿ ਉੱਚ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡਾਂ ਨੂੰ ਕਾਇਮ ਰੱਖਦੇ ਹਨ।

## ਵਿਕਾਸ ਅਤੇ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਉਦਾਹਰਨਾਂ

### ਟ੍ਰਾਂਸਫਾਰਮਰ ਨਾਲ ਜਲਦੀ ਸ਼ੁਰੂਆਤ

ਇੱਥੇ ਹੈ ਕਿ Phi ਮਾਡਲਾਂ ਨਾਲ Hugging Face Transformers ਲਾਇਬ੍ਰੇਰੀ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਕਿਵੇਂ ਸ਼ੁਰੂਆਤ ਕਰਨੀ ਹੈ:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### ਫਾਈਨ-ਟਿਊਨਿੰਗ ਉਦਾਹਰਨ

ਹੇਠਾਂ ਦਿੱਤਾ ਉਦਾਹਰਨ ਦਿਖਾਉਂਦਾ ਹੈ ਕਿ Phi-4-mini-instruct ਨੂੰ ਖਾਸ ਕੰਮਾਂ ਲਈ ਕਿਵੇਂ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### ਵਿਸ਼ੇਸ਼ ਪ੍ਰੋਮਪਟ ਫਾਰਮੈਟ

**ਤਰਕਸ਼ੀਲ ਕੰਮਾਂ ਲਈ (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**ਗਣਿਤੀ ਕੰਮਾਂ ਲਈ (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### ONNX ਨਾਲ ਮੋਬਾਈਲ ਤੈਨਾਤੀ

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## ਪ੍ਰਦਰਸ਼ਨ ਬੈਂਚਮਾਰਕ ਅਤੇ ਉਪਲਬਧੀਆਂ

Phi ਮਾਡਲ ਪਰਿਵਾਰ ਨੇ ਵੱਖ-ਵੱਖ ਬੈਂਚਮਾਰਕਾਂ 'ਤੇ ਸ਼ਾਨਦਾਰ ਪ੍ਰਦਰਸ਼ਨ ਹਾਸਲ ਕੀਤਾ ਹੈ, ਅਕਸਰ ਕਾਫ਼ੀ ਵੱਡੇ ਮਾਡਲਾਂ ਨੂੰ ਪਿੱਛੇ ਛੱਡਦੇ ਹੋਏ:

### ਮੁੱਖ ਪ੍ਰਦਰਸ਼ਨ ਹਾਈਲਾਈਟਸ

**ਗਣਿਤੀ ਤਰਕਸ਼ੀਲਤਾ ਵਿੱਚ ਸ਼ਾਨਦਾਰਤਾ:**
- Phi-4 ਨੇ AIME 2025 (Math Olympiad ਕਵਾਲੀਫਾਇਰ) 'ਤੇ 82.5% ਸਹੀਤਾ ਹਾਸਲ ਕੀਤੀ
- Phi-4-reasoning (14B) ਨੇ reasoning ਬੈਂਚਮਾਰਕਾਂ 'ਤੇ DeepSeek-R1-Distill-70B (5x ਵੱਡਾ) ਨੂੰ ਪਿੱਛੇ ਛੱਡਿਆ
- Phi-4-mini-reasoning (3.8B) ਨੇ ਗਣਿਤੀ ਤਰਕਸ਼ੀਲਤਾ ਕੰਮਾਂ 'ਤੇ ਦੋ ਗੁਣਾ ਵੱਡੇ ਮਾਡਲਾਂ ਦੇ ਸਮਾਨ ਪ੍ਰਦਰਸ਼ਨ ਕੀਤਾ

**ਕੁਸ਼ਲਤਾ ਉਪਲਬਧੀਆਂ:**
- Phi-3-Silica ਨੇ ਸਿਰਫ 1.5W ਪਾਵਰ ਖਪਤ ਨਾਲ 650 ਟੋਕਨ ਪ੍ਰਤੀ ਸਕਿੰਟ ਹਾਸਲ ਕੀਤੇ
- Phi-4-mini (3.8B) ਨੇ ਕਾਫ਼ੀ ਵੱਡੇ ਮਾਡਲਾਂ ਦੇ ਸਮਾਨ ਪ੍ਰਦਰਸ਼ਨ ਹਾਸਲ ਕੀਤਾ

**ਬੈਂਚਮਾਰਕ ਪ੍ਰਦਰਸ਼ਨ:**
- **MMLU (Massive Multitask Language Understanding)**: 57 ਅਕਾਦਮਿਕ ਵਿਸ਼ਿਆਂ 'ਤੇ ਮੁਕਾਬਲਾਤੀ ਪ੍ਰਦਰਸ਼ਨ
- **HumanEval**: ਕੋਡ ਜਨਰੇਸ਼ਨ ਸਮਰੱਥਾ, ਖਾਸ ਤੌਰ 'ਤੇ Python ਵਿੱਚ
- **MGSM**: ਬਹੁ-ਭਾਸ਼ਾਈ ਗਰੇਡ-ਸਕੂਲ ਗਣਿਤ ਸਮੱਸਿਆ ਹੱਲ
- **DROP**: ਜਟਿਲ ਸਮਝ ਅਤੇ ਤਰਕਸ਼ੀਲਤਾ ਕੰਮ
- **SimpleQA**: ਤਥਯਾਤਮਕ ਜਵਾਬ ਸਹੀਤਾ

### 📊 ਮਾਡਲ ਤੁਲਨਾ ਮੈਟ੍ਰਿਕਸ

| ਮਾਡਲ | ਪੈਰਾਮੀਟਰ | ਸੰਦਰਭ ਲੰਬਾਈ | ਮੁੱਖ ਤਾਕਤਾਂ | ਸਭ ਤੋਂ ਵਧੀਆ ਵਰਤੋਂ ਕੇਸ |
|-------|------------|----------------|---------------|----------------|
| **Phi-3-mini** | 3.8B | 4K/128K | ਜਨਰਲ ਕੁਸ਼ਲਤਾ | ਮੋਬਾਈਲ ਐਪਸ, ਬੇਸਿਕ ਚੈਟਬੋਟ |
| **Phi-3.5-mini** | 3.8B | 128K | ਬਹੁ-ਭਾਸ਼ਾਈ ਸਹਾਇਤਾ | ਅੰਤਰਰਾਸ਼ਟਰੀ ਐਪਲੀਕੇਸ਼ਨ |
| **Phi-4-mini** | 3.8B | 128K | ਵਧੀਆ ਤਰਕਸ਼ੀਲਤਾ, ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ | ਕਾਰੋਬਾਰੀ ਆਟੋਮੇਸ਼ਨ |
| **Phi-4-mini-reasoning** | 3.8B | 128K | ਗਣਿਤੀ ਤਰਕਸ਼ੀਲਤਾ | ਸ਼ਿਕਸ਼ਾ ਪਲੇਟਫਾਰਮ |
| **Phi-4** | 14B | 32K | ਜਟਿਲ ਤਰਕਸ਼ੀਲਤਾ | ਰਿਸਰਚ, ਉੱਚਤਮ ਵਿਸ਼ਲੇਸ਼ਣ |
| **Phi-4-reasoning** | 14B | 32K/64K | ਬਹੁ-ਕਦਮ ਤਰਕਸ਼ੀਲਤਾ | ਵਿਗਿਆਨਕ ਕੰਪਿਊਟਿੰਗ |
| **Phi-4-reasoning-plus** | 14B | 32K | ਅਧਿਕਤਮ ਸਹੀਤਾ ਤਰਕਸ਼ੀਲਤਾ | ਮਹੱਤਵਪੂਰਨ ਫੈਸਲੇ |
| **Phi-4-multimodal** | 5.6B | Variable | ਸਪੀਚ, ਵਿਜ਼ਨ, ਟੈਕਸਟ | ਮਲਟੀਮੀਡੀਆ ਐਪਲੀਕੇਸ਼ਨ |

## ਮਾਡਲ ਚੋਣ ਗਾਈਡ

### ਬੁਨਿਆਦੀ ਐਪਲੀਕੇਸ਼ਨ ਲਈ
- **Phi-3-mini**: ਸਧਾਰਨ ਟੈਕਸਟ ਜਨਰੇਸ਼ਨ, ਬੇਸਿਕ Q&A, ਜਲਦੀ ਜਵਾਬ
- **Phi-4-mini**: ਵਧੀਆ ਤਰਕਸ਼ੀਲਤਾ ਨਾਲ ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ ਸਮਰੱਥਾ

### ਗਣਿਤੀ ਅਤੇ ਤਰਕਸ਼ੀਲਤਾ ਕੰਮਾਂ ਲਈ
- **Phi-4**: ਜਟਿਲ ਗਣਿਤੀ ਸਮੱਸਿਆ ਹੱਲ ਅਤੇ ਤਰਕਸ਼ੀਲਤਾ
- **Phi-4-reasoning**: ਬਹੁ-ਕਦਮ ਤਰਕਸ਼ੀਲਤਾ ਨਾਲ ਵਿਸਤ੍ਰਿਤ ਵਿਆਖਿਆਵਾਂ
- **Phi-4-reasoning-plus**: ਮਹੱਤਵਪੂਰਨ ਤਰਕਸ਼ੀਲਤਾ ਐਪਲੀਕੇਸ਼ਨ ਲਈ ਅਧਿਕਤਮ ਸਹੀਤਾ
- **Phi-4-mini-reasoning**: ਸੰਸਾਧਨ-ਸੀਮਿਤ ਵਾਤਾਵਰਣਾਂ ਲਈ ਕੁਸ਼ਲ ਗਣਿਤੀ ਤਰਕਸ਼ੀਲਤਾ

### ਮਲਟੀਮੋਡਲ ਐਪਲੀਕੇਸ਼ਨ ਲਈ
- **Phi-3-vision**: ਚਿੱਤਰ ਅਤੇ ਟੈਕਸਟ ਪ੍ਰੋਸੈਸਿੰਗ ਸੰਯੋਜਨ
- **Phi-4-multimodal**: ਵਿਸਤ੍ਰਿਤ ਸਪੀਚ, ਵਿਜ਼ਨ, ਅਤੇ ਟੈਕਸਟ ਸਮਰੱਥਾ

### ਐਂਟਰਪ੍ਰਾਈਜ਼ ਤੈਨਾਤੀ ਲਈ
- **Phi-3-medium**: ਕਾਰੋਬਾਰੀ ਐਪਲੀਕੇਸ਼ਨ ਲਈ ਉੱਚਤਮ ਭਾਸ਼ਾ ਸਮਝ
- **Phi-3-Silica**: ਖਾਸ ਹਾਰਡਵੇਅਰ ਪਲੇਟਫਾਰਮ ਲਈ ਅਨੁਕੂਲਿਤ

## ਤੈਨਾਤੀ ਪਲੇਟਫਾਰਮ ਅਤੇ ਪਹੁੰਚਯੋਗਤਾ

### ਕਲਾਉਡ ਪਲੇਟਫਾਰਮ
- **Azure AI Foundry**: ਐਂਟਰਪ੍ਰਾਈਜ਼ ਟੂਲਾਂ ਨਾਲ ਪੂਰੀ-ਫੀਚਰ ਤੈਨਾਤੀ
- **Hugging Face**: ਖੁੱਲ੍ਹੇ-ਸਰੋਤ ਮਾਡਲ ਰਿਪੋਜ਼ਟਰੀ ਅਤੇ ਕਮਿਊਨਿਟੀ ਸਰੋਤ
- **NVIDIA API Catalog**: ਮਾਈਕ੍ਰੋਸਰਵਿਸ ਤੈਨਾਤੀ ਵਿਕਲਪ

### ਸਥਾਨਕ ਵਿਕਾਸ ਫਰੇਮਵਰਕ
- **Ollama**: ਸਥਾਨਕ ਮਾਡਲ ਤੈਨਾਤੀ ਲਈ ਹਲਕਾ ਫਰੇਮਵਰਕ
- **ONNX Runtime**: ਵੱਖ-ਵੱਖ ਹਾਰਡਵੇਅਰ ਸੰਰਚਨਾਵਾਂ ਲਈ ਅਨੁਕੂਲਿਤ  
- **DirectML**: Windows-ਅਨੁਕੂਲਿਤ ਪ੍ਰਦਰਸ਼ਨ
- **llama.cpp**: ਕ੍ਰਾਸ-ਪਲੇਟਫਾਰਮ ਇੰਫਰੈਂਸ ਇੰਜਨ

### ਸਿੱਖਣ ਦੇ ਸਰੋਤ
- **Phi Portal**: Microsoft Phi ਦਾ ਅਧਿਕਾਰਕ ਦਸਤਾਵੇਜ਼ੀ ਕੇਂਦਰ
- **Phi Cookbook**: ਵਿਸਤ੍ਰਿਤ ਉਦਾਹਰਨ ਅਤੇ ਟਿਊਟੋਰਿਅਲ
- **Technical Reports**: arxiv 'ਤੇ ਗਹਿਰੇ ਰਿਸਰਚ ਪੇਪਰ
- **Community Spaces**: Hugging Face ਇੰਟਰਐਕਟਿਵ ਡੈਮੋ

### Phi ਮਾਡਲਾਂ ਨਾਲ ਸ਼ੁਰੂਆਤ ਕਰਨਾ

#### ਵਿਕਾਸ ਪਲੇਟਫਾਰਮ
1. **Azure AI Foundry**: ਸਧਾਰਨ ਸਥਾਨਕ CLI ਅਤੇ ਮਾਡਲ ਪ੍ਰਬੰਧਨ।
2. **Hugging Face Transformers**: ਸਥਾਨਕ ਪ੍ਰਯੋਗ ਲਈ ਜਲਦੀ
3. **Ollama**: ਟੈਸਟਿੰਗ ਲਈ ਸਧਾਰਨ ਸਥਾਨਕ ਤੈਨਾਤੀ

#### ਸਿੱਖਣ ਦਾ ਪਾਥ
1. **ਮੁੱਢਲੇ ਸਿਧਾਂਤ ਸਮਝੋ**: ਮੁੱਖ ਡਿਜ਼ਾਈਨ ਸਿਧਾਂਤਾਂ ਦਾ ਅਧਿਐਨ ਕਰੋ
2. **ਵਿਕਲਪਾਂ ਨਾਲ ਪ੍ਰਯੋਗ ਕਰੋ**: ਵੱਖ-ਵੱਖ Phi ਮਾਡਲਾਂ ਦੀ ਸਮਰੱਥਾ ਸਮਝਣ ਲਈ ਕੋਸ਼ਿਸ਼ ਕਰੋ
3. **ਅਮਲ ਕਰਨ ਦੀ ਅਭਿਆਸ ਕਰੋ**: ਟੈਸਟ ਵਾਤਾਵਰਣਾਂ ਵਿੱਚ ਮਾਡਲ ਤੈਨਾਤ ਕਰੋ
4. **ਤੈਨਾਤੀ ਦਾ ਪੈਮਾਨਾ ਵਧਾਓ**: ਸਫਲ ਪਾਇਲਟਾਂ ਦੇ ਆਧਾਰ 'ਤੇ ਵਰਤੋਂ ਨੂੰ ਵਧਾਓ

#### ਸਭ ਤੋਂ ਵਧੀਆ ਅਭਿਆਸ
- **ਛੋਟੇ ਨਾਲ ਸ਼ੁਰੂ ਕਰੋ**: ਸ਼ੁਰੂਆਤੀ ਵਿਕਾਸ ਲਈ Phi-mini ਮਾਡਲਾਂ ਨਾਲ ਸ਼ੁਰੂਆਤ ਕਰੋ
- **ਪ੍ਰੋਮਪਟ ਨੂੰ ਅਨੁਕੂਲਿਤ ਕਰੋ**: ਵਧੀਆ ਨਤੀਜਿਆਂ ਲਈ ਸਹੀ ਚੈਟ ਫਾਰਮੈਟਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰੋ
- **ਪ੍ਰਦਰਸ਼ਨ ਦੀ ਨਿਗਰਾਨੀ ਕਰੋ**: ਇੰਫਰੈਂਸ ਗਤੀ ਅਤੇ ਸਹੀਤਾ ਮਾਪਦੰਡਾਂ ਨੂੰ ਟ੍ਰੈਕ ਕਰੋ
- **ਹਾਰਡਵੇਅਰ ਨੂੰ ਧਿਆਨ ਵਿੱਚ ਰੱਖੋ**: ਉਪਲਬਧ ਗਣਨਾ ਸੰਸਾਧਨਾਂ ਦੇ ਅਨੁਸਾਰ ਮਾਡਲ ਦਾ ਆਕਾਰ ਮਿਲਾਓ

## ਨਿਸਕਰਸ਼

Microsoft Phi ਮਾਡਲ ਪਰਿਵਾਰ AI ਮਾਡਲ ਡਿਜ਼ਾਈਨ ਲਈ ਇੱਕ ਕ੍ਰਾਂਤੀਕਾਰੀ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਦਾ ਪ੍ਰਤੀਨਿਧਿਤਾ ਕਰਦਾ ਹੈ, ਦਿਖਾਉਂਦਾ ਹੈ ਕਿ ਛੋਟੇ, ਜ਼ਿਆਦਾ ਕੁਸ਼ਲ ਮਾਡਲ ਵੱਖ-ਵੱਖ ਕੰਮਾਂ 'ਤੇ ਸ਼ਾਨਦਾਰ ਪ੍ਰਦਰਸ਼ਨ ਹਾਸਲ ਕਰ ਸਕਦੇ ਹਨ। ਉੱਚ-ਗੁਣਵੱਤਾ ਵਾਲੇ ਟ੍ਰੇਨਿੰਗ ਡੇਟਾ ਅਤੇ ਆਰਕੀਟੈਕਚਰਲ ਅਨੁਕੂਲਤਾਵਾਂ 'ਤੇ ਧਿਆਨ ਕੇਂਦਰਿਤ ਕਰਕੇ, Phi ਪਰਿਵਾਰ ਰਵਾਇਤੀ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਦੇ ਮੁਕਾਬਲੇ ਕਾਫ਼ੀ ਘੱਟ ਗਣਨਾ ਦੀਆਂ ਲੋੜਾਂ ਨਾਲ ਅਸਧਾਰਨ ਸਮਰੱਥਾਵਾਂ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।

## ਮੁੱਖ ਸਿੱਖਣ ਦੇ ਉਦੇਸ਼

1. Microsoft ਦੇ Phi ਮਾਡਲ ਪਰਿਵਾਰ ਦੇ ਡਿਜ਼ਾਈਨ ਫ਼ਲਸਫ਼ਾ ਅਤੇ ਵਿਕਾਸ ਨੂੰ ਸਮਝੋ (Phi-1 ਤੋਂ Phi-4 ਤੱਕ)
2. ਮੁੱਖ ਨਵੀਨਤਾਵਾਂ ਦੀ ਪਛਾਣ ਕਰੋ, ਜਿਵੇਂ ਕਿ "ਟੈਕਸਟਬੁੱਕ ਗੁਣਵੱਤਾ" ਟ੍ਰੇਨਿੰਗ ਅਤੇ ਆਰਕੀਟੈਕਚਰਲ ਅਨੁਕੂਲਤਾਵਾਂ
3. ਵੱਖ-ਵੱਖ ਤੈਨਾਤੀ ਦ੍ਰਿਸ਼ਾਂ 'ਤੇ ਵੱਖ-ਵੱਖ Phi ਰੂਪਾਂਤਰਨਾਂ ਦੇ ਫਾਇਦੇ ਅਤੇ ਸੀਮਾਵਾਂ ਨੂੰ ਪਛਾਣੋ
4. ਖਾਸ ਵਰਤੋਂ ਕੇਸਾਂ ਅਤੇ ਹਾਰਡਵੇਅਰ ਸੀਮਾਵਾਂ ਲਈ ਉਚਿਤ Phi ਮਾਡਲ ਚੁਣਨ ਲਈ ਗਿਆਨ ਲਾਗੂ ਕਰੋ
5. ਸੰਸਾਧਨ-ਸੀਮਿਤ ਡਿਵਾਈਸਾਂ 'ਤੇ Phi ਮਾਡਲ ਤੈਨਾਤ ਕਰਨ ਲਈ ਅਨੁਕੂਲਤਾਵਾਂ ਦੀਆਂ ਤਕਨੀਕਾਂ ਨੂੰ ਅਮਲ ਵਿੱਚ ਲਿਆਓ
6. ਰਵਾਇਤੀ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਦੇ ਮੁਕਾਬਲੇ Phi ਮਾਡਲ ਪਰਿਵਾਰ ਦੇ ਆਰਕੀਟੈਕਚਰਲ ਫਾਇਦਿਆਂ ਨੂੰ ਸਮਝਾਓ
7. ਖਾਸ ਐਪਲੀਕੇਸ਼ਨ ਦੀਆਂ ਲੋੜਾਂ ਅਤੇ ਹਾਰਡਵੇਅਰ ਸੀਮਾਵਾਂ ਦੇ ਆਧਾਰ 'ਤੇ ਉਚਿਤ Phi ਰੂਪਾਂਤਰਨ ਚੁਣੋ
8. ਕਲਾਉਡ ਅਤੇ ਐਜ ਤੈਨਾਤੀ ਦ੍ਰਿਸ਼ਾਂ ਵਿੱਚ ਅਨੁਕੂਲਿਤ ਸੰਰਚਨਾਵਾਂ ਨਾਲ Phi ਮਾਡਲਾਂ ਨੂੰ ਅਮਲ ਵਿੱਚ ਲਿਆਓ
9. ਟਾਰਗਟ ਡਿਵਾਈਸਾਂ 'ਤੇ Phi ਮਾਡਲ ਪ੍ਰਦਰਸ਼ਨ ਨੂੰ ਸੁਧਾਰਨ ਲਈ ਕੁਆਂਟਾਈਜ਼ੇਸ਼ਨ ਅਤੇ ਅਨੁਕੂਲਤਾਵਾਂ ਦੀਆਂ ਤਕਨੀਕਾਂ ਲਾਗੂ ਕਰੋ
10. Phi ਪਰਿਵਾਰ ਦੇ ਅੰਦਰ ਮਾਡਲ ਆਕਾਰ, ਪ੍ਰਦਰਸ਼ਨ, ਅਤੇ ਸਮਰੱਥਾਵਾਂ ਦੇ ਵਿਚਕਾਰ ਵਪਾਰ-ਬੰਦੀਆਂ ਦਾ ਮੁਲਾਂਕਣ ਕਰੋ

## ਅਗਲਾ ਕੀ ਹੈ

- [02: Qwen ਪਰਿਵਾਰ ਦੇ ਮੁੱਢਲੇ ਸਿਧਾਂਤ](02.QwenFamily.md)

---

**ਅਸਵੀਕਾਰਨਾ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਣੀਕਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਇਸ ਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੌਜੂਦ ਅਸਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।