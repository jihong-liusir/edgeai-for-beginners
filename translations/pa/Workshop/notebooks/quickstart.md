<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T11:15:15+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "pa"
}
-->
# ‡®µ‡®∞‡®ï‡®∏‡®º‡®æ‡®™ ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï‡®∏ - ‡®§‡©Å‡®∞‡©∞‡®§ ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§ ‡®ó‡®æ‡®à‡®°

## ‡®∏‡®Æ‡©±‡®ó‡®∞‡©Ä ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä

- [‡®™‡©Ç‡®∞‡®µ ‡®∏‡®º‡®∞‡®§‡®æ‡®Ç](../../../../Workshop/notebooks)
- [‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§‡©Ä ‡®∏‡©à‡®ü‡®Ö‡®™](../../../../Workshop/notebooks)
- [‡®∏‡©à‡®∏‡®º‡®® 04: ‡®Æ‡®æ‡®°‡®≤ ‡®§‡©Å‡®≤‡®®‡®æ](../../../../Workshop/notebooks)
- [‡®∏‡©à‡®∏‡®º‡®® 05: ‡®Æ‡®≤‡®ü‡©Ä-‡®è‡®ú‡©∞‡®ü ‡®Ü‡®∞‡®ï‡®ø‡®∏‡®ü‡®∞‡©á‡®ü‡®∞](../../../../Workshop/notebooks)
- [‡®∏‡©à‡®∏‡®º‡®® 06: ‡®á‡®∞‡®æ‡®¶‡®æ-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡©Ç‡®ü‡®ø‡©∞‡®ó](../../../../Workshop/notebooks)
- [‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®µ‡©à‡®∞‡©Ä‡®è‡®¨‡®≤](../../../../Workshop/notebooks)
- [‡®Ü‡®Æ ‡®ï‡®Æ‡®æ‡®Ç‡®°](../../../../Workshop/notebooks)

---

## ‡®™‡©Ç‡®∞‡®µ ‡®∏‡®º‡®∞‡®§‡®æ‡®Ç

### 1. Foundry Local ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã

**Windows:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**‡®á‡©∞‡®∏‡®ü‡®æ‡®≤‡©á‡®∏‡®º‡®® ‡®¶‡©Ä ‡®™‡©Å‡®∏‡®º‡®ü‡©Ä ‡®ï‡®∞‡©ã:**
```bash
foundry --version
```

### 2. Python Dependencies ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã

```bash
cd Workshop
pip install -r requirements.txt
```

‡®ú‡®æ‡®Ç ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§‡©Ä ‡®∏‡©à‡®ü‡®Ö‡®™

### Foundry Local ‡®∏‡©á‡®µ‡®æ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡©ã

**‡®ï‡©ã‡®à ‡®µ‡©Ä ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®ö‡®≤‡®æ‡®â‡®£ ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç ‡®≤‡®æ‡®ú‡®º‡®Æ‡©Ä:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

‡®â‡®Æ‡©Ä‡®¶ ‡®ï‡©Ä‡®§‡©Ä ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü:
```
‚úÖ Service started successfully
Endpoint: http://localhost:59959
```

### ‡®Æ‡®æ‡®°‡®≤ ‡®°‡®æ‡®ä‡®®‡®≤‡©ã‡®° ‡®Ö‡®§‡©á ‡®≤‡©ã‡®° ‡®ï‡®∞‡©ã

‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï‡®∏ ‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®∞‡©Ç‡®™ ‡®µ‡®ø‡©±‡®ö ‡®á‡®π ‡®Æ‡®æ‡®°‡®≤ ‡®µ‡®∞‡®§‡®¶‡©á ‡®π‡®®:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### ‡®∏‡©à‡®ü‡®Ö‡®™ ‡®¶‡©Ä ‡®™‡©Å‡®∏‡®º‡®ü‡©Ä ‡®ï‡®∞‡©ã

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## ‡®∏‡©à‡®∏‡®º‡®® 04: ‡®Æ‡®æ‡®°‡®≤ ‡®§‡©Å‡®≤‡®®‡®æ

### ‡®â‡®¶‡©á‡®∏‡®º
‡®õ‡©ã‡®ü‡©á ‡®≠‡®æ‡®∏‡®º‡®æ ‡®Æ‡®æ‡®°‡®≤ (SLM) ‡®Ö‡®§‡©á ‡®µ‡©±‡®°‡©á ‡®≠‡®æ‡®∏‡®º‡®æ ‡®Æ‡®æ‡®°‡®≤ (LLM) ‡®¶‡©á ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®¶‡©Ä ‡®§‡©Å‡®≤‡®®‡®æ ‡®ï‡®∞‡©ã‡•§

### ‡®§‡©Å‡®∞‡©∞‡®§ ‡®∏‡©à‡®ü‡®Ö‡®™

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®ö‡®≤‡®æ‡®â‡®£‡®æ

1. **‡®ñ‡©ã‡®≤‡©ç‡®π‡©ã** `session04_model_compare.ipynb` VS Code ‡®ú‡®æ‡®Ç Jupyter ‡®µ‡®ø‡©±‡®ö
2. **‡®ï‡®∞‡®®‡®≤ ‡®∞‡©Ä‡®∏‡®ü‡®æ‡®∞‡®ü ‡®ï‡®∞‡©ã** (Kernel ‚Üí Restart Kernel)
3. **‡®∏‡®æ‡®∞‡©á ‡®∏‡©à‡®≤ ‡®ö‡®≤‡®æ‡®ì** ‡®ï‡©ç‡®∞‡®Æ‡®µ‡®æ‡®∞

### ‡®Æ‡©Å‡©±‡®ñ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ

**‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®Æ‡®æ‡®°‡®≤:**
- **SLM:** `phi-4-mini` (~4GB RAM, ‡®§‡©á‡®ú‡®º)
- **LLM:** `qwen2.5-3b` (~3GB RAM, ‡®Æ‡©à‡®Æ‡®∞‡©Ä-‡®Ü‡®™‡®ü‡©Ä‡®Æ‡®æ‡®à‡®ú‡®º‡®°)

**‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®µ‡©à‡®∞‡©Ä‡®è‡®¨‡®≤ (‡®µ‡®ø‡®ï‡®≤‡®™‡®ø‡®ï):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### ‡®â‡®Æ‡©Ä‡®¶ ‡®ï‡©Ä‡®§‡©Ä ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

üí° SLM is 1.99x faster than LLM for this prompt
```

### ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º‡©á‡®∏‡®º‡®®

**‡®µ‡©±‡®ñ‡®∞‡©á ‡®Æ‡®æ‡®°‡®≤ ‡®µ‡®∞‡®§‡©ã:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**‡®ï‡®∏‡®ü‡®Æ ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### ‡®µ‡©à‡®ß‡®§‡®æ ‡®ö‡©à‡©±‡®ï‡®≤‡®ø‡®∏‡®ü

- [ ] ‡®∏‡©à‡®≤ 12 ‡®∏‡®π‡©Ä ‡®Æ‡®æ‡®°‡®≤ ‡®¶‡®ø‡®ñ‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à (phi-4-mini, qwen2.5-3b)
- [ ] ‡®∏‡©à‡®≤ 12 ‡®∏‡®π‡©Ä ‡®ê‡®Ç‡®°‡®™‡©å‡®á‡©∞‡®ü ‡®¶‡®ø‡®ñ‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à (port 59959)
- [ ] ‡®∏‡©à‡®≤ 16 ‡®°‡®æ‡®á‡®ó‡®®‡©ã‡®∏‡®ü‡®ø‡®ï ‡®™‡®æ‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à (‚úÖ ‡®∏‡©á‡®µ‡®æ ‡®ö‡©±‡®≤ ‡®∞‡®π‡©Ä ‡®π‡©à)
- [ ] ‡®∏‡©à‡®≤ 20 ‡®™‡©ç‡®∞‡©Ä-‡®´‡®≤‡®æ‡®à‡®ü ‡®ö‡©à‡©±‡®ï ‡®™‡®æ‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à (‡®¶‡©ã‡®µ‡©á‡®Ç ‡®Æ‡®æ‡®°‡®≤ ‡®†‡©Ä‡®ï ‡®π‡®®)
- [ ] ‡®∏‡©à‡®≤ 22 ‡®§‡©Å‡®≤‡®®‡®æ ‡®™‡©Ç‡®∞‡©Ä ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à ‡®≤‡©á‡®ü‡©à‡®Ç‡®∏‡©Ä ‡®µ‡©à‡®≤‡®ø‡®ä‡®ú‡®º ‡®®‡®æ‡®≤
- [ ] ‡®∏‡©à‡®≤ 24 ‡®µ‡©à‡®ß‡®§‡®æ ‡®¶‡®ø‡®ñ‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à üéâ ‡®∏‡®æ‡®∞‡©á ‡®ö‡©à‡©±‡®ï ‡®™‡®æ‡®∏!

### ‡®∏‡®Æ‡®æ‡®Ç ‡®Ö‡®®‡©Å‡®Æ‡®æ‡®®
- **‡®™‡®π‡®ø‡®≤‡©Ä ‡®µ‡®æ‡®∞ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ:** 5-10 ‡®Æ‡®ø‡©∞‡®ü (‡®Æ‡®æ‡®°‡®≤ ‡®°‡®æ‡®ä‡®®‡®≤‡©ã‡®° ‡®∏‡®Æ‡©á‡®§)
- **‡®Ö‡®ó‡®≤‡©Ä ‡®µ‡®æ‡®∞ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ:** 1-2 ‡®Æ‡®ø‡©∞‡®ü

---

## ‡®∏‡©à‡®∏‡®º‡®® 05: ‡®Æ‡®≤‡®ü‡©Ä-‡®è‡®ú‡©∞‡®ü ‡®Ü‡®∞‡®ï‡®ø‡®∏‡®ü‡®∞‡©á‡®ü‡®∞

### ‡®â‡®¶‡©á‡®∏‡®º
Foundry Local SDK ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Æ‡®≤‡®ü‡©Ä-‡®è‡®ú‡©∞‡®ü ‡®∏‡®π‡®ø‡®Ø‡©ã‡®ó ‡®¶‡®ø‡®ñ‡®æ‡®â‡®£‡®æ - ‡®è‡®ú‡©∞‡®ü ‡®Æ‡®ø‡®≤ ‡®ï‡©á ‡®∏‡©Å‡®ß‡®æ‡®∞‡®ø‡®§ ‡®®‡®§‡©Ä‡®ú‡©á ‡®™‡©à‡®¶‡®æ ‡®ï‡®∞‡®¶‡©á ‡®π‡®®‡•§

### ‡®§‡©Å‡®∞‡©∞‡®§ ‡®∏‡©à‡®ü‡®Ö‡®™

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®ö‡®≤‡®æ‡®â‡®£‡®æ

1. **‡®ñ‡©ã‡®≤‡©ç‡®π‡©ã** `session05_agents_orchestrator.ipynb`
2. **‡®ï‡®∞‡®®‡®≤ ‡®∞‡©Ä‡®∏‡®ü‡®æ‡®∞‡®ü ‡®ï‡®∞‡©ã**
3. **‡®∏‡®æ‡®∞‡©á ‡®∏‡©à‡®≤ ‡®ö‡®≤‡®æ‡®ì** ‡®ï‡©ç‡®∞‡®Æ‡®µ‡®æ‡®∞

### ‡®Æ‡©Å‡©±‡®ñ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ

**‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®∏‡©à‡®ü‡®Ö‡®™ (‡®¶‡©ã‡®µ‡©á‡®Ç ‡®è‡®ú‡©∞‡®ü ‡®≤‡®à ‡®á‡©±‡®ï‡©ã ‡®Æ‡®æ‡®°‡®≤):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**‡®â‡©±‡®ö‡®§‡®Æ ‡®∏‡©à‡®ü‡®Ö‡®™ (‡®µ‡©±‡®ñ‡®∞‡©á ‡®Æ‡®æ‡®°‡®≤):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞

```
User Question
    ‚Üì
Researcher Agent (phi-4-mini)
  ‚Üí Gathers bullet points
    ‚Üì
Editor Agent (phi-4-mini or qwen2.5-7b)
  ‚Üí Refines into executive summary
    ‚Üì
Final Output
```

### ‡®â‡®Æ‡©Ä‡®¶ ‡®ï‡©Ä‡®§‡©Ä ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: ‚Ä¢ Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### ‡®µ‡®ß‡®æ‡®à‡®Ü‡®Ç

**‡®π‡©ã‡®∞ ‡®è‡®ú‡©∞‡®ü ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**‡®¨‡©à‡®ö ‡®ü‡©à‡®∏‡®ü‡®ø‡©∞‡®ó:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### ‡®∏‡®Æ‡®æ‡®Ç ‡®Ö‡®®‡©Å‡®Æ‡®æ‡®®
- **‡®™‡®π‡®ø‡®≤‡©Ä ‡®µ‡®æ‡®∞ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ:** 3-5 ‡®Æ‡®ø‡©∞‡®ü
- **‡®Ö‡®ó‡®≤‡©Ä ‡®µ‡®æ‡®∞ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ:** ‡®™‡©ç‡®∞‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®§‡©Ä 1-2 ‡®Æ‡®ø‡©∞‡®ü

---

## ‡®∏‡©à‡®∏‡®º‡®® 06: ‡®á‡®∞‡®æ‡®¶‡®æ-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡©Ç‡®ü‡®ø‡©∞‡®ó

### ‡®â‡®¶‡©á‡®∏‡®º
‡®™‡®§‡®æ ‡®≤‡©±‡®ó‡©á ‡®á‡®∞‡®æ‡®¶‡©á ‡®¶‡©á ‡®Ö‡®ß‡®æ‡®∞ '‡®§‡©á ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü‡®∏ ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®∞‡®™‡®ø‡®§ ‡®§‡©å‡®∞ '‡®§‡©á ‡®∞‡©Ç‡®ü ‡®ï‡®∞‡©ã‡•§

### ‡®§‡©Å‡®∞‡©∞‡®§ ‡®∏‡©à‡®ü‡®Ö‡®™

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**‡®®‡©ã‡®ü:** ‡®∏‡©à‡®∏‡®º‡®® 06 ‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®∞‡©Ç‡®™ ‡®µ‡®ø‡©±‡®ö CPU ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®µ‡©±‡®ß ‡®§‡©ã‡®Ç ‡®µ‡©±‡®ß ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤‡®§‡®æ ‡®≤‡®à ‡®µ‡®∞‡®§‡®¶‡®æ ‡®π‡©à‡•§

### ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®ö‡®≤‡®æ‡®â‡®£‡®æ

1. **‡®ñ‡©ã‡®≤‡©ç‡®π‡©ã** `session06_models_router.ipynb`
2. **‡®ï‡®∞‡®®‡®≤ ‡®∞‡©Ä‡®∏‡®ü‡®æ‡®∞‡®ü ‡®ï‡®∞‡©ã**
3. **‡®∏‡®æ‡®∞‡©á ‡®∏‡©à‡®≤ ‡®ö‡®≤‡®æ‡®ì** ‡®ï‡©ç‡®∞‡®Æ‡®µ‡®æ‡®∞

### ‡®Æ‡©Å‡©±‡®ñ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ

**‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®ï‡©à‡®ü‡®æ‡®≤‡©å‡®ó (CPU ‡®Æ‡®æ‡®°‡®≤):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**‡®µ‡®ø‡®ï‡®≤‡®™ (GPU ‡®Æ‡®æ‡®°‡®≤):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### ‡®á‡®∞‡®æ‡®¶‡®æ ‡®™‡®§‡®æ ‡®≤‡®ó‡®æ‡®â‡®£‡®æ

‡®∞‡©Ç‡®ü‡®∞ regex ‡®™‡©à‡®ü‡®∞‡®® ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®á‡®∞‡®æ‡®¶‡®æ ‡®™‡®§‡®æ ‡®≤‡®ó‡®æ‡®â‡®£ ‡®≤‡®à:

| ‡®á‡®∞‡®æ‡®¶‡®æ | ‡®™‡©à‡®ü‡®∞‡®® ‡®â‡®¶‡®æ‡®π‡®∞‡®® | ‡®∞‡©Ç‡®ü ‡®ï‡©Ä‡®§‡®æ |
|--------|-----------------|-----------|
| `code` | "refactor", "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize", "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize", "tl;dr" | phi-4-mini-cpu |
| `general` | ‡®π‡©ã‡®∞ ‡®∏‡®≠ ‡®ï‡©Å‡®ù | phi-4-mini-cpu |

### ‡®â‡®Æ‡©Ä‡®¶ ‡®ï‡©Ä‡®§‡©Ä ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü

```
‚úì Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

‚úì Success! All prompts routed correctly.
```

### ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º‡©á‡®∏‡®º‡®®

**‡®ï‡®∏‡®ü‡®Æ ‡®á‡®∞‡®æ‡®¶‡®æ ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ÁøªËØë', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**‡®ü‡©ã‡®ï‡®® ‡®ü‡©ç‡®∞‡©à‡®ï‡®ø‡©∞‡®ó ‡®ö‡®æ‡®≤‡©Ç ‡®ï‡®∞‡©ã:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### GPU ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®∏‡®µ‡®ø‡©±‡®ö ‡®ï‡®∞‡®®‡®æ

‡®ú‡©á ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ 8GB+ VRAM ‡®π‡©à:

1. **‡®∏‡©à‡®≤ #6** ‡®µ‡®ø‡©±‡®ö, CPU ‡®ï‡©à‡®ü‡®æ‡®≤‡©å‡®ó ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®Æ‡©à‡®Ç‡®ü ‡®ï‡®∞‡©ã
2. GPU ‡®ï‡©à‡®ü‡®æ‡®≤‡©å‡®ó ‡®®‡©Ç‡©∞ ‡®Ö‡®®‡®ï‡®æ‡®Æ‡©à‡®Ç‡®ü ‡®ï‡®∞‡©ã
3. GPU ‡®Æ‡®æ‡®°‡®≤ ‡®≤‡©ã‡®° ‡®ï‡®∞‡©ã:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. ‡®ï‡®∞‡®®‡®≤ ‡®∞‡©Ä‡®∏‡®ü‡®æ‡®∞‡®ü ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ ‡®ö‡®≤‡®æ‡®ì

### ‡®∏‡®Æ‡®æ‡®Ç ‡®Ö‡®®‡©Å‡®Æ‡®æ‡®®
- **‡®™‡®π‡®ø‡®≤‡©Ä ‡®µ‡®æ‡®∞ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ:** 5-10 ‡®Æ‡®ø‡©∞‡®ü (‡®Æ‡®æ‡®°‡®≤ ‡®≤‡©ã‡®°‡®ø‡©∞‡®ó)
- **‡®Ö‡®ó‡®≤‡©Ä ‡®µ‡®æ‡®∞ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ:** ‡®™‡©ç‡®∞‡®§‡©Ä ‡®ü‡©à‡®∏‡®ü 30-60 ‡®∏‡®ï‡®ø‡©∞‡®ü

---

## ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®µ‡©à‡®∞‡©Ä‡®è‡®¨‡®≤

### ‡®ó‡®≤‡©ã‡®¨‡®≤ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ

Jupyter/VS Code ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡®® ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç ‡®∏‡©à‡®ü ‡®ï‡®∞‡©ã:

**Windows (Command Prompt):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**Windows (PowerShell):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®µ‡®ø‡©±‡®ö ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ

‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®¶‡©á ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®µ‡®ø‡©±‡®ö ‡®∏‡©à‡®ü ‡®ï‡®∞‡©ã:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## ‡®Ü‡®Æ ‡®ï‡®Æ‡®æ‡®Ç‡®°

### ‡®∏‡©á‡®µ‡®æ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### ‡®Æ‡®æ‡®°‡®≤ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### ‡®ê‡®Ç‡®°‡®™‡©å‡®á‡©∞‡®ü ‡®ü‡©à‡®∏‡®ü‡®ø‡©∞‡®ó

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### ‡®°‡®æ‡®á‡®ó‡®®‡©ã‡®∏‡®ü‡®ø‡®ï ‡®ï‡®Æ‡®æ‡®Ç‡®°

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## ‡®∏‡®∞‡®µ‡©ã‡®§‡®Æ ‡®Ö‡®≠‡®ø‡®Ü‡®∏

### ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡®® ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç

1. **‡®∏‡©á‡®µ‡®æ ‡®ö‡©±‡®≤ ‡®∞‡®π‡©Ä ‡®π‡©à ‡®ú‡®æ‡®Ç ‡®®‡®π‡©Ä‡®Ç ‡®ö‡©à‡©±‡®ï ‡®ï‡®∞‡©ã:**
   ```bash
   foundry service status
   ```

2. **‡®Æ‡®æ‡®°‡®≤ ‡®≤‡©ã‡®° ‡®π‡©ã‡®è ‡®π‡®® ‡®ú‡®æ‡®Ç ‡®®‡®π‡©Ä‡®Ç ‡®ö‡©à‡©±‡®ï ‡®ï‡®∞‡©ã:**
   ```bash
   foundry model ls
   ```

3. **‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®ï‡®∞‡®®‡®≤ ‡®∞‡©Ä‡®∏‡®ü‡®æ‡®∞‡®ü ‡®ï‡®∞‡©ã** ‡®ú‡©á ‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ ‡®π‡©à

4. **‡®∏‡®æ‡®∞‡©á ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü ‡®∏‡®æ‡®´‡®º ‡®ï‡®∞‡©ã** ‡®∏‡®æ‡®´‡®º ‡®ö‡®≤‡®æ‡®â‡®£ ‡®≤‡®à

### ‡®∏‡®∞‡©ã‡®§ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®

1. **‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®∞‡©Ç‡®™ ‡®µ‡®ø‡©±‡®ö CPU ‡®Æ‡®æ‡®°‡®≤ ‡®µ‡®∞‡®§‡©ã** ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤‡®§‡®æ ‡®≤‡®à
2. **GPU ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®∏‡®µ‡®ø‡©±‡®ö ‡®ï‡®∞‡©ã** ‡®ú‡©á ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ 8GB+ VRAM ‡®π‡©à
3. **GPU ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®¨‡©∞‡®¶ ‡®ï‡®∞‡©ã** ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®ö‡®≤‡®æ‡®â‡®£ ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç
4. **‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®∏‡©à‡®∏‡®º‡®® ‡®¶‡©á ‡®µ‡®ø‡®ö‡®ï‡®æ‡®∞ ‡®∏‡©á‡®µ‡®æ ‡®ö‡©±‡®≤ ‡®∞‡®π‡©Ä ‡®∞‡©±‡®ñ‡©ã**
5. **‡®∏‡®∞‡©ã‡®§ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®¶‡©Ä ‡®®‡®ø‡®ó‡®∞‡®æ‡®®‡©Ä ‡®ï‡®∞‡©ã** Task Manager / nvidia-smi ‡®®‡®æ‡®≤

### ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü ‡®π‡©±‡®≤

1. **‡®∏‡©á‡®µ‡®æ ‡®¶‡©Ä ‡®∏‡®•‡®ø‡®§‡©Ä ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç ‡®ö‡©à‡©±‡®ï ‡®ï‡®∞‡©ã** ‡®ï‡©ã‡®° ‡®°‡®ø‡®¨‡©±‡®ó ‡®ï‡®∞‡®® ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç
2. **‡®ï‡®∞‡®®‡®≤ ‡®∞‡©Ä‡®∏‡®ü‡®æ‡®∞‡®ü ‡®ï‡®∞‡©ã** ‡®ú‡©á ‡®™‡©Å‡®∞‡®æ‡®£‡©Ä ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ ‡®¶‡®ø‡®ñ‡®æ‡®à ‡®¶‡©á‡®µ‡©á
3. **‡®ï‡©ã‡®à ‡®µ‡©Ä ‡®¨‡®¶‡®≤‡®æ‡®Ö ‡®§‡©ã‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®°‡®æ‡®á‡®ó‡®®‡©ã‡®∏‡®ü‡®ø‡®ï ‡®∏‡©à‡®≤ ‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ ‡®ö‡®≤‡®æ‡®ì**
4. **‡®Æ‡®æ‡®°‡®≤ ‡®¶‡©á ‡®®‡®æ‡®Æ ‡®ö‡©à‡©±‡®ï ‡®ï‡®∞‡©ã** ‡®ú‡©ã ‡®≤‡©ã‡®° ‡®π‡©ã‡®è ‡®π‡®®
5. **‡®ê‡®Ç‡®°‡®™‡©å‡®á‡©∞‡®ü ‡®™‡©ã‡®∞‡®ü ‡®¶‡©Ä ‡®™‡©Å‡®∏‡®º‡®ü‡©Ä ‡®ï‡®∞‡©ã** ‡®∏‡©á‡®µ‡®æ ‡®∏‡®•‡®ø‡®§‡©Ä ‡®®‡®æ‡®≤ ‡®Æ‡®ø‡®≤‡®¶‡®æ ‡®π‡©à

---

## ‡®§‡©Å‡®∞‡©∞‡®§ ‡®∏‡©∞‡®¶‡®∞‡®≠: ‡®Æ‡®æ‡®°‡®≤ ‡®Ö‡®≤‡©Ä‡®Ö‡®∏

### ‡®Ü‡®Æ ‡®Æ‡®æ‡®°‡®≤

| ‡®Ö‡®≤‡©Ä‡®Ö‡®∏ | ‡®Ü‡®ï‡®æ‡®∞ | ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü | RAM/VRAM | ‡®µ‡©à‡®∞‡©Ä‡®ê‡®Ç‡®ü |
|-------|------|----------|----------|----------|
| `phi-4-mini` | ~4B | ‡®ú‡®®‡®∞‡®≤ ‡®ö‡©à‡®ü, ‡®∏‡©∞‡®ñ‡©á‡®™ | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | ‡®ï‡©ã‡®° ‡®ú‡®®‡®∞‡©á‡®∏‡®º‡®®, ‡®∞‡©Ä‡®´‡©à‡®ï‡®ü‡®∞‡©Ä‡©∞‡®ó | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | ‡®ú‡®®‡®∞‡®≤ ‡®ü‡®æ‡®∏‡®ï, ‡®ï‡©Å‡®∏‡®º‡®≤ | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | ‡®§‡©á‡®ú‡®º, ‡®ò‡©±‡®ü ‡®∏‡®∞‡©ã‡®§ | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | ‡®µ‡®∞‡®ó‡©Ä‡®ï‡®∞‡®®, ‡®ò‡©±‡®ü ‡®∏‡®∞‡©ã‡®§ | 1-2GB | `-cpu`, `-cuda-gpu` |

### ‡®µ‡©à‡®∞‡©Ä‡®ê‡®Ç‡®ü ‡®®‡®æ‡®Æ‡®ï‡®∞‡®®

- **‡®¨‡©á‡®∏ ‡®®‡®æ‡®Æ** (‡®ú‡®ø‡®µ‡©á‡®Ç `phi-4-mini`): ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®π‡®æ‡®∞‡®°‡®µ‡©á‡®Ö‡®∞ ‡®≤‡®à ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®µ‡©à‡®∞‡©Ä‡®ê‡®Ç‡®ü ‡®Ü‡®ü‡©ã-‡®ö‡©Å‡®£‡®¶‡®æ ‡®π‡©à
- **`-cpu`**: CPU-‡®Ü‡®™‡®ü‡©Ä‡®Æ‡®æ‡®à‡®ú‡®º‡®°, ‡®π‡®∞ ‡®ú‡®ó‡©ç‡®π‡®æ ‡®ï‡©∞‡®Æ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à
- **`-cuda-gpu`**: NVIDIA GPU-‡®Ü‡®™‡®ü‡©Ä‡®Æ‡®æ‡®à‡®ú‡®º‡®°, 8GB+ VRAM ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©à
- **`-npu`**: Qualcomm NPU-‡®Ü‡®™‡®ü‡©Ä‡®Æ‡®æ‡®à‡®ú‡®º‡®°, NPU ‡®°‡®∞‡®æ‡®à‡®µ‡®∞ ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©à

**‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º:** ‡®¨‡©á‡®∏ ‡®®‡®æ‡®Æ (‡®¨‡®ø‡®®‡®æ‡®Ç ‡®∏‡©Å‡®´‡®ø‡®ï‡®∏) ‡®µ‡®∞‡®§‡©ã ‡®Ö‡®§‡©á Foundry Local ‡®®‡©Ç‡©∞ ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®µ‡©à‡®∞‡©Ä‡®ê‡®Ç‡®ü ‡®ö‡©Å‡®£‡®® ‡®¶‡®ø‡®ì‡•§

---

## ‡®∏‡®´‡®≤‡®§‡®æ ‡®¶‡©á ‡®∏‡©∞‡®ï‡©á‡®§

‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®§‡®ø‡®Ü‡®∞ ‡®π‡©ã ‡®ú‡®¶‡©ã‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®µ‡©á‡®ñ‡®¶‡©á ‡®π‡©ã:

‚úÖ `foundry service status` "running" ‡®¶‡®ø‡®ñ‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à  
‚úÖ `foundry model ls` ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©á ‡®Æ‡®æ‡®°‡®≤ ‡®¶‡®ø‡®ñ‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à  
‚úÖ ‡®∏‡©á‡®µ‡®æ ‡®∏‡®π‡©Ä ‡®ê‡®Ç‡®°‡®™‡©å‡®á‡©∞‡®ü '‡®§‡©á ‡®™‡®π‡©Å‡©∞‡®ö‡®Ø‡©ã‡®ó ‡®π‡©à  
‚úÖ ‡®π‡©à‡®≤‡®• ‡®ö‡©à‡©±‡®ï 200 OK ‡®µ‡®æ‡®™‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à  
‚úÖ ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®°‡®æ‡®á‡®ó‡®®‡©ã‡®∏‡®ü‡®ø‡®ï ‡®∏‡©à‡®≤ ‡®™‡®æ‡®∏ ‡®ï‡®∞‡®¶‡©á ‡®π‡®®  
‚úÖ ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡©ã‡®à ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®ó‡®≤‡®§‡©Ä ‡®®‡®π‡©Ä‡®Ç

---

## ‡®Æ‡®¶‡®¶ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®®‡®æ

### ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º
- **‡®Æ‡©Å‡©±‡®ñ ‡®∞‡®ø‡®™‡©ã‡®ú‡®º‡®ü‡®∞‡©Ä**: https://github.com/microsoft/Foundry-Local  
- **Python SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python  
- **CLI ‡®∞‡®ø‡®´‡®∞‡©à‡®Ç‡®∏**: https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md  
- **‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü ‡®π‡©±‡®≤**: ‡®á‡®∏ ‡®°‡®æ‡®á‡®∞‡©à‡®ï‡®ü‡®∞‡©Ä ‡®µ‡®ø‡©±‡®ö `troubleshooting.md` ‡®µ‡©á‡®ñ‡©ã  

### GitHub Issues
- https://github.com/microsoft/Foundry-Local/issues  
- https://github.com/microsoft/edgeai-for-beginners/issues  

---

**‡®Ü‡®ñ‡®∞‡©Ä ‡®Ö‡®™‡®°‡©á‡®ü:** ‡®Ö‡®ï‡®§‡©Ç‡®¨‡®∞ 8, 2025  
**‡®µ‡®∞‡®ú‡®®:** ‡®µ‡®∞‡®ï‡®∏‡®º‡®æ‡®™ ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï‡®∏ 2.0  

---

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®∞‡®§‡©Ä**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä‡®Ö‡®§ ‡®≤‡®à ‡®Ø‡®§‡®®‡®∏‡®º‡©Ä‡®≤ ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡®ö‡®®‡®æ‡®µ‡®æ‡®Ç ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®á‡®∏ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®¶‡®æ ‡®Æ‡©Ç‡®≤ ‡®∞‡©Ç‡®™ ‡®á‡®∏‡®¶‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§ ‡®´‡®π‡®ø‡®Æ‡©Ä ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§