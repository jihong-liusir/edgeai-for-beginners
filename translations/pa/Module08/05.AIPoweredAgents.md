<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "382a763fcea7087e68a94c26216e5e70",
  "translation_date": "2025-09-22T18:26:20+00:00",
  "source_file": "Module08/05.AIPoweredAgents.md",
  "language_code": "pa"
}
-->
# ਸੈਸ਼ਨ 5: Foundry Local ਨਾਲ AI-ਚਲਿਤ ਏਜੰਟ ਤੇਜ਼ੀ ਨਾਲ ਬਣਾਓ

Note: Foundry Local ਵਿੱਚ ਏਜੰਟ ਸਮਰੱਥਾਵਾਂ ਵਿਕਸਿਤ ਹੁੰਦੀਆਂ ਹਨ—ਉੱਨਤ ਪੈਟਰਨ ਲਾਗੂ ਕਰਨ ਤੋਂ ਪਹਿਲਾਂ ਨਵੀਂ ਰਿਲੀਜ਼ ਨੋਟਸ ਵਿੱਚ ਸਮਰਥਨ ਦੀ ਪੁਸ਼ਟੀ ਕਰੋ।

## ਝਲਕ

Foundry Local ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਏਜੰਟਿਕ ਐਪਲੀਕੇਸ਼ਨ ਨੂੰ ਤੇਜ਼ੀ ਨਾਲ ਪ੍ਰੋਟੋਟਾਈਪ ਕਰੋ: ਸਿਸਟਮ ਪ੍ਰੋੰਪਟ, ਗ੍ਰਾਊਂਡਿੰਗ, ਅਤੇ ਆਰਕੇਸਟ੍ਰੇਸ਼ਨ ਪੈਟਰਨ। ਜਦੋਂ ਏਜੰਟ ਸਮਰਥਨ ਉਪਲਬਧ ਹੁੰਦਾ ਹੈ, ਤੁਸੀਂ OpenAI-ਅਨੁਕੂਲ ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ 'ਤੇ ਮਿਆਰੀਕਰਨ ਕਰ ਸਕਦੇ ਹੋ ਜਾਂ ਹਾਈਬ੍ਰਿਡ ਡਿਜ਼ਾਈਨ ਵਿੱਚ ਕਲਾਉਡ ਪਾਸੇ Azure AI Agents ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹੋ।

ਹਵਾਲੇ:
- Foundry Local ਡੌਕਸ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Azure AI Foundry Agents: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ ਸੈਂਪਲ (Foundry Local ਸੈਂਪਲ): https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling

## ਸਿੱਖਣ ਦੇ ਉਦੇਸ਼
- ਭਰੋਸੇਯੋਗ ਵਿਹਾਰ ਲਈ ਸਿਸਟਮ ਪ੍ਰੋੰਪਟ ਅਤੇ ਗ੍ਰਾਊਂਡਿੰਗ ਰਣਨੀਤੀਆਂ ਡਿਜ਼ਾਈਨ ਕਰੋ
- ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ (ਟੂਲ ਵਰਤੋਂ) ਪੈਟਰਨ ਲਾਗੂ ਕਰੋ
- ਮਲਟੀ-ਏਜੰਟ ਵਰਕਫਲੋਜ਼ (ਲੋਕਲ ਅਤੇ ਹਾਈਬ੍ਰਿਡ) ਆਰਕੇਸਟ੍ਰੇਟ ਕਰੋ
- ਨਿਗਰਾਨੀ ਅਤੇ ਸੁਰੱਖਿਆ ਦੀ ਯੋਜਨਾ ਬਣਾਓ

## ਭਾਗ 1: ਸਿਸਟਮ ਪ੍ਰੋੰਪਟ ਅਤੇ ਗ੍ਰਾਊਂਡਿੰਗ

- ਸਖ਼ਤ ਭੂਮਿਕਾਵਾਂ, ਰੋਕਾਂ, ਅਤੇ ਆਉਟਪੁੱਟ ਸਕੀਮਾਂ ਨੂੰ ਪਰਿਭਾਸ਼ਿਤ ਕਰੋ
- ਸਥਾਨਕ ਜਾਂ ਐਨਟਰਪ੍ਰਾਈਜ਼ ਡਾਟਾ ਨਾਲ ਜਵਾਬਾਂ ਨੂੰ ਗ੍ਰਾਊਂਡ ਕਰੋ
- ਡਾਊਨਸਟ੍ਰੀਮ ਆਟੋਮੇਸ਼ਨ ਲਈ JSON ਆਉਟਪੁੱਟ ਨੂੰ ਲਾਗੂ ਕਰੋ

## ਭਾਗ 2: ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ (OpenAI-ਅਨੁਕੂਲ)

```python
# tools.py
import json

def get_weather(city: str) -> str:
    return f"Weather in {city}: Sunny, 25C"

FUNCTIONS = [
    {
        "name": "get_weather",
        "description": "Get current weather for a city",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "City name"}
            },
            "required": ["city"]
        }
    }
]
```

```python
# agent.py
import requests
import json
from tools import FUNCTIONS, get_weather

BASE_URL = "http://localhost:8000"
MODEL = "phi-4-mini"

SYSTEM_PROMPT = "You are a helpful assistant. Use tools when needed."

def call_model(messages, functions=None):
    payload = {
        "model": MODEL,
        "messages": messages,
        "functions": functions,
        "function_call": "auto"
    }
    r = requests.post(f"{BASE_URL}/v1/chat/completions", json=payload, timeout=60)
    r.raise_for_status()
    return r.json()

messages = [{"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": "What's the weather in Paris?"}]

resp = call_model(messages, functions=FUNCTIONS)
choice = resp["choices"][0]["message"]

if "function_call" in choice:
    fc = choice["function_call"]
    if fc["name"] == "get_weather":
        args = json.loads(fc["arguments"])
        result = get_weather(args["city"])
        messages.append(choice)
        messages.append({"role": "function", "name": "get_weather", "content": result})
        final = call_model(messages)
        print(final["choices"][0]["message"]["content"]) 
else:
    print(choice.get("content"))
```

ਚਲਾਓ:
```powershell
# Ensure a model is running
foundry model run phi-4-mini
python agent.py
```


## ਭਾਗ 3: ਮਲਟੀ-ਏਜੰਟ ਆਰਕੇਸਟ੍ਰੇਸ਼ਨ (ਪੈਟਰਨ)

Foundry Local ਦੇ OpenAI-ਅਨੁਕੂਲ ਐਂਡਪੌਇੰਟ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਟਾਸਕ ਨੂੰ ਸਪੈਸ਼ਲਿਸਟ ਏਜੰਟ (ਰੀਟਰੀਵਲ, ਰੀਜ਼ਨਿੰਗ, ਐਗਜ਼ੀਕਿਊਸ਼ਨ) ਵੱਲ ਰੂਟ ਕਰਨ ਲਈ ਇੱਕ ਕੋਆਰਡੀਨੇਟਰ ਡਿਜ਼ਾਈਨ ਕਰੋ।

ਪਹਿਲਾ ਕਦਮ) ਸਪੈਸ਼ਲਿਸਟ ਏਜੰਟ ਪਰਿਭਾਸ਼ਿਤ ਕਰੋ  
```python
# agents/specialists.py
import requests
BASE_URL = "http://localhost:8000"
MODEL = "phi-4-mini"

headers = {"Content-Type": "application/json", "Authorization": "Bearer local-key"}

def chat(messages, max_tokens=300, temperature=0.4):
    r = requests.post(f"{BASE_URL}/v1/chat/completions", json={
        "model": MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature
    }, headers=headers, timeout=60)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

class RetrievalAgent:
    SYSTEM = "You retrieve relevant snippets from knowledge sources based on a query."
    def run(self, query: str) -> str:
        # Placeholder: in real use, fetch from local files or vector DB
        messages = [{"role": "system", "content": self.SYSTEM},
                    {"role": "user", "content": f"Retrieve key facts for: {query}"}]
        return chat(messages)

class ReasoningAgent:
    SYSTEM = "You analyze inputs step by step and produce structured conclusions."
    def run(self, context: str, question: str) -> str:
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Context:\n{context}\n\nQuestion: {question}\nThink step-by-step and produce a concise answer."}
        ]
        return chat(messages)

class ExecutionAgent:
    SYSTEM = "You transform decisions into actionable steps (JSON with actions)."
    def run(self, decision: str) -> str:
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Turn this decision into 3 executable steps as JSON:\n{decision}"}
        ]
        return chat(messages)
```
  
ਦੂਜਾ ਕਦਮ) ਕੋਆਰਡੀਨੇਟਰ ਬਣਾਓ  
```python
# agents/coordinator.py
from agents.specialists import RetrievalAgent, ReasoningAgent, ExecutionAgent

class Coordinator:
    def __init__(self):
        self.retrieval = RetrievalAgent()
        self.reasoning = ReasoningAgent()
        self.execution = ExecutionAgent()

    def handle(self, user_goal: str) -> dict:
        # 1. Retrieve context
        context = self.retrieval.run(user_goal)
        # 2. Reason on context
        decision = self.reasoning.run(context, user_goal)
        # 3. Produce actionable steps
        actions = self.execution.run(decision)
        return {
            "goal": user_goal,
            "context": context,
            "decision": decision,
            "actions": actions
        }

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    coord = Coordinator()
    result = coord.handle("Create a plan to onboard 5 new customers this month")
    print(result)
```
  
ਤੀਜਾ ਕਦਮ) Foundry Local ਦੇ ਖਿਲਾਫ ਵੈਰੀਫਾਈ ਕਰੋ  
```powershell
REM Confirm the local endpoint and model are available
foundry model list
foundry model run phi-4-mini
curl http://localhost:8000/v1/models

REM Run the coordinator
python -m samples.05.agents.coordinator
```
  

ਦਿਸ਼ਾ-ਨਿਰਦੇਸ਼:
- ਏਜੰਟਾਂ ਦੇ ਵਿਚਕਾਰ ਰੀਟ੍ਰਾਈਜ਼ ਅਤੇ ਟਾਈਮਆਉਟ ਲਾਗੂ ਕਰੋ
- ਗੱਲਬਾਤ/ਥ੍ਰੈਡ ਸਟੇਟ ਲਈ ਇੱਕ ਛੋਟਾ ਇਨ-ਮੇਮੋਰੀ ਸਟੋਰ (dict) ਸ਼ਾਮਲ ਕਰੋ
- ਕਈ ਕਾਲਾਂ ਨੂੰ ਚੇਨ ਕਰਨ ਸਮੇਂ ਰੇਟ-ਲਿਮਿਟਿੰਗ ਸ਼ਾਮਲ ਕਰੋ

## ਭਾਗ 4: ਨਿਗਰਾਨੀ ਅਤੇ ਸੁਰੱਖਿਆ

ਸਥਾਨਕ ਤੌਰ 'ਤੇ ਪ੍ਰੋੰਪਟ, ਜਵਾਬ, ਅਤੇ ਗਲਤੀਆਂ ਨੂੰ ਟ੍ਰੈਕ ਕਰੋ, ਜਦੋਂ ਕਿ ਆਪਣੇ ਏਜੰਟ ਸਟੈਕ ਵਿੱਚ ਡਾਟਾ ਹਾਈਜੀਨ ਨੂੰ ਲਾਗੂ ਕਰੋ।

ਪਹਿਲਾ ਕਦਮ) ਹਲਕਾ ਰਿਕਵੈਸਟ ਲੌਗਿੰਗ (ਵਿਕਲਪਿਕ)

Note: ਹੇਠਾਂ ਦਿੱਤਾ ਸਹਾਇਕ ਡਿਫਾਲਟ ਤੌਰ 'ਤੇ ਸ਼ਾਮਲ ਨਹੀਂ ਹੈ। ਜੇ ਤੁਸੀਂ ਪ੍ਰਯੋਗਾਂ ਲਈ ਸਥਾਨਕ JSON ਲੌਗਿੰਗ ਚਾਹੁੰਦੇ ਹੋ ਤਾਂ `infra/obs.py` ਬਣਾਓ।  
```python
# infra/obs.py
import time, json, os
from datetime import datetime

LOG_DIR = os.getenv("FOUNDRY_AGENT_LOG_DIR", "./agent_logs")
os.makedirs(LOG_DIR, exist_ok=True)

def log_event(kind: str, payload: dict):
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    path = os.path.join(LOG_DIR, f"{ts}_{kind}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
```
  
ਏਜੰਟਾਂ ਵਿੱਚ ਲੌਗਿੰਗ ਨੂੰ ਸ਼ਾਮਲ ਕਰੋ (ਵਿਕਲਪਿਕ):  
```python
# in agents/specialists.py after receiving content
from infra.obs import log_event
# ... inside chat(...)
resp = r.json()
log_event("chat_request", {"endpoint": f"{BASE_URL}/v1/chat/completions"})
log_event("chat_response", resp)
return resp["choices"][0]["message"]["content"]
```
  

ਦੂਜਾ ਕਦਮ) CLI ਰਾਹੀਂ ਉਪਲਬਧਤਾ ਅਤੇ ਬੁਨਿਆਦੀ ਸਿਹਤ ਦੀ ਪੁਸ਼ਟੀ ਕਰੋ  
```powershell
REM Ensure Foundry Local is running a model
foundry model list
foundry model run phi-4-mini

REM Validate the OpenAI-compatible endpoint
curl http://localhost:8000/v1/models
```
  

ਤੀਜਾ ਕਦਮ) ਰੀਡੈਕਸ਼ਨ ਅਤੇ PII ਹਾਈਜੀਨ  
- ਮਾਡਲ ਨੂੰ ਸੁਨੇਹੇ ਭੇਜਣ ਤੋਂ ਪਹਿਲਾਂ, ਸੰਵੇਦਨਸ਼ੀਲ ਖੇਤਰਾਂ (ਈਮੇਲ, ਫੋਨ ਨੰਬਰ, ID) ਨੂੰ ਸਟ੍ਰਿਪ ਜਾਂ ਹੈਸ਼ ਕਰੋ  
- ਕੱਚੇ ਸਰੋਤ ਡਾਟਾ ਨੂੰ ਡਿਵਾਈਸ 'ਤੇ ਰੱਖੋ, ਸਿਰਫ਼ ਜ਼ਰੂਰੀ ਸੰਦਰਭ ਸਤਰਾਂ ਨੂੰ ਪਾਸ ਕਰੋ  

ਰੀਡੈਕਸ਼ਨ ਸਹਾਇਕ ਦਾ ਉਦਾਹਰਨ:  
```python
# infra/redact.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
ਏਜੰਟਾਂ ਵਿੱਚ ਵਰਤੋਂ:  
```python
from infra.redact import sanitize
# user_goal = sanitize(user_goal)
# context = sanitize(context)
```
  

ਚੌਥਾ ਕਦਮ) ਸਰਕਿਟ ਬ੍ਰੇਕਰ ਅਤੇ ਗਲਤੀ ਸੰਭਾਲ  
- ਹਰ ਏਜੰਟ ਕਾਲ ਨੂੰ try/except ਅਤੇ exponential backoff ਨਾਲ ਲਪੇਟੋ  
- ਵਾਰ-ਵਾਰ ਹੋਣ ਵਾਲੀਆਂ ਨਾਕਾਮੀਆਂ 'ਤੇ ਪਾਈਪਲਾਈਨ ਨੂੰ ਸ਼ਾਰਟ-ਸਰਕਿਟ ਕਰੋ  

```python
import time

def with_retry(func, retries=3, base_delay=0.5):
    for i in range(retries):
        try:
            return func()
        except Exception as e:
            if i == retries - 1:
                raise
            time.sleep(base_delay * (2 ** i))
```
  

ਪੰਜਵਾਂ ਕਦਮ) ਸਥਾਨਕ ਆਡਿਟ ਟ੍ਰੇਲ ਅਤੇ ਐਕਸਪੋਰਟ  
- JSON ਲੌਗਸ ਨੂੰ `./agent_logs` ਦੇ ਅਧੀਨ ਸਟੋਰ ਕਰੋ  
- ਲੌਗਸ ਨੂੰ ਸਮੇਂ-ਸਮੇਂ 'ਤੇ ਕੰਪ੍ਰੈਸ ਅਤੇ ਰੋਟੇਟ ਕਰੋ  
- ਸਮੀਖਿਆਵਾਂ ਲਈ ਸਾਰਾਂ ਐਕਸਪੋਰਟ ਕਰੋ (ਗਿਣਤੀ, ਔਸਤ ਲੈਟੈਂਸੀ, ਗਲਤੀ ਦਰ)  

ਛੇਵਾਂ ਕਦਮ) Microsoft Learn ਡੌਕਸ ਨਾਲ ਕ੍ਰਾਸ-ਚੈੱਕ  
- Foundry Local ਇੱਕ OpenAI-ਅਨੁਕੂਲ API ਦੀ ਸੇਵਾ ਕਰਦਾ ਹੈ (validated with `curl /v1/models`)  
- ਮਾਡਲ ਉਪਲਬਧਤਾ ਦੀ ਪੁਸ਼ਟੀ ਕਰਨ ਲਈ `foundry model run <name>` ਦੀ ਵਰਤੋਂ ਕਰੋ  
- ਕਲਾਇੰਟ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਅਤੇ ਸੈਂਪਲ ਐਪਸ ਲਈ ਅਧਿਕਾਰਤ ਦਿਸ਼ਾ-ਨਿਰਦੇਸ਼ਾਂ ਦੀ ਪਾਲਣਾ ਕਰੋ (Open WebUI/how-tos)  

ਹਵਾਲੇ:
- Foundry Local (Learn): https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Open WebUI how-to: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
- ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ ਸੈਂਪਲ: https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling

## ਅਗਲੇ ਕਦਮ
- ਕਲਾਉਡ-ਹੋਸਟਡ ਆਰਕੇਸਟ੍ਰੇਸ਼ਨ ਲਈ Azure AI Agents ਦੀ ਖੋਜ ਕਰੋ  
- ਐਨਟਰਪ੍ਰਾਈਜ਼ ਕਨੈਕਟਰ ਸ਼ਾਮਲ ਕਰੋ (Microsoft Graph, Search, ਡਾਟਾਬੇਸ)  

---

