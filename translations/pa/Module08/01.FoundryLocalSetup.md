<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6a574846c3919c56f1d02bf1de2003ca",
  "translation_date": "2025-10-01T00:01:29+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "pa"
}
-->
# ‡®∏‡©à‡®∏‡®º‡®® 1: Foundry Local ‡®®‡®æ‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§

## ‡®ù‡®≤‡®ï

Microsoft Foundry Local ‡®§‡©Å‡®π‡®æ‡®°‡©á Windows 11 ‡®µ‡®ø‡®ï‡®æ‡®∏ ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®µ‡®ø‡©±‡®ö ‡®∏‡®ø‡©±‡®ß‡©á Azure AI Foundry ‡®¶‡©Ä‡®Ü‡®Ç ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®≤‡®ø‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à, ‡®ú‡©ã ‡®ó‡©ã‡®™‡®®‡©Ä‡®Ø‡®§‡®æ-‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ö‡®§, ‡®ò‡©±‡®ü-‡®µ‡®ø‡®≤‡©∞‡®¨‡©Ä AI ‡®µ‡®ø‡®ï‡®æ‡®∏ ‡®®‡©Ç‡©∞ ‡®â‡©±‡®ö-‡®ó‡©Å‡®£‡®µ‡©±‡®§‡®æ ‡®µ‡®æ‡®≤‡©á ‡®ü‡©Ç‡®≤‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®∏‡©∞‡®≠‡®µ ‡®¨‡®£‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®∏ ‡®∏‡©à‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö ‡®™‡©ç‡®∞‡®∏‡®ø‡©±‡®ß ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®ï‡®ø phi, qwen, deepseek, ‡®Ö‡®§‡©á GPT-OSS-20B ‡®¶‡©Ä ‡®™‡©Ç‡®∞‡©Ä ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤‡©á‡®∏‡®º‡®®, ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ, ‡®Ö‡®§‡©á ‡®π‡©±‡®•-‡®Ö‡®≠‡®ø‡®Ü‡®∏ ‡®§‡©å‡®∞ ‡®§‡©á ‡®°‡®ø‡®™‡®≤‡©å‡®á‡®Æ‡©à‡®Ç‡®ü ‡®ï‡®µ‡®∞ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§

## ‡®∏‡®ø‡©±‡®ñ‡®£ ‡®¶‡©á ‡®â‡®¶‡©á‡®∏‡®º

‡®á‡®∏ ‡®∏‡©à‡®∏‡®º‡®® ‡®¶‡©á ‡®Ö‡©∞‡®§ ‡®§‡©±‡®ï, ‡®§‡©Å‡®∏‡©Ä‡®Ç:
- Windows 11 '‡®§‡©á Foundry Local ‡®®‡©Ç‡©∞ ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®Ö‡®§‡©á ‡®∏‡©∞‡®∞‡®ö‡®ø‡®§ ‡®ï‡®∞‡®®‡®æ ‡®∏‡®ø‡©±‡®ñ‡©ã‡®ó‡©á
- CLI ‡®ï‡®Æ‡®æ‡®Ç‡®°‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ ‡®µ‡®ø‡®ï‡®≤‡®™‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®Æ‡®æ‡®π‡®∞ ‡®π‡©ã ‡®ú‡®æ‡®ì‡®ó‡©á
- ‡®µ‡®ß‡©Ä‡®Ü ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®≤‡®à ‡®Æ‡®æ‡®°‡®≤ ‡®ï‡©à‡®∏‡®º‡®ø‡©∞‡®ó ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù‡©ã‡®ó‡©á
- phi, qwen, deepseek, ‡®Ö‡®§‡©á GPT-OSS-20B ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡®´‡®≤‡®§‡®æ‡®™‡©Ç‡®∞‡®µ‡®ï ‡®ö‡®≤‡®æ‡®â‡®£‡®ó‡©á
- Foundry Local ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ü‡®™‡®£‡®æ ‡®™‡®π‡®ø‡®≤‡®æ AI ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®¨‡®£‡®æ‡®â‡®£‡®ó‡©á

## ‡®™‡©Ç‡®∞‡®µ-‡®∏‡®º‡®∞‡®§‡®æ‡®Ç

### ‡®∏‡®ø‡®∏‡®ü‡®Æ ‡®¶‡©Ä‡®Ü‡®Ç ‡®≤‡©ã‡©ú‡®æ‡®Ç
- **Windows 11**: ‡®µ‡®∞‡®ú‡®® 22H2 ‡®ú‡®æ‡®Ç ‡®á‡®∏ ‡®§‡©ã‡®Ç ‡®â‡©±‡®ö‡®æ
- **RAM**: ‡®ò‡©±‡®ü‡©ã-‡®ò‡©±‡®ü 16GB, 32GB ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º‡©Ä
- **‡®∏‡®ü‡©ã‡®∞‡©á‡®ú**: ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®ï‡©à‡®∏‡®º ‡®≤‡®à 50GB ‡®ñ‡®æ‡®≤‡©Ä ‡®ú‡®ó‡©ç‡®π‡®æ
- **‡®π‡®æ‡®∞‡®°‡®µ‡©á‡®Ö‡®∞**: NPU- ‡®ú‡®æ‡®Ç GPU-‡®∏‡®Æ‡®∞‡©±‡®• ‡®°‡®ø‡®µ‡®æ‡®à‡®∏ (Copilot+ PC ‡®ú‡®æ‡®Ç NVIDIA GPU) ‡®™‡®∏‡©∞‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à
- **‡®®‡©à‡©±‡®ü‡®µ‡®∞‡®ï**: ‡®Æ‡®æ‡®°‡®≤ ‡®°‡®æ‡®ä‡®®‡®≤‡©ã‡®° ‡®≤‡®à ‡®â‡©±‡®ö-‡®ó‡®§‡©Ä ‡®á‡©∞‡®ü‡®∞‡®®‡©à‡©±‡®ü

### ‡®µ‡®ø‡®ï‡®æ‡®∏ ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## ‡®≠‡®æ‡®ó 1: ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤‡©á‡®∏‡®º‡®® ‡®Ö‡®§‡©á ‡®∏‡©à‡®ü‡®Ö‡©±‡®™

### ‡®ï‡®¶‡®Æ 1: Foundry Local ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã

Winget ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®ú‡®æ‡®Ç GitHub ‡®§‡©ã‡®Ç ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤‡®∞ ‡®°‡®æ‡®ä‡®®‡®≤‡©ã‡®° ‡®ï‡®∞‡®ï‡©á Foundry Local ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### ‡®ï‡®¶‡®Æ 2: ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤‡©á‡®∏‡®º‡®® ‡®¶‡©Ä ‡®™‡©Å‡®∏‡®º‡®ü‡©Ä ‡®ï‡®∞‡©ã

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## ‡®≠‡®æ‡®ó 2: CLI ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù‡®£‡®æ

### ‡®ï‡©ã‡®∞ ‡®ï‡®Æ‡®æ‡®Ç‡®°‡®æ‡®Ç ‡®¶‡©Ä ‡®¨‡®£‡®§‡®∞

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## ‡®≠‡®æ‡®ó 3: ‡®Æ‡®æ‡®°‡®≤ ‡®ï‡©à‡®∏‡®º‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®

Foundry Local ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®Ö‡®§‡©á ‡®∏‡®ü‡©ã‡®∞‡©á‡®ú ‡®®‡©Ç‡©∞ ‡®µ‡®ß‡©Ä‡®Ü ‡®¨‡®£‡®æ‡®â‡®£ ‡®≤‡®à ‡®∏‡®Æ‡®∞‡©±‡®• ‡®Æ‡®æ‡®°‡®≤ ‡®ï‡©à‡®∏‡®º‡®ø‡©∞‡®ó ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## ‡®≠‡®æ‡®ó 4: ‡®π‡©±‡®•-‡®Ö‡®≠‡®ø‡®Ü‡®∏ ‡®Æ‡®æ‡®°‡®≤ ‡®°‡®ø‡®™‡®≤‡©å‡®á‡®Æ‡©à‡®Ç‡®ü

### Microsoft Phi ‡®Æ‡®æ‡®°‡®≤ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Qwen ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®ï‡©∞‡®Æ ‡®ï‡®∞‡®®‡®æ

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b
foundry model run qwen2.5-14b
```

### DeepSeek ‡®Æ‡®æ‡®°‡®≤ ‡®ö‡®≤‡®æ‡®â‡®£‡®æ

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-7b
```

### GPT-OSS-20B ‡®ö‡®≤‡®æ‡®â‡®£‡®æ

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## ‡®≠‡®æ‡®ó 5: ‡®Ü‡®™‡®£‡®æ ‡®™‡®π‡®ø‡®≤‡®æ ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®¨‡®£‡®æ‡®â‡®£‡®æ

### ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï ‡®ö‡©à‡®ü ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® (OpenAI SDK + Foundry Local)

Foundry Local ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®®‡®æ‡®≤ OpenAI SDK ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®á‡©±‡®ï ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®®-‡®§‡®ø‡®Ü‡®∞ ‡®ö‡©à‡®ü ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®¨‡®£‡®æ‡®ì, ‡®∏‡®æ‡®°‡©á Sample 01 ‡®¶‡©á ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®¶‡©Ä ‡®™‡®æ‡®≤‡®£‡®æ ‡®ï‡®∞‡®¶‡©á ‡®π‡©ã‡®è‡•§

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("‚ö†Ô∏è Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"üåê Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"üè† Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"‚ö†Ô∏è Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"üîß Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### ‡®ö‡©à‡®ü ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®ö‡®≤‡®æ‡®ì

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## ‡®≠‡®æ‡®ó 6: ‡®ü‡©ç‡®∞‡®¨‡®≤‡®∏‡®º‡©Ç‡®ü‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®µ‡®ß‡©Ä‡®Ü ‡®Ö‡®≠‡®ø‡®Ü‡®∏

### ‡®Ü‡®Æ ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü‡®µ‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®π‡©±‡®≤

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### ‡®∏‡®ø‡®∏‡®ü‡®Æ ‡®∏‡®∞‡©ã‡®§‡®æ‡®Ç ‡®¶‡©Ä ‡®®‡®ø‡®ó‡®∞‡®æ‡®®‡©Ä (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®ö‡®∞

| ‡®ö‡®∞ | ‡®µ‡©á‡®∞‡®µ‡®æ | ‡®°‡®ø‡®´‡®æ‡®≤‡®ü | ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡®æ |
|-----|-------|---------|----------|
| `MODEL` | ‡®Æ‡®æ‡®°‡®≤ ‡®â‡®™‡®®‡®æ‡®Æ ‡®ú‡®æ‡®Ç ‡®®‡®æ‡®Æ | `phi-4-mini` | ‡®®‡®π‡©Ä‡®Ç |
| `BASE_URL` | Foundry Local ‡®¨‡©á‡®∏ URL | `http://localhost:8000` | ‡®®‡®π‡©Ä‡®Ç |
| `API_KEY` | API ‡®ï‡©Å‡©∞‡®ú‡©Ä (‡®Ü‡®Æ ‡®§‡©å‡®∞ '‡®§‡©á ‡®∏‡®•‡®æ‡®®‡®ï ‡®≤‡®à ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©Ä ‡®®‡®π‡©Ä‡®Ç) | `""` | ‡®®‡®π‡©Ä‡®Ç |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI ‡®ê‡®Ç‡®°‡®™‡©å‡®á‡©∞‡®ü | - | Azure ‡®≤‡®à |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API ‡®ï‡©Å‡©∞‡®ú‡©Ä | - | Azure ‡®≤‡®à |
| `AZURE_OPENAI_API_VERSION` | Azure API ‡®µ‡®∞‡®ú‡®® | `2024-08-01-preview` | ‡®®‡®π‡©Ä‡®Ç |

### ‡®µ‡®ß‡©Ä‡®Ü ‡®Ö‡®≠‡®ø‡®Ü‡®∏

- **OpenAI SDK ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡©ã**: OpenAI SDK ‡®®‡©Ç‡©∞ ‡®ï‡©±‡®ö‡©á HTTP ‡®¨‡©á‡®®‡®§‡©Ä ‡®¶‡©á ‡®¨‡®¶‡®≤‡©á ‡®™‡®∏‡©∞‡®¶ ‡®ï‡®∞‡©ã, ‡®µ‡®ß‡©Ä‡®Ü ‡®∞‡©±‡®ñ-‡®∞‡®ñ‡®æ‡®µ ‡®≤‡®à
- **FoundryLocalManager**: ‡®ú‡®¶‡©ã‡®Ç ‡®â‡®™‡®≤‡®¨‡®ß ‡®π‡©ã‡®µ‡©á, ‡®∏‡©á‡®µ‡®æ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®® ‡®≤‡®à ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ SDK ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡©ã
- **‡®ó‡®≤‡®§‡©Ä ‡®∏‡©∞‡®≠‡®æ‡®≤‡®£‡®æ**: ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®®‡®æ‡®Ç ‡®≤‡®à ‡®¢‡©Å‡®ï‡®µ‡©á‡®Ç ‡®´‡®æ‡®≤‡®¨‡©à‡®ï ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã
- **‡®®‡®ø‡®Ø‡®Æ‡®ø‡®§ ‡®Ö‡®™‡®ó‡®∞‡©á‡®°**: ‡®®‡®µ‡©á‡®Ç ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®´‡®ø‡®ï‡®∏‡®æ‡®Ç ‡®§‡©±‡®ï ‡®™‡®π‡©Å‡©∞‡®ö ‡®≤‡®à Foundry Local ‡®®‡©Ç‡©∞ ‡®Ö‡®™‡®°‡©á‡®ü ‡®∞‡©±‡®ñ‡©ã
- **‡®õ‡©ã‡®ü‡©á ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§ ‡®ï‡®∞‡©ã**: ‡®õ‡©ã‡®ü‡©á ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç (Phi mini, Qwen 7B) ‡®®‡®æ‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®µ‡®ß‡®æ‡®ì
- **‡®∏‡®∞‡©ã‡®§‡®æ‡®Ç ‡®¶‡©Ä ‡®®‡®ø‡®ó‡®∞‡®æ‡®®‡©Ä ‡®ï‡®∞‡©ã**: ‡®™‡©ç‡®∞‡©ã‡®Æ‡®™‡®ü ‡®Ö‡®§‡©á ‡®∏‡©à‡®ü‡®ø‡©∞‡®ó‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ü‡®ø‡®ä‡®® ‡®ï‡®∞‡®¶‡©á ‡®∏‡®Æ‡©á‡®Ç CPU/GPU/‡®Æ‡©à‡®Æ‡©ã‡®∞‡©Ä ‡®®‡©Ç‡©∞ ‡®ü‡©ç‡®∞‡©à‡®ï ‡®ï‡®∞‡©ã

## ‡®≠‡®æ‡®ó 7: ‡®π‡©±‡®•-‡®Ö‡®≠‡®ø‡®Ü‡®∏

### ‡®Ö‡®≠‡®ø‡®Ü‡®∏ 1: ‡®§‡©Å‡®∞‡©∞‡®§ ‡®Æ‡®≤‡®ü‡©Ä-‡®Æ‡®æ‡®°‡®≤ ‡®ü‡©à‡®∏‡®ü

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### ‡®Ö‡®≠‡®ø‡®Ü‡®∏ 2: OpenAI SDK ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®ü‡©à‡®∏‡®ü

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"‚úÖ {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"‚ùå {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b"]
for model in models_to_test:
    test_model_integration(model)
```

### ‡®Ö‡®≠‡®ø‡®Ü‡®∏ 3: ‡®µ‡®ø‡®∏‡®§‡©ç‡®∞‡®ø‡®§ ‡®∏‡©á‡®µ‡®æ ‡®∏‡®ø‡®π‡®§ ‡®ú‡®æ‡®Ç‡®ö

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"‚úÖ Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"‚úÖ {model_id}: Working")
            except Exception as e:
                print(f"‚ùå {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"‚ùå Service check failed: {e}")
        return False

comprehensive_health_check()
```

## ‡®∏‡©∞‡®¶‡®∞‡®≠

- **Foundry Local ‡®®‡®æ‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§ ‡®ï‡®∞‡©ã**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **CLI ‡®∞‡®ø‡®´‡®∞‡©à‡®Ç‡®∏ ‡®Ö‡®§‡©á ‡®ï‡®Æ‡®æ‡®Ç‡®°‡®æ‡®Ç ‡®ù‡®≤‡®ï**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **OpenAI SDK ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **Hugging Face ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ï‡©∞‡®™‡®æ‡®á‡®≤ ‡®ï‡®∞‡©ã**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **Sample 01: OpenAI SDK ‡®∞‡®æ‡®π‡©Ä‡®Ç ‡®§‡©Å‡®∞‡©∞‡®§ ‡®ö‡©à‡®ü**: samples/01/README.md
- **Sample 02: ‡®â‡©±‡®ö-‡®∏‡®§‡®∞‡©Ä SDK ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®**: samples/02/README.md

---

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®∞‡®§‡©Ä**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä ‡®π‡©ã‡®£ ‡®¶‡©Ä ‡®ï‡©ã‡®∏‡®º‡®ø‡®∏‡®º ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡®ö‡®§‡®§‡®æ‡®µ‡®æ‡®Ç ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®á‡®∏ ‡®¶‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®Æ‡©å‡®ú‡©Ç‡®¶ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®®‡©Ç‡©∞ ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§‡®´‡®π‡®ø‡®Æ‡©Ä ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§