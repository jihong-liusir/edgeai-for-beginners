<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-22T18:29:40+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "pa"
}
-->
# ਸੈਸ਼ਨ 1: Foundry Local ਨਾਲ ਸ਼ੁਰੂਆਤ

## ਝਲਕ

Microsoft Foundry Local ਤੁਹਾਡੇ Windows 11 ਵਿਕਾਸ ਵਾਤਾਵਰਣ ਵਿੱਚ ਸਿੱਧੇ Azure AI Foundry ਦੀਆਂ ਸਮਰਥਾਵਾਂ ਲਿਆਉਂਦਾ ਹੈ, ਜੋ ਗੋਪਨੀਯਤਾ-ਸੁਰੱਖਿਅਤ, ਘੱਟ-ਵਿਲੰਬੀ AI ਵਿਕਾਸ ਨੂੰ ਉੱਨਤ ਦਰਜੇ ਦੇ ਟੂਲਾਂ ਨਾਲ ਸੰਭਵ ਬਣਾਉਂਦਾ ਹੈ। ਇਸ ਸੈਸ਼ਨ ਵਿੱਚ ਪ੍ਰਸਿੱਧ ਮਾਡਲਾਂ ਜਿਵੇਂ ਕਿ phi, qwen, deepseek, ਅਤੇ GPT-OSS-20B ਦੀ ਪੂਰੀ ਇੰਸਟਾਲੇਸ਼ਨ, ਸੰਰਚਨਾ, ਅਤੇ ਹੱਥ-ਅਭਿਆਸ ਤੌਰ ਤੇ ਡਿਪਲੌਇਮੈਂਟ ਕਵਰ ਕੀਤਾ ਗਿਆ ਹੈ।

## ਸਿੱਖਣ ਦੇ ਉਦੇਸ਼

ਇਸ ਸੈਸ਼ਨ ਦੇ ਅੰਤ ਤੱਕ, ਤੁਸੀਂ:
- Windows 11 'ਤੇ Foundry Local ਨੂੰ ਇੰਸਟਾਲ ਅਤੇ ਸੰਰਚਿਤ ਕਰਨਾ ਸਿੱਖੋਗੇ
- CLI ਕਮਾਂਡਾਂ ਅਤੇ ਸੰਰਚਨਾ ਵਿਕਲਪਾਂ ਵਿੱਚ ਮਾਹਰ ਹੋਵੋਗੇ
- ਵਧੀਆ ਪ੍ਰਦਰਸ਼ਨ ਲਈ ਮਾਡਲ ਕੈਸ਼ਿੰਗ ਰਣਨੀਤੀਆਂ ਨੂੰ ਸਮਝੋਗੇ
- phi, qwen, deepseek, ਅਤੇ GPT-OSS-20B ਮਾਡਲਾਂ ਨੂੰ ਸਫਲਤਾਪੂਰਵਕ ਚਲਾਉਣਗੇ
- Foundry Local ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਆਪਣਾ ਪਹਿਲਾ AI ਐਪਲੀਕੇਸ਼ਨ ਬਣਾਉਣਗੇ

## ਪੂਰਵ ਸ਼ਰਤਾਂ

### ਸਿਸਟਮ ਦੀਆਂ ਲੋੜਾਂ
- **Windows 11**: ਵਰਜਨ 22H2 ਜਾਂ ਇਸ ਤੋਂ ਉੱਚਾ
- **RAM**: ਘੱਟੋ-ਘੱਟ 16GB, 32GB ਸਿਫਾਰਸ਼ੀ
- **ਸਟੋਰੇਜ**: ਮਾਡਲਾਂ ਅਤੇ ਕੈਸ਼ ਲਈ 50GB ਖਾਲੀ ਜਗ੍ਹਾ
- **ਹਾਰਡਵੇਅਰ**: NPU- ਜਾਂ GPU-ਸਮਰਥਿਤ ਡਿਵਾਈਸ (Copilot+ PC ਜਾਂ NVIDIA GPU) ਪਸੰਦ ਕੀਤਾ ਜਾਂਦਾ ਹੈ
- **ਨੈਟਵਰਕ**: ਮਾਡਲ ਡਾਊਨਲੋਡ ਲਈ ਤੇਜ਼-ਗਤੀ ਇੰਟਰਨੈਟ

### ਵਿਕਾਸ ਵਾਤਾਵਰਣ
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## ਭਾਗ 1: ਇੰਸਟਾਲੇਸ਼ਨ ਅਤੇ ਸੈਟਅੱਪ

### ਕਦਮ 1: Foundry Local ਇੰਸਟਾਲ ਕਰੋ

Winget ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਜਾਂ GitHub ਤੋਂ ਇੰਸਟਾਲਰ ਡਾਊਨਲੋਡ ਕਰਕੇ Foundry Local ਇੰਸਟਾਲ ਕਰੋ:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### ਕਦਮ 2: ਇੰਸਟਾਲੇਸ਼ਨ ਦੀ ਪੁਸ਼ਟੀ ਕਰੋ

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## ਭਾਗ 2: CLI ਨੂੰ ਸਮਝਣਾ

### ਕੋਰ ਕਮਾਂਡਾਂ ਦੀ ਬਣਤਰ

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## ਭਾਗ 3: ਮਾਡਲ ਕੈਸ਼ਿੰਗ ਅਤੇ ਪ੍ਰਬੰਧਨ

Foundry Local ਪ੍ਰਦਰਸ਼ਨ ਅਤੇ ਸਟੋਰੇਜ ਨੂੰ ਵਧੀਆ ਬਣਾਉਣ ਲਈ ਸਮਰਥ ਮਾਡਲ ਕੈਸ਼ਿੰਗ ਨੂੰ ਲਾਗੂ ਕਰਦਾ ਹੈ:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## ਭਾਗ 4: ਹੱਥ-ਅਭਿਆਸ ਮਾਡਲ ਡਿਪਲੌਇਮੈਂਟ

### Microsoft Phi ਮਾਡਲ ਚਲਾਉਣਾ

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Qwen ਮਾਡਲਾਂ ਨਾਲ ਕੰਮ ਕਰਨਾ

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### DeepSeek ਮਾਡਲ ਚਲਾਉਣਾ

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### GPT-OSS-20B ਚਲਾਉਣਾ

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## ਭਾਗ 5: ਆਪਣਾ ਪਹਿਲਾ ਐਪਲੀਕੇਸ਼ਨ ਬਣਾਉਣਾ

### ਸਧਾਰਨ ਚੈਟ ਇੰਟਰਫੇਸ (OpenAI-ਅਨੁਕੂਲ API)

Foundry Local ਦੇ OpenAI-ਅਨੁਕੂਲ REST API ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇੱਕ ਬੁਨਿਆਦੀ ਚੈਟ ਐਪਲੀਕੇਸ਼ਨ ਬਣਾਓ। ਯਕੀਨੀ ਬਣਾਓ ਕਿ ਇੱਕ ਮਾਡਲ ਦੂਜੇ ਟਰਮੀਨਲ ਵਿੱਚ ਚੱਲ ਰਿਹਾ ਹੈ।

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### ਚੈਟ ਐਪਲੀਕੇਸ਼ਨ ਚਲਾਓ

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## ਭਾਗ 6: ਟ੍ਰਬਲਸ਼ੂਟਿੰਗ ਅਤੇ ਵਧੀਆ ਅਭਿਆਸ

### ਆਮ ਸਮੱਸਿਆਵਾਂ ਅਤੇ ਹੱਲ

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### ਸਿਸਟਮ ਸਰੋਤਾਂ ਦੀ ਨਿਗਰਾਨੀ (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### ਵਧੀਆ ਅਭਿਆਸ

- `foundry model ...`, `foundry cache ...`, ਅਤੇ `foundry service ...` ਕਮਾਂਡਾਂ ਨੂੰ ਤਰਜੀਹ ਦਿਓ (CLI ਰਿਫਰੈਂਸ ਵੇਖੋ)
- ਨਵੇਂ ਮਾਡਲਾਂ ਅਤੇ ਫਿਕਸਾਂ ਤੱਕ ਪਹੁੰਚ ਲਈ ਨਿਯਮਿਤ ਅਪਗਰੇਡ ਕਰੋ
- ਛੋਟੇ ਮਾਡਲਾਂ (Phi mini, Qwen 7B) ਨਾਲ ਸ਼ੁਰੂਆਤ ਕਰੋ ਅਤੇ ਵਧਾਓ
- ਪ੍ਰੋਮਪਟ ਅਤੇ ਸੈਟਿੰਗਾਂ ਨੂੰ ਟਿਊਨ ਕਰਦੇ ਸਮੇਂ CPU/GPU/ਮੈਮੋਰੀ ਦੀ ਨਿਗਰਾਨੀ ਕਰੋ

## ਭਾਗ 7: ਹੱਥ-ਅਭਿਆਸ

### ਅਭਿਆਸ 1: ਤੇਜ਼ ਮਲਟੀ-ਮਾਡਲ ਰਨ

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### ਅਭਿਆਸ 2: ਬੁਨਿਆਦੀ ਵਿਲੰਬੀ ਬੈਂਚਮਾਰਕ

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## ਸੰਦਰਭ

- Foundry Local ਨਾਲ ਸ਼ੁਰੂਆਤ ਕਰੋ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- CLI ਰਿਫਰੈਂਸ ਅਤੇ ਕਮਾਂਡਾਂ ਦਾ ਜਾਇਜ਼ਾ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Foundry Local ਲਈ Hugging Face ਮਾਡਲਾਂ ਨੂੰ ਕੰਪਾਇਲ ਕਰੋ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

