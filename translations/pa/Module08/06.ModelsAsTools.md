<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7256301d9d690c2054eabbf2bc5b10bf",
  "translation_date": "2025-09-22T18:30:44+00:00",
  "source_file": "Module08/06.ModelsAsTools.md",
  "language_code": "pa"
}
-->
# ਸੈਸ਼ਨ 6: Foundry Local – ਮਾਡਲਾਂ ਨੂੰ ਸੰਦ ਵਜੋਂ ਵਰਤਣਾ

## ਝਲਕ

Foundry Local ਨਾਲ AI ਮਾਡਲਾਂ ਨੂੰ ਮੋਡਿਊਲਰ, ਕਸਟਮਾਈਜ਼ ਕਰਨ ਯੋਗ ਸੰਦ ਵਜੋਂ ਵਰਤੋ ਜੋ ਸਿੱਧੇ ਡਿਵਾਈਸ 'ਤੇ ਚੱਲਦੇ ਹਨ। ਇਸ ਸੈਸ਼ਨ ਵਿੱਚ ਗੋਪਨੀਯਤਾ-ਸੰਰਖਣ, ਘੱਟ-ਵਿਲੰਬ ਇੰਫਰੈਂਸ ਲਈ ਵਿਹਾਰਕ ਵਰਕਫਲੋਜ਼ ਤੇ ਜ਼ੋਰ ਦਿੱਤਾ ਗਿਆ ਹੈ ਅਤੇ SDKs, APIs, ਜਾਂ CLI ਰਾਹੀਂ ਇਨ੍ਹਾਂ ਸੰਦਾਂ ਨੂੰ ਕਿਵੇਂ ਇੰਟੀਗਰੇਟ ਕਰਨਾ ਹੈ। ਤੁਸੀਂ ਜ਼ਰੂਰਤ ਪੈਣ 'ਤੇ Azure AI Foundry ਲਈ ਸਕੇਲ ਕਰਨ ਦੇ ਤਰੀਕੇ ਵੀ ਸਿੱਖੋਗੇ।

ਹਵਾਲੇ:
- Foundry Local ਡੌਕਸ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ਇੰਫਰੈਂਸ SDKs ਨਾਲ ਇੰਟੀਗਰੇਟ ਕਰੋ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ਮਾਡਲਾਂ ਨੂੰ ਕੰਪਾਇਲ ਕਰੋ: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## ਸਿੱਖਣ ਦੇ ਉਦੇਸ਼
- ਡਿਵਾਈਸ 'ਤੇ ਮਾਡਲ-ਵਜੋਂ-ਸੰਦ ਪੈਟਰਨ ਡਿਜ਼ਾਈਨ ਕਰੋ
- OpenAI-ਅਨੁਕੂਲ REST API ਜਾਂ SDKs ਰਾਹੀਂ ਇੰਟੀਗਰੇਟ ਕਰੋ
- ਮਾਡਲਾਂ ਨੂੰ ਡੋਮੇਨ-ਵਿਸ਼ੇਸ਼ ਵਰਤੋਂ ਦੇ ਕੇਸਾਂ ਲਈ ਕਸਟਮਾਈਜ਼ ਕਰੋ
- Azure AI Foundry ਲਈ ਹਾਈਬ੍ਰਿਡ ਸਕੇਲਿੰਗ ਦੀ ਯੋਜਨਾ ਬਣਾਓ

## ਭਾਗ 1: ਸੰਦ ਅਬਸਟਰੈਕਸ਼ਨ (ਕਦਮ-ਦਰ-ਕਦਮ)

ਉਦੇਸ਼: ਮਾਡਲਾਂ ਨੂੰ ਸਪਸ਼ਟ ਕਾਂਟ੍ਰੈਕਟ ਅਤੇ ਸਧਾਰਨ ਰਾਊਟਰ ਨਾਲ ਸੰਦ ਵਜੋਂ ਦਰਸਾਓ।

ਕਦਮ 1) ਸੰਦ ਇੰਟਰਫੇਸ ਅਤੇ ਰਜਿਸਟਰੀ ਨੂੰ ਪਰਿਭਾਸ਼ਿਤ ਕਰੋ  
```python
# tools/registry.py
from dataclasses import dataclass
from typing import Callable, Dict

@dataclass
class Tool:
    name: str
    description: str
    input_schema: Dict
    output_schema: Dict
    handler: Callable[[Dict], Dict]

REGISTRY: Dict[str, Tool] = {}

def register(tool: Tool):
    REGISTRY[tool.name] = tool

def get_tool(name: str) -> Tool:
    return REGISTRY[name]
```
  
ਕਦਮ 2) Foundry Local ਦੁਆਰਾ ਸਮਰਥਿਤ ਦੋ ਸੰਦ ਲਾਗੂ ਕਰੋ  
```python
# tools/impl.py
import requests, os
from tools.registry import Tool, register

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}

# Chat tool (general assistant)

def chat_handler(payload: dict) -> dict:
    model = payload.get("model", "phi-4-mini")
    messages = payload.get("messages", [{"role":"user","content":"Hello"}])
    r = requests.post(f"{BASE_URL}/chat/completions", json={
        "model": model,
        "messages": messages,
        "max_tokens": payload.get("max_tokens", 300),
        "temperature": payload.get("temperature", 0.6)
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    msg = r.json()["choices"][0]["message"]["content"]
    return {"content": msg}

register(Tool(
    name="chat.assistant",
    description="General chat assistant",
    input_schema={"type":"object","properties":{"messages":{"type":"array"}}},
    output_schema={"type":"object","properties":{"content":{"type":"string"}}},
    handler=chat_handler
))

# Summarizer tool

def summarize_handler(payload: dict) -> dict:
    model = payload.get("model", "phi-4-mini")
    text = payload.get("text", "")
    messages = [
        {"role":"system","content":"You summarize text into 3 concise bullet points."},
        {"role":"user","content": f"Summarize:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
        "model": model,
        "messages": messages,
        "max_tokens": 200,
        "temperature": 0.2
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    return {"summary": r.json()["choices"][0]["message"]["content"]}

register(Tool(
    name="text.summarize",
    description="Summarize text into bullets",
    input_schema={"type":"object","properties":{"text":{"type":"string"}}},
    output_schema={"type":"object","properties":{"summary":{"type":"string"}}},
    handler=summarize_handler
))
```
  
ਕਦਮ 3) ਟਾਸਕ ਦੁਆਰਾ ਰਾਊਟਰ  
```python
# tools/router.py
from tools.registry import get_tool

def route(task: str, payload: dict):
    mapping = {
        "general": "chat.assistant",
        "summarize": "text.summarize"
    }
    tool = get_tool(mapping[task])
    return tool.handler(payload)

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    print(route("general", {"messages":[{"role":"user","content":"Hi!"}]}))
    print(route("summarize", {"text":"Edge AI brings models to devices for privacy and low latency."}))
```
  

## ਭਾਗ 2: SDK ਅਤੇ API ਇੰਟੀਗ੍ਰੇਸ਼ਨ (ਕਦਮ-ਦਰ-ਕਦਮ)

ਉਦੇਸ਼: Foundry Local ਐਂਡਪੌਇੰਟ ਦੇ ਖਿਲਾਫ OpenAI Python SDK ਵਰਤੋ।

ਕਦਮ 1) ਇੰਸਟਾਲ ਕਰੋ  
```cmd
cd Module08
.\.venv\Scripts\activate
pip install openai
```
  
ਕਦਮ 2) env vars ਕਨਫਿਗਰ ਕਰੋ  
```cmd
setx OPENAI_BASE_URL http://localhost:8000/v1
setx OPENAI_API_KEY local-key
```
  
ਕਦਮ 3) ਚੈਟ API ਨੂੰ ਕਾਲ ਕਰੋ  
```python
# sdk_demo.py
from openai import OpenAI
import os

client = OpenAI(
    base_url=os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1"),
    api_key=os.getenv("OPENAI_API_KEY", "local-key")
)

resp = client.chat.completions.create(
    model="phi-4-mini",
    messages=[{"role": "user", "content": "Summarize edge AI in one sentence."}],
    max_tokens=64
)
print(resp.choices[0].message.content)
```
  

## ਭਾਗ 3: ਡੋਮੇਨ ਕਸਟਮਾਈਜ਼ੇਸ਼ਨ (ਕਦਮ-ਦਰ-ਕਦਮ)

ਉਦੇਸ਼: ਪ੍ਰੌੰਪਟ ਟੈਂਪਲੇਟ ਅਤੇ JSON ਸਕੀਮਾ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਡੋਮੇਨ ਲਈ ਆਉਟਪੁੱਟ ਨੂੰ ਅਨੁਕੂਲ ਬਣਾਓ।

ਕਦਮ 1) ਡੋਮੇਨ ਪ੍ਰੌੰਪਟ ਟੈਂਪਲੇਟ ਬਣਾਓ  
```python
# domain/templates.py
BUSINESS_ANALYST_SYSTEM = """
You are a senior business analyst. Provide:
1) Key insights
2) Risks
3) Next steps
Respond in valid JSON with fields: insights, risks, next_steps.
"""
```
  
ਕਦਮ 2) JSON ਆਉਟਪੁੱਟ ਨੂੰ ਲਾਗੂ ਕਰੋ  
```python
# domain/analyst.py
import requests, os, json

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}

from domain.templates import BUSINESS_ANALYST_SYSTEM

def analyze(text: str) -> dict:
    messages = [
        {"role":"system","content": BUSINESS_ANALYST_SYSTEM},
        {"role":"user","content": f"Analyze this business text:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
    "model":"phi-4-mini",
        "messages": messages,
        "response_format": {"type":"json_object"},
        "temperature": 0.3
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    # Parse JSON content
    content = r.json()["choices"][0]["message"]["content"]
    return json.loads(content)

if __name__ == "__main__":
    print(analyze("Sales dipped 12% in Q3 due to supply constraints and marketing cuts."))
```
  

## ਭਾਗ 4: ਆਫਲਾਈਨ ਅਤੇ ਸੁਰੱਖਿਆ ਰਵੱਈਆ (ਕਦਮ-ਦਰ-ਕਦਮ)

ਉਦੇਸ਼: ਮਾਡਲਾਂ ਨੂੰ ਸਥਾਨਕ ਤੌਰ 'ਤੇ ਸੰਦ ਵਜੋਂ ਚਲਾਉਣ ਸਮੇਂ ਗੋਪਨੀਯਤਾ ਅਤੇ ਲਚੀਲਾਪਨ ਨੂੰ ਯਕੀਨੀ ਬਣਾਓ।

ਕਦਮ 1) ਸਥਾਨਕ ਐਂਡਪੌਇੰਟ ਨੂੰ ਪ੍ਰੀ-ਵਾਰਮ ਅਤੇ ਵੈਧ ਬਣਾਓ  
```cmd
foundry model run phi-4-mini
curl http://localhost:8000/v1/models
```
  
ਕਦਮ 2) ਇਨਪੁਟਸ ਨੂੰ ਸੈਨੀਟਾਈਜ਼ ਕਰੋ  
```python
# security/sanitize.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
ਕਦਮ 3) ਸਿਰਫ ਸਥਾਨਕ ਝੰਡਾ ਅਤੇ ਲੌਗਿੰਗ  
```python
# security/local_only.py
import os, json, time
LOG = os.getenv("MODELS_AS_TOOLS_LOG", "./tools_logs.jsonl")

def record(event: dict):
    with open(LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")

# Usage before each call
def before_call(tool_name, payload):
    record({"ts": time.time(), "tool": tool_name, "event": "before_call"})

# After each call
def after_call(tool_name, result):
    record({"ts": time.time(), "tool": tool_name, "event": "after_call"})
```
  

## ਭਾਗ 5: Azure AI Foundry ਲਈ ਸਕੇਲਿੰਗ (ਕਦਮ-ਦਰ-ਕਦਮ)

ਉਦੇਸ਼: ਓਵਰਫਲੋ ਸਮਰੱਥਾ ਲਈ ਸਥਾਨਕ ਮਾਡਲਾਂ ਨੂੰ Azure ਐਂਡਪੌਇੰਟਸ ਨਾਲ ਮਿਲਾਓ।

ਕਦਮ 1) ਰਾਊਟਿੰਗ ਰਣਨੀਤੀ ਦਾ ਫੈਸਲਾ ਕਰੋ  
- ਗੋਪਨੀਯਤਾ/ਵਿਲੰਬ ਲਈ ਪਹਿਲਾਂ ਸਥਾਨਕ, ਗਲਤੀਆਂ ਜਾਂ ਵੱਡੇ ਪ੍ਰੌੰਪਟ 'ਤੇ Azure ਫਾਲਬੈਕ  

ਕਦਮ 2) ਸਧਾਰਨ ਰਾਊਟਰ ਸਟਬ ਲਾਗੂ ਕਰੋ  
```python
# hybrid/router.py
import os, requests

LOCAL_BASE = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
AZURE_BASE = os.getenv("AZURE_FOUNDRY_BASE_URL", "")  # set to your project endpoint
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
AZURE_KEY = os.getenv("AZURE_FOUNDRY_API_KEY", "")

HEADERS_LOCAL = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}
HEADERS_AZURE = {"Content-Type":"application/json","Authorization":f"Bearer {AZURE_KEY}"}

def chat_local(payload: dict):
    r = requests.post(f"{LOCAL_BASE}/chat/completions", json=payload, headers=HEADERS_LOCAL, timeout=60)
    r.raise_for_status()
    return r.json()

def chat_azure(payload: dict):
    if not AZURE_BASE:
        raise RuntimeError("Azure base URL not configured")
    r = requests.post(f"{AZURE_BASE}/chat/completions", json=payload, headers=HEADERS_AZURE, timeout=60)
    r.raise_for_status()
    return r.json()

def hybrid_chat(messages, prefer_local=True):
    payload = {"model":"phi-4-mini", "messages": messages, "max_tokens": 256}
    if prefer_local:
        try:
            return chat_local(payload)
        except Exception:
            return chat_azure(payload)
    else:
        try:
            return chat_azure(payload)
        except Exception:
            return chat_local(payload)

if __name__ == "__main__":
    # Ensure local model is running
    print(hybrid_chat([{"role":"user","content":"Hello from hybrid router!"}]))
```
  

## ਹੈਂਡਸ-ਆਨ ਚੈੱਕਲਿਸਟ
- [ ] ਘੱਟੋ-ਘੱਟ ਦੋ ਸੰਦ ਰਜਿਸਟਰ ਕਰੋ ਅਤੇ ਬੇਨਤੀਆਂ ਨੂੰ ਰੂਟ ਕਰੋ  
- [ ] OpenAI SDK ਅਤੇ ਰੌ REST ਰਾਹੀਂ Foundry Local ਨੂੰ ਕਾਲ ਕਰੋ  
- [ ] ਡੋਮੇਨ ਟੈਂਪਲੇਟ ਲਈ JSON ਆਉਟਪੁੱਟ ਲਾਗੂ ਕਰੋ  
- [ ] ਸਥਾਨਕ ਤੌਰ 'ਤੇ ਕਾਲਾਂ ਨੂੰ ਸੈਨੀਟਾਈਜ਼ ਅਤੇ ਲੌਗ ਕਰੋ  
- [ ] Azure ਫਾਲਬੈਕ ਨਾਲ ਸਧਾਰਨ ਹਾਈਬ੍ਰਿਡ ਰਾਊਟਰ ਲਾਗੂ ਕਰੋ  

## ਸੈਸ਼ਨ ਦਾ ਸਮਾਪਤ

Foundry Local ਮਜ਼ਬੂਤ ਡਿਵਾਈਸ-ਅਤੇ AI ਨੂੰ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ ਜਿੱਥੇ ਮਾਡਲ ਕੌਮਪੋਜ਼ੇਬਲ ਸੰਦ ਬਣ ਜਾਂਦੇ ਹਨ। ਸਪਸ਼ਟ ਇੰਟਰਫੇਸ, ਗਵਰਨੈਂਸ, ਅਤੇ ਹਾਈਬ੍ਰਿਡ ਸਕੇਲਿੰਗ ਨਾਲ, ਟੀਮਾਂ ਰੀਅਲ-ਟਾਈਮ, ਸੁਰੱਖਿਅਤ AI ਐਪਸ ਸ਼ਿਪ ਕਰ ਸਕਦੀਆਂ ਹਨ ਜੋ ਯੂਜ਼ਰ ਗੋਪਨੀਯਤਾ ਦਾ ਆਦਰ ਕਰਦੀਆਂ ਹਨ ਅਤੇ ਇੰਟਰਪ੍ਰਾਈਜ਼-ਤਿਆਰ ਰਹਿੰਦੀਆਂ ਹਨ।

---

