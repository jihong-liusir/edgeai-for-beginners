<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T23:53:05+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "pa"
}
-->
# ਸੈਕਸ਼ਨ 3: ਫਾਈਨ-ਟਿਊਨਿੰਗ - ਖਾਸ ਕੰਮਾਂ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਕਸਟਮਾਈਜ਼ ਕਰਨਾ

## ਸੂਚੀ
1. [ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦਾ ਪਰਿਚਯ](../../../Module05)
2. [ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕਿਉਂ ਮਹੱਤਵਪੂਰਨ ਹੈ](../../../Module05)
3. [ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੇ ਕਿਸਮਾਂ](../../../Module05)
4. [ਮਾਈਕਰੋਸਾਫਟ ਓਲਿਵ ਨਾਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ](../../../Module05)
5. [ਹੈਂਡਸ-ਆਨ ਉਦਾਹਰਨਾਂ](../../../Module05)
6. [ਸਰਵੋਤਮ ਅਭਿਆਸ ਅਤੇ ਦਿਸ਼ਾ-ਨਿਰਦੇਸ਼](../../../Module05)
7. [ਉੱਚ-ਸਤਰੀ ਤਕਨੀਕਾਂ](../../../Module05)
8. [ਮੁਲਾਂਕਣ ਅਤੇ ਨਿਗਰਾਨੀ](../../../Module05)
9. [ਆਮ ਚੁਣੌਤੀਆਂ ਅਤੇ ਹੱਲ](../../../Module05)
10. [ਨਿਸ਼ਕਰਸ਼](../../../Module05)

## ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦਾ ਪਰਿਚਯ

**ਫਾਈਨ-ਟਿਊਨਿੰਗ** ਇੱਕ ਸ਼ਕਤੀਸ਼ਾਲੀ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਤਕਨੀਕ ਹੈ ਜੋ ਪਹਿਲਾਂ ਤੋਂ ਸਿਖਲਾਈ ਪ੍ਰਾਪਤ ਮਾਡਲ ਨੂੰ ਖਾਸ ਕੰਮਾਂ ਲਈ ਅਨੁਕੂਲ ਕਰਨ ਜਾਂ ਵਿਸ਼ੇਸ਼ ਡੇਟਾਸੈਟਾਂ ਨਾਲ ਕੰਮ ਕਰਨ ਲਈ ਅਨੁਕੂਲਿਤ ਕਰਨ ਵਿੱਚ ਸਹਾਇਕ ਹੈ। ਮਾਡਲ ਨੂੰ ਸ਼ੁਰੂ ਤੋਂ ਸਿਖਲਾਈ ਦੇਣ ਦੀ ਬਜਾਏ, ਫਾਈਨ-ਟਿਊਨਿੰਗ ਪਹਿਲਾਂ ਤੋਂ ਸਿਖਲਾਈ ਪ੍ਰਾਪਤ ਮਾਡਲ ਦੁਆਰਾ ਸਿੱਖੀ ਗਈ ਜਾਣਕਾਰੀ ਨੂੰ ਵਰਤਦੀ ਹੈ ਅਤੇ ਇਸਨੂੰ ਤੁਹਾਡੇ ਵਿਸ਼ੇਸ਼ ਉਪਯੋਗ ਲਈ ਅਨੁਕੂਲ ਕਰਦੀ ਹੈ।

### ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕੀ ਹੈ?

ਫਾਈਨ-ਟਿਊਨਿੰਗ **ਟ੍ਰਾਂਸਫਰ ਲਰਨਿੰਗ** ਦਾ ਇੱਕ ਰੂਪ ਹੈ ਜਿਸ ਵਿੱਚ ਤੁਸੀਂ:
- ਇੱਕ ਪਹਿਲਾਂ ਤੋਂ ਸਿਖਲਾਈ ਪ੍ਰਾਪਤ ਮਾਡਲ ਨਾਲ ਸ਼ੁਰੂ ਕਰਦੇ ਹੋ ਜਿਸਨੇ ਵੱਡੇ ਡੇਟਾਸੈਟਾਂ ਤੋਂ ਆਮ ਪੈਟਰਨ ਸਿੱਖੇ ਹਨ
- ਆਪਣੇ ਵਿਸ਼ੇਸ਼ ਡੇਟਾਸੈਟ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਮਾਡਲ ਦੇ ਅੰਦਰੂਨੀ ਪੈਰਾਮੀਟਰਾਂ ਨੂੰ ਅਨੁਕੂਲ ਕਰਦੇ ਹੋ
- ਕੀਮਤੀ ਜਾਣਕਾਰੀ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਦੇ ਹੋ ਜਦੋਂ ਕਿ ਮਾਡਲ ਨੂੰ ਤੁਹਾਡੇ ਕੰਮ ਲਈ ਵਿਸ਼ੇਸ਼ ਬਣਾਉਂਦੇ ਹੋ

ਇਸਨੂੰ ਇੱਕ ਮਾਹਰ ਰਸੋਈਏ ਨੂੰ ਨਵੀਂ ਪਕਵਾਨ ਸਿਖਾਉਣ ਵਾਂਗ ਸੋਚੋ - ਉਹ ਪਹਿਲਾਂ ਹੀ ਖਾਣਾ ਬਣਾਉਣ ਦੇ ਮੂਲ ਸਿਧਾਂਤ ਸਮਝਦੇ ਹਨ, ਪਰ ਨਵੀਂ ਸ਼ੈਲੀ ਲਈ ਖਾਸ ਤਕਨੀਕਾਂ ਅਤੇ ਸਵਾਦ ਸਿੱਖਣ ਦੀ ਲੋੜ ਹੈ।

### ਮੁੱਖ ਫਾਇਦੇ

- **ਸਮਾਂ ਦੀ ਬਚਤ**: ਸ਼ੁਰੂ ਤੋਂ ਸਿਖਲਾਈ ਦੇਣ ਨਾਲੋਂ ਕਾਫ਼ੀ ਤੇਜ਼
- **ਡੇਟਾ ਦੀ ਬਚਤ**: ਚੰਗੇ ਪ੍ਰਦਰਸ਼ਨ ਲਈ ਛੋਟੇ ਡੇਟਾਸੈਟ ਦੀ ਲੋੜ ਹੁੰਦੀ ਹੈ
- **ਲਾਗਤ-ਪ੍ਰਭਾਵੀ**: ਘੱਟ ਗਣਨਾਤਮਕ ਜ਼ਰੂਰਤਾਂ
- **ਵਧੀਆ ਪ੍ਰਦਰਸ਼ਨ**: ਸ਼ੁਰੂ ਤੋਂ ਸਿਖਲਾਈ ਦੇਣ ਨਾਲੋਂ ਅਕਸਰ ਬਿਹਤਰ ਨਤੀਜੇ ਪ੍ਰਾਪਤ ਕਰਦਾ ਹੈ
- **ਸੰਸਾਧਨ ਅਨੁਕੂਲਤਾ**: ਛੋਟੀਆਂ ਟੀਮਾਂ ਅਤੇ ਸੰਗਠਨਾਂ ਲਈ ਸ਼ਕਤੀਸ਼ਾਲੀ AI ਉਪਲਬਧ ਕਰਾਉਂਦਾ ਹੈ

## ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕਿਉਂ ਮਹੱਤਵਪੂਰਨ ਹੈ

### ਅਸਲ-ਦੁਨੀਆ ਦੇ ਅਨੁਪ੍ਰਯੋਗ

ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕਈ ਸਥਿਤੀਆਂ ਵਿੱਚ ਜ਼ਰੂਰੀ ਹੈ:

**1. ਡੋਮੇਨ ਅਨੁਕੂਲਤਾ**
- ਮੈਡੀਕਲ AI: ਮੈਡੀਕਲ ਸ਼ਬਦਾਵਲੀ ਅਤੇ ਕਲੀਨਿਕਲ ਨੋਟਾਂ ਲਈ ਆਮ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨੂੰ ਅਨੁਕੂਲ ਕਰਨਾ
- ਕਾਨੂੰਨੀ ਤਕਨਾਲੋਜੀ: ਕਾਨੂੰਨੀ ਦਸਤਾਵੇਜ਼ ਵਿਸ਼ਲੇਸ਼ਣ ਅਤੇ ਠੇਕੇ ਦੀ ਸਮੀਖਿਆ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਵਿਸ਼ੇਸ਼ ਬਣਾਉਣਾ
- ਵਿੱਤੀ ਸੇਵਾਵਾਂ: ਵਿੱਤੀ ਰਿਪੋਰਟ ਵਿਸ਼ਲੇਸ਼ਣ ਅਤੇ ਜੋਖਮ ਮੁਲਾਂਕਣ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਕਸਟਮਾਈਜ਼ ਕਰਨਾ

**2. ਕੰਮ ਦੀ ਵਿਸ਼ੇਸ਼ਤਾ**
- ਸਮੱਗਰੀ ਸਿਰਜਣਾ: ਖਾਸ ਲਿਖਣ ਦੇ ਅੰਦਾਜ਼ ਜਾਂ ਸੁਰਾਂ ਲਈ ਫਾਈਨ-ਟਿਊਨਿੰਗ
- ਕੋਡ ਸਿਰਜਣਾ: ਖਾਸ ਪ੍ਰੋਗਰਾਮਿੰਗ ਭਾਸ਼ਾਵਾਂ ਜਾਂ ਫਰੇਮਵਰਕਾਂ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਅਨੁਕੂਲ ਕਰਨਾ
- ਅਨੁਵਾਦ: ਖਾਸ ਭਾਸ਼ਾ ਜੋੜਿਆਂ ਜਾਂ ਤਕਨੀਕੀ ਖੇਤਰਾਂ ਲਈ ਪ੍ਰਦਰਸ਼ਨ ਵਿੱਚ ਸੁਧਾਰ

**3. ਕਾਰਪੋਰੇਟ ਅਨੁਪ੍ਰਯੋਗ**
- ਗਾਹਕ ਸੇਵਾ: ਚੈਟਬੋਟ ਬਣਾਉਣਾ ਜੋ ਕੰਪਨੀ-ਵਿਸ਼ੇਸ਼ ਸ਼ਬਦਾਵਲੀ ਨੂੰ ਸਮਝਦੇ ਹਨ
- ਅੰਦਰੂਨੀ ਦਸਤਾਵੇਜ਼: AI ਸਹਾਇਕ ਬਣਾਉਣਾ ਜੋ ਸੰਗਠਨਕ ਪ੍ਰਕਿਰਿਆਵਾਂ ਨਾਲ ਜਾਣੂ ਹਨ
- ਉਦਯੋਗ-ਵਿਸ਼ੇਸ਼ ਹੱਲ: ਮਾਡਲਾਂ ਵਿਕਸਿਤ ਕਰਨਾ ਜੋ ਖੇਤਰ-ਵਿਸ਼ੇਸ਼ ਸ਼ਬਦਾਵਲੀ ਅਤੇ ਕੰਮਕਾਜ ਨੂੰ ਸਮਝਦੇ ਹਨ

## ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੇ ਕਿਸਮਾਂ

### 1. ਪੂਰੀ ਫਾਈਨ-ਟਿਊਨਿੰਗ (ਇੰਸਟ੍ਰਕਸ਼ਨ ਫਾਈਨ-ਟਿਊਨਿੰਗ)

ਪੂਰੀ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਵਿੱਚ ਸਿਖਲਾਈ ਦੌਰਾਨ ਸਾਰੇ ਮਾਡਲ ਪੈਰਾਮੀਟਰਾਂ ਨੂੰ ਅਪਡੇਟ ਕੀਤਾ ਜਾਂਦਾ ਹੈ। ਇਹ ਪਹੁੰਚ:
- ਵੱਧ ਤੋਂ ਵੱਧ ਲਚਕਤਾ ਅਤੇ ਪ੍ਰਦਰਸ਼ਨ ਸੰਭਾਵਨਾ ਪ੍ਰਦਾਨ ਕਰਦੀ ਹੈ
- ਮਹੱਤਵਪੂਰਨ ਗਣਨਾਤਮਕ ਸੰਸਾਧਨ ਦੀ ਲੋੜ ਹੁੰਦੀ ਹੈ
- ਮਾਡਲ ਦਾ ਇੱਕ ਬਿਲਕੁਲ ਨਵਾਂ ਸੰਸਕਰਣ ਬਣਾਉਂਦੀ ਹੈ
- ਉਹ ਸਥਿਤੀਆਂ ਲਈ ਸਭ ਤੋਂ ਵਧੀਆ ਹੈ ਜਿੱਥੇ ਤੁਹਾਡੇ ਕੋਲ ਵੱਡਾ ਸਿਖਲਾਈ ਡੇਟਾ ਅਤੇ ਗਣਨਾਤਮਕ ਸੰਸਾਧਨ ਹਨ

### 2. ਪੈਰਾਮੀਟਰ-ਕੁਸ਼ਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ (PEFT)

PEFT ਤਰੀਕੇ ਸਿਰਫ ਪੈਰਾਮੀਟਰਾਂ ਦੇ ਇੱਕ ਛੋਟੇ ਸੈੱਟ ਨੂੰ ਅਪਡੇਟ ਕਰਦੇ ਹਨ, ਜਿਸ ਨਾਲ ਪ੍ਰਕਿਰਿਆ ਹੋਰ ਕੁਸ਼ਲ ਬਣਦੀ ਹੈ:

#### ਲੋ-ਰੈਂਕ ਅਡਾਪਟੇਸ਼ਨ (LoRA)
- ਮੌਜੂਦਾ ਵਜ਼ਨਾਂ ਵਿੱਚ ਛੋਟੇ ਸਿਖਲਾਈ ਯੋਗ ਰੈਂਕ ਡੀਕੰਪੋਜ਼ੀਸ਼ਨ ਮੈਟ੍ਰਿਕਸ ਸ਼ਾਮਲ ਕਰਦਾ ਹੈ
- ਸਿਖਲਾਈ ਯੋਗ ਪੈਰਾਮੀਟਰਾਂ ਦੀ ਗਿਣਤੀ ਨੂੰ ਨਾਟਕੀ ਤੌਰ 'ਤੇ ਘਟਾਉਂਦਾ ਹੈ
- ਪੂਰੀ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੇ ਨੇੜੇ ਪ੍ਰਦਰਸ਼ਨ ਨੂੰ ਸਥਿਰ ਰੱਖਦਾ ਹੈ
- ਵੱਖ-ਵੱਖ ਅਨੁਕੂਲਤਾਵਾਂ ਦੇ ਵਿਚਕਾਰ ਆਸਾਨ ਸਵਿੱਚਿੰਗ ਨੂੰ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ

#### QLoRA (ਕਵਾਂਟਾਈਜ਼ਡ LoRA)
- LoRA ਨੂੰ ਕਵਾਂਟਾਈਜ਼ੇਸ਼ਨ ਤਕਨੀਕਾਂ ਨਾਲ ਜੋੜਦਾ ਹੈ
- ਮੈਮਰੀ ਦੀ ਲੋੜ ਨੂੰ ਹੋਰ ਘਟਾਉਂਦਾ ਹੈ
- ਵੱਡੇ ਮਾਡਲਾਂ ਨੂੰ ਉਪਭੋਗਤਾ ਹਾਰਡਵੇਅਰ 'ਤੇ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਦੀ ਯੋਗਤਾ ਦਿੰਦਾ ਹੈ
- ਕੁਸ਼ਲਤਾ ਅਤੇ ਪ੍ਰਦਰਸ਼ਨ ਦੇ ਵਿਚਕਾਰ ਸੰਤੁਲਨ ਬਣਾਉਂਦਾ ਹੈ

#### ਅਡਾਪਟਰ
- ਮੌਜੂਦਾ ਲੇਅਰਾਂ ਦੇ ਵਿਚਕਾਰ ਛੋਟੇ ਨਿਊਰਲ ਨੈਟਵਰਕ ਸ਼ਾਮਲ ਕਰਦਾ ਹੈ
- ਬੇਸ ਮਾਡਲ ਨੂੰ ਜਮਾਉਂਦੇ ਹੋਏ ਟਾਰਗਟਡ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ
- ਮਾਡਲ ਕਸਟਮਾਈਜ਼ੇਸ਼ਨ ਲਈ ਮਾਡੂਲਰ ਪਹੁੰਚ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ

### 3. ਕੰਮ-ਵਿਸ਼ੇਸ਼ ਫਾਈਨ-ਟਿਊਨਿੰਗ

ਖਾਸ ਡਾਊਨਸਟ੍ਰੀਮ ਕੰਮਾਂ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਅਨੁਕੂਲ ਕਰਨ 'ਤੇ ਧਿਆਨ ਕੇਂਦਰਿਤ ਕਰਦਾ ਹੈ:
- **ਵਰਗੀਕਰਨ**: ਸ਼੍ਰੇਣੀਕਰਨ ਕੰਮਾਂ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਅਨੁਕੂਲ ਕਰਨਾ
- **ਸਿਰਜਣਾ**: ਸਮੱਗਰੀ ਸਿਰਜਣਾ ਅਤੇ ਟੈਕਸਟ ਸਿਰਜਣਾ ਲਈ ਅਨੁਕੂਲਤਾ
- **ਨਿਕਾਲ**: ਜਾਣਕਾਰੀ ਨਿਕਾਲਣ ਅਤੇ ਨਾਮਿਤ ਇਕਾਈ ਪਛਾਣ ਲਈ ਫਾਈਨ-ਟਿਊਨਿੰਗ
- **ਸੰਖੇਪਣ**: ਦਸਤਾਵੇਜ਼ ਸੰਖੇਪਣ ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਵਿਸ਼ੇਸ਼ ਬਣਾਉਣਾ

## ਮਾਈਕਰੋਸਾਫਟ ਓਲਿਵ ਨਾਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ

### ਮਾਈਕਰੋਸਾਫਟ ਓਲਿਵ ਕੀ ਹੈ?

ਮਾਈਕਰੋਸਾਫਟ ਓਲਿਵ ਇੱਕ ਖੁੱਲ੍ਹੇ-ਸਰੋਤ ਮਾਡਲ ਅਨੁਕੂਲਤਾ ਸੰਦ ਹੈ ਜੋ:
- ਵੱਖ-ਵੱਖ ਹਾਰਡਵੇਅਰ ਟਾਰਗਟਾਂ ਲਈ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਵਰਕਫਲੋਜ਼ ਨੂੰ ਸਧਾਰਨ ਬਣਾਉਂਦਾ ਹੈ
- ਪ੍ਰਸਿੱਧ ਮਾਡਲ ਆਰਕੀਟੈਕਚਰਾਂ (Llama, Phi, Qwen, Gemma) ਲਈ ਬਿਲਟ-ਇਨ ਸਹਾਇਤਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ
- ਕਲਾਉਡ ਅਤੇ ਸਥਾਨਕ ਤੈਨਾਤੀ ਵਿਕਲਪਾਂ ਦਿੰਦਾ ਹੈ
- Azure ML ਅਤੇ ਹੋਰ ਮਾਈਕਰੋਸਾਫਟ AI ਸੇਵਾਵਾਂ ਨਾਲ ਬੇਦਾਅਗ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ
- ਆਟੋਮੈਟਿਕ ਅਨੁਕੂਲਤਾ ਅਤੇ ਕਵਾਂਟਾਈਜ਼ੇਸ਼ਨ ਦਾ ਸਮਰਥਨ ਕਰਦਾ ਹੈ

### ਮੁੱਖ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ

- **ਹਾਰਡਵੇਅਰ-ਅਨੁਕੂਲ ਅਨੁਕੂਲਤਾ**: ਖਾਸ ਹਾਰਡਵੇਅਰ (CPU, GPU, NPU) ਲਈ ਮਾਡਲਾਂ ਨੂੰ ਆਟੋਮੈਟਿਕ ਤੌਰ 'ਤੇ ਅਨੁਕੂਲ ਕਰਦਾ ਹੈ
- **ਮਲਟੀ-ਫਾਰਮੈਟ ਸਹਾਇਤਾ**: PyTorch, Hugging Face, ਅਤੇ ONNX ਮਾਡਲਾਂ ਨਾਲ ਕੰਮ ਕਰਦਾ ਹੈ
- **ਆਟੋਮੈਟਿਕ ਵਰਕਫਲੋਜ਼**: ਮੈਨੂਅਲ ਕਨਫਿਗਰੇਸ਼ਨ ਅਤੇ ਟ੍ਰਾਇਲ-ਐਂਡ-ਐਰਰ ਨੂੰ ਘਟਾਉਂਦਾ ਹੈ
- **ਇੰਟਰਪ੍ਰਾਈਜ਼ ਇੰਟੀਗ੍ਰੇਸ਼ਨ**: Azure ML ਅਤੇ ਕਲਾਉਡ ਤੈਨਾਤੀ ਲਈ ਬਿਲਟ-ਇਨ ਸਹਾਇਤਾ
- **ਵਿਸਤਾਰਯੋਗ ਆਰਕੀਟੈਕਚਰ**: ਕਸਟਮ ਅਨੁਕੂਲਤਾ ਤਕਨੀਕਾਂ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ

### ਇੰਸਟਾਲੇਸ਼ਨ ਅਤੇ ਸੈਟਅੱਪ

#### ਬੁਨਿਆਦੀ ਇੰਸਟਾਲੇਸ਼ਨ

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### ਵਿਕਲਪਿਕ ਨਿਰਭਰਤਾਵਾਂ

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### ਇੰਸਟਾਲੇਸ਼ਨ ਦੀ ਪੁਸ਼ਟੀ ਕਰੋ

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## ਹਨੂੰ-ਹਾਂਦ ਉਦਾਹਰਨਾਂ

### ਉਦਾਹਰਨ 1: ਓਲਿਵ CLI ਨਾਲ ਬੁਨਿਆਦੀ ਫਾਈਨ-ਟਿਊਨਿੰਗ

ਇਹ ਉਦਾਹਰਨ ਇੱਕ ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲ ਨੂੰ ਫਰੇਜ਼ ਵਰਗੀਕਰਨ ਲਈ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਦਾ ਪ੍ਰਦਰਸ਼ਨ ਕਰਦੀ ਹੈ:

#### ਕਦਮ 1: ਆਪਣੇ ਵਾਤਾਵਰਣ ਦੀ ਤਿਆਰੀ ਕਰੋ

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### ਕਦਮ 2: ਮਾਡਲ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰੋ

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### ਕਦਮ 3: ਤੈਨਾਤੀ ਲਈ ਅਨੁਕੂਲ ਕਰੋ

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### ਉਦਾਹਰਨ 2: ਕਸਟਮ ਡੇਟਾਸੈਟ ਨਾਲ ਉੱਚ-ਸਤਰੀ ਕਨਫਿਗਰੇਸ਼ਨ

#### ਕਦਮ 1: ਕਸਟਮ ਡੇਟਾਸੈਟ ਤਿਆਰ ਕਰੋ

ਆਪਣੇ ਸਿਖਲਾਈ ਡੇਟਾ ਨਾਲ ਇੱਕ JSON ਫਾਈਲ ਬਣਾਓ:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### ਕਦਮ 2: ਕਨਫਿਗਰੇਸ਼ਨ ਫਾਈਲ ਬਣਾਓ

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### ਕਦਮ 3: ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੂੰ ਅੰਜਾਮ ਦਿਓ

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### ਉਦਾਹਰਨ 3: ਮੈਮਰੀ ਕੁਸ਼ਲਤਾ ਲਈ QLoRA ਫਾਈਨ-ਟਿਊਨਿੰਗ

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## ਸਰਵੋਤਮ ਅਭਿਆਸ ਅਤੇ ਦਿਸ਼ਾ-ਨਿਰਦੇਸ਼

### ਡੇਟਾ ਤਿਆਰੀ

**1. ਗੁਣਵੱਤਾ ਡੇਟਾ ਦੀ ਮਹੱਤਤਾ**
- ਘੱਟ ਗੁਣਵੱਤਾ ਵਾਲੇ ਵੱਡੇ ਡੇਟਾ ਦੇ ਬਦਲੇ ਉੱਚ ਗੁਣਵੱਤਾ ਅਤੇ ਵਿਵਿਧ ਉਦਾਹਰਨਾਂ ਨੂੰ ਤਰਜੀਹ ਦਿਓ
- ਯਕੀਨੀ ਬਣਾਓ ਕਿ ਡੇਟਾ ਤੁਹਾਡੇ ਟਾਰਗਟ ਉਪਯੋਗ ਦੇ ਪ੍ਰਤੀਨਿਧੀ ਹੈ
- ਡੇਟਾ ਨੂੰ ਸਥਿਰ ਤੌਰ 'ਤੇ ਸਾਫ਼ ਅਤੇ ਪ੍ਰੀ-ਪ੍ਰੋਸੈਸ ਕਰੋ

**2. ਡੇਟਾ ਫਾਰਮੈਟ ਅਤੇ ਟੈਂਪਲੇਟ**
- ਸਾਰੇ ਸਿਖਲਾਈ ਉਦਾਹਰਨਾਂ ਵਿੱਚ ਸਥਿਰ ਫਾਰਮੈਟਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰੋ
- ਸਪਸ਼ਟ ਇਨਪੁਟ-ਆਉਟਪੁੱਟ ਟੈਂਪਲੇਟ ਬਣਾਓ ਜੋ ਤੁਹਾਡੇ ਉਪਯੋਗ ਨਾਲ ਮੇਲ ਖਾਂਦੇ ਹਨ
- ਇੰਸਟ੍ਰਕਸ਼ਨ-ਟਿਊਨ ਮਾਡਲਾਂ ਲਈ ਉਚਿਤ ਇੰਸਟ੍ਰਕਸ਼ਨ ਫਾਰਮੈਟਿੰਗ ਸ਼ਾਮਲ ਕਰੋ

**3. ਡੇਟਾਸੈਟ ਵੰਡ**
- ਡੇਟਾ ਦਾ 10-20% ਵੈਲੀਡੇਸ਼ਨ ਲਈ ਰਿਜ਼ਰਵ ਕਰੋ
- ਟ੍ਰੇਨ/ਵੈਲੀਡੇਸ਼ਨ ਵੰਡਾਂ ਵਿੱਚ ਸਮਾਨ ਵੰਡਾਂ ਨੂੰ ਸਥਿਰ ਰੱਖੋ
- ਵਰਗੀਕਰਨ ਕੰਮਾਂ ਲਈ ਸਟ੍ਰੈਟੀਫਾਈਡ ਸੈਂਪਲਿੰਗ 'ਤੇ ਵਿਚਾਰ ਕਰੋ

### ਸਿਖਲਾਈ ਕਨਫਿਗਰੇਸ਼ਨ

**1. ਲਰਨਿੰਗ ਰੇਟ ਦੀ ਚੋਣ**
- ਫਾਈਨ-ਟਿਊਨਿੰਗ ਲਈ ਛੋਟੇ ਲਰਨਿੰਗ ਰੇਟ (1e-5 ਤੋਂ 1e-4) ਨਾਲ ਸ਼ੁਰੂ ਕਰੋ
- ਵਧੀਆ ਸੰਮਿਲਨ ਲਈ ਲਰਨਿੰਗ ਰੇਟ ਸ਼ਡਿਊਲਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰੋ
- ਲੋਸ ਕਰਵਾਂ ਦੀ ਨਿਗਰਾਨੀ ਕਰੋ ਅਤੇ ਰੇਟਾਂ ਨੂੰ ਅਨੁਕੂਲ ਕਰੋ

**2. ਬੈਚ ਸਾਈਜ਼ ਅਨੁਕੂਲਤਾ**
- ਉਪਲਬਧ ਮੈਮਰੀ ਨਾਲ ਬੈਚ ਸਾਈਜ਼ ਦਾ ਸੰਤੁਲਨ ਬਣਾਓ
- ਵੱਡੇ ਪ੍ਰਭਾਵਸ਼ਾਲੀ ਬੈਚ ਸਾਈਜ਼ਾਂ ਲਈ ਗ੍ਰੇਡੀਅੰਟ ਅਕੂਮੂਲੇਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰੋ
- ਬੈਚ ਸਾਈਜ਼ ਅਤੇ ਲਰਨਿੰਗ ਰੇਟ ਦੇ ਸੰਬੰਧ 'ਤੇ ਵਿਚਾਰ ਕਰੋ

**3. ਸਿਖਲਾਈ ਦੀ ਮਿਆਦ**
- ਵੈਲੀਡੇਸ਼ਨ ਮੈਟ੍ਰਿਕਸ ਦੀ ਨਿਗਰਾਨੀ ਕਰੋ ਤਾਂ ਕਿ ਓਵਰਫਿਟਿੰਗ ਤੋਂ ਬਚਿਆ ਜਾ ਸਕੇ
- ਜਦੋਂ ਵੈਲੀਡੇਸ਼ਨ ਪ੍ਰਦਰਸ਼ਨ ਪਲੇਟੋਅ ਕਰਦਾ ਹੈ ਤਾਂ ਅਗੇਰੋ ਰੋਕੋ
- ਰਿਕਵਰੀ ਅਤੇ ਵਿਸ਼ਲੇਸ਼ਣ ਲਈ ਚੈਕਪੋਇੰਟਾਂ ਨੂੰ ਨਿਯਮਿਤ ਤੌਰ 'ਤੇ ਸੇਵ ਕਰੋ

### ਮਾਡਲ ਦੀ ਚੋਣ

**1. ਬੇਸ ਮਾਡਲ ਦੀ ਚੋਣ**
- ਜਦੋਂ ਸੰਭਵ ਹੋਵੇ ਤਾਂ ਸਮਾਨ ਖੇਤਰਾਂ 'ਤੇ ਪਹਿਲਾਂ ਤੋਂ ਸਿਖਲਾਈ ਪ੍ਰਾਪਤ ਮਾਡਲਾਂ ਦੀ ਚੋਣ ਕਰੋ
- ਤੁਹਾਡੇ ਗਣਨਾਤਮਕ ਪਾਬੰਦੀਆਂ ਦੇ ਅਨੁਸਾਰ ਮਾਡਲ ਦਾ ਆਕਾਰ ਵਿਚਾਰੋ
- ਵਪਾਰਕ ਵਰਤ

---

**ਅਸਵੀਕਾਰਨਾ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਣੀਕਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।