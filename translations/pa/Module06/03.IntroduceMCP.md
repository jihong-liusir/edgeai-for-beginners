<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bd5b920b610665fd0462f6b5c2e134",
  "translation_date": "2025-09-17T23:13:14+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "pa"
}
-->
# ਸੈਕਸ਼ਨ 03 - ਮਾਡਲ ਕਾਂਟੈਕਸਟ ਪ੍ਰੋਟੋਕੋਲ (MCP) ਇੰਟੀਗ੍ਰੇਸ਼ਨ

## MCP (ਮਾਡਲ ਕਾਂਟੈਕਸਟ ਪ੍ਰੋਟੋਕੋਲ) ਦਾ ਪਰਿਚਯ

ਮਾਡਲ ਕਾਂਟੈਕਸਟ ਪ੍ਰੋਟੋਕੋਲ (MCP) ਇੱਕ ਕ੍ਰਾਂਤੀਕਾਰੀ ਫਰੇਮਵਰਕ ਹੈ ਜੋ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨੂੰ ਬਾਹਰੀ ਟੂਲਾਂ ਅਤੇ ਸਿਸਟਮਾਂ ਨਾਲ ਇੱਕ ਮਿਆਰੀ ਢੰਗ ਵਿੱਚ ਸੰਚਾਰ ਕਰਨ ਦੀ ਸਮਰਥਾ ਦਿੰਦਾ ਹੈ। ਪਾਰੰਪਰਿਕ ਪਹੁੰਚਾਂ ਦੇ ਉਲਟ, ਜਿੱਥੇ ਮਾਡਲ ਅਲੱਗ-ਅਲੱਗ ਹੁੰਦੇ ਹਨ, MCP ਇੱਕ ਵਧੀਆ ਪਰਿਭਾਸ਼ਿਤ ਪ੍ਰੋਟੋਕੋਲ ਰਾਹੀਂ AI ਮਾਡਲਾਂ ਅਤੇ ਹਕੀਕਤੀ ਦੁਨੀਆ ਦੇ ਵਿਚਕਾਰ ਇੱਕ ਪੁਲ ਬਣਾਉਂਦਾ ਹੈ।

### MCP ਕੀ ਹੈ?

MCP ਇੱਕ ਸੰਚਾਰ ਪ੍ਰੋਟੋਕੋਲ ਵਜੋਂ ਕੰਮ ਕਰਦਾ ਹੈ ਜੋ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨੂੰ ਸਮਰਥਾ ਦਿੰਦਾ ਹੈ:
- ਬਾਹਰੀ ਡਾਟਾ ਸਰੋਤਾਂ ਨਾਲ ਜੁੜਨ ਦੀ
- ਟੂਲਾਂ ਅਤੇ ਫੰਕਸ਼ਨਾਂ ਨੂੰ ਚਲਾਉਣ ਦੀ
- APIs ਅਤੇ ਸੇਵਾਵਾਂ ਨਾਲ ਸੰਚਾਰ ਕਰਨ ਦੀ
- ਰੀਅਲ-ਟਾਈਮ ਜਾਣਕਾਰੀ ਤੱਕ ਪਹੁੰਚ ਕਰਨ ਦੀ
- ਜਟਿਲ ਬਹੁ-ਕਦਮ ਕਾਰਵਾਈਆਂ ਕਰਨ ਦੀ

ਇਹ ਪ੍ਰੋਟੋਕੋਲ ਸਥਿਰ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨੂੰ ਗਤੀਸ਼ੀਲ ਏਜੰਟਾਂ ਵਿੱਚ ਬਦਲ ਦਿੰਦਾ ਹੈ ਜੋ ਟੈਕਸਟ ਜਨਰੇਸ਼ਨ ਤੋਂ ਬਾਹਰ ਪ੍ਰਯੋਗਤਮਕ ਕੰਮ ਕਰਨ ਦੇ ਯੋਗ ਹੁੰਦੇ ਹਨ।

## ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲ (SLMs) MCP ਵਿੱਚ

ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲ AI ਤੈਨਾਤੀ ਲਈ ਇੱਕ ਕੁਸ਼ਲ ਪਹੁੰਚ ਦਾ ਪ੍ਰਤੀਨਿਧਿਤਾ ਕਰਦੇ ਹਨ, ਜੋ ਕਈ ਫਾਇਦੇ ਪੇਸ਼ ਕਰਦੇ ਹਨ:

### SLMs ਦੇ ਫਾਇਦੇ
- **ਸੰਸਾਧਨ ਕੁਸ਼ਲਤਾ**: ਘੱਟ ਗਣਨਾਤਮਕ ਜ਼ਰੂਰਤਾਂ
- **ਤੇਜ਼ ਜਵਾਬ ਸਮਾਂ**: ਰੀਅਲ-ਟਾਈਮ ਐਪਲੀਕੇਸ਼ਨਾਂ ਲਈ ਘੱਟ ਲੈਟੈਂਸੀ  
- **ਲਾਗਤ ਪ੍ਰਭਾਵੀਤਾ**: ਘੱਟ ਇੰਫਰਾਸਟਰਕਚਰ ਦੀ ਲੋੜ
- **ਗੋਪਨੀਯਤਾ**: ਡਾਟਾ ਪ੍ਰਸਾਰਣ ਤੋਂ ਬਿਨਾਂ ਸਥਾਨਕ ਤੌਰ 'ਤੇ ਚਲ ਸਕਦੇ ਹਨ
- **ਕਸਟਮਾਈਜ਼ੇਸ਼ਨ**: ਖਾਸ ਖੇਤਰਾਂ ਲਈ ਆਸਾਨੀ ਨਾਲ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ

### MCP ਨਾਲ SLMs ਕਿਉਂ ਚੰਗਾ ਕੰਮ ਕਰਦੇ ਹਨ

SLMs ਨੂੰ MCP ਨਾਲ ਜੋੜ ਕੇ ਇੱਕ ਸ਼ਕਤੀਸ਼ਾਲੀ ਸੰਯੋਗ ਬਣਾਇਆ ਜਾਂਦਾ ਹੈ ਜਿੱਥੇ ਮਾਡਲ ਦੀ ਤਰਕਸ਼ੀਲ ਸਮਰਥਾ ਨੂੰ ਬਾਹਰੀ ਟੂਲਾਂ ਦੁਆਰਾ ਵਧਾਇਆ ਜਾਂਦਾ ਹੈ, ਜੋ ਛੋਟੇ ਪੈਰਾਮੀਟਰ ਗਿਣਤੀ ਨੂੰ ਵਧੇਰੇ ਕਾਰਗੁਜ਼ਾਰੀ ਨਾਲ ਪੂਰਾ ਕਰਦੇ ਹਨ।

## ਪਾਇਥਨ MCP SDK ਦਾ ਝਲਕ

ਪਾਇਥਨ MCP SDK MCP-ਸਮਰਥਿਤ ਐਪਲੀਕੇਸ਼ਨਾਂ ਬਣਾਉਣ ਲਈ ਬੁਨਿਆਦ ਮੁਹੱਈਆ ਕਰਦਾ ਹੈ। SDK ਵਿੱਚ ਸ਼ਾਮਲ ਹੈ:

- **ਕਲਾਇੰਟ ਲਾਇਬ੍ਰੇਰੀਆਂ**: MCP ਸਰਵਰਾਂ ਨਾਲ ਜੁੜਨ ਲਈ
- **ਸਰਵਰ ਫਰੇਮਵਰਕ**: ਕਸਟਮ MCP ਸਰਵਰ ਬਣਾਉਣ ਲਈ
- **ਪ੍ਰੋਟੋਕੋਲ ਹੈਂਡਲਰ**: ਸੰਚਾਰ ਦਾ ਪ੍ਰਬੰਧਨ ਕਰਨ ਲਈ
- **ਟੂਲ ਇੰਟੀਗ੍ਰੇਸ਼ਨ**: ਬਾਹਰੀ ਫੰਕਸ਼ਨਾਂ ਨੂੰ ਚਲਾਉਣ ਲਈ

## ਪ੍ਰਯੋਗਤਮਕ ਇੰਟੀਗ੍ਰੇਸ਼ਨ: Phi-4 MCP ਕਲਾਇੰਟ

ਚਲੋ ਮਾਈਕਰੋਸਾਫਟ ਦੇ Phi-4 ਮਿਨੀ ਮਾਡਲ ਨੂੰ MCP ਸਮਰਥਾ ਨਾਲ ਜੋੜ ਕੇ ਇੱਕ ਹਕੀਕਤੀ ਉਦਾਹਰਨ ਦੀ ਪੜਚੋਲ ਕਰੀਏ।

### ਸਿਸਟਮ ਆਰਕੀਟੈਕਚਰ

ਇਹ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਇੱਕ ਪਰਤਦਾਰ ਆਰਕੀਟੈਕਚਰ ਦੀ ਪਾਲਨਾ ਕਰਦਾ ਹੈ:

```
┌─────────────────────────────────────┐
│        Application Layer           │
│  ├── Interactive Loop              │
│  ├── CLI Interface                 │
│  └── Configuration Management      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│         LLM Client Layer           │
│  ├── OllamaClient                  │
│  ├── VLLMClient                    │
│  └── LLMClient (Abstract)          │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│        MCP Client Layer            │
│  ├── Phi4MiniMCPClient (STDIO)     │
│  ├── Phi4MiniSSEMCPClient (SSE)    │
│  └── BaseMCPClient (Abstract)      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│      Tool Processing Layer         │
│  ├── ToolCallHandler               │
│  ├── Function Format Transformer   │
│  └── Tool Schema Management        │
└─────────────────────────────────────┘
```

### ਮੁੱਖ ਹਿੱਸੇ

#### 1. MCP ਕਲਾਇੰਟ ਕਲਾਸਾਂ

**BaseMCPClient**: ਆਮ ਕਾਰਗੁਜ਼ਾਰੀ ਮੁਹੱਈਆ ਕਰਨ ਵਾਲਾ ਅਬਸਟਰੈਕਟ ਫਾਊਂਡੇਸ਼ਨ
- Async ਕਾਂਟੈਕਸਟ ਮੈਨੇਜਰ ਪ੍ਰੋਟੋਕੋਲ
- ਮਿਆਰੀ ਇੰਟਰਫੇਸ ਪਰਿਭਾਸ਼ਾ
- ਸੰਸਾਧਨ ਪ੍ਰਬੰਧਨ

**Phi4MiniMCPClient**: STDIO-ਅਧਾਰਿਤ ਇੰਟੀਗ੍ਰੇਸ਼ਨ
- ਸਥਾਨਕ ਪ੍ਰਕਿਰਿਆ ਸੰਚਾਰ
- ਮਿਆਰੀ ਇਨਪੁਟ/ਆਉਟਪੁਟ ਸੰਭਾਲ
- ਸਬਪ੍ਰੋਸੈਸ ਪ੍ਰਬੰਧਨ

**Phi4MiniSSEMCPClient**: ਸਰਵਰ-ਸੈਂਟ ਇਵੈਂਟਸ ਇੰਟੀਗ੍ਰੇਸ਼ਨ
- HTTP ਸਟ੍ਰੀਮਿੰਗ ਸੰਚਾਰ
- ਰੀਅਲ-ਟਾਈਮ ਇਵੈਂਟ ਸੰਭਾਲ
- ਵੈੱਬ-ਅਧਾਰਿਤ ਸਰਵਰ ਕਨੈਕਟਿਵਿਟੀ

#### 2. LLM ਇੰਟੀਗ੍ਰੇਸ਼ਨ

**OllamaClient**: ਸਥਾਨਕ ਮਾਡਲ ਹੋਸਟਿੰਗ
```python
class OllamaClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:11434/api/chat"
        self.model_id = "phi4-mini:3.8b-fp16"
```

**VLLMClient**: ਉੱਚ-ਪ੍ਰਦਰਸ਼ਨ ਸਰਵਿੰਗ
```python
class VLLMClient(LLMClient):
    def __init__(self):
        self.url = "http://localhost:8000/v1"
        self.model_id = "microsoft/Phi-4-mini-instruct"
```

#### 3. ਟੂਲ ਪ੍ਰੋਸੈਸਿੰਗ ਪਾਈਪਲਾਈਨ

ਟੂਲ ਪ੍ਰੋਸੈਸਿੰਗ ਪਾਈਪਲਾਈਨ MCP ਟੂਲਾਂ ਨੂੰ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨਾਲ ਅਨੁਕੂਲ ਫਾਰਮੈਟ ਵਿੱਚ ਬਦਲਦਾ ਹੈ:

```python
def transform_functions_format(input_data):
    """Convert MCP tool schemas to LLM-compatible formats"""
    # Maps OpenAPI schemas to function calling schemas
    # Handles parameter type conversion
    # Maintains required field information
```

## ਸ਼ੁਰੂਆਤ: ਕਦਮ-ਦਰ-ਕਦਮ ਗਾਈਡ

### ਕਦਮ 1: ਵਾਤਾਵਰਣ ਸੈਟਅਪ

ਲੋੜੀਂਦੇ ਡਿਪੈਂਡੈਂਸੀਜ਼ ਇੰਸਟਾਲ ਕਰੋ:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### ਕਦਮ 2: ਬੁਨਿਆਦੀ ਸੰਰਚਨਾ

ਆਪਣੇ ਵਾਤਾਵਰਣ ਵੈਰੀਏਬਲ ਸੈਟ ਕਰੋ:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### ਕਦਮ 3: ਆਪਣਾ ਪਹਿਲਾ MCP ਕਲਾਇੰਟ ਚਲਾਉਣਾ

**ਬੁਨਿਆਦੀ Ollama ਸੈਟਅਪ:**
```bash
python ghmodel_mcp_demo.py
```

**vLLM ਬੈਕਐਂਡ ਦੀ ਵਰਤੋਂ:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**ਸਰਵਰ-ਸੈਂਟ ਇਵੈਂਟਸ ਕਨੈਕਸ਼ਨ:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**ਕਸਟਮ MCP ਸਰਵਰ:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### ਕਦਮ 4: ਪ੍ਰੋਗਰਾਮੈਟਿਕ ਵਰਤੋਂ

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## ਉੱਚ-ਸਤਰੀਆਂ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ

### ਮਲਟੀ-ਬੈਕਐਂਡ ਸਮਰਥਨ

ਇਹ ਇੰਟੀਗ੍ਰੇਸ਼ਨ Ollama ਅਤੇ vLLM ਦੋਨੋ ਬੈਕਐਂਡਾਂ ਦਾ ਸਮਰਥਨ ਕਰਦਾ ਹੈ, ਜੋ ਤੁਹਾਡੇ ਜ਼ਰੂਰਤਾਂ ਦੇ ਅਧਾਰ 'ਤੇ ਚੋਣ ਦੀ ਆਜ਼ਾਦੀ ਦਿੰਦਾ ਹੈ:

- **Ollama**: ਸਥਾਨਕ ਵਿਕਾਸ ਅਤੇ ਟੈਸਟਿੰਗ ਲਈ ਬਿਹਤਰ
- **vLLM**: ਉੱਚ-ਥਰੂਪੁੱਟ ਅਤੇ ਪ੍ਰੋਡਕਸ਼ਨ ਲਈ ਅਨੁਕੂਲ

### ਲਚਕਦਾਰ ਕਨੈਕਸ਼ਨ ਪ੍ਰੋਟੋਕੋਲ

ਦੋ ਕਨੈਕਸ਼ਨ ਮੋਡਾਂ ਦਾ ਸਮਰਥਨ ਕੀਤਾ ਜਾਂਦਾ ਹੈ:

**STDIO ਮੋਡ**: ਸਿੱਧਾ ਪ੍ਰਕਿਰਿਆ ਸੰਚਾਰ
- ਘੱਟ ਲੈਟੈਂਸੀ
- ਸਥਾਨਕ ਟੂਲਾਂ ਲਈ ਉਚਿਤ
- ਸਧਾਰਨ ਸੈਟਅਪ

**SSE ਮੋਡ**: HTTP-ਅਧਾਰਿਤ ਸਟ੍ਰੀਮਿੰਗ
- ਨੈਟਵਰਕ ਸਮਰਥ
- ਵੰਡੇ ਹੋਏ ਸਿਸਟਮਾਂ ਲਈ ਬਿਹਤਰ
- ਰੀਅਲ-ਟਾਈਮ ਅਪਡੇਟਸ

### ਟੂਲ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਸਮਰਥਾ

ਸਿਸਟਮ ਵੱਖ-ਵੱਖ ਟੂਲਾਂ ਨਾਲ ਇੰਟੀਗ੍ਰੇਟ ਕਰ ਸਕਦਾ ਹੈ:
- ਵੈੱਬ ਆਟੋਮੇਸ਼ਨ (Playwright)
- ਫਾਈਲ ਕਾਰਵਾਈਆਂ
- API ਇੰਟਰੈਕਸ਼ਨ
- ਸਿਸਟਮ ਕਮਾਂਡ
- ਕਸਟਮ ਫੰਕਸ਼ਨ

## ਗਲਤੀ ਸੰਭਾਲ ਅਤੇ ਵਧੀਆ ਅਭਿਆਸ

### ਵਿਸਤ੍ਰਿਤ ਗਲਤੀ ਪ੍ਰਬੰਧਨ

ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਵਿੱਚ ਮਜ਼ਬੂਤ ਗਲਤੀ ਸੰਭਾਲ ਸ਼ਾਮਲ ਹੈ:

**ਕਨੈਕਸ਼ਨ ਗਲਤੀਆਂ:**
- MCP ਸਰਵਰ ਫੇਲ੍ਹ
- ਨੈਟਵਰਕ ਟਾਈਮਆਉਟ
- ਕਨੈਕਟਿਵਿਟੀ ਸਮੱਸਿਆਵਾਂ

**ਟੂਲ ਚਲਾਉਣ ਦੀਆਂ ਗਲਤੀਆਂ:**
- ਗੁੰਮ ਟੂਲ
- ਪੈਰਾਮੀਟਰ ਵੈਰੀਫਿਕੇਸ਼ਨ
- ਕਾਰਵਾਈ ਫੇਲ੍ਹ

**ਜਵਾਬ ਪ੍ਰੋਸੈਸਿੰਗ ਗਲਤੀਆਂ:**
- JSON ਪਾਰਸਿੰਗ ਸਮੱਸਿਆਵਾਂ
- ਫਾਰਮੈਟ ਅਸੰਗਤਤਾ
- LLM ਜਵਾਬ ਵਿਸੰਗਤਤਾ

### ਵਧੀਆ ਅਭਿਆਸ

1. **ਸੰਸਾਧਨ ਪ੍ਰਬੰਧਨ**: Async ਕਾਂਟੈਕਸਟ ਮੈਨੇਜਰ ਦੀ ਵਰਤੋਂ ਕਰੋ
2. **ਗਲਤੀ ਸੰਭਾਲ**: ਵਿਸਤ੍ਰਿਤ try-catch ਬਲਾਕ ਲਾਗੂ ਕਰੋ
3. **ਲੌਗਿੰਗ**: ਉਚਿਤ ਲੌਗਿੰਗ ਲੈਵਲ ਚਾਲੂ ਕਰੋ
4. **ਸੁਰੱਖਿਆ**: ਇਨਪੁਟ ਵੈਰੀਫਾਈ ਕਰੋ ਅਤੇ ਆਉਟਪੁਟ ਸੈਨੀਟਾਈਜ਼ ਕਰੋ
5. **ਪ੍ਰਦਰਸ਼ਨ**: ਕਨੈਕਸ਼ਨ ਪੂਲਿੰਗ ਅਤੇ ਕੈਸ਼ਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰੋ

## ਹਕੀਕਤੀ ਦੁਨੀਆ ਦੇ ਐਪਲੀਕੇਸ਼ਨ

### ਵੈੱਬ ਆਟੋਮੇਸ਼ਨ
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### ਡਾਟਾ ਪ੍ਰੋਸੈਸਿੰਗ
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API ਇੰਟੀਗ੍ਰੇਸ਼ਨ
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## ਪ੍ਰਦਰਸ਼ਨ ਅਨੁਕੂਲਤਾ

### ਮੈਮਰੀ ਪ੍ਰਬੰਧਨ
- ਸੁਚਾਰੂ ਸੁਨੇਹਾ ਇਤਿਹਾਸ ਸੰਭਾਲ
- ਸੰਸਾਧਨ ਦੀ ਸਹੀ ਸਫਾਈ
- ਕਨੈਕਸ਼ਨ ਪੂਲਿੰਗ

### ਨੈਟਵਰਕ ਅਨੁਕੂਲਤਾ
- Async HTTP ਕਾਰਵਾਈਆਂ
- ਸੰਰਚਿਤ ਟਾਈਮਆਉਟ
- ਗਲਤੀ ਦੀ ਸੁਚਾਰੂ ਬਹਾਲੀ

### ਸਮਕਾਲੀ ਪ੍ਰੋਸੈਸਿੰਗ
- ਨਾਨ-ਬਲਾਕਿੰਗ I/O
- ਪੈਰਾਲਲ ਟੂਲ ਚਲਾਉਣਾ
- ਕੁਸ਼ਲ async ਪੈਟਰਨ

## ਸੁਰੱਖਿਆ ਵਿਚਾਰ

### ਡਾਟਾ ਸੁਰੱਖਿਆ
- ਸੁਰੱਖਿਅਤ API ਕੁੰਜੀ ਪ੍ਰਬੰਧਨ
- ਇਨਪੁਟ ਵੈਰੀਫਿਕੇਸ਼ਨ
- ਆਉਟਪੁਟ ਸੈਨੀਟਾਈਜ਼ੇਸ਼ਨ

### ਨੈਟਵਰਕ ਸੁਰੱਖਿਆ
- HTTPS ਸਮਰਥਨ
- ਸਥਾਨਕ ਐਂਡਪੌਇੰਟ ਡਿਫਾਲਟ
- ਸੁਰੱਖਿਅਤ ਟੋਕਨ ਸੰਭਾਲ

### ਕਾਰਵਾਈ ਸੁਰੱਖਿਆ
- ਟੂਲ ਫਿਲਟਰੀਂਗ
- ਸੈਂਡਬਾਕਸਡ ਵਾਤਾਵਰਣ
- ਆਡਿਟ ਲੌਗਿੰਗ

## ਨਿਸਕਰਸ਼

MCP ਨਾਲ ਜੋੜੇ SLMs AI ਐਪਲੀਕੇਸ਼ਨ ਵਿਕਾਸ ਵਿੱਚ ਇੱਕ ਨਵਾਂ ਮਾਪਦੰਡ ਪੇਸ਼ ਕਰਦੇ ਹਨ। ਛੋਟੇ ਮਾਡਲਾਂ ਦੀ ਕੁਸ਼ਲਤਾ ਨੂੰ ਬਾਹਰੀ ਟੂਲਾਂ ਦੀ ਸ਼ਕਤੀ ਨਾਲ ਜੋੜ ਕੇ, ਵਿਕਾਸਕਾਰ ਬੁੱਧੀਮਾਨ ਸਿਸਟਮ ਬਣਾਉਣ ਦੇ ਯੋਗ ਹੁੰਦੇ ਹਨ ਜੋ ਸੰਸਾਧਨ-ਕੁਸ਼ਲ ਅਤੇ ਬਹੁਤ ਸਮਰਥ ਹੁੰਦੇ ਹਨ।

Phi-4 MCP ਕਲਾਇੰਟ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਦਿਖਾਉਂਦਾ ਹੈ ਕਿ ਇਹ ਸੰਯੋਗ ਪ੍ਰਯੋਗ ਵਿੱਚ ਕਿਵੇਂ ਹਾਸਲ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ, ਜੋ ਉੱਚ-ਸਤਰੀਆਂ AI-ਸਮਰਥਿਤ ਐਪਲੀਕੇਸ਼ਨਾਂ ਬਣਾਉਣ ਲਈ ਇੱਕ ਮਜ਼ਬੂਤ ਬੁਨਿਆਦ ਮੁਹੱਈਆ ਕਰਦਾ ਹੈ।

ਮੁੱਖ ਸਿੱਟੇ:
- MCP ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਅਤੇ ਬਾਹਰੀ ਸਿਸਟਮਾਂ ਦੇ ਵਿਚਕਾਰ ਪੁਲ ਬਣਾਉਂਦਾ ਹੈ
- SLMs ਟੂਲਾਂ ਨਾਲ ਵਧੇਰੇ ਸਮਰਥਤਾ ਦੇ ਨਾਲ ਕੁਸ਼ਲਤਾ ਪੇਸ਼ ਕਰਦੇ ਹਨ
- ਮਾਡਿਊਲਰ ਆਰਕੀਟੈਕਚਰ ਆਸਾਨੀ ਨਾਲ ਵਧਾਈ ਅਤੇ ਕਸਟਮਾਈਜ਼ੇਸ਼ਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ
- ਪ੍ਰੋਡਕਸ਼ਨ ਵਰਤੋਂ ਲਈ ਸਹੀ ਗਲਤੀ ਸੰਭਾਲ ਅਤੇ ਸੁਰੱਖਿਆ ਉਪਾਅ ਜ਼ਰੂਰੀ ਹਨ

ਇਹ ਟਿਊਟੋਰਿਅਲ ਤੁਹਾਡੇ ਆਪਣੇ SLM-ਸਮਰਥਿਤ MCP ਐਪਲੀਕੇਸ਼ਨ ਬਣਾਉਣ ਲਈ ਬੁਨਿਆਦ ਮੁਹੱਈਆ ਕਰਦਾ ਹੈ, ਜੋ ਆਟੋਮੇਸ਼ਨ, ਡਾਟਾ ਪ੍ਰੋਸੈਸਿੰਗ, ਅਤੇ ਬੁੱਧੀਮਾਨ ਸਿਸਟਮ ਇੰਟੀਗ੍ਰੇਸ਼ਨ ਲਈ ਸੰਭਾਵਨਾਵਾਂ ਖੋਲ੍ਹਦਾ ਹੈ।

---

**ਅਸਵੀਕਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚਤਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤ ਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।