<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T14:52:38+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "fi"
}
-->
# Workshop-muistikirjat - Pikaopas

## Sis√§llysluettelo

- [Edellytykset](../../../../Workshop/notebooks)
- [Alkuasetukset](../../../../Workshop/notebooks)
- [Istunto 04: Mallien vertailu](../../../../Workshop/notebooks)
- [Istunto 05: Moniagenttinen orkestrointi](../../../../Workshop/notebooks)
- [Istunto 06: Aikomuspohjainen mallien reititys](../../../../Workshop/notebooks)
- [Ymp√§rist√∂muuttujat](../../../../Workshop/notebooks)
- [Yleiset komennot](../../../../Workshop/notebooks)

---

## Edellytykset

### 1. Asenna Foundry Local

**Windows:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**Vahvista asennus:**
```bash
foundry --version
```

### 2. Asenna Python-riippuvuudet

```bash
cd Workshop
pip install -r requirements.txt
```

Tai asenna yksitellen:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## Alkuasetukset

### K√§ynnist√§ Foundry Local -palvelu

**Vaaditaan ennen mink√§√§n muistikirjan suorittamista:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

Odotettu tulos:
```
‚úÖ Service started successfully
Endpoint: http://localhost:59959
```

### Lataa ja lataa mallit

Muistikirjat k√§ytt√§v√§t oletuksena n√§it√§ malleja:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### Vahvista asetukset

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## Istunto 04: Mallien vertailu

### Tarkoitus
Vertaa Small Language Models (SLM) ja Large Language Models (LLM) suorituskyky√§.

### Pika-asetus

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### Muistikirjan suorittaminen

1. **Avaa** `session04_model_compare.ipynb` VS Codessa tai Jupyteriss√§
2. **K√§ynnist√§ ydin uudelleen** (Kernel ‚Üí Restart Kernel)
3. **Suorita kaikki solut** j√§rjestyksess√§

### Keskeiset asetukset

**Oletusmallit:**
- **SLM:** `phi-4-mini` (~4GB RAM, nopeampi)
- **LLM:** `qwen2.5-3b` (~3GB RAM, muistitehokas)

**Ymp√§rist√∂muuttujat (valinnainen):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### Odotettu tulos

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

üí° SLM is 1.99x faster than LLM for this prompt
```

### Mukauttaminen

**K√§yt√§ eri malleja:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**Mukautettu kehotus:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### Vahvistuslista

- [ ] Solu 12 n√§ytt√§√§ oikeat mallit (phi-4-mini, qwen2.5-3b)
- [ ] Solu 12 n√§ytt√§√§ oikean p√§√§tepisteen (portti 59959)
- [ ] Solu 16 diagnostiikka onnistuu (‚úÖ Palvelu k√§ynniss√§)
- [ ] Solu 20 esitarkistus onnistuu (molemmat mallit ok)
- [ ] Solu 22 vertailu valmistuu viivearvoilla
- [ ] Solu 24 vahvistus n√§ytt√§√§ üéâ KAIKKI TARKISTUKSET ONNISTUIVAT!

### Aika-arvio
- **Ensimm√§inen suoritus:** 5-10 minuuttia (sis√§lt√§en mallien lataukset)
- **Seuraavat suoritukset:** 1-2 minuuttia

---

## Istunto 05: Moniagenttinen orkestrointi

### Tarkoitus
Esittele moniagenttista yhteisty√∂t√§ Foundry Local SDK:n avulla - agentit ty√∂skentelev√§t yhdess√§ tuottaakseen tarkennettuja tuloksia.

### Pika-asetus

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### Muistikirjan suorittaminen

1. **Avaa** `session05_agents_orchestrator.ipynb`
2. **K√§ynnist√§ ydin uudelleen**
3. **Suorita kaikki solut** j√§rjestyksess√§

### Keskeiset asetukset

**Oletusasetus (Sama malli molemmille agenteille):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**Edistynyt asetus (Eri mallit):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### Arkkitehtuuri

```
User Question
    ‚Üì
Researcher Agent (phi-4-mini)
  ‚Üí Gathers bullet points
    ‚Üì
Editor Agent (phi-4-mini or qwen2.5-7b)
  ‚Üí Refines into executive summary
    ‚Üì
Final Output
```

### Odotettu tulos

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: ‚Ä¢ Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### Laajennukset

**Lis√§√§ lis√§√§ agentteja:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**Er√§testaus:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### Aika-arvio
- **Ensimm√§inen suoritus:** 3-5 minuuttia
- **Seuraavat suoritukset:** 1-2 minuuttia per kysymys

---

## Istunto 06: Aikomuspohjainen mallien reititys

### Tarkoitus
Reitit√§ kehotukset √§lykk√§√§sti erikoistuneille malleille havaittujen aikomusten perusteella.

### Pika-asetus

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**Huom:** Istunto 06 k√§ytt√§√§ oletuksena CPU-malleja maksimaalisen yhteensopivuuden vuoksi.

### Muistikirjan suorittaminen

1. **Avaa** `session06_models_router.ipynb`
2. **K√§ynnist√§ ydin uudelleen**
3. **Suorita kaikki solut** j√§rjestyksess√§

### Keskeiset asetukset

**Oletuskatalogi (CPU-mallit):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**Vaihtoehto (GPU-mallit):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### Aikomusten tunnistus

Reititin k√§ytt√§√§ regex-kuvioita aikomusten tunnistamiseen:

| Aikomus | Esimerkki kuvioita | Reititetty |
|---------|--------------------|------------|
| `code` | "refactor", "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize", "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize", "tl;dr" | phi-4-mini-cpu |
| `general` | Kaikki muu | phi-4-mini-cpu |

### Odotettu tulos

```
‚úì Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

‚úì Success! All prompts routed correctly.
```

### Mukauttaminen

**Lis√§√§ mukautettu aikomus:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ÁøªËØë', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**Ota k√§ytt√∂√∂n token-seuranta:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### Siirtyminen GPU-malleihin

Jos sinulla on 8GB+ VRAM:

1. Solussa **#6**, kommentoi CPU-katalogi
2. Poista GPU-katalogin kommentointi
3. Lataa GPU-mallit:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. K√§ynnist√§ ydin uudelleen ja suorita muistikirja uudelleen

### Aika-arvio
- **Ensimm√§inen suoritus:** 5-10 minuuttia (mallien lataus)
- **Seuraavat suoritukset:** 30-60 sekuntia per testi

---

## Ymp√§rist√∂muuttujat

### Globaalit asetukset

Aseta ennen Jupyterin/VS Coden k√§ynnist√§mist√§:

**Windows (Komentokehote):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**Windows (PowerShell):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### Muistikirjan sis√§iset asetukset

Aseta mink√§ tahansa muistikirjan alussa:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## Yleiset komennot

### Palvelun hallinta

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### Mallien hallinta

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### P√§√§tepisteiden testaus

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### Diagnostiikkakomennot

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## Parhaat k√§yt√§nn√∂t

### Ennen mink√§√§n muistikirjan aloittamista

1. **Tarkista, ett√§ palvelu on k√§ynniss√§:**
   ```bash
   foundry service status
   ```

2. **Vahvista, ett√§ mallit on ladattu:**
   ```bash
   foundry model ls
   ```

3. **K√§ynnist√§ muistikirjan ydin uudelleen** jos suoritat uudelleen

4. **Tyhjenn√§ kaikki tulosteet** puhdasta suoritusta varten

### Resurssien hallinta

1. **K√§yt√§ CPU-malleja oletuksena** yhteensopivuuden vuoksi
2. **Vaihda GPU-malleihin** vain jos sinulla on 8GB+ VRAM
3. **Sulje muut GPU-sovellukset** ennen suorittamista
4. **Pid√§ palvelu k√§ynniss√§** muistikirjaistuntojen v√§lill√§
5. **Seuraa resurssien k√§ytt√∂√§** Task Managerilla / nvidia-smill√§

### Vianetsint√§

1. **Tarkista aina palvelu ensin** ennen koodin vianetsint√§√§
2. **K√§ynnist√§ ydin uudelleen** jos n√§et vanhentuneen asetuksen
3. **Suorita diagnostiikkasolut uudelleen** muutosten j√§lkeen
4. **Tarkista mallien nimet** vastaavat ladattuja
5. **Vahvista p√§√§tepisteen portti** vastaa palvelun tilaa

---

## Pikaopas: Mallialiaset

### Yleiset mallit

| Alias | Koko | Paras k√§ytt√∂ | RAM/VRAM | Variantit |
|-------|------|-------------|----------|----------|
| `phi-4-mini` | ~4B | Yleinen keskustelu, tiivistys | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | Koodin generointi, refaktorointi | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | Yleiset teht√§v√§t, tehokas | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | Nopea, v√§h√§iset resurssit | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | Luokittelu, minimaaliset resurssit | 1-2GB | `-cpu`, `-cuda-gpu` |

### Varianttien nime√§minen

- **Perusnimi** (esim. `phi-4-mini`): Valitsee automaattisesti parhaan variantin laitteistollesi
- **`-cpu`**: CPU-optimoitu, toimii kaikkialla
- **`-cuda-gpu`**: NVIDIA GPU optimoitu, vaatii 8GB+ VRAM
- **`-npu`**: Qualcomm NPU optimoitu, vaatii NPU-ajurit

**Suositus:** K√§yt√§ perusnimi√§ (ilman j√§lkiliitett√§) ja anna Foundry Localin valita automaattisesti paras variantti.

---

## Onnistumisen merkit

Olet valmis, kun n√§et:

‚úÖ `foundry service status` n√§ytt√§√§ "running"
‚úÖ `foundry model ls` n√§ytt√§√§ tarvittavat mallisi
‚úÖ Palvelu k√§ytett√§viss√§ oikeassa p√§√§tepisteess√§
‚úÖ Terveystarkistus palauttaa 200 OK
‚úÖ Muistikirjan diagnostiikkasolut onnistuvat
‚úÖ Ei yhteysvirheit√§ tulosteessa

---

## Apua saatavilla

### Dokumentaatio
- **P√§√§repository:** https://github.com/microsoft/Foundry-Local
- **Python SDK:** https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **CLI-viite:** https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md
- **Vianetsint√§:** Katso `troubleshooting.md` t√§ss√§ hakemistossa

### GitHub-ongelmat
- https://github.com/microsoft/Foundry-Local/issues
- https://github.com/microsoft/edgeai-for-beginners/issues

---

**Viimeksi p√§ivitetty:** 8. lokakuuta 2025  
**Versio:** Workshop-muistikirjat 2.0

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.