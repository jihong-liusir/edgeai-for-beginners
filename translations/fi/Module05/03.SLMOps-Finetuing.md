<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T10:36:07+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "fi"
}
-->
# Osa 3: Fine-Tuning – Mallien räätälöinti erityistehtäviin

## Sisällysluettelo
1. [Johdatus Fine-Tuningiin](../../../Module05)
2. [Miksi Fine-Tuning on tärkeää](../../../Module05)
3. [Fine-Tuningin tyypit](../../../Module05)
4. [Fine-Tuning Microsoft Olivella](../../../Module05)
5. [Käytännön esimerkit](../../../Module05)
6. [Parhaat käytännöt ja ohjeet](../../../Module05)
7. [Edistyneet tekniikat](../../../Module05)
8. [Arviointi ja seuranta](../../../Module05)
9. [Yleiset haasteet ja ratkaisut](../../../Module05)
10. [Yhteenveto](../../../Module05)

## Johdatus Fine-Tuningiin

**Fine-tuning** on tehokas koneoppimistekniikka, jossa valmiiksi koulutettu malli mukautetaan suorittamaan erityistehtäviä tai käsittelemään erikoistuneita aineistoja. Sen sijaan, että malli koulutettaisiin alusta alkaen, fine-tuning hyödyntää valmiiksi koulutetun mallin oppimaa tietoa ja säätää sitä vastaamaan juuri sinun käyttötarkoitustasi.

### Mitä Fine-Tuning tarkoittaa?

Fine-tuning on eräänlainen **siirto-oppiminen**, jossa:
- Aloitetaan valmiiksi koulutetulla mallilla, joka on oppinut yleisiä kuvioita suurista aineistoista
- Säädetään mallin sisäisiä parametreja käyttämällä omaa aineistoa
- Säilytetään arvokas tieto samalla, kun malli erikoistuu tehtävääsi

Ajattele sitä kuin opettaisit taitavaa kokkia valmistamaan uutta ruokakulttuuria – hän ymmärtää jo ruoanlaiton perusteet, mutta tarvitsee tietoa uusista tekniikoista ja makumaailmoista.

### Keskeiset hyödyt

- **Aikasäästö**: Merkittävästi nopeampaa kuin koulutus alusta alkaen
- **Aineistotehokkuus**: Hyvä suorituskyky pienemmillä aineistoilla
- **Kustannustehokkuus**: Vähemmän laskentatehoa vaativa
- **Parempi suorituskyky**: Usein parempia tuloksia kuin alusta koulutetuilla malleilla
- **Resurssien optimointi**: Tehokas AI pienemmille tiimeille ja organisaatioille

## Miksi Fine-Tuning on tärkeää

### Käyttökohteet tosielämässä

Fine-tuning on välttämätöntä monissa tilanteissa:

**1. Alakohtainen mukauttaminen**
- Lääketieteellinen AI: Yleisten kielimallien mukauttaminen lääketieteelliseen terminologiaan ja potilaskertomuksiin
- Lakiteknologia: Mallien erikoistaminen lakiasiakirjojen analysointiin ja sopimusten tarkasteluun
- Rahoituspalvelut: Mallien räätälöinti talousraporttien analysointiin ja riskien arviointiin

**2. Tehtäväkohtainen erikoistuminen**
- Sisällöntuotanto: Fine-tuning tiettyihin kirjoitustyyleihin tai sävyihin
- Koodin generointi: Mallien mukauttaminen tiettyihin ohjelmointikieliin tai -kehyksiin
- Käännös: Suorituskyvyn parantaminen tietyissä kielipareissa tai teknisissä aihealueissa

**3. Yrityskäyttö**
- Asiakaspalvelu: Chatbotit, jotka ymmärtävät yrityksen terminologiaa
- Sisäinen dokumentaatio: AI-avustajat, jotka tuntevat organisaation prosessit
- Alakohtaiset ratkaisut: Mallit, jotka ymmärtävät toimialakohtaisen terminologian ja työnkulut

## Fine-Tuningin tyypit

### 1. Täysi Fine-Tuning (Instruction Fine-Tuning)

Täydessä fine-tuningissa kaikki mallin parametrit päivitetään koulutuksen aikana. Tämä lähestymistapa:
- Tarjoaa maksimaalisen joustavuuden ja suorituskyvyn
- Vaatii merkittäviä laskentaresursseja
- Tuottaa täysin uuden version mallista
- Sopii tilanteisiin, joissa on runsaasti koulutusaineistoa ja laskentatehoa

### 2. Parametrien tehokas Fine-Tuning (PEFT)

PEFT-menetelmät päivittävät vain pienen osan parametreista, mikä tekee prosessista tehokkaamman:

#### Low-Rank Adaptation (LoRA)
- Lisää pieniä koulutettavia matriiseja olemassa oleviin painoihin
- Vähentää merkittävästi koulutettavien parametrien määrää
- Säilyttää suorituskyvyn lähellä täyttä fine-tuningia
- Mahdollistaa helpon siirtymisen eri mukautusten välillä

#### QLoRA (Quantized LoRA)
- Yhdistää LoRA:n kvantisointitekniikoihin
- Vähentää entisestään muistivaatimuksia
- Mahdollistaa suurempien mallien fine-tuningin kuluttajalaitteilla
- Tasapainottaa tehokkuuden ja suorituskyvyn

#### Adapterit
- Lisää pieniä hermoverkkoja olemassa olevien kerrosten väliin
- Mahdollistaa kohdennetun fine-tuningin pitäen perusmallin muuttumattomana
- Tarjoaa modulaarisen lähestymistavan mallin mukauttamiseen

### 3. Tehtäväkohtainen Fine-Tuning

Keskittyy mallien mukauttamiseen tiettyihin jatkotehtäviin:
- **Luokittelu**: Mallien säätäminen kategorisointitehtäviin
- **Generointi**: Optimointi sisällöntuotantoon ja tekstin generointiin
- **Poiminta**: Fine-tuning tiedon poimintaan ja nimettyjen entiteettien tunnistamiseen
- **Yhteenveto**: Mallien erikoistaminen dokumenttien tiivistämiseen

## Fine-Tuning Microsoft Olivella

Microsoft Olive on kattava mallien optimointityökalu, joka yksinkertaistaa fine-tuning-prosessia ja tarjoaa yritystason ominaisuuksia.

### Mikä on Microsoft Olive?

Microsoft Olive on avoimen lähdekoodin mallien optimointityökalu, joka:
- Virtaviivaistaa fine-tuning-työnkulut eri laitteistokohteille
- Tarjoaa sisäänrakennetun tuen suosituimmille mallirakenteille (Llama, Phi, Qwen, Gemma)
- Mahdollistaa sekä pilvi- että paikalliset käyttöönotot
- Integroituu saumattomasti Azure ML:n ja muiden Microsoftin AI-palveluiden kanssa
- Tukee automaattista optimointia ja kvantisointia

### Keskeiset ominaisuudet

- **Laitteistotietoinen optimointi**: Optimoi mallit automaattisesti tietylle laitteistolle (CPU, GPU, NPU)
- **Monimuotoinen tuki**: Toimii PyTorch-, Hugging Face- ja ONNX-mallien kanssa
- **Automatisoidut työnkulut**: Vähentää manuaalista konfigurointia ja kokeilua
- **Yritysintegraatio**: Sisäänrakennettu tuki Azure ML:lle ja pilvikäyttöönotolle
- **Laajennettava arkkitehtuuri**: Mahdollistaa mukautetut optimointitekniikat

### Asennus ja käyttöönotto

#### Perusasennus

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Valinnaiset riippuvuudet

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Asennuksen tarkistus

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Käytännön esimerkit

### Esimerkki 1: Perus Fine-Tuning Olive CLI:llä

Tässä esimerkissä fine-tunataan pieni kielimalli lauseiden luokitteluun:

#### Vaihe 1: Valmistele ympäristösi

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Vaihe 2: Fine-Tunaa malli

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Vaihe 3: Optimoi käyttöönottoa varten

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Esimerkki 2: Edistynyt konfigurointi mukautetulla aineistolla

#### Vaihe 1: Valmistele mukautettu aineisto

Luo JSON-tiedosto koulutusaineistollasi:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Vaihe 2: Luo konfiguraatiotiedosto

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Vaihe 3: Suorita Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Esimerkki 3: QLoRA Fine-Tuning muistitehokkuuden parantamiseksi

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Parhaat käytännöt ja ohjeet

### Aineiston valmistelu

**1. Laatu ennen määrää**
- Panosta korkealaatuisiin, monipuolisiin esimerkkeihin suurten huonolaatuisten aineistojen sijaan
- Varmista, että aineisto edustaa kohdekäyttötarkoitustasi
- Puhdista ja esikäsittele aineisto johdonmukaisesti

**2. Aineiston muoto ja mallit**
- Käytä johdonmukaista muotoilua kaikissa koulutusesimerkeissä
- Luo selkeät syöte-lähtömallit, jotka vastaavat käyttötarkoitustasi
- Sisällytä ohjeiden muotoilu ohjeistettuihin malleihin

**3. Aineiston jakaminen**
- Varaa 10–20 % aineistosta validointiin
- Säilytä samankaltaiset jakaumat koulutus/validointijaoissa
- Harkitse luokittelutehtäviin kerrostettua otantaa

### Koulutuskonfiguraatio

**1. Oppimisnopeuden valinta**
- Aloita pienemmillä oppimisnopeuksilla (1e-5 – 1e-4) fine-tuningissa
- Käytä oppimisnopeuden säätöä paremman konvergenssin saavuttamiseksi
- Seuraa häviökäyriä nopeuden säätämiseksi

**2. Eräkoon optimointi**
- Tasapainota eräkoko käytettävissä olevan muistin kanssa
- Käytä gradientin kertymistä suurempien tehokkaiden eräkokojen saavuttamiseksi
- Harkitse eräkoon ja oppimisnopeuden välistä suhdetta

**3. Koulutuksen kesto**
- Seuraa validointimittareita ylikoulutuksen välttämiseksi
- Käytä varhaista pysäytystä, kun validointisuorituskyky tasaantuu
- Tallenna tarkistuspisteet säännöllisesti palautusta ja analyysiä varten

### Mallin valinta

**1. Perusmallin valinta**
- Valitse mallit, jotka on koulutettu samankaltaisilla aloilla, kun mahdollista
- Harkitse mallin kokoa suhteessa laskentakapasiteettiisi
- Arvioi lisenssivaatimukset kaupallista käyttöä varten

**2. Fine-Tuning-menetelmän valinta**
- Käytä LoRA/QLoRA-menetelmiä resurssirajoitteisissa ympäristöissä
- Valitse täysi fine-tuning, kun maksimaalinen suorituskyky on kriittistä
- Harkitse adapteripohjaisia lähestymistapoja monitehtävätilanteisiin

### Resurssien hallinta

**1. Laitteiston optimointi**
- Valitse sopiva laitteisto mallisi koon ja menetelmän mukaan
- Hyödynnä GPU-muistia tehokkaasti gradientin tarkistuspisteiden avulla
- Harkitse pilvipohjaisia ratkaisuja suuremmille malleille

**2. Muistin hallinta**
- Käytä sekatarkkuuskoulutusta, kun mahdollista
- Toteuta gradientin kertymistä muistirajoitusten vuoksi
- Seuraa GPU-muistin käyttöä koulutuksen aikana

## Edistyneet tekniikat

### Moniadapterikoulutus

Kouluta useita adaptereita eri tehtäviin samalla, kun perusmalli jaetaan:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparametrien optimointi

Toteuta systemaattinen hyperparametrien säätö:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Mukautetut häviöfunktiot

Toteuta alakohtaisia häviöfunktioita:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Arviointi ja seuranta

### Mittarit ja arviointi

**1. Standardimittarit**
- **Tarkkuus**: Kokonaiskorrektius luokittelutehtävissä
- **Perpleksisyys**: Kielenmallinnuksen laadun mittari
- **BLEU/ROUGE**: Tekstin generoinnin ja tiivistämisen laatu
- **F1-pisteet**: Tasapainotettu tarkkuus ja palautus luokittelussa

**2. Alakohtaiset mittarit**
- **Tehtäväkohtaiset vertailut**: Käytä vakiintuneita vertailuja alallasi
- **Ihmisen arviointi**: Sisällytä ihmisen arviointi subjektiivisiin tehtäviin
- **Liiketoimintamittarit**: Kohdista todellisiin liiketoimintatavoitteisiin

**3. Arviointiasetukset**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Koulutuksen etenemisen seuranta

**1. Häviön seuranta**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validoinnin seuranta**
- Seuraa validointihäviötä koulutushäviön rinnalla
- Tarkkaile ylikoulutuksen merkkejä (validointihäviö kasvaa, kun koulutushäviö pienenee)
- Käytä varhaista pysäytystä validointimittareiden perusteella

**3. Resurssien seuranta**
- Seuraa GPU/CPU:n käyttöä
- Tarkkaile muistin käyttöä
- Seuraa koulutuksen nopeutta ja läpimenoaikaa

## Yleiset haasteet ja ratkaisut

### Haaste 1: Ylikoulutus

**Oireet:**
- Koulutushäviö jatkaa laskuaan, kun validointihäviö kasvaa
- Suuri ero koulutus- ja validointisuorituskyvyn välillä
- Huono yleistys uuteen aineistoon

**Ratkaisut:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Haaste 2: Muistirajoitukset

**Ratkaisut:**
- Käytä gradientin tarkistuspisteitä
- Toteuta gradientin kertymistä
- Valitse parametrien tehokkaat menetelmät (LoRA, QLoRA)
- Hyödynnä mallin rinnakkaiskäsittelyä suurille malleille

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Haaste 3: Hidas koulutus

**Ratkaisut:**
- Optimoi aineiston latausputket
- Käytä sekatarkkuuskoulutusta
- Toteuta tehokkaita erästrategioita
- Harkitse hajautettua koulutusta suurille aineistoille

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Haaste 4: Huono suorituskyky

**Diagnostiikkavaiheet:**
1. Varmista aineiston laatu ja muotoilu
2. Tarkista oppimisnopeus ja koulutuksen kesto
3. Arvioi perusmallin valinta
4. Tarkista esikäsittely ja tokenisointi

**Ratkaisut:**
- Lisää koulutusaineiston monimuotoisuutta
- Säädä oppimisnopeuden aikataulua
- Kokeile eri perusmalleja
- Toteuta aineiston augmentointitekniikoita

## Yhteenveto

Fine-tuning on tehokas tekniikka, joka demokratisoi pääsyn huipputason AI-ominaisuuksiin. Hyödyntämällä työkaluja, kuten Microsoft Olive, organisaatiot voivat mukauttaa valmiiksi koulutettuja malleja tehokkaasti omiin tarpeisiinsa samalla optimoiden suorituskykyä ja resurssien käyttöä.

### Keskeiset opit

1. **Valitse oikea lähestymistapa**: Valitse fine-tuning-menetelmät laskentaresurssien ja suorituskykyvaatimusten perusteella
2. **Aineiston laatu on tärkeää**: Panosta korkealaatuiseen, edustavaan koulutusaineistoon
3. **Seuraa ja iteroi**: Arvioi ja paranna malleja jatkuvasti
4. **Hyödynnä työkaluja**: Käytä Olive-kaltaisia kehyksiä prosessin yksinkertaistamiseen ja optimointiin
5. **Harkitse käyttöönottoa**: Suunnittele mallin optimointi ja käyttöönotto alusta alkaen

## ➡️ Mitä seuraavaksi

- [04: Käyttöönotto – tuotantovalmiiden mallien toteutus](./04.SLMOps.Deployment.md)

---

**Vastuuvapauslauseke**:  
Tämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, että automaattiset käännökset voivat sisältää virheitä tai epätarkkuuksia. Alkuperäinen asiakirja sen alkuperäisellä kielellä tulisi pitää ensisijaisena lähteenä. Kriittisen tiedon osalta suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa väärinkäsityksistä tai virhetulkinnoista, jotka johtuvat tämän käännöksen käytöstä.