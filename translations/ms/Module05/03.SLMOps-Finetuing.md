<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T14:50:46+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "ms"
}
-->
# Seksyen 3: Penyesuaian - Menyesuaikan Model untuk Tugas Khusus

## Kandungan
1. [Pengenalan kepada Penyesuaian](../../../Module05)
2. [Mengapa Penyesuaian Penting](../../../Module05)
3. [Jenis Penyesuaian](../../../Module05)
4. [Penyesuaian dengan Microsoft Olive](../../../Module05)
5. [Contoh Praktikal](../../../Module05)
6. [Amalan Terbaik dan Garis Panduan](../../../Module05)
7. [Teknik Lanjutan](../../../Module05)
8. [Penilaian dan Pemantauan](../../../Module05)
9. [Cabaran Umum dan Penyelesaian](../../../Module05)
10. [Kesimpulan](../../../Module05)

## Pengenalan kepada Penyesuaian

**Penyesuaian** adalah teknik pembelajaran mesin yang berkuasa, di mana model yang telah dilatih sebelumnya disesuaikan untuk melaksanakan tugas tertentu atau bekerja dengan set data khusus. Daripada melatih model dari awal, penyesuaian memanfaatkan pengetahuan yang telah dipelajari oleh model yang telah dilatih sebelumnya dan menyesuaikannya untuk kes penggunaan anda.

### Apa itu Penyesuaian?

Penyesuaian adalah bentuk **pembelajaran pemindahan** di mana anda:
- Bermula dengan model yang telah dilatih sebelumnya yang telah mempelajari corak umum daripada set data besar
- Menyesuaikan parameter dalaman model menggunakan set data khusus anda
- Mengekalkan pengetahuan yang bernilai sambil mengkhususkan model untuk tugas anda

Bayangkan seperti mengajar seorang chef mahir untuk memasak masakan baru - mereka sudah memahami asas memasak, tetapi perlu mempelajari teknik dan rasa khusus untuk gaya baru.

### Manfaat Utama

- **Kecekapan Masa**: Jauh lebih pantas daripada melatih dari awal
- **Kecekapan Data**: Memerlukan set data yang lebih kecil untuk mencapai prestasi yang baik
- **Kos Efektif**: Keperluan komputasi yang lebih rendah
- **Prestasi Lebih Baik**: Selalunya mencapai hasil yang lebih baik berbanding melatih dari awal
- **Pengoptimuman Sumber**: Membuat AI yang berkuasa dapat diakses oleh pasukan dan organisasi yang lebih kecil

## Mengapa Penyesuaian Penting

### Aplikasi Dunia Nyata

Penyesuaian adalah penting dalam pelbagai senario:

**1. Penyesuaian Domain**
- AI Perubatan: Menyesuaikan model bahasa umum untuk istilah perubatan dan nota klinikal
- Teknologi Undang-Undang: Mengkhususkan model untuk analisis dokumen undang-undang dan semakan kontrak
- Perkhidmatan Kewangan: Menyesuaikan model untuk analisis laporan kewangan dan penilaian risiko

**2. Pengkhususan Tugas**
- Penjanaan Kandungan: Penyesuaian untuk gaya penulisan atau nada tertentu
- Penjanaan Kod: Menyesuaikan model untuk bahasa pengaturcaraan atau rangka kerja tertentu
- Terjemahan: Meningkatkan prestasi untuk pasangan bahasa tertentu atau domain teknikal

**3. Aplikasi Korporat**
- Perkhidmatan Pelanggan: Mencipta chatbot yang memahami istilah khusus syarikat
- Dokumentasi Dalaman: Membina pembantu AI yang biasa dengan proses organisasi
- Penyelesaian Khusus Industri: Membangunkan model yang memahami jargon dan aliran kerja sektor tertentu

## Jenis Penyesuaian

### 1. Penyesuaian Penuh (Penyesuaian Arahan)

Dalam penyesuaian penuh, semua parameter model dikemas kini semasa latihan. Pendekatan ini:
- Memberikan fleksibiliti maksimum dan potensi prestasi
- Memerlukan sumber komputasi yang besar
- Menghasilkan versi model yang sepenuhnya baru
- Terbaik untuk senario di mana anda mempunyai data latihan yang banyak dan sumber komputasi yang mencukupi

### 2. Penyesuaian Parameter-Efektif (PEFT)

Kaedah PEFT hanya mengemas kini sebahagian kecil parameter, menjadikan proses lebih efisien:

#### Penyesuaian Pangkat Rendah (LoRA)
- Menambah matriks dekomposisi pangkat kecil yang boleh dilatih kepada berat sedia ada
- Mengurangkan jumlah parameter yang boleh dilatih secara dramatik
- Mengekalkan prestasi yang hampir dengan penyesuaian penuh
- Membolehkan pertukaran mudah antara penyesuaian yang berbeza

#### QLoRA (LoRA Kuantifikasi)
- Menggabungkan LoRA dengan teknik kuantifikasi
- Mengurangkan keperluan memori lebih jauh
- Membolehkan penyesuaian model yang lebih besar pada perkakasan pengguna
- Mengimbangi kecekapan dengan prestasi

#### Adapters
- Menyisipkan rangkaian neural kecil antara lapisan sedia ada
- Membolehkan penyesuaian yang disasarkan sambil mengekalkan model asas
- Membolehkan pendekatan modular untuk penyesuaian model

### 3. Penyesuaian Tugas Khusus

Fokus pada menyesuaikan model untuk tugas hiliran tertentu:
- **Klasifikasi**: Menyesuaikan model untuk tugas pengkategorian
- **Penjanaan**: Mengoptimumkan untuk penciptaan kandungan dan penjanaan teks
- **Ekstraksi**: Penyesuaian untuk ekstraksi maklumat dan pengenalan entiti bernama
- **Ringkasan**: Mengkhususkan model untuk ringkasan dokumen

## Penyesuaian dengan Microsoft Olive

Microsoft Olive adalah alat pengoptimuman model yang komprehensif yang mempermudah proses penyesuaian sambil menyediakan ciri-ciri bertaraf perusahaan.

### Apa itu Microsoft Olive?

Microsoft Olive adalah alat pengoptimuman model sumber terbuka yang:
- Mempermudah aliran kerja penyesuaian untuk pelbagai sasaran perkakasan
- Menyediakan sokongan terbina dalam untuk seni bina model popular (Llama, Phi, Qwen, Gemma)
- Menawarkan pilihan penyebaran awan dan tempatan
- Berintegrasi dengan lancar dengan Azure ML dan perkhidmatan AI Microsoft lain
- Menyokong pengoptimuman dan kuantifikasi automatik

### Ciri Utama

- **Pengoptimuman Berasaskan Perkakasan**: Mengoptimumkan model secara automatik untuk perkakasan tertentu (CPU, GPU, NPU)
- **Sokongan Multi-Format**: Berfungsi dengan model PyTorch, Hugging Face, dan ONNX
- **Aliran Kerja Automatik**: Mengurangkan konfigurasi manual dan percubaan-cuba
- **Integrasi Perusahaan**: Sokongan terbina dalam untuk Azure ML dan penyebaran awan
- **Seni Bina Boleh Diperluas**: Membolehkan teknik pengoptimuman khusus

### Pemasangan dan Persediaan

#### Pemasangan Asas

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Kebergantungan Pilihan

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Pengesahan Pemasangan

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Contoh Praktikal

### Contoh 1: Penyesuaian Asas dengan Olive CLI

Contoh ini menunjukkan penyesuaian model bahasa kecil untuk klasifikasi frasa:

#### Langkah 1: Sediakan Persekitaran Anda

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Langkah 2: Menyesuaikan Model

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Langkah 3: Mengoptimumkan untuk Penyebaran

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Contoh 2: Konfigurasi Lanjutan dengan Dataset Khusus

#### Langkah 1: Sediakan Dataset Khusus

Cipta fail JSON dengan data latihan anda:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Langkah 2: Cipta Fail Konfigurasi

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Langkah 3: Laksanakan Penyesuaian

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Contoh 3: Penyesuaian QLoRA untuk Kecekapan Memori

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Amalan Terbaik dan Garis Panduan

### Penyediaan Data

**1. Kualiti Data Lebih Penting Daripada Kuantiti**
- Utamakan contoh yang berkualiti tinggi dan pelbagai berbanding jumlah data yang besar tetapi berkualiti rendah
- Pastikan data mewakili kes penggunaan sasaran anda
- Bersihkan dan pra-proses data secara konsisten

**2. Format Data dan Templat**
- Gunakan format yang konsisten di semua contoh latihan
- Cipta templat input-output yang jelas yang sesuai dengan kes penggunaan anda
- Sertakan format arahan yang sesuai untuk model yang disesuaikan dengan arahan

**3. Pembahagian Dataset**
- Simpan 10-20% data untuk pengesahan
- Kekalkan pengedaran yang serupa di antara pembahagian latihan/pengesahan
- Pertimbangkan pensampelan berstrata untuk tugas klasifikasi

### Konfigurasi Latihan

**1. Pemilihan Kadar Pembelajaran**
- Mulakan dengan kadar pembelajaran yang lebih kecil (1e-5 hingga 1e-4) untuk penyesuaian
- Gunakan penjadualan kadar pembelajaran untuk penumpuan yang lebih baik
- Pantau lengkung kehilangan untuk menyesuaikan kadar dengan sewajarnya

**2. Pengoptimuman Saiz Batch**
- Seimbangkan saiz batch dengan memori yang tersedia
- Gunakan pengumpulan gradien untuk saiz batch efektif yang lebih besar
- Pertimbangkan hubungan antara saiz batch dan kadar pembelajaran

**3. Tempoh Latihan**
- Pantau metrik pengesahan untuk mengelakkan overfitting
- Gunakan pemberhentian awal apabila prestasi pengesahan mendatar
- Simpan titik semak secara berkala untuk pemulihan dan analisis

### Pemilihan Model

**1. Pilihan Model Asas**
- Pilih model yang telah dilatih sebelumnya pada domain yang serupa jika boleh
- Pertimbangkan saiz model relatif kepada kekangan komputasi anda
- Nilai keperluan pelesenan untuk penggunaan komersial

**2. Pemilihan Kaedah Penyesuaian**
- Gunakan LoRA/QLoRA untuk persekitaran yang terhad sumber
- Pilih penyesuaian penuh apabila prestasi maksimum adalah kritikal
- Pertimbangkan pendekatan berasaskan adapter untuk senario tugas berganda

### Pengurusan Sumber

**1. Pengoptimuman Perkakasan**
- Pilih perkakasan yang sesuai untuk saiz model dan kaedah anda
- Gunakan memori GPU dengan cekap dengan pemeriksaan gradien
- Pertimbangkan penyelesaian berasaskan awan untuk model yang lebih besar

**2. Pengurusan Memori**
- Gunakan latihan ketepatan campuran apabila tersedia
- Laksanakan pengumpulan gradien untuk kekangan memori
- Pantau penggunaan memori GPU sepanjang latihan

## Teknik Lanjutan

### Latihan Multi-Adapter

Latih pelbagai adapter untuk tugas yang berbeza sambil berkongsi model asas:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Pengoptimuman Hiperparameter

Laksanakan penalaan hiperparameter secara sistematik:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Fungsi Kehilangan Khusus

Laksanakan fungsi kehilangan khusus domain:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Penilaian dan Pemantauan

### Metrik dan Penilaian

**1. Metrik Standard**
- **Ketepatan**: Ketepatan keseluruhan untuk tugas klasifikasi
- **Perplexity**: Ukuran kualiti pemodelan bahasa
- **BLEU/ROUGE**: Kualiti penjanaan teks dan ringkasan
- **Skor F1**: Keseimbangan ketepatan dan panggilan untuk klasifikasi

**2. Metrik Khusus Domain**
- **Penanda Aras Tugas Khusus**: Gunakan penanda aras yang ditetapkan untuk domain anda
- **Penilaian Manusia**: Sertakan penilaian manusia untuk tugas subjektif
- **Metrik Perniagaan**: Selaraskan dengan objektif perniagaan sebenar

**3. Persediaan Penilaian**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Pemantauan Kemajuan Latihan

**1. Penjejakan Kehilangan**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Pemantauan Pengesahan**
- Pantau kehilangan pengesahan bersama kehilangan latihan
- Pantau tanda-tanda overfitting (kehilangan pengesahan meningkat sementara kehilangan latihan menurun)
- Gunakan pemberhentian awal berdasarkan metrik pengesahan

**3. Pemantauan Sumber**
- Pantau penggunaan GPU/CPU
- Jejak pola penggunaan memori
- Pantau kelajuan dan throughput latihan

## Cabaran Umum dan Penyelesaian

### Cabaran 1: Overfitting

**Gejala:**
- Kehilangan latihan terus menurun sementara kehilangan pengesahan meningkat
- Jurang besar antara prestasi latihan dan pengesahan
- Generalisasi yang lemah kepada data baru

**Penyelesaian:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Cabaran 2: Kekangan Memori

**Penyelesaian:**
- Gunakan pemeriksaan gradien
- Laksanakan pengumpulan gradien
- Pilih kaedah parameter-efektif (LoRA, QLoRA)
- Gunakan paralelisme model untuk model besar

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Cabaran 3: Latihan Perlahan

**Penyelesaian:**
- Optimumkan saluran paip pemuatan data
- Gunakan latihan ketepatan campuran
- Laksanakan strategi batching yang efisien
- Pertimbangkan latihan terdistribusi untuk set data besar

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Cabaran 4: Prestasi Lemah

**Langkah Diagnostik:**
1. Sahkan kualiti dan format data
2. Periksa kadar pembelajaran dan tempoh latihan
3. Nilai pilihan model asas
4. Semak pra-pemprosesan dan tokenisasi

**Penyelesaian:**
- Tingkatkan kepelbagaian data latihan
- Laraskan jadual kadar pembelajaran
- Cuba model asas yang berbeza
- Laksanakan teknik pengayaan data

## Kesimpulan

Penyesuaian adalah teknik yang berkuasa yang mendemokrasikan akses kepada keupayaan AI terkini. Dengan memanfaatkan alat seperti Microsoft Olive, organisasi dapat menyesuaikan model yang telah dilatih sebelumnya dengan cekap untuk keperluan khusus mereka sambil mengoptimumkan prestasi dan kekangan sumber.

### Pengajaran Utama

1. **Pilih Pendekatan yang Tepat**: Pilih kaedah penyesuaian berdasarkan sumber komputasi dan keperluan prestasi anda
2. **Kualiti Data Penting**: Melabur dalam data latihan yang berkualiti tinggi dan mewakili
3. **Pantau dan Iterasi**: Sentiasa menilai dan meningkatkan model anda
4. **Manfaatkan Alat**: Gunakan rangka kerja seperti Olive untuk mempermudah dan mengoptimumkan proses
5. **Pertimbangkan Penyebaran**: Rancang pengoptimuman dan penyebaran model dari awal


## ➡️ Apa yang seterusnya

- [04: Penyebaran - Pelaksanaan Model Sedia Pengeluaran](./04.SLMOps.Deployment.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat yang kritikal, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.