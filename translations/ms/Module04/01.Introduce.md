<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49e18143f97a802a8647f4be28355348",
  "translation_date": "2025-09-18T14:44:38+00:00",
  "source_file": "Module04/01.Introduce.md",
  "language_code": "ms"
}
-->
# Seksyen 1: Asas Penukaran Format Model dan Kuantisasi

Penukaran format model dan kuantisasi merupakan kemajuan penting dalam EdgeAI, yang membolehkan keupayaan pembelajaran mesin canggih pada peranti dengan sumber terhad. Memahami cara menukar, mengoptimumkan, dan menggunakan model dengan berkesan adalah penting untuk membina penyelesaian AI berasaskan edge yang praktikal.

## Pengenalan

Dalam tutorial ini, kita akan meneroka teknik penukaran format model dan kuantisasi serta strategi pelaksanaannya yang lebih maju. Kita akan membincangkan konsep asas pemampatan model, sempadan dan klasifikasi penukaran format, teknik pengoptimuman, dan strategi penggunaan praktikal untuk persekitaran pengkomputeran edge.

## Objektif Pembelajaran

Pada akhir tutorial ini, anda akan dapat:

- 🔢 Memahami sempadan kuantisasi dan klasifikasi tahap ketepatan yang berbeza.
- 🛠️ Mengenal pasti teknik penukaran format utama untuk penggunaan model pada peranti edge.
- 🚀 Mempelajari strategi kuantisasi dan pemampatan lanjutan untuk inferens yang dioptimumkan.

## Memahami Sempadan dan Klasifikasi Kuantisasi Model

Kuantisasi model adalah teknik yang direka untuk mengurangkan ketepatan parameter rangkaian neural dengan bilangan bit yang jauh lebih sedikit berbanding model ketepatan penuh. Walaupun model ketepatan penuh menggunakan perwakilan titik terapung 32-bit, model kuantisasi direka khusus untuk kecekapan dan penggunaan pada peranti edge.

Kerangka klasifikasi ketepatan membantu kita memahami kategori tahap kuantisasi yang berbeza dan kes penggunaan yang sesuai. Klasifikasi ini penting untuk memilih tahap ketepatan yang tepat untuk senario pengkomputeran edge tertentu.

### Kerangka Klasifikasi Ketepatan

Memahami sempadan ketepatan membantu dalam memilih tahap kuantisasi yang sesuai untuk senario pengkomputeran edge yang berbeza:

- **🔬 Ketepatan Ultra-Rendah**: Kuantisasi 1-bit hingga 2-bit (pemampatan ekstrem untuk perkakasan khusus)
- **📱 Ketepatan Rendah**: Kuantisasi 3-bit hingga 4-bit (prestasi dan kecekapan yang seimbang)
- **⚖️ Ketepatan Sederhana**: Kuantisasi 5-bit hingga 8-bit (mendekati keupayaan ketepatan penuh sambil mengekalkan kecekapan)

Sempadan tepat kekal fleksibel dalam komuniti penyelidikan, tetapi kebanyakan pengamal menganggap 8-bit dan ke bawah sebagai "kuantisasi," dengan beberapa sumber menetapkan ambang khusus untuk sasaran perkakasan yang berbeza.

### Kelebihan Utama Kuantisasi Model

Kuantisasi model menawarkan beberapa kelebihan asas yang menjadikannya ideal untuk aplikasi pengkomputeran edge:

**Kecekapan Operasi**: Model kuantisasi memberikan masa inferens yang lebih pantas kerana kerumitan pengiraan yang dikurangkan, menjadikannya ideal untuk aplikasi masa nyata. Ia memerlukan sumber pengiraan yang lebih rendah, membolehkan penggunaan pada peranti dengan sumber terhad sambil menggunakan tenaga yang lebih sedikit dan mengekalkan jejak karbon yang rendah.

**Fleksibiliti Penggunaan**: Model ini membolehkan keupayaan AI pada peranti tanpa keperluan sambungan internet, meningkatkan privasi dan keselamatan melalui pemprosesan tempatan, boleh disesuaikan untuk aplikasi khusus domain, dan sesuai untuk pelbagai persekitaran pengkomputeran edge.

**Kos Efektif**: Model kuantisasi menawarkan latihan dan penggunaan yang lebih kos efektif berbanding model ketepatan penuh, dengan kos operasi yang lebih rendah dan keperluan jalur lebar yang lebih rendah untuk aplikasi edge.

## Strategi Pemerolehan Format Model Lanjutan

### GGUF (General GGML Universal Format)

GGUF berfungsi sebagai format utama untuk menggunakan model kuantisasi pada CPU dan peranti edge. Format ini menyediakan sumber yang komprehensif untuk penukaran dan penggunaan model:

**Ciri Penemuan Format**: Format ini menawarkan sokongan lanjutan untuk pelbagai tahap kuantisasi, keserasian lesen, dan pengoptimuman prestasi. Pengguna boleh mengakses keserasian rentas platform, penanda aras prestasi masa nyata, dan sokongan WebGPU untuk penggunaan berasaskan pelayar.

**Koleksi Tahap Kuantisasi**: Format kuantisasi popular termasuk Q4_K_M untuk pemampatan seimbang, siri Q5_K_S untuk aplikasi yang memfokuskan kualiti, Q8_0 untuk ketepatan hampir asal, dan format eksperimen seperti Q2_K untuk penggunaan ketepatan ultra-rendah. Format ini juga menampilkan variasi yang dipacu komuniti dengan konfigurasi khusus untuk domain tertentu serta varian tujuan umum dan yang ditala untuk arahan, dioptimumkan untuk kes penggunaan yang berbeza.

### ONNX (Open Neural Network Exchange)

Format ONNX menyediakan keserasian rentas rangka kerja untuk model kuantisasi dengan keupayaan integrasi yang dipertingkatkan:

**Integrasi Perusahaan**: Format ini merangkumi model dengan sokongan dan keupayaan pengoptimuman bertaraf perusahaan, menampilkan kuantisasi dinamik untuk ketepatan adaptif dan kuantisasi statik untuk penggunaan pengeluaran. Ia juga menyokong model daripada pelbagai rangka kerja dengan pendekatan kuantisasi yang standard.

**Manfaat Perusahaan**: Alat terbina dalam untuk pengoptimuman, penggunaan rentas platform, dan pecutan perkakasan diintegrasikan merentasi enjin inferens yang berbeza. Sokongan rangka kerja langsung dengan API standard, ciri pengoptimuman bersepadu, dan aliran kerja penggunaan yang komprehensif meningkatkan pengalaman perusahaan.

## Teknik Kuantisasi dan Pengoptimuman Lanjutan

### Kerangka Pengoptimuman Llama.cpp

Llama.cpp menyediakan teknik kuantisasi terkini untuk kecekapan maksimum dalam penggunaan edge:

**Kaedah Kuantisasi**: Kerangka ini menyokong pelbagai tahap kuantisasi termasuk Q4_0 (kuantisasi 4-bit dengan pengurangan saiz yang sangat baik - ideal untuk penggunaan mudah alih), Q5_1 (kuantisasi 5-bit yang mengimbangi kualiti dan pemampatan - sesuai untuk inferens edge), dan Q8_0 (kuantisasi 8-bit untuk kualiti hampir asal - disyorkan untuk penggunaan pengeluaran). Format lanjutan seperti Q2_K mewakili pemampatan terkini untuk senario ekstrem.

**Manfaat Pelaksanaan**: Inferens yang dioptimumkan CPU dengan pecutan SIMD menyediakan pemuatan dan pelaksanaan model yang cekap memori. Keserasian rentas platform merentasi seni bina x86, ARM, dan Apple Silicon membolehkan keupayaan penggunaan bebas perkakasan.

**Perbandingan Jejak Memori**: Tahap kuantisasi yang berbeza menawarkan pertukaran antara saiz model dan kualiti. Q4_0 menyediakan pengurangan saiz kira-kira 75%, Q5_1 menawarkan pengurangan 70% dengan pengekalan kualiti yang lebih baik, dan Q8_0 mencapai pengurangan 50% sambil mengekalkan prestasi hampir asal.

### Microsoft Olive Optimization Suite

Microsoft Olive menawarkan aliran kerja pengoptimuman model yang komprehensif yang direka untuk persekitaran pengeluaran:

**Teknik Pengoptimuman**: Suite ini merangkumi kuantisasi dinamik untuk pemilihan ketepatan automatik, pengoptimuman graf dan gabungan operator untuk kecekapan yang lebih baik, pengoptimuman khusus perkakasan untuk penggunaan CPU, GPU, dan NPU, serta saluran pengoptimuman berbilang peringkat. Aliran kerja kuantisasi khusus menyokong pelbagai tahap ketepatan dari 8-bit hingga konfigurasi eksperimen 1-bit.

**Automasi Aliran Kerja**: Penanda aras automatik merentasi varian pengoptimuman memastikan pemeliharaan metrik kualiti semasa pengoptimuman. Integrasi dengan rangka kerja ML popular seperti PyTorch dan ONNX menyediakan keupayaan pengoptimuman penggunaan awan dan edge.

### Kerangka Apple MLX

Apple MLX menyediakan pengoptimuman asli yang direka khusus untuk peranti Apple Silicon:

**Pengoptimuman Apple Silicon**: Kerangka ini menggunakan seni bina memori bersatu dengan integrasi Metal Performance Shaders, inferens ketepatan campuran automatik, dan penggunaan lebar jalur memori yang dioptimumkan. Model menunjukkan prestasi luar biasa pada cip siri M dengan keseimbangan optimum untuk pelbagai penggunaan peranti Apple.

**Ciri Pembangunan**: Sokongan API Python dan Swift dengan operasi array yang serasi NumPy, keupayaan pembezaan automatik, dan integrasi lancar dengan alat pembangunan Apple menyediakan persekitaran pembangunan yang komprehensif.

## Strategi Penggunaan dan Inferens Pengeluaran

### Ollama: Penggunaan Tempatan yang Dipermudahkan

Ollama mempermudah penggunaan model dengan ciri sedia perusahaan untuk persekitaran tempatan dan edge:

**Keupayaan Penggunaan**: Pemasangan dan pelaksanaan model dengan satu arahan dengan penarikan dan caching model automatik. Sokongan untuk pelbagai format kuantisasi dengan REST API untuk integrasi aplikasi serta pengurusan dan penukaran model berbilang. Tahap kuantisasi lanjutan memerlukan konfigurasi khusus untuk penggunaan optimum.

**Ciri Lanjutan**: Sokongan penalaan model tersuai, penjanaan Dockerfile untuk penggunaan berbekas, pecutan GPU dengan pengesanan automatik, dan pilihan kuantisasi serta pengoptimuman model menyediakan fleksibiliti penggunaan yang komprehensif.

### VLLM: Inferens Berprestasi Tinggi

VLLM menyampaikan pengoptimuman inferens bertaraf pengeluaran untuk senario throughput tinggi:

**Pengoptimuman Prestasi**: PagedAttention untuk pengiraan perhatian yang cekap memori, batching dinamik untuk pengoptimuman throughput, paralelisme tensor untuk penskalaan multi-GPU, dan decoding spekulatif untuk pengurangan latensi. Format kuantisasi lanjutan memerlukan kernel inferens khusus untuk prestasi optimum.

**Integrasi Perusahaan**: Endpoint API yang serasi dengan OpenAI, sokongan penggunaan Kubernetes, integrasi pemantauan dan pemerhatian, serta keupayaan penskalaan automatik menyediakan penyelesaian penggunaan bertaraf perusahaan.

### Penyelesaian Edge Microsoft

Microsoft menyediakan keupayaan penggunaan edge yang komprehensif untuk persekitaran perusahaan:

**Ciri Pengkomputeran Edge**: Reka bentuk seni bina offline-first dengan pengoptimuman sumber terhad, pengurusan daftar model tempatan, dan keupayaan penyegerakan edge-ke-awan memastikan penggunaan edge yang boleh dipercayai.

**Keselamatan dan Pematuhan**: Pemprosesan data tempatan untuk pemeliharaan privasi, kawalan keselamatan perusahaan, log audit dan pelaporan pematuhan, serta pengurusan akses berdasarkan peranan menyediakan keselamatan yang komprehensif untuk penggunaan edge.

## Amalan Terbaik untuk Pelaksanaan Kuantisasi Model

### Garis Panduan Pemilihan Tahap Kuantisasi

Apabila memilih tahap kuantisasi untuk penggunaan edge, pertimbangkan faktor berikut:

**Pertimbangan Bilangan Ketepatan**: Pilih ketepatan ultra-rendah seperti Q2_K untuk aplikasi mudah alih ekstrem, ketepatan rendah seperti Q4_K_M untuk senario prestasi seimbang, dan ketepatan sederhana seperti Q8_0 apabila mendekati keupayaan ketepatan penuh sambil mengekalkan kecekapan. Format eksperimen menawarkan pemampatan khusus untuk aplikasi penyelidikan tertentu.

**Penyelarasan Kes Penggunaan**: Padankan keupayaan kuantisasi dengan keperluan aplikasi tertentu, dengan mempertimbangkan faktor seperti pemeliharaan ketepatan, kelajuan inferens, kekangan memori, dan keperluan operasi offline.

### Pemilihan Strategi Pengoptimuman

**Pendekatan Kuantisasi**: Pilih tahap kuantisasi yang sesuai berdasarkan keperluan kualiti dan kekangan perkakasan. Pertimbangkan Q4_0 untuk pemampatan maksimum, Q5_1 untuk keseimbangan kualiti-pemampatan, dan Q8_0 untuk pemeliharaan kualiti hampir asal. Format eksperimen mewakili sempadan pemampatan ekstrem untuk aplikasi khusus.

**Pemilihan Kerangka**: Pilih kerangka pengoptimuman berdasarkan perkakasan sasaran dan keperluan penggunaan. Gunakan Llama.cpp untuk penggunaan yang dioptimumkan CPU, Microsoft Olive untuk aliran kerja pengoptimuman yang komprehensif, dan Apple MLX untuk peranti Apple Silicon.

## Penukaran Format Praktikal dan Kes Penggunaan

### Senario Penggunaan Dunia Sebenar

**Aplikasi Mudah Alih**: Format Q4_K cemerlang dalam aplikasi telefon pintar dengan jejak memori yang minimum, manakala Q8_0 menyediakan prestasi seimbang untuk aplikasi berasaskan tablet. Format Q5_K menawarkan kualiti unggul untuk aplikasi produktiviti mudah alih.

**Pengkomputeran Desktop dan Edge**: Q5_K memberikan prestasi optimum untuk aplikasi desktop, Q8_0 menyediakan inferens berkualiti tinggi untuk persekitaran stesen kerja, dan Q4_K membolehkan pemprosesan cekap pada peranti edge.

**Penyelidikan dan Eksperimen**: Format kuantisasi lanjutan membolehkan penerokaan inferens ketepatan ultra-rendah untuk penyelidikan akademik dan aplikasi bukti konsep yang memerlukan kekangan sumber yang ekstrem.

### Penanda Aras Prestasi dan Perbandingan

**Kelajuan Inferens**: Q4_K mencapai masa inferens terpantas pada CPU mudah alih, Q5_K menyediakan nisbah kelajuan-kualiti yang seimbang untuk aplikasi umum, Q8_0 menawarkan kualiti unggul untuk tugas kompleks, dan format eksperimen memberikan throughput maksimum teori dengan perkakasan khusus.

**Keperluan Memori**: Tahap kuantisasi berkisar dari Q2_K (di bawah 500MB untuk model kecil) hingga Q8_0 (kira-kira 50% daripada saiz asal), dengan konfigurasi eksperimen mencapai nisbah pemampatan maksimum.

## Cabaran dan Pertimbangan

### Pertukaran Prestasi

Penggunaan kuantisasi melibatkan pertimbangan teliti terhadap pertukaran antara saiz model, kelajuan inferens, dan kualiti output. Walaupun Q4_K menawarkan kelajuan dan kecekapan yang luar biasa, Q8_0 menyediakan kualiti unggul dengan kos keperluan sumber yang meningkat. Q5_K memberikan keseimbangan yang sesuai untuk kebanyakan aplikasi umum.

### Keserasian Perkakasan

Peranti edge yang berbeza mempunyai keupayaan dan kekangan yang berbeza. Q4_K berjalan dengan cekap pada pemproses asas, Q5_K memerlukan sumber pengiraan sederhana, dan Q8_0 mendapat manfaat daripada perkakasan kelas atas. Format eksperimen memerlukan pelaksanaan perkakasan atau perisian khusus untuk operasi optimum.

### Keselamatan dan Privasi

Walaupun model kuantisasi membolehkan pemprosesan tempatan untuk meningkatkan privasi, langkah keselamatan yang betul mesti dilaksanakan untuk melindungi model dan data dalam persekitaran edge. Ini amat penting apabila menggunakan format ketepatan tinggi dalam persekitaran perusahaan atau format mampat dalam aplikasi yang mengendalikan data sensitif.

## Trend Masa Depan dalam Kuantisasi Model

Landskap kuantisasi terus berkembang dengan kemajuan dalam teknik pemampatan, kaedah pengoptimuman, dan strategi penggunaan. Perkembangan masa depan termasuk algoritma kuantisasi yang lebih cekap, kaedah pemampatan yang lebih baik, dan integrasi yang lebih baik dengan pecutan perkakasan edge.

Memahami trend ini dan mengekalkan kesedaran tentang teknologi yang muncul akan menjadi penting untuk kekal terkini dengan amalan terbaik pembangunan dan penggunaan kuantisasi.

## Sumber Tambahan

- [Hugging Face GGUF Documentation](https://huggingface.co/docs/hub/en/gguf)
- [ONNX Model Optimization](https://onnxruntime.ai/docs/performance/model-optimizations/)
- [llama.cpp Documentation](https://github.com/ggml-org/llama.cpp)
- [Microsoft Olive Framework](https://github.com/microsoft/Olive)
- [Apple MLX Documentation](https://github.com/ml-explore/mlx)

## ➡️ Apa yang seterusnya

- [02: Panduan Pelaksanaan Llama.cpp](./02.Llamacpp.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat yang kritikal, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.