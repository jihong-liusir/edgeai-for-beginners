<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-22T22:38:20+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "ms"
}
-->
# Sesi 1: Memulakan dengan Foundry Local

## Gambaran Keseluruhan

Microsoft Foundry Local membawa keupayaan Azure AI Foundry terus ke persekitaran pembangunan Windows 11 anda, membolehkan pembangunan AI yang melindungi privasi, berlatensi rendah dengan alat bertaraf perusahaan. Sesi ini merangkumi pemasangan lengkap, konfigurasi, dan penerapan model popular seperti phi, qwen, deepseek, dan GPT-OSS-20B secara praktikal.

## Objektif Pembelajaran

Pada akhir sesi ini, anda akan:
- Memasang dan mengkonfigurasi Foundry Local pada Windows 11
- Menguasai arahan CLI dan pilihan konfigurasi
- Memahami strategi caching model untuk prestasi optimum
- Berjaya menjalankan model phi, qwen, deepseek, dan GPT-OSS-20B
- Membuat aplikasi AI pertama anda menggunakan Foundry Local

## Prasyarat

### Keperluan Sistem
- **Windows 11**: Versi 22H2 atau lebih baru
- **RAM**: Minimum 16GB, disyorkan 32GB
- **Storan**: Ruang kosong 50GB untuk model dan cache
- **Perkakasan**: Peranti dengan NPU atau GPU disyorkan (PC Copilot+ atau GPU NVIDIA)
- **Rangkaian**: Internet berkelajuan tinggi untuk muat turun model

### Persekitaran Pembangunan
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## Bahagian 1: Pemasangan dan Persediaan

### Langkah 1: Pasang Foundry Local

Pasang Foundry Local menggunakan Winget atau muat turun pemasang dari GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Langkah 2: Sahkan Pemasangan

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Bahagian 2: Memahami CLI

### Struktur Arahan Teras

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Bahagian 3: Pengurusan dan Caching Model

Foundry Local melaksanakan caching model pintar untuk mengoptimumkan prestasi dan storan:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Bahagian 4: Penerapan Model Secara Praktikal

### Menjalankan Model Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Bekerja dengan Model Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### Menjalankan Model DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### Menjalankan GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Bahagian 5: Membuat Aplikasi Pertama Anda

### Antara Muka Chat Mudah (API Serasi OpenAI)

Buat aplikasi chat asas menggunakan API REST Foundry Local yang serasi dengan OpenAI. Pastikan model sedang berjalan di terminal lain.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Jalankan Aplikasi Chat

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## Bahagian 6: Penyelesaian Masalah dan Amalan Terbaik

### Isu Biasa dan Penyelesaian

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Memantau Sumber Sistem (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Amalan Terbaik

- Utamakan arahan `foundry model ...`, `foundry cache ...`, dan `foundry service ...` (rujuk CLI)
- Kemas kini secara berkala untuk akses kepada model dan pembaikan baru
- Mulakan dengan model yang lebih kecil (Phi mini, Qwen 7B) dan tingkatkan secara beransur
- Pantau CPU/GPU/memori semasa menyesuaikan prompt dan tetapan

## Bahagian 7: Latihan Praktikal

### Latihan 1: Jalankan Multi-Model dengan Cepat

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Latihan 2: Penanda Aras Latensi Asas

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Rujukan

- Memulakan dengan Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- Rujukan CLI dan gambaran keseluruhan arahan: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Kompilasi model Hugging Face untuk Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

