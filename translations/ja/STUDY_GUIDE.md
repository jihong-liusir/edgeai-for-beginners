<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T18:59:22+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ja"
}
-->
# EdgeAI初心者向け：学習パスと学習スケジュール

### 集中学習パス（1週間）

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 0 | モジュール0: EdgeAIの概要 | 1-2時間 |
| Day 1 | モジュール1: EdgeAIの基礎 | 3時間 |
| Day 2 | モジュール2: SLMの基礎 | 3時間 |
| Day 3 | モジュール3: SLMの展開 | 2時間 |
| Day 4-5 | モジュール4: モデル最適化（6つのフレームワーク） | 4時間 |
| Day 6 | モジュール5: SLMOps | 3時間 |
| Day 7 | モジュール6-7: AIエージェントと開発ツール | 4時間 |
| Day 8 | モジュール8: Foundry Local Toolkit（最新の実装） | 1時間 |

### 集中学習パス（2週間）

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 1-2 | モジュール1: EdgeAIの基礎 | 3時間 |
| Day 3-4 | モジュール2: SLMの基礎 | 3時間 |
| Day 5-6 | モジュール3: SLMの展開 | 2時間 |
| Day 7-8 | モジュール4: モデル最適化 | 4時間 |
| Day 9-10 | モジュール5: SLMOps | 3時間 |
| Day 11-12 | モジュール6: AIエージェント | 2時間 |
| Day 13-14 | モジュール7: 開発ツール | 3時間 |

### パートタイム学習（4週間）

| 週 | 内容 | 推定時間 |
|------|-------|------------------|
| Week 1 | モジュール1-2: 基礎とSLMの基礎 | 6時間 |
| Week 2 | モジュール3-4: 展開と最適化 | 6時間 |
| Week 3 | モジュール5-6: SLMOpsとAIエージェント | 5時間 |
| Week 4 | モジュール7: 開発ツールと統合 | 3時間 |

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 0 | モジュール0: EdgeAIの概要 | 1-2時間 |
| Day 1-2 | モジュール1: EdgeAIの基礎 | 3時間 |
| Day 3-4 | モジュール2: SLMの基礎 | 3時間 |
| Day 5-6 | モジュール3: SLMの展開 | 2時間 |
| Day 7-8 | モジュール4: モデル最適化 | 4時間 |
| Day 9-10 | モジュール5: SLMOps | 3時間 |
| Day 11-12 | モジュール6: SLMエージェントシステム | 2時間 |
| Day 13-14 | モジュール7: EdgeAI実装サンプル | 2時間 |

| モジュール | 完了日 | 費やした時間 | 主な学び |
|--------|----------------|-------------|--------------|
| モジュール0: EdgeAIの概要 | | | |
| モジュール1: EdgeAIの基礎 | | | |
| モジュール2: SLMの基礎 | | | |
| モジュール3: SLMの展開 | | | |
| モジュール4: モデル最適化（6つのフレームワーク） | | | |
| モジュール5: SLMOps | | | |
| モジュール6: SLMエージェントシステム | | | |
| モジュール7: EdgeAI実装サンプル | | | |
| 実践演習 | | | |
| ミニプロジェクト | | | |

### パートタイム学習（4週間）

| 週 | 内容 | 推定時間 |
|------|-------|------------------|
| Week 1 | モジュール1-2: 基礎とSLMの基礎 | 6時間 |
| Week 2 | モジュール3-4: 展開と最適化 | 6時間 |
| Week 3 | モジュール5-6: SLMOpsとAIエージェント | 5時間 |
| Week 4 | モジュール7: 開発ツールと統合 | 3時間 |

## 概要

EdgeAI初心者向け学習ガイドへようこそ！このドキュメントは、コース教材を効率的に活用し、学習体験を最大化するための手助けをするために作成されています。構造化された学習パス、推奨される学習スケジュール、主要な概念の要約、そしてEdgeAI技術の理解を深めるための補足リソースを提供します。

このコースは、EdgeAIに関する基本的な知識を効率的に学べる20時間の凝縮された内容で、忙しいプロフェッショナルや学生がこの新興分野で実践的なスキルを迅速に習得するのに最適です。

## コース概要

このコースは、以下の8つの包括的なモジュールで構成されています：

0. **EdgeAIの概要** - 業界での応用例と学習目標を設定する基礎
1. **EdgeAIの基礎と変革** - コア概念と技術的な変化を理解する
2. **小型言語モデル（SLM）の基礎** - 様々なSLMファミリーとそのアーキテクチャを探る
3. **小型言語モデルの展開** - 実践的な展開戦略を実装する
4. **モデル形式変換と量子化** - OpenVINOを含む6つのフレームワークでの高度な最適化
5. **SLMOps - 小型言語モデルの運用管理** - 生産ライフサイクル管理と展開
6. **SLMエージェントシステム** - AIエージェント、関数呼び出し、モデルコンテキストプロトコル
7. **EdgeAI実装サンプル** - AIツールキット、Windows開発、プラットフォーム固有の実装
8. **Microsoft Foundry Local – 完全な開発ツールキット** - ローカルファースト開発とハイブリッドAzure統合（モジュール08）

## 学習ガイドの使い方

- **段階的学習**: モジュールを順番に進めることで、最も一貫性のある学習体験を得られます
- **知識チェックポイント**: 各セクション後の自己評価質問を活用してください
- **実践練習**: 理論的な概念を強化するために提案された演習を完了してください
- **補足リソース**: 興味のあるトピックについて追加資料を探索してください

## 学習スケジュールの推奨

### 集中学習パス（1週間）

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 0 | モジュール0: EdgeAIの概要 | 1-2時間 |
| Day 1-2 | モジュール1: EdgeAIの基礎 | 6時間 |
| Day 3-4 | モジュール2: SLMの基礎 | 8時間 |
| Day 5 | モジュール3: SLMの展開 | 3時間 |
| Day 6 | モジュール8: Foundry Local Toolkit | 3時間 |

### パートタイム学習（3週間）

| 週 | 内容 | 推定時間 |
|------|-------|------------------|
| Week 1 | モジュール0: 概要 + モジュール1: EdgeAIの基礎 | 7-9時間 |
| Week 2 | モジュール2: SLMの基礎 | 7-8時間 |
| Week 3 | モジュール3: SLMの展開（3時間） + モジュール8: Foundry Local Toolkit（2-3時間） | 5-6時間 |

## モジュール0: EdgeAIの概要

### 主な学習目標

- EdgeAIとは何か、そしてそれが今日の技術分野で重要である理由を理解する
- EdgeAIによって変革された主要な業界とその具体的なユースケースを特定する
- 小型言語モデル（SLM）がエッジ展開において持つ利点を理解する
- コース全体の学習期待値と成果を明確にする
- EdgeAI分野でのキャリア機会と必要なスキルを認識する

### 学習の重点領域

#### セクション1: EdgeAIのパラダイムと定義
- **優先概念**: 
  - EdgeAIと従来のクラウドAI処理の違い
  - ハードウェア、モデル最適化、ビジネスニーズの融合
  - リアルタイム、プライバシー保護、コスト効率の良いAI展開

#### セクション2: 業界応用例
- **優先概念**: 
  - 製造業 & Industry 4.0: 予測保守と品質管理
  - 医療: 診断画像と患者モニタリング
  - 自律システム: 自動運転車と輸送
  - スマートシティ: 交通管理と公共安全
  - 消費者技術: スマートフォン、ウェアラブル、スマートホーム

#### セクション3: 小型言語モデルの基礎
- **優先概念**: 
  - SLMの特性と性能比較
  - パラメータ効率と能力のトレードオフ
  - エッジ展開の制約と最適化戦略

#### セクション4: 学習フレームワークとキャリアパス
- **優先概念**: 
  - コース構造と段階的習得アプローチ
  - 技術スキルと実践的な実装目標
  - キャリア向上の機会と業界応用例

### 自己評価質問

1. EdgeAIを可能にした3つの主要な技術トレンドは何ですか？
2. EdgeAIとクラウドベースAIの利点と課題を比較してください。
3. EdgeAIが重要なビジネス価値を提供する3つの業界を挙げ、それぞれの理由を説明してください。
4. 小型言語モデルが現実世界でのEdgeAI展開を可能にする方法を説明してください。
5. このコースを通じて習得する主要な技術スキルは何ですか？
6. このコースで使用される4段階の学習アプローチを説明してください。

### 実践演習

1. **業界調査**: 1つの業界応用例を選び、実際のEdgeAI実装を調査する（30分）
2. **モデル探索**: Hugging Faceで利用可能な小型言語モデルを閲覧し、パラメータ数と能力を比較する（30分）
3. **学習計画**: コース全体の構造を確認し、個人の学習スケジュールを作成する（15分）

### 補足資料

- [EdgeAI市場概要 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [小型言語モデル概要 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Edge Computing Foundation](https://www.edgecomputing.org/)

## モジュール1: EdgeAIの基礎と変革

### 主な学習目標

- クラウドベースAIとエッジベースAIの違いを理解する
- リソース制約環境向けの主要な最適化技術を習得する
- EdgeAI技術の実際の応用例を分析する
- EdgeAIプロジェクトの開発環境を設定する

### 学習の重点領域

#### セクション1: EdgeAIの基礎
- **優先概念**: 
  - エッジとクラウドコンピューティングのパラダイム
  - モデル量子化技術
  - ハードウェアアクセラレーションオプション（NPU、GPU、CPU）
  - プライバシーとセキュリティの利点

- **補足資料**:
  - [TensorFlow Lite ドキュメント](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse ドキュメント](https://docs.edgeimpulse.com)

#### セクション2: 実際のケーススタディ
- **優先概念**: 
  - Microsoft Phi & Muモデルエコシステム
  - 業界での実践的な実装例
  - 展開の考慮事項

#### セクション3: 実践的な実装ガイド
- **優先概念**: 
  - 開発環境の設定
  - 量子化と最適化ツール
  - EdgeAI実装の評価方法

#### セクション4: エッジ展開ハードウェア
- **優先概念**: 
  - ハードウェアプラットフォームの比較
  - 特定のハードウェア向けの最適化戦略
  - 展開の考慮事項

### 自己評価質問

1. クラウドベースAIとエッジベースAIの実装を比較してください。
2. エッジ展開向けモデルを最適化するための3つの主要技術を説明してください。
3. エッジでAIモデルを実行する主な利点は何ですか？
4. モデルを量子化するプロセスとその性能への影響を説明してください。
5. 異なるハードウェアアクセラレーター（NPU、GPU、CPU）がEdgeAI展開に与える影響を説明してください。

### 実践演習

1. **簡易環境設定**: 必要なパッケージを使用して最小限の開発環境を設定する（30分）
2. **モデル探索**: 事前学習済みの小型言語モデルをダウンロードして調査する（1時間）
3. **基本的な量子化**: 小型モデルで簡単な量子化を試す（1時間）

## モジュール2: 小型言語モデルの基礎

### 主な学習目標

- 様々なSLMファミリーのアーキテクチャ原則を理解する
- 異なるパラメータスケールでのモデル能力を比較する
- 効率性、能力、展開要件に基づいてモデルを評価する
- 各モデルファミリーに適したユースケースを認識する

### 学習の重点領域

#### セクション1: Microsoft Phiモデルファミリー
- **優先概念**: 
  - 設計哲学の進化
  - 効率性重視のアーキテクチャ
  - 特化した能力

#### セクション2: Qwenファミリー
- **優先概念**: 
  - オープンソースの貢献
  - スケーラブルな展開オプション
  - 高度な推論アーキテクチャ

#### セクション3: Gemmaファミリー
- **優先概念**: 
  - 研究主導の革新
  - マルチモーダル能力
  - モバイル最適化

#### セクション4: BitNETファミリー
- **優先概念**: 
  - 1ビット量子化技術
  - 推論最適化フレームワーク
  - 持続可能性の考慮

#### セクション5: Microsoft Muモデル
- **優先概念**: 
  - デバイス重視のアーキテクチャ
  - Windowsとのシステム統合
  - プライバシー保護の運用

#### セクション6: Phi-Silica
- **優先概念**: 
  - NPU最適化アーキテクチャ
  - 性能指標
  - 開発者統合

### 自己評価質問

1. PhiモデルファミリーとQwenモデルファミリーのアーキテクチャアプローチを比較してください。
2. BitNETの量子化技術が従来の量子化とどのように異なるか説明してください。
3. Windows統合におけるMuモデルのユニークな利点は何ですか？  
4. Phi-SilicaがNPUハードウェアをどのように活用してパフォーマンスを最適化しているか説明してください。  
5. 接続性が制限されたモバイルアプリケーションに最も適したモデルファミリーはどれで、なぜですか？  

### 実践演習

1. **モデル比較**: 2つの異なるSLMモデルの簡易ベンチマーク（1時間）  
2. **簡単なテキスト生成**: 小規模モデルを使用した基本的なテキスト生成の実装（1時間）  
3. **高速最適化**: 推論速度を向上させるための最適化技術を1つ適用（1時間）  

## モジュール3: 小規模言語モデルのデプロイ

### 主な学習目標

- デプロイ制約に基づいた適切なモデルの選択  
- さまざまなデプロイシナリオにおける最適化技術の習得  
- ローカルおよびクラウド環境でのSLMの実装  
- EdgeAIアプリケーション向けの本番環境対応の構成設計  

### 学習の重点分野

#### セクション1: SLMの高度な学習
- **優先概念**:  
  - パラメータ分類フレームワーク  
  - 高度な最適化技術  
  - モデル取得戦略  

#### セクション2: ローカル環境でのデプロイ
- **優先概念**:  
  - Ollamaプラットフォームでのデプロイ  
  - Microsoft Foundryのローカルソリューション  
  - フレームワークの比較分析  

#### セクション3: コンテナ化されたクラウドデプロイ
- **優先概念**:  
  - vLLMの高性能推論  
  - コンテナオーケストレーション  
  - ONNX Runtimeの実装  

### 自己評価の質問

1. ローカルデプロイとクラウドデプロイを選択する際に考慮すべき要因は何ですか？  
2. デプロイオプションとしてのOllamaとMicrosoft Foundry Localを比較してください。  
3. SLMデプロイにおけるコンテナ化の利点を説明してください。  
4. エッジにデプロイされたSLMの主要なパフォーマンス指標は何ですか？  
5. モデル選択から本番実装までの完全なデプロイワークフローを説明してください。  

### 実践演習

1. **基本的なローカルデプロイ**: Ollamaを使用してシンプルなSLMをデプロイ（1時間）  
2. **パフォーマンスチェック**: デプロイしたモデルの簡易ベンチマークを実行（30分）  
3. **簡単な統合**: デプロイしたモデルを使用する最小限のアプリケーションを作成（1時間）  

## モジュール4: モデル形式の変換と量子化

### 主な学習目標

- 1ビットから8ビット精度までの高度な量子化技術を習得  
- 形式変換戦略（GGUF、ONNX）を理解  
- 6つのフレームワーク（Llama.cpp、Olive、OpenVINO、MLX、ワークフロー合成）を通じた最適化の実装  
- Intel、Apple、クロスプラットフォームハードウェア向けの本番エッジ環境で最適化されたモデルをデプロイ  

### 学習の重点分野

#### セクション1: 量子化の基礎
- **優先概念**:  
  - 精度分類フレームワーク  
  - パフォーマンスと精度のトレードオフ  
  - メモリフットプリントの最適化  

#### セクション2: Llama.cppの実装
- **優先概念**:  
  - クロスプラットフォームデプロイ  
  - GGUF形式の最適化  
  - ハードウェアアクセラレーション技術  

#### セクション3: Microsoft Olive Suite
- **優先概念**:  
  - ハードウェア対応の最適化  
  - エンタープライズ向けデプロイ  
  - 自動化された最適化ワークフロー  

#### セクション4: OpenVINO Toolkit
- **優先概念**:  
  - Intelハードウェアの最適化  
  - ニューラルネットワーク圧縮フレームワーク（NNCF）  
  - クロスプラットフォーム推論デプロイ  
  - OpenVINO GenAIによるLLMデプロイ  

#### セクション5: Apple MLXフレームワーク
- **優先概念**:  
  - Apple Siliconの最適化  
  - 統合メモリアーキテクチャ  
  - LoRAファインチューニング機能  

#### セクション6: Edge AI開発ワークフローの統合
- **優先概念**:  
  - 統一されたワークフローアーキテクチャ  
  - フレームワーク選択の意思決定ツリー  
  - 本番対応の検証  
  - 将来を見据えた戦略  

### 自己評価の質問

1. 異なる精度レベル（1ビットから8ビット）の量子化戦略を比較してください。  
2. エッジデプロイにおけるGGUF形式の利点を説明してください。  
3. Microsoft Oliveのハードウェア対応最適化がデプロイ効率をどのように向上させるか説明してください。  
4. OpenVINOのNNCFがモデル圧縮において持つ主な利点は何ですか？  
5. Apple MLXが統合メモリアーキテクチャをどのように活用して最適化を行うか説明してください。  
6. ワークフローの統合が最適な最適化フレームワークの選択にどのように役立つか説明してください。  

### 実践演習

1. **モデル量子化**: モデルに異なる量子化レベルを適用し、結果を比較（1時間）  
2. **OpenVINO最適化**: NNCFを使用してIntelハードウェア向けにモデルを圧縮（1時間）  
3. **フレームワーク比較**: 同じモデルを3つの異なる最適化フレームワークでテスト（1時間）  
4. **パフォーマンスベンチマーク**: 推論速度とメモリ使用量に対する最適化の影響を測定（1時間）  

## モジュール5: SLMOps - 小規模言語モデル運用

### 主な学習目標

- SLMOpsライフサイクル管理の原則を理解  
- エッジデプロイのための蒸留とファインチューニング技術を習得  
- モニタリングを伴う本番デプロイ戦略を実装  
- エンタープライズ向けのSLM運用および保守ワークフローを構築  

### 学習の重点分野

#### セクション1: SLMOpsの概要
- **優先概念**:  
  - AI運用におけるSLMOpsのパラダイムシフト  
  - コスト効率とプライバシー重視のアーキテクチャ  
  - 戦略的ビジネスインパクトと競争優位性  

#### セクション2: モデル蒸留
- **優先概念**:  
  - 知識転移技術  
  - 2段階の蒸留プロセスの実装  
  - Azure ML蒸留ワークフロー  

#### セクション3: ファインチューニング戦略
- **優先概念**:  
  - パラメータ効率の良いファインチューニング（PEFT）  
  - LoRAおよびQLoRAの高度な手法  
  - マルチアダプタートレーニングとハイパーパラメータ最適化  

#### セクション4: 本番デプロイ
- **優先概念**:  
  - 本番向けのモデル変換と量子化  
  - Foundry Localデプロイ構成  
  - パフォーマンスベンチマークと品質検証  

### 自己評価の質問

1. SLMOpsは従来のMLOpsとどのように異なりますか？  
2. エッジデプロイにおけるモデル蒸留の利点を説明してください。  
3. リソースが制約された環境でSLMをファインチューニングする際の主な考慮事項は何ですか？  
4. エッジAIアプリケーションの完全な本番デプロイパイプラインを説明してください。  

### 実践演習

1. **基本的な蒸留**: 大規模な教師モデルから小規模モデルを作成（1時間）  
2. **ファインチューニング実験**: 特定のドメイン向けにモデルをファインチューニング（1時間）  
3. **デプロイパイプライン**: モデルデプロイのための基本的なCI/CDパイプラインを設定（1時間）  

## モジュール6: SLMエージェンティックシステム - AIエージェントと関数呼び出し

### 主な学習目標

- 小規模言語モデルを使用してエッジ環境向けのインテリジェントAIエージェントを構築  
- システマチックなワークフローで関数呼び出し機能を実装  
- 標準化されたツール相互作用のためのModel Context Protocol（MCP）統合を習得  
- 最小限の人間の介入で高度なエージェンティックシステムを作成  

### 学習の重点分野

#### セクション1: AIエージェントとSLMの基礎
- **優先概念**:  
  - エージェント分類フレームワーク（反射型、モデルベース型、目標ベース型、学習エージェント）  
  - SLMとLLMのトレードオフ分析  
  - エッジ特有のエージェント設計パターン  
  - エージェントのリソース最適化  

#### セクション2: 小規模言語モデルにおける関数呼び出し
- **優先概念**:  
  - システマチックなワークフローの実装（意図検出、JSON出力、外部実行）  
  - プラットフォーム固有の実装（Phi-4-mini、選択されたQwenモデル、Microsoft Foundry Local）  
  - 高度な例（マルチエージェントの協調、動的ツール選択）  
  - 本番環境の考慮事項（レート制限、監査ログ、セキュリティ対策）  

#### セクション3: Model Context Protocol（MCP）の統合
- **優先概念**:  
  - プロトコルアーキテクチャとレイヤードシステム設計  
  - マルチバックエンドサポート（開発用Ollama、本番用vLLM）  
  - 接続プロトコル（STDIOおよびSSEモード）  
  - 実世界のアプリケーション（ウェブ自動化、データ処理、API統合）  

### 自己評価の質問

1. エッジAIエージェントの主要なアーキテクチャ上の考慮事項は何ですか？  
2. 関数呼び出しはエージェントの機能をどのように強化しますか？  
3. Model Context Protocolがエージェントの通信において果たす役割を説明してください。  

### 実践演習

1. **シンプルなエージェント**: 関数呼び出しを備えた基本的なAIエージェントを構築（1時間）  
2. **MCP統合**: エージェントアプリケーションにMCPを実装（30分）  

## ワークショップ: 実践的な学習パス

### 主な学習目標

- Foundry Local SDKとベストプラクティスを使用して本番対応のAIアプリケーションを構築  
- 包括的なエラーハンドリングとユーザーフィードバックパターンを実装  
- 品質評価とパフォーマンスモニタリングを備えたRAGパイプラインを作成  
- コーディネーターパターンを使用してマルチエージェントシステムを開発  
- タスクベースのモデル選択のためのインテリジェントモデルルーティングを習得  
- プライバシー保護アーキテクチャを備えたローカルファーストAIソリューションをデプロイ  

### 学習の重点分野

#### セッション01: Foundry Localの使い方
- **優先概念**:  
  - FoundryLocalManager SDKの統合と自動サービス検出  
  - 基本およびストリーミングチャットの実装  
  - エラーハンドリングパターンとユーザーフィードバック  
  - 環境ベースの構成  

#### セッション02: RAGを使用したAIソリューションの構築
- **優先概念**:  
  - sentence-transformersを使用したインメモリベクトル埋め込み  
  - RAGパイプラインの実装（検索→生成）  
  - RAGASメトリクスを使用した品質評価  
  - オプション依存関係のインポート安全性  

#### セッション03: オープンソースモデル
- **優先概念**:  
  - マルチモデルベンチマーク戦略  
  - レイテンシーとスループットの測定  
  - 優雅な劣化とエラー回復  
  - モデルファミリー間のパフォーマンス比較  

#### セッション04: 最先端モデル
- **優先概念**:  
  - SLMとLLMの比較方法論  
  - 型ヒントと包括的な出力フォーマット  
  - モデルごとのエラーハンドリング  
  - 分析のための構造化された結果  

#### セッション05: AI駆動エージェント
- **優先概念**:  
  - コーディネーターパターンを使用したマルチエージェントのオーケストレーション  
  - エージェントのメモリ管理と状態追跡  
  - パイプラインエラーハンドリングとステージログ  
  - パフォーマンスモニタリングと統計  

#### セッション06: ツールとしてのモデル
- **優先概念**:  
  - 意図検出とパターンマッチング  
  - キーワードベースのモデルルーティングアルゴリズム  
  - マルチステップパイプライン（計画→実行→改良）  
  - 包括的な関数ドキュメント  

### 自己評価の質問

1. FoundryLocalManagerは手動のREST呼び出しと比較して、どのようにサービス管理を簡素化しますか？  
2. sentence-transformersのようなオプション依存関係に対するインポートガードの重要性を説明してください。  
3. マルチモデルベンチマークで優雅な劣化を確保する戦略は何ですか？  
4. コーディネーターパターンはどのように複数の専門エージェントをオーケストレーションしますか？  
5. インテリジェントモデルルーターの構成要素を説明してください。  
6. 本番対応のエラーハンドリングの主要な要素は何ですか？  

### 実践演習

1. **チャットアプリケーション**: エラーハンドリングを備えたストリーミングチャットを実装（45分）  
2. **RAGパイプライン**: 品質評価を備えた最小限のRAGを構築（1時間）  
3. **モデルベンチマーク**: 3つ以上のモデルをパフォーマンスで比較（1時間）  
4. **マルチエージェントシステム**: 2つの専門エージェントを持つコーディネータを作成（1.5時間）  
5. **インテリジェントルーター**: タスクベースのモデル選択を構築（1時間）  
6. **本番デプロイ**: モニタリングと包括的なエラーハンドリングを追加（
4. 現代のエッジAIアプリケーションにおけるNPU最適化の役割を説明してください。
5. Phi Silica APIは、NPUハードウェアをどのように活用してパフォーマンスを最適化していますか？
6. プライバシーに敏感なアプリケーションにおけるローカル展開とクラウド展開の利点を比較してください。

### 実践演習

1. **AIツールキットのセットアップ**: AIツールキットを構成し、モデルを最適化する (1時間)
2. **Windows AI Foundry**: Phi Silica APIを使用してシンプルなWindows AIアプリケーションを構築する (1時間)
3. **クロスプラットフォーム展開**: 同じモデルを異なる2つのプラットフォームに展開する (1時間)
4. **NPU最適化**: Windows AI Foundryツールを使用してNPUのパフォーマンスをテストする (30分)

## モジュール8: Microsoft Foundry Local – 完全な開発者ツールキット（現代化版）

### 主な学習目標

- Foundry Localを最新のSDK統合でインストールおよび構成する
- コーディネーターパターンを使用して高度なマルチエージェントシステムを実装する
- 自動タスクベース選択を備えたインテリジェントモデルルーターを構築する
- 包括的なモニタリングを備えた本番対応のAIソリューションを展開する
- Azure AI Foundryと統合してハイブリッド展開シナリオを実現する
- FoundryLocalManagerとOpenAIクライアントを使用した最新のSDKパターンを習得する

### 学習重点領域

#### セクション1: 最新のインストールと構成
- **優先概念**: 
  - FoundryLocalManager SDK統合
  - 自動サービス検出とヘルスモニタリング
  - 環境ベースの構成パターン
  - 本番展開の考慮事項

#### セクション2: 高度なマルチエージェントシステム
- **優先概念**: 
  - 専門エージェントを使用したコーディネーターパターン
  - 検索、推論、実行エージェントの専門化
  - 改善のためのフィードバックループメカニズム
  - パフォーマンスモニタリングと統計追跡

#### セクション3: インテリジェントモデルルーティング
- **優先概念**: 
  - キーワードベースのモデル選択アルゴリズム
  - 複数モデルのサポート（一般、推論、コード、クリエイティブ）
  - 柔軟性を持たせるための環境変数構成
  - サービスのヘルスチェックとエラーハンドリング

#### セクション4: 本番対応の実装
- **優先概念**: 
  - 包括的なエラーハンドリングとフォールバックメカニズム
  - リクエストモニタリングとパフォーマンストラッキング
  - ベンチマーク付きのインタラクティブなJupyterノートブック例
  - 既存のアプリケーションとの統合パターン

### 自己評価質問

1. 最新のFoundryLocalManagerアプローチは手動のRESTコールとどう異なりますか？
2. コーディネーターパターンとは何か、専門エージェントをどのように調整するか説明してください。
3. インテリジェントルーターはクエリ内容に基づいて適切なモデルをどのように選択しますか？
4. 本番対応のAIエージェントシステムの主要な構成要素は何ですか？
5. Foundry Localサービスの包括的なヘルスモニタリングをどのように実装しますか？
6. 現代化されたアプローチと従来の実装パターンの利点を比較してください。

### 実践演習

1. **最新SDKのセットアップ**: FoundryLocalManagerを自動サービス検出で構成する (30分)
2. **マルチエージェントシステム**: 専門エージェントを備えた高度なコーディネーターを実行する (30分)
3. **インテリジェントルーティング**: 異なるクエリタイプでモデルルーターをテストする (30分)
4. **インタラクティブな探索**: Jupyterノートブックを使用して高度な機能を探索する (45分)
5. **本番展開**: モニタリングとエラーハンドリングパターンを実装する (30分)
6. **ハイブリッド統合**: Azure AI Foundryのフォールバックシナリオを構成する (30分)

## 時間配分ガイド

30時間のコースタイムライン（ワークショップを含む）を最大限に活用するための推奨時間配分は以下の通りです：

| アクティビティ | 時間配分 | 説明 |
|---------------|----------|------|
| コア資料の読解 | 12時間 | 各モジュールの重要な概念に集中 |
| 実践演習 | 10時間 | 主要な技術の実践的な実装（ワークショップを含む） |
| 自己評価 | 3時間 | 質問と振り返りを通じて理解度をテスト |
| ミニプロジェクト | 5時間 | 小規模な実践的な実装に知識を応用 |

### 時間制約別の重点領域

**10時間しかない場合**:
- モジュール0（イントロダクション）とモジュール1、2、3（コアEdgeAI概念）を完了
- 各モジュールで少なくとも1つの実践演習を行う
- 実装の詳細よりもコア概念の理解に集中

**20時間を確保できる場合**:
- イントロダクションを含む全8モジュールを完了
- 各モジュールの主要な実践演習を実施
- モジュール7のミニプロジェクトを1つ完了
- 補足リソースを少なくとも2～3つ探索

**20時間以上確保できる場合**:
- イントロダクションを含む全モジュールを詳細な演習付きで完了
- 複数のミニプロジェクトを構築
- モジュール4で高度な最適化技術を探索
- モジュール5から本番展開を実装

## 必須リソース

限られた学習時間で最大の価値を提供する厳選されたリソース：

### 必読ドキュメント
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - 最も効率的なモデル最適化ツール
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - SLMをローカルに迅速に展開する方法
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - エッジ最適化モデルのリファレンス
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intelの包括的な最適化ツールキット
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - 統合されたEdgeAI開発環境
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows特化のEdgeAI開発プラットフォーム

### 時間節約ツール
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - モデルの迅速なアクセスと展開
- [Gradio](https://www.gradio.app/docs/interface) - AIデモ用の迅速なUI開発
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡易化されたモデル最適化
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 効率的なCPU推論
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - ニューラルネットワーク圧縮フレームワーク
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大規模言語モデル展開ツールキット

## 進捗追跡テンプレート

20時間のコースを通じて学習進捗を追跡するための簡易テンプレート：

| モジュール | 完了日 | 費やした時間 | 主な学び |
|-----------|--------|-------------|----------|
| モジュール0: EdgeAIのイントロダクション | | | |
| モジュール1: EdgeAIの基礎 | | | |
| モジュール2: SLMの基礎 | | | |
| モジュール3: SLMの展開 | | | |
| モジュール4: モデル最適化 | | | |
| モジュール5: SLMOps | | | |
| モジュール6: AIエージェント | | | |
| モジュール7: 開発ツール | | | |
| ワークショップ: 実践学習 | | | |
| モジュール8: Foundry Localツールキット | | | |
| 実践演習 | | | |
| ミニプロジェクト | | | |

## ミニプロジェクトのアイデア

EdgeAIの概念を練習するために以下のプロジェクトを検討してください（各プロジェクトは2～4時間で完了可能）：

### 初級プロジェクト（各2～3時間）
1. **エッジテキストアシスタント**: 小型言語モデルを使用してシンプルなオフラインテキスト補完ツールを作成
2. **モデル比較ダッシュボード**: 異なるSLMのパフォーマンス指標を可視化する基本的なダッシュボードを構築
3. **最適化実験**: 同じベースモデルで異なる量子化レベルの影響を測定

### 中級プロジェクト（各3～4時間）
4. **AIツールキットワークフロー**: VS Code AIツールキットを使用してモデルを最適化し、展開するワークフローを実施
5. **Windows AI Foundryアプリケーション**: Phi Silica APIとNPU最適化を使用してWindowsアプリを作成
6. **クロスプラットフォーム展開**: 最適化された同じモデルをWindows（OpenVINO）とモバイル（.NET MAUI）に展開
7. **関数呼び出しエージェント**: エッジシナリオ向けの関数呼び出し機能を備えたAIエージェントを構築

### 高度な統合プロジェクト（各4～5時間）
8. **OpenVINO最適化パイプライン**: NNCFとGenAIツールキットを使用して完全なモデル最適化を実装
9. **SLMOpsパイプライン**: トレーニングからエッジ展開までの完全なモデルライフサイクルを実装
10. **マルチモデルエッジシステム**: エッジハードウェア上で協調して動作する複数の専門モデルを展開
11. **MCP統合システム**: ツールとの相互作用のためのモデルコンテキストプロトコルを使用してエージェントシステムを構築

## 参考資料

- Microsoft Learn (Foundry Local)
  - 概要: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - 始め方: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLIリファレンス: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - 推論SDKとの統合: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUIの使い方: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Hugging Faceモデルのコンパイル: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - 概要: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - エージェント（概要）: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- 最適化と推論ツール
  - Microsoft Olive (ドキュメント): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (始め方): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive統合: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (ドキュメント): https://docs.openvino.ai/2025/index.html
  - Apple MLX (ドキュメント): https://ml-explore.github.io/mlx/build/html/index.html
- 展開フレームワークとモデル
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (ドキュメント): https://docs.vllm.ai/
  - Ollama (クイックスタート): https://github.com/ollama/ollama#get-started
- 開発者ツール（WindowsとVS Code）
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (概要): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## 学習コミュニティ

ディスカッションに参加し、他の学習者とつながりましょう：
- [EdgeAI for BeginnersリポジトリのGitHub Discussions](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

EdgeAIは人工知能の実装の最前線を代表し、プライバシー、遅延、接続性に関する重要な課題に対応しながら、強力な機能をデバイスに直接提供します。この20時間のコースは、EdgeAI技術をすぐに活用するための基本的な知識と実践的なスキルを提供します。

コースは意図的に簡潔で、最も重要な概念に焦点を当てており、圧倒的な時間の負担をかけずに貴重な専門知識を迅速に習得できるように設計されています。学んだことを強化するためには、シンプルな例でも実践的な練習が鍵となります。

学習を楽しんでください！

---

**免責事項**:  
この文書は、AI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を期すよう努めておりますが、自動翻訳には誤りや不正確さが含まれる可能性があります。原文（元の言語で記載された文書）が信頼できる情報源とみなされるべきです。重要な情報については、専門の人間による翻訳をお勧めします。この翻訳の使用に起因する誤解や誤認について、当社は一切の責任を負いません。