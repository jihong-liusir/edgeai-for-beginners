<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T07:58:39+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ja"
}
-->
# 初心者向けEdgeAI: 学習パスと学習スケジュール

### 集中学習パス (1週間)

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 0 | Module 0: EdgeAIの概要 | 1-2時間 |
| Day 1 | Module 1: EdgeAIの基礎 | 3時間 |
| Day 2 | Module 2: SLMの基礎 | 3時間 |
| Day 3 | Module 3: SLMの展開 | 2時間 |
| Day 4-5 | Module 4: モデル最適化 (6つのフレームワーク) | 4時間 |
| Day 6 | Module 5: SLMOps | 3時間 |
| Day 7 | Module 6-7: AIエージェントと開発ツール | 4時間 |
| Day 8 | Module 8: Foundry Local Toolkit (最新の実装) | 1時間 |

### 集中学習パス (2週間)

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 1-2 | Module 1: EdgeAIの基礎 | 3時間 |
| Day 3-4 | Module 2: SLMの基礎 | 3時間 |
| Day 5-6 | Module 3: SLMの展開 | 2時間 |
| Day 7-8 | Module 4: モデル最適化 | 4時間 |
| Day 9-10 | Module 5: SLMOps | 3時間 |
| Day 11-12 | Module 6: AIエージェント | 2時間 |
| Day 13-14 | Module 7: 開発ツール | 3時間 |

### パートタイム学習 (4週間)

| 週 | 内容 | 推定時間 |
|------|-------|------------------|
| Week 1 | Module 1-2: 基礎 & SLMの基礎 | 6時間 |
| Week 2 | Module 3-4: 展開 & 最適化 | 6時間 |
| Week 3 | Module 5-6: SLMOps & AIエージェント | 5時間 |
| Week 4 | Module 7: 開発ツール & 統合 | 3時間 |

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 0 | Module 0: EdgeAIの概要 | 1-2時間 |
| Day 1-2 | Module 1: EdgeAIの基礎 | 3時間 |
| Day 3-4 | Module 2: SLMの基礎 | 3時間 |
| Day 5-6 | Module 3: SLMの展開 | 2時間 |
| Day 7-8 | Module 4: モデル最適化 | 4時間 |
| Day 9-10 | Module 5: SLMOps | 3時間 |
| Day 11-12 | Module 6: SLMエージェントシステム | 2時間 |
| Day 13-14 | Module 7: EdgeAI実装サンプル | 2時間 |

| モジュール | 完了日 | 費やした時間 | 主な学び |
|--------|----------------|-------------|--------------|
| Module 0: EdgeAIの概要 | | | |
| Module 1: EdgeAIの基礎 | | | |
| Module 2: SLMの基礎 | | | |
| Module 3: SLMの展開 | | | |
| Module 4: モデル最適化 (6つのフレームワーク) | | | |
| Module 5: SLMOps | | | |
| Module 6: SLMエージェントシステム | | | |
| Module 7: EdgeAI実装サンプル | | | |
| 実践演習 | | | |
| ミニプロジェクト | | | |

### パートタイム学習 (4週間)

| 週 | 内容 | 推定時間 |
|------|-------|------------------|
| Week 1 | Module 1-2: 基礎 & SLMの基礎 | 6時間 |
| Week 2 | Module 3-4: 展開 & 最適化 | 6時間 |
| Week 3 | Module 5-6: SLMOps & AIエージェント | 5時間 |
| Week 4 | Module 7: 開発ツール & 統合 | 3時間 |

## はじめに

EdgeAI初心者向け学習ガイドへようこそ！このドキュメントは、コース教材を効率的に活用し、学習体験を最大化するための手助けをするために作成されています。構造化された学習パス、推奨される学習スケジュール、主要な概念の要約、そしてEdgeAI技術の理解を深めるための補足リソースを提供します。

このコースは、EdgeAIに関する基本的な知識を効率的に学べる20時間の凝縮された内容で、忙しいプロフェッショナルや学生がこの新興分野で実践的なスキルを迅速に習得するのに最適です。

## コース概要

このコースは、以下の8つの包括的なモジュールで構成されています：

0. **EdgeAIの概要** - 基礎と業界での応用、学習目標の設定
1. **EdgeAIの基礎と変革** - コア概念と技術の変化を理解
2. **小型言語モデル(SLM)の基礎** - 様々なSLMファミリーとそのアーキテクチャを探る
3. **小型言語モデルの展開** - 実践的な展開戦略の実装
4. **モデル形式変換と量子化** - OpenVINOを含む6つのフレームワークでの高度な最適化
5. **SLMOps - 小型言語モデルの運用** - 生産ライフサイクル管理と展開
6. **SLMエージェントシステム** - AIエージェント、関数呼び出し、モデルコンテキストプロトコル
7. **EdgeAI実装サンプル** - AIツールキット、Windows開発、プラットフォーム固有の実装
8. **Microsoft Foundry Local – 完全な開発者ツールキット** - ローカルファースト開発とハイブリッドAzure統合 (Module 08)

## この学習ガイドの使い方

- **段階的学習**: モジュールを順番に進めることで、最も一貫性のある学習体験を得られます
- **知識チェックポイント**: 各セクション後の自己評価質問を活用してください
- **実践練習**: 理論的な概念を強化するために提案された演習を完了してください
- **補足リソース**: 興味のあるトピックについて追加資料を探求してください

## 学習スケジュールの推奨

### 集中学習パス (1週間)

| 日 | 内容 | 推定時間 |
|------|-------|------------------|
| Day 0 | Module 0: EdgeAIの概要 | 1-2時間 |
| Day 1-2 | Module 1: EdgeAIの基礎 | 6時間 |
| Day 3-4 | Module 2: SLMの基礎 | 8時間 |
| Day 5 | Module 3: SLMの展開 | 3時間 |
| Day 6 | Module 8: Foundry Local Toolkit | 3時間 |

### パートタイム学習 (3週間)

| 週 | 内容 | 推定時間 |
|------|-------|------------------|
| Week 1 | Module 0: 概要 + Module 1: EdgeAIの基礎 | 7-9時間 |
| Week 2 | Module 2: SLMの基礎 | 7-8時間 |
| Week 3 | Module 3: SLMの展開 (3時間) + Module 8: Foundry Local Toolkit (2-3時間) | 5-6時間 |

## Module 0: EdgeAIの概要

### 主な学習目標

- EdgeAIとは何か、そしてそれが今日の技術環境でなぜ重要なのかを理解する
- EdgeAIによって変革された主要な業界とその具体的なユースケースを特定する
- 小型言語モデル(SLM)がエッジ展開において持つ利点を理解する
- コース全体の学習期待値と成果を明確にする
- EdgeAI分野でのキャリア機会と必要なスキルを認識する

### 学習の重点領域

#### セクション1: EdgeAIのパラダイムと定義
- **優先概念**: 
  - EdgeAIと従来のクラウドAI処理の違い
  - ハードウェア、モデル最適化、ビジネスニーズの融合
  - リアルタイム、プライバシー保護、コスト効率の良いAI展開

#### セクション2: 業界応用
- **優先概念**: 
  - 製造業 & Industry 4.0: 予測保守と品質管理
  - 医療: 診断画像と患者モニタリング
  - 自律システム: 自動運転車と輸送
  - スマートシティ: 交通管理と公共安全
  - 消費者技術: スマートフォン、ウェアラブル、スマートホーム

#### セクション3: 小型言語モデルの基礎
- **優先概念**: 
  - SLMの特性と性能比較
  - パラメータ効率と能力のトレードオフ
  - エッジ展開の制約と最適化戦略

#### セクション4: 学習フレームワークとキャリアパス
- **優先概念**: 
  - コース構造と段階的習得アプローチ
  - 技術スキルと実践的実装目標
  - キャリア向上の機会と業界応用

### 自己評価質問

1. EdgeAIを可能にした3つの主要な技術トレンドは何ですか？
2. EdgeAIとクラウドベースAIの利点と課題を比較してください。
3. EdgeAIが重要なビジネス価値を提供する3つの業界を挙げ、それぞれの理由を説明してください。
4. 小型言語モデルがどのようにしてEdgeAIを現実世界で実用的にしているのか説明してください。
5. このコースを通じて習得する主要な技術スキルは何ですか？
6. このコースで使用される4段階の学習アプローチを説明してください。

### 実践演習

1. **業界調査**: 1つの業界応用を選び、実際のEdgeAI実装を調査する (30分)
2. **モデル探索**: Hugging Faceで利用可能な小型言語モデルを閲覧し、パラメータ数と能力を比較する (30分)
3. **学習計画**: コース全体の構造を確認し、個人の学習スケジュールを作成する (15分)

### 補足資料

- [Edge AI市場概要 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [小型言語モデル概要 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Edge Computing Foundation](https://www.edgecomputing.org/)

## Module 1: EdgeAIの基礎と変革

### 主な学習目標

- クラウドベースAIとエッジベースAIの違いを理解する
- リソース制約環境向けの主要な最適化技術を習得する
- EdgeAI技術の実際の応用を分析する
- EdgeAIプロジェクトの開発環境を設定する

### 学習の重点領域

#### セクション1: EdgeAIの基礎
- **優先概念**: 
  - Edgeとクラウドコンピューティングのパラダイム
  - モデル量子化技術
  - ハードウェアアクセラレーションオプション (NPU、GPU、CPU)
  - プライバシーとセキュリティの利点

- **補足資料**:
  - [TensorFlow Lite ドキュメント](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse ドキュメント](https://docs.edgeimpulse.com)

#### セクション2: 実際のケーススタディ
- **優先概念**: 
  - Microsoft Phi & Muモデルエコシステム
  - 業界での実践的な実装
  - 展開の考慮事項

#### セクション3: 実践的な実装ガイド
- **優先概念**: 
  - 開発環境の設定
  - 量子化と最適化ツール
  - EdgeAI実装の評価方法

#### セクション4: エッジ展開ハードウェア
- **優先概念**: 
  - ハードウェアプラットフォームの比較
  - 特定のハードウェア向けの最適化戦略
  - 展開の考慮事項

### 自己評価質問

1. クラウドベースAIとエッジベースAIの実装を比較してください。
2. エッジ展開向けのモデルを最適化するための3つの主要技術を説明してください。
3. エッジでAIモデルを実行する主な利点は何ですか？
4. モデルを量子化するプロセスとそれが性能に与える影響を説明してください。
5. 異なるハードウェアアクセラレータ (NPU、GPU、CPU) がEdgeAI展開にどのように影響するか説明してください。

### 実践演習

1. **簡易環境設定**: 必要なパッケージを使用して最小限の開発環境を設定する (30分)
2. **モデル探索**: 事前学習済みの小型言語モデルをダウンロードして調査する (1時間)
3. **基本的な量子化**: 小型モデルで簡単な量子化を試す (1時間)

## Module 2: 小型言語モデルの基礎

### 主な学習目標

- 様々なSLMファミリーのアーキテクチャ原則を理解する
- 異なるパラメータスケールでのモデル能力を比較する
- 効率性、能力、展開要件に基づいてモデルを評価する
- 各モデルファミリーの適切なユースケースを認識する

### 学習の重点領域

#### セクション1: Microsoft Phiモデルファミリー
- **優先概念**: 
  - 設計哲学の進化
  - 効率性重視のアーキテクチャ
  - 特化した能力

#### セクション2: Qwenファミリー
- **優先概念**: 
  - オープンソースの貢献
  - スケーラブルな展開オプション
  - 高度な推論アーキテクチャ

#### セクション3: Gemmaファミリー
- **優先概念**: 
  - 研究主導の革新
  - マルチモーダル能力
  - モバイル最適化

#### セクション4: BitNETファミリー
- **優先概念**: 
  - 1ビット量子化技術
  - 推論最適化フレームワーク
  - 持続可能性の考慮

#### セクション5: Microsoft Muモデル
- **優先概念**: 
  - デバイス重視のアーキテクチャ
  - Windowsとのシステム統合
  - プライバシー保護の運用

#### セクション6: Phi-Silica
- **優先概念**: 
  - NPU最適化アーキテクチャ
  - 性能指標
  - 開発者統合

### 自己評価質問

1. PhiモデルファミリーとQwenモデルファミリーのアーキテクチャアプローチを比較してください。
2. BitNETの量子化技術が従来の量子化とどのように異なるか説明してください。
3. MuモデルがWindows統合において持つ独自の利点は何ですか？
4. Phi-SilicaがNPUハードウェアを活用してパフォーマンスを最適化する方法を説明してください。
5. 接続が制限されているモバイルアプリケーションに最適なモデルファミリーはどれで、なぜそれが適しているのか説明してください。

### 実践演習

1. **モデル比較**: 2つの異なるSLMモデルの簡易ベンチマーク（1時間）
2. **簡単なテキスト生成**: 小型モデルを使用した基本的なテキスト生成の実装（1時間）
3. **高速化の最適化**: 推論速度を向上させるための最適化技術を1つ適用（1時間）

## モジュール3: 小型言語モデルのデプロイ

### 主な学習目標

- デプロイ制約に基づいた適切なモデルの選択
- 様々なデプロイシナリオに対応する最適化技術の習得
- ローカルおよびクラウド環境でのSLMの実装
- EdgeAIアプリケーション向けの本番環境構成の設計

### 学習重点領域

#### セクション1: SLM高度学習
- **優先概念**: 
  - パラメータ分類フレームワーク
  - 高度な最適化技術
  - モデル取得戦略

#### セクション2: ローカル環境でのデプロイ
- **優先概念**: 
  - Ollamaプラットフォームでのデプロイ
  - Microsoft Foundryローカルソリューション
  - フレームワークの比較分析

#### セクション3: コンテナ化されたクラウドデプロイ
- **優先概念**: 
  - vLLM高性能推論
  - コンテナオーケストレーション
  - ONNX Runtimeの実装

### 自己評価質問

1. ローカルデプロイとクラウドデプロイを選択する際に考慮すべき要因は何ですか？
2. OllamaとMicrosoft Foundry Localをデプロイオプションとして比較してください。
3. SLMデプロイにおけるコンテナ化の利点を説明してください。
4. エッジにデプロイされたSLMの主要なパフォーマンス指標は何ですか？
5. モデル選択から本番実装までの完全なデプロイワークフローを説明してください。

### 実践演習

1. **基本的なローカルデプロイ**: Ollamaを使用して簡単なSLMをデプロイ（1時間）
2. **パフォーマンスチェック**: デプロイしたモデルの簡易ベンチマークを実行（30分）
3. **簡単な統合**: デプロイしたモデルを使用する最小限のアプリケーションを作成（1時間）

## モジュール4: モデル形式変換と量子化

### 主な学習目標

- 1ビットから8ビット精度までの高度な量子化技術を習得
- 形式変換戦略（GGUF、ONNX）を理解
- 6つのフレームワーク（Llama.cpp、Olive、OpenVINO、MLX、ワークフロー合成）での最適化を実装
- Intel、Apple、クロスプラットフォームハードウェア向けに最適化されたモデルを本番環境にデプロイ

### 学習重点領域

#### セクション1: 量子化の基礎
- **優先概念**: 
  - 精度分類フレームワーク
  - パフォーマンスと精度のトレードオフ
  - メモリフットプリントの最適化

#### セクション2: Llama.cppの実装
- **優先概念**: 
  - クロスプラットフォームデプロイ
  - GGUF形式の最適化
  - ハードウェアアクセラレーション技術

#### セクション3: Microsoft Olive Suite
- **優先概念**: 
  - ハードウェア対応の最適化
  - エンタープライズグレードのデプロイ
  - 自動化された最適化ワークフロー

#### セクション4: OpenVINOツールキット
- **優先概念**: 
  - Intelハードウェアの最適化
  - ニューラルネットワーク圧縮フレームワーク（NNCF）
  - クロスプラットフォーム推論デプロイ
  - OpenVINO GenAIによるLLMデプロイ

#### セクション5: Apple MLXフレームワーク
- **優先概念**: 
  - Apple Siliconの最適化
  - 統一メモリアーキテクチャ
  - LoRA微調整機能

#### セクション6: Edge AI開発ワークフロー合成
- **優先概念**: 
  - 統一ワークフローアーキテクチャ
  - フレームワーク選択の意思決定ツリー
  - 本番環境の準備検証
  - 将来を見据えた戦略

### 自己評価質問

1. 異なる精度レベル（1ビットから8ビット）の量子化戦略を比較してください。
2. エッジデプロイにおけるGGUF形式の利点を説明してください。
3. Microsoft Oliveのハードウェア対応最適化がデプロイ効率をどのように向上させるか説明してください。
4. OpenVINOのNNCFがモデル圧縮において持つ主要な利点は何ですか？
5. Apple MLXが統一メモリアーキテクチャを活用して最適化を行う方法を説明してください。
6. ワークフロー合成が最適な最適化フレームワークの選択にどのように役立つか説明してください。

### 実践演習

1. **モデル量子化**: 異なる量子化レベルをモデルに適用し、結果を比較（1時間）
2. **OpenVINO最適化**: NNCFを使用してIntelハードウェア向けにモデルを圧縮（1時間）
3. **フレームワーク比較**: 同じモデルを3つの異なる最適化フレームワークでテスト（1時間）
4. **パフォーマンスベンチマーク**: 推論速度とメモリ使用量に対する最適化の影響を測定（1時間）

## モジュール5: SLMOps - 小型言語モデル運用

### 主な学習目標

- SLMOpsライフサイクル管理の原則を理解
- エッジデプロイ向けの蒸留と微調整技術を習得
- モニタリングを伴う本番デプロイ戦略を実装
- エンタープライズグレードのSLM運用および保守ワークフローを構築

### 学習重点領域

#### セクション1: SLMOpsの概要
- **優先概念**: 
  - SLMOpsによるAI運用のパラダイムシフト
  - コスト効率とプライバシー重視のアーキテクチャ
  - 戦略的ビジネスインパクトと競争上の利点

#### セクション2: モデル蒸留
- **優先概念**: 
  - 知識移転技術
  - 2段階蒸留プロセスの実装
  - Azure ML蒸留ワークフロー

#### セクション3: 微調整戦略
- **優先概念**: 
  - パラメータ効率の良い微調整（PEFT）
  - LoRAおよびQLoRAの高度な手法
  - マルチアダプタトレーニングとハイパーパラメータ最適化

#### セクション4: 本番デプロイ
- **優先概念**: 
  - 本番環境向けのモデル変換と量子化
  - Foundry Localデプロイ構成
  - パフォーマンスベンチマークと品質検証

### 自己評価質問

1. SLMOpsは従来のMLOpsとどのように異なるか？
2. エッジデプロイにおけるモデル蒸留の利点を説明してください。
3. リソースが制約された環境でSLMを微調整する際の重要な考慮事項は何ですか？
4. Edge AIアプリケーション向けの完全な本番デプロイパイプラインを説明してください。

### 実践演習

1. **基本的な蒸留**: 大型の教師モデルから小型モデルを作成（1時間）
2. **微調整実験**: 特定のドメイン向けにモデルを微調整（1時間）
3. **デプロイパイプライン**: モデルデプロイ用の基本的なCI/CDパイプラインを設定（1時間）

## モジュール6: SLMエージェントシステム - AIエージェントと関数呼び出し

### 主な学習目標

- 小型言語モデルを使用してエッジ環境向けのインテリジェントAIエージェントを構築
- システマティックなワークフローで関数呼び出し機能を実装
- 標準化されたツール連携のためのModel Context Protocol（MCP）統合を習得
- 最小限の人間の介入で高度なエージェントシステムを作成

### 学習重点領域

#### セクション1: AIエージェントとSLMの基礎
- **優先概念**: 
  - エージェント分類フレームワーク（反射型、モデルベース型、目標ベース型、学習エージェント）
  - SLMとLLMのトレードオフ分析
  - エッジ特化型エージェント設計パターン
  - エージェントのリソース最適化

#### セクション2: 小型言語モデルでの関数呼び出し
- **優先概念**: 
  - システマティックなワークフロー実装（意図検出、JSON出力、外部実行）
  - プラットフォーム固有の実装（Phi-4-mini、選択されたQwenモデル、Microsoft Foundry Local）
  - 高度な例（マルチエージェント協力、動的ツール選択）
  - 本番環境の考慮事項（レート制限、監査ログ、セキュリティ対策）

#### セクション3: Model Context Protocol（MCP）統合
- **優先概念**: 
  - プロトコルアーキテクチャと階層型システム設計
  - マルチバックエンドサポート（開発用Ollama、本番用vLLM）
  - 接続プロトコル（STDIOおよびSSEモード）
  - 実世界のアプリケーション（ウェブ自動化、データ処理、API統合）

### 自己評価質問

1. エッジAIエージェントの主要なアーキテクチャ上の考慮事項は何ですか？
2. 関数呼び出しがエージェントの能力をどのように向上させるか説明してください。
3. エージェント通信におけるModel Context Protocolの役割を説明してください。

### 実践演習

1. **簡単なエージェント**: 関数呼び出しを備えた基本的なAIエージェントを構築（1時間）
2. **MCP統合**: エージェントアプリケーションにMCPを実装（30分）

## モジュール7: EdgeAI実装サンプル

### 主な学習目標

- Visual Studio Code用AI Toolkitを活用して包括的なEdgeAI開発ワークフローを習得
- Windows AI FoundryプラットフォームとNPU最適化戦略に精通
- 複数のハードウェアプラットフォームとデプロイシナリオでEdgeAIを実装
- プラットフォーム固有の最適化を伴う本番環境向けEdgeAIアプリケーションを構築

### 学習重点領域

#### セクション1: Visual Studio Code用AI Toolkit
- **優先概念**: 
  - VS Code内での包括的なEdge AI開発環境
  - エッジデプロイ向けのモデルカタログと発見
  - ローカルテスト、最適化、エージェント開発ワークフロー
  - エッジシナリオ向けのパフォーマンスモニタリングと評価

#### セクション2: Windows EdgeAI開発ガイド
- **優先概念**: 
  - Windows AI Foundryプラットフォームの包括的な概要
  - Phi Silica APIによる効率的なNPU推論
  - 画像処理とOCR向けのコンピュータビジョンAPI
  - Foundry Local CLIによるローカル開発とテスト

#### セクション3: プラットフォーム固有の実装
- **優先概念**: 
  - NVIDIA Jetson Orin Nanoデプロイ（67 TOPS AI性能）
  - .NET MAUIとONNX Runtime GenAIを使用したモバイルアプリケーション
  - クラウドとエッジのハイブリッドアーキテクチャを備えたAzure EdgeAIソリューション
  - ユニバーサルハードウェアサポートを備えたWindows ML最適化
  - プライバシー重視のRAG実装を伴うFoundry Localアプリケーション

### 自己評価質問

1. AI ToolkitがEdgeAI開発ワークフローをどのように簡素化するか説明してください。
2. 異なるハードウェアプラットフォーム間でのデプロイ戦略を比較してください。
3. Edge開発におけるWindows AI Foundryの利点は何ですか？
4. 現代のEdge AIアプリケーションにおけるNPU最適化の役割を説明してください。
5. Phi Silica APIがNPUハードウェアを活用してパフォーマンスを最適化する方法を説明してください。
6. プライバシーに敏感なアプリケーションにおけるローカルデプロイとクラウドデプロイの利点を比較してください。

### 実践演習

1. **AI Toolkitセットアップ**: AI Toolkitを構成し、モデルを最適化（1時間）
2. **Windows AI Foundry**: Phi Silica APIを使用して簡単なWindows AIアプリケーションを構築（1時間）
3. **クロスプラットフォームデプロイ**: 同じモデルを2つの異なるプラットフォームにデプロイ（1時間）
4. **NPU最適化**: Windows AI Foundryツールを使用してNPU性能をテスト（30分）

## モジュール8: Microsoft Foundry Local – 完全な開発者ツールキット（現代化版）

### 主な学習目標

- 最新のSDK統合を伴うFoundry Localのインストールと構成
- コーディネーターパターンを使用した高度なマルチエージェントシステムを実装
- 自動タスクベース選択を備えたインテリジェントモデルルーターを構築
- 包括的なモニタリングを伴う本番環境向けAIソリューションをデプロイ
- Azure AI Foundryとの統合によるハイブリッドデプロイシナリオを実現
- FoundryLocalManagerとOpenAIクライアントを使用した最新SDKパターンを習得

### 学習重点領域

#### セクション1: 最新のインストールと構成
- **優先概念**: 
  - FoundryLocalManager SDK統合
  - 自動サービス検出とヘルスモニタリング
  - 環境ベースの構成パターン
  - 本番デプロイの考慮事項

#### セクション2: 高度なマルチエージェントシステム
- **優先概念**: 
  - 専門エージェントを伴うコーディネーターパターン
  - 検索、推論、実行エージェントの専門化
  - 改善のためのフィードバックループメカニズム
  - パフォーマンスモニタリングと統計追跡

#### セクション3: インテリジェントモデルルーティング
- **優先概念**: 
  - キーワードベースのモデル選択アルゴリズム
| 実践演習 | 6時間 | 主要な技術の実践的な実装 |
| 自己評価 | 2時間 | 質問や振り返りを通じて理解度をテスト |
| ミニプロジェクト | 3時間 | 小規模な実践的な実装で知識を応用 |

### 時間制約に応じた重点領域

**10時間しかない場合:**
- モジュール0（イントロダクション）とモジュール1、2、3（EdgeAIの基本概念）を完了
- 各モジュールで少なくとも1つの実践演習を行う
- 実装の詳細よりも基本概念の理解に集中

**20時間すべてを使える場合:**
- イントロダクションを含む全8モジュールを完了
- 各モジュールの主要な実践演習を実施
- モジュール7のミニプロジェクトを1つ完了
- 少なくとも2～3の補足リソースを探索

**20時間以上使える場合:**
- イントロダクションを含む全モジュールを詳細な演習付きで完了
- 複数のミニプロジェクトを構築
- モジュール4で高度な最適化技術を探索
- モジュール5で本番環境へのデプロイを実装

## 必須リソース

限られた学習時間で最大の価値を提供する厳選されたリソース：

### 必読ドキュメント
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - 最も効率的なモデル最適化ツール
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - SLMをローカルで迅速にデプロイする方法
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - エッジ最適化モデルのリファレンス
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intelの包括的な最適化ツールキット
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - 統合されたEdgeAI開発環境
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows特化のEdgeAI開発プラットフォーム

### 時間節約ツール
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - モデルの迅速なアクセスとデプロイ
- [Gradio](https://www.gradio.app/docs/interface) - AIデモ用の迅速なUI開発
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡易化されたモデル最適化
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 効率的なCPU推論
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - ニューラルネットワーク圧縮フレームワーク
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大規模言語モデルデプロイツールキット

## 進捗追跡テンプレート

20時間のコースを通じて学習進捗を追跡するための簡易テンプレートを使用してください：

| モジュール | 完了日 | 費やした時間 | 主な学び |
|--------|----------------|-------------|---------------|
| モジュール0: EdgeAIのイントロダクション | | | |
| モジュール1: EdgeAIの基礎 | | | |
| モジュール2: SLMの基礎 | | | |
| モジュール3: SLMのデプロイ | | | |
| モジュール4: モデル最適化 | | | |
| モジュール5: SLMOps | | | |
| モジュール6: AIエージェント | | | |
| モジュール7: 開発ツール | | | |
| モジュール8: Foundry Local Toolkit | | | |
| 実践演習 | | | |
| ミニプロジェクト | | | |

## ミニプロジェクトのアイデア

EdgeAIの概念を練習するために以下のプロジェクトを検討してください（各プロジェクトは2～4時間で完了可能）：

### 初級プロジェクト（各2～3時間）
1. **エッジテキストアシスタント**: 小型言語モデルを使用して簡単なオフラインテキスト補完ツールを作成
2. **モデル比較ダッシュボード**: 異なるSLMのパフォーマンス指標を可視化する基本的なダッシュボードを構築
3. **最適化実験**: 同じベースモデルに対する異なる量子化レベルの影響を測定

### 中級プロジェクト（各3～4時間）
4. **AIツールキットワークフロー**: VS Code AI Toolkitを使用してモデルを最適化し、デプロイする一連の作業を実施
5. **Windows AI Foundryアプリケーション**: Phi Silica APIとNPU最適化を使用してWindowsアプリを作成
6. **クロスプラットフォームデプロイ**: 最適化された同じモデルをWindows（OpenVINO）とモバイル（.NET MAUI）にデプロイ
7. **関数呼び出しエージェント**: エッジシナリオ向けの関数呼び出し機能を持つAIエージェントを構築

### 高度な統合プロジェクト（各4～5時間）
8. **OpenVINO最適化パイプライン**: NNCFとGenAIツールキットを使用して完全なモデル最適化を実装
9. **SLMOpsパイプライン**: トレーニングからエッジデプロイまでの完全なモデルライフサイクルを実装
10. **マルチモデルエッジシステム**: エッジハードウェア上で連携する複数の専門モデルをデプロイ
11. **MCP統合システム**: ツールとの相互作用のためのModel Context Protocolを使用してエージェントシステムを構築

## 参考資料

- Microsoft Learn (Foundry Local)
  - 概要: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - 始め方: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLIリファレンス: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - 推論SDKとの統合: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUIの使い方: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Hugging Faceモデルのコンパイル: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - 概要: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - エージェント（概要）: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- 最適化と推論ツール
  - Microsoft Olive (ドキュメント): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (始め方): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive統合: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (ドキュメント): https://docs.openvino.ai/2025/index.html
  - Apple MLX (ドキュメント): https://ml-explore.github.io/mlx/build/html/index.html
- デプロイフレームワークとモデル
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (ドキュメント): https://docs.vllm.ai/
  - Ollama (クイックスタート): https://github.com/ollama/ollama#get-started
- 開発ツール（WindowsとVS Code）
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (概要): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## 学習コミュニティ

ディスカッションに参加し、他の学習者とつながりましょう：
- [EdgeAI for Beginnersリポジトリ](https://github.com/microsoft/edgeai-for-beginners/discussions)のGitHubディスカッション
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

EdgeAIは人工知能の実装の最前線を代表し、プライバシー、遅延、接続性に関する重要な課題に対応しながら、強力な機能をデバイスに直接提供します。この20時間のコースは、EdgeAI技術をすぐに活用するための基本的な知識と実践的なスキルを提供します。

コースは意図的に簡潔で、最も重要な概念に焦点を当てており、圧倒的な時間の負担なしに貴重な専門知識を迅速に得ることができます。簡単な例でも実践的な練習が学んだことを強化する鍵です。

学習を楽しんでください！

---

