<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f921854683b0ba903972831f6e61c28f",
  "translation_date": "2025-07-22T05:24:26+00:00",
  "source_file": "Module07/README.md",
  "language_code": "ja"
}
-->
# 第7章 : EdgeAI サンプル

Edge AIは、人工知能とエッジコンピューティングの融合を表し、クラウド接続に依存せずにデバイス上で直接インテリジェントな処理を可能にします。この章では、異なるプラットフォームとフレームワークを使用した5つの独自のEdgeAI実装を探り、エッジでAIモデルを実行する際の多様性と可能性を紹介します。

## 1. NVIDIA Jetson Orin NanoでのEdgeAI

NVIDIA Jetson Orin Nanoは、手頃な価格で利用可能なエッジAIコンピューティングの革新を象徴し、最大67 TOPSのAI性能をコンパクトなクレジットカードサイズのフォームファクターで提供します。この強力なエッジAIプラットフォームは、ホビイスト、学生、プロの開発者に向けて生成AI開発を民主化します。

### 主な特徴
- 最大67 TOPSのAI性能を提供し、前世代比で1.7倍の改善
- 1024 CUDAコアと最大32 TensorコアによるAI処理
- 最大周波数1.5 GHzの6コアArm Cortex-A78AE v8.2 64ビットCPU
- 価格はわずか249ドルで、開発者、学生、メーカーに最も手頃でアクセス可能なプラットフォームを提供

### アプリケーション
Jetson Orin Nanoは、ビジョントランスフォーマー、大規模言語モデル、ビジョンと言語モデルを含む最新の生成AIモデルの実行に優れています。特にGenAIユースケース向けに設計されており、手のひらサイズのデバイスで複数のLLMを実行できます。人気のあるユースケースには、AI搭載ロボット、スマートドローン、インテリジェントカメラ、自律型エッジデバイスが含まれます。

**詳細はこちら**: [NVIDIAのJetson Orin Nanoスーパーコンピュータ: EdgeAIの次なる大きな進化](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. .NET MAUIとONNX Runtime GenAIを使用したモバイルアプリケーションでのEdgeAI

このソリューションは、.NET MAUI（マルチプラットフォームアプリUI）とONNX Runtime GenAIを使用して、生成AIと大規模言語モデル（LLM）をクロスプラットフォームのモバイルアプリケーションに統合する方法を示します。このアプローチにより、.NET開発者はAndroidおよびiOSデバイス上でネイティブに動作する高度なAI搭載モバイルアプリケーションを構築できます。

### 主な特徴
- .NET MAUIフレームワークに基づき、AndroidおよびiOSアプリケーションの単一コードベースを提供
- ONNX Runtime GenAI統合により、モバイルデバイス上で生成AIモデルを直接実行可能
- CPU、GPU、モバイルAIプロセッサなど、モバイルデバイス向けのさまざまなハードウェアアクセラレータをサポート
- ONNX Runtimeを通じて、iOS向けのCoreMLやAndroid向けのNNAPIなどのプラットフォーム固有の最適化を提供
- 前処理と後処理、推論、ロジット処理、検索とサンプリング、KVキャッシュ管理を含む完全な生成AIループを実装

### 開発の利点
.NET MAUIアプローチにより、開発者は既存のC#および.NETスキルを活用しながらクロスプラットフォームAIアプリケーションを構築できます。ONNX Runtime GenAIフレームワークは、Llama、Mistral、Phi、Gemmaなどの複数のモデルアーキテクチャをサポートします。ARM64向けに最適化されたカーネルがINT4量子化行列乗算を加速し、モバイルハードウェア上で効率的な性能を確保しながら、.NET開発の使い慣れた体験を維持します。

### ユースケース
このソリューションは、.NET技術を使用してAI搭載モバイルアプリケーションを構築したい開発者に最適です。インテリジェントチャットボット、画像認識アプリ、言語翻訳ツール、完全にオンデバイスで動作する個別化された推薦システムなど、プライバシーを強化しオフライン機能を提供するアプリケーションに適しています。

**詳細はこちら**: [.NET MAUI ONNX Runtime GenAI例](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. Azureでの小型言語モデルエンジンを使用したEdgeAI

MicrosoftのAzureベースのEdgeAIソリューションは、小型言語モデル（SLM）をクラウドとエッジのハイブリッド環境で効率的に展開することに焦点を当てています。このアプローチは、クラウド規模のAIサービスとエッジ展開要件のギャップを埋めます。

### アーキテクチャの利点
- Azure AIサービスとのシームレスな統合
- ONNX Runtimeを使用してSLM/LLMおよびマルチモーダルモデルをデバイス上およびクラウドで実行
- エンタープライズ規模の展開に最適化
- 継続的なモデル更新と管理をサポート

### ユースケース
Azure EdgeAIの実装は、クラウド管理機能を備えたエンタープライズグレードのAI展開を必要とするシナリオで優れています。これには、インテリジェントな文書処理、リアルタイム分析、クラウドとエッジコンピューティングリソースを活用したハイブリッドAIワークフローが含まれます。

**詳細はこちら**: [Azure EdgeAI SLMエンジン](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## 4. Windows MLを使用したEdgeAI

Windows MLは、オンデバイスモデル推論と簡易展開のために最適化されたMicrosoftの最先端ランタイムであり、Windows AI Foundryの基盤として機能します。このプラットフォームは、PCハードウェアの全範囲を活用したAI搭載Windowsアプリケーションの開発を可能にします。

### プラットフォームの能力
- バージョン24H2（ビルド26100）以降のすべてのWindows 11 PCで動作
- NPUやGPUを搭載していないPCを含む、すべてのx64およびARM64 PCハードウェアで動作
- 開発者が独自のモデルを持ち込み、AMD、Intel、NVIDIA、Qualcommを含むシリコンパートナーエコシステム全体で効率的に展開可能
- インフラストラクチャAPIを活用することで、異なるシリコンを対象とする複数のアプリビルドを作成する必要がなくなる

### 開発者の利点
Windows MLはハードウェアと実行プロバイダーを抽象化するため、コードを書くことに集中できます。また、Windows MLは最新のNPU、GPU、CPUがリリースされるたびに自動的に更新されます。このプラットフォームは、多様なWindowsハードウェアエコシステム全体でAI開発の統一されたフレームワークを提供します。

**詳細はこちら**: [Windows ML概要](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)

## 5. Foundry Localアプリケーションを使用したEdgeAI

Foundry Localは、.NETを使用してローカルリソースで検索強化生成（RAG）アプリケーションを構築することを可能にし、ローカル言語モデルとセマンティック検索機能を組み合わせます。このアプローチは、完全にローカルインフラストラクチャ上で動作するプライバシー重視のAIソリューションを提供します。

### 技術アーキテクチャ
- Phi-3言語モデル、ローカル埋め込み、セマンティックカーネルを組み合わせてRAGシナリオを構築
- 埋め込みを浮動小数点値の配列（ベクトル）として使用し、コンテンツとそのセマンティックな意味を表現
- セマンティックカーネルが主要なオーケストレーターとして機能し、Phi-3とスマートコンポーネントを統合してシームレスなRAGパイプラインを構築
- SQLiteやQdrantなどのローカルベクトルデータベースをサポート

### 実装の利点
RAG（検索強化生成）は、「何かを検索してプロンプトに組み込む」というシンプルな方法を指します。このローカル実装は、データプライバシーを確保しながら、カスタム知識ベースに基づいたインテリジェントな応答を提供します。このアプローチは、データ主権やオフライン操作機能を必要とするエンタープライズシナリオに特に価値があります。

**詳細はこちら**: [Foundry Local RAGサンプル](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

## 結論

これら5つのEdgeAI実装は、現在利用可能なエッジAIソリューションの成熟度と多様性を示しています。Jetson Orin Nanoのようなハードウェアアクセラレートエッジデバイスから、ONNX Runtime GenAIやWindows MLのようなソフトウェアフレームワークまで、開発者はエッジでインテリジェントなアプリケーションを展開するための前例のない選択肢を持っています。

これらのプラットフォームに共通するテーマは、AI機能の民主化であり、異なるスキルレベルやユースケースの開発者に高度な機械学習を利用可能にすることです。モバイルアプリケーション、デスクトップソフトウェア、組み込みシステムを構築する際、これらのEdgeAIソリューションは効率的かつプライバシーを重視したエッジで動作する次世代のインテリジェントアプリケーションの基盤を提供します。

各プラットフォームは独自の利点を提供します。Jetson Orin Nanoはハードウェアアクセラレートエッジコンピューティング向け、ONNX Runtime GenAIはクロスプラットフォームモバイル開発向け、Azure EdgeAIはエンタープライズクラウドエッジ統合向け、Windows MLはWindowsネイティブアプリケーション向け、Foundry Localはプライバシー重視のRAG実装向けです。これらは、EdgeAI開発の包括的なエコシステムを形成しています。

**免責事項**:  
この文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解について、当社は責任を負いません。