<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-07-22T04:37:25+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "ja"
}
-->
# Section02 : 小型言語モデル (SLM) における関数呼び出し

## 目次
1. [関数呼び出しとは？](../../../Module06)
2. [関数呼び出しの仕組み](../../../Module06)
3. [適用シナリオ](../../../Module06)
4. [Phi-4-mini と Ollama を使った関数呼び出しの設定](../../../Module06)
5. [Qwen3 関数呼び出しの活用](../../../Module06)
6. [Foundry Local の統合](../../../Module06)
7. [ベストプラクティスとトラブルシューティング](../../../Module06)
8. [高度な例](../../../Module06)

## 関数呼び出しとは？

関数呼び出しは、小型言語モデル (SLM) が外部ツール、API、サービスと連携するための強力な機能です。これにより、SLM はトレーニングデータに限定されることなく、以下のようなことが可能になります：

- **外部APIとの接続**（天気サービス、データベース、検索エンジンなど）
- **ユーザーリクエストに基づく特定の関数の実行**
- **さまざまなソースからのリアルタイム情報の取得**
- **専門ツールを使った計算タスクの実行**
- **複数の操作を連鎖させた複雑なワークフローの実現**

この機能により、SLM は静的なテキスト生成器から、現実世界のタスクを実行できる動的なAIエージェントへと進化します。

## 関数呼び出しの仕組み

関数呼び出しのプロセスは、以下の体系的なワークフローに従います：

### 1. ツールの統合
- **外部ツール**：SLM は天気API、データベース、Webサービス、その他の外部システムと接続可能
- **関数定義**：各ツールは特定のパラメータ、入出力形式、説明で定義される
- **API互換性**：ツールは標準化されたインターフェース（REST API、SDKなど）を通じて統合される

### 2. 関数定義
関数は以下の3つの主要コンポーネントで定義されます：
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. 意図の検出
- **自然言語処理**：SLM はユーザー入力を分析して意図を理解
- **関数のマッチング**：リクエストを満たすために必要な関数を特定
- **パラメータ抽出**：ユーザーのメッセージから必要なパラメータを特定して抽出

### 4. JSON出力の生成
SLM は以下を含む構造化JSONを生成します：
- 呼び出す関数名
- 必要なパラメータとその適切な値
- 実行コンテキストとメタデータ

### 5. 外部実行
- **パラメータの検証**：すべての必要なパラメータが揃っており、正しい形式であることを確認
- **関数の実行**：指定されたパラメータでアプリケーションが関数を実行
- **エラーハンドリング**：失敗、タイムアウト、不正な応答を管理

### 6. 応答の統合
- **結果処理**：関数の出力をSLMに返す
- **コンテキスト統合**：SLMが結果を応答に組み込む
- **ユーザーとのコミュニケーション**：自然で会話的な形式で情報を提示

## 適用シナリオ

### データ取得
自然言語クエリを構造化されたAPI呼び出しに変換：
- **「最近の注文を表示して」** → ユーザーIDと日付フィルタを使ったデータベースクエリ
- **「東京の天気は？」** → 場所パラメータを使った天気API呼び出し
- **「先週ジョンからのメールを探して」** → 送信者と日付フィルタを使ったメールサービスクエリ

### 操作の実行
ユーザーリクエストを特定の関数呼び出しに変換：
- **「明日午後2時に会議を設定して」** → カレンダーAPI統合
- **「チームにメッセージを送って」** → コミュニケーションプラットフォームAPI
- **「ファイルのバックアップを作成して」** → ファイルシステム操作

### 計算タスク
複雑な数学的または論理的操作を処理：
- **「$10,000を5%で10年間の複利計算して」** → 金融計算関数
- **「このデータセットを分析してトレンドを見つけて」** → 統計分析ツール
- **「配送のためにこのルートを最適化して」** → ルート最適化アルゴリズム

### データ処理ワークフロー
複数の関数呼び出しを連鎖させて複雑な操作を実現：
1. **複数のソースからデータを取得**
2. **情報を解析して検証**
3. **必要な形式にデータを変換**
4. **結果を適切なシステムに保存**
5. **レポートや可視化を生成**

### UI/UX統合
動的なインターフェース更新を可能に：
- **「ダッシュボードに売上データを表示して」** → グラフ生成と表示
- **「新しい場所で地図を更新して」** → 地理空間データ統合
- **「在庫表示を更新して」** → リアルタイムデータ同期

## Phi-4-mini と Ollama を使った関数呼び出しの設定

MicrosoftのPhi-4-miniは、Ollamaを通じて単一および並列の関数呼び出しをサポートします。以下はその設定方法です：

### 前提条件
- Ollama バージョン 0.5.13 以上
- Phi-4-mini モデル（推奨：`phi4-mini:3.8b-fp16`）

### インストール手順

#### 1. Phi-4-mini のインストールと実行
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. カスタム ModelFile テンプレートの作成
現在のOllamaのデフォルトテンプレートの制限により、以下のテンプレートでカスタムModelFileを作成する必要があります：

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. カスタムモデルの作成
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### 単一関数呼び出しの例

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### 並列関数呼び出しの例

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Qwen3 関数呼び出しの活用

Qwen3は、優れた性能と柔軟性を備えた高度な関数呼び出し機能を提供します。以下はその実装方法です：

### Qwen-Agent フレームワークの使用

Qwen-Agentは、関数呼び出しの実装を簡素化する高レベルのフレームワークを提供します：

#### インストール
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### 基本設定

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### カスタム関数の実装

Qwen3用にカスタム関数を定義することも可能です：

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Qwen3 の高度な機能

#### 思考モードの制御
Qwen3は、思考モードと非思考モードの動的切り替えをサポートします：

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### 複数ステップの関数呼び出し
Qwen3は、複数の関数呼び出しを連鎖させるのに優れています：

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Foundry Local の統合

MicrosoftのFoundry Localは、プライバシーとパフォーマンスを強化したローカルモデル実行のためのOpenAI互換APIを提供します。

### セットアップとインストール

#### Windows
[Foundry Local リリースページ](https://github.com/microsoft/Foundry-Local/releases)からインストーラーをダウンロードし、インストール手順に従ってください。

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### 基本的な使用法

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Foundry Local の高度な機能

#### モデル管理
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### パフォーマンス最適化
Foundry Localは、ハードウェアに最適なモデルバリアントを自動的に選択します：
- **CUDA GPU**：GPU最適化モデルをダウンロード
- **Qualcomm NPU**：NPU加速バリアントを使用
- **CPUのみ**：CPU最適化モデルを選択

## ベストプラクティスとトラブルシューティング

### 関数定義のベストプラクティス

#### 1. 明確で説明的な命名
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. 包括的なパラメータ定義
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. 入力検証とエラーハンドリング
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### よくある問題と解決策

#### 問題1: 関数が呼び出されない
**症状**：モデルが関数を呼び出さず、テキストで応答する

**解決策**：
1. **関数の説明を確認**：ユーザーの意図に明確に一致していることを確認
2. **パラメータ定義を検証**：すべての必要なパラメータが適切に定義されていることを確認
3. **システムプロンプトを見直す**：関数を使用するタイミングについて明確な指示を含める
4. **明示的なリクエストでテスト**：「ロンドンのデータを取得するために天気関数を使ってください」と試す

#### 問題2: パラメータが正しくない
**症状**：関数が間違ったまたは不足しているパラメータで呼び出される

**解決策**：
1. **パラメータ例を追加**：パラメータ説明にサンプル値を含める
2. **列挙型制約を使用**：パラメータ値を特定のオプションに制限
3. **フォールバック値を実装**：オプションのパラメータに適切なデフォルト値を提供

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### 問題3: 並列関数呼び出しの失敗
**症状**：複数の関数が実行されるべきところで1つしか実行されない

**解決策**：
1. **モデルのサポートを確認**：モデルが並列関数呼び出しをサポートしていることを確認
2. **システムプロンプトを更新**：「いくつかのツール」または「複数のツール」をシステムメッセージに含める
3. **適切なモデルバージョンを使用**：Ollama用にはPhi-4-mini:3.8b-fp16を推奨

#### 問題4: Ollamaでのテンプレート問題
**症状**：デフォルトのOllama設定で関数呼び出しが機能しない

**解決策**：
1. **カスタムModelFileを使用**：このチュートリアルで提供された修正済みテンプレートを適用
2. **Ollamaを更新**：バージョン0.5.13以上を使用
3. **モデルの量子化を確認**：高い量子化レベル（Q8_0、fp16）は、過度に量子化されたバージョンよりも優れた動作を示す

### パフォーマンス最適化

#### 1. 効率的な関数設計
- **関数を焦点化**：各関数は単一の明確な目的を持つべき
- **外部依存を最小化**：API呼び出しやネットワークリクエストを減らす
- **結果をキャッシュ**：頻繁にリクエストされるデータを保存して応答時間を改善

#### 2. バッチ処理と非同期操作
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. リソース管理
- **接続プーリング**：データベースやAPI接続を再利用
- **レート制限**：外部APIに適切なレート制限を実装
- **タイムアウト処理**：すべての外部呼び出しに適切なタイムアウトを設定

## 高度な例

### マルチエージェント協調システム

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### 動的ツール選択システム

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """すべての関数呼び出しの標準結果形式"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """包括的な関数呼び出し機能を備えた本番対応AIエージェント"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # コアビジネス関数の初期化
        self._register_core_functions()
    
    def _register_core_functions(self):
        """利用可能なすべてのビジネス関数を登録"""
        
        # CRM関数
        self.register_function(
            name="get_customer_info",
            description="CRMから顧客情報を取得",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # 1分あたりの呼び出し回数
        )
        
        # 営業関数
        self.register_function(
            name="create_sales_opportunity",
            description="新しい営業機会を作成",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # 分析関数
        self.register_function(
            name="generate_sales_report",
            description="営業パフォーマンスレポートを生成",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # 通知関数
        self.register_function(
            name="send_notification",
            description="チームメンバーに通知を送信",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """エージェントに新しい関数を登録"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
申し訳ありませんが、翻訳するための具体的なMarkdownファイルの内容が提供されていません。翻訳する内容を記載してください。
## 結論

小型言語モデル（SLM）の関数呼び出しは、静的なAIアシスタントから、外部ツールやサービスと連携できる動的で有能なエージェントへのパラダイムシフトを表しています。このチュートリアルでは以下の内容をカバーしました。

### 主なポイント

1. **基礎的な理解**: 関数呼び出しにより、SLMはトレーニングデータを超えて外部ツールやサービスと接続する能力を得ます。

2. **柔軟な実装**: カスタムテンプレートを使用した低レベルの実装から、Qwen-AgentやFoundry Localのような高レベルのフレームワークまで、複数のアプローチがあります。

3. **運用上の考慮事項**: エンタープライズ環境での展開には、エラーハンドリング、レート制限、セキュリティ、監査ログへの注意が必要です。

4. **パフォーマンス最適化**: 適切な関数設計、効率的な実行、スマートなキャッシングにより、応答時間を大幅に改善できます。

### 今後の展望

SLM技術が進化するにつれて、以下のような進展が期待されます：

- **関数呼び出しの精度向上**: より良い意図検出とパラメータ抽出
- **並列処理の強化**: より洗練された複数関数のオーケストレーション
- **統合標準の向上**: ツール統合のための標準化されたプロトコル
- **セキュリティ機能の強化**: 認証と認可メカニズムの向上
- **エコシステムの拡大**: 事前構築された関数や統合のライブラリの拡充

### 始めるためのステップ

プロジェクトで関数呼び出しを実装するには：

1. **シンプルに始める**: 基本的な単一関数のシナリオから始めましょう。
2. **フレームワークを選ぶ**: 直接実装（Ollama/Phi-4）か、フレームワーク支援（Qwen-Agent）のどちらかを選択。
3. **関数を慎重に設計**: 明確でよく文書化された関数定義に注力。
4. **エラーハンドリングを実装**: 初期段階から堅牢なエラーハンドリングを構築。
5. **段階的にスケールアップ**: 経験を積みながら、シンプルなシナリオから複雑なシナリオへ移行。

関数呼び出しは、SLMを単なるテキスト生成器から、実際の問題を解決できる実用的なAIエージェントへと変貌させます。このチュートリアルで紹介したパターンと実践を活用することで、従来のチャットインターフェースを超えた強力で信頼性の高いAIシステムを構築できます。

### リソースと参考文献
- **Phi-4モデル**: [Hugging Faceコレクション](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Qwen3ドキュメント**: [公式Qwenドキュメント](https://qwen.readthedocs.io/)
- **Ollama**: [公式ウェブサイト](https://ollama.com/)
- **Foundry Local**: [GitHubリポジトリ](https://github.com/microsoft/Foundry-Local)
- **関数呼び出しのベストプラクティス**: [Hugging Faceガイド](https://huggingface.co/docs/hugs/en/guides/function-calling)

関数呼び出しは進化し続ける分野であり、選択したフレームワークやモデルの最新の進展を常に把握することで、より効果的なAIエージェントを構築することができます。


## ➡️ 次に進むべきこと

- [03: モデルコンテキストプロトコル (MCP) の統合](./03.IntroduceMCP.md)

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があることをご承知ください。元の言語で記載された文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当社は責任を負いません。