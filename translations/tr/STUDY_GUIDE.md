<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T18:17:55+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tr"
}
-->
# EdgeAI için Yeni Başlayanlar: Öğrenme Yolları ve Çalışma Programı

### Yoğunlaştırılmış Öğrenme Yolu (1 hafta)

| Gün | Odak | Tahmini Saat |
|------|-------|------------------|
| Gün 1 | Modül 1: EdgeAI Temelleri | 3 saat |
| Gün 2 | Modül 2: SLM Temelleri | 3 saat |
| Gün 3 | Modül 3: SLM Dağıtımı | 2 saat |
| Gün 4-5 | Modül 4: Model Optimizasyonu (6 framework) | 4 saat |
| Gün 6 | Modül 5: SLMOps | 3 saat |
| Gün 7 | Modül 6-7: AI Ajanları ve Geliştirme Araçları | 5 saat |

### Yoğunlaştırılmış Öğrenme Yolu (2 hafta)

| Gün | Odak | Tahmini Saat |
|------|-------|------------------|
| Gün 1-2 | Modül 1: EdgeAI Temelleri | 3 saat |
| Gün 3-4 | Modül 2: SLM Temelleri | 3 saat |
| Gün 5-6 | Modül 3: SLM Dağıtımı | 2 saat |
| Gün 7-8 | Modül 4: Model Optimizasyonu | 4 saat |
| Gün 9-10 | Modül 5: SLMOps | 3 saat |
| Gün 11-12 | Modül 6: AI Ajanları | 2 saat |
| Gün 13-14 | Modül 7: Geliştirme Araçları | 3 saat |

### Yarı Zamanlı Çalışma (4 hafta)

| Hafta | Odak | Tahmini Saat |
|------|-------|------------------|
| Hafta 1 | Modül 1-2: Temeller ve SLM Temelleri | 6 saat |
| Hafta 2 | Modül 3-4: Dağıtım ve Optimizasyon | 6 saat |
| Hafta 3 | Modül 5-6: SLMOps ve AI Ajanları | 5 saat |
| Hafta 4 | Modül 7: Geliştirme Araçları ve Entegrasyon | 3 saat |

| Gün | Odak | Tahmini Saat |
|------|-------|------------------|
| Gün 1-2 | Modül 1: EdgeAI Temelleri | 3 saat |
| Gün 3-4 | Modül 2: SLM Temelleri | 3 saat |
| Gün 5-6 | Modül 3: SLM Dağıtımı | 2 saat |
| Gün 7-8 | Modül 4: Model Optimizasyonu | 4 saat |
| Gün 9-10 | Modül 5: SLMOps | 3 saat |
| Gün 11-12 | Modül 6: SLM Ajan Sistemleri | 2 saat |
| Gün 13-14 | Modül 7: EdgeAI Uygulama Örnekleri | 2 saat |

| Modül | Tamamlama Tarihi | Harcanan Saat | Ana Çıkarımlar |
|--------|----------------|-------------|--------------|
| Modül 1: EdgeAI Temelleri | | | |
| Modül 2: SLM Temelleri | | | |
| Modül 3: SLM Dağıtımı | | | |
| Modül 4: Model Optimizasyonu (6 framework) | | | |
| Modül 5: SLMOps | | | |
| Modül 6: SLM Ajan Sistemleri | | | |
| Modül 7: EdgeAI Uygulama Örnekleri | | | |
| Uygulamalı Egzersizler | | | |
| Mini Proje | | | |

### Yarı Zamanlı Çalışma (4 hafta)

| Hafta | Odak | Tahmini Saat |
|------|-------|------------------|
| Hafta 1 | Modül 1-2: Temeller ve SLM Temelleri | 6 saat |
| Hafta 2 | Modül 3-4: Dağıtım ve Optimizasyon | 6 saat |
| Hafta 3 | Modül 5-6: SLMOps ve AI Ajanları | 5 saat |
| Hafta 4 | Modül 7: Geliştirme Araçları ve Entegrasyon | 3 saat |

## Giriş

EdgeAI için Yeni Başlayanlar çalışma rehberine hoş geldiniz! Bu belge, kurs materyallerini etkili bir şekilde takip etmenize ve öğrenme deneyiminizi en üst düzeye çıkarmanıza yardımcı olmak için tasarlanmıştır. Yapılandırılmış öğrenme yolları, önerilen çalışma programları, temel kavram özetleri ve EdgeAI teknolojilerini daha iyi anlamanızı sağlayacak ek kaynaklar sunar.

Bu, EdgeAI hakkında temel bilgileri zaman açısından verimli bir formatta sunan, yoğun bir 20 saatlik kurstur. Yoğun programlara sahip profesyoneller ve bu yükselen alanda hızlı bir şekilde pratik beceriler kazanmak isteyen öğrenciler için idealdir.

## Kurs Genel Bakış

Bu kurs, yedi kapsamlı modülden oluşmaktadır:

1. **EdgeAI Temelleri ve Dönüşüm** - Temel kavramları ve teknolojik değişimi anlamak
2. **Küçük Dil Modeli (SLM) Temelleri** - Çeşitli SLM ailelerini ve mimarilerini keşfetmek
3. **Küçük Dil Modeli Dağıtımı** - Pratik dağıtım stratejilerini uygulamak
4. **Model Format Dönüşümü ve Kuantizasyon** - OpenVINO dahil 6 framework ile ileri düzey optimizasyon
5. **SLMOps - Küçük Dil Modeli Operasyonları** - Üretim yaşam döngüsü yönetimi ve dağıtım
6. **SLM Ajan Sistemleri** - AI ajanları, fonksiyon çağrısı ve Model Bağlam Protokolü
7. **EdgeAI Uygulama Örnekleri** - AI Araç Seti, Windows geliştirme ve platforma özel uygulamalar
8. **Microsoft Foundry Local – Tam Geliştirici Araç Seti** - Yerel odaklı geliştirme ve hibrit Azure entegrasyonu (Modül 08)

## Bu Çalışma Rehberi Nasıl Kullanılır

- **Aşamalı Öğrenme**: En tutarlı öğrenme deneyimi için modülleri sırayla takip edin
- **Bilgi Kontrol Noktaları**: Her bölümden sonra kendinizi değerlendirme sorularını kullanın
- **Uygulamalı Pratik**: Teorik kavramları pekiştirmek için önerilen egzersizleri tamamlayın
- **Ek Kaynaklar**: En çok ilgilendiğiniz konular için ek materyalleri keşfedin

## Çalışma Programı Önerileri

### Yoğunlaştırılmış Öğrenme Yolu (1 hafta)

| Gün | Odak | Tahmini Saat |
|------|-------|-----------------|
| Gün 1-2 | Modül 1: EdgeAI Temelleri | 6 saat |
| Gün 3-4 | Modül 2: SLM Temelleri | 8 saat |
| Gün 5 | Modül 3: SLM Dağıtımı | 3 saat |
| Gün 6 | Modül 8: Foundry Local Araç Seti | 3 saat |

### Yarı Zamanlı Çalışma (3 hafta)

| Hafta | Odak | Tahmini Saat |
|------|-------|-----------------|
| Hafta 1 | Modül 1: EdgeAI Temelleri | 6-7 saat |
| Hafta 2 | Modül 2: SLM Temelleri | 7-8 saat |
| Hafta 3 | Modül 3: SLM Dağıtımı (3s) + Modül 8: Foundry Local Araç Seti (2-3s) | 5-6 saat |

## Modül 1: EdgeAI Temelleri ve Dönüşüm

### Temel Öğrenme Hedefleri

- Bulut tabanlı ve uç tabanlı AI arasındaki farkları anlamak
- Kaynak kısıtlı ortamlar için temel optimizasyon tekniklerini öğrenmek
- EdgeAI teknolojilerinin gerçek dünya uygulamalarını analiz etmek
- EdgeAI projeleri için bir geliştirme ortamı kurmak

### Çalışma Odak Alanları

#### Bölüm 1: EdgeAI Temelleri
- **Öncelikli Kavramlar**: 
  - Uç ve Bulut bilişim paradigmaları
  - Model kuantizasyon teknikleri
  - Donanım hızlandırma seçenekleri (NPU'lar, GPU'lar, CPU'lar)
  - Gizlilik ve güvenlik avantajları

- **Ek Kaynaklar**:
  - [TensorFlow Lite Belgeleri](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Belgeleri](https://docs.edgeimpulse.com)

#### Bölüm 2: Gerçek Dünya Vaka Çalışmaları
- **Öncelikli Kavramlar**: 
  - Microsoft Phi & Mu model ekosistemi
  - Endüstrilerdeki pratik uygulamalar
  - Dağıtım dikkate alınması gerekenler

#### Bölüm 3: Pratik Uygulama Rehberi
- **Öncelikli Kavramlar**: 
  - Geliştirme ortamı kurulumu
  - Kuantizasyon ve optimizasyon araçları
  - EdgeAI uygulamaları için değerlendirme yöntemleri

#### Bölüm 4: Uç Dağıtım Donanımı
- **Öncelikli Kavramlar**: 
  - Donanım platform karşılaştırmaları
  - Belirli donanım için optimizasyon stratejileri
  - Dağıtım dikkate alınması gerekenler

### Kendini Değerlendirme Soruları

1. Bulut tabanlı AI ile uç tabanlı AI uygulamalarını karşılaştırın ve karşıtlıklarını açıklayın.
2. Uç dağıtım için modelleri optimize etmek için üç ana teknik açıklayın.
3. AI modellerini uçta çalıştırmanın başlıca avantajları nelerdir?
4. Bir modeli kuantize etme sürecini ve bunun performansı nasıl etkilediğini açıklayın.
5. Farklı donanım hızlandırıcıların (NPU'lar, GPU'lar, CPU'lar) EdgeAI dağıtımını nasıl etkilediğini açıklayın.

### Uygulamalı Egzersizler

1. **Hızlı Ortam Kurulumu**: Temel paketlerle minimal bir geliştirme ortamı yapılandırın (30 dakika)
2. **Model Keşfi**: Önceden eğitilmiş bir küçük dil modelini indirin ve inceleyin (1 saat)
3. **Temel Kuantizasyon**: Küçük bir model üzerinde basit kuantizasyon deneyin (1 saat)

## Modül 2: Küçük Dil Modeli Temelleri

### Temel Öğrenme Hedefleri

- Farklı SLM ailelerinin mimari prensiplerini anlamak
- Farklı parametre ölçeklerinde model yeteneklerini karşılaştırmak
- Verimlilik, yetenek ve dağıtım gereksinimlerine göre modelleri değerlendirmek
- Farklı model aileleri için uygun kullanım senaryolarını tanımak

### Çalışma Odak Alanları

#### Bölüm 1: Microsoft Phi Model Ailesi
- **Öncelikli Kavramlar**: 
  - Tasarım felsefesi evrimi
  - Verimlilik odaklı mimari
  - Özelleşmiş yetenekler

#### Bölüm 2: Qwen Ailesi
- **Öncelikli Kavramlar**: 
  - Açık kaynak katkıları
  - Ölçeklenebilir dağıtım seçenekleri
  - İleri düzey akıl yürütme mimarisi

#### Bölüm 3: Gemma Ailesi
- **Öncelikli Kavramlar**: 
  - Araştırma odaklı yenilik
  - Çok modlu yetenekler
  - Mobil optimizasyon

#### Bölüm 4: BitNET Ailesi
- **Öncelikli Kavramlar**: 
  - 1-bit kuantizasyon teknolojisi
  - Çıkarım optimizasyon çerçevesi
  - Sürdürülebilirlik dikkate alınması gerekenler

#### Bölüm 5: Microsoft Mu Modeli
- **Öncelikli Kavramlar**: 
  - Cihaz odaklı mimari
  - Windows ile sistem entegrasyonu
  - Gizlilik koruyucu operasyon

#### Bölüm 6: Phi-Silica
- **Öncelikli Kavramlar**: 
  - NPU optimizasyonlu mimari
  - Performans metrikleri
  - Geliştirici entegrasyonu

### Kendini Değerlendirme Soruları

1. Phi ve Qwen model ailelerinin mimari yaklaşımlarını karşılaştırın.
2. BitNET'in kuantizasyon teknolojisinin geleneksel kuantizasyondan nasıl farklı olduğunu açıklayın.
3. Windows entegrasyonu için Mu modelinin benzersiz avantajları nelerdir?
4. Phi-Silica'nın NPU donanımını performans optimizasyonu için nasıl kullandığını açıklayın.
5. Sınırlı bağlantıya sahip bir mobil uygulama için hangi model ailesi en uygun olur ve neden?

### Uygulamalı Egzersizler

1. **Model Karşılaştırması**: İki farklı SLM modelinin hızlı bir karşılaştırmasını yapın (1 saat)
2. **Basit Metin Üretimi**: Küçük bir modelle temel metin üretimi uygulaması yapın (1 saat)
3. **Hızlı Optimizasyon**: Çıkarım hızını artırmak için bir optimizasyon tekniği uygulayın (1 saat)

## Modül 3: Küçük Dil Modeli Dağıtımı

### Temel Öğrenme Hedefleri

- Dağıtım kısıtlamalarına göre uygun modelleri seçmek
- Çeşitli dağıtım senaryoları için optimizasyon tekniklerini öğrenmek
- SLM'leri hem yerel hem de bulut ortamlarında uygulamak
- EdgeAI uygulamaları için üretime hazır yapılandırmalar tasarlamak

### Çalışma Odak Alanları

#### Bölüm 1: SLM İleri Düzey Öğrenme
- **Öncelikli Kavramlar**: 
  - Parametre sınıflandırma çerçevesi
  - İleri düzey optimizasyon teknikleri
  - Model edinme stratejileri

#### Bölüm 2: Yerel Ortam Dağıtımı
- **Öncelikli Kavramlar**: 
  - Ollama platform dağıtımı
  - Microsoft Foundry yerel çözümleri
  - Çerçeve karşılaştırmalı analiz

#### Bölüm 3: Konteynerize Bulut Dağıtımı
- **Öncelikli Kavramlar**: 
  - vLLM yüksek performanslı çıkarım
  - Konteyner orkestrasyonu
  - ONNX Runtime uygulaması

### Kendini Değerlendirme Soruları

1. Yerel dağıtım ile bulut dağıtımı arasında seçim yaparken dikkate alınması gereken faktörler nelerdir?
2. Ollama ve Microsoft Foundry Local'ı dağıtım seçenekleri olarak karşılaştırın.
3. SLM dağıtımı için konteynerizasyonun faydalarını açıklayın.
4. Uçta dağıtılmış bir SLM için izlenmesi gereken ana performans metrikleri nelerdir?
5. Model seçiminden üretim uygulamasına kadar tam bir dağıtım iş akışını açıklayın.

### Uygulamalı Egzersizler

1. **Temel Yerel Dağıtım**: Ollama kullanarak basit bir SLM dağıtımı yapın (1 saat)
2. **Performans Kontrolü**: Dağıtılmış modelinizde hızlı bir benchmark çalıştırın (30 dakika)
3. **Basit Entegrasyon**: Dağıtılmış modelinizi kullanan minimal bir uygulama oluşturun (1 saat)

## Modül 4: Model Format Dönüşümü ve Kuantizasyon

### Temel Öğrenme Hedefleri

- 1-bit'ten 8-bit hassasiyete kadar ileri düzey kuantizasyon tekniklerini öğrenmek
- Format dönüşüm stratejilerini anlamak (GGUF, ONNX)
- Altı framework üzerinde optimizasyon uygulamak (Llama.cpp, Olive, OpenVINO, MLX, iş akışı sentezi)
- Intel, Apple ve çapraz platform donanımları için üretim uç ortamlarında optimize edilmiş modelleri dağıtmak

### Çalışma Odak Alanları

#### Bölüm 1: Kuantizasyon Temelleri
- **Öncelikli Kavramlar**: 
  - Hassasiyet sınıflandırma çerçevesi
  - Performans ve doğruluk arasındaki denge
  - Bellek ayak izi optimizasyonu

#### Bölüm 2: Llama.cpp Uygulaması
- **Öncelikli Kavramlar**: 
  - Çapraz platform dağıtımı
  - GGUF format optimizasyonu
  - Donanım hızlandırma teknikleri

#### Bölüm 3: Microsoft Olive Suite
- **Öncelikli Kavramlar**: 
  - Donanım farkındalığı optimizasyonu
  - Kurumsal düzeyde dağıtım
  - Otomatik optimizasyon iş akışları

#### Bölüm 4: OpenVINO Araç Seti
- **Öncelikli Kavramlar**: 
  - Intel donanım optimizasyonu
  - Sinir Ağı Sıkıştırma Çerçevesi (NNCF)
  - Çapraz platform çıkarım dağıtımı
  - OpenVINO GenAI ile LLM dağıtımı

#### Bölüm 5: Apple MLX Framework
- **Öncelikli Kavramlar**:  
  - Apple Silicon optimizasyonu  
  - Birleşik bellek mimarisi  
  - LoRA ince ayar yetenekleri  

#### Bölüm 6: Edge AI Geliştirme İş Akışı Sentezi  
- **Öncelikli Kavramlar**:  
  - Birleşik iş akışı mimarisi  
  - Çerçeve seçimi karar ağaçları  
  - Üretim hazır olma doğrulaması  
  - Geleceğe yönelik stratejiler  

### Kendini Değerlendirme Soruları  

1. Farklı hassasiyet seviyelerinde (1-bitten 8-bite kadar) kuantizasyon stratejilerini karşılaştırın.  
2. GGUF formatının edge dağıtımı için avantajlarını açıklayın.  
3. Microsoft Olive'deki donanım odaklı optimizasyon, dağıtım verimliliğini nasıl artırır?  
4. OpenVINO'nun NNCF'sinin model sıkıştırma için temel faydaları nelerdir?  
5. Apple MLX'in birleşik bellek mimarisini optimizasyon için nasıl kullandığını açıklayın.  
6. İş akışı sentezi, optimal optimizasyon çerçevelerini seçmede nasıl yardımcı olur?  

### Uygulamalı Alıştırmalar  

1. **Model Kuantizasyonu**: Bir modele farklı kuantizasyon seviyeleri uygulayın ve sonuçları karşılaştırın (1 saat)  
2. **OpenVINO Optimizasyonu**: Intel donanımı için bir modeli NNCF kullanarak sıkıştırın (1 saat)  
3. **Çerçeve Karşılaştırması**: Aynı modeli üç farklı optimizasyon çerçevesinde test edin (1 saat)  
4. **Performans Karşılaştırması**: Optimizasyonun çıkarım hızı ve bellek kullanımı üzerindeki etkisini ölçün (1 saat)  

## Modül 5: SLMOps - Küçük Dil Modeli Operasyonları  

### Temel Öğrenme Hedefleri  

- SLMOps yaşam döngüsü yönetimi prensiplerini anlayın  
- Edge dağıtımı için distilasyon ve ince ayar tekniklerinde ustalaşın  
- İzleme ile üretim dağıtım stratejilerini uygulayın  
- Kurumsal düzeyde SLM operasyonları ve bakım iş akışları oluşturun  

### Çalışma Odak Alanları  

#### Bölüm 1: SLMOps'a Giriş  
- **Öncelikli Kavramlar**:  
  - AI operasyonlarında SLMOps paradigma değişimi  
  - Maliyet verimliliği ve gizlilik odaklı mimari  
  - Stratejik iş etkisi ve rekabet avantajları  

#### Bölüm 2: Model Distilasyonu  
- **Öncelikli Kavramlar**:  
  - Bilgi transfer teknikleri  
  - İki aşamalı distilasyon süreci uygulaması  
  - Azure ML distilasyon iş akışları  

#### Bölüm 3: İnce Ayar Stratejileri  
- **Öncelikli Kavramlar**:  
  - Parametre verimli ince ayar (PEFT)  
  - LoRA ve QLoRA gelişmiş yöntemleri  
  - Çoklu adaptör eğitimi ve hiperparametre optimizasyonu  

#### Bölüm 4: Üretim Dağıtımı  
- **Öncelikli Kavramlar**:  
  - Üretim için model dönüştürme ve kuantizasyon  
  - Foundry Local dağıtım yapılandırması  
  - Performans karşılaştırması ve kalite doğrulaması  

### Kendini Değerlendirme Soruları  

1. SLMOps, geleneksel MLOps'tan nasıl farklıdır?  
2. Model distilasyonunun edge dağıtımı için faydalarını açıklayın.  
3. Kaynak kısıtlı ortamlarda SLM'lerin ince ayarı için temel hususlar nelerdir?  
4. Edge AI uygulamaları için tam bir üretim dağıtım hattını açıklayın.  

### Uygulamalı Alıştırmalar  

1. **Temel Distilasyon**: Daha büyük bir öğretmen modelden daha küçük bir model oluşturun (1 saat)  
2. **İnce Ayar Deneyi**: Belirli bir alan için bir modeli ince ayar yapın (1 saat)  
3. **Dağıtım Hattı**: Model dağıtımı için temel bir CI/CD hattı kurun (1 saat)  

## Modül 6: SLM Agentik Sistemler - AI Ajanları ve Fonksiyon Çağrısı  

### Temel Öğrenme Hedefleri  

- Küçük Dil Modelleri kullanarak edge ortamları için akıllı AI ajanları oluşturun  
- Sistematik iş akışları ile fonksiyon çağrısı yeteneklerini uygulayın  
- Standartlaştırılmış araç etkileşimi için Model Context Protocol (MCP) entegrasyonunda ustalaşın  
- Minimum insan müdahalesi ile sofistike agentik sistemler oluşturun  

### Çalışma Odak Alanları  

#### Bölüm 1: AI Ajanları ve SLM Temelleri  
- **Öncelikli Kavramlar**:  
  - Ajan sınıflandırma çerçevesi (refleks, model tabanlı, hedef tabanlı, öğrenen ajanlar)  
  - SLM ve LLM karşılaştırması  
  - Edge'e özgü ajan tasarım desenleri  
  - Ajanlar için kaynak optimizasyonu  

#### Bölüm 2: Küçük Dil Modellerinde Fonksiyon Çağrısı  
- **Öncelikli Kavramlar**:  
  - Sistematik iş akışı uygulaması (niyet algılama, JSON çıktısı, harici yürütme)  
  - Platforma özgü uygulamalar (Phi-4-mini, seçilmiş Qwen modelleri, Microsoft Foundry Local)  
  - Gelişmiş örnekler (çoklu ajan iş birliği, dinamik araç seçimi)  
  - Üretim hususları (hız sınırlama, denetim kaydı, güvenlik önlemleri)  

#### Bölüm 3: Model Context Protocol (MCP) Entegrasyonu  
- **Öncelikli Kavramlar**:  
  - Protokol mimarisi ve katmanlı sistem tasarımı  
  - Çoklu arka uç desteği (Ollama geliştirme için, vLLM üretim için)  
  - Bağlantı protokolleri (STDIO ve SSE modları)  
  - Gerçek dünya uygulamaları (web otomasyonu, veri işleme, API entegrasyonu)  

### Kendini Değerlendirme Soruları  

1. Edge AI ajanları için temel mimari hususlar nelerdir?  
2. Fonksiyon çağrısı ajan yeteneklerini nasıl geliştirir?  
3. Model Context Protocol'ün ajan iletişimindeki rolünü açıklayın.  

### Uygulamalı Alıştırmalar  

1. **Basit Ajan**: Fonksiyon çağrısı ile temel bir AI ajanı oluşturun (1 saat)  
2. **MCP Entegrasyonu**: Bir ajan uygulamasında MCP'yi uygulayın (30 dakika)  

## Modül 7: EdgeAI Uygulama Örnekleri  

### Temel Öğrenme Hedefleri  

- Visual Studio Code için AI Toolkit ile kapsamlı EdgeAI geliştirme iş akışlarında ustalaşın  
- Windows AI Foundry platformu ve NPU optimizasyon stratejilerinde uzmanlaşın  
- EdgeAI'yi birden fazla donanım platformunda ve dağıtım senaryosunda uygulayın  
- Platforma özgü optimizasyonlarla üretime hazır EdgeAI uygulamaları oluşturun  

### Çalışma Odak Alanları  

#### Bölüm 1: Visual Studio Code için AI Toolkit  
- **Öncelikli Kavramlar**:  
  - VS Code içinde kapsamlı Edge AI geliştirme ortamı  
  - Edge dağıtımı için model kataloğu ve keşfi  
  - Yerel test, optimizasyon ve ajan geliştirme iş akışları  
  - Edge senaryoları için performans izleme ve değerlendirme  

#### Bölüm 2: Windows EdgeAI Geliştirme Rehberi  
- **Öncelikli Kavramlar**:  
  - Windows AI Foundry platformunun kapsamlı bir genel görünümü  
  - Phi Silica API ile verimli NPU çıkarımı  
  - Görüntü işleme ve OCR için Bilgisayar Görüşü API'leri  
  - Yerel geliştirme ve test için Foundry Local CLI  

#### Bölüm 3: Platforma Özgü Uygulamalar  
- **Öncelikli Kavramlar**:  
  - NVIDIA Jetson Orin Nano dağıtımı (67 TOPS AI performansı)  
  - .NET MAUI ve ONNX Runtime GenAI ile mobil uygulamalar  
  - Bulut-edge hibrit mimarisi ile Azure EdgeAI çözümleri  
  - Evrensel donanım desteği ile Windows ML optimizasyonu  
  - Gizlilik odaklı RAG uygulaması ile Foundry Local uygulamaları  

### Kendini Değerlendirme Soruları  

1. AI Toolkit, EdgeAI geliştirme iş akışını nasıl kolaylaştırır?  
2. Farklı donanım platformları arasında dağıtım stratejilerini karşılaştırın.  
3. Windows AI Foundry'nin edge geliştirme için avantajları nelerdir?  
4. Modern edge AI uygulamalarında NPU optimizasyonunun rolünü açıklayın.  
5. Phi Silica API, NPU donanımını performans optimizasyonu için nasıl kullanır?  
6. Gizlilik hassas uygulamalar için yerel ve bulut dağıtımının faydalarını karşılaştırın.  

### Uygulamalı Alıştırmalar  

1. **AI Toolkit Kurulumu**: AI Toolkit'i yapılandırın ve bir modeli optimize edin (1 saat)  
2. **Windows AI Foundry**: Phi Silica API kullanarak basit bir Windows AI uygulaması oluşturun (1 saat)  
3. **Çapraz Platform Dağıtımı**: Aynı modeli iki farklı platformda dağıtın (1 saat)  
4. **NPU Optimizasyonu**: Windows AI Foundry araçları ile NPU performansını test edin (30 dakika)  

## Modül 8: Microsoft Foundry Local – Tam Geliştirici Araç Seti  

### Temel Öğrenme Hedefleri  

- Foundry Local'ı Windows üzerinde kurun ve yapılandırın  
- Foundry CLI aracılığıyla modelleri yerel olarak çalıştırın, keşfedin ve yönetin  
- OpenAI uyumlu REST ve SDK istemcileri ile entegre edin  
- Pratik örnekler oluşturun: Chainlit sohbet, ajanlar ve model yönlendirici  
- Azure AI Foundry ile hibrit desenleri anlayın  

### Çalışma Odak Alanları  

- Kurulum ve CLI temel bilgileri (model, hizmet, önbellek)  
- SDK entegrasyonu (OpenAI uyumlu istemciler ve Azure OpenAI)  
- Open WebUI hızlı doğrulama  
- Ajanlar ve fonksiyon çağrısı desenleri  
- Araç olarak modeller (yönlendirici ve kayıt tasarımı)  

### Kendini Değerlendirme Soruları  

1. Yerel uç noktayı nasıl keşfeder ve mevcut modelleri nasıl listeleyebilirsiniz?  
2. Foundry Local REST ve Azure OpenAI kullanımı arasındaki farklar nelerdir?  
3. Araç olarak modelleri seçmek için basit bir yönlendirici nasıl tasarlarsınız?  
4. Günlük geliştirme için en alakalı CLI kategorileri hangileridir?  
5. Uygulamaları çalıştırmadan önce Foundry Local hazır olup olmadığını nasıl doğrularsınız?  

### Uygulamalı Alıştırmalar  

1. Foundry Local'ı kurun/güncelleyin ve `phi-4-mini` modelini yerel olarak çalıştırın (30 dakika)  
2. `/v1/models` çağrısı yapın ve REST üzerinden basit bir sohbet çalıştırın (30 dakika)  
3. Chainlit uygulama örneğini başlatın ve yerel olarak sohbet edin (30 dakika)  
4. Çoklu ajan koordinatörünü çalıştırın ve çıktıları inceleyin (30 dakika)  
5. Çevreye dayalı geçersiz kılmalarla araç olarak modeller yönlendiricisini deneyin (30 dakika)  

## Zaman Ayırma Rehberi  

20 saatlik kurs zaman çizelgesinden en iyi şekilde yararlanmanıza yardımcı olmak için önerilen bir zaman dağılımı:  

| Aktivite | Zaman Ayırma | Açıklama |  
|----------|--------------|----------|  
| Temel Materyalleri Okuma | 9 saat | Her modüldeki temel kavramlara odaklanma |  
| Uygulamalı Alıştırmalar | 6 saat | Temel tekniklerin pratik uygulaması |  
| Kendini Değerlendirme | 2 saat | Sorular ve düşünce yoluyla anlayışınızı test etme |  
| Mini Proje | 3 saat | Küçük bir pratik uygulamaya bilgi uygulama |  

### Zaman Kısıtlamasına Göre Ana Odak Alanları  

**Sadece 10 saatiniz varsa:**  
- Modül 1, 2 ve 3'ü tamamlayın (temel EdgeAI kavramları)  
- Her modülden en az bir uygulamalı alıştırma yapın  
- Uygulama detaylarından ziyade temel kavramları anlamaya odaklanın  

**Tam 20 saat ayırabiliyorsanız:**  
- Tüm yedi modülü tamamlayın  
- Her modülden temel uygulamalı alıştırmaları gerçekleştirin  
- Modül 7'den bir mini proje tamamlayın  
- En az 2-3 ek kaynağı keşfedin  

**20 saatten fazla zamanınız varsa:**  
- Tüm modülleri detaylı alıştırmalarla tamamlayın  
- Birden fazla mini proje oluşturun  
- Modül 4'teki gelişmiş optimizasyon tekniklerini keşfedin  
- Modül 5'ten üretim dağıtımını uygulayın  

## Temel Kaynaklar  

Bu dikkatle seçilmiş kaynaklar sınırlı çalışma süreniz için en fazla değeri sağlar:  

### Mutlaka Okunması Gereken Belgeler  
- [ONNX Runtime Başlangıç Kılavuzu](https://onnxruntime.ai/docs/get-started/with-python.html) - En verimli model optimizasyon aracı  
- [Ollama Hızlı Başlangıç](https://github.com/ollama/ollama#get-started) - SLM'leri yerel olarak dağıtmanın en hızlı yolu  
- [Microsoft Phi Model Kartı](https://huggingface.co/microsoft/phi-2) - Önde gelen edge-optimize edilmiş model için referans  
- [OpenVINO Belgeleri](https://docs.openvino.ai/2025/index.html) - Intel'in kapsamlı optimizasyon araç seti  
- [VS Code için AI Toolkit](https://code.visualstudio.com/docs/intelligentapps/overview) - Entegre EdgeAI geliştirme ortamı  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows'a özgü EdgeAI geliştirme platformu  

### Zaman Kazandıran Araçlar  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Hızlı model erişimi ve dağıtımı  
- [Gradio](https://www.gradio.app/docs/interface) - AI demoları için hızlı UI geliştirme  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Basitleştirilmiş model optimizasyonu  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Verimli CPU çıkarımı  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Sinir ağı sıkıştırma çerçevesi  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Büyük dil modeli dağıtım araç seti  

## İlerleme Takip Şablonu  

20 saatlik kurs boyunca öğrenme ilerlemenizi takip etmek için bu basitleştirilmiş şablonu kullanın:  

| Modül | Tamamlama Tarihi | Harcanan Saat | Temel Çıkarımlar |  
|-------|------------------|---------------|------------------|  
| Modül 1: EdgeAI Temelleri | | | |  
| Modül 2: SLM Temelleri | | | |  
| Modül 3: SLM Dağıtımı | | | |  
| Modül 4: Model Optimizasyonu | | | |  
| Modül 5: SLMOps | | | |  
| Modül 6: AI Ajanları | | | |  
| Modül 7: Geliştirme Araçları | | | |  
| Modül 8: Foundry Local Araç Seti | | | |  
| Uygulamalı Alıştırmalar | | | |  
| Mini Proje | | | |  

## Mini Proje Fikirleri  

EdgeAI kavramlarını uygulamak için bu projelerden birini tamamlamayı düşünün (her biri 2-4 saat sürmek üzere tasarlanmıştır):  

### Başlangıç Seviyesi Projeler (2-3 saat)  
1. **Edge Metin Asistanı**: Küçük bir dil modeli kullanarak basit bir çevrimdışı metin tamamlama aracı oluşturun  
2. **Model Karşılaştırma Panosu**: Farklı SLM'ler arasındaki performans metriklerinin görselleştirilmesini sağlayan temel bir gösterge panosu oluşturun  
3. **Optimizasyon Deneyi**: Aynı temel modelde farklı kuantizasyon seviyelerinin etkisini ölçün  

### Orta Seviye Projeler (3-4 saat)  
4. **AI Toolkit İş Akışı**: VS Code AI Toolkit kullanarak bir modeli baştan sona optimize edin ve dağıtın  
5. **Windows AI Foundry Uygulaması**: Phi Silica API ve NPU optimizasyonu kullanarak bir Windows uygulaması oluşturun  
6. **Çapraz Platform Dağıtımı**: Optimize edilmiş aynı modeli Windows (OpenVINO) ve mobil (.NET MAUI) üzerinde dağıtın  
7. **Fonksiyon Çağrısı Ajanı**: Edge senary
8. **OpenVINO Optimizasyon Süreci**: NNCF ve GenAI araç setini kullanarak tam model optimizasyonunu uygulayın  
9. **SLMOps Süreci**: Model yaşam döngüsünü eğitimden uç cihaz dağıtımına kadar eksiksiz bir şekilde uygulayın  
10. **Çoklu Model Uç Sistem**: Uç donanımda birlikte çalışan birden fazla özel modeli dağıtın  
11. **MCP Entegrasyon Sistemi**: Araç etkileşimi için Model Context Protocol kullanarak bir ajan sistem oluşturun  

## Kaynaklar  

- Microsoft Learn (Foundry Local)  
  - Genel Bakış: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Başlarken: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI referansı: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Çıkarım SDK'ları ile entegrasyon: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI nasıl yapılır: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Hugging Face modellerini derleme: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Genel Bakış: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Ajanlar (genel bakış): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimizasyon ve Çıkarım Araçları  
  - Microsoft Olive (dokümanlar): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (başlarken): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive entegrasyonu: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (dokümanlar): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (dokümanlar): https://ml-explore.github.io/mlx/build/html/index.html  
- Dağıtım Çerçeveleri ve Modeller  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (dokümanlar): https://docs.vllm.ai/  
  - Ollama (hızlı başlangıç): https://github.com/ollama/ollama#get-started  
- Geliştirici Araçları (Windows ve VS Code)  
  - VS Code için AI Araç Seti: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (genel bakış): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Öğrenme Topluluğu  

Tartışmalara katılın ve diğer öğrenenlerle bağlantı kurun:  
- [EdgeAI for Beginners deposunda GitHub Tartışmaları](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Sonuç  

EdgeAI, yapay zekanın uygulanmasında öncü bir alanı temsil eder ve güçlü yetenekleri doğrudan cihazlara getirirken gizlilik, gecikme ve bağlantı sorunlarını ele alır. Bu 20 saatlik kurs, EdgeAI teknolojileriyle hemen çalışmaya başlamak için gerekli temel bilgileri ve pratik becerileri sağlar.  

Kurs, en önemli kavramlara odaklanarak kasıtlı olarak kısa ve öz tutulmuştur, böylece aşırı zaman harcamadan değerli uzmanlık kazanabilirsiniz. Öğrendiklerinizi pekiştirmenin anahtarı, basit örneklerle bile olsa uygulamalı pratik yapmaktır.  

İyi öğrenmeler!  

---

