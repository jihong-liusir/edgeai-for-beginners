<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-24T21:28:39+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tr"
}
-->
# EdgeAI için Yeni Başlayanlar: Öğrenme Yolları ve Çalışma Programı

### Yoğunlaştırılmış Öğrenme Yolu (1 hafta)

| Gün | Odak | Tahmini Süre |
|------|-------|------------------|
| Gün 1 | Modül 1: EdgeAI Temelleri | 3 saat |
| Gün 2 | Modül 2: SLM Temelleri | 3 saat |
| Gün 3 | Modül 3: SLM Dağıtımı | 2 saat |
| Gün 4-5 | Modül 4: Model Optimizasyonu (6 framework) | 4 saat |
| Gün 6 | Modül 5: SLMOps | 3 saat |
| Gün 7 | Modül 6-7: AI Ajanları ve Geliştirme Araçları | 4 saat |
| Gün 8 | Modül 8: Foundry Yerel Araç Seti (Modern Uygulama) | 1 saat |

### Yoğunlaştırılmış Öğrenme Yolu (2 hafta)

| Gün | Odak | Tahmini Süre |
|------|-------|------------------|
| Gün 1-2 | Modül 1: EdgeAI Temelleri | 3 saat |
| Gün 3-4 | Modül 2: SLM Temelleri | 3 saat |
| Gün 5-6 | Modül 3: SLM Dağıtımı | 2 saat |
| Gün 7-8 | Modül 4: Model Optimizasyonu | 4 saat |
| Gün 9-10 | Modül 5: SLMOps | 3 saat |
| Gün 11-12 | Modül 6: AI Ajanları | 2 saat |
| Gün 13-14 | Modül 7: Geliştirme Araçları | 3 saat |

### Yarı Zamanlı Çalışma (4 hafta)

| Hafta | Odak | Tahmini Süre |
|------|-------|------------------|
| Hafta 1 | Modül 1-2: Temeller ve SLM Temelleri | 6 saat |
| Hafta 2 | Modül 3-4: Dağıtım ve Optimizasyon | 6 saat |
| Hafta 3 | Modül 5-6: SLMOps ve AI Ajanları | 5 saat |
| Hafta 4 | Modül 7: Geliştirme Araçları ve Entegrasyon | 3 saat |

| Gün | Odak | Tahmini Süre |
|------|-------|------------------|
| Gün 1-2 | Modül 1: EdgeAI Temelleri | 3 saat |
| Gün 3-4 | Modül 2: SLM Temelleri | 3 saat |
| Gün 5-6 | Modül 3: SLM Dağıtımı | 2 saat |
| Gün 7-8 | Modül 4: Model Optimizasyonu | 4 saat |
| Gün 9-10 | Modül 5: SLMOps | 3 saat |
| Gün 11-12 | Modül 6: SLM Ajan Sistemleri | 2 saat |
| Gün 13-14 | Modül 7: EdgeAI Uygulama Örnekleri | 2 saat |

| Modül | Tamamlanma Tarihi | Harcanan Süre | Ana Çıkarımlar |
|--------|----------------|-------------|--------------|
| Modül 1: EdgeAI Temelleri | | | |
| Modül 2: SLM Temelleri | | | |
| Modül 3: SLM Dağıtımı | | | |
| Modül 4: Model Optimizasyonu (6 framework) | | | |
| Modül 5: SLMOps | | | |
| Modül 6: SLM Ajan Sistemleri | | | |
| Modül 7: EdgeAI Uygulama Örnekleri | | | |
| Uygulamalı Egzersizler | | | |
| Mini Proje | | | |

### Yarı Zamanlı Çalışma (4 hafta)

| Hafta | Odak | Tahmini Süre |
|------|-------|------------------|
| Hafta 1 | Modül 1-2: Temeller ve SLM Temelleri | 6 saat |
| Hafta 2 | Modül 3-4: Dağıtım ve Optimizasyon | 6 saat |
| Hafta 3 | Modül 5-6: SLMOps ve AI Ajanları | 5 saat |
| Hafta 4 | Modül 7: Geliştirme Araçları ve Entegrasyon | 3 saat |

## Giriş

EdgeAI için Yeni Başlayanlar çalışma rehberine hoş geldiniz! Bu belge, kurs materyallerini etkili bir şekilde takip etmenize ve öğrenme deneyiminizi en üst düzeye çıkarmanıza yardımcı olmak için tasarlanmıştır. Yapılandırılmış öğrenme yolları, önerilen çalışma programları, anahtar kavram özetleri ve EdgeAI teknolojilerini daha iyi anlamanızı sağlayacak ek kaynaklar sunar.

Bu, EdgeAI hakkında temel bilgileri zaman açısından verimli bir formatta sunan, yoğun bir 20 saatlik kurstur. Yoğun programlara sahip profesyoneller ve bu yükselen alanda hızlı bir şekilde pratik beceriler kazanmak isteyen öğrenciler için idealdir.

## Kurs Genel Bakış

Bu kurs, yedi kapsamlı modülden oluşmaktadır:

1. **EdgeAI Temelleri ve Dönüşüm** - Temel kavramları ve teknolojik değişimi anlamak
2. **Küçük Dil Modeli (SLM) Temelleri** - Çeşitli SLM ailelerini ve mimarilerini keşfetmek
3. **Küçük Dil Modeli Dağıtımı** - Pratik dağıtım stratejilerini uygulamak
4. **Model Format Dönüşümü ve Kuantizasyon** - OpenVINO dahil olmak üzere 6 framework ile ileri düzey optimizasyon
5. **SLMOps - Küçük Dil Modeli Operasyonları** - Üretim yaşam döngüsü yönetimi ve dağıtım
6. **SLM Ajan Sistemleri** - AI ajanları, işlev çağrısı ve Model Bağlam Protokolü
7. **EdgeAI Uygulama Örnekleri** - AI Araç Seti, Windows geliştirme ve platforma özgü uygulamalar
8. **Microsoft Foundry Yerel – Tam Geliştirici Araç Seti** - Yerel odaklı geliştirme ve hibrit Azure entegrasyonu (Modül 08)

## Bu Çalışma Rehberi Nasıl Kullanılır

- **Aşamalı Öğrenme**: En tutarlı öğrenme deneyimi için modülleri sırayla takip edin
- **Bilgi Kontrol Noktaları**: Her bölümden sonra kendinizi değerlendirme sorularını kullanın
- **Uygulamalı Pratik**: Teorik kavramları pekiştirmek için önerilen egzersizleri tamamlayın
- **Ek Kaynaklar**: İlginizi çeken konular için ek materyalleri keşfedin

## Çalışma Programı Önerileri

### Yoğunlaştırılmış Öğrenme Yolu (1 hafta)

| Gün | Odak | Tahmini Süre |
|------|-------|-----------------|
| Gün 1-2 | Modül 1: EdgeAI Temelleri | 6 saat |
| Gün 3-4 | Modül 2: SLM Temelleri | 8 saat |
| Gün 5 | Modül 3: SLM Dağıtımı | 3 saat |
| Gün 6 | Modül 8: Foundry Yerel Araç Seti | 3 saat |

### Yarı Zamanlı Çalışma (3 hafta)

| Hafta | Odak | Tahmini Süre |
|------|-------|-----------------|
| Hafta 1 | Modül 1: EdgeAI Temelleri | 6-7 saat |
| Hafta 2 | Modül 2: SLM Temelleri | 7-8 saat |
| Hafta 3 | Modül 3: SLM Dağıtımı (3 saat) + Modül 8: Foundry Yerel Araç Seti (2-3 saat) | 5-6 saat |

## Modül 1: EdgeAI Temelleri ve Dönüşüm

### Ana Öğrenme Hedefleri

- Bulut tabanlı ve uç tabanlı AI arasındaki farkları anlamak
- Kaynak kısıtlı ortamlar için temel optimizasyon tekniklerini öğrenmek
- EdgeAI teknolojilerinin gerçek dünya uygulamalarını analiz etmek
- EdgeAI projeleri için bir geliştirme ortamı kurmak

### Çalışma Odak Alanları

#### Bölüm 1: EdgeAI Temelleri
- **Öncelikli Kavramlar**: 
  - Uç ve Bulut bilişim paradigmaları
  - Model kuantizasyon teknikleri
  - Donanım hızlandırma seçenekleri (NPU'lar, GPU'lar, CPU'lar)
  - Gizlilik ve güvenlik avantajları

- **Ek Kaynaklar**:
  - [TensorFlow Lite Belgeleri](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Belgeleri](https://docs.edgeimpulse.com)

#### Bölüm 2: Gerçek Dünya Vaka Çalışmaları
- **Öncelikli Kavramlar**: 
  - Microsoft Phi & Mu model ekosistemi
  - Endüstrilerdeki pratik uygulamalar
  - Dağıtım dikkate alınması gerekenler

#### Bölüm 3: Pratik Uygulama Rehberi
- **Öncelikli Kavramlar**: 
  - Geliştirme ortamı kurulumu
  - Kuantizasyon ve optimizasyon araçları
  - EdgeAI uygulamaları için değerlendirme yöntemleri

#### Bölüm 4: Uç Dağıtım Donanımı
- **Öncelikli Kavramlar**: 
  - Donanım platform karşılaştırmaları
  - Belirli donanımlar için optimizasyon stratejileri
  - Dağıtım dikkate alınması gerekenler

### Kendini Değerlendirme Soruları

1. Bulut tabanlı AI ile uç tabanlı AI uygulamalarını karşılaştırın ve farklılıklarını açıklayın.
2. Uç dağıtım için modelleri optimize etmek için üç anahtar tekniği açıklayın.
3. AI modellerini uçta çalıştırmanın başlıca avantajları nelerdir?
4. Bir modeli kuantize etme sürecini ve bunun performansı nasıl etkilediğini açıklayın.
5. Farklı donanım hızlandırıcıların (NPU'lar, GPU'lar, CPU'lar) EdgeAI dağıtımını nasıl etkilediğini açıklayın.

### Uygulamalı Egzersizler

1. **Hızlı Ortam Kurulumu**: Temel paketlerle minimal bir geliştirme ortamı yapılandırın (30 dakika)
2. **Model Keşfi**: Önceden eğitilmiş bir küçük dil modelini indirin ve inceleyin (1 saat)
3. **Temel Kuantizasyon**: Küçük bir model üzerinde basit kuantizasyon deneyin (1 saat)

## Modül 2: Küçük Dil Modeli Temelleri

### Ana Öğrenme Hedefleri

- Farklı SLM ailelerinin mimari prensiplerini anlamak
- Farklı parametre ölçeklerinde model yeteneklerini karşılaştırmak
- Verimlilik, yetenek ve dağıtım gereksinimlerine göre modelleri değerlendirmek
- Farklı model aileleri için uygun kullanım senaryolarını tanımak

### Çalışma Odak Alanları

#### Bölüm 1: Microsoft Phi Model Ailesi
- **Öncelikli Kavramlar**: 
  - Tasarım felsefesi evrimi
  - Verimlilik odaklı mimari
  - Özelleşmiş yetenekler

#### Bölüm 2: Qwen Ailesi
- **Öncelikli Kavramlar**: 
  - Açık kaynak katkıları
  - Ölçeklenebilir dağıtım seçenekleri
  - İleri düzey akıl yürütme mimarisi

#### Bölüm 3: Gemma Ailesi
- **Öncelikli Kavramlar**: 
  - Araştırma odaklı yenilik
  - Çok modlu yetenekler
  - Mobil optimizasyon

#### Bölüm 4: BitNET Ailesi
- **Öncelikli Kavramlar**: 
  - 1-bit kuantizasyon teknolojisi
  - Çıkarım optimizasyon çerçevesi
  - Sürdürülebilirlik dikkate alınması gerekenler

#### Bölüm 5: Microsoft Mu Modeli
- **Öncelikli Kavramlar**: 
  - Cihaz odaklı mimari
  - Windows ile sistem entegrasyonu
  - Gizlilik koruyucu çalışma

#### Bölüm 6: Phi-Silica
- **Öncelikli Kavramlar**: 
  - NPU'ya optimize edilmiş mimari
  - Performans metrikleri
  - Geliştirici entegrasyonu

### Kendini Değerlendirme Soruları

1. Phi ve Qwen model ailelerinin mimari yaklaşımlarını karşılaştırın.
2. BitNET'in kuantizasyon teknolojisinin geleneksel kuantizasyondan nasıl farklı olduğunu açıklayın.
3. Windows entegrasyonu için Mu modelinin benzersiz avantajları nelerdir?
4. Phi-Silica'nın performans optimizasyonu için NPU donanımını nasıl kullandığını açıklayın.
5. Sınırlı bağlantıya sahip bir mobil uygulama için hangi model ailesi en uygun olur ve neden?

### Uygulamalı Egzersizler

1. **Model Karşılaştırması**: İki farklı SLM modelinin hızlı bir karşılaştırmasını yapın (1 saat)
2. **Basit Metin Üretimi**: Küçük bir modelle metin üretiminin temel bir uygulamasını gerçekleştirin (1 saat)
3. **Hızlı Optimizasyon**: Çıkarım hızını artırmak için bir optimizasyon tekniği uygulayın (1 saat)

## Modül 3: Küçük Dil Modeli Dağıtımı

### Ana Öğrenme Hedefleri

- Dağıtım kısıtlamalarına göre uygun modelleri seçmek
- Çeşitli dağıtım senaryoları için optimizasyon tekniklerini öğrenmek
- SLM'leri hem yerel hem de bulut ortamlarında uygulamak
- EdgeAI uygulamaları için üretime hazır yapılandırmalar tasarlamak

### Çalışma Odak Alanları

#### Bölüm 1: SLM İleri Düzey Öğrenme
- **Öncelikli Kavramlar**: 
  - Parametre sınıflandırma çerçevesi
  - İleri düzey optimizasyon teknikleri
  - Model edinme stratejileri

#### Bölüm 2: Yerel Ortam Dağıtımı
- **Öncelikli Kavramlar**: 
  - Ollama platform dağıtımı
  - Microsoft Foundry yerel çözümleri
  - Çerçeve karşılaştırmalı analiz

#### Bölüm 3: Konteynerize Bulut Dağıtımı
- **Öncelikli Kavramlar**: 
  - vLLM yüksek performanslı çıkarım
  - Konteyner orkestrasyonu
  - ONNX Runtime uygulaması

### Kendini Değerlendirme Soruları

1. Yerel dağıtım ile bulut dağıtımı arasında seçim yaparken dikkate alınması gereken faktörler nelerdir?
2. Ollama ve Microsoft Foundry Yerel'i dağıtım seçenekleri olarak karşılaştırın.
3. SLM dağıtımı için konteynerizasyonun faydalarını açıklayın.
4. Uçta dağıtılmış bir SLM için izlenmesi gereken ana performans metrikleri nelerdir?
5. Model seçiminden üretim uygulamasına kadar tam bir dağıtım iş akışını açıklayın.

### Uygulamalı Egzersizler

1. **Temel Yerel Dağıtım**: Ollama kullanarak basit bir SLM dağıtımı gerçekleştirin (1 saat)
2. **Performans Kontrolü**: Dağıtılmış modelinizde hızlı bir benchmark çalıştırın (30 dakika)
3. **Basit Entegrasyon**: Dağıtılmış modelinizi kullanan minimal bir uygulama oluşturun (1 saat)

## Modül 4: Model Format Dönüşümü ve Kuantizasyon

### Ana Öğrenme Hedefleri

- 1-bit'ten 8-bit hassasiyete kadar ileri düzey kuantizasyon tekniklerini öğrenmek
- Format dönüşüm stratejilerini anlamak (GGUF, ONNX)
- Altı framework üzerinde optimizasyon uygulamak (Llama.cpp, Olive, OpenVINO, MLX, iş akışı sentezi)
- Intel, Apple ve çapraz platform donanımları için üretim uç ortamlarında optimize edilmiş modelleri dağıtmak

### Çalışma Odak Alanları

#### Bölüm 1: Kuantizasyon Temelleri
- **Öncelikli Kavramlar**: 
  - Hassasiyet sınıflandırma çerçevesi
  - Performans ve doğruluk arasındaki denge
  - Bellek ayak izi optimizasyonu

#### Bölüm 2: Llama.cpp Uygulaması
- **Öncelikli Kavramlar**: 
  - Çapraz platform dağıtımı
  - GGUF format optimizasyonu
  - Donanım hızlandırma teknikleri

#### Bölüm 3: Microsoft Olive Suite
- **Öncelikli Kavramlar**: 
  - Donanım farkındalığı ile optimizasyon
  - Kurumsal düzeyde dağıtım
  - Otomatik optimizasyon iş akışları

#### Bölüm 4: OpenVINO Araç Seti
- **Öncelikli Kavramlar**: 
  - Intel donanım optimizasyonu
  - Sinir Ağı Sıkıştırma Çerçevesi (NNCF)
  - Çapraz platform çıkarım dağıtımı
- OpenVINO GenAI ile LLM dağıtımı

#### Bölüm 5: Apple MLX Framework
- **Öncelikli Kavramlar**: 
  - Apple Silicon optimizasyonu
  - Birleşik bellek mimarisi
  - LoRA ince ayar yetenekleri

#### Bölüm 6: Edge AI Geliştirme İş Akışı Sentezi
- **Öncelikli Kavramlar**: 
  - Birleşik iş akışı mimarisi
  - Framework seçimi karar ağaçları
  - Üretim hazır olma doğrulaması
  - Geleceğe yönelik stratejiler

### Kendini Değerlendirme Soruları

1. Farklı hassasiyet seviyelerinde (1-bitten 8-bite kadar) kuantizasyon stratejilerini karşılaştırın.
2. Edge dağıtımı için GGUF formatının avantajlarını açıklayın.
3. Microsoft Olive'deki donanım farkındalığı optimizasyonu, dağıtım verimliliğini nasıl artırır?
4. OpenVINO'nun NNCF'sinin model sıkıştırma için sunduğu temel avantajlar nelerdir?
5. Apple MLX'in birleşik bellek mimarisini optimizasyon için nasıl kullandığını açıklayın.
6. İş akışı sentezi, optimal optimizasyon frameworklerini seçmede nasıl yardımcı olur?

### Uygulamalı Alıştırmalar

1. **Model Kuantizasyonu**: Bir modele farklı kuantizasyon seviyeleri uygulayın ve sonuçları karşılaştırın (1 saat)
2. **OpenVINO Optimizasyonu**: Intel donanımı için bir modeli NNCF ile sıkıştırın (1 saat)
3. **Framework Karşılaştırması**: Aynı modeli üç farklı optimizasyon frameworkünde test edin (1 saat)
4. **Performans Karşılaştırması**: Optimizasyonun çıkarım hızı ve bellek kullanımı üzerindeki etkisini ölçün (1 saat)

## Modül 5: SLMOps - Küçük Dil Modeli Operasyonları

### Temel Öğrenme Hedefleri

- SLMOps yaşam döngüsü yönetimi prensiplerini anlayın
- Edge dağıtımı için distilasyon ve ince ayar tekniklerini öğrenin
- İzleme ile üretim dağıtım stratejilerini uygulayın
- Kurumsal düzeyde SLM operasyonları ve bakım iş akışları oluşturun

### Çalışma Odak Alanları

#### Bölüm 1: SLMOps'a Giriş
- **Öncelikli Kavramlar**: 
  - SLMOps'un AI operasyonlarındaki paradigma değişimi
  - Maliyet etkinliği ve gizlilik odaklı mimari
  - Stratejik iş etkisi ve rekabet avantajları

#### Bölüm 2: Model Distilasyonu
- **Öncelikli Kavramlar**: 
  - Bilgi transfer teknikleri
  - İki aşamalı distilasyon süreci uygulaması
  - Azure ML distilasyon iş akışları

#### Bölüm 3: İnce Ayar Stratejileri
- **Öncelikli Kavramlar**: 
  - Parametre verimli ince ayar (PEFT)
  - LoRA ve QLoRA ileri düzey yöntemleri
  - Çoklu adaptör eğitimi ve hiperparametre optimizasyonu

#### Bölüm 4: Üretim Dağıtımı
- **Öncelikli Kavramlar**: 
  - Üretim için model dönüştürme ve kuantizasyon
  - Foundry Local dağıtım yapılandırması
  - Performans karşılaştırması ve kalite doğrulaması

### Kendini Değerlendirme Soruları

1. SLMOps, geleneksel MLOps'tan nasıl farklıdır?
2. Edge dağıtımı için model distilasyonunun faydalarını açıklayın.
3. Kaynak kısıtlı ortamlarda SLM'lerin ince ayarı için temel hususlar nelerdir?
4. Edge AI uygulamaları için tam bir üretim dağıtım hattını açıklayın.

### Uygulamalı Alıştırmalar

1. **Temel Distilasyon**: Daha büyük bir öğretmen modelden daha küçük bir model oluşturun (1 saat)
2. **İnce Ayar Deneyi**: Belirli bir alan için bir modeli ince ayar yapın (1 saat)
3. **Dağıtım Hattı**: Model dağıtımı için temel bir CI/CD hattı kurun (1 saat)

## Modül 6: SLM Agentic Systems - AI Ajanları ve Fonksiyon Çağrısı

### Temel Öğrenme Hedefleri

- Küçük Dil Modelleri kullanarak edge ortamları için akıllı AI ajanları oluşturun
- Sistematik iş akışları ile fonksiyon çağrısı yeteneklerini uygulayın
- Standartlaştırılmış araç etkileşimi için Model Context Protocol (MCP) entegrasyonunu öğrenin
- Minimum insan müdahalesi ile sofistike ajan sistemleri oluşturun

### Çalışma Odak Alanları

#### Bölüm 1: AI Ajanları ve SLM Temelleri
- **Öncelikli Kavramlar**: 
  - Ajan sınıflandırma çerçevesi (refleks, model tabanlı, hedef tabanlı, öğrenen ajanlar)
  - SLM ve LLM arasındaki denge analizi
  - Edge'e özgü ajan tasarım desenleri
  - Ajanlar için kaynak optimizasyonu

#### Bölüm 2: Küçük Dil Modellerinde Fonksiyon Çağrısı
- **Öncelikli Kavramlar**: 
  - Sistematik iş akışı uygulaması (niyet algılama, JSON çıktısı, harici yürütme)
  - Platforma özgü uygulamalar (Phi-4-mini, seçilmiş Qwen modelleri, Microsoft Foundry Local)
  - İleri düzey örnekler (çoklu ajan iş birliği, dinamik araç seçimi)
  - Üretim hususları (hız sınırlama, denetim kaydı, güvenlik önlemleri)

#### Bölüm 3: Model Context Protocol (MCP) Entegrasyonu
- **Öncelikli Kavramlar**: 
  - Protokol mimarisi ve katmanlı sistem tasarımı
  - Çoklu backend desteği (Ollama geliştirme için, vLLM üretim için)
  - Bağlantı protokolleri (STDIO ve SSE modları)
  - Gerçek dünya uygulamaları (web otomasyonu, veri işleme, API entegrasyonu)

### Kendini Değerlendirme Soruları

1. Edge AI ajanları için temel mimari hususlar nelerdir?
2. Fonksiyon çağrısı ajan yeteneklerini nasıl geliştirir?
3. Model Context Protocol'ün ajan iletişimindeki rolünü açıklayın.

### Uygulamalı Alıştırmalar

1. **Basit Ajan**: Fonksiyon çağrısı ile temel bir AI ajanı oluşturun (1 saat)
2. **MCP Entegrasyonu**: Bir ajan uygulamasında MCP'yi uygulayın (30 dakika)

## Modül 7: EdgeAI Uygulama Örnekleri

### Temel Öğrenme Hedefleri

- Visual Studio Code için AI Toolkit ile kapsamlı EdgeAI geliştirme iş akışlarını öğrenin
- Windows AI Foundry platformu ve NPU optimizasyon stratejileri konusunda uzmanlaşın
- Çeşitli donanım platformları ve dağıtım senaryolarında EdgeAI uygulayın
- Platforma özgü optimizasyonlarla üretime hazır EdgeAI uygulamaları oluşturun

### Çalışma Odak Alanları

#### Bölüm 1: Visual Studio Code için AI Toolkit
- **Öncelikli Kavramlar**: 
  - VS Code içinde kapsamlı Edge AI geliştirme ortamı
  - Edge dağıtımı için model kataloğu ve keşfi
  - Yerel test, optimizasyon ve ajan geliştirme iş akışları
  - Edge senaryoları için performans izleme ve değerlendirme

#### Bölüm 2: Windows EdgeAI Geliştirme Kılavuzu
- **Öncelikli Kavramlar**: 
  - Windows AI Foundry platformunun kapsamlı bir genel bakışı
  - NPU çıkarımı için Phi Silica API
  - Görüntü işleme ve OCR için Bilgisayar Görüşü API'leri
  - Yerel geliştirme ve test için Foundry Local CLI

#### Bölüm 3: Platforma Özgü Uygulamalar
- **Öncelikli Kavramlar**: 
  - NVIDIA Jetson Orin Nano dağıtımı (67 TOPS AI performansı)
  - .NET MAUI ve ONNX Runtime GenAI ile mobil uygulamalar
  - Bulut-edge hibrit mimarisi ile Azure EdgeAI çözümleri
  - Evrensel donanım desteği ile Windows ML optimizasyonu
  - Gizlilik odaklı RAG uygulaması ile Foundry Local uygulamaları

### Kendini Değerlendirme Soruları

1. AI Toolkit, EdgeAI geliştirme iş akışını nasıl kolaylaştırır?
2. Farklı donanım platformları arasında dağıtım stratejilerini karşılaştırın.
3. Edge geliştirme için Windows AI Foundry'nin avantajları nelerdir?
4. Modern edge AI uygulamalarında NPU optimizasyonunun rolünü açıklayın.
5. Phi Silica API, NPU donanımını performans optimizasyonu için nasıl kullanır?
6. Gizlilik hassas uygulamalar için yerel ve bulut dağıtımının faydalarını karşılaştırın.

### Uygulamalı Alıştırmalar

1. **AI Toolkit Kurulumu**: AI Toolkit'i yapılandırın ve bir modeli optimize edin (1 saat)
2. **Windows AI Foundry**: Phi Silica API kullanarak basit bir Windows AI uygulaması oluşturun (1 saat)
3. **Çapraz Platform Dağıtımı**: Aynı modeli iki farklı platformda dağıtın (1 saat)
4. **NPU Optimizasyonu**: Windows AI Foundry araçları ile NPU performansını test edin (30 dakika)

## Modül 8: Microsoft Foundry Local – Tam Geliştirici Araç Seti (Modernize Edilmiş)

### Temel Öğrenme Hedefleri

- Modern SDK entegrasyonu ile Foundry Local'ı kurun ve yapılandırın
- Koordinatör desenleri ile gelişmiş çoklu ajan sistemleri uygulayın
- Otomatik görev tabanlı seçim ile akıllı model yönlendiriciler oluşturun
- Kapsamlı izleme ile üretime hazır AI çözümleri dağıtın
- Hibrit dağıtım senaryoları için Azure AI Foundry ile entegre edin
- FoundryLocalManager ve OpenAI istemcisi ile modern SDK desenlerini öğrenin

### Çalışma Odak Alanları

#### Bölüm 1: Modern Kurulum ve Yapılandırma
- **Öncelikli Kavramlar**: 
  - FoundryLocalManager SDK entegrasyonu
  - Otomatik hizmet keşfi ve sağlık izleme
  - Ortam tabanlı yapılandırma desenleri
  - Üretim dağıtım hususları

#### Bölüm 2: Gelişmiş Çoklu Ajan Sistemleri
- **Öncelikli Kavramlar**: 
  - Uzman ajanlarla koordinatör deseni
  - Geri bildirim döngüsü mekanizmaları ile iyileştirme
  - Performans izleme ve istatistik takibi

#### Bölüm 3: Akıllı Model Yönlendirme
- **Öncelikli Kavramlar**: 
  - Anahtar kelime tabanlı model seçim algoritmaları
  - Birden fazla model desteği (genel, akıl yürütme, kod, yaratıcı)
  - Esneklik için ortam değişkeni yapılandırması
  - Hizmet sağlık kontrolü ve hata yönetimi

#### Bölüm 4: Üretime Hazır Uygulama
- **Öncelikli Kavramlar**: 
  - Kapsamlı hata yönetimi ve geri dönüş mekanizmaları
  - İstek izleme ve performans takibi
  - Benchmarklarla etkileşimli Jupyter notebook örnekleri
  - Mevcut uygulamalarla entegrasyon desenleri

### Kendini Değerlendirme Soruları

1. Modern FoundryLocalManager yaklaşımı manuel REST çağrılarından nasıl farklıdır?
2. Koordinatör desenini ve uzman ajanları nasıl yönettiğini açıklayın.
3. Akıllı yönlendirici, sorgu içeriğine göre uygun modelleri nasıl seçer?
4. Üretime hazır bir AI ajan sisteminin temel bileşenleri nelerdir?
5. Foundry Local hizmetleri için kapsamlı sağlık izleme nasıl uygulanır?
6. Modernize edilmiş yaklaşımın geleneksel uygulama desenlerine göre avantajlarını karşılaştırın.

### Uygulamalı Alıştırmalar

1. **Modern SDK Kurulumu**: FoundryLocalManager'ı otomatik hizmet keşfi ile yapılandırın (30 dakika)
2. **Çoklu Ajan Sistemi**: Uzman ajanlarla gelişmiş koordinatörü çalıştırın (30 dakika)
3. **Akıllı Yönlendirme**: Farklı sorgu türleriyle model yönlendiriciyi test edin (30 dakika)
4. **Etkileşimli Keşif**: Gelişmiş özellikleri keşfetmek için Jupyter notebookları kullanın (45 dakika)
5. **Üretim Dağıtımı**: İzleme ve hata yönetimi desenlerini uygulayın (30 dakika)
6. **Hibrit Entegrasyon**: Azure AI Foundry geri dönüş senaryolarını yapılandırın (30 dakika)

## Zaman Tahsis Kılavuzu

20 saatlik kurs zaman çizelgesinden en iyi şekilde yararlanmanız için önerilen bir zaman tahsisi:

| Aktivite | Zaman Tahsisi | Açıklama |
|----------|----------------|-------------|
| Temel Materyalleri Okuma | 9 saat | Her modüldeki temel kavramlara odaklanma |
| Uygulamalı Alıştırmalar | 6 saat | Temel tekniklerin pratik uygulaması |
| Kendini Değerlendirme | 2 saat | Sorular ve düşünce yoluyla anlayışınızı test etme |
| Mini Proje | 3 saat | Küçük bir pratik uygulama ile bilgiyi kullanma |

### Zaman Kısıtlamasına Göre Ana Odak Alanları

**Eğer sadece 10 saatiniz varsa:**
- Modül 1, 2 ve 3'ü tamamlayın (temel EdgeAI kavramları)
- Her modülden en az bir uygulamalı alıştırma yapın
- Uygulama detaylarından çok temel kavramları anlamaya odaklanın

**Eğer tam 20 saat ayırabiliyorsanız:**
- Tüm yedi modülü tamamlayın
- Her modülden önemli uygulamalı alıştırmaları yapın
- Modül 7'den bir mini proje tamamlayın
- En az 2-3 ek kaynağı keşfedin

**Eğer 20 saatten fazla zamanınız varsa:**
- Tüm modülleri detaylı alıştırmalarla tamamlayın
- Birden fazla mini proje oluşturun
- Modül 4'teki ileri düzey optimizasyon tekniklerini keşfedin
- Modül 5'ten üretim dağıtımını uygulayın

## Temel Kaynaklar

Bu dikkatle seçilmiş kaynaklar, sınırlı çalışma süreniz için en fazla değeri sağlar:

### Mutlaka Okunması Gereken Belgeler
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - En verimli model optimizasyon aracı
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - SLM'leri yerel olarak dağıtmanın en hızlı yolu
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Önde gelen edge-optimize edilmiş model için referans
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intel'in kapsamlı optimizasyon araç seti
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Entegre EdgeAI geliştirme ortamı
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows'a özgü EdgeAI geliştirme platformu

### Zaman Kazandıran Araçlar
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Hızlı model erişimi ve dağıtımı
- [Gradio](https://www.gradio.app/docs/interface) - AI demoları için hızlı UI geliştirme
- [Microsoft Olive](https://github.com/microsoft/Olive) - Basitleştirilmiş model optimizasyonu
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Verimli CPU çıkarımı
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Sinir ağı sıkıştırma frameworkü
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Büyük dil modeli dağıtım araç seti

## İlerleme Takip Şablonu

20 saatlik kurs boyunca öğrenme ilerlemenizi takip etmek için bu basitleştirilmiş şablonu kullanın:

| Modül | Tamamlama Tarihi | Harcanan Saat | Temel Çıkarımlar |
|--------|----------------|-------------|---------------|
| Modül 1: EdgeAI Temelleri | | | |
| Modül 2: SLM Temelleri | | | |
| Modül 3: SLM Dağıtımı | | | |
| Modül 4: Model Optimizasyonu | | | |
| Modül 5: SLMOps | | | |
| Modül 6: AI Ajanları | | | |
| Modül 7: Geliştirme Araçları | | | |
| Modül 8: Foundry Local Araç Seti | | | |
| Uygulamalı Alıştırmalar | | | |
| Mini Proje | | | |

## Mini Proje Fikirleri

EdgeAI kavramlarını pratik yapmak için aşağıdaki projelerden birini tamamlamayı düşünebilirsiniz (her biri 2-4 saat sürmek üzere tasarlanmıştır):

### Başlangıç Seviyesi Projeler (Her biri 2-3 saat)
1. **Edge Metin Asistanı**: Küçük bir dil modeli kullanarak basit bir çevrimdışı metin tamamlama aracı oluşturun
2. **Model Karşılaştırma Panosu**: Farklı SLM'lerin performans metriklerini görselleştiren temel bir araç geliştirin
3. **Optimizasyon Deneyi**: Aynı temel model üzerinde farklı kuantizasyon seviyelerinin etkisini ölçün

### Orta Seviye Projeler (Her biri 3-4 saat)
4. **AI Toolkit İş Akışı**: VS Code AI Toolkit kullanarak bir modeli baştan sona optimize edin ve dağıtın
5. **Windows AI Foundry Uygulaması**: Phi Silica API ve NPU optimizasyonu kullanarak bir Windows uygulaması oluşturun
6. **Çapraz Platform Dağıtımı**: Aynı optimize edilmiş modeli Windows (OpenVINO) ve mobil (.NET MAUI) üzerinde dağıtın
7. **Fonksiyon Çağırma Yeteneği Olan Ajan**: Edge senaryoları için fonksiyon çağırma yeteneklerine sahip bir AI ajanı oluşturun

### İleri Seviye Entegrasyon Projeleri (Her biri 4-5 saat)
8. **OpenVINO Optimizasyon Süreci**: NNCF ve GenAI araç seti kullanarak tam model optimizasyonunu uygulayın
9. **SLMOps Süreci**: Eğitimden edge dağıtımına kadar tam bir model yaşam döngüsünü uygulayın
10. **Çoklu Model Edge Sistemi**: Edge donanımında birlikte çalışan birden fazla özel modeli dağıtın
11. **MCP Entegrasyon Sistemi**: Araç etkileşimi için Model Context Protocol kullanarak bir ajan sistemi oluşturun

## Referanslar

- Microsoft Learn (Foundry Local)
  - Genel Bakış: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Başlangıç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI referansı: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Çıkarım SDK'ları ile entegrasyon: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI nasıl yapılır: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Hugging Face modellerini derleme: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Genel Bakış: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Ajanlar (genel bakış): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimizasyon ve Çıkarım Araçları
  - Microsoft Olive (dokümanlar): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (başlangıç): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive entegrasyonu: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokümanlar): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokümanlar): https://ml-explore.github.io/mlx/build/html/index.html
- Dağıtım Çerçeveleri ve Modeller
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokümanlar): https://docs.vllm.ai/
  - Ollama (hızlı başlangıç): https://github.com/ollama/ollama#get-started
- Geliştirici Araçları (Windows ve VS Code)
  - VS Code için AI Toolkit: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (genel bakış): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Öğrenme Topluluğu

Tartışmalara katılın ve diğer öğrenenlerle bağlantı kurun:
- [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions) üzerindeki GitHub Tartışmaları
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Sonuç

EdgeAI, yapay zeka uygulamalarının ön saflarını temsil eder ve güçlü yetenekleri doğrudan cihazlara getirirken gizlilik, gecikme ve bağlantı sorunlarını ele alır. Bu 20 saatlik kurs, EdgeAI teknolojileriyle hemen çalışmaya başlamak için gerekli temel bilgileri ve pratik becerileri sağlar.

Kurs, en önemli kavramlara odaklanarak kasıtlı olarak kısa ve öz tutulmuştur, böylece aşırı zaman harcamadan değerli uzmanlık kazanabilirsiniz. Basit örneklerle bile uygulamalı pratik yapmanın, öğrendiklerinizi pekiştirmenin anahtarı olduğunu unutmayın.

İyi öğrenmeler!

---

