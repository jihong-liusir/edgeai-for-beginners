<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-22T18:30:15+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "tr"
}
-->
# Oturum 1: Foundry Local ile Başlangıç

## Genel Bakış

Microsoft Foundry Local, Azure AI Foundry yeteneklerini doğrudan Windows 11 geliştirme ortamınıza getirerek gizliliği koruyan, düşük gecikmeli AI geliştirme imkanı sunar ve kurumsal düzeyde araçlar sağlar. Bu oturum, phi, qwen, deepseek ve GPT-OSS-20B gibi popüler modellerin tam kurulum, yapılandırma ve uygulamalı dağıtımını kapsar.

## Öğrenme Hedefleri

Bu oturumun sonunda:
- Foundry Local'ı Windows 11 üzerinde kurup yapılandırabileceksiniz
- CLI komutları ve yapılandırma seçeneklerini ustalıkla kullanabileceksiniz
- Performansı optimize etmek için model önbellekleme stratejilerini anlayabileceksiniz
- Phi, qwen, deepseek ve GPT-OSS-20B modellerini başarıyla çalıştırabileceksiniz
- Foundry Local kullanarak ilk AI uygulamanızı oluşturabileceksiniz

## Ön Koşullar

### Sistem Gereksinimleri
- **Windows 11**: Sürüm 22H2 veya daha yeni
- **RAM**: Minimum 16GB, önerilen 32GB
- **Depolama**: Modeller ve önbellek için 50GB boş alan
- **Donanım**: NPU veya GPU destekli cihaz tercih edilir (Copilot+ PC veya NVIDIA GPU)
- **Ağ**: Modelleri indirmek için yüksek hızlı internet bağlantısı

### Geliştirme Ortamı
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## Bölüm 1: Kurulum ve Ayarlar

### Adım 1: Foundry Local'ı Kurun

Foundry Local'ı Winget kullanarak veya GitHub'dan yükleyici indirerek kurun:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Adım 2: Kurulumu Doğrulayın

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Bölüm 2: CLI'yi Anlamak

### Temel Komut Yapısı

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Bölüm 3: Model Önbellekleme ve Yönetimi

Foundry Local, performansı ve depolamayı optimize etmek için akıllı model önbellekleme uygular:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Bölüm 4: Uygulamalı Model Dağıtımı

### Microsoft Phi Modellerini Çalıştırma

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Qwen Modelleri ile Çalışma

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### DeepSeek Modellerini Çalıştırma

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### GPT-OSS-20B Çalıştırma

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Bölüm 5: İlk Uygulamanızı Oluşturma

### Basit Sohbet Arayüzü (OpenAI uyumlu API)

Foundry Local'ın OpenAI uyumlu REST API'sini kullanarak temel bir sohbet uygulaması oluşturun. Başka bir terminalde bir modelin çalıştığından emin olun.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Sohbet Uygulamasını Çalıştırma

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## Bölüm 6: Sorun Giderme ve En İyi Uygulamalar

### Yaygın Sorunlar ve Çözümleri

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Sistem Kaynaklarını İzleme (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### En İyi Uygulamalar

- `foundry model ...`, `foundry cache ...` ve `foundry service ...` komutlarını tercih edin (CLI referansına bakın)
- Yeni modeller ve düzeltmelere erişmek için düzenli olarak güncelleme yapın
- Daha küçük modellerle başlayın (Phi mini, Qwen 7B) ve ölçeklendirin
- İstekleri ve ayarları ayarlarken CPU/GPU/belleği izleyin

## Bölüm 7: Uygulamalı Alıştırmalar

### Alıştırma 1: Hızlı Çoklu Model Çalıştırma

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Alıştırma 2: Temel Gecikme Karşılaştırması

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Referanslar

- Foundry Local ile başlama: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- CLI referansı ve komutlar genel bakışı: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Hugging Face modellerini Foundry Local için derleme: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

