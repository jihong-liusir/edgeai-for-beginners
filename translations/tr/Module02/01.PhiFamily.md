<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T22:43:19+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "tr"
}
-->
# Bölüm 1: Microsoft Phi Model Ailesi Temelleri

Microsoft Phi model ailesi, yapay zekada bir paradigma değişimini temsil eder ve kompakt, verimli modellerin, geleneksel büyük dil modellerine kıyasla çok daha az kaynak tüketirken olağanüstü performans elde edebileceğini gösterir. Phi ailesinin, çeşitli görevlerde yüksek performansı korurken azaltılmış hesaplama gereksinimleriyle güçlü yapay zeka yeteneklerini nasıl sağladığını anlamak önemlidir.

## Geliştiriciler için Kaynaklar

### Azure AI Foundry Model Kataloğu
Phi model ailesi (Phi-silica hariç), [Azure AI Foundry Model Kataloğu](https://ai.azure.com/explore/models?q=phi) üzerinden erişilebilir. Bu katalog, geliştiricilerin bu modelleri kolayca erişim, ince ayar ve uygulamalarında dağıtım yapmalarını sağlar. Katalog, farklı Phi varyantlarını denemek ve projelerinize entegre etmek için pratik bir yol sunar.

### Azure AI Foundry
Phi modellerini [Azure AI Foundry](https://ai.azure.com) kullanarak dağıtabilir ve deneyebilirsiniz. Bu platform, minimum kurulumla yapay zeka çözümleri oluşturmak, test etmek ve dağıtmak için kapsamlı bir ortam sağlar.

### Foundry Local
Yerel geliştirme ve dağıtım için [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) platformunu inceleyebilirsiniz. Bu araç, Phi modellerini optimize edilmiş yapılandırmalarla geliştirme makinenizde çalıştırmanıza olanak tanır.

### Dokümantasyon Kaynakları
- [Microsoft Research: Phi Model Teknik Raporları](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Giriş

Bu derste, Microsoft'un Phi model ailesini ve temel kavramlarını inceleyeceğiz. Phi ailesinin evrimini, Phi modellerini verimli kılan yenilikçi eğitim yöntemlerini, ailedeki ana varyantları ve farklı senaryolardaki pratik uygulamaları ele alacağız.

## Öğrenme Hedefleri

Bu dersin sonunda şunları yapabileceksiniz:

- Microsoft'un Phi model ailesinin tasarım felsefesini ve evrimini anlayın.
- Phi modellerinin daha az parametreyle yüksek performans elde etmesini sağlayan temel yenilikleri tanımlayın.
- Farklı Phi model varyantlarının avantajlarını ve sınırlamalarını tanıyın.
- Gerçek dünya senaryoları için uygun varyantları seçmek üzere Phi modelleri hakkındaki bilgilerinizi uygulayın.

## Geleneksel Yapay Zeka Model Paradigmasını Anlamak

Geleneksel olarak, doğal dil işleme alanında yüksek performans elde etmek, milyarlarca veya yüz milyarlarca parametreye sahip devasa dil modelleri gerektiriyordu. Kuruluşlar genellikle bu modelleri güçlü GPU kümelerinde çalıştırır ve yeteneklerine API arayüzleri veya özel donanım altyapısı aracılığıyla erişir.

Bu yaklaşım birçok uygulama için iyi çalışsa da, pratik dağıtım senaryolarında doğal sınırlamaları vardır. Geleneksel yöntem, büyük hesaplama kaynakları, büyük miktarda bellek ve önemli enerji tüketimi gerektiren modellerin kullanılmasını içerir. Bu yaklaşım, en son teknolojilere erişim sağlasa da pahalı donanıma bağımlılık yaratır, yüksek operasyonel maliyetler getirir ve dağıtım esnekliğini sınırlar.

## Verimli Yapay Zeka Dağıtımının Zorlukları

Daha verimli yapay zeka ihtiyacı, çeşitli senaryolarda giderek daha önemli hale gelmiştir. Örneğin, gizlilik nedenleriyle yerel dağıtım gerektiren uygulamalar, bulut API maliyetlerinin engelleyici olduğu maliyet duyarlı uygulamalar, sınırlı donanım kaynaklarına sahip uç bilişim senaryoları veya gecikmenin kritik olduğu gerçek zamanlı uygulamalar.

### Temel Dağıtım Kısıtlamaları

Geleneksel büyük model dağıtımları, pratik uygulanabilirliklerini sınırlayan birkaç temel kısıtlamayla karşı karşıyadır:

- **Maliyet Sınırlamaları**: Yüksek hesaplama maliyetleri, sürekli dağıtımı birçok kuruluş için pahalı hale getirir.
- **Kaynak Kısıtlamaları**: Yüksek kaliteli GPU altyapısına sınırlı erişim, dağıtım seçeneklerini sınırlar.
- **Gizlilik Gereksinimleri**: Hassas uygulamalar, veri gizliliğini korumak için yerel işlem gerektirir.
- **Gecikme Hassasiyeti**: Gerçek zamanlı uygulamalar, bulut üzerinden veri alışverişi gecikmeleri olmadan anında yanıtlar gerektirir.

## Microsoft Phi Model Felsefesi

Microsoft Phi model ailesi, verimlilik ve pratik dağıtımı önceliklendirirken güçlü performans özelliklerini koruyan bir yapay zeka model tasarım felsefesinde temel bir değişimi temsil eder. Phi modelleri, yenilikçi mimariler, yüksek kaliteli eğitim yöntemleri ve özel optimizasyon teknikleri sayesinde bu hedefe ulaşır.

Phi ailesi, standart donanımda anlamlı yapay zeka yetenekleri sağlarken, parametre başına performansı en üst düzeye çıkarmak için tasarlanmış çeşitli yaklaşımları kapsar. Amaç, rekabetçi performansı korurken hesaplama gereksinimlerini, bellek kullanımını ve operasyonel maliyetleri önemli ölçüde azaltmaktır.

### Temel Phi Tasarım İlkeleri

Phi modelleri, geleneksel büyük dil modellerinden farklı kılan birkaç temel ilkeye dayanır:

- **Öncelik Verimlilik**: Mutlak ölçek yerine parametre başına maksimum performans için optimize edilmiştir.
- **Kaliteli Eğitim**: Büyük veri setleri yerine yüksek kaliteli, özenle seçilmiş eğitim verilerine odaklanır.
- **Dağıtım Esnekliği**: Çeşitli donanım yapılandırmalarında etkili bir şekilde çalışacak şekilde tasarlanmıştır.
- **Özel Yetkinlikler**: Belirli görevler veya alanlar için optimize edilerek etkinliği en üst düzeye çıkarır.

## Phi Ailesini Etkinleştiren Temel Teknolojiler

### "Ders Kitabı" Eğitim Yaklaşımı

Phi ailesinin en devrimci yönlerinden biri, "ders kitabı kalitesinde" eğitim metodolojisidir. Phi modelleri, büyük miktarda filtrelenmemiş internet verisi yerine, akıl yürütme, matematik, kodlama ve genel bilgiyi etkili bir şekilde öğretmek için tasarlanmış özenle seçilmiş, yüksek kaliteli eğitim içeriği kullanır.

Bu yaklaşım, yüksek kaliteli ders kitapları ve akademik materyalleri yansıtan sentetik eğitim içeriği oluşturarak çalışır. Eğitim verileri, pedagojik olarak sağlam olacak şekilde tasarlanmıştır ve açık açıklamalar, adım adım akıl yürütme ve yapılandırılmış bilgi sunumuna odaklanır.

### Gelişmiş Akıl Yürütme Eğitimi

Son Phi modelleri, karmaşık çok adımlı problem çözmeyi mümkün kılan sofistike akıl yürütme eğitim metodolojilerini içerir. Bu teknikler şunları içerir:

**Düşünce Zinciri Eğitimi**: Modeller, karmaşık problemleri ara akıl yürütme adımlarına ayırmayı öğrenir, bu da problem çözme sürecini daha şeffaf ve güvenilir hale getirir.

**Çıkarım Zamanı Ölçeklendirme**: Modeller, yanıt oluşturma sırasında ek hesaplama kaynaklarını kullanarak ayrıntılı akıl yürütme zincirleri oluşturur ve doğruluğu artırır.

**Yetkinlik Sınırında Eğitim**: Eğitim verileri, modelin mevcut yeteneklerinin sınırında zorluklar yaratacak şekilde seçilir ve karmaşık akıl yürütme kalıplarını öğrenmeyi teşvik eder.

### Mimari Yenilikler

Phi ailesi, özellikle verimlilik için tasarlanmış birkaç mimari optimizasyon içerir:

**Parametre Verimliliği**: Modeldeki her bir parametrenin etkisini en üst düzeye çıkaran dikkatli mimari seçimler.

**Çoklu Mod Entegrasyonu**: Metin, görsel ve konuşma işleme yeteneklerinin kompakt mimariler içinde verimli entegrasyonu.

**Donanım Optimizasyonu**: Belirli donanım platformları ve dağıtım senaryoları için optimize edilmiş özel varyantlar.

## Phi Modelleri için Donanım Optimizasyonu

Modern dağıtım ortamları, Phi modellerinin çeşitli donanım yapılandırmalarında sağladığı verimlilikten faydalanır:

### CPU Optimizasyonlu Dağıtım

Phi modelleri, yalnızca CPU donanımında etkili bir şekilde çalışacak şekilde tasarlanmıştır. Bu, özel yapay zeka hızlandırıcıları gerektirmeden standart bilgi işlem altyapısında dağıtımı mümkün kılar.

### GPU Hızlandırma

Güçlü GPU'lara ihtiyaç duymasa da, Phi modelleri mevcut GPU kaynaklarını performansı artırmak için kullanabilir ve dağıtım yapılandırmalarında esneklik sağlar.

### Uç Cihaz Entegrasyonu

Phi-3-Silica gibi özel varyantlar, belirli uç bilişim platformları için optimize edilmiştir ve yalnızca 1.5W güç tüketimiyle saniyede 650 token gibi dikkat çekici verimlilik metriklerine ulaşır.

## Phi Model Ailesinin Faydaları

### Maliyet Verimliliği

Phi modelleri, rekabetçi performansı korurken önemli ölçüde daha az hesaplama altyapısı gerektirerek operasyonel maliyetleri önemli ölçüde azaltır. Bu, yapay zekayı sınırlı bütçelere sahip kuruluşlar veya yüksek hacimli uygulamalar için erişilebilir hale getirir.

### Dağıtım Esnekliği

Phi modellerinin verimliliği, kişisel dizüstü bilgisayarlardan kurumsal sunuculara kadar geniş bir donanım yapılandırmasında dağıtımı mümkün kılar ve kuruluşlara yapay zeka altyapısı seçimlerinde daha fazla esneklik sağlar.

### Gizlilik ve Güvenlik

Phi modellerinin verimliliği, gizlilik hassasiyeti olan uygulamalar için yerel dağıtımı mümkün kılar. Bu, hassas verilerin kuruluşun kontrolünden çıkmadan güçlü yapay zeka yetenekleri sağlamasını garanti eder.

### Gerçek Zamanlı Performans

Azaltılmış hesaplama gereksinimleri, daha hızlı çıkarım sürelerine dönüşür ve gerçek zamanlı uygulamalarda anında yanıtlar sağlar. Bu, yapay zeka yeteneklerinin kalitesinden ödün vermeden gerçekleştirilir.

### Erişilebilir Yapay Zeka

Phi modelleri, yapay zeka dağıtımındaki engelleri azaltarak, gelişmiş yapay zeka yeteneklerini sınırlı kaynaklara sahip kuruluşlara erişilebilir hale getirir. Bu, küçük ekiplerin ve bireysel geliştiricilerin sofistike dil anlayışından faydalanmasını sağlar.

## Pratik Örnekler ve Kullanım Senaryoları

Teknik evrime geçmeden önce, Phi modellerinin neler yapabileceğini gösteren somut örnekleri inceleyelim:

### Matematiksel Akıl Yürütme Örneği

Phi-4-mini-reasoning, adım adım matematiksel problem çözmede mükemmeldir. Örneğin, "3*x^2+4*x+5=1 nasıl çözülür?" sorulduğunda, model ayrıntılı akıl yürütme adımları sağlar:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Çok Dilli Destek Örneği

Phi-3.5-mini-instruct, çeşitli dillerde güçlü çok dilli yetenekler sergiler. İşte bir örnek istem formatı:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Çoklu Mod Yetkinlikleri Örneği

Phi-4-multimodal, metin, görseller ve konuşmayı aynı anda işleyebilir. İşte bazı pratik uygulamalar:

**Sesli Girdi ile Seyahat Planlama:**
Phi-4 Multimodal'ın konuşulan dili analiz ederek Seattle'a bir gezi planlamaya nasıl yardımcı olduğunu izleyin. Bu, gelişmiş ses işleme ve öneri yeteneklerini gösterir.

**Görsellerden Matematiksel Problem Çözme:**
Phi-4 Multimodal'ın görsel girdilerde sunulan denklemleri işleyip çözerek karmaşık matematiksel problemleri nasıl ele aldığını görün.

**Fonksiyon Çağrısı Örneği:**
Fonksiyon çağrısı ile Phi-4-mini ve Phi-4-multimodal, metin işleme yeteneklerini arama motorları, çeşitli araçlarla bağlantı kurma ve daha fazlasını entegre ederek genişletebilir. Örneğin, model Phi-4-mini aracılığıyla Premier League maç bilgilerini alabilir ve harici veri kaynaklarıyla sorunsuz bir şekilde etkileşim kurma yeteneğini sergiler.

### Kod Üretimi Örneği

Phi-4-multimodal, hem görsel içerik hem de sağlanan istemlere dayalı olarak yapılandırılmış proje kodu üretebilir. İşte bu pratik iş akışının bir örneği:

1. Bir tel çerçeve veya tasarım görüntüsü yükleyin
2. Proje gereksinimleri hakkında bağlam sağlayın
3. Model, eksiksiz ve işlevsel kod yapıları oluşturur
4. Kod, belirli çerçeveler veya diller temelinde özelleştirilebilir

### Uç Dağıtım Örneği

Kuantize edilmiş modeli uç cihazlarda dağıtabiliriz. Microsoft Olive ve ONNX GenAI Runtime'ı birleştirerek Phi-4-mini'yi Windows, iPhone, Android ve diğer cihazlarda dağıtabiliriz. Bu, iPhone 12 Pro'da çalışan bir örnektir.

Dağıtım süreci şunları içerir:
- Mobil optimizasyon için model kuantizasyonu
- Çapraz platform uyumluluğu için ONNX çalışma zamanı entegrasyonu
- İnternet bağlantısı olmadan yerel çıkarım
- Minimum güç tüketimiyle gerçek zamanlı performans

## Phi Ailesinin Evrimi

### Phi-1 ve Phi-2: Temel Modeller

Erken Phi modelleri, yüksek kaliteli eğitim verileri ve verimli mimarilerle ilgili temel ilkeleri oluşturdu:

- **Phi-1 (1.3B parametre)**: Temel dil anlayışı ve kod üretimi için özenle seçilmiş eğitim verisi konseptini tanıttı.
- **Phi-2 (2.7B parametre)**: Sentetik NLP verileri ve dikkatlice filtrelenmiş web içeriği aracılığıyla akıl yürütme yeteneklerini geliştirdi.

### Phi-3 Ailesi: Ana Akım Benimseme

Phi-3 serisi, birden fazla özel varyantla SLM yeteneklerinde bir atılım sağladı:

- **Phi-3-mini (3.8B parametre)**: İki katı büyüklüğündeki modelleri geride bırakan olağanüstü verimlilikle genel dil görevleri.
- **Phi-3-small (7B parametre)**: Çeşitli ölçütlerde GPT-3.5 Turbo'yu geride bırakan gelişmiş performans.
- **Phi-3-medium (14B parametre)**: Gemini 1.0 Pro'yu geride bırakan kurumsal düzeyde performans.
- **Phi-3-vision (4.2B parametre)**: Görsel ve metin işleme için çoklu mod yetenekleri.
- **Phi-3-Silica (3.3B parametre)**: Windows 11 yerleşik dağıtımı için özel optimizasyon.

### Phi-4 Ailesi: Gelişmiş Akıl Yürütme

Son nesil, akıl yürütme yeteneklerinin sınırlarını zorlar:

- **Phi-4 (14B parametre)**: Özellikle matematikte karmaşık akıl yürütme uzmanlığı.
- **Phi-4-mini (3.8B parametre)**: Fonksiyon çağrısı ve uzun bağlam desteği ile geliştirilmiş akıl yürütme.
- **Phi-4-multimodal**: Eşzamanlı konuşma, görsel ve metin işleme yetenekleri.
- **Phi-4-reasoning (14B parametre)**: Karmaşık çok adımlı akıl yürütme görevleri için uzmanlaşmış.
- **Phi-4-reasoning-plus (14B parametre)**: Ek pekiştirmeli öğrenme ile artırılmış doğruluk.
- **Phi-4-mini-reasoning (3.8B parametre)**: Sınırlı ortamlar için optimize edilmiş matematiksel akıl yürütme.

## Phi Modellerinin Uygulamaları

### Kurumsal Uygulamalar

Kuruluşlar, Phi modellerini belge analizi, müşteri hizmetleri otomasyonu, kod üretim yardımı ve uyumluluk ve güvenlik nedenleriyle yerel dağıtım gerektiren iş zekası uygulamaları için kullanır.

### Mobil ve Uç Bilişim

Mobil uygulamalar, sürekli internet bağlantısı gerektirmeden gerçek zamanlı çeviri, akıllı asistanlar, içerik üretimi ve kişiselleştirilmiş öneriler için Phi modellerinden faydalanır.

### Eğitim Teknolojisi

Eğitim platformları, Phi modellerini kişiselleştirilmiş öğretim, otomatik notlama, içerik üretimi ve çevrimdışı veya düşük bağlantı ortamlarında çalışabilen etkileşimli öğrenme deneyimleri için kullanır.

### Sağlık ve Uyumluluk

Sağlık uygulamaları, Phi modellerinin hassas tıbbi verileri yerel olarak işleme yeteneğinden faydalanır. Bu, yapay zeka destekli tanı yardımı, hasta takibi ve tedavi önerileri sağlar.

## Zorluklar ve Sınırlamalar

### Bilgi Sınırlamaları

Verimli olmasına rağmen, Phi modelleri daha büyük modellere kıyasla daha az bilgi kapasitesine sahiptir. Bu, geniş alan uzmanlığı gerektiren bilgi yoğun uygulamalarda etkinliklerini sınırlayabilir.

### Dil Desteği

Phi modelleri öncelikle İngilizce için optimize edilmiştir. Ancak, daha yeni varyantlar çok dilli yetenekler içerir. G
Phi ailesi, yapay zeka dağıtımının geleceğinin sadece daha büyük modeller oluşturmakta değil, aynı zamanda daha akıllı ve daha verimli modeller geliştirmekte olduğunu gösteriyor. Bu modeller, çeşitli donanım ortamlarında yüksek performans standartlarını koruyarak etkili bir şekilde çalışabilir.

## Geliştirme ve Entegrasyon Örnekleri

### Transformers ile Hızlı Başlangıç

Phi modellerini Hugging Face Transformers kütüphanesi ile kullanmaya başlamak için:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### İnce Ayar Örneği

Aşağıdaki örnek, Phi-4-mini-instruct modelini belirli görevler için nasıl ince ayar yapabileceğinizi gösteriyor:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Özel İpucu Formatları

**Akıl Yürütme Görevleri İçin (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Matematiksel Görevler İçin (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### ONNX ile Mobil Dağıtım

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Performans Karşılaştırmaları ve Başarılar

Phi model ailesi, çeşitli karşılaştırmalarda olağanüstü performans sergileyerek genellikle çok daha büyük modelleri geride bırakmıştır:

### Önemli Performans Özellikleri

**Matematiksel Akıl Yürütme Mükemmelliği:**
- Phi-4, AIME 2025 (Matematik Olimpiyatı elemesi) üzerinde %82.5 doğruluk oranı elde etti
- Phi-4-reasoning (14B), akıl yürütme karşılaştırmalarında DeepSeek-R1-Distill-70B (5 kat daha büyük) modelini geride bıraktı
- Phi-4-mini-reasoning (3.8B), matematiksel akıl yürütme görevlerinde iki katı büyüklüğündeki modellerle rekabet ediyor

**Verimlilik Başarıları:**
- Phi-3-Silica, yalnızca 1.5W güç tüketimiyle saniyede 650 token işliyor
- Phi-4-mini (3.8B), çok daha büyük modellere benzer performans sağlıyor

**Karşılaştırma Performansı:**
- **MMLU (Massive Multitask Language Understanding)**: 57 akademik konu arasında rekabetçi performans
- **HumanEval**: Özellikle Python'da güçlü kod üretme yetenekleri
- **MGSM**: Çok dilli ilkokul matematik problemlerini çözme
- **DROP**: Karmaşık anlama ve akıl yürütme görevleri
- **SimpleQA**: Gerçeklere dayalı yanıt doğruluğu

### 📊 Model Karşılaştırma Matrisi

| Model | Parametreler | Bağlam Uzunluğu | Temel Güçlü Yönler | En İyi Kullanım Alanları |
|-------|--------------|-----------------|--------------------|--------------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Genel verimlilik | Mobil uygulamalar, temel sohbet botları |
| **Phi-3.5-mini** | 3.8B | 128K | Çok dilli destek | Uluslararası uygulamalar |
| **Phi-4-mini** | 3.8B | 128K | Gelişmiş akıl yürütme, fonksiyon çağırma | İş otomasyonu |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matematiksel akıl yürütme | Eğitim platformları |
| **Phi-4** | 14B | 32K | Karmaşık akıl yürütme | Araştırma, ileri analiz |
| **Phi-4-reasoning** | 14B | 32K/64K | Çok adımlı akıl yürütme | Bilimsel hesaplama |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimum doğrulukta akıl yürütme | Kritik karar verme |
| **Phi-4-multimodal** | 5.6B | Değişken | Konuşma, görsel, metin | Multimedya uygulamaları |

## Model Seçim Rehberi

### Temel Uygulamalar İçin
- **Phi-3-mini**: Basit metin üretimi, temel Soru-Cevap, hızlı yanıtlar
- **Phi-4-mini**: Fonksiyon çağırma yetenekleriyle gelişmiş akıl yürütme

### Matematiksel ve Akıl Yürütme Görevleri İçin
- **Phi-4**: Karmaşık matematik problemleri çözme ve akıl yürütme
- **Phi-4-reasoning**: Ayrıntılı açıklamalarla çok adımlı akıl yürütme
- **Phi-4-reasoning-plus**: Kritik akıl yürütme uygulamaları için maksimum doğruluk
- **Phi-4-mini-reasoning**: Kaynak kısıtlı ortamlar için verimli matematiksel akıl yürütme

### Multimodal Uygulamalar İçin
- **Phi-3-vision**: Görüntü ve metin işleme kombinasyonları
- **Phi-4-multimodal**: Kapsamlı konuşma, görsel ve metin yetenekleri

### Kurumsal Dağıtım İçin
- **Phi-3-medium**: İş uygulamaları için gelişmiş dil anlayışı
- **Phi-3-Silica**: Belirli donanım platformları için optimize edilmiş

## Dağıtım Platformları ve Erişilebilirlik

### Bulut Platformları
- **Azure AI Foundry**: Kurumsal araçlarla tam özellikli dağıtım
- **Hugging Face**: Açık kaynaklı model deposu ve topluluk kaynakları
- **NVIDIA API Catalog**: Mikro hizmet dağıtım seçenekleri

### Yerel Geliştirme Çerçeveleri
- **Ollama**: Yerel model dağıtımı için hafif çerçeve
- **ONNX Runtime**: Çeşitli donanım yapılandırmaları için optimize edilmiş  
- **DirectML**: Windows için optimize edilmiş performans
- **llama.cpp**: Platformlar arası çıkarım motoru

### Öğrenme Kaynakları
- **Phi Portal**: Microsoft Phi resmi dokümantasyon merkezi
- **Phi Cookbook**: Kapsamlı örnekler ve eğitim materyalleri
- **Teknik Raporlar**: Arxiv'deki ayrıntılı araştırma makaleleri
- **Topluluk Alanları**: Hugging Face etkileşimli demolar

### Phi Modelleriyle Başlangıç

#### Geliştirme Platformları
1. **Azure AI Foundry**: Basit yerel CLI ve model yönetimi.
2. **Hugging Face Transformers**: Hızlı yerel deneyler
3. **Ollama**: Test için basit yerel dağıtım

#### Öğrenme Yolu
1. **Temel Kavramları Anlayın**: Temel tasarım prensiplerini inceleyin
2. **Varyantlarla Deney Yapın**: Farklı Phi modellerini deneyerek yeteneklerini anlayın
3. **Uygulama Pratiği Yapın**: Modelleri test ortamlarında dağıtın
4. **Dağıtımı Ölçeklendirin**: Başarılı pilotlara dayanarak kullanımı kademeli olarak genişletin

#### En İyi Uygulamalar
- **Küçük Başlayın**: İlk geliştirme için Phi-mini modelleriyle başlayın
- **İpuçlarını Optimize Edin**: En iyi sonuçlar için uygun sohbet formatlarını kullanın
- **Performansı İzleyin**: Çıkarım hızı ve doğruluk metriklerini takip edin
- **Donanımı Düşünün**: Model boyutunu mevcut hesaplama kaynaklarına uygun hale getirin

## Sonuç

Microsoft Phi model ailesi, yapay zeka model tasarımında devrim niteliğinde bir yaklaşımı temsil ediyor. Daha küçük, daha verimli modellerin çeşitli görevlerde olağanüstü performans elde edebileceğini gösteriyor. Yüksek kaliteli eğitim verileri ve mimari optimizasyonlara odaklanarak, Phi ailesi geleneksel büyük dil modellerine kıyasla önemli ölçüde azaltılmış hesaplama gereksinimleriyle olağanüstü yetenekler sunuyor.

## Temel Öğrenme Hedefleri

1. Microsoft'un Phi model ailesinin Phi-1'den Phi-4'e kadar olan tasarım felsefesini ve evrimini anlamak
2. "Ders kitabı kalitesinde" eğitim ve mimari optimizasyonlar dahil olmak üzere temel yenilikleri tanımlamak
3. Farklı Phi varyantlarının farklı dağıtım senaryolarındaki avantajlarını ve sınırlamalarını tanımak
4. Belirli kullanım durumları ve donanım kısıtlamaları için uygun Phi modellerini seçmek
5. Kaynak kısıtlı cihazlarda Phi modellerini dağıtmak için optimizasyon tekniklerini uygulamak
6. Phi model ailesinin geleneksel büyük dil modellerine göre mimari avantajlarını açıklamak
7. Belirli uygulama gereksinimlerine ve donanım kısıtlamalarına göre uygun Phi varyantını seçmek
8. Phi modellerini optimize edilmiş yapılandırmalarla hem bulut hem de uç dağıtım senaryolarında uygulamak
9. Hedef cihazlarda Phi model performansını artırmak için kuantizasyon ve optimizasyon tekniklerini uygulamak
10. Phi ailesi genelinde model boyutu, performans ve yetenekler arasındaki ödünleşimleri değerlendirmek

## Sırada Ne Var

- [02: Qwen Ailesi Temelleri](02.QwenFamily.md)

---

**Feragatname**:  
Bu belge, AI çeviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluğu sağlamak için çaba göstersek de, otomatik çevirilerin hata veya yanlışlık içerebileceğini lütfen unutmayın. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından kaynaklanan yanlış anlamalar veya yanlış yorumlamalardan sorumlu değiliz.