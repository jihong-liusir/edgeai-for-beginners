<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-18T13:05:36+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "vi"
}
-->
# Phần 4: Triển khai - Thực hiện mô hình sẵn sàng cho sản xuất

## Tổng quan

Hướng dẫn toàn diện này sẽ giúp bạn thực hiện toàn bộ quy trình triển khai các mô hình đã tinh chỉnh và lượng tử hóa bằng Foundry Local. Chúng ta sẽ đi qua các bước chuyển đổi mô hình, tối ưu hóa lượng tử hóa, và cấu hình triển khai từ đầu đến cuối.

## Yêu cầu trước

Trước khi bắt đầu, hãy đảm bảo bạn có các điều kiện sau:

- ✅ Một mô hình onnx đã tinh chỉnh, sẵn sàng để triển khai
- ✅ Máy tính Windows hoặc Mac
- ✅ Python 3.10 hoặc cao hơn
- ✅ Ít nhất 8GB RAM khả dụng
- ✅ Foundry Local đã được cài đặt trên hệ thống của bạn

## Phần 1: Thiết lập môi trường

### Cài đặt các công cụ cần thiết

Mở terminal của bạn (Command Prompt trên Windows, Terminal trên Mac) và chạy các lệnh sau theo thứ tự:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

⚠️ **Lưu ý quan trọng**: Bạn cũng cần CMake phiên bản 3.31 hoặc mới hơn, có thể tải xuống từ [cmake.org](https://cmake.org/download/).

## Phần 2: Chuyển đổi mô hình và lượng tử hóa

### Chọn định dạng phù hợp

Đối với các mô hình ngôn ngữ nhỏ đã tinh chỉnh, chúng tôi khuyến nghị sử dụng **định dạng ONNX** vì:

- 🚀 Tối ưu hóa hiệu suất tốt hơn
- 🔧 Triển khai không phụ thuộc vào phần cứng
- 🏭 Khả năng sẵn sàng cho sản xuất
- 📱 Tương thích đa nền tảng

### Phương pháp 1: Chuyển đổi bằng một lệnh (Khuyến nghị)

Sử dụng lệnh sau để chuyển đổi trực tiếp mô hình đã tinh chỉnh của bạn:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**Giải thích tham số:**
- `--model_name_or_path`: Đường dẫn đến mô hình đã tinh chỉnh của bạn
- `--device cpu`: Sử dụng CPU để tối ưu hóa
- `--precision int4`: Sử dụng lượng tử hóa INT4 (giảm kích thước khoảng 75%)
- `--output_path`: Đường dẫn đầu ra cho mô hình đã chuyển đổi

### Phương pháp 2: Sử dụng tệp cấu hình (Dành cho người dùng nâng cao)

Tạo một tệp cấu hình có tên `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

Sau đó chạy:

```bash
olive run --config ./finetuned_conversion_config.json
```

### So sánh các tùy chọn lượng tử hóa

| Độ chính xác | Kích thước tệp | Tốc độ suy luận | Chất lượng mô hình | Sử dụng khuyến nghị |
|--------------|----------------|-----------------|--------------------|---------------------|
| FP16         | Baseline × 0.5 | Nhanh           | Tốt nhất          | Phần cứng cao cấp  |
| INT8         | Baseline × 0.25 | Rất nhanh       | Tốt               | Lựa chọn cân bằng  |
| INT4         | Baseline × 0.125 | Nhanh nhất      | Chấp nhận được    | Hạn chế tài nguyên |

💡 **Khuyến nghị**: Bắt đầu với lượng tử hóa INT4 cho lần triển khai đầu tiên của bạn. Nếu chất lượng không đạt yêu cầu, hãy thử INT8 hoặc FP16.

## Phần 3: Cấu hình triển khai Foundry Local

### Tạo cấu hình mô hình

Đi đến thư mục mô hình của Foundry Local:

```bash
foundry cache cd ./models/
```

Tạo cấu trúc thư mục mô hình của bạn:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

Tạo tệp cấu hình `inference_model.json` trong thư mục mô hình của bạn:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### Cấu hình mẫu dành riêng cho mô hình

#### Đối với các mô hình dòng Qwen:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## Phần 4: Kiểm tra và tối ưu hóa mô hình

### Xác minh cài đặt mô hình

Kiểm tra xem Foundry Local có nhận diện được mô hình của bạn không:

```bash
foundry cache ls
```

Bạn sẽ thấy `your-finetuned-model-int4` trong danh sách.

### Bắt đầu kiểm tra mô hình

```bash
foundry model run your-finetuned-model-int4
```

### Đánh giá hiệu suất

Theo dõi các chỉ số chính trong quá trình kiểm tra:

1. **Thời gian phản hồi**: Đo thời gian trung bình cho mỗi phản hồi
2. **Sử dụng bộ nhớ**: Theo dõi mức tiêu thụ RAM
3. **Sử dụng CPU**: Kiểm tra tải của bộ xử lý
4. **Chất lượng đầu ra**: Đánh giá mức độ liên quan và mạch lạc của phản hồi

### Danh sách kiểm tra xác nhận chất lượng

- ✅ Mô hình phản hồi phù hợp với các truy vấn trong lĩnh vực đã tinh chỉnh
- ✅ Định dạng phản hồi khớp với cấu trúc đầu ra mong đợi
- ✅ Không có rò rỉ bộ nhớ trong quá trình sử dụng kéo dài
- ✅ Hiệu suất ổn định với các độ dài đầu vào khác nhau
- ✅ Xử lý đúng các trường hợp ngoại lệ và đầu vào không hợp lệ

## Tóm tắt

Chúc mừng! Bạn đã hoàn thành:

- ✅ Chuyển đổi định dạng mô hình đã tinh chỉnh
- ✅ Tối ưu hóa lượng tử hóa mô hình
- ✅ Cấu hình triển khai Foundry Local
- ✅ Tinh chỉnh hiệu suất và khắc phục sự cố

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.