<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2db7a2f6e9873c3cd09fea6736bf360b",
  "translation_date": "2025-09-18T12:59:23+00:00",
  "source_file": "Module05/README.md",
  "language_code": "vi"
}
-->
# Chương 05: SLMOps - Hướng Dẫn Toàn Diện Về Vận Hành Mô Hình Ngôn Ngữ Nhỏ

## Tổng Quan

SLMOps (Vận hành Mô hình Ngôn ngữ Nhỏ) đại diện cho một cách tiếp cận đột phá trong triển khai AI, ưu tiên hiệu quả, tiết kiệm chi phí và khả năng tính toán tại biên. Hướng dẫn toàn diện này bao gồm toàn bộ vòng đời của vận hành SLM, từ việc hiểu các khái niệm cơ bản đến triển khai sẵn sàng cho sản xuất.

---

## [Phần 1: Giới Thiệu Về SLMOps](./01.IntroduceSLMOps.md)

**Cách mạng hóa Vận hành AI tại Biên**

Chương nền tảng này giới thiệu sự chuyển đổi từ các vận hành AI truyền thống quy mô lớn sang Vận hành Mô hình Ngôn ngữ Nhỏ (SLMOps). Bạn sẽ khám phá cách SLMOps giải quyết các thách thức quan trọng trong việc triển khai AI ở quy mô lớn, đồng thời duy trì hiệu quả chi phí và tuân thủ quyền riêng tư.

**Những Điều Bạn Sẽ Học:**
- Sự xuất hiện và tầm quan trọng của SLMOps trong chiến lược AI hiện đại
- Cách SLMs thu hẹp khoảng cách giữa hiệu suất và hiệu quả tài nguyên
- Các nguyên tắc vận hành cốt lõi bao gồm quản lý tài nguyên thông minh và kiến trúc ưu tiên quyền riêng tư
- Các thách thức triển khai thực tế và giải pháp của chúng
- Tác động chiến lược đến doanh nghiệp và lợi thế cạnh tranh

**Điểm Mấu Chốt:** SLMOps dân chủ hóa việc triển khai AI bằng cách làm cho các khả năng xử lý ngôn ngữ tiên tiến trở nên dễ tiếp cận với các tổ chức có cơ sở hạ tầng kỹ thuật hạn chế, cho phép chu kỳ phát triển nhanh hơn và chi phí vận hành dễ dự đoán hơn.

---

## [Phần 2: Chưng Cất Mô Hình - Từ Lý Thuyết Đến Thực Tiễn](./02.SLMOps-Distillation.md)

**Tạo Mô Hình Hiệu Quả Thông Qua Chuyển Giao Kiến Thức**

Chưng cất mô hình là kỹ thuật nền tảng để tạo ra các mô hình nhỏ hơn, hiệu quả hơn mà vẫn giữ được hiệu suất của các mô hình lớn hơn. Chương này cung cấp hướng dẫn toàn diện về việc triển khai quy trình chưng cất, chuyển giao kiến thức từ các mô hình giáo viên lớn sang các mô hình học sinh nhỏ gọn.

**Những Điều Bạn Sẽ Học:**
- Các khái niệm cơ bản và lợi ích của chưng cất mô hình
- Quy trình chưng cất hai giai đoạn: tạo dữ liệu tổng hợp và huấn luyện mô hình học sinh
- Chiến lược triển khai thực tế sử dụng các mô hình tiên tiến như DeepSeek V3 và Phi-4-mini
- Quy trình chưng cất trên Azure ML với các ví dụ thực hành
- Các phương pháp tốt nhất để điều chỉnh siêu tham số và chiến lược đánh giá
- Các nghiên cứu thực tế cho thấy cải thiện đáng kể về chi phí và hiệu suất

**Điểm Mấu Chốt:** Chưng cất mô hình giúp các tổ chức giảm 85% thời gian suy luận và 95% yêu cầu bộ nhớ trong khi giữ được 92% độ chính xác của mô hình gốc, làm cho các khả năng AI tiên tiến có thể triển khai thực tế.

---

## [Phần 3: Tinh Chỉnh - Tùy Chỉnh Mô Hình Cho Nhiệm Vụ Cụ Thể](./03.SLMOps-Finetuing.md)

**Biến Đổi Mô Hình Được Huấn Luyện Sẵn Thành Giải Pháp Chuyên Biệt**

Tinh chỉnh biến đổi các mô hình đa dụng thành các giải pháp chuyên biệt phù hợp với các trường hợp sử dụng và lĩnh vực cụ thể của bạn. Chương này bao gồm mọi thứ từ điều chỉnh tham số cơ bản đến các kỹ thuật tiên tiến như LoRA và QLoRA để tùy chỉnh mô hình hiệu quả.

**Những Điều Bạn Sẽ Học:**
- Tổng quan toàn diện về các phương pháp tinh chỉnh và ứng dụng của chúng
- Các loại tinh chỉnh khác nhau: tinh chỉnh toàn bộ, tinh chỉnh hiệu quả tham số (PEFT), và các phương pháp theo nhiệm vụ cụ thể
- Triển khai thực hành sử dụng Microsoft Olive với các ví dụ thực tế
- Các kỹ thuật tiên tiến bao gồm huấn luyện đa bộ điều hợp và tối ưu hóa siêu tham số
- Các phương pháp tốt nhất cho việc chuẩn bị dữ liệu, cấu hình huấn luyện, và quản lý tài nguyên
- Các thách thức phổ biến và giải pháp đã được chứng minh cho các dự án tinh chỉnh thành công

**Điểm Mấu Chốt:** Tinh chỉnh với các công cụ như Microsoft Olive giúp các tổ chức tùy chỉnh hiệu quả các mô hình được huấn luyện sẵn theo nhu cầu cụ thể, đồng thời tối ưu hóa hiệu suất và hạn chế tài nguyên, làm cho AI tiên tiến trở nên dễ tiếp cận trong nhiều ứng dụng.

---

## [Phần 4: Triển Khai - Thực Hiện Mô Hình Sẵn Sàng Sản Xuất](./04.SLMOps.Deployment.md)

**Đưa Mô Hình Đã Tinh Chỉnh Vào Sản Xuất Với Foundry Local**

Chương cuối tập trung vào giai đoạn triển khai quan trọng, bao gồm chuyển đổi mô hình, lượng tử hóa, và cấu hình sản xuất. Bạn sẽ học cách triển khai các mô hình đã tinh chỉnh và lượng tử hóa bằng Foundry Local để tối ưu hóa hiệu suất và sử dụng tài nguyên.

**Những Điều Bạn Sẽ Học:**
- Quy trình thiết lập môi trường hoàn chỉnh và cài đặt công cụ
- Kỹ thuật chuyển đổi và lượng tử hóa mô hình cho các kịch bản triển khai khác nhau
- Cấu hình triển khai Foundry Local với các tối ưu hóa cụ thể cho mô hình
- Phương pháp đo lường hiệu suất và xác thực chất lượng
- Xử lý các vấn đề triển khai phổ biến và chiến lược tối ưu hóa
- Các phương pháp tốt nhất cho giám sát và bảo trì sản xuất

**Điểm Mấu Chốt:** Cấu hình triển khai đúng cách với các kỹ thuật lượng tử hóa có thể giảm kích thước mô hình lên đến 75% trong khi vẫn duy trì chất lượng mô hình chấp nhận được, cho phép triển khai sản xuất hiệu quả trên nhiều cấu hình phần cứng.

---

## Bắt Đầu

Hướng dẫn này được thiết kế để đưa bạn qua toàn bộ hành trình SLMOps, từ việc hiểu các khái niệm cơ bản đến triển khai sẵn sàng cho sản xuất. Mỗi chương xây dựng dựa trên chương trước, cung cấp cả kiến thức lý thuyết và kỹ năng triển khai thực tế.

Dù bạn là nhà khoa học dữ liệu muốn tối ưu hóa triển khai mô hình, kỹ sư DevOps thực hiện vận hành AI, hay lãnh đạo kỹ thuật đánh giá SLMOps cho tổ chức của mình, hướng dẫn toàn diện này cung cấp kiến thức và công cụ cần thiết để triển khai thành công Vận hành Mô hình Ngôn ngữ Nhỏ.

**Sẵn sàng bắt đầu chưa?** Hãy bắt đầu với Chương 1 để hiểu các nguyên tắc cơ bản của SLMOps và xây dựng nền tảng cho các kỹ thuật triển khai tiên tiến được đề cập trong các chương tiếp theo.

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp từ con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.