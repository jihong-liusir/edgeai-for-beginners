<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "50eb9028095f21012291c453fc82b40c",
  "translation_date": "2025-09-18T12:30:02+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "vi"
}
-->
# Các Tác Nhân AI và Mô Hình Ngôn Ngữ Nhỏ: Hướng Dẫn Toàn Diện

## Giới Thiệu

Trong hướng dẫn này, chúng ta sẽ khám phá các Tác Nhân AI và Mô Hình Ngôn Ngữ Nhỏ (SLMs) cùng với các chiến lược triển khai tiên tiến trong môi trường tính toán biên. Chúng ta sẽ tìm hiểu các khái niệm cơ bản về AI tác nhân, kỹ thuật tối ưu hóa SLM, và chiến lược triển khai thực tế cho các thiết bị hạn chế tài nguyên.

Năm 2025 đánh dấu một sự chuyển đổi lớn trong lĩnh vực trí tuệ nhân tạo. Trong khi năm 2023 là năm của chatbot và năm 2024 chứng kiến sự bùng nổ của các copilots, thì năm 2025 thuộc về các tác nhân AI — hệ thống thông minh có khả năng suy nghĩ, lập luận, lập kế hoạch, sử dụng công cụ, và thực hiện nhiệm vụ với sự can thiệp tối thiểu từ con người, được hỗ trợ ngày càng nhiều bởi các Mô Hình Ngôn Ngữ Nhỏ hiệu quả.

## Mục Tiêu Học Tập

Kết thúc hướng dẫn này, bạn sẽ có thể:

- 🤖 Hiểu các khái niệm cơ bản về tác nhân AI và hệ thống tác nhân
- 🔬 Xác định lợi thế của Mô Hình Ngôn Ngữ Nhỏ so với Mô Hình Ngôn Ngữ Lớn trong các ứng dụng tác nhân
- 🚀 Học các chiến lược triển khai SLM tiên tiến trong môi trường tính toán biên
- 📱 Triển khai các tác nhân sử dụng SLM cho các ứng dụng thực tế

## Hiểu Về Tác Nhân AI: Nền Tảng và Phân Loại

### Định Nghĩa và Các Khái Niệm Cốt Lõi

Tác nhân trí tuệ nhân tạo (AI agent) là một hệ thống hoặc chương trình có khả năng tự động thực hiện các nhiệm vụ thay mặt cho người dùng hoặc hệ thống khác bằng cách thiết kế quy trình làm việc và sử dụng các công cụ có sẵn. Khác với AI truyền thống chỉ phản hồi câu hỏi của bạn, một tác nhân có thể hành động độc lập để đạt được mục tiêu.

### Khung Phân Loại Tác Nhân

Hiểu rõ ranh giới của tác nhân giúp lựa chọn loại tác nhân phù hợp cho các kịch bản tính toán khác nhau:

- **🔬 Tác Nhân Phản Xạ Đơn Giản**: Hệ thống dựa trên quy tắc phản hồi theo nhận thức tức thời (máy điều nhiệt, tự động hóa cơ bản)
- **📱 Tác Nhân Dựa Trên Mô Hình**: Hệ thống duy trì trạng thái nội bộ và bộ nhớ (robot hút bụi, hệ thống định vị)
- **⚖️ Tác Nhân Dựa Trên Mục Tiêu**: Hệ thống lập kế hoạch và thực hiện các chuỗi hành động để đạt được mục tiêu (lập kế hoạch tuyến đường, lập lịch công việc)
- **🧠 Tác Nhân Học Tập**: Hệ thống thích nghi cải thiện hiệu suất theo thời gian (hệ thống gợi ý, trợ lý cá nhân)

### Lợi Thế Chính của Tác Nhân AI

Tác nhân AI mang lại nhiều lợi ích cơ bản khiến chúng trở nên lý tưởng cho các ứng dụng tính toán biên:

**Tự Chủ Vận Hành**: Tác nhân cung cấp khả năng thực hiện nhiệm vụ độc lập mà không cần giám sát liên tục, lý tưởng cho các ứng dụng thời gian thực. Chúng yêu cầu ít sự giám sát trong khi duy trì hành vi thích nghi, cho phép triển khai trên các thiết bị hạn chế tài nguyên với chi phí vận hành thấp.

**Linh Hoạt Triển Khai**: Các hệ thống này cho phép khả năng AI trên thiết bị mà không cần kết nối internet, tăng cường quyền riêng tư và bảo mật thông qua xử lý cục bộ, có thể tùy chỉnh cho các ứng dụng chuyên biệt, và phù hợp với nhiều môi trường tính toán biên.

**Hiệu Quả Chi Phí**: Hệ thống tác nhân mang lại triển khai hiệu quả về chi phí so với các giải pháp dựa trên đám mây, với chi phí vận hành thấp hơn và yêu cầu băng thông thấp hơn cho các ứng dụng biên.

## Chiến Lược Tiên Tiến cho Mô Hình Ngôn Ngữ Nhỏ

### Nền Tảng của SLM (Mô Hình Ngôn Ngữ Nhỏ)

Mô Hình Ngôn Ngữ Nhỏ (SLM) là một mô hình ngôn ngữ có thể hoạt động trên các thiết bị điện tử tiêu dùng phổ biến và thực hiện suy luận với độ trễ đủ thấp để phục vụ các yêu cầu tác nhân của một người dùng. Trong thực tế, SLM thường là các mô hình có ít hơn 10 tỷ tham số.

**Các Tính Năng Khám Phá Định Dạng**: SLM cung cấp hỗ trợ tiên tiến cho các mức lượng tử hóa khác nhau, khả năng tương thích đa nền tảng, tối ưu hóa hiệu suất thời gian thực, và khả năng triển khai biên. Người dùng có thể truy cập quyền riêng tư nâng cao thông qua xử lý cục bộ và hỗ trợ WebGPU cho triển khai trên trình duyệt.

**Bộ Sưu Tập Mức Lượng Tử Hóa**: Các định dạng SLM phổ biến bao gồm Q4_K_M cho nén cân bằng trong các ứng dụng di động, dòng Q5_K_S cho triển khai biên tập trung vào chất lượng, Q8_0 cho độ chính xác gần như nguyên bản trên các thiết bị biên mạnh mẽ, và các định dạng thử nghiệm như Q2_K cho các kịch bản tài nguyên cực thấp.

### GGUF (Định Dạng Chung GGML Universal) cho Triển Khai SLM

GGUF là định dạng chính để triển khai các SLM lượng tử hóa trên CPU và các thiết bị biên, được tối ưu hóa đặc biệt cho các ứng dụng tác nhân:

**Các Tính Năng Tối Ưu Hóa Tác Nhân**: Định dạng cung cấp các tài nguyên toàn diện cho chuyển đổi và triển khai SLM với hỗ trợ nâng cao cho gọi công cụ, tạo đầu ra có cấu trúc, và các cuộc hội thoại nhiều lượt. Khả năng tương thích đa nền tảng đảm bảo hành vi tác nhân nhất quán trên các thiết bị biên khác nhau.

**Tối Ưu Hóa Hiệu Suất**: GGUF cho phép sử dụng bộ nhớ hiệu quả cho quy trình làm việc của tác nhân, hỗ trợ tải mô hình động cho các hệ thống đa tác nhân, và cung cấp suy luận tối ưu cho các tương tác tác nhân thời gian thực.

### Các Khung SLM Tối Ưu Hóa cho Biên

#### Tối Ưu Hóa Llama.cpp cho Tác Nhân

Llama.cpp cung cấp các kỹ thuật lượng tử hóa tiên tiến được tối ưu hóa đặc biệt cho triển khai SLM tác nhân:

**Lượng Tử Hóa Cụ Thể cho Tác Nhân**: Khung hỗ trợ Q4_0 (tối ưu cho triển khai tác nhân di động với giảm kích thước 75%), Q5_1 (cân bằng chất lượng-nén cho các tác nhân suy luận biên), và Q8_0 (chất lượng gần như nguyên bản cho các hệ thống tác nhân sản xuất). Các định dạng tiên tiến cho phép các tác nhân siêu nén cho các kịch bản biên cực đoan.

**Lợi Ích Triển Khai**: Suy luận tối ưu hóa CPU với tăng tốc SIMD cung cấp thực thi tác nhân hiệu quả về bộ nhớ. Khả năng tương thích đa nền tảng trên các kiến trúc x86, ARM, và Apple Silicon cho phép khả năng triển khai tác nhân toàn cầu.

#### Khung Apple MLX cho Tác Nhân SLM

Apple MLX cung cấp tối ưu hóa bản địa được thiết kế đặc biệt cho các tác nhân sử dụng SLM trên các thiết bị Apple Silicon:

**Tối Ưu Hóa Tác Nhân Apple Silicon**: Khung sử dụng kiến trúc bộ nhớ hợp nhất với tích hợp Metal Performance Shaders, độ chính xác hỗn hợp tự động cho suy luận tác nhân, và băng thông bộ nhớ tối ưu cho các hệ thống đa tác nhân. Các tác nhân SLM cho thấy hiệu suất vượt trội trên chip dòng M.

**Các Tính Năng Phát Triển**: Hỗ trợ API Python và Swift với các tối ưu hóa cụ thể cho tác nhân, phân biệt tự động cho học tập tác nhân, và tích hợp liền mạch với các công cụ phát triển của Apple cung cấp môi trường phát triển tác nhân toàn diện.

## SLM vs LLM trong Hệ Thống Tác Nhân: So Sánh Nâng Cao

### Lợi Thế của SLM trong Ứng Dụng Tác Nhân

**Hiệu Quả Vận Hành**: SLM cung cấp giảm chi phí 10-30× so với LLM cho các nhiệm vụ tác nhân, cho phép phản hồi tác nhân thời gian thực ở quy mô lớn. Chúng mang lại thời gian suy luận nhanh hơn nhờ độ phức tạp tính toán giảm, khiến chúng trở nên lý tưởng cho các ứng dụng tác nhân tương tác.

**Khả Năng Triển Khai Biên**: SLM cho phép thực thi tác nhân trên thiết bị mà không cần phụ thuộc vào internet, tăng cường quyền riêng tư thông qua xử lý tác nhân cục bộ, và tùy chỉnh cho các ứng dụng tác nhân chuyên biệt phù hợp với nhiều môi trường tính toán biên.

**Tối Ưu Hóa Cụ Thể cho Tác Nhân**: SLM vượt trội trong việc gọi công cụ, tạo đầu ra có cấu trúc, và quy trình ra quyết định thường xuyên chiếm 70-80% các nhiệm vụ tác nhân điển hình.

### Khi Nào Nên Sử Dụng SLM so với LLM trong Hệ Thống Tác Nhân

**Hoàn Hảo cho SLM**:
- **Nhiệm vụ tác nhân lặp lại**: Nhập dữ liệu, điền biểu mẫu, gọi API thường xuyên
- **Tích hợp công cụ**: Truy vấn cơ sở dữ liệu, thao tác tệp, tương tác hệ thống
- **Quy trình có cấu trúc**: Thực hiện các quy trình tác nhân được định sẵn
- **Tác nhân chuyên biệt**: Dịch vụ khách hàng, lập lịch, phân tích cơ bản
- **Xử lý cục bộ**: Các hoạt động tác nhân nhạy cảm với quyền riêng tư

**Tốt hơn cho LLM**:
- **Lập luận phức tạp**: Giải quyết vấn đề mới, lập kế hoạch chiến lược
- **Hội thoại mở**: Trò chuyện chung, thảo luận sáng tạo
- **Nhiệm vụ kiến thức rộng**: Nghiên cứu yêu cầu kiến thức chung rộng lớn
- **Tình huống mới**: Xử lý các kịch bản tác nhân hoàn toàn mới

### Kiến Trúc Tác Nhân Lai

Cách tiếp cận tối ưu kết hợp SLM và LLM trong các hệ thống tác nhân dị thể:

**Điều Phối Tác Nhân Thông Minh**:
1. **SLM làm chính**: Xử lý 70-80% các nhiệm vụ tác nhân thường xuyên tại chỗ
2. **LLM khi cần**: Chuyển các truy vấn phức tạp đến các mô hình lớn dựa trên đám mây
3. **SLM chuyên biệt**: Các mô hình nhỏ khác nhau cho các lĩnh vực tác nhân khác nhau
4. **Tối ưu hóa chi phí**: Giảm thiểu các cuộc gọi LLM đắt đỏ thông qua định tuyến thông minh

## Chiến Lược Triển Khai Tác Nhân SLM Sản Xuất

### Ollama: Triển Khai Tác Nhân SLM Đơn Giản

Ollama đơn giản hóa việc triển khai tác nhân SLM với các tính năng sẵn sàng cho doanh nghiệp trong môi trường cục bộ và biên:

**Khả Năng Triển Khai Tác Nhân**: Cài đặt và thực thi SLM chỉ với một lệnh với tự động tải và lưu trữ mô hình. Hỗ trợ các định dạng SLM lượng tử hóa khác nhau với REST API để tích hợp tác nhân và quản lý đa mô hình cho các hệ thống tác nhân phức tạp.

**Các Tính Năng Tác Nhân Nâng Cao**: Tinh chỉnh SLM tùy chỉnh cho các nhiệm vụ tác nhân cụ thể, triển khai container hóa cho các hệ thống tác nhân có khả năng mở rộng, tăng tốc GPU với phát hiện tự động, và tối ưu hóa lượng tử hóa mô hình cho triển khai tác nhân biên.

### VLLM: Suy Luận Tác Nhân SLM Hiệu Suất Cao

VLLM cung cấp tối ưu hóa suy luận cấp sản xuất cho các kịch bản tác nhân thông lượng cao:

**Tối Ưu Hóa Hiệu Suất Tác Nhân**: PagedAttention cho tính toán chú ý tác nhân hiệu quả về bộ nhớ, batching động để tối ưu hóa thông lượng tác nhân, và giải mã suy đoán để giảm độ trễ tác nhân. Các định dạng lượng tử hóa tiên tiến cho phép hiệu suất tác nhân SLM tối ưu.

**Tích Hợp Tác Nhân Doanh Nghiệp**: Các điểm cuối API tương thích với OpenAI để tích hợp tác nhân liền mạch, hỗ trợ triển khai Kubernetes cho các hệ thống tác nhân có khả năng mở rộng, và khả năng giám sát để tối ưu hóa hiệu suất tác nhân.

### Giải Pháp Tác Nhân SLM Biên của Microsoft

Microsoft cung cấp các khả năng triển khai biên toàn diện cho các tác nhân doanh nghiệp sử dụng SLM:

**Các Tính Năng Tính Toán Tác Nhân Biên**: Thiết kế kiến trúc tác nhân ưu tiên ngoại tuyến với tối ưu hóa hạn chế tài nguyên, quản lý registry SLM cục bộ, và khả năng đồng bộ hóa tác nhân từ biên đến đám mây đảm bảo triển khai tác nhân đáng tin cậy.

**Bảo Mật và Tuân Thủ**: Xử lý dữ liệu tác nhân cục bộ để bảo vệ quyền riêng tư, kiểm soát bảo mật doanh nghiệp cho các hệ thống tác nhân, và ghi nhật ký kiểm toán để báo cáo tuân thủ tác nhân cung cấp bảo mật toàn diện cho các triển khai tác nhân biên.

## Ứng Dụng Tác Nhân SLM Thực Tế

### Tác Nhân Dịch Vụ Khách Hàng SLM
- **Khả năng của SLM**: Tra cứu tài khoản, đặt lại mật khẩu, kiểm tra trạng thái đơn hàng
- **Lợi ích chi phí**: Giảm chi phí suy luận 10 lần so với tác nhân LLM
- **Hiệu suất**: Thời gian phản hồi nhanh hơn với chất lượng nhất quán cho các truy vấn thường xuyên

### Tác Nhân Quy Trình Kinh Doanh SLM
- **Tác nhân xử lý hóa đơn**: Trích xuất dữ liệu, xác thực thông tin, chuyển tiếp để phê duyệt
- **Tác nhân quản lý email**: Phân loại, ưu tiên, soạn thảo phản hồi tự động
- **Tác nhân lập lịch**: Điều phối cuộc họp, quản lý lịch, gửi nhắc nhở

### Trợ Lý Kỹ Thuật Số Cá Nhân SLM
- **Tác nhân quản lý nhiệm vụ**: Tạo, cập nhật, tổ chức danh sách việc cần làm hiệu quả
- **Tác nhân thu thập thông tin**: Nghiên cứu chủ đề, tóm tắt kết quả cục bộ
- **Tác nhân giao tiếp**: Soạn thảo email, tin nhắn, bài đăng mạng xã hội một cách riêng tư

### Tác Nhân Giao Dịch và Tài Chính SLM
- **Tác nhân giám sát thị trường**: Theo dõi giá cả, xác định xu hướng trong thời gian thực
- **Tác nhân tạo báo cáo**: Tự động tạo các bản tóm tắt hàng ngày/tuần
- **Tác nhân đánh giá rủi ro**: Đánh giá vị trí danh mục đầu tư bằng dữ liệu cục bộ

### Tác Nhân Hỗ Trợ Y Tế SLM
- **Tác nhân lập lịch bệnh nhân**: Điều phối cuộc hẹn, gửi nhắc nhở tự động
- **Tác nhân tài liệu**: Tạo tóm tắt y tế, báo cáo cục bộ
- **Tác nhân quản lý đơn thuốc**: Theo dõi việc tái cấp, kiểm tra tương tác một cách riêng tư

## Các Thực Tiễn Tốt Nhất cho Triển Khai Tác Nhân SLM

### Hướng Dẫn Lựa Chọn SLM cho Tác Nhân

Khi chọn SLM cho triển khai tác nhân, hãy xem xét các yếu tố sau:

**Cân Nhắc Kích Thước Mô Hình**: Chọn các mô hình siêu nén như Q2_K cho các ứng dụng tác nhân di động cực đoan, các mô hình cân bằng như Q4_K_M cho các kịch bản tác nhân chung, và các mô hình độ chính xác cao như Q8_0 cho các ứng dụng tác nhân quan trọng về chất lượng.

**Sự Phù Hợp với Trường Hợp Sử Dụng Tác Nhân**: Kết hợp khả năng của SLM với các yêu cầu cụ thể của tác nhân, xem xét các yếu tố như bảo toàn độ chính xác cho các quyết định của tác nhân, tốc độ suy luận cho các tương tác tác nhân thời gian thực, hạn chế bộ nhớ cho triển khai tác nhân biên, và yêu cầu hoạt động ngoại tuyến cho các tác nhân tập trung vào quyền riêng tư.

### Lựa Chọn Chiến Lược Tối Ưu Hóa cho Tác Nhân SLM

**Cách Tiếp Cận Lượng Tử Hóa cho Tác Nhân**: Chọn mức lượng tử hóa phù hợp dựa trên yêu cầu chất lượng của tác nhân và hạn chế phần cứng. Xem xét Q4_0 cho nén tối đa trong các tác nhân di động, Q5_1 cho cân bằng chất lượng-nén trong các tác nhân chung, và Q8_0 cho chất lượng gần như nguyên bản trong các ứng dụng tác nhân quan trọng.

**Lựa Chọn Khung cho Triển Khai Tác Nhân**: Chọn các khung tối ưu
### Bảo mật và Quyền riêng tư trong Hệ thống Đại lý SLM

Mặc dù các đại lý SLM cho phép xử lý cục bộ để tăng cường quyền riêng tư, các biện pháp bảo mật phù hợp phải được triển khai để bảo vệ mô hình đại lý và dữ liệu trong môi trường biên. Điều này đặc biệt quan trọng khi triển khai các định dạng đại lý có độ chính xác cao trong môi trường doanh nghiệp hoặc các định dạng đại lý nén trong các ứng dụng xử lý dữ liệu nhạy cảm.

## Xu hướng Tương lai trong Phát triển Đại lý SLM

Cảnh quan đại lý SLM tiếp tục phát triển với những tiến bộ trong kỹ thuật nén, phương pháp tối ưu hóa và chiến lược triển khai biên. Các phát triển trong tương lai bao gồm các thuật toán lượng hóa hiệu quả hơn cho mô hình đại lý, phương pháp nén cải tiến cho quy trình làm việc của đại lý, và tích hợp tốt hơn với các bộ tăng tốc phần cứng biên để xử lý đại lý.

**Dự đoán Thị trường cho Đại lý SLM**: Theo nghiên cứu gần đây, tự động hóa dựa trên đại lý có thể loại bỏ 40–60% các nhiệm vụ nhận thức lặp lại trong quy trình làm việc doanh nghiệp vào năm 2027, với SLM dẫn đầu sự chuyển đổi này nhờ hiệu quả chi phí và tính linh hoạt trong triển khai.

**Xu hướng Công nghệ trong Đại lý SLM**:
- **Đại lý SLM chuyên biệt**: Các mô hình theo lĩnh vực được đào tạo cho các nhiệm vụ đại lý và ngành cụ thể
- **Tính toán Đại lý Biên**: Nâng cao khả năng đại lý trên thiết bị với quyền riêng tư tốt hơn và độ trễ giảm
- **Điều phối Đại lý**: Phối hợp tốt hơn giữa nhiều đại lý SLM với định tuyến động và cân bằng tải
- **Dân chủ hóa**: Tính linh hoạt của SLM cho phép nhiều tổ chức tham gia phát triển đại lý hơn

## Bắt đầu với Đại lý SLM

### Bước 1: Chọn SLM cho Ứng dụng Đại lý
Các tùy chọn phổ biến cho ứng dụng đại lý:
- **Microsoft Phi-4 Mini (3.8B)**: Tuyệt vời cho các nhiệm vụ đại lý chung với hiệu suất cân bằng
- **NVIDIA Nemotron-4-Mini (4B)**: Xuất sắc trong việc gọi công cụ trong hệ thống đại lý
- **Hugging Face SmolLM2 (1.7B)**: Siêu hiệu quả cho quy trình làm việc đại lý đơn giản
- **DeepSeek-R1-Distill (1.5-8B)**: Khả năng suy luận mạnh mẽ cho các đại lý phức tạp

### Bước 2: Xác định Phạm vi và Yêu cầu của Đại lý
Bắt đầu với các ứng dụng đại lý tập trung và được xác định rõ ràng:
- **Đại lý một lĩnh vực**: Dịch vụ khách hàng HOẶC lập lịch HOẶC nghiên cứu
- **Mục tiêu đại lý rõ ràng**: Các mục tiêu cụ thể, có thể đo lường cho hiệu suất đại lý
- **Tích hợp công cụ hạn chế**: Tối đa 3-5 công cụ cho triển khai đại lý ban đầu
- **Ranh giới đại lý được xác định**: Các đường dẫn rõ ràng để xử lý các tình huống phức tạp

### Bước 3: Triển khai Tối ưu hóa Đại lý SLM
Tinh chỉnh SLM cho các trường hợp sử dụng đại lý cụ thể bằng cách thu thập dữ liệu hướng dẫn chuyên biệt từ các tương tác đại lý và sử dụng dữ liệu này để tạo ra các biến thể SLM chuyên gia, giúp giảm chi phí và cải thiện hiệu suất cho các nhiệm vụ đại lý cụ thể.

### Bước 4: Triển khai Biện pháp An toàn cho Đại lý SLM
- **Xác thực đầu vào đại lý**: Kiểm tra yêu cầu để đảm bảo an toàn và phù hợp
- **Lọc đầu ra đại lý**: Đảm bảo phản hồi đáp ứng tiêu chuẩn chất lượng
- **Tích hợp giám sát con người**: Các quyết định quan trọng của đại lý cần được phê duyệt
- **Giám sát đại lý**: Theo dõi hiệu suất và đánh dấu các vấn đề trong thời gian thực

### Bước 5: Đo lường và Tối ưu hóa Hiệu suất Đại lý SLM
- **Tỷ lệ hoàn thành nhiệm vụ của đại lý**: Đại lý thành công bao nhiêu lần?
- **Thời gian phản hồi của đại lý**: Tương tác có đủ nhanh cho người dùng không?
- **Sự hài lòng của người dùng với đại lý**: Người dùng có thấy đại lý hữu ích và đáng tin cậy không?
- **Hiệu quả chi phí của đại lý**: So sánh với các giải pháp trước đây và các lựa chọn thay thế trên đám mây

## Những Điểm Chính cho Triển khai Đại lý SLM

1. **SLM đủ cho đại lý**: Đối với hầu hết các nhiệm vụ đại lý, các mô hình nhỏ hoạt động tốt như các mô hình lớn trong khi mang lại lợi ích đáng kể
2. **Hiệu quả chi phí trong đại lý**: Chạy đại lý SLM rẻ hơn 10-30 lần, khiến chúng khả thi về mặt kinh tế cho triển khai rộng rãi
3. **Chuyên môn hóa hiệu quả cho đại lý**: SLM được tinh chỉnh thường vượt trội hơn LLM đa dụng trong các ứng dụng đại lý cụ thể
4. **Kiến trúc đại lý lai**: Sử dụng SLM cho các nhiệm vụ đại lý thường xuyên, LLM cho suy luận phức tạp khi cần thiết
5. **Tương lai là đại lý SLM**: Các mô hình ngôn ngữ nhỏ là tương lai của AI đại lý, cho phép triển khai đại lý dân chủ hóa và hiệu quả

## ➡️ Điều gì Tiếp theo

Sự chuyển đổi sang các đại lý dựa trên SLM đại diện cho một sự thay đổi cơ bản trong cách chúng ta tiếp cận triển khai AI. Bằng cách tập trung vào hiệu quả, chuyên môn hóa và tiện ích thực tế, SLM đang làm cho các đại lý AI trở nên dễ tiếp cận, tiết kiệm chi phí và hiệu quả hơn cho các ứng dụng thực tế trong mọi ngành công nghiệp và môi trường tính toán biên.

Khi chúng ta tiến đến năm 2025, sự kết hợp giữa các mô hình nhỏ ngày càng mạnh mẽ và các khung đại lý tinh vi sẽ mở ra những khả năng mới cho các hệ thống tự động có thể hoạt động hiệu quả trên các thiết bị biên trong khi duy trì quyền riêng tư, giảm chi phí và mang lại trải nghiệm người dùng xuất sắc.

## ➡️ Điều gì tiếp theo

- [02: Gọi Hàm trong Các Mô hình Ngôn ngữ Nhỏ (SLMs)](./02.FunctionCalling.md)

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp từ con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.