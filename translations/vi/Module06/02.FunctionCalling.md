<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-09-18T12:25:22+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "vi"
}
-->
# Section02 : Gọi Hàm trong Mô Hình Ngôn Ngữ Nhỏ (SLMs)

## Mục Lục
1. [Gọi Hàm là gì?](../../../Module06)
2. [Cách Gọi Hàm Hoạt Động](../../../Module06)
3. [Các Kịch Bản Ứng Dụng](../../../Module06)
4. [Cài Đặt Gọi Hàm với Phi-4-mini và Ollama](../../../Module06)
5. [Làm Việc với Gọi Hàm của Qwen3](../../../Module06)
6. [Tích Hợp Foundry Local](../../../Module06)
7. [Thực Hành Tốt Nhất và Xử Lý Sự Cố](../../../Module06)
8. [Ví Dụ Nâng Cao](../../../Module06)

## Gọi Hàm là gì?

Gọi hàm là một khả năng mạnh mẽ cho phép các Mô Hình Ngôn Ngữ Nhỏ (SLMs) tương tác với các công cụ, API và dịch vụ bên ngoài. Thay vì chỉ giới hạn trong dữ liệu huấn luyện, SLMs giờ đây có thể:

- **Kết nối với các API bên ngoài** (dịch vụ thời tiết, cơ sở dữ liệu, công cụ tìm kiếm)
- **Thực thi các hàm cụ thể** dựa trên yêu cầu của người dùng
- **Lấy thông tin thời gian thực** từ nhiều nguồn khác nhau
- **Thực hiện các tác vụ tính toán** thông qua các công cụ chuyên biệt
- **Kết hợp nhiều thao tác** để tạo ra các quy trình phức tạp

Khả năng này biến SLMs từ các trình tạo văn bản tĩnh thành các tác nhân AI động có thể thực hiện các nhiệm vụ thực tế.

## Cách Gọi Hàm Hoạt Động

Quy trình gọi hàm tuân theo một luồng công việc có hệ thống:

### 1. Tích Hợp Công Cụ
- **Công cụ bên ngoài**: SLMs có thể kết nối với các API thời tiết, cơ sở dữ liệu, dịch vụ web và các hệ thống bên ngoài khác
- **Định nghĩa Hàm**: Mỗi công cụ được định nghĩa với các tham số cụ thể, định dạng đầu vào/đầu ra và mô tả
- **Tương thích API**: Các công cụ được tích hợp thông qua các giao diện tiêu chuẩn (REST APIs, SDKs, v.v.)

### 2. Định Nghĩa Hàm
Các hàm được định nghĩa với ba thành phần chính:
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Phát Hiện Ý Định
- **Xử lý Ngôn ngữ Tự nhiên**: SLM phân tích đầu vào của người dùng để hiểu ý định
- **Khớp Hàm**: Xác định hàm nào cần được gọi để đáp ứng yêu cầu
- **Trích Xuất Tham Số**: Xác định và trích xuất các tham số cần thiết từ tin nhắn của người dùng

### 4. Tạo Đầu Ra JSON
SLM tạo ra một JSON có cấu trúc bao gồm:
- Tên hàm cần gọi
- Các tham số cần thiết với giá trị phù hợp
- Ngữ cảnh thực thi và siêu dữ liệu

### 5. Thực Thi Bên Ngoài
- **Xác Thực Tham Số**: Đảm bảo tất cả các tham số cần thiết đều có và được định dạng đúng
- **Thực Thi Hàm**: Ứng dụng thực thi hàm được chỉ định với các tham số đã cung cấp
- **Xử Lý Lỗi**: Quản lý các lỗi, hết thời gian và phản hồi không hợp lệ

### 6. Tích Hợp Phản Hồi
- **Xử Lý Kết Quả**: Đầu ra của hàm được trả về cho SLM
- **Tích Hợp Ngữ Cảnh**: SLM kết hợp kết quả vào phản hồi của nó
- **Giao Tiếp với Người Dùng**: Trình bày thông tin dưới dạng tự nhiên, dễ hiểu

## Các Kịch Bản Ứng Dụng

### Truy Xuất Dữ Liệu
Chuyển đổi các truy vấn ngôn ngữ tự nhiên thành các lệnh gọi API có cấu trúc:
- **"Hiển thị các đơn hàng gần đây của tôi"** → Truy vấn cơ sở dữ liệu với ID người dùng và bộ lọc ngày
- **"Thời tiết ở Tokyo thế nào?"** → Gọi API thời tiết với tham số vị trí
- **"Tìm email từ John tuần trước"** → Truy vấn dịch vụ email với bộ lọc người gửi và ngày

### Thực Thi Tác Vụ
Chuyển đổi yêu cầu của người dùng thành các lệnh gọi hàm cụ thể:
- **"Lên lịch họp vào ngày mai lúc 2 giờ chiều"** → Tích hợp API lịch
- **"Gửi tin nhắn cho nhóm"** → API nền tảng giao tiếp
- **"Tạo bản sao lưu cho các tệp của tôi"** → Thao tác hệ thống tệp

### Tác Vụ Tính Toán
Xử lý các phép toán hoặc logic phức tạp:
- **"Tính lãi kép cho $10,000 với lãi suất 5% trong 10 năm"** → Hàm tính toán tài chính
- **"Phân tích tập dữ liệu này để tìm xu hướng"** → Công cụ phân tích thống kê
- **"Tối ưu hóa tuyến đường giao hàng này"** → Thuật toán tối ưu hóa tuyến đường

### Quy Trình Xử Lý Dữ Liệu
Kết hợp nhiều lệnh gọi hàm để thực hiện các thao tác phức tạp:
1. **Truy xuất dữ liệu** từ nhiều nguồn
2. **Phân tích và xác thực** thông tin
3. **Chuyển đổi** dữ liệu sang định dạng yêu cầu
4. **Lưu kết quả** vào các hệ thống phù hợp
5. **Tạo báo cáo** hoặc hình ảnh hóa

### Tích Hợp UI/UX
Cho phép cập nhật giao diện động:
- **"Hiển thị dữ liệu bán hàng trên bảng điều khiển"** → Tạo và hiển thị biểu đồ
- **"Cập nhật bản đồ với các vị trí mới"** → Tích hợp dữ liệu địa lý
- **"Làm mới hiển thị kho hàng"** → Đồng bộ hóa dữ liệu thời gian thực

## Cài Đặt Gọi Hàm với Phi-4-mini và Ollama

Phi-4-mini của Microsoft hỗ trợ cả gọi hàm đơn và song song thông qua Ollama. Dưới đây là cách cài đặt:

### Yêu Cầu Trước
- Phiên bản Ollama 0.5.13 hoặc cao hơn
- Mô hình Phi-4-mini (khuyến nghị: `phi4-mini:3.8b-fp16`)

### Các Bước Cài Đặt

#### 1. Cài Đặt và Chạy Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Tạo Mẫu ModelFile Tùy Chỉnh
Do các hạn chế hiện tại trong các mẫu mặc định của Ollama, bạn cần tạo một ModelFile tùy chỉnh với mẫu sau:

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Tạo Mô Hình Tùy Chỉnh
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Ví Dụ Gọi Hàm Đơn

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Ví Dụ Gọi Hàm Song Song

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Làm Việc với Gọi Hàm của Qwen3

Qwen3 cung cấp khả năng gọi hàm tiên tiến với hiệu suất và tính linh hoạt cao. Dưới đây là cách triển khai:

### Sử Dụng Khung Qwen-Agent

Qwen-Agent cung cấp một khung cấp cao giúp đơn giản hóa việc triển khai gọi hàm:

#### Cài Đặt
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Cấu Hình Cơ Bản

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Triển Khai Hàm Tùy Chỉnh

Bạn cũng có thể định nghĩa các hàm tùy chỉnh cho Qwen3:

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Các Tính Năng Nâng Cao của Qwen3

#### Kiểm Soát Chế Độ Suy Nghĩ
Qwen3 hỗ trợ chuyển đổi động giữa chế độ suy nghĩ và không suy nghĩ:

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Gọi Hàm Nhiều Bước
Qwen3 xuất sắc trong việc kết hợp nhiều lệnh gọi hàm:

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Tích Hợp Foundry Local

Foundry Local của Microsoft cung cấp một API tương thích với OpenAI để chạy các mô hình cục bộ với tính riêng tư và hiệu suất cao hơn.

### Cài Đặt và Triển Khai

#### Windows
Tải xuống trình cài đặt từ [trang phát hành Foundry Local](https://github.com/microsoft/Foundry-Local/releases) và làm theo hướng dẫn cài đặt.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Sử Dụng Cơ Bản

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Các Tính Năng Nâng Cao của Foundry Local

#### Quản Lý Mô Hình
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Tối Ưu Hóa Hiệu Suất
Foundry Local tự động chọn biến thể mô hình tốt nhất cho phần cứng của bạn:
- **CUDA GPU**: Tải xuống các mô hình tối ưu hóa GPU
- **Qualcomm NPU**: Sử dụng các biến thể tăng tốc NPU
- **Chỉ CPU**: Chọn các mô hình tối ưu hóa CPU

## Thực Hành Tốt Nhất và Xử Lý Sự Cố

### Thực Hành Tốt Nhất Khi Định Nghĩa Hàm

#### 1. Đặt Tên Rõ Ràng và Mô Tả
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Định Nghĩa Tham Số Toàn Diện
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Xác Thực Đầu Vào và Xử Lý Lỗi
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Các Vấn Đề Thường Gặp và Giải Pháp

#### Vấn Đề 1: Hàm Không Được Gọi
**Triệu Chứng**: Mô hình phản hồi bằng văn bản thay vì gọi hàm

**Giải Pháp**:
1. **Kiểm tra mô tả hàm**: Đảm bảo nó rõ ràng và phù hợp với ý định của người dùng
2. **Xác minh định nghĩa tham số**: Đảm bảo tất cả các tham số cần thiết được định nghĩa đúng
3. **Xem lại lời nhắc hệ thống**: Bao gồm hướng dẫn rõ ràng về thời điểm sử dụng hàm
4. **Kiểm tra với yêu cầu rõ ràng**: Thử "Vui lòng sử dụng hàm thời tiết để lấy dữ liệu cho London"

#### Vấn Đề 2: Tham Số Sai
**Triệu Chứng**: Hàm được gọi với tham số sai hoặc thiếu

**Giải Pháp**:
1. **Thêm ví dụ tham số**: Bao gồm các giá trị mẫu trong mô tả tham số
2. **Sử dụng ràng buộc enum**: Giới hạn giá trị tham số vào các tùy chọn cụ thể khi có thể
3. **Triển khai giá trị dự phòng**: Cung cấp giá trị mặc định hợp lý cho các tham số tùy chọn

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Vấn Đề 3: Lỗi Gọi Hàm Song Song
**Triệu Chứng**: Chỉ một hàm được thực thi khi nhiều hàm cần chạy

**Giải Pháp**:
1. **Kiểm tra hỗ trợ mô hình**: Đảm bảo mô hình của bạn hỗ trợ gọi hàm song song
2. **Cập nhật lời nhắc hệ thống**: Bao gồm "một số công cụ" hoặc "nhiều công cụ" trong tin nhắn hệ thống
3. **Sử dụng phiên bản mô hình phù hợp**: Phi-4-mini:3.8b-fp16 được khuyến nghị cho Ollama

#### Vấn Đề 4: Vấn Đề Mẫu với Ollama
**Triệu Chứng**: Gọi hàm không hoạt động với thiết lập mặc định của Ollama

**Giải Pháp**:
1. **Sử dụng ModelFile tùy chỉnh**: Áp dụng mẫu đã chỉnh sửa được cung cấp trong hướng dẫn này
2. **Cập nhật Ollama**: Đảm bảo bạn đang sử dụng phiên bản 0.5.13 hoặc cao hơn
3. **Kiểm tra lượng tử hóa mô hình**: Các mức lượng tử hóa cao hơn (Q8_0, fp16) hoạt động tốt hơn so với các phiên bản lượng tử hóa nặng

### Tối Ưu Hóa Hiệu Suất

#### 1. Thiết Kế Hàm Hiệu Quả
- **Giữ hàm tập trung**: Mỗi hàm nên có một mục đích rõ ràng
- **Giảm phụ thuộc bên ngoài**: Hạn chế các lệnh gọi API và yêu cầu mạng khi có thể
- **Lưu trữ kết quả**: Lưu trữ dữ liệu được yêu cầu thường xuyên để cải thiện thời gian phản hồi

#### 2. Gộp và Thao Tác Bất Đồng Bộ
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Quản Lý Tài Nguyên
- **Tái sử dụng kết nối**: Tái sử dụng kết nối cơ sở dữ liệu và API
- **Giới hạn tốc độ**: Triển khai giới hạn tốc độ phù hợp cho các API bên ngoài
- **Xử lý hết thời gian**: Đặt thời gian chờ hợp lý cho tất cả các lệnh gọi bên ngoài

## Ví Dụ Nâng Cao

### Hệ Thống Hợp Tác Nhiều Tác Nhân

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Hệ Thống Lựa Chọn Công Cụ Động

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Định dạng kết quả tiêu chuẩn cho tất cả các lệnh gọi hàm"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Tác nhân AI sẵn sàng cho sản xuất với khả năng gọi hàm toàn diện"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Khởi tạo các hàm kinh doanh cốt lõi
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Đăng ký tất cả các hàm kinh doanh có sẵn"""
        
        # Hàm CRM
        self.register_function(
            name="get_customer_info",
            description="Lấy thông tin khách hàng từ CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # số lần gọi mỗi phút
        )
        
        # Hàm Bán Hàng
        self.register_function(
            name="create_sales_opportunity",
            description="Tạo cơ hội bán hàng mới",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Hàm Phân Tích
        self.register_function(
            name="generate_sales_report",
            description="Tạo báo cáo hiệu suất bán hàng",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Hàm Thông Báo
        self.register_function(
            name="send_notification",
            description="Gửi thông báo cho các thành viên trong nhóm",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Đăng ký một hàm mới với tác nhân"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
Sure! Please provide the markdown file you'd like me to translate.
"""Thực thi một hàm với xử lý lỗi toàn diện và ghi nhật ký"""
start_time = datetime.now()

try:
    # Kiểm tra hàm có tồn tại
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Hàm '{function_name}' không được tìm thấy",
            timestamp=start_time
        )
    
    # Kiểm tra giới hạn tần suất
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Vượt quá giới hạn tần suất cho hàm '{function_name}'",
            timestamp=start_time
        )
    
    # Xác thực tham số
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Thực thi hàm
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Ghi nhật ký thực thi thành công
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Ghi nhật ký thực thi thất bại
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Kiểm tra xem hàm có nằm trong giới hạn tần suất không"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Đặt lại bộ đếm nếu đã qua một phút
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Kiểm tra xem có dưới giới hạn không
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Xác thực tham số của hàm"""
    func_params = self.functions[function_name]['parameters']
    
    # Kiểm tra tham số bắt buộc
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Thiếu tham số bắt buộc: {param_name}"
            )
    
    # Xác thực kiểu và ràng buộc của tham số
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Xác thực kiểu
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Tham số '{param_name}' phải là chuỗi"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Tham số '{param_name}' phải là số"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Tham số '{param_name}' phải là giá trị boolean"
                )
            
            # Xác thực giá trị enum
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Tham số '{param_name}' phải là một trong các giá trị: {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Ghi nhật ký cuộc gọi hàm để kiểm tra"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Tùy chọn ghi vào hệ thống nhật ký bên ngoài
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Ghi nhật ký vào hệ thống nhật ký bên ngoài"""
    # Việc triển khai sẽ phụ thuộc vào cơ sở hạ tầng nhật ký của bạn
    # Ví dụ: gửi đến ELK stack, CloudWatch, v.v.
    pass

# Triển khai các hàm nghiệp vụ
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Lấy thông tin khách hàng từ hệ thống CRM"""
    # Mô phỏng cuộc gọi cơ sở dữ liệu/API
    await asyncio.sleep(0.1)  # Mô phỏng độ trễ mạng
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'active',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Product A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Product B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                  estimated_value: float, expected_close_date: str) -> Dict:
    """Tạo cơ hội bán hàng mới"""
    # Mô phỏng cuộc gọi API CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'open',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                               product_category: str = None) -> Dict:
    """Tạo báo cáo bán hàng toàn diện"""
    # Mô phỏng tổng hợp dữ liệu
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                           priority: str = 'medium', channel: str = 'email') -> Dict:
    """Gửi thông báo qua kênh được chỉ định"""
    # Mô phỏng cuộc gọi dịch vụ thông báo
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'sent',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Lấy định nghĩa hàm tương thích với OpenAI cho tất cả các hàm đã đăng ký"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Ví dụ sử dụng cho tích hợp doanh nghiệp
async def enterprise_demo():
    """Trình diễn khả năng của tác nhân AI doanh nghiệp"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Ví dụ 1: Xử lý yêu cầu khách hàng
    print("=== Xử lý yêu cầu khách hàng ===")
    
    # Lấy thông tin khách hàng
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Thông tin khách hàng đã lấy: {result.data['name']}")
        print(f"Thời gian thực thi: {result.execution_time:.3f}s")
    
    # Ví dụ 2: Tạo cơ hội bán hàng
    print("\n=== Tạo cơ hội bán hàng ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Cơ hội đã được tạo: {result.data['opportunity_id']}")
    
    # Ví dụ 3: Thực hiện hàng loạt
    print("\n=== Thực hiện hàng loạt ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Cơ hội mới đã được tạo',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Nhiệm vụ {i+1} hoàn thành thành công")
        else:
            print(f"Nhiệm vụ {i+1} thất bại: {result.error}")
    
    # Hiển thị nhật ký kiểm tra
    print(f"\n=== Nhật ký kiểm tra ({len(agent.audit_log)} mục) ===")
    for entry in agent.audit_log[-3:]:  # Hiển thị 3 mục cuối
        print(f"{entry['timestamp']}: {entry['function_name']} - {'THÀNH CÔNG' if entry['success'] else 'THẤT BẠI'}")

# Chạy trình diễn doanh nghiệp
# asyncio.run(enterprise_demo())

## Kết luận

Gọi hàm trong Mô hình Ngôn ngữ Nhỏ (SLM) đại diện cho một sự thay đổi từ các trợ lý AI tĩnh sang các tác nhân năng động, có khả năng tương tác với thế giới thực. Hướng dẫn này đã bao gồm:

### Những điểm chính

1. **Hiểu nền tảng**: Gọi hàm cho phép SLM mở rộng vượt ra ngoài dữ liệu huấn luyện bằng cách kết nối với các công cụ và dịch vụ bên ngoài.

2. **Linh hoạt triển khai**: Có nhiều cách tiếp cận, từ triển khai cấp thấp với các mẫu tùy chỉnh đến các framework cao cấp như Qwen-Agent và Foundry Local.

3. **Cân nhắc triển khai**: Các triển khai doanh nghiệp yêu cầu chú ý đến xử lý lỗi, giới hạn tần suất, bảo mật và ghi nhật ký kiểm tra.

4. **Tối ưu hóa hiệu suất**: Thiết kế hàm hợp lý, thực thi hiệu quả và bộ nhớ đệm thông minh có thể cải thiện đáng kể thời gian phản hồi.

### Hướng đi tương lai

Khi công nghệ SLM tiếp tục phát triển, chúng ta có thể mong đợi:

- **Độ chính xác gọi hàm được cải thiện**: Phát hiện ý định và trích xuất tham số tốt hơn
- **Xử lý song song nâng cao**: Điều phối nhiều hàm phức tạp hơn
- **Tiêu chuẩn tích hợp tốt hơn**: Các giao thức chuẩn hóa cho tích hợp công cụ
- **Tính năng bảo mật tiên tiến**: Cơ chế xác thực và ủy quyền được nâng cao
- **Hệ sinh thái mở rộng**: Thư viện các hàm và tích hợp được xây dựng sẵn ngày càng phát triển

### Bắt đầu

Để bắt đầu triển khai gọi hàm trong dự án của bạn:

1. **Bắt đầu đơn giản**: Bắt đầu với các kịch bản hàm đơn giản
2. **Chọn framework của bạn**: Chọn giữa triển khai trực tiếp (Ollama/Phi-4) hoặc hỗ trợ framework (Qwen-Agent)
3. **Thiết kế hàm cẩn thận**: Tập trung vào định nghĩa hàm rõ ràng, được tài liệu hóa tốt
4. **Triển khai xử lý lỗi**: Xây dựng xử lý lỗi mạnh mẽ từ đầu
5. **Mở rộng dần dần**: Chuyển từ các kịch bản đơn giản sang phức tạp khi bạn có kinh nghiệm

Gọi hàm biến SLM từ các trình tạo văn bản ấn tượng thành các tác nhân AI thực tế có khả năng giải quyết các vấn đề thực tế. Bằng cách làm theo các mẫu và thực tiễn được nêu trong hướng dẫn này, bạn có thể xây dựng các hệ thống AI mạnh mẽ, đáng tin cậy vượt xa các giao diện trò chuyện truyền thống.

### Tài nguyên và tham khảo
- **Phi-4 Models**: [Bộ sưu tập Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)
- **Qwen3 Documentation**: [Tài liệu chính thức của Qwen](https://qwen.readthedocs.io/)
- **Ollama**: [Trang web chính thức](https://ollama.com/)
- **Foundry Local**: [Kho lưu trữ GitHub](https://github.com/microsoft/Foundry-Local)
- **Function Calling Best Practices**: [Hướng dẫn của Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)

Hãy nhớ rằng việc gọi hàm là một lĩnh vực đang phát triển, và việc cập nhật những tiến bộ mới nhất trong các framework và mô hình mà bạn chọn sẽ giúp bạn xây dựng các tác nhân AI hiệu quả hơn.


## ➡️ Tiếp theo

- [03: Tích hợp Giao thức Ngữ cảnh Mô hình (MCP)](./03.IntroduceMCP.md)

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.