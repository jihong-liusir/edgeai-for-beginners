<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-18T12:27:34+00:00",
  "source_file": "Module06/README.md",
  "language_code": "vi"
}
-->
# Chương 06: Hệ Thống Đại Diện SLM: Tổng Quan Toàn Diện

Cảnh quan trí tuệ nhân tạo đang trải qua một sự chuyển đổi cơ bản khi chúng ta tiến từ các chatbot đơn giản đến các đại diện AI phức tạp được hỗ trợ bởi Mô Hình Ngôn Ngữ Nhỏ (SLM). Hướng dẫn toàn diện này khám phá ba khía cạnh quan trọng của các hệ thống đại diện SLM hiện đại: các khái niệm nền tảng và chiến lược triển khai, khả năng gọi hàm, và tích hợp giao thức ngữ cảnh mô hình (MCP) mang tính cách mạng.

## [Phần 1: Nền Tảng Đại Diện AI và Mô Hình Ngôn Ngữ Nhỏ](./01.IntroduceAgent.md)

Phần đầu tiên thiết lập sự hiểu biết nền tảng về các đại diện AI và Mô Hình Ngôn Ngữ Nhỏ, định vị năm 2025 là năm của các đại diện AI sau kỷ nguyên chatbot năm 2023 và sự bùng nổ của copilot năm 2024. Phần này giới thiệu **hệ thống AI đại diện** có khả năng suy nghĩ, lý luận, lập kế hoạch, sử dụng công cụ, và thực hiện nhiệm vụ với sự can thiệp tối thiểu từ con người.

### Các Khái Niệm Chính Được Đề Cập:
- **Khung Phân Loại Đại Diện**: Từ các đại diện phản xạ đơn giản đến các đại diện học tập, cung cấp một phân loại toàn diện cho các kịch bản tính toán khác nhau
- **Nền Tảng SLM**: Định nghĩa Mô Hình Ngôn Ngữ Nhỏ là các mô hình có ít hơn 10 tỷ tham số, có khả năng thực hiện suy luận thực tế trên các thiết bị tiêu dùng
- **Chiến Lược Tối Ưu Hóa Nâng Cao**: Bao gồm triển khai định dạng GGUF, các kỹ thuật lượng hóa (Q4_K_M, Q5_K_S, Q8_0), và các khung tối ưu hóa cho thiết bị biên như Llama.cpp và Apple MLX
- **So Sánh SLM và LLM**: Chứng minh giảm chi phí từ 10-30 lần với SLM trong khi vẫn duy trì hiệu quả cho 70-80% các nhiệm vụ đại diện thông thường

Phần này kết thúc với các chiến lược triển khai thực tế sử dụng Ollama, VLLM, và các giải pháp biên của Microsoft, khẳng định SLM là tương lai của triển khai AI đại diện tiết kiệm chi phí và bảo vệ quyền riêng tư.

## [Phần 2: Gọi Hàm Trong Mô Hình Ngôn Ngữ Nhỏ](./02.FunctionCalling.md)

Phần thứ hai đi sâu vào **khả năng gọi hàm**, cơ chế biến các mô hình ngôn ngữ tĩnh thành các đại diện AI động có khả năng tương tác với thế giới thực. Phân tích kỹ thuật này bao gồm toàn bộ quy trình từ phát hiện ý định đến tích hợp phản hồi.

### Các Lĩnh Vực Triển Khai Cốt Lõi:
- **Quy Trình Hệ Thống**: Khám phá chi tiết việc tích hợp công cụ, định nghĩa hàm, phát hiện ý định, tạo đầu ra JSON, và thực thi bên ngoài
- **Triển Khai Theo Nền Tảng**: Hướng dẫn toàn diện cho Phi-4-mini với Ollama, gọi hàm Qwen3, và tích hợp Microsoft Foundry Local
- **Ví Dụ Nâng Cao**: Hệ thống hợp tác đa đại diện, lựa chọn công cụ động, và các mẫu tích hợp doanh nghiệp với xử lý lỗi toàn diện
- **Cân Nhắc Sản Xuất**: Giới hạn tốc độ, ghi nhật ký kiểm toán, các biện pháp bảo mật, và chiến lược tối ưu hóa hiệu suất

Phần này cung cấp cả sự hiểu biết lý thuyết và các mẫu triển khai thực tế, giúp các nhà phát triển xây dựng hệ thống gọi hàm mạnh mẽ có thể xử lý mọi thứ từ các cuộc gọi API đơn giản đến các quy trình doanh nghiệp phức tạp nhiều bước.

## [Phần 3: Tích Hợp Giao Thức Ngữ Cảnh Mô Hình (MCP)](./03.IntroduceMCP.md)

Phần cuối cùng giới thiệu **Giao Thức Ngữ Cảnh Mô Hình (MCP)**, một khung làm việc mang tính cách mạng chuẩn hóa cách các mô hình ngôn ngữ tương tác với các công cụ và hệ thống bên ngoài. Phần này minh họa cách MCP tạo cầu nối giữa các mô hình AI và thế giới thực thông qua các giao thức được định nghĩa rõ ràng.

### Điểm Nổi Bật Về Tích Hợp:
- **Kiến Trúc Giao Thức**: Thiết kế hệ thống phân lớp bao gồm lớp ứng dụng, lớp khách hàng LLM, lớp khách hàng MCP, và lớp xử lý công cụ
- **Hỗ Trợ Nhiều Backend**: Triển khai linh hoạt hỗ trợ cả Ollama (phát triển cục bộ) và vLLM (sản xuất)
- **Giao Thức Kết Nối**: Chế độ STDIO cho giao tiếp trực tiếp giữa các quy trình và chế độ SSE cho streaming dựa trên HTTP
- **Ứng Dụng Thực Tế**: Tự động hóa web, xử lý dữ liệu, và các ví dụ tích hợp API với xử lý lỗi toàn diện

Tích hợp MCP minh họa cách SLM có thể được tăng cường với các khả năng bên ngoài, bù đắp cho số lượng tham số nhỏ hơn thông qua chức năng nâng cao trong khi vẫn duy trì lợi ích của triển khai cục bộ và hiệu quả tài nguyên.

## Ý Nghĩa Chiến Lược

Cả ba phần này cùng nhau trình bày một khung làm việc toàn diện để hiểu và triển khai các hệ thống đại diện SLM. Sự tiến hóa từ các khái niệm nền tảng qua gọi hàm đến tích hợp MCP thể hiện một lộ trình rõ ràng hướng tới triển khai AI được dân chủ hóa, nơi:

- **Hiệu quả kết hợp khả năng** thông qua các mô hình nhỏ được tối ưu hóa
- **Tiết kiệm chi phí** thúc đẩy sự phổ biến rộng rãi
- **Các giao thức chuẩn hóa** đảm bảo khả năng tương tác
- **Triển khai cục bộ** bảo vệ quyền riêng tư và giảm độ trễ

Sự tiến triển này không chỉ đại diện cho một bước tiến công nghệ mà còn là một sự thay đổi mô hình hướng tới các hệ thống AI dễ tiếp cận hơn, hiệu quả hơn, và thực tế hơn, có thể hoạt động hiệu quả trong các môi trường hạn chế tài nguyên trong khi cung cấp các khả năng đại diện phức tạp.

Sự kết hợp giữa SLM với các chiến lược triển khai tiên tiến, khả năng gọi hàm mạnh mẽ, và các giao thức tích hợp công cụ chuẩn hóa định vị các hệ thống này là nền tảng cho thế hệ tiếp theo của các đại diện AI, sẽ thay đổi cách chúng ta tương tác và hưởng lợi từ trí tuệ nhân tạo trong các ngành công nghiệp và ứng dụng khác nhau.

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.