<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-18T11:46:25+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "vi"
}
-->
# EdgeAI cho Người Mới Bắt Đầu: Lộ Trình Học và Lịch Trình Học Tập

### Lộ Trình Học Tập Tập Trung (1 tuần)

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 1 | Module 1: Kiến thức cơ bản về EdgeAI | 3 giờ |
| Ngày 2 | Module 2: Nền tảng SLM | 3 giờ |
| Ngày 3 | Module 3: Triển khai SLM | 2 giờ |
| Ngày 4-5 | Module 4: Tối ưu hóa mô hình (6 framework) | 4 giờ |
| Ngày 6 | Module 5: SLMOps | 3 giờ |
| Ngày 7 | Module 6-7: AI Agents & Công cụ phát triển | 5 giờ |

### Lộ Trình Học Tập Tập Trung (2 tuần)

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 1-2 | Module 1: Kiến thức cơ bản về EdgeAI | 3 giờ |
| Ngày 3-4 | Module 2: Nền tảng SLM | 3 giờ |
| Ngày 5-6 | Module 3: Triển khai SLM | 2 giờ |
| Ngày 7-8 | Module 4: Tối ưu hóa mô hình | 4 giờ |
| Ngày 9-10 | Module 5: SLMOps | 3 giờ |
| Ngày 11-12 | Module 6: AI Agents | 2 giờ |
| Ngày 13-14 | Module 7: Công cụ phát triển | 3 giờ |

### Học Bán Thời Gian (4 tuần)

| Tuần | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Tuần 1 | Module 1-2: Kiến thức cơ bản & Nền tảng SLM | 6 giờ |
| Tuần 2 | Module 3-4: Triển khai & Tối ưu hóa | 6 giờ |
| Tuần 3 | Module 5-6: SLMOps & AI Agents | 5 giờ |
| Tuần 4 | Module 7: Công cụ phát triển & Tích hợp | 3 giờ |

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 1-2 | Module 1: Kiến thức cơ bản về EdgeAI | 3 giờ |
| Ngày 3-4 | Module 2: Nền tảng SLM | 3 giờ |
| Ngày 5-6 | Module 3: Triển khai SLM | 2 giờ |
| Ngày 7-8 | Module 4: Tối ưu hóa mô hình | 4 giờ |
| Ngày 9-10 | Module 5: SLMOps | 3 giờ |
| Ngày 11-12 | Module 6: Hệ thống AI Agentic | 2 giờ |
| Ngày 13-14 | Module 7: Các mẫu triển khai EdgeAI | 2 giờ |

| Module | Ngày hoàn thành | Thời gian đã dành | Những điểm chính |
|--------|-----------------|-------------------|------------------|
| Module 1: Kiến thức cơ bản về EdgeAI | | | |
| Module 2: Nền tảng SLM | | | |
| Module 3: Triển khai SLM | | | |
| Module 4: Tối ưu hóa mô hình (6 framework) | | | |
| Module 5: SLMOps | | | |
| Module 6: Hệ thống AI Agentic | | | |
| Module 7: Các mẫu triển khai EdgeAI | | | |
| Bài tập thực hành | | | |
| Dự án nhỏ | | | |

### Học Bán Thời Gian (4 tuần)

| Tuần | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Tuần 1 | Module 1-2: Kiến thức cơ bản & Nền tảng SLM | 6 giờ |
| Tuần 2 | Module 3-4: Triển khai & Tối ưu hóa | 6 giờ |
| Tuần 3 | Module 5-6: SLMOps & AI Agents | 5 giờ |
| Tuần 4 | Module 7: Công cụ phát triển & Tích hợp | 3 giờ |

## Giới thiệu

Chào mừng bạn đến với hướng dẫn học EdgeAI cho người mới bắt đầu! Tài liệu này được thiết kế để giúp bạn tiếp cận các tài liệu khóa học một cách hiệu quả và tối ưu hóa trải nghiệm học tập của mình. Nó cung cấp các lộ trình học tập có cấu trúc, lịch trình học tập được đề xuất, tóm tắt các khái niệm chính, và tài nguyên bổ sung để bạn hiểu sâu hơn về các công nghệ EdgeAI.

Đây là một khóa học ngắn gọn kéo dài 20 giờ, cung cấp kiến thức thiết yếu về EdgeAI trong một định dạng tiết kiệm thời gian, rất phù hợp cho các chuyên gia bận rộn và sinh viên muốn nhanh chóng nắm bắt các kỹ năng thực tế trong lĩnh vực đang phát triển này.

## Tổng quan về khóa học

Khóa học này được tổ chức thành bảy module toàn diện:

1. **Kiến thức cơ bản và sự chuyển đổi của EdgeAI** - Hiểu các khái niệm cốt lõi và sự thay đổi công nghệ
2. **Nền tảng Mô hình Ngôn ngữ Nhỏ (SLM)** - Khám phá các họ SLM khác nhau và kiến trúc của chúng
3. **Triển khai Mô hình Ngôn ngữ Nhỏ** - Thực hiện các chiến lược triển khai thực tế
4. **Chuyển đổi định dạng mô hình và lượng hóa** - Tối ưu hóa nâng cao với 6 framework bao gồm OpenVINO
5. **SLMOps - Vận hành Mô hình Ngôn ngữ Nhỏ** - Quản lý vòng đời sản xuất và triển khai
6. **Hệ thống AI Agentic** - AI agents, gọi hàm, và giao thức ngữ cảnh mô hình
7. **Các mẫu triển khai EdgeAI** - Bộ công cụ AI, phát triển trên Windows, và triển khai theo nền tảng

## Cách sử dụng hướng dẫn học này

- **Học tập tiến bộ**: Theo dõi các module theo thứ tự để có trải nghiệm học tập mạch lạc nhất
- **Điểm kiểm tra kiến thức**: Sử dụng các câu hỏi tự đánh giá sau mỗi phần
- **Thực hành thực tế**: Hoàn thành các bài tập được đề xuất để củng cố các khái niệm lý thuyết
- **Tài nguyên bổ sung**: Khám phá các tài liệu bổ sung cho các chủ đề bạn quan tâm nhất

## Lịch trình học tập được đề xuất

### Lộ Trình Học Tập Tập Trung (1 tuần)

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 1-2 | Module 1: Kiến thức cơ bản về EdgeAI | 6 giờ |
| Ngày 3-4 | Module 2: Nền tảng SLM | 8 giờ |
| Ngày 5-6 | Module 3: Triển khai SLM | 6 giờ |

### Học Bán Thời Gian (3 tuần)

| Tuần | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Tuần 1 | Module 1: Kiến thức cơ bản về EdgeAI | 6-7 giờ |
| Tuần 2 | Module 2: Nền tảng SLM | 7-8 giờ |
| Tuần 3 | Module 3: Triển khai SLM | 5-6 giờ |
- Cây quyết định lựa chọn framework  
- Xác thực khả năng sẵn sàng sản xuất  
- Chiến lược đảm bảo tính tương lai  

### Câu hỏi tự đánh giá  

1. So sánh các chiến lược lượng hóa ở các mức độ chính xác khác nhau (1-bit đến 8-bit).  
2. Giải thích lợi ích của định dạng GGUF cho triển khai tại biên.  
3. Tối ưu hóa dựa trên phần cứng trong Microsoft Olive cải thiện hiệu quả triển khai như thế nào?  
4. Những lợi ích chính của NNCF trong OpenVINO đối với việc nén mô hình là gì?  
5. Mô tả cách Apple MLX tận dụng kiến trúc bộ nhớ hợp nhất để tối ưu hóa.  
6. Tổng hợp quy trình làm việc giúp chọn framework tối ưu hóa tốt nhất như thế nào?  

### Bài tập thực hành  

1. **Lượng hóa mô hình**: Áp dụng các mức lượng hóa khác nhau cho một mô hình và so sánh kết quả (1 giờ)  
2. **Tối ưu hóa OpenVINO**: Sử dụng NNCF để nén một mô hình cho phần cứng Intel (1 giờ)  
3. **So sánh framework**: Kiểm tra cùng một mô hình trên ba framework tối ưu hóa khác nhau (1 giờ)  
4. **Đánh giá hiệu suất**: Đo lường tác động của tối ưu hóa lên tốc độ suy luận và sử dụng bộ nhớ (1 giờ)  

## Module 5: SLMOps - Vận hành Mô hình Ngôn ngữ Nhỏ  

### Mục tiêu học tập chính  

- Hiểu các nguyên tắc quản lý vòng đời SLMOps  
- Thành thạo các kỹ thuật chưng cất và tinh chỉnh cho triển khai tại biên  
- Triển khai chiến lược triển khai sản xuất với giám sát  
- Xây dựng quy trình vận hành và bảo trì SLM cấp doanh nghiệp  

### Các lĩnh vực trọng tâm nghiên cứu  

#### Phần 1: Giới thiệu về SLMOps  
- **Khái niệm ưu tiên**:  
  - Sự thay đổi mô hình SLMOps trong vận hành AI  
  - Kiến trúc tiết kiệm chi phí và ưu tiên quyền riêng tư  
  - Tác động chiến lược đến kinh doanh và lợi thế cạnh tranh  

#### Phần 2: Chưng cất mô hình  
- **Khái niệm ưu tiên**:  
  - Kỹ thuật chuyển giao kiến thức  
  - Triển khai quy trình chưng cất hai giai đoạn  
  - Quy trình chưng cất Azure ML  

#### Phần 3: Chiến lược tinh chỉnh  
- **Khái niệm ưu tiên**:  
  - Tinh chỉnh hiệu quả tham số (PEFT)  
  - Các phương pháp nâng cao LoRA và QLoRA  
  - Đào tạo đa bộ điều hợp và tối ưu hóa siêu tham số  

#### Phần 4: Triển khai sản xuất  
- **Khái niệm ưu tiên**:  
  - Chuyển đổi và lượng hóa mô hình cho sản xuất  
  - Cấu hình triển khai Foundry Local  
  - Đánh giá hiệu suất và xác thực chất lượng  

### Câu hỏi tự đánh giá  

1. SLMOps khác gì so với MLOps truyền thống?  
2. Giải thích lợi ích của chưng cất mô hình cho triển khai tại biên.  
3. Những yếu tố chính cần cân nhắc khi tinh chỉnh SLM trong môi trường hạn chế tài nguyên là gì?  
4. Mô tả một quy trình triển khai sản xuất hoàn chỉnh cho ứng dụng AI tại biên.  

### Bài tập thực hành  

1. **Chưng cất cơ bản**: Tạo một mô hình nhỏ hơn từ một mô hình lớn hơn (1 giờ)  
2. **Thử nghiệm tinh chỉnh**: Tinh chỉnh một mô hình cho một lĩnh vực cụ thể (1 giờ)  
3. **Quy trình triển khai**: Thiết lập một quy trình CI/CD cơ bản cho triển khai mô hình (1 giờ)  

## Module 6: Hệ thống SLM Agentic - Tác nhân AI và Gọi hàm  

### Mục tiêu học tập chính  

- Xây dựng các tác nhân AI thông minh cho môi trường biên sử dụng Mô hình Ngôn ngữ Nhỏ  
- Triển khai khả năng gọi hàm với quy trình làm việc có hệ thống  
- Thành thạo tích hợp Model Context Protocol (MCP) để tương tác công cụ chuẩn hóa  
- Tạo hệ thống tác nhân phức tạp với sự can thiệp tối thiểu của con người  

### Các lĩnh vực trọng tâm nghiên cứu  

#### Phần 1: Tác nhân AI và Nền tảng SLM  
- **Khái niệm ưu tiên**:  
  - Khung phân loại tác nhân (phản xạ, dựa trên mô hình, dựa trên mục tiêu, tác nhân học tập)  
  - Phân tích đánh đổi giữa SLM và LLM  
  - Mẫu thiết kế tác nhân dành riêng cho biên  
  - Tối ưu hóa tài nguyên cho tác nhân  

#### Phần 2: Gọi hàm trong Mô hình Ngôn ngữ Nhỏ  
- **Khái niệm ưu tiên**:  
  - Triển khai quy trình làm việc có hệ thống (phát hiện ý định, đầu ra JSON, thực thi bên ngoài)  
  - Triển khai cụ thể theo nền tảng (Phi-4-mini, các mô hình Qwen được chọn, Microsoft Foundry Local)  
  - Ví dụ nâng cao (hợp tác đa tác nhân, lựa chọn công cụ động)  
  - Cân nhắc sản xuất (giới hạn tốc độ, ghi nhật ký kiểm toán, biện pháp bảo mật)  

#### Phần 3: Tích hợp Model Context Protocol (MCP)  
- **Khái niệm ưu tiên**:  
  - Kiến trúc giao thức và thiết kế hệ thống phân lớp  
  - Hỗ trợ đa backend (Ollama cho phát triển, vLLM cho sản xuất)  
  - Giao thức kết nối (chế độ STDIO và SSE)  
  - Ứng dụng thực tế (tự động hóa web, xử lý dữ liệu, tích hợp API)  

### Câu hỏi tự đánh giá  

1. Những cân nhắc kiến trúc chính cho tác nhân AI tại biên là gì?  
2. Gọi hàm cải thiện khả năng của tác nhân như thế nào?  
3. Giải thích vai trò của Model Context Protocol trong giao tiếp của tác nhân.  

### Bài tập thực hành  

1. **Tác nhân đơn giản**: Xây dựng một tác nhân AI cơ bản với khả năng gọi hàm (1 giờ)  
2. **Tích hợp MCP**: Triển khai MCP trong một ứng dụng tác nhân (30 phút)  

## Module 7: Các mẫu triển khai EdgeAI  

### Mục tiêu học tập chính  

- Thành thạo AI Toolkit cho Visual Studio Code để phát triển quy trình EdgeAI toàn diện  
- Nắm vững nền tảng Windows AI Foundry và các chiến lược tối ưu hóa NPU  
- Triển khai EdgeAI trên nhiều nền tảng phần cứng và kịch bản triển khai  
- Xây dựng ứng dụng EdgeAI sẵn sàng sản xuất với các tối ưu hóa cụ thể theo nền tảng  

### Các lĩnh vực trọng tâm nghiên cứu  

#### Phần 1: AI Toolkit cho Visual Studio Code  
- **Khái niệm ưu tiên**:  
  - Môi trường phát triển Edge AI toàn diện trong VS Code  
  - Danh mục mô hình và khám phá cho triển khai tại biên  
  - Quy trình thử nghiệm, tối ưu hóa và phát triển tác nhân tại địa phương  
  - Giám sát hiệu suất và đánh giá cho các kịch bản tại biên  

#### Phần 2: Hướng dẫn phát triển Windows EdgeAI  
- **Khái niệm ưu tiên**:  
  - Tổng quan toàn diện về nền tảng Windows AI Foundry  
  - API Phi Silica cho suy luận NPU hiệu quả  
  - API Thị giác Máy tính cho xử lý hình ảnh và OCR  
  - CLI Foundry Local cho phát triển và thử nghiệm tại địa phương  

#### Phần 3: Triển khai cụ thể theo nền tảng  
- **Khái niệm ưu tiên**:  
  - Triển khai NVIDIA Jetson Orin Nano (hiệu suất AI 67 TOPS)  
  - Ứng dụng di động với .NET MAUI và ONNX Runtime GenAI  
  - Giải pháp Azure EdgeAI với kiến trúc lai giữa đám mây và biên  
  - Tối ưu hóa Windows ML với hỗ trợ phần cứng phổ quát  
  - Ứng dụng Foundry Local với triển khai RAG tập trung vào quyền riêng tư  

### Câu hỏi tự đánh giá  

1. AI Toolkit hợp lý hóa quy trình phát triển EdgeAI như thế nào?  
2. So sánh các chiến lược triển khai trên các nền tảng phần cứng khác nhau.  
3. Những lợi ích của Windows AI Foundry đối với phát triển tại biên là gì?  
4. Giải thích vai trò của tối ưu hóa NPU trong các ứng dụng Edge AI hiện đại.  
5. API Phi Silica tận dụng phần cứng NPU để tối ưu hóa hiệu suất như thế nào?  
6. So sánh lợi ích của triển khai tại địa phương và trên đám mây đối với các ứng dụng nhạy cảm về quyền riêng tư.  

### Bài tập thực hành  

1. **Cài đặt AI Toolkit**: Cấu hình AI Toolkit và tối ưu hóa một mô hình (1 giờ)  
2. **Windows AI Foundry**: Xây dựng một ứng dụng AI Windows đơn giản sử dụng API Phi Silica (1 giờ)  
3. **Triển khai đa nền tảng**: Triển khai cùng một mô hình trên hai nền tảng khác nhau (1 giờ)  
4. **Tối ưu hóa NPU**: Kiểm tra hiệu suất NPU với các công cụ Windows AI Foundry (30 phút)  

## Hướng dẫn phân bổ thời gian  

Để giúp bạn tận dụng tối đa thời gian học 20 giờ, đây là gợi ý phân bổ thời gian:  

| Hoạt động | Phân bổ thời gian | Mô tả |  
|-----------|-------------------|-------|  
| Đọc tài liệu cốt lõi | 9 giờ | Tập trung vào các khái niệm thiết yếu trong mỗi module |  
| Bài tập thực hành | 6 giờ | Triển khai thực tế các kỹ thuật chính |  
| Tự đánh giá | 2 giờ | Kiểm tra sự hiểu biết của bạn qua câu hỏi và phản ánh |  
| Dự án nhỏ | 3 giờ | Áp dụng kiến thức vào một triển khai thực tế nhỏ |  

### Các lĩnh vực trọng tâm theo giới hạn thời gian  

**Nếu bạn chỉ có 10 giờ:**  
- Hoàn thành Module 1, 2 và 3 (các khái niệm cốt lõi về EdgeAI)  
- Thực hiện ít nhất một bài tập thực hành mỗi module  
- Tập trung vào việc hiểu các khái niệm cốt lõi thay vì chi tiết triển khai  

**Nếu bạn có thể dành toàn bộ 20 giờ:**  
- Hoàn thành tất cả bảy module  
- Thực hiện các bài tập thực hành chính từ mỗi module  
- Hoàn thành một dự án nhỏ từ Module 7  
- Khám phá ít nhất 2-3 tài liệu bổ sung  

**Nếu bạn có hơn 20 giờ:**  
- Hoàn thành tất cả các module với các bài tập chi tiết  
- Xây dựng nhiều dự án nhỏ  
- Khám phá các kỹ thuật tối ưu hóa nâng cao trong Module 4  
- Triển khai sản xuất từ Module 5  

## Kết luận  

EdgeAI đại diện cho biên giới của việc triển khai trí tuệ nhân tạo, mang lại khả năng mạnh mẽ trực tiếp đến các thiết bị trong khi giải quyết các vấn đề quan trọng về quyền riêng tư, độ trễ và kết nối. Khóa học 20 giờ này cung cấp cho bạn kiến thức thiết yếu và kỹ năng thực hành để bắt đầu làm việc với các công nghệ EdgeAI ngay lập tức.  

Khóa học được thiết kế ngắn gọn và tập trung vào các khái niệm quan trọng nhất, cho phép bạn nhanh chóng đạt được chuyên môn giá trị mà không cần cam kết thời gian quá lớn. Hãy nhớ rằng thực hành thực tế, ngay cả với các ví dụ đơn giản, là chìa khóa để củng cố những gì bạn đã học.  

Chúc bạn học tập vui vẻ!  

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp từ con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.