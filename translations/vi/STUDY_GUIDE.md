<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-09T16:34:40+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "vi"
}
-->
# EdgeAI cho Người Mới Bắt Đầu: Lộ Trình Học và Lịch Trình Học Tập

### Lộ Trình Học Tập Tập Trung (1 tuần)

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 0 | Module 0: Giới thiệu về EdgeAI | 1-2 giờ |
| Ngày 1 | Module 1: Kiến thức cơ bản về EdgeAI | 3 giờ |
| Ngày 2 | Module 2: Nền tảng SLM | 3 giờ |
| Ngày 3 | Module 3: Triển khai SLM | 2 giờ |
| Ngày 4-5 | Module 4: Tối ưu hóa mô hình (6 framework) | 4 giờ |
| Ngày 6 | Module 5: SLMOps | 3 giờ |
| Ngày 7 | Module 6-7: AI Agents & Công cụ phát triển | 4 giờ |
| Ngày 8 | Module 8: Bộ công cụ Foundry Local (Triển khai hiện đại) | 1 giờ |

### Lộ Trình Học Tập Tập Trung (2 tuần)

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 1-2 | Module 1: Kiến thức cơ bản về EdgeAI | 3 giờ |
| Ngày 3-4 | Module 2: Nền tảng SLM | 3 giờ |
| Ngày 5-6 | Module 3: Triển khai SLM | 2 giờ |
| Ngày 7-8 | Module 4: Tối ưu hóa mô hình | 4 giờ |
| Ngày 9-10 | Module 5: SLMOps | 3 giờ |
| Ngày 11-12 | Module 6: AI Agents | 2 giờ |
| Ngày 13-14 | Module 7: Công cụ phát triển | 3 giờ |

### Học Bán Thời Gian (4 tuần)

| Tuần | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Tuần 1 | Module 1-2: Kiến thức cơ bản & Nền tảng SLM | 6 giờ |
| Tuần 2 | Module 3-4: Triển khai & Tối ưu hóa | 6 giờ |
| Tuần 3 | Module 5-6: SLMOps & AI Agents | 5 giờ |
| Tuần 4 | Module 7: Công cụ phát triển & Tích hợp | 3 giờ |

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 0 | Module 0: Giới thiệu về EdgeAI | 1-2 giờ |
| Ngày 1-2 | Module 1: Kiến thức cơ bản về EdgeAI | 3 giờ |
| Ngày 3-4 | Module 2: Nền tảng SLM | 3 giờ |
| Ngày 5-6 | Module 3: Triển khai SLM | 2 giờ |
| Ngày 7-8 | Module 4: Tối ưu hóa mô hình | 4 giờ |
| Ngày 9-10 | Module 5: SLMOps | 3 giờ |
| Ngày 11-12 | Module 6: Hệ thống SLM Agentic | 2 giờ |
| Ngày 13-14 | Module 7: Mẫu triển khai EdgeAI | 2 giờ |

| Module | Ngày hoàn thành | Thời gian đã dành | Kết quả chính |
|--------|-----------------|-------------------|---------------|
| Module 0: Giới thiệu về EdgeAI | | | |
| Module 1: Kiến thức cơ bản về EdgeAI | | | |
| Module 2: Nền tảng SLM | | | |
| Module 3: Triển khai SLM | | | |
| Module 4: Tối ưu hóa mô hình (6 framework) | | | |
| Module 5: SLMOps | | | |
| Module 6: Hệ thống SLM Agentic | | | |
| Module 7: Mẫu triển khai EdgeAI | | | |
| Bài tập thực hành | | | |
| Dự án nhỏ | | | |

### Học Bán Thời Gian (4 tuần)

| Tuần | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Tuần 1 | Module 1-2: Kiến thức cơ bản & Nền tảng SLM | 6 giờ |
| Tuần 2 | Module 3-4: Triển khai & Tối ưu hóa | 6 giờ |
| Tuần 3 | Module 5-6: SLMOps & AI Agents | 5 giờ |
| Tuần 4 | Module 7: Công cụ phát triển & Tích hợp | 3 giờ |

## Giới thiệu

Chào mừng bạn đến với hướng dẫn học EdgeAI cho người mới bắt đầu! Tài liệu này được thiết kế để giúp bạn tiếp cận các tài liệu khóa học một cách hiệu quả và tối ưu hóa trải nghiệm học tập của mình. Nó cung cấp các lộ trình học tập có cấu trúc, lịch trình học tập được đề xuất, tóm tắt các khái niệm chính và tài nguyên bổ sung để làm sâu sắc thêm sự hiểu biết của bạn về các công nghệ Edge AI.

Đây là một khóa học ngắn gọn kéo dài 20 giờ, cung cấp kiến thức thiết yếu về EdgeAI trong một định dạng tiết kiệm thời gian, rất phù hợp cho các chuyên gia bận rộn và sinh viên muốn nhanh chóng có được kỹ năng thực tế trong lĩnh vực đang phát triển này.

## Tổng Quan Khóa Học

Khóa học này được tổ chức thành tám module toàn diện:

0. **Giới thiệu về EdgeAI** - Đặt nền tảng và bối cảnh với các ứng dụng ngành và mục tiêu học tập
1. **Kiến thức cơ bản và sự chuyển đổi của EdgeAI** - Hiểu các khái niệm cốt lõi và sự thay đổi công nghệ
2. **Nền tảng Mô hình Ngôn ngữ Nhỏ (SLM)** - Khám phá các họ SLM khác nhau và kiến trúc của chúng
3. **Triển khai Mô hình Ngôn ngữ Nhỏ** - Thực hiện các chiến lược triển khai thực tế
4. **Chuyển đổi định dạng mô hình và lượng hóa** - Tối ưu hóa nâng cao với 6 framework bao gồm OpenVINO
5. **SLMOps - Vận hành Mô hình Ngôn ngữ Nhỏ** - Quản lý vòng đời sản xuất và triển khai
6. **Hệ thống SLM Agentic** - AI agents, gọi hàm và giao thức ngữ cảnh mô hình
7. **Mẫu triển khai EdgeAI** - Bộ công cụ AI, phát triển trên Windows và triển khai theo nền tảng
8. **Microsoft Foundry Local – Bộ công cụ phát triển hoàn chỉnh** - Phát triển ưu tiên cục bộ với tích hợp Azure lai (Module 08)

## Cách Sử Dụng Hướng Dẫn Học Này

- **Học tập tiến bộ**: Theo dõi các module theo thứ tự để có trải nghiệm học tập mạch lạc nhất
- **Điểm kiểm tra kiến thức**: Sử dụng các câu hỏi tự đánh giá sau mỗi phần
- **Thực hành thực tế**: Hoàn thành các bài tập được đề xuất để củng cố các khái niệm lý thuyết
- **Tài nguyên bổ sung**: Khám phá thêm tài liệu cho các chủ đề mà bạn quan tâm nhất

## Khuyến Nghị Lịch Trình Học Tập

### Lộ Trình Học Tập Tập Trung (1 tuần)

| Ngày | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Ngày 0 | Module 0: Giới thiệu về EdgeAI | 1-2 giờ |
| Ngày 1-2 | Module 1: Kiến thức cơ bản về EdgeAI | 6 giờ |
| Ngày 3-4 | Module 2: Nền tảng SLM | 8 giờ |
| Ngày 5 | Module 3: Triển khai SLM | 3 giờ |
| Ngày 6 | Module 8: Bộ công cụ Foundry Local | 3 giờ |

### Học Bán Thời Gian (3 tuần)

| Tuần | Nội dung | Thời gian ước tính |
|------|----------|--------------------|
| Tuần 1 | Module 0: Giới thiệu + Module 1: Kiến thức cơ bản về EdgeAI | 7-9 giờ |
| Tuần 2 | Module 2: Nền tảng SLM | 7-8 giờ |
| Tuần 3 | Module 3: Triển khai SLM (3 giờ) + Module 8: Bộ công cụ Foundry Local (2-3 giờ) | 5-6 giờ |

## Module 0: Giới thiệu về EdgeAI

### Mục Tiêu Học Tập Chính

- Hiểu Edge AI là gì và tại sao nó quan trọng trong bối cảnh công nghệ hiện nay
- Xác định các ngành công nghiệp lớn được chuyển đổi bởi Edge AI và các trường hợp sử dụng cụ thể của chúng
- Hiểu rõ các lợi ích của Mô hình Ngôn ngữ Nhỏ (SLM) cho triển khai tại edge
- Thiết lập kỳ vọng học tập rõ ràng và kết quả cho toàn bộ khóa học
- Nhận biết cơ hội nghề nghiệp và yêu cầu kỹ năng trong lĩnh vực Edge AI

### Các Lĩnh Vực Tập Trung Học Tập

#### Phần 1: Mô hình và Định nghĩa Edge AI
- **Các khái niệm ưu tiên**: 
  - Edge AI so với xử lý AI truyền thống trên cloud
  - Sự hội tụ của phần cứng, tối ưu hóa mô hình và nhu cầu kinh doanh
  - Triển khai AI theo thời gian thực, bảo vệ quyền riêng tư và tiết kiệm chi phí

#### Phần 2: Ứng dụng Ngành
- **Các khái niệm ưu tiên**: 
  - Sản xuất & Công nghiệp 4.0: Bảo trì dự đoán và kiểm soát chất lượng
  - Y tế: Hình ảnh chẩn đoán và giám sát bệnh nhân
  - Hệ thống tự động: Xe tự lái và giao thông vận tải
  - Thành phố thông minh: Quản lý giao thông và an toàn công cộng
  - Công nghệ tiêu dùng: Điện thoại thông minh, thiết bị đeo và nhà thông minh

#### Phần 3: Nền tảng Mô hình Ngôn ngữ Nhỏ
- **Các khái niệm ưu tiên**: 
  - Đặc điểm và so sánh hiệu suất của SLM
  - Hiệu quả tham số so với sự đánh đổi khả năng
  - Các ràng buộc triển khai tại edge và chiến lược tối ưu hóa

#### Phần 4: Khung học tập và Lộ trình nghề nghiệp
- **Các khái niệm ưu tiên**: 
  - Kiến trúc khóa học và cách tiếp cận làm chủ tiến bộ
  - Kỹ năng kỹ thuật và mục tiêu triển khai thực tế
  - Cơ hội thăng tiến nghề nghiệp và ứng dụng ngành

### Câu Hỏi Tự Đánh Giá

1. Ba xu hướng công nghệ chính nào đã cho phép Edge AI phát triển?
2. So sánh lợi ích và thách thức của Edge AI so với AI dựa trên cloud.
3. Nêu tên ba ngành công nghiệp mà Edge AI mang lại giá trị kinh doanh quan trọng và giải thích lý do.
4. Làm thế nào Mô hình Ngôn ngữ Nhỏ giúp Edge AI trở nên thực tế trong triển khai thực tế?
5. Những kỹ năng kỹ thuật chính nào bạn sẽ phát triển trong suốt khóa học này?
6. Mô tả cách tiếp cận học tập bốn giai đoạn được sử dụng trong khóa học này.

### Bài Tập Thực Hành

1. **Nghiên cứu ngành**: Chọn một ứng dụng ngành và nghiên cứu một triển khai Edge AI thực tế (30 phút)
2. **Khám phá mô hình**: Duyệt qua các Mô hình Ngôn ngữ Nhỏ có sẵn trên Hugging Face và so sánh số lượng tham số và khả năng của chúng (30 phút)
3. **Lập kế hoạch học tập**: Xem lại cấu trúc khóa học đầy đủ và tạo lịch trình học tập cá nhân của bạn (15 phút)

### Tài Liệu Bổ Sung

- [Tổng quan thị trường Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [Tổng quan Mô hình Ngôn ngữ Nhỏ - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Nền tảng Edge Computing](https://www.edgecomputing.org/)

## Module 1: Kiến thức cơ bản về EdgeAI và sự chuyển đổi

### Mục Tiêu Học Tập Chính

- Hiểu sự khác biệt giữa AI dựa trên cloud và AI dựa trên edge
- Làm chủ các kỹ thuật tối ưu hóa cốt lõi cho môi trường hạn chế tài nguyên
- Phân tích các ứng dụng thực tế của công nghệ EdgeAI
- Thiết lập môi trường phát triển cho các dự án EdgeAI

### Các Lĩnh Vực Tập Trung Học Tập

#### Phần 1: Kiến thức cơ bản về EdgeAI
- **Các khái niệm ưu tiên**: 
  - Các mô hình điện toán Edge so với Cloud
  - Kỹ thuật lượng hóa mô hình
  - Các tùy chọn tăng tốc phần cứng (NPUs, GPUs, CPUs)
  - Lợi ích về quyền riêng tư và bảo mật

- **Tài liệu bổ sung**:
  - [Tài liệu TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Tài liệu Edge Impulse](https://docs.edgeimpulse.com)

#### Phần 2: Các nghiên cứu trường hợp thực tế
- **Các khái niệm ưu tiên**: 
  - Hệ sinh thái mô hình Microsoft Phi & Mu
  - Các triển khai thực tế trong các ngành công nghiệp
  - Các cân nhắc triển khai

#### Phần 3: Hướng dẫn triển khai thực tế
- **Các khái niệm ưu tiên**: 
  - Thiết lập môi trường phát triển
  - Công cụ lượng hóa và tối ưu hóa
  - Phương pháp đánh giá cho các triển khai EdgeAI

#### Phần 4: Phần cứng triển khai Edge
- **Các khái niệm ưu tiên**: 
  - So sánh các nền tảng phần cứng
  - Chiến lược tối ưu hóa cho phần cứng cụ thể
  - Các cân nhắc triển khai

### Câu Hỏi Tự Đánh Giá

1. So sánh và đối chiếu AI dựa trên cloud với các triển khai AI dựa trên edge.
2. Giải thích ba kỹ thuật chính để tối ưu hóa mô hình cho triển khai edge.
3. Những lợi ích chính của việc chạy các mô hình AI tại edge là gì?
4. Mô tả quá trình lượng hóa một mô hình và cách nó ảnh hưởng đến hiệu suất.
5. Giải thích cách các bộ tăng tốc phần cứng khác nhau (NPUs, GPUs, CPUs) ảnh hưởng đến triển khai EdgeAI.

### Bài Tập Thực Hành

1. **Thiết lập môi trường nhanh**: Cấu hình một môi trường phát triển tối thiểu với các gói cần thiết (30 phút)
2. **Khám phá mô hình**: Tải xuống và kiểm tra một mô hình ngôn ngữ nhỏ đã được huấn luyện trước (1 giờ)
3. **Lượng hóa cơ bản**: Thử lượng hóa đơn giản trên một mô hình nhỏ (1 giờ)

## Module 2: Nền tảng Mô hình Ngôn ngữ Nhỏ

### Mục Tiêu Học Tập Chính

- Hiểu các nguyên tắc kiến trúc của các họ SLM khác nhau
- So sánh khả năng của các mô hình ở các quy mô tham số khác nhau
- Đánh giá các mô hình dựa trên hiệu quả, khả năng và yêu cầu triển khai
- Nhận biết các trường hợp sử dụng phù hợp cho các họ mô hình khác nhau

### Các Lĩnh Vực Tập Trung Học Tập

#### Phần 1: Họ mô hình Microsoft Phi
- **Các khái niệm ưu tiên**: 
  - Sự phát triển triết lý thiết kế
  - Kiến trúc ưu tiên hiệu quả
  - Khả năng chuyên biệt

#### Phần 2: Họ Qwen
- **Các khái niệm ưu tiên**: 
  - Đóng góp mã nguồn mở
  - Tùy chọn triển khai có thể mở rộng
  - Kiến trúc lý luận nâng cao

#### Phần 3: Họ Gemma
- **Các khái niệm ưu tiên**: 
  - Đổi mới dựa trên nghiên cứu
  - Khả năng đa phương thức
  - Tối ưu hóa cho di động

#### Phần 4: Họ BitNET
- **Các khái niệm ưu tiên**: 
  - Công nghệ lượng hóa 1-bit
  - Khung tối ưu hóa suy luận
  - Cân nhắc về tính bền vững

#### Phần 5: Mô hình Microsoft Mu
- **Các khái niệm ưu tiên**: 
  - Kiến trúc ưu tiên thiết bị
  - Tích hợp hệ thống với Windows
  - Hoạt động bảo vệ quyền riêng tư

#### Phần 6: Phi-Silica
- **Các khái niệm ưu tiên**: 
  - Kiến trúc tối ưu hóa NPU
  - Các chỉ số hiệu suất
  - Tích hợp cho nhà phát triển

### Câu Hỏi Tự Đánh Giá

1. So sánh các cách tiếp cận kiến trúc của họ mô hình Phi và Qwen.
2. Giải thích cách công nghệ lượng hóa của BitNET khác với lượng hóa truyền thống.
3. Những lợi thế độc đáo của mô hình Mu trong việc tích hợp với Windows là gì?
4. Mô tả cách Phi-Silica tận dụng phần cứng NPU để tối ưu hóa hiệu suất.
5. Đối với một ứng dụng di động có kết nối hạn chế, dòng mô hình nào sẽ phù hợp nhất và tại sao?

### Bài tập thực hành

1. **So sánh mô hình**: Đánh giá nhanh hai mô hình SLM khác nhau (1 giờ)
2. **Tạo văn bản đơn giản**: Triển khai cơ bản việc tạo văn bản với một mô hình nhỏ (1 giờ)
3. **Tối ưu hóa nhanh**: Áp dụng một kỹ thuật tối ưu hóa để cải thiện tốc độ suy luận (1 giờ)

## Module 3: Triển khai Mô hình Ngôn ngữ Nhỏ

### Mục tiêu học tập chính

- Lựa chọn mô hình phù hợp dựa trên các hạn chế triển khai
- Thành thạo các kỹ thuật tối ưu hóa cho nhiều kịch bản triển khai
- Triển khai SLM trong cả môi trường cục bộ và đám mây
- Thiết kế cấu hình sẵn sàng sản xuất cho các ứng dụng EdgeAI

### Các lĩnh vực trọng tâm nghiên cứu

#### Phần 1: Học nâng cao về SLM
- **Khái niệm ưu tiên**: 
  - Khung phân loại tham số
  - Kỹ thuật tối ưu hóa nâng cao
  - Chiến lược thu nhận mô hình

#### Phần 2: Triển khai môi trường cục bộ
- **Khái niệm ưu tiên**: 
  - Triển khai nền tảng Ollama
  - Giải pháp cục bộ Microsoft Foundry
  - Phân tích so sánh các khung làm việc

#### Phần 3: Triển khai đám mây dạng container
- **Khái niệm ưu tiên**: 
  - Suy luận hiệu suất cao vLLM
  - Điều phối container
  - Triển khai ONNX Runtime

### Câu hỏi tự đánh giá

1. Những yếu tố nào cần xem xét khi lựa chọn giữa triển khai cục bộ và triển khai đám mây?
2. So sánh Ollama và Microsoft Foundry Local như các tùy chọn triển khai.
3. Giải thích lợi ích của việc đóng gói container cho triển khai SLM.
4. Những chỉ số hiệu suất chính nào cần theo dõi đối với một SLM triển khai tại edge?
5. Mô tả quy trình triển khai hoàn chỉnh từ việc chọn mô hình đến triển khai sản xuất.

### Bài tập thực hành

1. **Triển khai cục bộ cơ bản**: Triển khai một SLM đơn giản bằng Ollama (1 giờ)
2. **Kiểm tra hiệu suất**: Chạy đánh giá nhanh trên mô hình đã triển khai (30 phút)
3. **Tích hợp đơn giản**: Tạo một ứng dụng tối thiểu sử dụng mô hình đã triển khai (1 giờ)

## Module 4: Chuyển đổi định dạng mô hình và lượng hóa

### Mục tiêu học tập chính

- Thành thạo các kỹ thuật lượng hóa nâng cao từ độ chính xác 1-bit đến 8-bit
- Hiểu các chiến lược chuyển đổi định dạng (GGUF, ONNX)
- Triển khai tối ưu hóa trên sáu khung làm việc (Llama.cpp, Olive, OpenVINO, MLX, tổng hợp quy trình làm việc)
- Triển khai các mô hình đã tối ưu hóa cho môi trường edge sản xuất trên phần cứng Intel, Apple và đa nền tảng

### Các lĩnh vực trọng tâm nghiên cứu

#### Phần 1: Nền tảng lượng hóa
- **Khái niệm ưu tiên**: 
  - Khung phân loại độ chính xác
  - Cân bằng giữa hiệu suất và độ chính xác
  - Tối ưu hóa dung lượng bộ nhớ

#### Phần 2: Triển khai Llama.cpp
- **Khái niệm ưu tiên**: 
  - Triển khai đa nền tảng
  - Tối ưu hóa định dạng GGUF
  - Kỹ thuật tăng tốc phần cứng

#### Phần 3: Bộ công cụ Microsoft Olive
- **Khái niệm ưu tiên**: 
  - Tối ưu hóa dựa trên phần cứng
  - Triển khai cấp doanh nghiệp
  - Quy trình tối ưu hóa tự động

#### Phần 4: Bộ công cụ OpenVINO
- **Khái niệm ưu tiên**: 
  - Tối ưu hóa phần cứng Intel
  - Khung nén mạng thần kinh (NNCF)
  - Triển khai suy luận đa nền tảng
  - OpenVINO GenAI cho triển khai LLM

#### Phần 5: Khung làm việc Apple MLX
- **Khái niệm ưu tiên**: 
  - Tối ưu hóa Apple Silicon
  - Kiến trúc bộ nhớ hợp nhất
  - Khả năng tinh chỉnh LoRA

#### Phần 6: Tổng hợp quy trình phát triển Edge AI
- **Khái niệm ưu tiên**: 
  - Kiến trúc quy trình làm việc hợp nhất
  - Cây quyết định lựa chọn khung làm việc
  - Xác thực sẵn sàng sản xuất
  - Chiến lược đảm bảo tương lai

### Câu hỏi tự đánh giá

1. So sánh các chiến lược lượng hóa ở các mức độ chính xác khác nhau (1-bit đến 8-bit).
2. Giải thích lợi ích của định dạng GGUF cho triển khai tại edge.
3. Làm thế nào tối ưu hóa dựa trên phần cứng trong Microsoft Olive cải thiện hiệu quả triển khai?
4. Những lợi ích chính của NNCF trong OpenVINO đối với việc nén mô hình là gì?
5. Mô tả cách Apple MLX tận dụng kiến trúc bộ nhớ hợp nhất để tối ưu hóa.
6. Tổng hợp quy trình làm việc giúp chọn khung tối ưu hóa tốt nhất như thế nào?

### Bài tập thực hành

1. **Lượng hóa mô hình**: Áp dụng các mức lượng hóa khác nhau cho một mô hình và so sánh kết quả (1 giờ)
2. **Tối ưu hóa OpenVINO**: Sử dụng NNCF để nén một mô hình cho phần cứng Intel (1 giờ)
3. **So sánh khung làm việc**: Kiểm tra cùng một mô hình trên ba khung tối ưu hóa khác nhau (1 giờ)
4. **Đánh giá hiệu suất**: Đo lường tác động của tối ưu hóa lên tốc độ suy luận và sử dụng bộ nhớ (1 giờ)

## Module 5: SLMOps - Vận hành Mô hình Ngôn ngữ Nhỏ

### Mục tiêu học tập chính

- Hiểu các nguyên tắc quản lý vòng đời SLMOps
- Thành thạo các kỹ thuật chưng cất và tinh chỉnh cho triển khai tại edge
- Triển khai chiến lược triển khai sản xuất với giám sát
- Xây dựng quy trình vận hành và bảo trì SLM cấp doanh nghiệp

### Các lĩnh vực trọng tâm nghiên cứu

#### Phần 1: Giới thiệu về SLMOps
- **Khái niệm ưu tiên**: 
  - Sự thay đổi mô hình SLMOps trong vận hành AI
  - Kiến trúc ưu tiên chi phí và quyền riêng tư
  - Tác động chiến lược kinh doanh và lợi thế cạnh tranh

#### Phần 2: Chưng cất mô hình
- **Khái niệm ưu tiên**: 
  - Kỹ thuật chuyển giao kiến thức
  - Triển khai quy trình chưng cất hai giai đoạn
  - Quy trình chưng cất Azure ML

#### Phần 3: Chiến lược tinh chỉnh
- **Khái niệm ưu tiên**: 
  - Tinh chỉnh hiệu quả tham số (PEFT)
  - Phương pháp LoRA và QLoRA nâng cao
  - Đào tạo đa bộ điều hợp và tối ưu hóa siêu tham số

#### Phần 4: Triển khai sản xuất
- **Khái niệm ưu tiên**: 
  - Chuyển đổi và lượng hóa mô hình cho sản xuất
  - Cấu hình triển khai Foundry Local
  - Đánh giá hiệu suất và xác thực chất lượng

### Câu hỏi tự đánh giá

1. SLMOps khác gì so với MLOps truyền thống?
2. Giải thích lợi ích của chưng cất mô hình cho triển khai tại edge.
3. Những yếu tố chính cần xem xét khi tinh chỉnh SLM trong môi trường hạn chế tài nguyên là gì?
4. Mô tả một quy trình triển khai sản xuất hoàn chỉnh cho các ứng dụng AI tại edge.

### Bài tập thực hành

1. **Chưng cất cơ bản**: Tạo một mô hình nhỏ hơn từ một mô hình lớn hơn (1 giờ)
2. **Thử nghiệm tinh chỉnh**: Tinh chỉnh một mô hình cho một lĩnh vực cụ thể (1 giờ)
3. **Quy trình triển khai**: Thiết lập một quy trình CI/CD cơ bản cho triển khai mô hình (1 giờ)

## Module 6: Hệ thống SLM Agentic - Tác nhân AI và Gọi hàm

### Mục tiêu học tập chính

- Xây dựng các tác nhân AI thông minh cho môi trường edge sử dụng Mô hình Ngôn ngữ Nhỏ
- Triển khai khả năng gọi hàm với các quy trình làm việc có hệ thống
- Thành thạo tích hợp Model Context Protocol (MCP) để tương tác công cụ tiêu chuẩn hóa
- Tạo hệ thống tác nhân phức tạp với sự can thiệp tối thiểu của con người

### Các lĩnh vực trọng tâm nghiên cứu

#### Phần 1: Tác nhân AI và nền tảng SLM
- **Khái niệm ưu tiên**: 
  - Khung phân loại tác nhân (phản xạ, dựa trên mô hình, dựa trên mục tiêu, tác nhân học tập)
  - Phân tích đánh đổi giữa SLM và LLM
  - Mẫu thiết kế tác nhân dành riêng cho edge
  - Tối ưu hóa tài nguyên cho tác nhân

#### Phần 2: Gọi hàm trong Mô hình Ngôn ngữ Nhỏ
- **Khái niệm ưu tiên**: 
  - Triển khai quy trình làm việc có hệ thống (phát hiện ý định, đầu ra JSON, thực thi bên ngoài)
  - Triển khai cụ thể theo nền tảng (Phi-4-mini, các mô hình Qwen được chọn, Microsoft Foundry Local)
  - Ví dụ nâng cao (hợp tác đa tác nhân, lựa chọn công cụ động)
  - Cân nhắc sản xuất (giới hạn tốc độ, ghi nhật ký kiểm toán, biện pháp bảo mật)

#### Phần 3: Tích hợp Model Context Protocol (MCP)
- **Khái niệm ưu tiên**: 
  - Kiến trúc giao thức và thiết kế hệ thống phân lớp
  - Hỗ trợ đa backend (Ollama cho phát triển, vLLM cho sản xuất)
  - Giao thức kết nối (chế độ STDIO và SSE)
  - Ứng dụng thực tế (tự động hóa web, xử lý dữ liệu, tích hợp API)

### Câu hỏi tự đánh giá

1. Những cân nhắc kiến trúc chính cho các tác nhân AI tại edge là gì?
2. Gọi hàm cải thiện khả năng của tác nhân như thế nào?
3. Giải thích vai trò của Model Context Protocol trong giao tiếp của tác nhân.

### Bài tập thực hành

1. **Tác nhân đơn giản**: Xây dựng một tác nhân AI cơ bản với khả năng gọi hàm (1 giờ)
2. **Tích hợp MCP**: Triển khai MCP trong một ứng dụng tác nhân (30 phút)

## Workshop: Lộ trình học tập thực hành

### Mục tiêu học tập chính

- Xây dựng ứng dụng AI sẵn sàng sản xuất bằng SDK Foundry Local và các phương pháp tốt nhất
- Triển khai xử lý lỗi toàn diện và mẫu phản hồi người dùng
- Tạo các pipeline RAG với đánh giá chất lượng và giám sát hiệu suất
- Phát triển hệ thống đa tác nhân với mẫu điều phối viên
- Thành thạo định tuyến mô hình thông minh cho lựa chọn mô hình dựa trên nhiệm vụ
- Triển khai các giải pháp AI ưu tiên cục bộ với kiến trúc bảo vệ quyền riêng tư

### Các lĩnh vực trọng tâm nghiên cứu

#### Phiên 01: Bắt đầu với Foundry Local
- **Khái niệm ưu tiên**:
  - Tích hợp SDK FoundryLocalManager và khám phá dịch vụ tự động
  - Triển khai chat cơ bản và streaming
  - Mẫu xử lý lỗi và phản hồi người dùng
  - Cấu hình dựa trên môi trường

#### Phiên 02: Xây dựng giải pháp AI với RAG
- **Khái niệm ưu tiên**:
  - Nhúng vector trong bộ nhớ với sentence-transformers
  - Triển khai pipeline RAG (truy xuất → tạo)
  - Đánh giá chất lượng với số liệu RAGAS
  - Nhập an toàn cho các phụ thuộc tùy chọn

#### Phiên 03: Mô hình mã nguồn mở
- **Khái niệm ưu tiên**:
  - Chiến lược đánh giá đa mô hình
  - Đo lường độ trễ và thông lượng
  - Suy giảm dần và phục hồi lỗi
  - So sánh hiệu suất giữa các dòng mô hình

#### Phiên 04: Mô hình tiên tiến
- **Khái niệm ưu tiên**:
  - Phương pháp so sánh SLM và LLM
  - Gợi ý kiểu và định dạng đầu ra toàn diện
  - Xử lý lỗi theo từng mô hình
  - Kết quả có cấu trúc để phân tích

#### Phiên 05: Tác nhân hỗ trợ AI
- **Khái niệm ưu tiên**:
  - Điều phối đa tác nhân với mẫu điều phối viên
  - Quản lý bộ nhớ tác nhân và theo dõi trạng thái
  - Xử lý lỗi pipeline và ghi nhật ký giai đoạn
  - Giám sát hiệu suất và thống kê

#### Phiên 06: Mô hình như công cụ
- **Khái niệm ưu tiên**:
  - Phát hiện ý định và khớp mẫu
  - Thuật toán định tuyến mô hình dựa trên từ khóa
  - Pipeline nhiều bước (lập kế hoạch → thực thi → tinh chỉnh)
  - Tài liệu chức năng toàn diện

### Câu hỏi tự đánh giá

1. FoundryLocalManager đơn giản hóa quản lý dịch vụ như thế nào so với các cuộc gọi REST thủ công?
2. Giải thích tầm quan trọng của các bảo vệ nhập cho các phụ thuộc tùy chọn như sentence-transformers.
3. Những chiến lược nào đảm bảo suy giảm dần trong đánh giá đa mô hình?
4. Mẫu điều phối viên điều phối nhiều tác nhân chuyên biệt như thế nào?
5. Mô tả các thành phần của một bộ định tuyến mô hình thông minh.
6. Những yếu tố chính của xử lý lỗi sẵn sàng sản xuất là gì?

### Bài tập thực hành

1. **Ứng dụng chat**: Triển khai chat streaming với xử lý lỗi (45 phút)
2. **Pipeline RAG**: Xây dựng RAG tối thiểu với đánh giá chất lượng (1 giờ)
3. **Đánh giá mô hình**: So sánh 3+ mô hình về hiệu suất (1 giờ)
4. **Hệ thống đa tác nhân**: Tạo điều phối viên với 2 tác nhân chuyên biệt (1.5 giờ)
5. **Bộ định tuyến thông minh**: Xây dựng lựa chọn mô hình dựa trên nhiệm vụ (1 giờ)
6. **Triển khai sản xuất**: Thêm giám sát và xử lý lỗi toàn diện (45 phút)

### Phân bổ thời gian

**Học tập tập trung (1 tuần)**:
- Ngày 1: Phiên 01-02 (Chat + RAG) - 3 giờ
- Ngày 2: Phiên 03-04 (Đánh giá + So sánh) - 3 giờ
- Ngày 3: Phiên 05-06 (Tác nhân + Định tuyến) - 3 giờ
- Ngày 4: Bài tập thực hành và xác thực - 2 giờ

**Học bán thời gian (2 tuần)**:
- Tuần 1: Phiên 01-03 (6 giờ tổng cộng)
- Tuần 2: Phiên 04-06 + bài tập (5 giờ tổng cộng)

## Module 7: Các mẫu triển khai EdgeAI

### Mục tiêu học tập chính

- Thành thạo AI Toolkit cho Visual Studio Code để phát triển quy trình làm việc EdgeAI toàn diện
- Nắm vững nền tảng Windows AI Foundry và các chiến lược tối ưu hóa NPU
- Triển khai EdgeAI trên nhiều nền tảng phần cứng và kịch bản triển khai
- Xây dựng ứng dụng EdgeAI sẵn sàng sản xuất với các tối ưu hóa cụ thể theo nền tảng

### Các lĩnh vực trọng tâm nghiên cứu

#### Phần 1: AI Toolkit cho Visual Studio Code
- **Khái niệm ưu tiên**: 
  - Môi trường phát triển Edge AI toàn diện trong VS Code
  - Danh mục mô hình và khám phá cho triển khai tại edge
  - Quy trình thử nghiệm cục bộ, tối ưu hóa và phát triển tác nhân
  - Giám sát hiệu suất và đánh giá cho các kịch bản edge

#### Phần 2: Hướng dẫn phát triển Windows EdgeAI
- **Khái niệm ưu tiên**: 
  - Tổng quan toàn diện về nền tảng Windows AI Foundry
  - API Phi Silica cho suy luận NPU hiệu quả
  - API Thị giác Máy tính cho xử lý hình ảnh và OCR
  - CLI Foundry Local cho phát triển và thử nghiệm cục bộ

#### Phần 3: Triển khai cụ thể theo nền tảng
- **Khái niệm ưu tiên**: 
  - Triển khai NVIDIA Jetson Orin Nano (hiệu suất AI 67 TOPS)
  - Ứng dụng di động với .NET MAUI và ONNX Runtime GenAI
  - Giải pháp Azure EdgeAI với kiến trúc lai đám mây-edge
  - Tối ưu hóa Windows ML với hỗ trợ phần cứng phổ quát
  - Ứng dụng Foundry Local với triển khai RAG tập trung vào quyền riêng tư

### Câu hỏi tự đánh giá

1
4. Giải thích vai trò của tối ưu hóa NPU trong các ứng dụng AI biên hiện đại.  
5. API Phi Silica tận dụng phần cứng NPU để tối ưu hóa hiệu suất như thế nào?  
6. So sánh lợi ích của triển khai cục bộ so với triển khai trên đám mây đối với các ứng dụng nhạy cảm về quyền riêng tư.  

### Bài tập thực hành  

1. **Cài đặt AI Toolkit**: Cấu hình AI Toolkit và tối ưu hóa một mô hình (1 giờ)  
2. **Windows AI Foundry**: Xây dựng một ứng dụng AI đơn giản trên Windows sử dụng Phi Silica API (1 giờ)  
3. **Triển khai đa nền tảng**: Triển khai cùng một mô hình trên hai nền tảng khác nhau (1 giờ)  
4. **Tối ưu hóa NPU**: Kiểm tra hiệu suất NPU với các công cụ của Windows AI Foundry (30 phút)  

## Module 8: Microsoft Foundry Local – Bộ công cụ phát triển hoàn chỉnh (Hiện đại hóa)  

### Mục tiêu học tập chính  

- Cài đặt và cấu hình Foundry Local với tích hợp SDK hiện đại  
- Triển khai các hệ thống đa tác nhân nâng cao với mô hình điều phối  
- Xây dựng bộ định tuyến mô hình thông minh với lựa chọn tự động dựa trên nhiệm vụ  
- Triển khai các giải pháp AI sẵn sàng cho sản xuất với giám sát toàn diện  
- Tích hợp với Azure AI Foundry cho các kịch bản triển khai kết hợp  
- Thành thạo các mẫu SDK hiện đại với FoundryLocalManager và OpenAI client  

### Các lĩnh vực cần tập trung học  

#### Phần 1: Cài đặt và cấu hình hiện đại  
- **Các khái niệm ưu tiên**:  
  - Tích hợp SDK FoundryLocalManager  
  - Tự động phát hiện dịch vụ và giám sát tình trạng  
  - Mẫu cấu hình dựa trên môi trường  
  - Các cân nhắc khi triển khai sản xuất  

#### Phần 2: Hệ thống đa tác nhân nâng cao  
- **Các khái niệm ưu tiên**:  
  - Mô hình điều phối với các tác nhân chuyên biệt  
  - Chuyên môn hóa tác nhân truy xuất, suy luận và thực thi  
  - Cơ chế vòng lặp phản hồi để cải tiến  
  - Giám sát hiệu suất và theo dõi thống kê  

#### Phần 3: Định tuyến mô hình thông minh  
- **Các khái niệm ưu tiên**:  
  - Thuật toán lựa chọn mô hình dựa trên từ khóa  
  - Hỗ trợ nhiều mô hình (tổng quát, suy luận, mã hóa, sáng tạo)  
  - Cấu hình biến môi trường để linh hoạt  
  - Kiểm tra tình trạng dịch vụ và xử lý lỗi  

#### Phần 4: Triển khai sẵn sàng sản xuất  
- **Các khái niệm ưu tiên**:  
  - Xử lý lỗi toàn diện và cơ chế dự phòng  
  - Giám sát yêu cầu và theo dõi hiệu suất  
  - Ví dụ tương tác với Jupyter notebook và các chỉ số đánh giá  
  - Các mẫu tích hợp với ứng dụng hiện có  

### Câu hỏi tự đánh giá  

1. Cách tiếp cận hiện đại của FoundryLocalManager khác gì so với các cuộc gọi REST thủ công?  
2. Giải thích mô hình điều phối và cách nó tổ chức các tác nhân chuyên biệt.  
3. Bộ định tuyến thông minh chọn mô hình phù hợp dựa trên nội dung truy vấn như thế nào?  
4. Các thành phần chính của một hệ thống tác nhân AI sẵn sàng sản xuất là gì?  
5. Làm thế nào để triển khai giám sát tình trạng toàn diện cho các dịch vụ Foundry Local?  
6. So sánh lợi ích của cách tiếp cận hiện đại hóa so với các mẫu triển khai truyền thống.  

### Bài tập thực hành  

1. **Cài đặt SDK hiện đại**: Cấu hình FoundryLocalManager với tự động phát hiện dịch vụ (30 phút)  
2. **Hệ thống đa tác nhân**: Chạy mô hình điều phối nâng cao với các tác nhân chuyên biệt (30 phút)  
3. **Định tuyến thông minh**: Kiểm tra bộ định tuyến mô hình với các loại truy vấn khác nhau (30 phút)  
4. **Khám phá tương tác**: Sử dụng Jupyter notebook để khám phá các tính năng nâng cao (45 phút)  
5. **Triển khai sản xuất**: Triển khai các mẫu giám sát và xử lý lỗi (30 phút)  
6. **Tích hợp kết hợp**: Cấu hình các kịch bản dự phòng của Azure AI Foundry (30 phút)  

## Hướng dẫn phân bổ thời gian  

Để giúp bạn tận dụng tối đa thời gian 30 giờ của khóa học (bao gồm Workshop), dưới đây là gợi ý phân bổ thời gian:  

| Hoạt động | Thời gian phân bổ | Mô tả |  
|-----------|-------------------|-------|  
| Đọc tài liệu cốt lõi | 12 giờ | Tập trung vào các khái niệm quan trọng trong từng module |  
| Bài tập thực hành | 10 giờ | Thực hành các kỹ thuật chính (bao gồm Workshop) |  
| Tự đánh giá | 3 giờ | Kiểm tra hiểu biết của bạn qua các câu hỏi và tự đánh giá |  
| Dự án nhỏ | 5 giờ | Áp dụng kiến thức vào một bài thực hành nhỏ |  

### Các lĩnh vực trọng tâm theo thời gian  

**Nếu bạn chỉ có 10 giờ:**  
- Hoàn thành Module 0 (Giới thiệu) và Module 1, 2, 3 (các khái niệm cốt lõi về EdgeAI)  
- Thực hiện ít nhất một bài tập thực hành cho mỗi module  
- Tập trung vào việc hiểu các khái niệm cốt lõi thay vì chi tiết triển khai  

**Nếu bạn có thể dành toàn bộ 20 giờ:**  
- Hoàn thành tất cả tám module (bao gồm Giới thiệu)  
- Thực hiện các bài tập thực hành chính từ mỗi module  
- Hoàn thành một dự án nhỏ từ Module 7  
- Khám phá ít nhất 2-3 tài liệu bổ sung  

**Nếu bạn có hơn 20 giờ:**  
- Hoàn thành tất cả các module (bao gồm Giới thiệu) với các bài tập chi tiết  
- Xây dựng nhiều dự án nhỏ  
- Khám phá các kỹ thuật tối ưu hóa nâng cao trong Module 4  
- Triển khai sản xuất từ Module 5  

## Tài nguyên cần thiết  

Những tài nguyên được chọn lọc kỹ lưỡng này mang lại giá trị cao nhất cho thời gian học tập của bạn:  

### Tài liệu cần đọc  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Công cụ tối ưu hóa mô hình hiệu quả nhất  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cách nhanh nhất để triển khai SLMs cục bộ  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Tham khảo cho một mô hình tối ưu hóa biên hàng đầu  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Bộ công cụ tối ưu hóa toàn diện của Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Môi trường phát triển EdgeAI tích hợp  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Nền tảng phát triển EdgeAI dành riêng cho Windows  

### Công cụ tiết kiệm thời gian  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Truy cập và triển khai mô hình nhanh chóng  
- [Gradio](https://www.gradio.app/docs/interface) - Phát triển giao diện người dùng nhanh chóng cho các bản demo AI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Đơn giản hóa việc tối ưu hóa mô hình  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Suy luận CPU hiệu quả  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Khung nén mạng nơ-ron  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Bộ công cụ triển khai mô hình ngôn ngữ lớn  

## Mẫu theo dõi tiến độ  

Sử dụng mẫu đơn giản này để theo dõi tiến độ học tập của bạn qua khóa học 20 giờ:  

| Module | Ngày hoàn thành | Thời gian đã dành | Những điều rút ra chính |  
|--------|-----------------|-------------------|--------------------------|  
| Module 0: Giới thiệu về EdgeAI | | | |  
| Module 1: Các nguyên lý cơ bản về EdgeAI | | | |  
| Module 2: Nền tảng SLM | | | |  
| Module 3: Triển khai SLM | | | |  
| Module 4: Tối ưu hóa mô hình | | | |  
| Module 5: SLMOps | | | |  
| Module 6: Tác nhân AI | | | |  
| Module 7: Công cụ phát triển | | | |  
| Workshop: Học tập thực hành | | | |  
| Module 8: Bộ công cụ Foundry Local | | | |  
| Bài tập thực hành | | | |  
| Dự án nhỏ | | | |  

## Ý tưởng dự án nhỏ  

Hãy hoàn thành một trong những dự án sau để thực hành các khái niệm về EdgeAI (mỗi dự án được thiết kế để mất từ 2-4 giờ):  

### Dự án cơ bản (2-3 giờ mỗi dự án)  
1. **Trợ lý văn bản biên**: Tạo một công cụ hoàn thành văn bản ngoại tuyến đơn giản sử dụng mô hình ngôn ngữ nhỏ  
2. **Bảng điều khiển so sánh mô hình**: Xây dựng một công cụ trực quan hóa cơ bản về các chỉ số hiệu suất của các SLM khác nhau  
3. **Thí nghiệm tối ưu hóa**: Đo lường tác động của các mức lượng tử hóa khác nhau trên cùng một mô hình cơ bản  

### Dự án trung cấp (3-4 giờ mỗi dự án)  
4. **Quy trình làm việc AI Toolkit**: Sử dụng AI Toolkit của VS Code để tối ưu hóa và triển khai một mô hình từ đầu đến cuối  
5. **Ứng dụng Windows AI Foundry**: Tạo một ứng dụng Windows sử dụng Phi Silica API và tối ưu hóa NPU  
6. **Triển khai đa nền tảng**: Triển khai cùng một mô hình tối ưu hóa trên Windows (OpenVINO) và di động (.NET MAUI)  
7. **Tác nhân gọi hàm**: Xây dựng một tác nhân AI với khả năng gọi hàm cho các kịch bản biên  

### Dự án tích hợp nâng cao (4-5 giờ mỗi dự án)  
8. **Pipeline tối ưu hóa OpenVINO**: Triển khai tối ưu hóa mô hình hoàn chỉnh sử dụng NNCF và bộ công cụ GenAI  
9. **Pipeline SLMOps**: Triển khai toàn bộ vòng đời mô hình từ huấn luyện đến triển khai biên  
10. **Hệ thống biên đa mô hình**: Triển khai nhiều mô hình chuyên biệt làm việc cùng nhau trên phần cứng biên  
11. **Hệ thống tích hợp MCP**: Xây dựng một hệ thống tác nhân sử dụng Giao thức Ngữ cảnh Mô hình để tương tác công cụ  

## Tài liệu tham khảo  

- Microsoft Learn (Foundry Local)  
  - Tổng quan: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Bắt đầu: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - Tham khảo CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Tích hợp với SDK suy luận: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Hướng dẫn mở WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Biên dịch mô hình Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Tổng quan: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Tác nhân (tổng quan): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Công cụ tối ưu hóa và suy luận  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (bắt đầu): https://onnxruntime.ai/docs/get-started/with-python.html  
  - Tích hợp Olive với ONNX Runtime: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Khung triển khai và mô hình  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (bắt đầu): https://github.com/ollama/ollama#get-started  
- Công cụ phát triển (Windows và VS Code)  
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (tổng quan): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Cộng đồng học tập  

Tham gia thảo luận và kết nối với các học viên khác:  
- Thảo luận trên GitHub tại [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Kết luận  

EdgeAI đại diện cho biên giới của việc triển khai trí tuệ nhân tạo, mang lại khả năng mạnh mẽ trực tiếp đến các thiết bị trong khi giải quyết các mối quan tâm quan trọng về quyền riêng tư, độ trễ và kết nối. Khóa học 20 giờ này cung cấp cho bạn kiến thức cơ bản và kỹ năng thực hành để bắt đầu làm việc với các công nghệ EdgeAI ngay lập tức.  

Khóa học được thiết kế ngắn gọn và tập trung vào các khái niệm quan trọng nhất, giúp bạn nhanh chóng nắm bắt kiến thức giá trị mà không cần cam kết thời gian quá lớn. Hãy nhớ rằng thực hành thực tế, ngay cả với các ví dụ đơn giản, là chìa khóa để củng cố những gì bạn đã học.  

Chúc bạn học tập vui vẻ!

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp của con người. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.