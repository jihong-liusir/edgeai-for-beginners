<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a534c7d108d29f908a8f9f693d694664",
  "translation_date": "2025-09-25T00:06:44+00:00",
  "source_file": "Module08/05.AIPoweredAgents.md",
  "language_code": "vi"
}
-->
# Buổi 5: Xây dựng các tác nhân AI nhanh chóng với Foundry Local

Lưu ý: Khả năng của các tác nhân trong Foundry Local liên tục phát triển—hãy kiểm tra hỗ trợ trong ghi chú phát hành mới nhất trước khi triển khai các mẫu nâng cao.

## Tổng quan

Sử dụng Foundry Local để nhanh chóng tạo mẫu ứng dụng tác nhân: lời nhắc hệ thống, nền tảng dữ liệu, và các mẫu điều phối. Khi hỗ trợ tác nhân có sẵn, bạn có thể chuẩn hóa theo cách gọi hàm tương thích với OpenAI hoặc sử dụng Azure AI Agents trên đám mây trong các thiết kế kết hợp.

> **🔄 Cập nhật cho SDK hiện đại**: Module này đã được điều chỉnh theo các mẫu kho lưu trữ Microsoft Foundry-Local mới nhất và phù hợp với triển khai toàn diện trong `samples/05/`. Các ví dụ hiện sử dụng `foundry-local-sdk` hiện đại và client `OpenAI` thay vì các yêu cầu thủ công.

**🏗️ Điểm nổi bật về kiến trúc:**
- **Tác nhân chuyên biệt**: Tác nhân truy xuất, suy luận, và thực thi với các khả năng riêng biệt
- **Mẫu điều phối**: Điều phối các quy trình làm việc đa tác nhân với vòng phản hồi
- **Tích hợp SDK hiện đại**: Sử dụng `FoundryLocalManager` và client OpenAI
- **Sẵn sàng cho sản xuất**: Bao gồm xử lý lỗi, giám sát hiệu suất, và kiểm tra sức khỏe
- **Ví dụ toàn diện**: Notebook Jupyter tương tác với các tính năng nâng cao

**📁 Triển khai cục bộ:**
- `samples/05/multi_agent_orchestration.ipynb` - Ví dụ tương tác và đánh giá hiệu suất
- `samples/05/agents/specialists.py` - Triển khai tác nhân
- `samples/05/agents/coordinator.py` - Logic điều phối

Tham khảo:
- Tài liệu Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Azure AI Foundry Agents: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Ví dụ gọi hàm (Foundry Local samples): https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling

## Mục tiêu học tập
- Thiết kế lời nhắc hệ thống và chiến lược nền tảng dữ liệu để đảm bảo hành vi đáng tin cậy
- Triển khai các mẫu gọi hàm (sử dụng công cụ)
- Điều phối quy trình làm việc đa tác nhân (cục bộ và kết hợp)
- Lập kế hoạch cho khả năng quan sát và an toàn

## Phần 1: Lời nhắc hệ thống và nền tảng dữ liệu

- Xác định vai trò, ràng buộc, và các mẫu đầu ra nghiêm ngặt
- Nền tảng phản hồi với dữ liệu cục bộ hoặc doanh nghiệp
- Bắt buộc đầu ra JSON để tự động hóa hạ nguồn

## Phần 2: Gọi hàm (Cách tiếp cận SDK hiện đại)

```python
# tools.py
import json
from typing import List, Dict, Any

def get_weather(city: str) -> str:
    return f"Weather in {city}: Sunny, 25C"

# Modern tools format for OpenAI API
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a city",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "City name"}
                },
                "required": ["city"]
            }
        }
    }
]
```

```python
# agent.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
import json
from tools import TOOLS, get_weather

# Initialize Foundry Local Manager
alias = "phi-4-mini"
manager = FoundryLocalManager(alias)

# Create OpenAI client using Foundry Local endpoint
client = OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

SYSTEM_PROMPT = "You are a helpful assistant. Use tools when needed."

def process_function_call(messages: List[Dict], tools: List[Dict]) -> str:
    """Process function calling with modern OpenAI API."""
    try:
        response = client.chat.completions.create(
            model=manager.get_model_info(alias).id,
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
        
        message = response.choices[0].message
        
        if message.tool_calls:
            # Handle function calls
            messages.append(message)
            
            for tool_call in message.tool_calls:
                if tool_call.function.name == "get_weather":
                    args = json.loads(tool_call.function.arguments)
                    result = get_weather(args["city"])
                    
                    # Add function result to messages
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
            
            # Get final response
            final_response = client.chat.completions.create(
                model=manager.get_model_info(alias).id,
                messages=messages
            )
            return final_response.choices[0].message.content
        else:
            return message.content
            
    except Exception as e:
        return f"Error: {str(e)}"

# Example usage
messages = [
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": "What's the weather in Paris?"}
]

result = process_function_call(messages, TOOLS)
print(result)
```

Chạy:
```powershell
# Ensure Foundry Local is running with a model
foundry model run phi-4-mini
python agent.py
```

## Phần 3: Điều phối đa tác nhân (Mẫu)

Thiết kế một bộ điều phối để phân công nhiệm vụ cho các tác nhân chuyên biệt (truy xuất, suy luận, thực thi) sử dụng endpoint tương thích OpenAI của Foundry Local.

Bước 1) Xác định các tác nhân chuyên biệt với SDK hiện đại (xem `samples/05/agents/specialists.py`)
```python
# agents/specialists.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
from typing import List, Dict, Any

class FoundryClient:
    """Shared client for all specialist agents."""
    
    def __init__(self, model_alias: str = "phi-4-mini"):
        self.client = None
        self.model_name = None
        self.model_alias = model_alias
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize OpenAI client with Foundry Local."""
        try:
            manager = FoundryLocalManager(self.model_alias)
            model_info = manager.get_model_info(self.model_alias)
            
            self.client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            self.model_name = model_info.id
            print(f"✅ Foundry Local initialized with model: {self.model_name}")
        except Exception as e:
            print(f"❌ Error initializing Foundry Local: {e}")
            raise
    
    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:
        """Send chat completion request to the model."""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Error generating response: {str(e)}"

# Global client instance
_client = FoundryClient()

class RetrievalAgent:
    """Agent specialized in retrieving relevant information from knowledge sources."""
    
    SYSTEM = """You are a specialized retrieval agent. Your job is to extract and retrieve 
    the most relevant information from knowledge sources based on a given query. Focus on key facts, 
    data points, and contextual information that would be useful for decision-making."""
    
    def run(self, query: str) -> str:
        """Retrieve relevant information based on the query."""
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Query: {query}\n\nRetrieve the most relevant key facts, data points, and contextual information that would help answer this query or support decision-making around it."}
        ]
        return _client.chat(messages)

class ReasoningAgent:
    """Agent specialized in step-by-step analysis and reasoning."""
    
    SYSTEM = """You are a specialized reasoning agent. Your job is to analyze inputs 
    step-by-step and produce structured, logical conclusions. Break down complex problems 
    into manageable parts and provide clear reasoning for your conclusions."""
    
    def run(self, context: str, question: str) -> str:
        """Analyze context and question to produce structured conclusions."""
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Context:\n{context}\n\nQuestion: {question}\n\nAnalyze this step-by-step and provide a structured, logical conclusion with clear reasoning."}
        ]
        return _client.chat(messages, max_tokens=400)

class ExecutionAgent:
    """Agent specialized in creating actionable execution plans."""
    
    SYSTEM = """You are a specialized execution agent. Your job is to transform decisions 
    and conclusions into concrete, actionable steps. Always format your response as valid JSON 
    with an array of action items. Each action should be specific, measurable, and achievable."""
    
    def run(self, decision: str) -> str:
        """Transform decision into actionable steps in JSON format."""
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Decision/Conclusion:\n{decision}\n\nCreate 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n{{\"actions\": [{{\"step\": 1, \"description\": \"...\", \"priority\": \"high/medium/low\", \"timeline\": \"...\"}}]}}"}
        ]
        return _client.chat(messages, max_tokens=400, temperature=0.3)
```

Bước 2) Xây dựng bộ điều phối với các tính năng nâng cao
```python
# agents/coordinator.py
from .specialists import RetrievalAgent, ReasoningAgent, ExecutionAgent
from typing import Dict, Any
import time
import json

class Coordinator:
    """Multi-agent coordinator that orchestrates specialist agents to handle complex tasks."""
    
    def __init__(self):
        """Initialize the coordinator with specialist agents."""
        self.retrieval = RetrievalAgent()
        self.reasoning = ReasoningAgent()
        self.execution = ExecutionAgent()
    
    def handle(self, user_goal: str) -> Dict[str, Any]:
        """
        Orchestrate multiple agents to handle a complex user goal.
        
        Args:
            user_goal: The user's high-level goal or request
            
        Returns:
            Dictionary containing the goal, context, decision, and actions
        """
        print(f"🎯 **Coordinator:** Processing goal: {user_goal}")
        print("=" * 60)
        
        start_time = time.time()
        
        # Step 1: Retrieve relevant context
        print("📚 **Step 1:** Retrieving context...")
        context = self.retrieval.run(user_goal)
        print(f"   ✅ Context retrieved ({len(context)} chars)")
        
        # Step 2: Analyze and reason about the context
        print("🧠 **Step 2:** Analyzing and reasoning...")
        decision = self.reasoning.run(context, user_goal)
        print(f"   ✅ Analysis completed ({len(decision)} chars)")
        
        # Step 3: Create actionable execution plan
        print("⚡ **Step 3:** Creating execution plan...")
        actions = self.execution.run(decision)
        print(f"   ✅ Execution plan created ({len(actions)} chars)")
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        result = {
            "goal": user_goal,
            "context": context,
            "decision": decision,
            "actions": actions,
            "agent_flow": ["retrieval", "reasoning", "execution"],
            "processing_time": processing_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        print(f"✅ **Coordination Complete** (⏱️ {processing_time:.2f}s)")
        return result
    
    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:
        """
        Handle a goal with multiple feedback rounds for refinement.
        
        Args:
            user_goal: The user's high-level goal or request
            feedback_rounds: Number of feedback rounds to perform
            
        Returns:
            Dictionary containing the refined result
        """
        result = self.handle(user_goal)
        
        for round_num in range(feedback_rounds):
            print(f"\n🔄 **Feedback Round {round_num + 1}:**")
            print("-" * 40)
            
            # Use reasoning agent to refine the execution plan
            refinement_prompt = f"""
            Original Goal: {user_goal}
            Current Decision: {result['decision']}
            Current Actions: {result['actions']}
            
            Review the above and suggest improvements or refinements to make the execution plan more effective.
            """
            
            refined_decision = self.reasoning.run(result['context'], refinement_prompt)
            refined_actions = self.execution.run(refined_decision)
            
            result['decision'] = refined_decision
            result['actions'] = refined_actions
            result['refinement_rounds'] = round_num + 1
            
            print(f"   ✅ Round {round_num + 1} refinement completed")
        
        return result

def main():
    """Main function demonstrating the multi-agent coordinator."""
    print("🤖 **Multi-Agent Coordinator Demo**")
    print("=" * 50)
    
    # Create coordinator
    coord = Coordinator()
    
    # Example goals
    example_goals = [
        "Create a plan to onboard 5 new customers this month",
        "Develop a strategy to improve team productivity by 20%",
        "Design a customer feedback collection system"
    ]
    
    # Process example with feedback
    goal = example_goals[0]
    print(f"🎯 **Processing Goal:** {goal}")
    print("-" * 50)
    
    try:
        # Basic processing
        result = coord.handle(goal)
        
        # With feedback refinement
        refined_result = coord.handle_with_feedback(goal, feedback_rounds=1)
        
        print("\n📊 **Final Result:**")
        print("=" * 50)
        print(f"**Goal:** {refined_result['goal']}")
        print(f"**Processing Time:** {refined_result['processing_time']:.2f}s")
        
        # Try to parse actions as JSON
        try:
            actions_json = json.loads(refined_result['actions'])
            print(f"\n**Formatted Actions:**")
            print(json.dumps(actions_json, indent=2))
        except (json.JSONDecodeError, TypeError):
            print(f"\n**Actions:** {refined_result['actions']}")
            
    except Exception as e:
        print(f"❌ **Error:** {e}")
        print("\nPlease ensure Foundry Local is running with a model loaded.")

if __name__ == "__main__":
    main()
```

Bước 3) Xác thực với Foundry Local và chạy các mẫu
```powershell
REM Confirm the local endpoint and model are available
foundry model list
foundry model run phi-4-mini
curl http://localhost:8000/v1/models

REM Run the coordinator from Module08 directory
cd Module08
python -m samples.05.agents.coordinator

REM Or explore the comprehensive Jupyter notebook
jupyter notebook samples/05/multi_agent_orchestration.ipynb
```

> **📚 Tham khảo mẫu cục bộ:**
> - **Triển khai chính**: `samples/05/agents/specialists.py` và `samples/05/agents/coordinator.py`
> - **Ví dụ toàn diện**: `samples/05/multi_agent_orchestration.ipynb`
> - **Hướng dẫn thiết lập**: `samples/05/README.md`
> 
> **🔗 Các mẫu liên quan Foundry Local:**
> - [Ví dụ gọi hàm](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling)
> - [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)

Hướng dẫn:
- Triển khai cơ chế thử lại và giới hạn thời gian giữa các tác nhân
- Thêm một bộ nhớ nhỏ trong RAM (dict) để lưu trạng thái cuộc trò chuyện/chủ đề
- Giới hạn tốc độ khi liên kết nhiều cuộc gọi

## Phần 4: Khả năng quan sát và an toàn

Theo dõi lời nhắc, phản hồi, và lỗi cục bộ, đồng thời đảm bảo vệ sinh dữ liệu trong ngăn xếp tác nhân của bạn.

Bước 1) Ghi nhật ký yêu cầu nhẹ (tùy chọn)

Lưu ý: Trình trợ giúp sau đây không được bao gồm theo mặc định. Tạo `infra/obs.py` nếu bạn muốn ghi nhật ký JSON cục bộ cho các thử nghiệm.
```python
# infra/obs.py
import time, json, os
from datetime import datetime

LOG_DIR = os.getenv("FOUNDRY_AGENT_LOG_DIR", "./agent_logs")
os.makedirs(LOG_DIR, exist_ok=True)

def log_event(kind: str, payload: dict):
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    path = os.path.join(LOG_DIR, f"{ts}_{kind}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
```

Tích hợp ghi nhật ký vào các tác nhân (tùy chọn):
```python
# in agents/specialists.py after receiving content
from infra.obs import log_event
# ... inside chat(...)
resp = r.json()
log_event("chat_request", {"endpoint": f"{BASE_URL}/v1/chat/completions"})
log_event("chat_response", resp)
return resp["choices"][0]["message"]["content"]
```

Bước 2) Xác thực khả dụng và kiểm tra sức khỏe cơ bản qua CLI
```powershell
REM Ensure Foundry Local is running a model
foundry model list
foundry model run phi-4-mini

REM Validate the OpenAI-compatible endpoint
curl http://localhost:8000/v1/models
```

Bước 3) Vệ sinh và bảo mật thông tin cá nhân (PII)
- Trước khi gửi tin nhắn đến mô hình, loại bỏ hoặc mã hóa các trường nhạy cảm (email, số điện thoại, ID)
- Giữ dữ liệu nguồn thô trên thiết bị, chỉ truyền các chuỗi ngữ cảnh cần thiết

Trình trợ giúp vệ sinh ví dụ:
```python
# infra/redact.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```

Sử dụng trong các tác nhân:
```python
from infra.redact import sanitize
# user_goal = sanitize(user_goal)
# context = sanitize(context)
```

Bước 4) Bộ ngắt mạch và xử lý lỗi
- Bao quanh mỗi cuộc gọi tác nhân bằng try/except và cơ chế backoff lũy tiến
- Ngắt ngắn pipeline khi gặp lỗi lặp lại

```python
import time

def with_retry(func, retries=3, base_delay=0.5):
    for i in range(retries):
        try:
            return func()
        except Exception as e:
            if i == retries - 1:
                raise
            time.sleep(base_delay * (2 ** i))
```

Bước 5) Dấu vết kiểm toán cục bộ và xuất dữ liệu
- Lưu nhật ký JSON dưới `./agent_logs`
- Định kỳ nén và xoay vòng nhật ký
- Xuất các bản tóm tắt để xem xét (số lượng, độ trễ trung bình, tỷ lệ lỗi)

Bước 6) Kiểm tra chéo với tài liệu Microsoft Learn
- Foundry Local cung cấp API tương thích OpenAI (đã xác thực với `curl /v1/models`)
- Sử dụng `foundry model run <name>` để xác nhận tính khả dụng của mô hình
- Tuân theo hướng dẫn chính thức để tích hợp client và ứng dụng mẫu (Open WebUI/how-tos)

Tham khảo
- **Tài liệu Foundry Local**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- **Azure AI Agents**: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- **Mẫu cục bộ**:
  - Điều phối đa tác nhân: `Module08/samples/05/multi_agent_orchestration.ipynb`
  - Triển khai tác nhân: `Module08/samples/05/agents/`
  - README mẫu: `Module08/samples/05/README.md`
- **Mẫu chính thức của Microsoft**:
  - [Gọi hàm](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling)
  - [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)
  - [Foundry Local Python SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **Ví dụ tích hợp**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui

## Bước tiếp theo
- Khám phá Azure AI Agents để điều phối trên đám mây
- Thêm các kết nối doanh nghiệp (Microsoft Graph, Tìm kiếm, cơ sở dữ liệu)

---

