<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "382a763fcea7087e68a94c26216e5e70",
  "translation_date": "2025-09-22T21:49:48+00:00",
  "source_file": "Module08/05.AIPoweredAgents.md",
  "language_code": "vi"
}
-->
# Buổi 5: Xây dựng các tác nhân AI nhanh chóng với Foundry Local

Lưu ý: Khả năng của các tác nhân trong Foundry Local liên tục phát triển—hãy kiểm tra hỗ trợ trong ghi chú phát hành mới nhất trước khi triển khai các mẫu nâng cao.

## Tổng quan

Sử dụng Foundry Local để nhanh chóng tạo mẫu ứng dụng tác nhân: lời nhắc hệ thống, dữ liệu nền và các mẫu điều phối. Khi hỗ trợ tác nhân có sẵn, bạn có thể chuẩn hóa theo cách gọi hàm tương thích với OpenAI hoặc sử dụng Azure AI Agents trên đám mây trong các thiết kế kết hợp.

Tham khảo:
- Tài liệu Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Azure AI Foundry Agents: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Mẫu gọi hàm (Foundry Local samples): https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling

## Mục tiêu học tập
- Thiết kế lời nhắc hệ thống và chiến lược dữ liệu nền để đảm bảo hành vi đáng tin cậy
- Triển khai các mẫu gọi hàm (sử dụng công cụ)
- Điều phối quy trình làm việc đa tác nhân (cục bộ và kết hợp)
- Lập kế hoạch cho khả năng quan sát và an toàn

## Phần 1: Lời nhắc hệ thống và dữ liệu nền

- Xác định vai trò, ràng buộc và các mẫu đầu ra nghiêm ngặt
- Kết nối phản hồi với dữ liệu cục bộ hoặc dữ liệu doanh nghiệp
- Bắt buộc đầu ra JSON để tự động hóa quy trình sau

## Phần 2: Gọi hàm (Tương thích với OpenAI)

```python
# tools.py
import json

def get_weather(city: str) -> str:
    return f"Weather in {city}: Sunny, 25C"

FUNCTIONS = [
    {
        "name": "get_weather",
        "description": "Get current weather for a city",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "City name"}
            },
            "required": ["city"]
        }
    }
]
```

```python
# agent.py
import requests
import json
from tools import FUNCTIONS, get_weather

BASE_URL = "http://localhost:8000"
MODEL = "phi-4-mini"

SYSTEM_PROMPT = "You are a helpful assistant. Use tools when needed."

def call_model(messages, functions=None):
    payload = {
        "model": MODEL,
        "messages": messages,
        "functions": functions,
        "function_call": "auto"
    }
    r = requests.post(f"{BASE_URL}/v1/chat/completions", json=payload, timeout=60)
    r.raise_for_status()
    return r.json()

messages = [{"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": "What's the weather in Paris?"}]

resp = call_model(messages, functions=FUNCTIONS)
choice = resp["choices"][0]["message"]

if "function_call" in choice:
    fc = choice["function_call"]
    if fc["name"] == "get_weather":
        args = json.loads(fc["arguments"])
        result = get_weather(args["city"])
        messages.append(choice)
        messages.append({"role": "function", "name": "get_weather", "content": result})
        final = call_model(messages)
        print(final["choices"][0]["message"]["content"]) 
else:
    print(choice.get("content"))
```

Chạy:
```powershell
# Ensure a model is running
foundry model run phi-4-mini
python agent.py
```


## Phần 3: Điều phối đa tác nhân (Mẫu)

Thiết kế một bộ điều phối để phân công nhiệm vụ cho các tác nhân chuyên biệt (truy xuất, suy luận, thực thi) sử dụng điểm cuối tương thích với OpenAI của Foundry Local.

Bước 1) Xác định các tác nhân chuyên biệt  
```python
# agents/specialists.py
import requests
BASE_URL = "http://localhost:8000"
MODEL = "phi-4-mini"

headers = {"Content-Type": "application/json", "Authorization": "Bearer local-key"}

def chat(messages, max_tokens=300, temperature=0.4):
    r = requests.post(f"{BASE_URL}/v1/chat/completions", json={
        "model": MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature
    }, headers=headers, timeout=60)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

class RetrievalAgent:
    SYSTEM = "You retrieve relevant snippets from knowledge sources based on a query."
    def run(self, query: str) -> str:
        # Placeholder: in real use, fetch from local files or vector DB
        messages = [{"role": "system", "content": self.SYSTEM},
                    {"role": "user", "content": f"Retrieve key facts for: {query}"}]
        return chat(messages)

class ReasoningAgent:
    SYSTEM = "You analyze inputs step by step and produce structured conclusions."
    def run(self, context: str, question: str) -> str:
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Context:\n{context}\n\nQuestion: {question}\nThink step-by-step and produce a concise answer."}
        ]
        return chat(messages)

class ExecutionAgent:
    SYSTEM = "You transform decisions into actionable steps (JSON with actions)."
    def run(self, decision: str) -> str:
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Turn this decision into 3 executable steps as JSON:\n{decision}"}
        ]
        return chat(messages)
```
  
Bước 2) Xây dựng bộ điều phối  
```python
# agents/coordinator.py
from agents.specialists import RetrievalAgent, ReasoningAgent, ExecutionAgent

class Coordinator:
    def __init__(self):
        self.retrieval = RetrievalAgent()
        self.reasoning = ReasoningAgent()
        self.execution = ExecutionAgent()

    def handle(self, user_goal: str) -> dict:
        # 1. Retrieve context
        context = self.retrieval.run(user_goal)
        # 2. Reason on context
        decision = self.reasoning.run(context, user_goal)
        # 3. Produce actionable steps
        actions = self.execution.run(decision)
        return {
            "goal": user_goal,
            "context": context,
            "decision": decision,
            "actions": actions
        }

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    coord = Coordinator()
    result = coord.handle("Create a plan to onboard 5 new customers this month")
    print(result)
```
  
Bước 3) Xác thực với Foundry Local  
```powershell
REM Confirm the local endpoint and model are available
foundry model list
foundry model run phi-4-mini
curl http://localhost:8000/v1/models

REM Run the coordinator
python -m samples.05.agents.coordinator
```
  

Hướng dẫn:
- Triển khai cơ chế thử lại và giới hạn thời gian giữa các tác nhân
- Thêm một bộ nhớ nhỏ trong RAM (dict) để lưu trạng thái cuộc trò chuyện/chủ đề
- Giới hạn tốc độ khi liên kết nhiều cuộc gọi

## Phần 4: Khả năng quan sát và an toàn

Theo dõi lời nhắc, phản hồi và lỗi cục bộ, đồng thời đảm bảo vệ sinh dữ liệu trong ngăn xếp tác nhân của bạn.

Bước 1) Ghi nhật ký yêu cầu nhẹ (tùy chọn)

Lưu ý: Trình trợ giúp sau đây không được bao gồm theo mặc định. Tạo `infra/obs.py` nếu bạn muốn ghi nhật ký JSON cục bộ cho các thử nghiệm.  
```python
# infra/obs.py
import time, json, os
from datetime import datetime

LOG_DIR = os.getenv("FOUNDRY_AGENT_LOG_DIR", "./agent_logs")
os.makedirs(LOG_DIR, exist_ok=True)

def log_event(kind: str, payload: dict):
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    path = os.path.join(LOG_DIR, f"{ts}_{kind}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
```
  

Tích hợp ghi nhật ký vào các tác nhân (tùy chọn):  
```python
# in agents/specialists.py after receiving content
from infra.obs import log_event
# ... inside chat(...)
resp = r.json()
log_event("chat_request", {"endpoint": f"{BASE_URL}/v1/chat/completions"})
log_event("chat_response", resp)
return resp["choices"][0]["message"]["content"]
```
  

Bước 2) Xác thực tính khả dụng và sức khỏe cơ bản qua CLI  
```powershell
REM Ensure Foundry Local is running a model
foundry model list
foundry model run phi-4-mini

REM Validate the OpenAI-compatible endpoint
curl http://localhost:8000/v1/models
```
  

Bước 3) Xóa thông tin nhạy cảm và vệ sinh PII  
- Trước khi gửi tin nhắn đến mô hình, hãy xóa hoặc mã hóa các trường nhạy cảm (email, số điện thoại, ID)  
- Giữ dữ liệu nguồn thô trên thiết bị, chỉ gửi các chuỗi ngữ cảnh cần thiết  

Trình trợ giúp xóa ví dụ:  
```python
# infra/redact.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  

Sử dụng trong các tác nhân:  
```python
from infra.redact import sanitize
# user_goal = sanitize(user_goal)
# context = sanitize(context)
```
  

Bước 4) Cơ chế ngắt mạch và xử lý lỗi  
- Bao bọc mỗi cuộc gọi tác nhân bằng try/except và cơ chế lùi dần  
- Ngắt mạch quy trình khi gặp lỗi lặp lại  

```python
import time

def with_retry(func, retries=3, base_delay=0.5):
    for i in range(retries):
        try:
            return func()
        except Exception as e:
            if i == retries - 1:
                raise
            time.sleep(base_delay * (2 ** i))
```
  

Bước 5) Dấu vết kiểm toán cục bộ và xuất dữ liệu  
- Lưu nhật ký JSON dưới `./agent_logs`  
- Định kỳ nén và xoay vòng nhật ký  
- Xuất các bản tóm tắt để xem xét (số lượng, độ trễ trung bình, tỷ lệ lỗi)  

Bước 6) Kiểm tra chéo với tài liệu Microsoft Learn  
- Foundry Local cung cấp API tương thích với OpenAI (được xác thực với `curl /v1/models`)  
- Sử dụng `foundry model run <name>` để xác nhận tính khả dụng của mô hình  
- Tuân theo hướng dẫn chính thức để tích hợp khách hàng và ứng dụng mẫu (Open WebUI/how-tos)  

Tham khảo:
- Foundry Local (Learn): https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Hướng dẫn Open WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
- Mẫu gọi hàm: https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling

## Bước tiếp theo
- Khám phá Azure AI Agents để điều phối trên đám mây
- Thêm các kết nối doanh nghiệp (Microsoft Graph, Tìm kiếm, cơ sở dữ liệu)

---

