<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-22T21:51:06+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "vi"
}
-->
# Buổi 1: Bắt đầu với Foundry Local

## Tổng quan

Microsoft Foundry Local mang các khả năng của Azure AI Foundry trực tiếp đến môi trường phát triển Windows 11 của bạn, cho phép phát triển AI bảo vệ quyền riêng tư, độ trễ thấp với các công cụ cấp doanh nghiệp. Buổi học này bao gồm toàn bộ quá trình cài đặt, cấu hình và triển khai thực hành các mô hình phổ biến như phi, qwen, deepseek và GPT-OSS-20B.

## Mục tiêu học tập

Sau khi hoàn thành buổi học này, bạn sẽ:
- Cài đặt và cấu hình Foundry Local trên Windows 11
- Thành thạo các lệnh CLI và tùy chọn cấu hình
- Hiểu chiến lược lưu trữ mô hình để đạt hiệu suất tối ưu
- Chạy thành công các mô hình phi, qwen, deepseek và GPT-OSS-20B
- Tạo ứng dụng AI đầu tiên của bạn bằng Foundry Local

## Yêu cầu trước

### Yêu cầu hệ thống
- **Windows 11**: Phiên bản 22H2 hoặc mới hơn
- **RAM**: Tối thiểu 16GB, khuyến nghị 32GB
- **Dung lượng lưu trữ**: 50GB trống cho mô hình và bộ nhớ đệm
- **Phần cứng**: Thiết bị hỗ trợ NPU hoặc GPU được ưu tiên (PC Copilot+ hoặc GPU NVIDIA)
- **Mạng**: Internet tốc độ cao để tải xuống mô hình

### Môi trường phát triển
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## Phần 1: Cài đặt và thiết lập

### Bước 1: Cài đặt Foundry Local

Cài đặt Foundry Local bằng Winget hoặc tải trình cài đặt từ GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Bước 2: Xác minh cài đặt

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## Phần 2: Hiểu về CLI

### Cấu trúc lệnh cốt lõi

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## Phần 3: Quản lý và lưu trữ mô hình

Foundry Local triển khai lưu trữ mô hình thông minh để tối ưu hóa hiệu suất và dung lượng:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## Phần 4: Triển khai mô hình thực hành

### Chạy các mô hình Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Làm việc với các mô hình Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### Chạy các mô hình DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### Chạy GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## Phần 5: Tạo ứng dụng đầu tiên của bạn

### Giao diện trò chuyện đơn giản (API tương thích OpenAI)

Tạo một ứng dụng trò chuyện cơ bản sử dụng REST API tương thích OpenAI của Foundry Local. Đảm bảo một mô hình đang chạy trong một terminal khác.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### Chạy ứng dụng trò chuyện

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## Phần 6: Khắc phục sự cố và thực hành tốt nhất

### Các vấn đề thường gặp và giải pháp

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### Giám sát tài nguyên hệ thống (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### Thực hành tốt nhất

- Ưu tiên các lệnh `foundry model ...`, `foundry cache ...`, và `foundry service ...` (xem tham khảo CLI)
- Nâng cấp thường xuyên để truy cập các mô hình và bản sửa lỗi mới
- Bắt đầu với các mô hình nhỏ hơn (Phi mini, Qwen 7B) và mở rộng dần
- Giám sát CPU/GPU/bộ nhớ khi điều chỉnh prompt và cài đặt

## Phần 7: Bài tập thực hành

### Bài tập 1: Chạy nhanh nhiều mô hình

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Bài tập 2: Đánh giá độ trễ cơ bản

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## Tài liệu tham khảo

- Bắt đầu với Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- Tham khảo CLI và tổng quan lệnh: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- Biên dịch các mô hình Hugging Face cho Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local GitHub: https://github.com/microsoft/Foundry-Local

---

