<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-09-18T12:33:21+00:00",
  "source_file": "Module01/README.md",
  "language_code": "vi"
}
-->
# Chương 01: Chuyển đổi Triển khai AI cho Edge

EdgeAI đại diện cho một sự thay đổi mang tính cách mạng trong triển khai trí tuệ nhân tạo, chuyển đổi khả năng AI từ xử lý dựa trên đám mây sang các thiết bị cục bộ tại biên. Chương này khám phá các khái niệm cơ bản, công nghệ chủ chốt, và các ứng dụng thực tiễn định hình cách tiếp cận đổi mới này trong triển khai AI.

## Cấu trúc Module

### [Phần 1: Các nguyên lý cơ bản của EdgeAI](./01.EdgeAIFundamentals.md)
Phần này xây dựng nền tảng bằng cách so sánh mô hình AI dựa trên đám mây truyền thống với mô hình triển khai AI tại biên. Chúng ta sẽ tìm hiểu các công nghệ quan trọng như lượng tử hóa mô hình, tối ưu hóa nén, và các Mô hình Ngôn ngữ Nhỏ (SLMs) giúp vượt qua các hạn chế về tính toán của thiết bị biên. Nội dung nhấn mạnh cách những đổi mới này mang lại khả năng bảo vệ quyền riêng tư tốt hơn, độ trễ cực thấp, và khả năng xử lý ngoại tuyến mạnh mẽ.

### [Phần 2: Các nghiên cứu điển hình thực tế](./02.RealWorldCaseStudies.md)
Thông qua các ví dụ cụ thể như hệ sinh thái mô hình Phi và Mu của Microsoft và hệ thống báo cáo AI của Japan Airlines, phần này minh họa các triển khai EdgeAI thành công trong nhiều ngành công nghiệp khác nhau. Các nghiên cứu điển hình này chứng minh hiệu suất vượt trội của SLMs trong các nhiệm vụ chuyên biệt và làm rõ những lợi ích thực tiễn của chiến lược triển khai tại biên.

### [Phần 3: Hướng dẫn triển khai thực tiễn](./03.PracticalImplementationGuide.md)
Phần này cung cấp hướng dẫn chuẩn bị môi trường toàn diện cho việc học thực hành, bao gồm các công cụ phát triển cần thiết, yêu cầu phần cứng, tài nguyên mô hình cốt lõi, và các khung tối ưu hóa. Nội dung thiết lập nền tảng kỹ thuật cần thiết để người học có thể xây dựng và triển khai các giải pháp EdgeAI của riêng mình.

### [Phần 4: Các nền tảng phần cứng triển khai Edge AI](./04.EdgeDeployment.md)
Phần này khám phá hệ sinh thái phần cứng hỗ trợ triển khai AI tại biên, bao gồm các nền tảng từ Intel, Qualcomm, NVIDIA, và Windows AI PCs. Nội dung cung cấp các so sánh chi tiết về khả năng phần cứng, các kỹ thuật tối ưu hóa đặc thù của từng nền tảng, và các cân nhắc triển khai thực tiễn trong các kịch bản tính toán tại biên khác nhau.

## Kết quả học tập chính

Sau khi hoàn thành chương này, người đọc sẽ hiểu:
- Sự khác biệt cơ bản giữa kiến trúc AI đám mây và AI tại biên
- Các kỹ thuật tối ưu hóa cốt lõi cho triển khai tại biên
- Các ứng dụng thực tế và câu chuyện thành công
- Kỹ năng thực tiễn để triển khai các giải pháp EdgeAI
- Cách lựa chọn nền tảng phần cứng và các phương pháp tối ưu hóa đặc thù của từng nền tảng
- Đánh giá hiệu suất và các phương pháp triển khai tốt nhất

## Hàm ý tương lai

EdgeAI nổi lên như một xu hướng quan trọng định hình tương lai của triển khai AI, mở đường cho các hệ thống AI phân tán, hiệu quả, và bảo vệ quyền riêng tư, có khả năng hoạt động độc lập với kết nối đám mây trong khi vẫn duy trì các tiêu chuẩn hiệu suất cao.

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.