<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a887b7e85782dadd3fd1216cd63b6c23",
  "translation_date": "2025-10-09T16:57:20+00:00",
  "source_file": "Workshop/QUICK_REFERENCE.md",
  "language_code": "vi"
}
-->
# Th·∫ª Tham Kh·∫£o Nhanh - M·∫´u Workshop

**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi**: Ng√†y 8 th√°ng 10 nƒÉm 2025

---

## üöÄ B·∫Øt ƒë·∫ßu nhanh

```bash
# 1. Ensure Foundry Local is running
foundry service status
foundry model run phi-4-mini

# 2. Install dependencies
pip install -r Workshop/requirements.txt

# 3. Run a sample
cd Workshop/samples/session01
python chat_bootstrap.py "What is edge AI?"
```

---

## üìÇ T·ªïng quan v·ªÅ m·∫´u

| Phi√™n | M·∫´u | M·ª•c ƒë√≠ch | Th·ªùi gian |
|-------|------|----------|-----------|
| 01 | `chat_bootstrap.py` | Chat c∆° b·∫£n + streaming | ~30s |
| 02 | `rag_pipeline.py` | RAG v·ªõi embeddings | ~45s |
| 02 | `rag_eval_ragas.py` | ƒê√°nh gi√° RAG | ~60s |
| 03 | `benchmark_oss_models.py` | ƒê√°nh gi√° hi·ªáu nƒÉng m√¥ h√¨nh | ~2m |
| 04 | `model_compare.py` | SLM vs LLM | ~45s |
| 05 | `agents_orchestrator.py` | H·ªá th·ªëng ƒëa t√°c nh√¢n | ~60s |
| 06 | `models_router.py` | ƒê·ªãnh tuy·∫øn √Ω ƒë·ªãnh | ~45s |
| 06 | `models_pipeline.py` | Quy tr√¨nh nhi·ªÅu b∆∞·ªõc | ~60s |

---

## üõ†Ô∏è Bi·∫øn m√¥i tr∆∞·ªùng

### C·∫ßn thi·∫øt
```bash
# Choose model
set FOUNDRY_LOCAL_ALIAS=phi-4-mini

# Override endpoint (optional)
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Show token usage
set SHOW_USAGE=1
```

### Theo phi√™n
```bash
# Session 02: RAG
set RAG_QUESTION="What is local inference?"
set EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Session 03: Benchmarking
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
set BENCH_STREAM=1

# Session 04: Comparison
set SLM_ALIAS=phi-4-mini
set LLM_ALIAS=qwen2.5-7b

# Session 05: Agents
set AGENT_MODEL_PRIMARY=phi-4-mini
set AGENT_QUESTION="Why use edge AI?"

# Session 06: Pipeline
set PIPELINE_TASK="Your task here"
```

---

## ‚úÖ X√°c th·ª±c & Ki·ªÉm tra

```bash
# Validate syntax and imports
python scripts/validate_samples.py

# Validate specific session
python scripts/validate_samples.py --session 01

# Run smoke tests
python scripts/test_samples.py --quick

# Verbose testing
python scripts/test_samples.py --verbose
```

---

## üêõ X·ª≠ l√Ω s·ª± c·ªë

### L·ªói k·∫øt n·ªëi
```bash
# Check Foundry Local
foundry service status

# Start if needed
foundry service start
foundry model run phi-4-mini
```

### L·ªói nh·∫≠p kh·∫©u
```bash
# Install missing dependencies
pip install sentence-transformers ragas datasets

# Or install all
pip install -r Workshop/requirements.txt
```

### Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh
```bash
# List available models
foundry model ls

# Download model
foundry model download phi-4-mini
```

### Hi·ªáu nƒÉng ch·∫≠m
```bash
# Use smaller model
set FOUNDRY_LOCAL_ALIAS=qwen2.5-0.5b

# Reduce benchmark rounds
set BENCH_ROUNDS=1
```

---

## üìñ M·∫´u ph·ªï bi·∫øn

### Chat c∆° b·∫£n
```python
from workshop_utils import chat_once

text, usage = chat_once(
    'phi-4-mini',
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100,
    temperature=0.7
)
```

### L·∫•y Client
```python
from workshop_utils import get_client

manager, client, model_id = get_client(
    alias='phi-4-mini',
    endpoint=None  # Auto-detect
)
```

### X·ª≠ l√Ω l·ªói
```python
try:
    manager, client, model_id = get_client(alias)
except Exception as e:
    print(f"[ERROR] Failed: {e}")
    print("[INFO] Check: foundry service status")
    sys.exit(1)
```

### Streaming
```python
stream = client.chat.completions.create(
    model=model_id,
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

---

## üìä L·ª±a ch·ªçn m√¥ h√¨nh

| M√¥ h√¨nh | K√≠ch th∆∞·ªõc | T·ªët nh·∫•t cho | T·ªëc ƒë·ªô |
|---------|------------|--------------|--------|
| `qwen2.5-0.5b` | 0.5B | Ph√¢n lo·∫°i nhanh | ‚ö°‚ö°‚ö° |
| `qwen2.5-coder-0.5b` | 0.5B | Sinh m√£ nhanh | ‚ö°‚ö°‚ö° |
| `gemma-2-2b` | 2B | Vi·∫øt s√°ng t·∫°o | ‚ö°‚ö° |
| `phi-3.5-mini` | 3.5B | M√£, t√°i c·∫•u tr√∫c | ‚ö°‚ö° |
| `phi-4-mini` | 4B | T·ªïng qu√°t, t√≥m t·∫Øt | ‚ö°‚ö° |
| `qwen2.5-7b` | 7B | L√Ω lu·∫≠n ph·ª©c t·∫°p | ‚ö° |

---

## üîó T√†i nguy√™n

- **T√†i li·ªáu SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **Tham kh·∫£o nhanh**: `Workshop/FOUNDRY_SDK_QUICKREF.md`
- **T√≥m t·∫Øt c·∫≠p nh·∫≠t**: `Workshop/SAMPLES_UPDATE_SUMMARY.md`
- **Ghi ch√∫ di chuy·ªÉn**: `Workshop/SDK_MIGRATION_NOTES.md`

---

## üí° M·∫πo

1. **B·ªô nh·ªõ ƒë·ªám client**: `workshop_utils` t·ª± ƒë·ªông l∆∞u tr·ªØ cho b·∫°n
2. **S·ª≠ d·ª•ng m√¥ h√¨nh nh·ªè h∆°n**: B·∫Øt ƒë·∫ßu v·ªõi `qwen2.5-0.5b` ƒë·ªÉ th·ª≠ nghi·ªám
3. **B·∫≠t th·ªëng k√™ s·ª≠ d·ª•ng**: ƒê·∫∑t `SHOW_USAGE=1` ƒë·ªÉ theo d√µi token
4. **X·ª≠ l√Ω theo l√¥**: X·ª≠ l√Ω nhi·ªÅu prompt tu·∫ßn t·ª±
5. **Gi·∫£m max_tokens**: Gi·∫£m ƒë·ªô tr·ªÖ cho ph·∫£n h·ªìi nhanh

---

## üéØ Quy tr√¨nh m·∫´u

### Ki·ªÉm tra m·ªçi th·ª©
```bash
python scripts/validate_samples.py
python scripts/test_samples.py --quick
```

### ƒê√°nh gi√° m√¥ h√¨nh
```bash
cd samples/session03
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b,gemma-2-2b
set BENCH_ROUNDS=3
python benchmark_oss_models.py
```

### Quy tr√¨nh RAG
```bash
cd samples/session02
set RAG_QUESTION="What is RAG?"
python rag_pipeline.py
```

### H·ªá th·ªëng ƒëa t√°c nh√¢n
```bash
cd samples/session05
set AGENT_QUESTION="Why edge AI for healthcare?"
python agents_orchestrator.py
```

---

**Tr·ª£ gi√∫p nhanh**: Ch·∫°y b·∫•t k·ª≥ m·∫´u n√†o v·ªõi `--help` ho·∫∑c ki·ªÉm tra docstring:
```bash
python chat_bootstrap.py --help
# or
python -c "import chat_bootstrap; help(chat_bootstrap)"
```

---

**T·∫•t c·∫£ c√°c m·∫´u ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t v√†o th√°ng 10 nƒÉm 2025 v·ªõi c√°c th·ª±c ti·ªÖn t·ªët nh·∫•t c·ªßa Foundry Local SDK** ‚ú®

---

**Tuy√™n b·ªë mi·ªÖn tr·ª´ tr√°ch nhi·ªám**:  
T√†i li·ªáu n√†y ƒë√£ ƒë∆∞·ª£c d·ªãch b·∫±ng d·ªãch v·ª• d·ªãch thu·∫≠t AI [Co-op Translator](https://github.com/Azure/co-op-translator). M·∫∑c d√π ch√∫ng t√¥i c·ªë g·∫Øng ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c, xin l∆∞u √Ω r·∫±ng c√°c b·∫£n d·ªãch t·ª± ƒë·ªông c√≥ th·ªÉ ch·ª©a l·ªói ho·∫∑c kh√¥ng ch√≠nh x√°c. T√†i li·ªáu g·ªëc b·∫±ng ng√¥n ng·ªØ b·∫£n ƒë·ªãa n√™n ƒë∆∞·ª£c coi l√† ngu·ªìn th√¥ng tin ch√≠nh th·ª©c. ƒê·ªëi v·ªõi c√°c th√¥ng tin quan tr·ªçng, khuy·∫øn ngh·ªã s·ª≠ d·ª•ng d·ªãch v·ª• d·ªãch thu·∫≠t chuy√™n nghi·ªáp b·ªüi con ng∆∞·ªùi. Ch√∫ng t√¥i kh√¥ng ch·ªãu tr√°ch nhi·ªám cho b·∫•t k·ª≥ s·ª± hi·ªÉu l·∫ßm ho·∫∑c di·ªÖn gi·∫£i sai n√†o ph√°t sinh t·ª´ vi·ªác s·ª≠ d·ª•ng b·∫£n d·ªãch n√†y.