<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T12:09:29+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "vi"
}
-->
# Phần 1: Kiến thức cơ bản về dòng mô hình Microsoft Phi

Dòng mô hình Microsoft Phi đại diện cho một sự thay đổi lớn trong trí tuệ nhân tạo, chứng minh rằng các mô hình nhỏ gọn, hiệu quả có thể đạt được hiệu suất đáng kinh ngạc trong khi sử dụng tài nguyên ít hơn đáng kể so với các mô hình ngôn ngữ lớn truyền thống. Điều quan trọng là phải hiểu cách dòng Phi cung cấp khả năng AI mạnh mẽ với yêu cầu tính toán giảm mà vẫn duy trì hiệu suất cao trên nhiều nhiệm vụ khác nhau.

## Tài nguyên dành cho nhà phát triển

### Danh mục mô hình Azure AI Foundry
Dòng mô hình Phi (ngoại trừ Phi-silica) có sẵn thông qua [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), giúp các nhà phát triển dễ dàng truy cập, tinh chỉnh và triển khai các mô hình này trong ứng dụng của họ. Danh mục cung cấp một cách đơn giản để thử nghiệm các biến thể Phi khác nhau và tích hợp chúng vào dự án của bạn.

### Azure AI Foundry
Bạn có thể triển khai và thử nghiệm các mô hình Phi bằng [Azure AI Foundry](https://ai.azure.com), nơi cung cấp một môi trường toàn diện để xây dựng, kiểm tra và triển khai các giải pháp AI với thiết lập tối thiểu.

### Foundry Local
Đối với phát triển và triển khai tại chỗ, hãy xem [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), cho phép bạn chạy các mô hình Phi trên máy phát triển của mình với cấu hình tối ưu.

### Tài liệu tham khảo
- [Microsoft Research: Báo cáo kỹ thuật về mô hình Phi](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Giới thiệu

Trong bài học này, chúng ta sẽ khám phá dòng mô hình Phi của Microsoft và các khái niệm cơ bản của nó. Chúng ta sẽ tìm hiểu về sự phát triển của dòng Phi, các phương pháp đào tạo sáng tạo giúp mô hình Phi trở nên hiệu quả, các biến thể chính trong dòng này, và các ứng dụng thực tế trong các tình huống khác nhau.

## Mục tiêu học tập

Kết thúc bài học này, bạn sẽ có thể:

- Hiểu triết lý thiết kế và sự phát triển của dòng mô hình Phi của Microsoft.
- Xác định các đổi mới chính giúp mô hình Phi đạt được hiệu suất cao với ít tham số hơn.
- Nhận biết lợi ích và hạn chế của các biến thể mô hình Phi khác nhau.
- Áp dụng kiến thức về mô hình Phi để chọn các biến thể phù hợp cho các tình huống thực tế.

## Hiểu về mô hình AI truyền thống

Truyền thống, để đạt được hiệu suất cao trong xử lý ngôn ngữ tự nhiên, cần các mô hình ngôn ngữ lớn với hàng tỷ hoặc hàng trăm tỷ tham số. Các tổ chức thường triển khai các mô hình này trên các cụm GPU mạnh mẽ, truy cập khả năng của chúng thông qua giao diện API hoặc cơ sở hạ tầng phần cứng chuyên dụng.

Cách tiếp cận này hoạt động tốt cho nhiều ứng dụng nhưng có những hạn chế vốn có khi triển khai thực tế. Phương pháp truyền thống liên quan đến việc sử dụng các mô hình yêu cầu tài nguyên tính toán lớn, lượng bộ nhớ lớn và tiêu thụ năng lượng đáng kể. Mặc dù cách tiếp cận này cung cấp khả năng tiên tiến, nó tạo ra sự phụ thuộc vào phần cứng đắt tiền, dẫn đến chi phí vận hành cao và hạn chế tính linh hoạt trong triển khai.

## Thách thức của triển khai AI hiệu quả

Nhu cầu về AI hiệu quả hơn ngày càng trở nên quan trọng trong nhiều tình huống. Hãy xem xét các ứng dụng yêu cầu triển khai tại chỗ vì lý do bảo mật, các triển khai nhạy cảm về chi phí nơi chi phí API đám mây trở nên cấm kỵ, các tình huống tính toán biên với tài nguyên phần cứng hạn chế, hoặc các ứng dụng thời gian thực nơi độ trễ là yếu tố quan trọng.

### Các hạn chế chính trong triển khai

Việc triển khai mô hình lớn truyền thống gặp phải một số hạn chế cơ bản làm giảm tính khả thi thực tế:

- **Hạn chế về chi phí**: Chi phí tính toán cao khiến việc triển khai liên tục trở nên đắt đỏ đối với nhiều tổ chức.
- **Hạn chế về tài nguyên**: Việc tiếp cận hạn chế với cơ sở hạ tầng GPU cao cấp làm giảm các tùy chọn triển khai.
- **Yêu cầu về bảo mật**: Các ứng dụng nhạy cảm yêu cầu xử lý tại chỗ để duy trì bảo mật dữ liệu.
- **Độ nhạy về độ trễ**: Các ứng dụng thời gian thực cần phản hồi ngay lập tức mà không có độ trễ vòng lặp đám mây.

## Triết lý mô hình Microsoft Phi

Dòng mô hình Microsoft Phi đại diện cho một sự thay đổi cơ bản trong triết lý thiết kế mô hình AI, ưu tiên hiệu quả và triển khai thực tế trong khi vẫn duy trì các đặc điểm hiệu suất mạnh mẽ. Các mô hình Phi đạt được điều này thông qua các kiến trúc sáng tạo, phương pháp đào tạo chất lượng cao, và các kỹ thuật tối ưu hóa chuyên biệt.

Dòng Phi bao gồm nhiều cách tiếp cận được thiết kế để tối đa hóa hiệu suất trên mỗi tham số, cho phép triển khai trên phần cứng tiêu chuẩn trong khi cung cấp các khả năng AI có ý nghĩa. Mục tiêu là duy trì hiệu suất cạnh tranh trong khi giảm đáng kể yêu cầu tính toán, sử dụng bộ nhớ và chi phí vận hành.

### Nguyên tắc thiết kế cốt lõi của Phi

Các mô hình Phi được xây dựng dựa trên một số nguyên tắc cơ bản phân biệt chúng với các mô hình ngôn ngữ lớn truyền thống:

- **Hiệu quả là ưu tiên hàng đầu**: Tối ưu hóa để đạt hiệu suất tối đa trên mỗi tham số thay vì quy mô tuyệt đối.
- **Đào tạo chất lượng**: Tập trung vào dữ liệu đào tạo chất lượng cao, được chọn lọc thay vì các tập dữ liệu khổng lồ.
- **Tính linh hoạt trong triển khai**: Được thiết kế để chạy hiệu quả trên nhiều cấu hình phần cứng khác nhau.
- **Khả năng chuyên biệt**: Thường được tối ưu hóa cho các nhiệm vụ hoặc lĩnh vực cụ thể để tối đa hóa hiệu quả.

## Các công nghệ chính hỗ trợ dòng Phi

### Phương pháp đào tạo "Textbook"

Một trong những khía cạnh cách mạng nhất của dòng Phi là phương pháp đào tạo "chất lượng sách giáo khoa". Thay vì đào tạo trên lượng lớn dữ liệu internet không được lọc, các mô hình Phi sử dụng nội dung giáo dục được chọn lọc kỹ lưỡng, chất lượng cao, được thiết kế để dạy lý luận, toán học, lập trình, và kiến thức tổng quát một cách hiệu quả.

Phương pháp này hoạt động bằng cách tạo nội dung giáo dục tổng hợp mô phỏng các sách giáo khoa và tài liệu học thuật chất lượng cao. Dữ liệu đào tạo được thiết kế đặc biệt để có tính sư phạm, tập trung vào các giải thích rõ ràng, lý luận từng bước, và trình bày kiến thức có cấu trúc.

### Đào tạo lý luận nâng cao

Các mô hình Phi gần đây tích hợp các phương pháp đào tạo lý luận tinh vi cho phép giải quyết các vấn đề phức tạp nhiều bước. Các kỹ thuật này bao gồm:

**Đào tạo chuỗi lý luận**: Các mô hình học cách phân tích các vấn đề phức tạp thành các bước lý luận trung gian, làm cho quá trình giải quyết vấn đề của chúng trở nên minh bạch và đáng tin cậy.

**Mở rộng quy mô tại thời điểm suy luận**: Các mô hình tạo ra các chuỗi lý luận chi tiết tận dụng tài nguyên tính toán bổ sung trong quá trình tạo phản hồi để cải thiện độ chính xác.

**Đào tạo tại giới hạn khả năng**: Dữ liệu đào tạo được chọn đặc biệt để thách thức mô hình tại giới hạn khả năng hiện tại của nó, thúc đẩy học các mẫu lý luận phức tạp.

### Đổi mới kiến trúc

Dòng Phi tích hợp một số tối ưu hóa kiến trúc được thiết kế đặc biệt cho hiệu quả:

**Hiệu quả tham số**: Các lựa chọn kiến trúc cẩn thận để tối đa hóa tác động của mỗi tham số trong mô hình.

**Tích hợp đa phương thức**: Tích hợp hiệu quả khả năng xử lý văn bản, hình ảnh, và giọng nói trong các kiến trúc nhỏ gọn.

**Tối ưu hóa phần cứng**: Các biến thể chuyên biệt được tối ưu hóa cho các nền tảng phần cứng cụ thể và các tình huống triển khai.

## Tối ưu hóa phần cứng cho các mô hình Phi

Các môi trường triển khai hiện đại hưởng lợi từ hiệu quả của các mô hình Phi trên nhiều cấu hình phần cứng:

### Triển khai tối ưu hóa CPU

Các mô hình Phi được thiết kế để chạy hiệu quả trên phần cứng chỉ sử dụng CPU, giúp chúng dễ dàng triển khai trên cơ sở hạ tầng máy tính tiêu chuẩn mà không cần các bộ tăng tốc AI chuyên dụng.

### Tăng tốc GPU

Mặc dù không yêu cầu GPU mạnh mẽ, các mô hình Phi có thể tận dụng tài nguyên GPU sẵn có để cải thiện hiệu suất, cung cấp tính linh hoạt trong cấu hình triển khai.

### Tích hợp thiết bị biên

Các biến thể chuyên biệt như Phi-3-Silica được tối ưu hóa cho các nền tảng tính toán biên cụ thể, đạt được các chỉ số hiệu quả đáng kể như 650 token mỗi giây với chỉ 1.5W tiêu thụ năng lượng.

## Lợi ích của dòng mô hình Phi

### Hiệu quả chi phí

Các mô hình Phi giảm đáng kể chi phí vận hành bằng cách yêu cầu cơ sở hạ tầng tính toán ít hơn trong khi vẫn duy trì hiệu suất cạnh tranh. Điều này làm cho AI trở nên dễ tiếp cận hơn đối với các tổ chức có ngân sách hạn chế hoặc các ứng dụng có khối lượng lớn nơi chi phí cho mỗi lần suy luận là yếu tố quan trọng.

### Tính linh hoạt trong triển khai

Hiệu quả của các mô hình Phi cho phép triển khai trên nhiều cấu hình phần cứng, từ máy tính cá nhân đến máy chủ doanh nghiệp, cung cấp cho các tổ chức sự linh hoạt hơn trong lựa chọn cơ sở hạ tầng AI.

### Bảo mật và quyền riêng tư

Hiệu quả của các mô hình Phi cho phép triển khai tại chỗ cho các ứng dụng nhạy cảm về quyền riêng tư, đảm bảo rằng dữ liệu nhạy cảm không bao giờ rời khỏi sự kiểm soát của tổ chức trong khi vẫn cung cấp các khả năng AI mạnh mẽ.

### Hiệu suất thời gian thực

Yêu cầu tính toán giảm dẫn đến thời gian suy luận nhanh hơn, cho phép các ứng dụng thời gian thực cần phản hồi ngay lập tức mà không làm giảm chất lượng khả năng AI.

### AI dễ tiếp cận

Bằng cách giảm các rào cản triển khai AI, các mô hình Phi làm cho các khả năng AI tiên tiến trở nên dễ tiếp cận hơn đối với các tổ chức có nguồn lực hạn chế, cho phép các nhóm nhỏ và các nhà phát triển cá nhân tận dụng khả năng hiểu ngôn ngữ tinh vi.

## Ví dụ thực tế và các trường hợp sử dụng

Trước khi đi sâu vào sự phát triển kỹ thuật, hãy khám phá một số ví dụ cụ thể về những gì các mô hình Phi có thể làm:

### Ví dụ về lý luận toán học

Phi-4-mini-reasoning xuất sắc trong việc giải quyết các vấn đề toán học từng bước. Ví dụ, khi được hỏi "Làm thế nào để giải phương trình 3*x^2+4*x+5=1?", mô hình cung cấp các bước lý luận chi tiết:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### Ví dụ về hỗ trợ đa ngôn ngữ

Phi-3.5-mini-instruct thể hiện khả năng đa ngôn ngữ mạnh mẽ trên nhiều ngôn ngữ. Đây là một ví dụ về định dạng lời nhắc:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Ví dụ về khả năng đa phương thức

Phi-4-multimodal có thể xử lý văn bản, hình ảnh, và giọng nói đồng thời. Dưới đây là một số ứng dụng thực tế:

**Lập kế hoạch du lịch với đầu vào âm thanh:**
Xem Phi-4 Multimodal phân tích ngôn ngữ nói để giúp lập kế hoạch chuyến đi đến Seattle, thể hiện khả năng xử lý âm thanh và đưa ra gợi ý tiên tiến.

**Giải quyết vấn đề toán học từ hình ảnh:**
Xem cách Phi-4 Multimodal giải quyết các vấn đề toán học phức tạp thông qua đầu vào hình ảnh, thể hiện khả năng xử lý và giải quyết các phương trình được trình bày trong hình ảnh.

**Ví dụ về gọi hàm:**
Với khả năng gọi hàm, Phi-4-mini và Phi-4-multimodal có thể mở rộng khả năng xử lý văn bản của mình bằng cách tích hợp các công cụ tìm kiếm, kết nối các công cụ khác nhau, và hơn thế nữa. Như minh họa, mô hình có thể truy xuất thông tin trận đấu Premier League thông qua Phi-4-mini, thể hiện khả năng tương tác liền mạch với các nguồn dữ liệu bên ngoài.

### Ví dụ về tạo mã

Phi-4-multimodal có thể tạo mã dự án có cấu trúc dựa trên cả nội dung hình ảnh và lời nhắc được cung cấp, như được minh họa trong quy trình làm việc thực tế này:

1. Tải lên hình ảnh của một wireframe hoặc thiết kế
2. Cung cấp ngữ cảnh về yêu cầu dự án
3. Mô hình tạo cấu trúc mã hoàn chỉnh, chức năng
4. Mã có thể được tùy chỉnh dựa trên các framework hoặc ngôn ngữ cụ thể

### Ví dụ về triển khai trên thiết bị biên

Chúng ta có thể triển khai mô hình được lượng hóa trên các thiết bị biên. Bằng cách kết hợp Microsoft Olive và ONNX GenAI Runtime, chúng ta có thể triển khai Phi-4-mini trên Windows, iPhone, Android và các thiết bị khác. Đây là một ví dụ chạy trên iPhone 12 Pro.

Quy trình triển khai bao gồm:
- Lượng hóa mô hình để tối ưu hóa cho di động
- Tích hợp runtime ONNX để tương thích đa nền tảng
- Suy luận tại chỗ mà không cần kết nối internet
- Hiệu suất thời gian thực với mức tiêu thụ năng lượng tối thiểu

## Sự phát triển của dòng Phi

### Phi-1 và Phi-2: Các mô hình nền tảng

Các mô hình Phi đầu tiên thiết lập các nguyên tắc cơ bản về dữ liệu đào tạo chất lượng cao và kiến trúc hiệu quả:

- **Phi-1 (1.3B tham số)**: Giới thiệu khái niệm về dữ liệu đào tạo được chọn lọc cho hiểu ngôn ngữ cơ bản và tạo mã.
- **Phi-2 (2.7B tham số)**: Nâng cao khả năng lý luận thông qua dữ liệu NLP tổng hợp và nội dung web được lọc cẩn thận.

### Dòng Phi-3: Sự chấp nhận rộng rãi

Dòng Phi-3 đánh dấu một bước đột phá trong khả năng SLM với nhiều biến thể chuyên biệt:

- **Phi-3-mini (3.8B tham số)**: Nhiệm vụ ngôn ngữ tổng quát với hiệu quả đặc biệt, vượt trội hơn các mô hình có kích thước gấp đôi.
- **Phi-3-small (7B tham số)**: Hiệu suất nâng cao vượt qua GPT-3.5 Turbo trên nhiều tiêu chuẩn.
- **Phi-3-medium (14B tham số)**: Hiệu suất cấp doanh nghiệp vượt qua Gemini 1.0 Pro.
- **Phi-3-vision (4.2B tham số)**: Khả năng đa phương thức cho xử lý hình ảnh và văn bản.
- **Phi-3-Silica (3.3B tham số)**: Tối ưu hóa chuyên biệt cho triển khai tích hợp trên Windows 11.

### Dòng Phi-4: Lý luận nâng cao

Thế hệ mới nhất đẩy giới hạn của khả năng lý luận:

- **Phi-4 (14B tham số)**: Chuyên môn hóa lý luận phức tạp, đặc biệt trong toán học.
- **Phi-4-mini (3.8B tham số)**: Lý luận nâng cao với khả năng gọi hàm và hỗ trợ ngữ cảnh dài.
- **Phi-4-multimodal**: Xử lý đồng thời giọng nói, hình ảnh, và văn bản.
- **Phi-4-reasoning (14B tham số)**: Chuyên biệt cho các nhiệm vụ lý luận nhiều bước phức tạp.
- **Phi-4-reasoning-plus (14B tham số)**: Độ chính xác nâng cao thông qua học tăng cường bổ sung.
- **Phi-4-mini-reasoning (3.8B tham số)**: Lý luận toán học được tối ưu hóa cho các môi trường hạn chế.

## Ứng dụng của các mô hình Phi

### Ứng dụng doanh nghiệp

Các tổ chức sử dụng các mô hình Phi để phân tích tài liệu, tự động hóa dịch vụ khách hàng, hỗ trợ tạo mã, và các ứng dụng thông minh kinh doanh yêu cầu triển khai tại chỗ để tuân thủ và bảo mật.

### Tính toán di động và biên

Các ứng dụng di động tận dụng các mô hình Phi để dịch thời gian thực, trợ lý thông minh, tạo nội dung, và gợi ý cá nhân hóa mà không cần kết nối internet liên tục.

### Công nghệ giáo dục

Các nền tảng giáo dục sử dụng các mô hình Phi để dạy kèm cá nhân hóa, chấm điểm tự động, tạo nội dung, và trải nghiệm học tập tương tác có thể hoạt động ngoại tuyến hoặc trong môi trường kết nối thấp.

### Y tế và tuân thủ

Các ứng dụng y tế hưởng lợi từ khả năng xử lý dữ liệu y tế nhạy cảm tại chỗ của các mô hình Phi trong khi cung cấp hỗ trợ chẩn đoán dựa trên AI, giám sát bệnh nhân, và gợi ý điều trị.

## Thách thức và hạn chế

### Hạn chế về kiến thức

Mặc dù hiệu quả, các mô hình Phi có khả năng kiến thức thực tế giảm so với các mô hình lớn hơn, điều này có thể hạn chế hiệu quả của chúng trong các ứng dụng đòi hỏi chuyên môn sâu rộng.

### Hỗ trợ ngôn ngữ

Các mô hình Phi chủ yếu được tối ưu hóa cho tiếng Anh, mặc dù
Gia đình Phi cho thấy rằng tương lai của việc triển khai AI không chỉ nằm ở việc xây dựng các mô hình lớn hơn, mà còn ở việc tạo ra các mô hình thông minh hơn, hiệu quả hơn, có thể hoạt động hiệu quả trên nhiều môi trường phần cứng khác nhau trong khi vẫn duy trì tiêu chuẩn hiệu suất cao.

## Ví dụ về Phát triển và Tích hợp

### Bắt đầu nhanh với Transformers

Dưới đây là cách bắt đầu với các mô hình Phi bằng thư viện Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Ví dụ về Tinh chỉnh

Ví dụ sau đây minh họa cách tinh chỉnh Phi-4-mini-instruct cho các nhiệm vụ cụ thể:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Định dạng Prompt Chuyên biệt

**Cho các nhiệm vụ suy luận (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Cho các nhiệm vụ toán học (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Triển khai trên di động với ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Các Mốc Hiệu suất và Thành tựu

Gia đình mô hình Phi đã đạt được hiệu suất đáng kể trên nhiều tiêu chuẩn, thường vượt qua các mô hình lớn hơn nhiều:

### Điểm nổi bật về Hiệu suất

**Xuất sắc trong Suy luận Toán học:**
- Phi-4 đạt độ chính xác 82.5% trên AIME 2025 (vòng loại Olympic Toán học)
- Phi-4-reasoning (14B) vượt qua DeepSeek-R1-Distill-70B (lớn hơn 5 lần) trên các tiêu chuẩn suy luận
- Phi-4-mini-reasoning (3.8B) ngang bằng với các mô hình lớn gấp đôi về nhiệm vụ suy luận toán học

**Thành tựu về Hiệu quả:**
- Phi-3-Silica đạt 650 token mỗi giây với chỉ 1.5W tiêu thụ năng lượng
- Phi-4-mini (3.8B) đạt hiệu suất tương tự như các mô hình lớn hơn nhiều

**Hiệu suất trên các tiêu chuẩn:**
- **MMLU (Hiểu ngôn ngữ đa nhiệm quy mô lớn)**: Hiệu suất cạnh tranh trên 57 môn học học thuật
- **HumanEval**: Khả năng tạo mã mạnh mẽ, đặc biệt trong Python
- **MGSM**: Giải toán cấp tiểu học đa ngôn ngữ
- **DROP**: Nhiệm vụ hiểu và suy luận phức tạp
- **SimpleQA**: Độ chính xác trong phản hồi thực tế

### 📊 Ma trận So sánh Mô hình

| Mô hình | Số tham số | Độ dài ngữ cảnh | Điểm mạnh chính | Trường hợp sử dụng tốt nhất |
|---------|------------|------------------|-----------------|----------------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Hiệu quả chung | Ứng dụng di động, chatbot cơ bản |
| **Phi-3.5-mini** | 3.8B | 128K | Hỗ trợ đa ngôn ngữ | Ứng dụng quốc tế |
| **Phi-4-mini** | 3.8B | 128K | Suy luận nâng cao, gọi hàm | Tự động hóa doanh nghiệp |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Suy luận toán học | Nền tảng giáo dục |
| **Phi-4** | 14B | 32K | Suy luận phức tạp | Nghiên cứu, phân tích nâng cao |
| **Phi-4-reasoning** | 14B | 32K/64K | Suy luận nhiều bước | Tính toán khoa học |
| **Phi-4-reasoning-plus** | 14B | 32K | Suy luận chính xác tối đa | Ra quyết định quan trọng |
| **Phi-4-multimodal** | 5.6B | Biến đổi | Giọng nói, hình ảnh, văn bản | Ứng dụng đa phương tiện |

## Hướng dẫn Chọn Mô hình

### Cho các ứng dụng cơ bản
- **Phi-3-mini**: Tạo văn bản đơn giản, hỏi đáp cơ bản, phản hồi nhanh
- **Phi-4-mini**: Suy luận nâng cao với khả năng gọi hàm

### Cho các nhiệm vụ toán học và suy luận
- **Phi-4**: Giải quyết vấn đề toán học phức tạp và suy luận
- **Phi-4-reasoning**: Suy luận nhiều bước với giải thích chi tiết
- **Phi-4-reasoning-plus**: Độ chính xác tối đa cho các ứng dụng suy luận quan trọng
- **Phi-4-mini-reasoning**: Suy luận toán học hiệu quả cho môi trường hạn chế tài nguyên

### Cho các ứng dụng đa phương tiện
- **Phi-3-vision**: Kết hợp xử lý hình ảnh và văn bản
- **Phi-4-multimodal**: Khả năng toàn diện về giọng nói, hình ảnh và văn bản

### Cho triển khai doanh nghiệp
- **Phi-3-medium**: Hiểu ngôn ngữ nâng cao cho các ứng dụng kinh doanh
- **Phi-3-Silica**: Tối ưu hóa cho các nền tảng phần cứng cụ thể

## Nền tảng Triển khai và Khả năng Tiếp cận

### Nền tảng Đám mây
- **Azure AI Foundry**: Triển khai đầy đủ tính năng với công cụ doanh nghiệp
- **Hugging Face**: Kho mô hình mã nguồn mở và tài nguyên cộng đồng
- **NVIDIA API Catalog**: Tùy chọn triển khai dịch vụ vi mô

### Khung Phát triển Cục bộ
- **Ollama**: Khung nhẹ cho triển khai mô hình cục bộ
- **ONNX Runtime**: Tối ưu hóa cho nhiều cấu hình phần cứng  
- **DirectML**: Hiệu suất tối ưu hóa cho Windows
- **llama.cpp**: Công cụ suy luận đa nền tảng

### Tài nguyên Học tập
- **Phi Portal**: Trung tâm tài liệu chính thức của Microsoft Phi
- **Phi Cookbook**: Các ví dụ và hướng dẫn toàn diện
- **Báo cáo Kỹ thuật**: Các bài nghiên cứu chuyên sâu trên arxiv
- **Không gian Cộng đồng**: Các bản demo tương tác trên Hugging Face

### Bắt đầu với các Mô hình Phi

#### Nền tảng Phát triển
1. **Azure AI Foundry**: CLI cục bộ đơn giản và quản lý mô hình.
2. **Hugging Face Transformers**: Thử nghiệm cục bộ nhanh chóng
3. **Ollama**: Triển khai cục bộ đơn giản để thử nghiệm

#### Lộ trình Học tập
1. **Hiểu các Khái niệm Cốt lõi**: Nghiên cứu các nguyên tắc thiết kế cơ bản
2. **Thử nghiệm với các Biến thể**: Thử các mô hình Phi khác nhau để hiểu khả năng
3. **Thực hành Triển khai**: Triển khai mô hình trong môi trường thử nghiệm
4. **Mở rộng Triển khai**: Dần dần mở rộng sử dụng dựa trên các thử nghiệm thành công

#### Thực hành Tốt nhất
- **Bắt đầu Nhỏ**: Bắt đầu với các mô hình Phi-mini cho phát triển ban đầu
- **Tối ưu hóa Prompt**: Sử dụng định dạng chat phù hợp để đạt kết quả tốt nhất
- **Theo dõi Hiệu suất**: Theo dõi tốc độ suy luận và các chỉ số độ chính xác
- **Xem xét Phần cứng**: Khớp kích thước mô hình với tài nguyên tính toán sẵn có

## Kết luận

Gia đình mô hình Phi của Microsoft đại diện cho một cách tiếp cận cách mạng trong thiết kế mô hình AI, chứng minh rằng các mô hình nhỏ hơn, hiệu quả hơn có thể đạt được hiệu suất đáng kể trên nhiều nhiệm vụ. Bằng cách tập trung vào dữ liệu huấn luyện chất lượng cao và tối ưu hóa kiến trúc, gia đình Phi mang lại khả năng vượt trội với yêu cầu tính toán giảm đáng kể so với các mô hình ngôn ngữ lớn truyền thống.

## Mục tiêu Học tập Chính

1. Hiểu triết lý thiết kế và sự phát triển của gia đình mô hình Phi của Microsoft từ Phi-1 đến Phi-4
2. Xác định các đổi mới chính, bao gồm huấn luyện "chất lượng sách giáo khoa" và tối ưu hóa kiến trúc
3. Nhận biết lợi ích và hạn chế của các biến thể Phi khác nhau trong các kịch bản triển khai khác nhau
4. Áp dụng kiến thức để chọn mô hình Phi phù hợp cho các trường hợp sử dụng cụ thể và hạn chế phần cứng
5. Triển khai các kỹ thuật tối ưu hóa để triển khai mô hình Phi trên các thiết bị hạn chế tài nguyên
6. Giải thích các lợi thế kiến trúc của gia đình mô hình Phi so với các mô hình ngôn ngữ lớn truyền thống
7. Chọn biến thể Phi phù hợp dựa trên yêu cầu ứng dụng cụ thể và hạn chế phần cứng
8. Triển khai các mô hình Phi trong cả kịch bản triển khai đám mây và biên với cấu hình tối ưu
9. Áp dụng các kỹ thuật lượng hóa và tối ưu hóa để cải thiện hiệu suất mô hình Phi trên các thiết bị mục tiêu
10. Đánh giá các đánh đổi giữa kích thước mô hình, hiệu suất và khả năng trên toàn bộ gia đình Phi

## Tiếp theo

- [02: Kiến thức cơ bản về Gia đình Qwen](02.QwenFamily.md)

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với các thông tin quan trọng, khuyến nghị sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.