{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d4d2e0",
   "metadata": {},
   "source": [
    "# 第六節 – 多步驟管道（計劃 → 執行 → 優化）\n",
    "\n",
    "使用路由函數在每個步驟中選擇模型，然後優化最終答案。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959acb1",
   "metadata": {},
   "source": [
    "### 解釋：依賴安裝\n",
    "安裝 `foundry-local-sdk` 和 `openai`，這些是每步聊天調用所需的。可以安全地重新執行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58285936",
   "metadata": {},
   "source": [
    "# 情境\n",
    "多步模型管道包括以下步驟：(1) 將任務規劃為獨立的步驟，(2) 使用基於意圖的模型選擇執行每個步驟，(3) 精煉最終綜合答案。展示如何鏈接異質SLM功能以提高效率，同時保持質量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0b10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q foundry-local-sdk openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220de1ac",
   "metadata": {},
   "source": [
    "### 解釋：核心導入\n",
    "導入正則表達式用於意圖檢測，Foundry Local 管理器用於每個別名的附件，以及 OpenAI 客戶端用於聊天完成。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d63e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from foundry_local import FoundryLocalManager\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17da8d",
   "metadata": {},
   "source": [
    "### 解釋：功能目錄與規則\n",
    "定義一個功能感知的目錄以及用於將步驟文本映射到意圖類別（代碼、摘要、分類、一般）的正則表達式規則。當多個模型支持某個意圖時，優先級較低的值將獲勝。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee8e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = {\n",
    " 'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},\n",
    " 'qwen2.5-coder-7b': {'capabilities':['code','refactor'],'priority':1},\n",
    " 'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':3},\n",
    "}\n",
    "RULES = [\n",
    " (re.compile('code|refactor|function', re.I), 'code'),\n",
    " (re.compile('summari|abstract|tl;dr', re.I), 'summarize'),\n",
    " (re.compile('classif|category|label', re.I), 'classification'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d29a6",
   "metadata": {},
   "source": [
    "### 解釋：意圖、模型選擇與聊天助手\n",
    "提供：\n",
    "- `detect_intent` 用於基於正則表達式的分類。\n",
    "- `pick_model` 根據能力和優先級選擇最佳別名。\n",
    "- `chat` 便捷的封裝器，為每個別名實例化一個客戶端並返回單輪回應。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fe43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intent(text: str):\n",
    "    \"\"\"Return an intent label based on simple regex rules; falls back to 'general'.\"\"\"\n",
    "    for pat, intent in RULES:\n",
    "        if pat.search(text):\n",
    "            return intent\n",
    "    return 'general'\n",
    "\n",
    "def pick_model(intent: str) -> str:\n",
    "    \"\"\"Pick the best model for an intent using capability match first, then priority.\"\"\"\n",
    "    ranked = []\n",
    "    for name, meta in CATALOG.items():\n",
    "        ranked.append((name, intent in meta['capabilities'], meta['priority']))\n",
    "    # Sort: capability match (True first), then lower priority value\n",
    "    ranked.sort(key=lambda t: (not t[1], t[2]))\n",
    "    return ranked[0][0]\n",
    "\n",
    "def chat(alias: str, content: str, temp: float = 0.4) -> str:\n",
    "    \"\"\"Simple helper to send a single user message to a Foundry Local model via OpenAI client.\"\"\"\n",
    "    m = FoundryLocalManager(alias)\n",
    "    client = OpenAI(base_url=m.endpoint, api_key=m.api_key or 'not-needed')\n",
    "    mid = m.get_model_info(alias).id\n",
    "    resp = client.chat.completions.create(\n",
    "        model=mid,\n",
    "        messages=[{'role': 'user', 'content': content}],\n",
    "        max_tokens=180,\n",
    "        temperature=temp,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ba53d",
   "metadata": {},
   "source": [
    "### 解釋：多步驟管道功能\n",
    "實現管道：計劃 → 解析步驟 → 使用基於意圖的路由執行每個步驟 → 優化合併的輸出。返回結構化的字典以供檢查或評估。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22bf8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(task: str):\n",
    "    \"\"\"Multi-step pipeline: plan → execute steps → refine final answer.\n",
    "\n",
    "    Returns dict with keys: plan (raw plan text), steps (list of tuples), final (refined answer).\n",
    "    Each step tuple: (index, step_text, step_result, model_alias_used)\n",
    "    \"\"\"\n",
    "    # 1. Plan\n",
    "    plan_alias = pick_model('general')\n",
    "    plan_prompt = (\n",
    "        \"Break the task into 3 concise, actionable steps (no extra commentary).\\n\"\n",
    "        f\"Task: {task}\"\n",
    "    )\n",
    "    plan = chat(plan_alias, plan_prompt)\n",
    "\n",
    "    # 2. Parse steps (robust to numbering or bullet styles)\n",
    "    raw_lines = [l.strip() for l in plan.splitlines() if l.strip()]\n",
    "    steps = []\n",
    "    for line in raw_lines:\n",
    "        cleaned = re.sub(r'^\\d+[).:-]?\\s*', '', line)  # remove leading numbering\n",
    "        cleaned = re.sub(r'^[-*]\\s*', '', cleaned)      # remove bullet markers\n",
    "        if cleaned:\n",
    "            steps.append(cleaned)\n",
    "        if len(steps) == 3:\n",
    "            break\n",
    "    if not steps:\n",
    "        steps = [task]\n",
    "\n",
    "    # 3. Execute steps\n",
    "    outputs = []\n",
    "    for idx, step in enumerate(steps, 1):\n",
    "        intent = detect_intent(step)\n",
    "        exec_alias = pick_model(intent)\n",
    "        exec_prompt = (\n",
    "            f\"Execute step {idx} for the overall task.\\n\"\n",
    "            f\"Overall task: {task}\\n\"\n",
    "            f\"Step {idx}: {step}\\n\"\n",
    "            \"Return a concise result focusing only on the step objective.\"\n",
    "        )\n",
    "        result = chat(exec_alias, exec_prompt)\n",
    "        outputs.append((idx, step, result, exec_alias))\n",
    "\n",
    "    # 4. Refine final answer\n",
    "    refine_alias = pick_model('summarize')\n",
    "    combined = \"\\n\\n\".join(\n",
    "        f\"Step {idx} ({alias}) Output:\\n{res}\" for idx, _step, res, alias in outputs\n",
    "    )\n",
    "    refine_prompt = (\n",
    "        \"You are a senior assistant. Synthesize these step outputs into a cohesive final answer.\\n\"\n",
    "        \"Ensure clarity, avoid repetition, and highlight improvements or key insights if relevant.\\n\\n\"\n",
    "        f\"Task: {task}\\n\\n\"\n",
    "        f\"Step Outputs:\\n{combined}\"\n",
    "    )\n",
    "    final_ans = chat(refine_alias, refine_prompt)\n",
    "\n",
    "    return {\"plan\": plan, \"steps\": outputs, \"final\": final_ans}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282472b0",
   "metadata": {},
   "source": [
    "### 解釋：執行範例任務  \n",
    "執行完整的管道，針對以重構為導向的任務展示混合意圖（程式碼 + 摘要）。結果字典顯示原始計劃、每步輸出及所選模型別名，以及最終綜合答案。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac0f568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plan': '1. Profile the existing slow Python loop to identify bottlenecks.\\n2. Refactor the loop using optimized techniques (e.g., list comprehensions, map, or itertools).\\n3. Compare the performance of the refactored loop with the original using a benchmarking tool and summarize the gains.',\n",
       " 'steps': [(1,\n",
       "   'Profile the existing slow Python loop to identify bottlenecks.',\n",
       "   \"To execute step 1, you would use a profiling tool like `cProfile` in Python to analyze the performance of the existing slow loop. Here's an example of how you might do this:\\n\\n```python\\nimport cProfile\\n\\ndef slow_loop():\\n    # Example of a slow loop\\n    result = []\\n    for i in range(1000000):\\n        result.append(i * i)\\n    return result\\n\\n# Profile the slow loop\\ncProfile.run('slow_loop()', 'profile_stats')\\n\\n# To see the results, you can use pstats module\\nimport pstats\\np = pstats.Stats('profile_stats')\\np.sort_stats('cumulative').print_stats()\\n```\\n\\nThis code will run the `slow_loop` function and profile it, saving the results to 'profile_stats'. The `pstats` module can then be used to analyze the profiling data, which will show\",\n",
       "   'phi-4-mini'),\n",
       "  (2,\n",
       "   'Refactor the loop using optimized techniques (e.g., list comprehensions, map, or itertools).',\n",
       "   'To refactor a slow Python loop using optimized techniques such as list comprehensions, `map`, or `itertools`, follow these steps:\\n\\n1. **Identify the Loop**: Determine which loop in your code is causing the slowdown.\\n2. **Understand the Loop**: Analyze what the loop does, including any operations performed on each element.\\n3. **Choose an Optimization Technique**:\\n   - **List Comprehension**: If the loop constructs a new list, use a list comprehension.\\n   - **Map Function**: Use `map` if you need to apply a function to each item in an iterable.\\n   - **Itertools**: Utilize functions from the `itertools` module for more efficient looping patterns.\\n4. **Refactor the Loop**: Replace the original loop with the chosen optimization technique.\\n5. **Test the Code**: Ensure that the refactored code produces the same',\n",
       "   'qwen2.5-coder-7b'),\n",
       "  (3,\n",
       "   'Compare the performance of the refactored loop with the original using a benchmarking tool and summarize the gains.',\n",
       "   'To compare the performance of the refactored loop with the original using a benchmarking tool, follow these steps:\\n\\n1. **Choose a Benchmarking Tool**: Select an appropriate benchmarking tool such as `timeit`, `cProfile`, or `line_profiler` depending on your needs.\\n\\n2. **Set Up Your Environment**: Ensure that both the original and refactored code snippets are in separate functions or scripts so they can be easily compared.\\n\\n3. **Run Benchmarks**:\\n   - Use the chosen tool to measure the execution time of the original loop.\\n   - Repeat the process for the refactored loop.\\n\\n4. **Compare Results**: Analyze the results from both benchmarks to determine the performance gain achieved by the refactoring.\\n\\n5. **Summarize Gains**: Provide a concise summary of the performance improvements, including any specific metrics (e.g., speedup factor',\n",
       "   'qwen2.5-coder-7b')],\n",
       " 'final': 'To optimize a slow Python loop, you can use profiling tools like `cProfile` to identify the loop causing the slowdown. Once identified, you can refactor the loop using techniques such as list comprehensions, `map`, or `itertools` for more efficient looping patterns. After refactoring, you can use benchmarking tools like `timeit`, `cProfile`, or `line_profiler` to compare the performance of the original and refactored loops. The performance gains can be summarized in terms of speedup factor or other relevant metrics. This process can significantly improve the performance of your Python code.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline('Generate a refactored version of a slow Python loop and summarize performance gains.')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4251879",
   "metadata": {},
   "source": [
    "### 解釋：顯示結果物件\n",
    "展示結構化的管道輸出，方便快速檢查或後續評估（例如，測量步驟質量或改進效果）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責聲明**：  \n本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們致力於提供準確的翻譯，請注意自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋概不負責。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "coopTranslator": {
   "original_hash": "4b16cb98e431df1b9f64f627bad7009c",
   "translation_date": "2025-10-08T16:53:32+00:00",
   "source_file": "Workshop/notebooks/session06_models_pipeline.ipynb",
   "language_code": "hk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}