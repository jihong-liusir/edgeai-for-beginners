<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-08T16:09:56+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "hk"
}
-->
# EdgeAI 初學者指南：學習路徑與學習計劃

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第2天 | 模組2：SLM 基礎 | 3小時 |
| 第3天 | 模組3：SLM 部署 | 2小時 |
| 第4-5天 | 模組4：模型優化（6個框架） | 4小時 |
| 第6天 | 模組5：SLMOps | 3小時 |
| 第7天 | 模組6-7：AI代理與開發工具 | 4小時 |
| 第8天 | 模組8：Foundry Local 工具包（現代實現） | 1小時 |

### 集中學習路徑（2週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：AI代理 | 2小時 |
| 第13-14天 | 模組7：開發工具 | 3小時 |

### 兼職學習（4週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：SLM代理系統 | 2小時 |
| 第13-14天 | 模組7：EdgeAI 實現範例 | 2小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|--------|----------------|-------------|--------------|
| 模組0：EdgeAI 簡介 | | | |
| 模組1：EdgeAI 基礎 | | | |
| 模組2：SLM 基礎 | | | |
| 模組3：SLM 部署 | | | |
| 模組4：模型優化（6個框架） | | | |
| 模組5：SLMOps | | | |
| 模組6：SLM代理系統 | | | |
| 模組7：EdgeAI 實現範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習（4週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM 基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

## 簡介

歡迎使用《EdgeAI 初學者指南》！本文件旨在幫助您有效地學習課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，幫助您深入了解EdgeAI技術。

這是一門精簡的20小時課程，旨在以高效的方式傳授EdgeAI的基本知識，非常適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概述

本課程分為八個全面的模組：

0. **EdgeAI 簡介** - 建立基礎並提供行業應用和學習目標
1. **EdgeAI 基礎與轉型** - 理解核心概念和技術變革
2. **小型語言模型（SLM）基礎** - 探索各種SLM家族及其架構
3. **小型語言模型部署** - 實現實際部署策略
4. **模型格式轉換與量化** - 使用包括OpenVINO在內的6個框架進行高級優化
5. **SLMOps - 小型語言模型操作** - 生產生命周期管理與部署
6. **SLM代理系統** - AI代理、函數調用與模型上下文協議
7. **EdgeAI 實現範例** - AI工具包、Windows開發與平台特定實現
8. **Microsoft Foundry Local – 完整開發工具包** - 本地優先開發與混合Azure整合（模組08）

## 如何使用本學習指南

- **循序漸進學習**：按順序學習模組以獲得最連貫的學習體驗
- **知識檢查點**：使用每部分後的自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑（1週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI 基礎 | 6小時 |
| 第3-4天 | 模組2：SLM 基礎 | 8小時 |
| 第5天 | 模組3：SLM 部署 | 3小時 |
| 第6天 | 模組8：Foundry Local 工具包 | 3小時 |

### 兼職學習（3週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組0：簡介 + 模組1：EdgeAI 基礎 | 7-9小時 |
| 第2週 | 模組2：SLM 基礎 | 7-8小時 |
| 第3週 | 模組3：SLM 部署（3小時）+ 模組8：Foundry Local 工具包（2-3小時） | 5-6小時 |

## 模組0：EdgeAI 簡介

### 主要學習目標

- 理解什麼是EdgeAI以及它在當今技術中的重要性
- 識別被EdgeAI改變的主要行業及其具體應用案例
- 理解小型語言模型（SLM）在邊緣部署中的優勢
- 為整個課程建立清晰的學習期望和成果
- 認識EdgeAI領域的職業機會和技能需求

### 學習重點區域

#### 第1節：EdgeAI 範式與定義
- **重點概念**：
  - EdgeAI與傳統雲端AI處理的區別
  - 硬件、模型優化與商業需求的融合
  - 實時、隱私保護與成本高效的AI部署

#### 第2節：行業應用
- **重點概念**：
  - 製造業與工業4.0：預測性維護與質量控制
  - 醫療保健：診斷影像與患者監測
  - 自主系統：自駕車與交通運輸
  - 智慧城市：交通管理與公共安全
  - 消費技術：智能手機、穿戴設備與智能家居

#### 第3節：小型語言模型基礎
- **重點概念**：
  - SLM特性與性能比較
  - 參數效率與能力的權衡
  - 邊緣部署限制與優化策略

#### 第4節：學習框架與職業路徑
- **重點概念**：
  - 課程架構與循序漸進的掌握方法
  - 技術技能與實際實現目標
  - 職業發展機會與行業應用

### 自我評估問題

1. 哪三個主要技術趨勢促成了EdgeAI的發展？
2. 比較EdgeAI與基於雲端的AI的優勢與挑戰。
3. 列出三個EdgeAI提供關鍵商業價值的行業並解釋原因。
4. 小型語言模型如何使EdgeAI在實際部署中更具可行性？
5. 您將在本課程中發展哪些關鍵技術技能？
6. 描述本課程使用的四階段學習方法。

### 實作練習

1. **行業研究**：選擇一個行業應用並研究一個真實的EdgeAI實現案例（30分鐘）
2. **模型探索**：瀏覽Hugging Face上的小型語言模型，並比較其參數數量與能力（30分鐘）
3. **學習計劃**：審查完整課程結構並制定個人學習計劃（15分鐘）

### 補充材料

- [EdgeAI市場概述 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [小型語言模型概述 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Edge Computing Foundation](https://www.edgecomputing.org/)

## 模組1：EdgeAI 基礎與轉型

### 主要學習目標

- 理解基於雲端與基於邊緣的AI的差異
- 掌握資源受限環境的核心優化技術
- 分析EdgeAI技術的真實應用案例
- 設置EdgeAI項目的開發環境

### 學習重點區域

#### 第1節：EdgeAI 基礎
- **重點概念**：
  - Edge與雲端計算範式
  - 模型量化技術
  - 硬件加速選項（NPU、GPU、CPU）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文檔](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文檔](https://docs.edgeimpulse.com)

#### 第2節：真實案例研究
- **重點概念**：
  - Microsoft Phi & Mu模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第3節：實際實現指南
- **重點概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI實現的評估方法

#### 第4節：邊緣部署硬件
- **重點概念**：
  - 硬件平台比較
  - 特定硬件的優化策略
  - 部署考量

### 自我評估問題

1. 比較基於雲端的AI與基於邊緣的AI實現。
2. 解釋三個關鍵技術，用於優化邊緣部署的模型。
3. 在邊緣運行AI模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬件加速器（NPU、GPU、CPU）如何影響EdgeAI部署。

### 實作練習

1. **快速環境設置**：配置一個包含基本套件的最小開發環境（30分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1小時）
3. **基礎量化**：嘗試對一個小型模型進行簡單量化（1小時）

## 模組2：小型語言模型基礎

### 主要學習目標

- 理解不同SLM家族的架構原則
- 比較不同參數規模模型的能力
- 根據效率、能力和部署需求評估模型
- 識別不同模型家族的適用場景

### 學習重點區域

#### 第1節：Microsoft Phi 模型家族
- **重點概念**：
  - 設計理念演變
  - 效率優先架構
  - 專業化能力

#### 第2節：Qwen 家族
- **重點概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第3節：Gemma 家族
- **重點概念**：
  - 研究驅動創新
  - 多模態能力
  - 移動優化

#### 第4節：BitNET 家族
- **重點概念**：
  - 1-bit量化技術
  - 推理優化框架
  - 可持續性考量

#### 第5節：Microsoft Mu 模型
- **重點概念**：
  - 設備優先架構
  - 與Windows的系統整合
  - 隱私保護操作

#### 第6節：Phi-Silica
- **重點概念**：
  - NPU優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較Phi與Qwen模型家族的架構方法。
2. 解釋BitNET的量化技術與傳統量化的不同之處。
3. Mu 模型在 Windows 整合方面有什麼獨特優勢？
4. Phi-Silica 如何利用 NPU 硬件進行性能優化？
5. 對於一個連接有限的移動應用程式，哪個模型系列最適合？為什麼？

### 實作練習

1. **模型比較**：快速對比兩個不同的 SLM 模型（1小時）
2. **簡單文本生成**：使用小型模型進行基本文本生成實作（1小時）
3. **快速優化**：應用一種優化技術以提升推理速度（1小時）

## 模組 3：小型語言模型部署

### 核心學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實作 SLM
- 設計適用於 EdgeAI 應用的生產級配置

### 學習重點領域

#### 第一部分：SLM 高級學習
- **優先概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第二部分：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第三部分：容器化雲端部署
- **優先概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實作

### 自我評估問題

1. 在選擇本地部署和雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 針對邊緣部署的 SLM，應監控哪些關鍵性能指標？
5. 描述從模型選擇到生產實作的完整部署工作流程。

### 實作練習

1. **基本本地部署**：使用 Ollama 部署一個簡單的 SLM（1小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30分鐘）
3. **簡單整合**：創建一個使用已部署模型的簡易應用程式（1小時）

## 模組 4：模型格式轉換與量化

### 核心學習目標

- 掌握從 1-bit 到 8-bit 精度的高級量化技術
- 理解格式轉換策略（GGUF、ONNX）
- 在六個框架中實作優化（Llama.cpp、Olive、OpenVINO、MLX、工作流程綜合）
- 為 Intel、Apple 和跨平台硬件部署生產級優化模型

### 學習重點領域

#### 第一部分：量化基礎
- **優先概念**：
  - 精度分類框架
  - 性能與準確性權衡
  - 記憶體佔用優化

#### 第二部分：Llama.cpp 實作
- **優先概念**：
  - 跨平台部署
  - GGUF 格式優化
  - 硬件加速技術

#### 第三部分：Microsoft Olive 套件
- **優先概念**：
  - 硬件感知優化
  - 企業級部署
  - 自動化優化工作流程

#### 第四部分：OpenVINO 工具包
- **優先概念**：
  - Intel 硬件優化
  - 神經網絡壓縮框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI 用於 LLM 部署

#### 第五部分：Apple MLX 框架
- **優先概念**：
  - Apple Silicon 優化
  - 統一記憶體架構
  - LoRA 微調能力

#### 第六部分：邊緣 AI 開發工作流程綜合
- **優先概念**：
  - 統一工作流程架構
  - 框架選擇決策樹
  - 生產準備驗證
  - 未來適應性策略

### 自我評估問題

1. 比較不同精度級別（1-bit 到 8-bit）的量化策略。
2. 解釋 GGUF 格式在邊緣部署中的優勢。
3. Microsoft Olive 的硬件感知優化如何提升部署效率？
4. OpenVINO 的 NNCF 在模型壓縮方面有什麼主要優勢？
5. 描述 Apple MLX 如何利用統一記憶體架構進行優化。
6. 工作流程綜合如何幫助選擇最佳優化框架？

### 實作練習

1. **模型量化**：對模型應用不同的量化級別並比較結果（1小時）
2. **OpenVINO 優化**：使用 NNCF 壓縮模型以適配 Intel 硬件（1小時）
3. **框架比較**：在三個不同的優化框架中測試同一模型（1小時）
4. **性能基準測試**：測量優化對推理速度和記憶體使用的影響（1小時）

## 模組 5：SLMOps - 小型語言模型運營

### 核心學習目標

- 理解 SLMOps 生命周期管理原則
- 掌握邊緣部署的蒸餾和微調技術
- 實作具有監控功能的生產部署策略
- 建立企業級 SLM 運營和維護工作流程

### 學習重點領域

#### 第一部分：SLMOps 簡介
- **優先概念**：
  - SLMOps 在 AI 運營中的範式轉變
  - 成本效率和隱私優先架構
  - 戰略性商業影響和競爭優勢

#### 第二部分：模型蒸餾
- **優先概念**：
  - 知識轉移技術
  - 雙階段蒸餾過程實作
  - Azure ML 蒸餾工作流程

#### 第三部分：微調策略
- **優先概念**：
  - 參數高效微調（PEFT）
  - LoRA 和 QLoRA 高級方法
  - 多適配器訓練和超參數優化

#### 第四部分：生產部署
- **優先概念**：
  - 生產級模型轉換和量化
  - Foundry Local 部署配置
  - 性能基準測試和質量驗證

### 自我評估問題

1. SLMOps 與傳統 MLOps 有何不同？
2. 解釋模型蒸餾對邊緣部署的好處。
3. 在資源受限的環境中微調 SLM 時需要考慮哪些關鍵因素？
4. 描述一個完整的邊緣 AI 應用生產部署管道。

### 實作練習

1. **基本蒸餾**：從較大的教師模型創建一個較小的模型（1小時）
2. **微調實驗**：針對特定領域微調模型（1小時）
3. **部署管道**：設置一個基本的 CI/CD 管道以進行模型部署（1小時）

## 模組 6：SLM Agentic 系統 - AI 代理與函數調用

### 核心學習目標

- 使用小型語言模型構建適用於邊緣環境的智能 AI 代理
- 通過系統化工作流程實作函數調用功能
- 掌握模型上下文協議（MCP）整合以標準化工具交互
- 創建高級代理系統，減少人工干預

### 學習重點領域

#### 第一部分：AI 代理與 SLM 基礎
- **優先概念**：
  - 代理分類框架（反射型、基於模型、基於目標、學習型代理）
  - SLM 與 LLM 的權衡分析
  - 邊緣特定代理設計模式
  - 代理資源優化

#### 第二部分：小型語言模型中的函數調用
- **優先概念**：
  - 系統化工作流程實作（意圖檢測、JSON 輸出、外部執行）
  - 平台特定實作（Phi-4-mini、選定的 Qwen 模型、Microsoft Foundry Local）
  - 高級示例（多代理協作、動態工具選擇）
  - 生產考量（速率限制、審計記錄、安全措施）

#### 第三部分：模型上下文協議（MCP）整合
- **優先概念**：
  - 協議架構與分層系統設計
  - 多後端支持（Ollama 用於開發，vLLM 用於生產）
  - 連接協議（STDIO 和 SSE 模式）
  - 實際應用（網頁自動化、數據處理、API 整合）

### 自我評估問題

1. 邊緣 AI 代理的關鍵架構考量是什麼？
2. 函數調用如何增強代理功能？
3. 解釋模型上下文協議在代理通信中的作用。

### 實作練習

1. **簡單代理**：構建一個帶有函數調用功能的基本 AI 代理（1小時）
2. **MCP 整合**：在代理應用中實作 MCP（30分鐘）

## 工作坊：實作學習路徑

### 核心學習目標

- 使用 Foundry Local SDK 和最佳實踐構建生產級 AI 應用
- 實作全面的錯誤處理和用戶反饋模式
- 創建 RAG 管道並進行質量評估和性能監控
- 開發具有協調模式的多代理系統
- 掌握智能模型路由以進行基於任務的模型選擇
- 部署以隱私保護架構為主的本地優先 AI 解決方案

### 學習重點領域

#### 第一節：使用 Foundry Local 入門
- **優先概念**：
  - FoundryLocalManager SDK 整合與自動服務發現
  - 基本和流式聊天實作
  - 錯誤處理模式與用戶反饋
  - 基於環境的配置

#### 第二節：使用 RAG 構建 AI 解決方案
- **優先概念**：
  - 使用 sentence-transformers 的內存向量嵌入
  - RAG 管道實作（檢索 → 生成）
  - 使用 RAGAS 指標進行質量評估
  - 可選依賴項的導入安全性

#### 第三節：開源模型
- **優先概念**：
  - 多模型基準測試策略
  - 延遲和吞吐量測量
  - 優雅降級與錯誤恢復
  - 模型系列間的性能比較

#### 第四節：尖端模型
- **優先概念**：
  - SLM 與 LLM 比較方法論
  - 類型提示與全面的輸出格式化
  - 每模型錯誤處理
  - 結構化結果分析

#### 第五節：AI 驅動代理
- **優先概念**：
  - 使用協調模式進行多代理編排
  - 代理記憶管理與狀態跟蹤
  - 管道錯誤處理與階段記錄
  - 性能監控與統計

#### 第六節：模型作為工具
- **優先概念**：
  - 意圖檢測與模式匹配
  - 基於關鍵字的模型路由算法
  - 多步管道（計劃 → 執行 → 優化）
  - 全面的函數文檔

### 自我評估問題

1. FoundryLocalManager 如何簡化服務管理，相較於手動 REST 調用？
2. 解釋可選依賴項（如 sentence-transformers）的導入保護的重要性。
3. 在多模型基準測試中，哪些策略能確保優雅降級？
4. 協調模式如何編排多個專家代理？
5. 描述智能模型路由器的組成部分。
6. 生產級錯誤處理的關鍵要素是什麼？

### 實作練習

1. **聊天應用**：實作帶有錯誤處理的流式聊天（45分鐘）
2. **RAG 管道**：構建最小化 RAG 並進行質量評估（1小時）
3. **模型基準測試**：比較 3+ 模型的性能（1小時）
4. **多代理系統**：創建具有 2 個專家代理的協調器（1.5小時）
5. **智能路由器**：構建基於任務的模型選擇（1小時）
6. **生產部署**：添加監控和全面的錯誤處理（45分鐘）

### 時間分配

**集中學習（1週）**：
- 第一天：第一節至第二節（聊天 + RAG）- 3小時
- 第二天：第三節至第四節（基準測試 + 比較）- 3小時
- 第三天：第五節至第六節（代理 + 路由）- 3小時
- 第四天：實作練習與驗證 - 2小時

**兼職學習（2週）**：
- 第一週：第一節至第三節（共 6小時）
- 第二週：第四節至第六節 + 實作練習（共 5小時）

## 模組 7：EdgeAI 實作範例

### 核心學習目標

- 掌握 Visual Studio Code 的 AI 工具包以進行全面的 EdgeAI 開發工作流程
- 熟悉 Windows AI Foundry 平台和 NPU 優化策略
- 在多個硬件平台和部署場景中實作 EdgeAI
- 使用平台特定的優化構建生產級 EdgeAI 應用

### 學習重點領域

#### 第一部分：Visual Studio Code 的 AI 工具包
- **優先概念**：
  - 在 VS Code 中進行全面的 Edge AI 開發環境
  - 用於邊緣部署的模型目錄與發現
  - 本地測試、優化和代理開發工作流程
  - 邊緣場景的性能監控與評估

#### 第二部分：Windows EdgeAI 開發指南
- **優先概念**：
  - Windows AI Foundry 平台全面概述
  - Phi Silica API 用於高效 NPU 推理
  - 用於圖像處理和 OCR 的計算機視覺 API
  - Foundry Local CLI 用於本地開發與測試

#### 第三部分：平台特定實作
- **優先概念**：
  - NVIDIA Jetson Orin Nano 部署（67 TOPS AI 性能）
  - 使用 .NET MAUI 和 ONNX Runtime GenAI 的移動應用
  - Azure EdgeAI 解決方案與雲端-邊緣混合架構
  - Windows ML 優化與通用硬件支持
  - Foundry Local 應用與隱私聚焦的 RAG 實作

### 自我評估問題

1. AI 工具包如何簡化 EdgeAI 開發工作流程？
2. 比較不同硬件平台的部署策略。
3. Windows AI Foundry 在邊緣開發方面有什麼優勢？
4. 解釋 NPU 優化在現代邊緣 AI 應用中的角色。
5. Phi Silica API 如何利用 NPU 硬件進行性能優化？
6. 比較本地部署與雲端部署在隱私敏感應用中的優勢。

### 實作練習

1. **AI 工具包設置**：配置 AI 工具包並優化模型（1小時）
2. **Windows AI Foundry**：使用 Phi Silica API 建立簡單的 Windows AI 應用程式（1小時）
3. **跨平台部署**：在兩個不同平台上部署相同模型（1小時）
4. **NPU 優化**：使用 Windows AI Foundry 工具測試 NPU 性能（30分鐘）

## 模組 8：Microsoft Foundry Local – 完整開發者工具包（現代化）

### 主要學習目標

- 安裝並配置 Foundry Local，整合現代 SDK
- 實現進階多代理系統，使用協調器模式
- 建立智能模型路由器，進行自動化基於任務的選擇
- 部署生產級 AI 解決方案，配備全面監控功能
- 與 Azure AI Foundry 整合，實現混合部署場景
- 掌握 FoundryLocalManager 和 OpenAI 客戶端的現代 SDK 模式

### 學習重點領域

#### 第一部分：現代化安裝與配置
- **重點概念**：
  - FoundryLocalManager SDK 整合
  - 自動服務發現與健康監控
  - 基於環境的配置模式
  - 生產部署考量

#### 第二部分：進階多代理系統
- **重點概念**：
  - 使用專家代理的協調器模式
  - 檢索、推理與執行代理的專業化
  - 用於改進的反饋迴路機制
  - 性能監控與統計追蹤

#### 第三部分：智能模型路由
- **重點概念**：
  - 基於關鍵字的模型選擇算法
  - 支援多模型（通用、推理、代碼、創意）
  - 環境變數配置的靈活性
  - 服務健康檢查與錯誤處理

#### 第四部分：生產級實現
- **重點概念**：
  - 全面的錯誤處理與備援機制
  - 請求監控與性能追蹤
  - 使用 Jupyter notebook 的互動示例與基準測試
  - 與現有應用程式的整合模式

### 自我評估問題

1. 現代 FoundryLocalManager 方法與手動 REST 調用有何不同？
2. 解釋協調器模式及其如何協調專家代理。
3. 智能路由器如何根據查詢內容選擇合適的模型？
4. 生產級 AI 代理系統的關鍵組成部分是什麼？
5. 如何為 Foundry Local 服務實現全面的健康監控？
6. 比較現代化方法與傳統實現模式的優勢。

### 實作練習

1. **現代 SDK 設置**：配置 FoundryLocalManager，實現自動服務發現（30分鐘）
2. **多代理系統**：運行進階協調器，配備專家代理（30分鐘）
3. **智能路由**：使用不同查詢類型測試模型路由器（30分鐘）
4. **互動探索**：使用 Jupyter notebook 探索進階功能（45分鐘）
5. **生產部署**：實現監控與錯誤處理模式（30分鐘）
6. **混合整合**：配置 Azure AI Foundry 備援場景（30分鐘）

## 時間分配指南

為了幫助您充分利用 30 小時的課程時間（包括工作坊），以下是建議的時間分配：

| 活動 | 時間分配 | 描述 |
|------|----------|------|
| 閱讀核心材料 | 12小時 | 專注於每個模組的基本概念 |
| 實作練習 | 10小時 | 實際應用關鍵技術（包括工作坊） |
| 自我評估 | 3小時 | 通過問題和反思測試您的理解 |
| 小型專案 | 5小時 | 將知識應用於小型實作 |

### 根據時間限制的重點領域

**如果您只有 10 小時：**
- 完成模組 0（介紹）以及模組 1、2 和 3（核心邊緣 AI 概念）
- 每個模組至少完成一個實作練習
- 專注於理解核心概念，而非實作細節

**如果您可以投入完整的 20 小時：**
- 完成所有八個模組（包括介紹）
- 執行每個模組的關鍵實作練習
- 完成模組 7 的一個小型專案
- 探索至少 2-3 個補充資源

**如果您有超過 20 小時：**
- 完成所有模組（包括介紹），並進行詳細的練習
- 建立多個小型專案
- 探索模組 4 的進階優化技術
- 實現模組 5 的生產部署

## 必備資源

以下精選資源能為您的有限學習時間提供最大價值：

### 必讀文件
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最有效的模型優化工具
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快的本地部署 SLM 方法
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考
- [OpenVINO 文件](https://docs.openvino.ai/2025/index.html) - Intel 的全面優化工具包
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - 整合的邊緣 AI 開發環境
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 特定的邊緣 AI 開發平台

### 節省時間的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問與部署
- [Gradio](https://www.gradio.app/docs/interface) - 快速建立 AI 演示的 UI
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化的模型優化工具
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的 CPU 推理
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網絡壓縮框架
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包

## 進度追蹤模板

使用此簡化模板追蹤您在 20 小時課程中的學習進度：

| 模組 | 完成日期 | 花費時間 | 主要收穫 |
|------|----------|----------|----------|
| 模組 0：邊緣 AI 介紹 | | | |
| 模組 1：邊緣 AI 基礎 | | | |
| 模組 2：SLM 基礎 | | | |
| 模組 3：SLM 部署 | | | |
| 模組 4：模型優化 | | | |
| 模組 5：SLMOps | | | |
| 模組 6：AI 代理 | | | |
| 模組 7：開發工具 | | | |
| 工作坊：實作學習 | | | |
| 模組 8：Foundry Local 工具包 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

## 小型專案構想

考慮完成以下專案以練習邊緣 AI 概念（每個設計為 2-4 小時）：

### 初學者專案（2-3 小時）
1. **邊緣文字助手**：使用小型語言模型創建簡單的離線文字補全工具
2. **模型比較儀表板**：建立基本的性能指標可視化工具，對比不同 SLM
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響

### 中級專案（3-4 小時）
4. **AI 工具包工作流程**：使用 VS Code AI 工具包完成模型的優化與部署
5. **Windows AI Foundry 應用程式**：使用 Phi Silica API 和 NPU 優化創建 Windows 應用程式
6. **跨平台部署**：在 Windows（OpenVINO）和移動端（.NET MAUI）部署相同的優化模型
7. **函數調用代理**：建立具有函數調用能力的 AI 代理，用於邊緣場景

### 高級整合專案（4-5 小時）
8. **OpenVINO 優化管道**：使用 NNCF 和 GenAI 工具包實現完整的模型優化
9. **SLMOps 管道**：實現從訓練到邊緣部署的完整模型生命周期
10. **多模型邊緣系統**：在邊緣硬件上部署多個專業化模型協同工作
11. **MCP 整合系統**：使用模型上下文協議建立代理系統進行工具交互

## 參考資料

- Microsoft Learn (Foundry Local)
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - 入門：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI 參考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - 與推理 SDK 整合：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - 開啟 WebUI 教學：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - 編譯 Hugging Face 模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/
  - 代理（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- 優化與推理工具
  - Microsoft Olive（文件）：https://microsoft.github.io/Olive/
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive
  - ONNX Runtime（入門）：https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive 整合：https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO（文件）：https://docs.openvino.ai/2025/index.html
  - Apple MLX（文件）：https://ml-explore.github.io/mlx/build/html/index.html
- 部署框架與模型
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index
  - vLLM（文件）：https://docs.vllm.ai/
  - Ollama（快速入門）：https://github.com/ollama/ollama#get-started
- 開發工具（Windows 和 VS Code）
  - AI Toolkit for VS Code：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## 學習社群

加入討論並與其他學習者交流：
- GitHub 討論：[EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

邊緣 AI 代表了人工智能實現的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等關鍵問題。本課程提供了 20 小時的學習內容，幫助您立即開始使用邊緣 AI 技術。

課程內容精簡且專注於最重要的概念，讓您能快速獲得有價值的專業知識，而不需要投入過多的時間。請記住，即使是簡單的實作練習，也能有效鞏固您的學習成果。

祝學習愉快！

---

**免責聲明**：  
本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋概不負責。