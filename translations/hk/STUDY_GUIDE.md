<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-15T16:45:04+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "hk"
}
-->
# EdgeAI 初學者指南：學習路徑及學習時間表

### 集中學習路徑（一週）

| 天數 | 學習重點 | 預估時數 |
|------|-------|------------------|
| 第一天 | 模組 1：EdgeAI 基礎 | 3 小時 |
| 第二天 | 模組 2：SLM 基礎 | 3 小時 |
| 第三天 | 模組 3：SLM 部署 | 2 小時 |
| 第四至五天 | 模組 4：模型優化（6 個框架） | 4 小時 |
| 第六天 | 模組 5：SLMOps | 3 小時 |
| 第七天 | 模組 6-7：AI 代理及開發工具 | 5 小時 |

### 集中學習路徑（兩週）

| 天數 | 學習重點 | 預估時數 |
|------|-------|------------------|
| 第 1-2 天 | 模組 1：EdgeAI 基礎 | 3 小時 |
| 第 3-4 天 | 模組 2：SLM 基礎 | 3 小時 |
| 第 5-6 天 | 模組 3：SLM 部署 | 2 小時 |
| 第 7-8 天 | 模組 4：模型優化 | 4 小時 |
| 第 9-10 天 | 模組 5：SLMOps | 3 小時 |
| 第 11-12 天 | 模組 6：AI 代理 | 2 小時 |
| 第 13-14 天 | 模組 7：開發工具 | 3 小時 |

### 兼職學習（四週）

| 週數 | 學習重點 | 預估時數 |
|------|-------|------------------|
| 第一週 | 模組 1-2：基礎及 SLM 基礎 | 6 小時 |
| 第二週 | 模組 3-4：部署及優化 | 6 小時 |
| 第三週 | 模組 5-6：SLMOps 及 AI 代理 | 5 小時 |
| 第四週 | 模組 7：開發工具及整合 | 3 小時 |

| 天數 | 學習重點 | 預估時數 |
|------|-------|------------------|
| 第 1-2 天 | 模組 1：EdgeAI 基礎 | 3 小時 |
| 第 3-4 天 | 模組 2：SLM 基礎 | 3 小時 |
| 第 5-6 天 | 模組 3：SLM 部署 | 2 小時 |
| 第 7-8 天 | 模組 4：模型優化 | 4 小時 |
| 第 9-10 天 | 模組 5：SLMOps | 3 小時 |
| 第 11-12 天 | 模組 6：SLM 代理系統 | 2 小時 |
| 第 13-14 天 | 模組 7：EdgeAI 實作範例 | 2 小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|--------|----------------|-------------|--------------|
| 模組 1：EdgeAI 基礎 | | | |
| 模組 2：SLM 基礎 | | | |
| 模組 3：SLM 部署 | | | |
| 模組 4：模型優化（6 個框架） | | | |
| 模組 5：SLMOps | | | |
| 模組 6：SLM 代理系統 | | | |
| 模組 7：EdgeAI 實作範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習（四週）

| 週數 | 學習重點 | 預估時數 |
|------|-------|------------------|
| 第一週 | 模組 1-2：基礎及 SLM 基礎 | 6 小時 |
| 第二週 | 模組 3-4：部署及優化 | 6 小時 |
| 第三週 | 模組 5-6：SLMOps 及 AI 代理 | 5 小時 |
| 第四週 | 模組 7：開發工具及整合 | 3 小時 |

## 簡介

歡迎使用 EdgeAI 初學者學習指南！此文件旨在幫助您有效地學習課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習時間表、關鍵概念摘要，以及補充資源以加深您對 EdgeAI 技術的理解。

這是一門精簡的 20 小時課程，能以高效的方式傳授 EdgeAI 的基本知識，非常適合忙碌的專業人士和學生快速掌握這個新興領域的實用技能。

## 課程概述

此課程分為七個全面的模組：

1. **EdgeAI 基礎及轉型** - 理解核心概念及技術轉變
2. **小型語言模型（SLM）基礎** - 探索各種 SLM 家族及其架構
3. **小型語言模型部署** - 實現實際部署策略
4. **模型格式轉換及量化** - 使用 6 個框架進行高級優化，包括 OpenVINO
5. **SLMOps - 小型語言模型運營** - 生產生命周期管理及部署
6. **SLM 代理系統** - AI 代理、函數調用及模型上下文協議
7. **EdgeAI 實作範例** - AI 工具包、Windows 開發及平台特定實作

## 如何使用此學習指南

- **循序漸進學習**：按順序學習模組以獲得最連貫的學習體驗
- **知識檢查點**：在每個章節後使用自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習時間表建議

### 集中學習路徑（一週）

| 天數 | 學習重點 | 預估時數 |
|------|-------|-----------------|
| 第 1-2 天 | 模組 1：EdgeAI 基礎 | 6 小時 |
| 第 3-4 天 | 模組 2：SLM 基礎 | 8 小時 |
| 第 5-6 天 | 模組 3：SLM 部署 | 6 小時 |

### 兼職學習（三週）

| 週數 | 學習重點 | 預估時數 |
|------|-------|-----------------|
| 第一週 | 模組 1：EdgeAI 基礎 | 6-7 小時 |
| 第二週 | 模組 2：SLM 基礎 | 7-8 小時 |
| 第三週 | 模組 3：SLM 部署 | 5-6 小時 |

## 模組 1：EdgeAI 基礎及轉型

### 主要學習目標

- 理解雲端 AI 與邊緣 AI 的差異
- 掌握資源受限環境的核心優化技術
- 分析 EdgeAI 技術的實際應用
- 設置 EdgeAI 專案的開發環境

### 學習重點區域

#### 第一節：EdgeAI 基礎
- **重點概念**：
  - 邊緣與雲端計算範式
  - 模型量化技術
  - 硬件加速選項（NPUs、GPUs、CPUs）
  - 隱私及安全優勢

- **補充材料**：
  - [TensorFlow Lite 文件](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文件](https://docs.edgeimpulse.com)

#### 第二節：實際案例研究
- **重點概念**：
  - Microsoft Phi & Mu 模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第三節：實際實作指南
- **重點概念**：
  - 開發環境設置
  - 量化及優化工具
  - EdgeAI 實作的評估方法

#### 第四節：邊緣部署硬件
- **重點概念**：
  - 硬件平台比較
  - 特定硬件的優化策略
  - 部署考量

### 自我評估問題

1. 比較雲端 AI 與邊緣 AI 的實作差異。
2. 解釋三種優化模型以進行邊緣部署的關鍵技術。
3. 在邊緣運行 AI 模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬件加速器（NPUs、GPUs、CPUs）如何影響 EdgeAI 部署。

### 實作練習

1. **快速環境設置**：配置基本開發環境及必要套件（30 分鐘）
2. **模型探索**：下載並檢視預訓練的小型語言模型（1 小時）
3. **基礎量化**：對小型模型進行簡單量化（1 小時）

## 模組 2：小型語言模型基礎

### 主要學習目標

- 理解不同 SLM 家族的架構原則
- 比較不同參數規模的模型能力
- 根據效率、能力及部署需求評估模型
- 辨識不同模型家族的適用場景

### 學習重點區域

#### 第一節：Microsoft Phi 模型家族
- **重點概念**：
  - 設計理念演變
  - 效率優先架構
  - 專業化能力

#### 第二節：Qwen 家族
- **重點概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第三節：Gemma 家族
- **重點概念**：
  - 研究驅動創新
  - 多模態能力
  - 移動優化

#### 第四節：BitNET 家族
- **重點概念**：
  - 1-bit 量化技術
  - 推理優化框架
  - 可持續性考量

#### 第五節：Microsoft Mu 模型
- **重點概念**：
  - 設備優先架構
  - 與 Windows 的系統整合
  - 隱私保護操作

#### 第六節：Phi-Silica
- **重點概念**：
  - NPU 優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較 Phi 和 Qwen 模型家族的架構方法。
2. 解釋 BitNET 的量化技術與傳統量化的不同之處。
3. Mu 模型在 Windows 整合方面的獨特優勢是什麼？
4. 描述 Phi-Silica 如何利用 NPU 硬件進行性能優化。
5. 對於有限連接的移動應用，哪個模型家族最適合？為什麼？

### 實作練習

1. **模型比較**：快速對比兩個不同的 SLM 模型（1 小時）
2. **簡單文本生成**：使用小型模型進行基礎文本生成（1 小時）
3. **快速優化**：應用一種優化技術以提升推理速度（1 小時）

## 模組 3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地及雲端環境中實作 SLM
- 設計適合生產的 EdgeAI 應用配置

### 學習重點區域

#### 第一節：SLM 高級學習
- **重點概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第二節：本地環境部署
- **重點概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第三節：容器化雲端部署
- **重點概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實作

### 自我評估問題

1. 選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 邊緣部署 SLM 的關鍵性能指標是什麼？
5. 描述從模型選擇到生產實作的完整部署工作流程。

### 實作練習

1. **基礎本地部署**：使用 Ollama 部署簡單的 SLM（1 小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30 分鐘）
3. **簡單整合**：創建一個使用已部署模型的最小應用程式（1 小時）

## 模組 4：模型格式轉換及量化

### 主要學習目標

- 掌握從 1-bit 到 8-bit 精度的高級量化技術
- 理解格式轉換策略（GGUF、ONNX）
- 在六個框架中實作優化（Llama.cpp、Olive、OpenVINO、MLX、工作流程綜合）
- 部署優化模型至 Intel、Apple 及跨平台硬件的生產邊緣環境

### 學習重點區域

#### 第一節：量化基礎
- **重點概念**：
  - 精度分類框架
  - 性能與準確性權衡
  - 記憶體占用優化

#### 第二節：Llama.cpp 實作
- **重點概念**：
  - 跨平台部署
  - GGUF 格式優化
  - 硬件加速技術

#### 第三節：Microsoft Olive 套件
- **重點概念**：
  - 硬件感知優化
  - 企業級部署
  - 自動化優化工作流程

#### 第四節：OpenVINO 工具包
- **重點概念**：
  - Intel 硬件優化
  - 神經網絡壓縮框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI 用於 LLM 部署

#### 第五節：Apple MLX 框架
- **重點概念**：
  - Apple Silicon 優化
  - 統一記憶體架構
  - LoRA 微調能力

#### 第六節：Edge AI 開發工作流程綜合
- **重點概念**：
  - 統一工作流程架構
- 框架選擇決策樹  
- 生產準備驗證  
- 未來適應策略  

### 自我評估問題  

1. 比較不同精度級別（1-bit到8-bit）的量化策略。  
2. 解釋GGUF格式在邊緣部署中的優勢。  
3. 微軟Olive的硬件感知優化如何提升部署效率？  
4. OpenVINO的NNCF在模型壓縮方面的主要優勢是什麼？  
5. 描述Apple MLX如何利用統一記憶體架構進行優化。  
6. 工作流程合成如何幫助選擇最佳的優化框架？  

### 實作練習  

1. **模型量化**：對模型應用不同的量化級別並比較結果（1小時）  
2. **OpenVINO優化**：使用NNCF壓縮模型以適配Intel硬件（1小時）  
3. **框架比較**：在三個不同的優化框架中測試同一模型（1小時）  
4. **性能基準測試**：測量優化對推理速度和記憶體使用的影響（1小時）  

## 模組5：SLMOps - 小型語言模型操作  

### 主要學習目標  

- 理解SLMOps生命周期管理原則  
- 掌握邊緣部署的蒸餾和微調技術  
- 實施具有監控功能的生產部署策略  
- 建立企業級SLM操作和維護工作流程  

### 學習重點領域  

#### 第一部分：SLMOps簡介  
- **優先概念**：  
  - SLMOps在AI操作中的範式轉變  
  - 成本效益和隱私優先架構  
  - 戰略商業影響和競爭優勢  

#### 第二部分：模型蒸餾  
- **優先概念**：  
  - 知識轉移技術  
  - 兩階段蒸餾過程的實施  
  - Azure ML蒸餾工作流程  

#### 第三部分：微調策略  
- **優先概念**：  
  - 參數高效微調（PEFT）  
  - LoRA和QLoRA的高級方法  
  - 多適配器訓練和超參數優化  

#### 第四部分：生產部署  
- **優先概念**：  
  - 生產模型轉換和量化  
  - Foundry Local部署配置  
  - 性能基準測試和質量驗證  

### 自我評估問題  

1. SLMOps與傳統MLOps有何不同？  
2. 解釋模型蒸餾對邊緣部署的好處。  
3. 在資源受限環境中微調SLM的主要考量是什麼？  
4. 描述邊緣AI應用的完整生產部署管道。  

### 實作練習  

1. **基礎蒸餾**：從較大的教師模型創建較小的模型（1小時）  
2. **微調實驗**：針對特定領域微調模型（1小時）  
3. **部署管道**：設置基本的CI/CD管道以進行模型部署（1小時）  

## 模組6：SLM代理系統 - AI代理和函數調用  

### 主要學習目標  

- 使用小型語言模型構建適用於邊緣環境的智能AI代理  
- 實施具有系統化工作流程的函數調用功能  
- 掌握模型上下文協議（MCP）集成以標準化工具交互  
- 創建高級代理系統，減少人工干預  

### 學習重點領域  

#### 第一部分：AI代理和SLM基礎  
- **優先概念**：  
  - 代理分類框架（反射型、基於模型、基於目標、學習型代理）  
  - SLM與LLM的權衡分析  
  - 邊緣特定代理設計模式  
  - 代理的資源優化  

#### 第二部分：小型語言模型中的函數調用  
- **優先概念**：  
  - 系統化工作流程實施（意圖檢測、JSON輸出、外部執行）  
  - 平台特定實施（Phi-4-mini、選定的Qwen模型、Microsoft Foundry Local）  
  - 高級示例（多代理協作、動態工具選擇）  
  - 生產考量（速率限制、審計記錄、安全措施）  

#### 第三部分：模型上下文協議（MCP）集成  
- **優先概念**：  
  - 協議架構和分層系統設計  
  - 多後端支持（Ollama用於開發，vLLM用於生產）  
  - 連接協議（STDIO和SSE模式）  
  - 實際應用（網頁自動化、數據處理、API集成）  

### 自我評估問題  

1. 邊緣AI代理的主要架構考量是什麼？  
2. 函數調用如何增強代理功能？  
3. 解釋模型上下文協議在代理通信中的作用。  

### 實作練習  

1. **簡單代理**：構建具有函數調用功能的基本AI代理（1小時）  
2. **MCP集成**：在代理應用中實施MCP（30分鐘）  

## 模組7：邊緣AI實施範例  

### 主要學習目標  

- 掌握Visual Studio Code的AI工具包以進行全面的邊緣AI開發工作流程  
- 精通Windows AI Foundry平台和NPU優化策略  
- 在多個硬件平台和部署場景中實施邊緣AI  
- 使用平台特定的優化構建生產就緒的邊緣AI應用  

### 學習重點領域  

#### 第一部分：Visual Studio Code的AI工具包  
- **優先概念**：  
  - 在VS Code中全面的邊緣AI開發環境  
  - 用於邊緣部署的模型目錄和發現  
  - 本地測試、優化和代理開發工作流程  
  - 邊緣場景的性能監控和評估  

#### 第二部分：Windows邊緣AI開發指南  
- **優先概念**：  
  - Windows AI Foundry平台全面概述  
  - Phi Silica API用於高效NPU推理  
  - 用於圖像處理和OCR的計算機視覺API  
  - Foundry Local CLI用於本地開發和測試  

#### 第三部分：平台特定實施  
- **優先概念**：  
  - NVIDIA Jetson Orin Nano部署（67 TOPS AI性能）  
  - 使用.NET MAUI和ONNX Runtime GenAI的移動應用  
  - Azure邊緣AI解決方案與雲-邊緣混合架構  
  - Windows ML優化與通用硬件支持  
  - Foundry Local應用與隱私聚焦的RAG實施  

### 自我評估問題  

1. AI工具包如何簡化邊緣AI開發工作流程？  
2. 比較不同硬件平台的部署策略。  
3. Windows AI Foundry在邊緣開發中的優勢是什麼？  
4. NPU優化在現代邊緣AI應用中的作用是什麼？  
5. Phi Silica API如何利用NPU硬件進行性能優化？  
6. 比較本地部署與雲端部署在隱私敏感應用中的優勢。  

### 實作練習  

1. **AI工具包設置**：配置AI工具包並優化模型（1小時）  
2. **Windows AI Foundry**：使用Phi Silica API構建簡單的Windows AI應用（1小時）  
3. **跨平台部署**：在兩個不同平台上部署同一模型（1小時）  
4. **NPU優化**：使用Windows AI Foundry工具測試NPU性能（30分鐘）  

## 時間分配指南  

為幫助您充分利用20小時的課程時間，以下是建議的時間分配：  

| 活動 | 時間分配 | 描述 |  
|------|----------|------|  
| 閱讀核心材料 | 9小時 | 專注於每個模組中的基本概念 |  
| 實作練習 | 6小時 | 關鍵技術的實際應用 |  
| 自我評估 | 2小時 | 通過問題和反思測試您的理解 |  
| 小型專案 | 3小時 | 將知識應用於小型實際實施 |  

### 根據時間限制的重點領域  

**如果您只有10小時：**  
- 完成模組1、2和3（核心邊緣AI概念）  
- 每個模組至少完成一個實作練習  
- 專注於理解核心概念而非實施細節  

**如果您可以投入完整的20小時：**  
- 完成所有七個模組  
- 執行每個模組的關鍵實作練習  
- 完成模組7中的一個小型專案  
- 探索至少2-3個補充資源  

**如果您有超過20小時：**  
- 詳細完成所有模組和練習  
- 建立多個小型專案  
- 探索模組4中的高級優化技術  
- 實施模組5中的生產部署  

## 必備資源  

以下精選資源能為您的有限學習時間提供最大價值：  

### 必讀文檔  
- [ONNX Runtime入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型優化工具  
- [Ollama快速入門](https://github.com/ollama/ollama#get-started) - 最快的本地部署SLM方法  
- [Microsoft Phi模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考  
- [OpenVINO文檔](https://docs.openvino.ai/2025/index.html) - Intel的全面優化工具包  
- [VS Code的AI工具包](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成的邊緣AI開發環境  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows特定的邊緣AI開發平台  

### 節省時間的工具  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速模型訪問和部署  
- [Gradio](https://www.gradio.app/docs/interface) - 快速開發AI演示的UI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化模型優化  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的CPU推理  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網絡壓縮框架  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包  

## 進度追蹤模板  

使用此簡化模板追蹤您在20小時課程中的學習進度：  

| 模組 | 完成日期 | 花費時間 | 主要收穫 |  
|------|----------|----------|----------|  
| 模組1：邊緣AI基礎 | | | |  
| 模組2：SLM基礎 | | | |  
| 模組3：SLM部署 | | | |  
| 模組4：模型優化 | | | |  
| 模組5：SLMOps | | | |  
| 模組6：AI代理 | | | |  
| 模組7：開發工具 | | | |  
| 實作練習 | | | |  
| 小型專案 | | | |  

## 小型專案構想  

考慮完成以下專案以練習邊緣AI概念（每個設計為2-4小時）：  

### 初學者專案（2-3小時）  
1. **邊緣文本助手**：使用小型語言模型創建簡單的離線文本補全工具  
2. **模型比較儀表板**：構建基本的性能指標可視化工具以比較不同SLM  
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響  

### 中級專案（3-4小時）  
4. **AI工具包工作流程**：使用VS Code AI工具包從頭到尾優化並部署模型  
5. **Windows AI Foundry應用**：使用Phi Silica API和NPU優化創建Windows應用  
6. **跨平台部署**：在Windows（OpenVINO）和移動端（.NET MAUI）部署同一優化模型  
7. **函數調用代理**：構建具有函數調用功能的AI代理以適配邊緣場景  

### 高級集成專案（4-5小時）  
8. **OpenVINO優化管道**：使用NNCF和GenAI工具包實施完整的模型優化  
9. **SLMOps管道**：實施完整的模型生命周期，從訓練到邊緣部署  
10. **多模型邊緣系統**：在邊緣硬件上部署多個專用模型協同工作  
11. **MCP集成系統**：使用模型上下文協議構建代理系統以進行工具交互  

## 學習社群  

加入討論並與其他學習者交流：  
- [EdgeAI for Beginners GitHub討論區](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft技術社群](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## 結論  

邊緣AI代表了人工智能實施的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等關鍵問題。本20小時課程為您提供了必要的知識和實際技能，讓您能立即開始使用邊緣AI技術。  

課程內容精簡且專注於最重要的概念，讓您能快速獲得有價值的專業知識，而不會感到時間壓力。請記住，即使是簡單的實作練習，也能有效鞏固您的學習成果。  

祝您學習愉快！  

---

**免責聲明**：  
本文件已使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們致力於提供準確的翻譯，請注意自動翻譯可能包含錯誤或不準確之處。原始語言的文件應被視為權威來源。對於重要資訊，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋概不負責。