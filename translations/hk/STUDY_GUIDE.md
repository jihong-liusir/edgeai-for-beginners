<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3f8ec059920a41b354c806f312b6ee24",
  "translation_date": "2025-09-26T07:51:07+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "hk"
}
-->
# EdgeAI 初學者指南：學習路徑與學習計劃

### 集中學習路徑（一週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第2天 | 模組2：SLM 基礎 | 3小時 |
| 第3天 | 模組3：SLM 部署 | 2小時 |
| 第4-5天 | 模組4：模型優化（6個框架） | 4小時 |
| 第6天 | 模組5：SLMOps | 3小時 |
| 第7天 | 模組6-7：AI代理與開發工具 | 4小時 |
| 第8天 | 模組8：Foundry Local 工具包（現代實現） | 1小時 |

### 集中學習路徑（兩週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：AI代理 | 2小時 |
| 第13-14天 | 模組7：開發工具 | 3小時 |

### 兼職學習（四週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI 基礎 | 3小時 |
| 第3-4天 | 模組2：SLM 基礎 | 3小時 |
| 第5-6天 | 模組3：SLM 部署 | 2小時 |
| 第7-8天 | 模組4：模型優化 | 4小時 |
| 第9-10天 | 模組5：SLMOps | 3小時 |
| 第11-12天 | 模組6：SLM代理系統 | 2小時 |
| 第13-14天 | 模組7：EdgeAI 實現範例 | 2小時 |

| 模組 | 完成日期 | 花費時數 | 主要收穫 |
|--------|----------------|-------------|--------------|
| 模組0：EdgeAI 簡介 | | | |
| 模組1：EdgeAI 基礎 | | | |
| 模組2：SLM 基礎 | | | |
| 模組3：SLM 部署 | | | |
| 模組4：模型優化（6個框架） | | | |
| 模組5：SLMOps | | | |
| 模組6：SLM代理系統 | | | |
| 模組7：EdgeAI 實現範例 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

### 兼職學習（四週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組1-2：基礎與SLM基礎 | 6小時 |
| 第2週 | 模組3-4：部署與優化 | 6小時 |
| 第3週 | 模組5-6：SLMOps與AI代理 | 5小時 |
| 第4週 | 模組7：開發工具與整合 | 3小時 |

## 簡介

歡迎使用《EdgeAI 初學者指南》！本文件旨在幫助您有效地學習課程內容，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習計劃、關鍵概念摘要以及補充資源，幫助您深入了解EdgeAI技術。

這是一門精簡的20小時課程，旨在以高效的方式傳授EdgeAI的基本知識，非常適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概述

本課程分為八個全面的模組：

0. **EdgeAI 簡介** - 建立基礎並提供行業應用和學習目標
1. **EdgeAI 基礎與轉型** - 理解核心概念和技術變革
2. **小型語言模型（SLM）基礎** - 探索各種SLM家族及其架構
3. **小型語言模型部署** - 實現實際部署策略
4. **模型格式轉換與量化** - 使用包括OpenVINO在內的6個框架進行高級優化
5. **SLMOps - 小型語言模型運營** - 生產生命周期管理與部署
6. **SLM代理系統** - AI代理、函數調用與模型上下文協議
7. **EdgeAI 實現範例** - AI工具包、Windows開發與平台特定實現
8. **Microsoft Foundry Local – 完整開發工具包** - 本地優先開發與混合Azure整合（模組08）

## 如何使用本學習指南

- **循序漸進學習**：按順序學習模組以獲得最連貫的學習體驗
- **知識檢查點**：使用每節後的自我評估問題
- **實作練習**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習計劃建議

### 集中學習路徑（一週）

| 天數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第0天 | 模組0：EdgeAI 簡介 | 1-2小時 |
| 第1-2天 | 模組1：EdgeAI 基礎 | 6小時 |
| 第3-4天 | 模組2：SLM 基礎 | 8小時 |
| 第5天 | 模組3：SLM 部署 | 3小時 |
| 第6天 | 模組8：Foundry Local 工具包 | 3小時 |

### 兼職學習（三週）

| 週數 | 重點 | 預估時數 |
|------|-------|------------------|
| 第1週 | 模組0：簡介 + 模組1：EdgeAI 基礎 | 7-9小時 |
| 第2週 | 模組2：SLM 基礎 | 7-8小時 |
| 第3週 | 模組3：SLM 部署（3小時）+ 模組8：Foundry Local 工具包（2-3小時） | 5-6小時 |

## 模組0：EdgeAI 簡介

### 主要學習目標

- 理解什麼是EdgeAI以及它在當今技術中的重要性
- 識別被EdgeAI改變的主要行業及其具體應用案例
- 理解小型語言模型（SLM）在邊緣部署中的優勢
- 為整個課程建立清晰的學習期望和成果
- 認識EdgeAI領域的職業機會和技能需求

### 學習重點區域

#### 第1節：EdgeAI 範式與定義
- **重點概念**：
  - EdgeAI與傳統雲端AI處理的區別
  - 硬件、模型優化與商業需求的融合
  - 實時、隱私保護與成本效益的AI部署

#### 第2節：行業應用
- **重點概念**：
  - 製造業與工業4.0：預測性維護與質量控制
  - 醫療保健：診斷影像與患者監測
  - 自主系統：自駕車與交通運輸
  - 智慧城市：交通管理與公共安全
  - 消費技術：智能手機、穿戴設備與智能家居

#### 第3節：小型語言模型基礎
- **重點概念**：
  - SLM特性與性能比較
  - 參數效率與能力的權衡
  - 邊緣部署限制與優化策略

#### 第4節：學習框架與職業路徑
- **重點概念**：
  - 課程架構與循序漸進的掌握方法
  - 技術技能與實際實現目標
  - 職業發展機會與行業應用

### 自我評估問題

1. 哪三個主要技術趨勢促成了EdgeAI的發展？
2. 比較EdgeAI與基於雲端的AI的優勢與挑戰。
3. 列舉三個EdgeAI提供重要商業價值的行業並解釋原因。
4. 小型語言模型如何使EdgeAI在實際部署中更具可行性？
5. 在整個課程中您將學到哪些關鍵技術技能？
6. 描述本課程使用的四階段學習方法。

### 實作練習

1. **行業研究**：選擇一個行業應用並研究一個真實的EdgeAI實現案例（30分鐘）
2. **模型探索**：瀏覽Hugging Face上的小型語言模型並比較其參數數量與能力（30分鐘）
3. **學習計劃**：審查完整課程結構並制定個人學習計劃（15分鐘）

### 補充材料

- [Edge AI 市場概述 - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [小型語言模型概述 - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Edge Computing Foundation](https://www.edgecomputing.org/)

## 模組1：EdgeAI 基礎與轉型

### 主要學習目標

- 理解基於雲端與基於邊緣的AI的差異
- 掌握資源受限環境的核心優化技術
- 分析EdgeAI技術的真實應用案例
- 設置EdgeAI項目的開發環境

### 學習重點區域

#### 第1節：EdgeAI 基礎
- **重點概念**：
  - 邊緣與雲端計算範式
  - 模型量化技術
  - 硬件加速選項（NPU、GPU、CPU）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文檔](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文檔](https://docs.edgeimpulse.com)

#### 第2節：真實案例研究
- **重點概念**：
  - Microsoft Phi & Mu 模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第3節：實際實現指南
- **重點概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI實現的評估方法

#### 第4節：邊緣部署硬件
- **重點概念**：
  - 硬件平台比較
  - 特定硬件的優化策略
  - 部署考量

### 自我評估問題

1. 比較基於雲端的AI與基於邊緣的AI實現。
2. 解釋三種優化模型以進行邊緣部署的關鍵技術。
3. 在邊緣運行AI模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬件加速器（NPU、GPU、CPU）如何影響EdgeAI部署。

### 實作練習

1. **快速環境設置**：配置一個包含基本套件的最小開發環境（30分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1小時）
3. **基本量化**：嘗試對一個小型模型進行簡單量化（1小時）

## 模組2：小型語言模型基礎

### 主要學習目標

- 理解不同SLM家族的架構原則
- 比較不同參數規模模型的能力
- 根據效率、能力和部署需求評估模型
- 識別不同模型家族的適用場景

### 學習重點區域

#### 第1節：Microsoft Phi 模型家族
- **重點概念**：
  - 設計理念演變
  - 效率優先架構
  - 專業化能力

#### 第2節：Qwen 家族
- **重點概念**：
  - 開源貢獻
  - 可擴展部署選項
  - 高級推理架構

#### 第3節：Gemma 家族
- **重點概念**：
  - 研究驅動創新
  - 多模態能力
  - 移動優化

#### 第4節：BitNET 家族
- **重點概念**：
  - 1-bit量化技術
  - 推理優化框架
  - 可持續性考量

#### 第5節：Microsoft Mu 模型
- **重點概念**：
  - 設備優先架構
  - 與Windows的系統整合
  - 隱私保護操作

#### 第6節：Phi-Silica
- **重點概念**：
  - NPU優化架構
  - 性能指標
  - 開發者整合

### 自我評估問題

1. 比較Phi與Qwen模型家族的架構方法。
2. 解釋BitNET的量化技術如何與傳統量化技術不同。
3. Mu 模型在 Windows 整合方面有什麼獨特優勢？
4. Phi-Silica 如何利用 NPU 硬件進行性能優化？
5. 對於一個連接有限的移動應用程式，哪個模型系列最適合？為什麼？

### 實作練習

1. **模型比較**：快速對比兩個不同的 SLM 模型（1小時）
2. **簡單文本生成**：使用小型模型進行基本文本生成實作（1小時）
3. **快速優化**：應用一種優化技術以提升推理速度（1小時）

## 模組 3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實作 SLM
- 設計適用於 EdgeAI 應用的生產級配置

### 學習重點領域

#### 第一部分：SLM 高階學習
- **優先概念**：
  - 參數分類框架
  - 高階優化技術
  - 模型獲取策略

#### 第二部分：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第三部分：容器化雲端部署
- **優先概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實作

### 自我評估問題

1. 選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 邊緣部署的 SLM 需要監控哪些關鍵性能指標？
5. 描述從模型選擇到生產實作的完整部署工作流程。

### 實作練習

1. **基本本地部署**：使用 Ollama 部署一個簡單的 SLM（1小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30分鐘）
3. **簡單整合**：創建一個使用已部署模型的簡易應用程式（1小時）

## 模組 4：模型格式轉換與量化

### 主要學習目標

- 掌握從 1-bit 到 8-bit 精度的高階量化技術
- 理解格式轉換策略（GGUF、ONNX）
- 在六個框架中實作優化（Llama.cpp、Olive、OpenVINO、MLX、工作流程綜合）
- 為 Intel、Apple 和跨平台硬件部署生產級優化模型

### 學習重點領域

#### 第一部分：量化基礎
- **優先概念**：
  - 精度分類框架
  - 性能與準確性權衡
  - 記憶體占用優化

#### 第二部分：Llama.cpp 實作
- **優先概念**：
  - 跨平台部署
  - GGUF 格式優化
  - 硬件加速技術

#### 第三部分：Microsoft Olive 套件
- **優先概念**：
  - 硬件感知優化
  - 企業級部署
  - 自動化優化工作流程

#### 第四部分：OpenVINO 工具包
- **優先概念**：
  - Intel 硬件優化
  - 神經網絡壓縮框架（NNCF）
  - 跨平台推理部署
  - OpenVINO GenAI 用於 LLM 部署

#### 第五部分：Apple MLX 框架
- **優先概念**：
  - Apple Silicon 優化
  - 統一記憶體架構
  - LoRA 微調能力

#### 第六部分：Edge AI 開發工作流程綜合
- **優先概念**：
  - 統一工作流程架構
  - 框架選擇決策樹
  - 生產準備驗證
  - 未來適應性策略

### 自我評估問題

1. 比較不同精度級別（1-bit 到 8-bit）的量化策略。
2. 解釋 GGUF 格式在邊緣部署中的優勢。
3. Microsoft Olive 的硬件感知優化如何提升部署效率？
4. OpenVINO 的 NNCF 在模型壓縮方面有什麼主要優勢？
5. 描述 Apple MLX 如何利用統一記憶體架構進行優化。
6. 工作流程綜合如何幫助選擇最佳優化框架？

### 實作練習

1. **模型量化**：對模型應用不同量化級別並比較結果（1小時）
2. **OpenVINO 優化**：使用 NNCF 壓縮模型以適配 Intel 硬件（1小時）
3. **框架比較**：在三個不同的優化框架中測試同一模型（1小時）
4. **性能基準測試**：測量優化對推理速度和記憶體使用的影響（1小時）

## 模組 5：SLMOps - 小型語言模型運營

### 主要學習目標

- 理解 SLMOps 生命周期管理原則
- 掌握邊緣部署的蒸餾和微調技術
- 實作具有監控功能的生產部署策略
- 建立企業級 SLM 運營和維護工作流程

### 學習重點領域

#### 第一部分：SLMOps 簡介
- **優先概念**：
  - SLMOps 在 AI 運營中的範式轉變
  - 成本效率與隱私優先架構
  - 戰略商業影響與競爭優勢

#### 第二部分：模型蒸餾
- **優先概念**：
  - 知識轉移技術
  - 雙階段蒸餾流程實作
  - Azure ML 蒸餾工作流程

#### 第三部分：微調策略
- **優先概念**：
  - 參數高效微調（PEFT）
  - LoRA 和 QLoRA 高階方法
  - 多適配器訓練與超參數優化

#### 第四部分：生產部署
- **優先概念**：
  - 生產級模型轉換與量化
  - Foundry Local 部署配置
  - 性能基準測試與質量驗證

### 自我評估問題

1. SLMOps 與傳統 MLOps 有何不同？
2. 解釋模型蒸餾對邊緣部署的好處。
3. 在資源有限的環境中微調 SLM 時需要考慮哪些關鍵因素？
4. 描述邊緣 AI 應用的完整生產部署管道。

### 實作練習

1. **基本蒸餾**：從較大的教師模型創建一個較小的模型（1小時）
2. **微調實驗**：針對特定領域微調模型（1小時）
3. **部署管道**：設置一個基本的 CI/CD 管道以進行模型部署（1小時）

## 模組 6：SLM Agentic 系統 - AI 代理與功能調用

### 主要學習目標

- 使用小型語言模型構建適用於邊緣環境的智能 AI 代理
- 實作具有系統化工作流程的功能調用能力
- 掌握模型上下文協議（MCP）整合以標準化工具交互
- 創建高級代理系統，減少人為干預

### 學習重點領域

#### 第一部分：AI 代理與 SLM 基礎
- **優先概念**：
  - 代理分類框架（反射型、基於模型、基於目標、學習型代理）
  - SLM 與 LLM 的權衡分析
  - 邊緣特定代理設計模式
  - 代理資源優化

#### 第二部分：小型語言模型中的功能調用
- **優先概念**：
  - 系統化工作流程實作（意圖檢測、JSON 輸出、外部執行）
  - 平台特定實作（Phi-4-mini、選定的 Qwen 模型、Microsoft Foundry Local）
  - 高階範例（多代理協作、動態工具選擇）
  - 生產考量（速率限制、審計記錄、安全措施）

#### 第三部分：模型上下文協議（MCP）整合
- **優先概念**：
  - 協議架構與分層系統設計
  - 多後端支持（Ollama 用於開發，vLLM 用於生產）
  - 連接協議（STDIO 和 SSE 模式）
  - 實際應用（網頁自動化、數據處理、API 整合）

### 自我評估問題

1. 邊緣 AI 代理的關鍵架構考量是什麼？
2. 功能調用如何增強代理能力？
3. 解釋模型上下文協議在代理通信中的角色。

### 實作練習

1. **簡單代理**：構建一個具有功能調用的基本 AI 代理（1小時）
2. **MCP 整合**：在代理應用中實作 MCP（30分鐘）

## 模組 7：EdgeAI 實作範例

### 主要學習目標

- 掌握 Visual Studio Code 的 AI 工具包以進行全面的 EdgeAI 開發工作流程
- 熟悉 Windows AI Foundry 平台與 NPU 優化策略
- 在多個硬件平台和部署場景中實作 EdgeAI
- 構建生產級 EdgeAI 應用，並進行平台特定優化

### 學習重點領域

#### 第一部分：Visual Studio Code 的 AI 工具包
- **優先概念**：
  - 在 VS Code 中進行全面的 Edge AI 開發環境
  - 用於邊緣部署的模型目錄與發現
  - 本地測試、優化與代理開發工作流程
  - 邊緣場景的性能監控與評估

#### 第二部分：Windows EdgeAI 開發指南
- **優先概念**：
  - Windows AI Foundry 平台全面概述
  - Phi Silica API 用於高效 NPU 推理
  - 用於圖像處理和 OCR 的計算機視覺 API
  - Foundry Local CLI 用於本地開發與測試

#### 第三部分：平台特定實作
- **優先概念**：
  - NVIDIA Jetson Orin Nano 部署（67 TOPS AI 性能）
  - 使用 .NET MAUI 和 ONNX Runtime GenAI 的移動應用程式
  - Azure EdgeAI 解決方案與雲端-邊緣混合架構
  - Windows ML 優化與通用硬件支持
  - Foundry Local 應用與隱私聚焦的 RAG 實作

### 自我評估問題

1. AI 工具包如何簡化 EdgeAI 的開發工作流程？
2. 比較不同硬件平台的部署策略。
3. Windows AI Foundry 在邊緣開發方面有什麼優勢？
4. 解釋 NPU 優化在現代邊緣 AI 應用中的角色。
5. Phi Silica API 如何利用 NPU 硬件進行性能優化？
6. 比較本地與雲端部署在隱私敏感應用中的優勢。

### 實作練習

1. **AI 工具包設置**：配置 AI 工具包並優化模型（1小時）
2. **Windows AI Foundry**：使用 Phi Silica API 構建簡單的 Windows AI 應用（1小時）
3. **跨平台部署**：在兩個不同平台上部署同一模型（1小時）
4. **NPU 優化**：使用 Windows AI Foundry 工具測試 NPU 性能（30分鐘）

## 模組 8：Microsoft Foundry Local – 完整開發者工具包（現代化）

### 主要學習目標

- 安裝並配置 Foundry Local，整合現代 SDK
- 實作具有協調模式的高階多代理系統
- 構建具有自動任務選擇的智能模型路由器
- 部署具有全面監控功能的生產級 AI 解決方案
- 整合 Azure AI Foundry 以進行混合部署場景
- 掌握 FoundryLocalManager 和 OpenAI 客戶端的現代 SDK 模式

### 學習重點領域

#### 第一部分：現代化安裝與配置
- **優先概念**：
  - FoundryLocalManager SDK 整合
  - 自動服務發現與健康監控
  - 基於環境的配置模式
  - 生產部署考量

#### 第二部分：高階多代理系統
- **優先概念**：
  - 協調模式與專家代理
  - 檢索、推理與執行代理專業化
  - 反饋循環機制以進行改進
  - 性能監控與統計追蹤

#### 第三部分：智能模型路由
- **優先概念**：
  - 基於關鍵字的模型選擇算法
  - 多模型支持（通用、推理、代碼、創意）
  - 環境變數配置的靈活性
  - 服務健康檢查與錯誤處理

#### 第四部分：生產級實作
- **優先概念**：
  - 全面的錯誤處理與回退機制
  - 請求監控與性能追蹤
  - 交互式 Jupyter notebook 範例與基準測試
  - 與現有應用的整合模式

### 自我評估問題

1. 現代化的 FoundryLocalManager 方法與手動 REST 調用有何不同？
2. 解釋協調模式如何協作專家代理。
3. 智能路由器如何根據查詢內容選擇合適的模型？
4. 生產級 AI 代理系統的關鍵組成部分是什麼？
5. 如何為 Foundry Local 服務實作全面的健康監控？
6. 比較現代化方法與傳統實作模式的優勢。

### 實作練習

1. **現代 SDK 設置**：配置 FoundryLocalManager 並進行自動服務發現（30分鐘）
2. **多代理系統**：運行具有專家代理的高階協調器（30分鐘）
3. **智能路由**：使用不同查詢類型測試模型路由器（30分鐘）
4. **交互式探索**：使用 Jupyter notebook 探索高階功能（45分鐘）
5. **生產部署**：實作監控與錯誤處理模式（30分鐘）
6. **混合整合**：配置 Azure AI Foundry 回退場景（30分鐘）

## 時間分配指南

為幫助您充分利用 20 小時的課程時間，以下是建議的時間分配：

| 活動 | 時間分配 | 描述 |
|------|----------|------|
| 閱讀核心材料 | 9小時 | 專注於每個模組中的基本概念 |
| 實作練習 | 6 小時 | 實際應用核心技術 |
| 自我評估 | 2 小時 | 通過問題和反思測試你的理解 |
| 小型專案 | 3 小時 | 將知識應用於小型實作項目 |

### 根據時間限制的重點範疇

**如果你只有 10 小時：**
- 完成模組 0（簡介）以及模組 1、2 和 3（核心 EdgeAI 概念）
- 每個模組至少完成一個實作練習
- 專注於理解核心概念，而非實作細節

**如果你可以投入完整的 20 小時：**
- 完成所有八個模組（包括簡介）
- 每個模組完成關鍵的實作練習
- 完成模組 7 的一個小型專案
- 探索至少 2-3 個補充資源

**如果你有超過 20 小時：**
- 詳細完成所有模組（包括簡介）及其練習
- 建立多個小型專案
- 探索模組 4 的高級優化技術
- 實作模組 5 的生產部署

## 必備資源

以下精選資源能在有限的學習時間內提供最大價值：

### 必讀文件
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - 最有效的模型優化工具
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - 本地部署 SLM 的最快方法
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intel 的全面優化工具包
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - 集成的 EdgeAI 開發環境
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows 專屬的 EdgeAI 開發平台

### 節省時間的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速獲取和部署模型
- [Gradio](https://www.gradio.app/docs/interface) - 快速開發 AI 演示的 UI
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化模型優化
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - 高效的 CPU 推理
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - 神經網絡壓縮框架
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - 大型語言模型部署工具包

## 進度追蹤模板

使用此簡化模板追蹤你在 20 小時課程中的學習進度：

| 模組 | 完成日期 | 花費時間 | 主要收穫 |
|------|----------|----------|----------|
| 模組 0：EdgeAI 簡介 | | | |
| 模組 1：EdgeAI 基礎 | | | |
| 模組 2：SLM 基礎 | | | |
| 模組 3：SLM 部署 | | | |
| 模組 4：模型優化 | | | |
| 模組 5：SLMOps | | | |
| 模組 6：AI Agents | | | |
| 模組 7：開發工具 | | | |
| 模組 8：Foundry 本地工具包 | | | |
| 實作練習 | | | |
| 小型專案 | | | |

## 小型專案建議

考慮完成以下專案以練習 EdgeAI 概念（每個設計需時 2-4 小時）：

### 初學者專案（每個 2-3 小時）
1. **邊緣文字助手**：使用小型語言模型創建簡單的離線文字補全工具
2. **模型比較儀表板**：建立基本的可視化工具，展示不同 SLM 的性能指標
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響

### 中級專案（每個 3-4 小時）
4. **AI 工具包工作流程**：使用 VS Code AI 工具包從頭到尾優化並部署模型
5. **Windows AI Foundry 應用**：使用 Phi Silica API 和 NPU 優化創建 Windows 應用
6. **跨平台部署**：在 Windows（OpenVINO）和移動端（.NET MAUI）部署同一優化模型
7. **函數調用代理**：建立具有函數調用能力的 AI 代理，用於邊緣場景

### 高級整合專案（每個 4-5 小時）
8. **OpenVINO 優化管道**：使用 NNCF 和 GenAI 工具包實現完整的模型優化
9. **SLMOps 管道**：實現從訓練到邊緣部署的完整模型生命周期
10. **多模型邊緣系統**：在邊緣硬件上部署多個專用模型協同工作
11. **MCP 整合系統**：使用模型上下文協議構建工具交互的代理系統

## 參考資料

- Microsoft Learn (Foundry Local)
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - 入門：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI 參考：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - 與推理 SDK 整合：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - 開啟 WebUI 教學：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - 編譯 Hugging Face 模型：https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - 概述：https://learn.microsoft.com/en-us/azure/ai-foundry/
  - 代理（概述）：https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- 優化與推理工具
  - Microsoft Olive（文件）：https://microsoft.github.io/Olive/
  - Microsoft Olive（GitHub）：https://github.com/microsoft/Olive
  - ONNX Runtime（入門）：https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive 整合：https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO（文件）：https://docs.openvino.ai/2025/index.html
  - Apple MLX（文件）：https://ml-explore.github.io/mlx/build/html/index.html
- 部署框架與模型
  - Llama.cpp：https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers：https://huggingface.co/docs/transformers/index
  - vLLM（文件）：https://docs.vllm.ai/
  - Ollama（快速入門）：https://github.com/ollama/ollama#get-started
- 開發工具（Windows 和 VS Code）
  - AI Toolkit for VS Code：https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML（概述）：https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## 學習社群

加入討論並與其他學員交流：
- [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions) 的 GitHub 討論
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

EdgeAI 代表人工智能實作的前沿技術，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等關鍵問題。本課程提供了 20 小時的核心知識和實作技能，讓你能立即開始使用 EdgeAI 技術。

課程內容精簡且專注於最重要的概念，讓你能快速獲得有價值的專業知識，而不需要投入過多時間。記住，即使是簡單的實作練習，也能有效鞏固你的學習成果。

祝學習愉快！

---

