<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "64b8bb9e3cb942191493b8348a05127b",
  "translation_date": "2025-07-22T02:49:41+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "hk"
}
-->
# 初學者的 EdgeAI：全面學習指南

## 簡介

歡迎來到《初學者的 EdgeAI 學習指南》！本文件旨在幫助您有效地瀏覽課程材料，並最大化您的學習體驗。它提供結構化的學習路徑、建議的學習時間表、關鍵概念摘要，以及補充資源以加深您對 EdgeAI 技術的理解。

這是一門精簡的 20 小時課程，能夠在有限的時間內傳授有關 EdgeAI 的基本知識，非常適合忙碌的專業人士和學生快速掌握這一新興領域的實用技能。

## 課程概覽

本課程分為三個主要模組：

1. **EdgeAI 基礎與轉型** - 理解核心概念與技術轉變
2. **小型語言模型基礎** - 探索各種模型家族及其架構
3. **小型語言模型部署** - 實現實際部署策略

## 如何使用本學習指南

- **循序漸進學習**：按順序學習模組，以獲得最連貫的學習體驗
- **知識檢查點**：在每個章節後使用自我評估問題
- **實踐操作**：完成建議的練習以鞏固理論概念
- **補充資源**：探索您最感興趣的主題的額外材料

## 學習時間表建議

### 集中學習路徑（1 週）

| 天數 | 重點 | 預估時數 |
|------|-------|----------|
| 第 1-2 天 | 模組 1：EdgeAI 基礎 | 6 小時 |
| 第 3-4 天 | 模組 2：SLM 基礎 | 8 小時 |
| 第 5-6 天 | 模組 3：SLM 部署 | 6 小時 |

### 兼職學習（3 週）

| 週數 | 重點 | 預估時數 |
|------|-------|----------|
| 第 1 週 | 模組 1：EdgeAI 基礎 | 6-7 小時 |
| 第 2 週 | 模組 2：SLM 基礎 | 7-8 小時 |
| 第 3 週 | 模組 3：SLM 部署 | 5-6 小時 |

## 模組 1：EdgeAI 基礎與轉型

### 主要學習目標

- 理解雲端 AI 與邊緣 AI 的差異
- 掌握資源受限環境的核心優化技術
- 分析 EdgeAI 技術的實際應用
- 設置 EdgeAI 項目的開發環境

### 學習重點區域

#### 第 1 節：EdgeAI 基礎
- **優先概念**：
  - 邊緣計算與雲端計算的範式
  - 模型量化技術
  - 硬件加速選項（NPU、GPU、CPU）
  - 隱私與安全優勢

- **補充材料**：
  - [TensorFlow Lite 文檔](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse 文檔](https://docs.edgeimpulse.com)

#### 第 2 節：實際案例研究
- **優先概念**：
  - Microsoft Phi & Mu 模型生態系統
  - 各行業的實際應用
  - 部署考量

#### 第 3 節：實踐實施指南
- **優先概念**：
  - 開發環境設置
  - 量化與優化工具
  - EdgeAI 實施的評估方法

#### 第 4 節：邊緣部署硬件
- **優先概念**：
  - 硬件平台比較
  - 特定硬件的優化策略
  - 部署考量

### 自我評估問題

1. 比較雲端 AI 與邊緣 AI 的實施差異。
2. 解釋三種關鍵技術以優化邊緣部署的模型。
3. 在邊緣運行 AI 模型的主要優勢是什麼？
4. 描述量化模型的過程及其對性能的影響。
5. 解釋不同硬件加速器（NPU、GPU、CPU）如何影響 EdgeAI 部署。

### 實踐練習

1. **快速環境設置**：配置一個包含基本套件的最小開發環境（30 分鐘）
2. **模型探索**：下載並檢查一個預訓練的小型語言模型（1 小時）
3. **基礎量化**：對一個小型模型進行簡單量化（1 小時）

## 模組 2：小型語言模型基礎

### 主要學習目標

- 理解不同 SLM 家族的架構原則
- 比較不同參數規模的模型能力
- 根據效率、能力和部署需求評估模型
- 辨識不同模型家族的適用場景

### 學習重點區域

#### 第 1 節：Microsoft Phi 模型家族
- **優先概念**：
  - 設計理念的演變
  - 以效率為先的架構
  - 專業化能力

#### 第 2 節：Qwen 家族
- **優先概念**：
  - 開源貢獻
  - 可擴展的部署選項
  - 高級推理架構

#### 第 3 節：Gemma 家族
- **優先概念**：
  - 以研究為驅動的創新
  - 多模態能力
  - 移動端優化

#### 第 4 節：BitNET 家族
- **優先概念**：
  - 1-bit 量化技術
  - 推理優化框架
  - 可持續性考量

#### 第 5 節：Microsoft Mu 模型
- **優先概念**：
  - 以設備為先的架構
  - 與 Windows 的系統集成
  - 隱私保護操作

#### 第 6 節：Phi-Silica
- **優先概念**：
  - NPU 優化架構
  - 性能指標
  - 開發者集成

### 自我評估問題

1. 比較 Phi 和 Qwen 模型家族的架構方法。
2. 解釋 BitNET 的量化技術與傳統量化的不同之處。
3. Mu 模型在 Windows 集成方面的獨特優勢是什麼？
4. 描述 Phi-Silica 如何利用 NPU 硬件進行性能優化。
5. 對於一個連接有限的移動應用，哪個模型家族最適合？為什麼？

### 實踐練習

1. **模型比較**：對兩個不同的 SLM 模型進行快速基準測試（1 小時）
2. **簡單文本生成**：使用一個小型模型實現基本的文本生成（1 小時）
3. **快速優化**：應用一種優化技術以提高推理速度（1 小時）

## 模組 3：小型語言模型部署

### 主要學習目標

- 根據部署限制選擇合適的模型
- 掌握各種部署場景的優化技術
- 在本地和雲端環境中實施 SLM
- 設計適合生產的 EdgeAI 應用配置

### 學習重點區域

#### 第 1 節：SLM 高級學習
- **優先概念**：
  - 參數分類框架
  - 高級優化技術
  - 模型獲取策略

#### 第 2 節：本地環境部署
- **優先概念**：
  - Ollama 平台部署
  - Microsoft Foundry 本地解決方案
  - 框架比較分析

#### 第 3 節：容器化雲端部署
- **優先概念**：
  - vLLM 高性能推理
  - 容器編排
  - ONNX Runtime 實施

### 自我評估問題

1. 選擇本地部署與雲端部署時應考慮哪些因素？
2. 比較 Ollama 和 Microsoft Foundry Local 作為部署選項。
3. 解釋容器化對 SLM 部署的好處。
4. 邊緣部署 SLM 的關鍵性能指標是什麼？
5. 描述從模型選擇到生產實施的完整部署工作流程。

### 實踐練習

1. **基礎本地部署**：使用 Ollama 部署一個簡單的 SLM（1 小時）
2. **性能檢查**：對已部署的模型進行快速基準測試（30 分鐘）
3. **簡單集成**：創建一個使用已部署模型的最小應用程序（1 小時）

## 時間分配指南

為幫助您充分利用 20 小時的課程時間，以下是建議的時間分配：

| 活動 | 時間分配 | 描述 |
|------|----------|------|
| 閱讀核心材料 | 9 小時 | 專注於每個模組的核心概念 |
| 實踐練習 | 6 小時 | 實踐關鍵技術 |
| 自我評估 | 2 小時 | 通過問題和反思測試您的理解 |
| 小型項目 | 3 小時 | 將知識應用於小型實踐實施 |

### 根據時間限制的重點區域

**如果您只有 10 小時：**
- 完成模組 1 和模組 2 的前半部分
- 每個模組至少完成一個實踐練習
- 專注於理解核心概念，而非實施細節

**如果您可以投入完整的 20 小時：**
- 完成所有三個模組
- 完成所有實踐練習
- 完成一個小型項目
- 探索至少 2-3 個補充資源

## 必備資源

這些精選資源為您的有限學習時間提供最大價值：

### 必讀文檔
- [ONNX Runtime 入門](https://onnxruntime.ai/docs/get-started/with-python.html) - 最高效的模型優化工具
- [Ollama 快速入門](https://github.com/ollama/ollama#get-started) - 最快的本地部署 SLM 方法
- [Microsoft Phi 模型卡](https://huggingface.co/microsoft/phi-2) - 領先的邊緣優化模型參考

### 節省時間的工具
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - 快速訪問和部署模型
- [Gradio](https://www.gradio.app/docs/interface) - 快速開發 AI 演示的用戶界面
- [Microsoft Olive](https://github.com/microsoft/Olive) - 簡化模型優化

## 進度追蹤模板

使用此簡化模板追蹤您在 20 小時課程中的學習進度：

| 模組 | 完成日期 | 花費時間 | 關鍵收穫 |
|------|----------|----------|----------|
| 模組 1：EdgeAI 基礎 | | | |
| 模組 2：SLM 基礎 | | | |
| 模組 3：SLM 部署 | | | |
| 實踐練習 | | | |
| 小型項目 | | | |

## 小型項目點子

考慮完成以下小型項目之一來練習 EdgeAI 概念（每個設計為 2-3 小時）：

1. **邊緣文本助手**：使用小型語言模型創建一個簡單的離線文本補全工具
2. **模型比較儀表板**：構建一個基本的性能指標可視化工具，用於比較不同的 SLM
3. **優化實驗**：測量不同量化級別對同一基礎模型的影響

## 學習社群

加入討論並與其他學習者聯繫：
- [EdgeAI for Beginners 存儲庫的 GitHub 討論](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft 技術社群](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## 結論

EdgeAI 代表了人工智能實施的前沿，將強大的能力直接帶到設備上，同時解決隱私、延遲和連接性等關鍵問題。本 20 小時課程為您提供了必要的知識和實用技能，讓您能夠立即開始使用 EdgeAI 技術。

課程內容精簡，專注於最重要的概念，讓您能夠在不佔用過多時間的情況下快速獲得寶貴的專業知識。請記住，即使是簡單的實踐練習，也能有效鞏固您的學習成果。

祝學習愉快！

**免責聲明**：  
本文件已使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於重要信息，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋概不負責。