<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-07-22T02:59:51+00:00",
  "source_file": "Module01/README.md",
  "language_code": "hk"
}
-->
# 第 01 章：為邊緣設備轉型 AI 部署

邊緣人工智能（EdgeAI）代表了一種人工智能部署的範式轉變，將 AI 能力從基於雲端的處理轉移到本地邊緣設備。本章將探討定義這種 AI 實施轉型的基本概念、關鍵技術和實際應用。

## 模組結構

### [第 1 節：EdgeAI 基礎](./01.EdgeAIFundamentals.md)
本節通過對比傳統的基於雲端的 AI 與邊緣 AI 部署模型，建立基礎。我們將探討關鍵的支持技術，包括模型量化、壓縮優化以及克服邊緣設備計算限制的小型語言模型（SLMs）。討論重點在於這些創新如何提供增強的隱私保護、超低延遲以及強大的離線處理能力。

### [第 2 節：實際案例研究](./02.RealWorldCaseStudies.md)
通過具體例子，例如 Microsoft 的 Phi 和 Mu 模型生態系統以及日本航空的 AI 報告系統，本節展示了邊緣 AI 在多個行業中的成功實施。這些案例研究驗證了 SLMs 在專業任務中的卓越表現，並說明了邊緣部署策略的實際效益。

### [第 3 節：實踐實施指南](./03.PracticalImplementationGuide.md)
本節提供了全面的環境準備指南，涵蓋必要的開發工具、硬件需求、核心模型資源以及優化框架，為學習者建立技術基礎，幫助他們構建和部署自己的邊緣 AI 解決方案。

### [第 4 節：邊緣 AI 部署硬件平台](./04.EdgeDeployment.md)
本節探討了支持邊緣 AI 部署的硬件生態系統，涵蓋來自 Intel、Qualcomm、NVIDIA 和 Windows AI PCs 的平台。內容包括硬件能力的詳細比較、平台特定的優化技術，以及在各種邊緣計算場景中的實際部署考量。

## 主要學習成果

完成本章後，讀者將能夠理解：
- 雲端 AI 與邊緣 AI 架構的基本差異
- 邊緣部署的核心優化技術
- 實際應用和成功案例
- 實施邊緣 AI 解決方案的實踐技能
- 硬件平台選擇及平台特定的優化方法
- 性能基準測試和部署最佳實踐

## 未來影響

邊緣 AI 作為塑造 AI 部署未來的重要趨勢，為分佈式、高效且注重隱私的 AI 系統鋪平了道路。這些系統能夠在保持高性能標準的同時，獨立於雲端連接運行。

**免責聲明**：  
本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們致力於提供準確的翻譯，請注意自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於重要資訊，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或錯誤解釋概不負責。