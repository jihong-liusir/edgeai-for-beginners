<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c817161ba08864340737d623f761b9ae",
  "translation_date": "2025-09-17T22:04:38+00:00",
  "source_file": "README.md",
  "language_code": "it"
}
-->
# EdgeAI per Principianti

![Immagine di copertina del corso](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.it.png)

[![Contributori GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![Problemi GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![Richieste di pull GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

[![Osservatori GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![Fork GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![Stelle GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Segui questi passaggi per iniziare a utilizzare queste risorse:

1. **Fork del Repository**: Clicca [![Fork GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Clona il Repository**: `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Unisciti al Discord di Azure AI Foundry e incontra esperti e sviluppatori**](https://discord.com/invite/ByRwuEEgH4)

### üåê Supporto Multilingue

#### Supportato tramite GitHub Action (Automatizzato e Sempre Aggiornato)

[Arabo](../ar/README.md) | [Bengalese](../bn/README.md) | [Bulgaro](../bg/README.md) | [Birmano (Myanmar)](../my/README.md) | [Cinese (Semplificato)](../zh/README.md) | [Cinese (Tradizionale, Hong Kong)](../hk/README.md) | [Cinese (Tradizionale, Macao)](../mo/README.md) | [Cinese (Tradizionale, Taiwan)](../tw/README.md) | [Croato](../hr/README.md) | [Ceco](../cs/README.md) | [Danese](../da/README.md) | [Olandese](../nl/README.md) | [Finlandese](../fi/README.md) | [Francese](../fr/README.md) | [Tedesco](../de/README.md) | [Greco](../el/README.md) | [Ebraico](../he/README.md) | [Hindi](../hi/README.md) | [Ungherese](../hu/README.md) | [Indonesiano](../id/README.md) | [Italiano](./README.md) | [Giapponese](../ja/README.md) | [Coreano](../ko/README.md) | [Malese](../ms/README.md) | [Marathi](../mr/README.md) | [Nepalese](../ne/README.md) | [Norvegese](../no/README.md) | [Persiano (Farsi)](../fa/README.md) | [Polacco](../pl/README.md) | [Portoghese (Brasile)](../br/README.md) | [Portoghese (Portogallo)](../pt/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Rumeno](../ro/README.md) | [Russo](../ru/README.md) | [Serbo (Cirillico)](../sr/README.md) | [Slovacco](../sk/README.md) | [Sloveno](../sl/README.md) | [Spagnolo](../es/README.md) | [Swahili](../sw/README.md) | [Svedese](../sv/README.md) | [Tagalog (Filippino)](../tl/README.md) | [Thailandese](../th/README.md) | [Turco](../tr/README.md) | [Ucraino](../uk/README.md) | [Urdu](../ur/README.md) | [Vietnamita](../vi/README.md)

**Se desideri supportare ulteriori lingue, l'elenco delle lingue disponibili √® [qui](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Introduzione

Benvenuto in **EdgeAI per Principianti** ‚Äì il tuo viaggio completo nel mondo trasformativo dell'Intelligenza Artificiale Edge. Questo corso colma il divario tra le potenti capacit√† dell'IA e la loro applicazione pratica su dispositivi edge, permettendoti di sfruttare il potenziale dell'IA direttamente dove i dati vengono generati e le decisioni devono essere prese.

### Cosa Imparerai

Questo corso ti guider√† dai concetti fondamentali fino alle implementazioni pronte per la produzione, trattando:
- **Small Language Models (SLMs)** ottimizzati per il deployment edge
- **Ottimizzazione hardware-aware** su piattaforme diverse
- **Inferenza in tempo reale** con capacit√† di preservare la privacy
- **Strategie di deployment in produzione** per applicazioni aziendali

### Perch√© EdgeAI √® Importante

Edge AI rappresenta un cambiamento di paradigma che affronta sfide moderne cruciali:
- **Privacy e Sicurezza**: Processa dati sensibili localmente senza esposizione al cloud
- **Prestazioni in Tempo Reale**: Elimina la latenza di rete per applicazioni critiche
- **Efficienza dei Costi**: Riduce la larghezza di banda e le spese di calcolo nel cloud
- **Operazioni Resilienti**: Mantiene la funzionalit√† durante interruzioni di rete
- **Conformit√† Normativa**: Rispetta i requisiti di sovranit√† dei dati

### Edge AI

Edge AI si riferisce all'esecuzione di algoritmi di IA e modelli linguistici localmente sull'hardware‚Äîvicino a dove i dati vengono generati‚Äîsenza fare affidamento su risorse cloud per l'inferenza. Riduce la latenza, migliora la privacy e consente decisioni in tempo reale.

### Principi Fondamentali:
- **Inferenza sul dispositivo**: I modelli di IA vengono eseguiti su dispositivi edge (telefoni, router, microcontrollori, PC industriali)
- **Capacit√† offline**: Funziona senza connettivit√† internet persistente
- **Bassa latenza**: Risposte immediate adatte a sistemi in tempo reale
- **Sovranit√† dei dati**: Mantiene i dati sensibili localmente, migliorando sicurezza e conformit√†

### Small Language Models (SLMs)

Gli SLMs come Phi-4, Mistral-7B e Gemma sono versioni ottimizzate di LLMs pi√π grandi‚Äîaddestrati o distillati per:
- **Ridotto utilizzo di memoria**: Uso efficiente della memoria limitata dei dispositivi edge
- **Minore richiesta di calcolo**: Ottimizzati per prestazioni su CPU e GPU edge
- **Tempi di avvio pi√π rapidi**: Inizializzazione veloce per applicazioni reattive

Sbloccano potenti capacit√† NLP rispettando i vincoli di:
- **Sistemi embedded**: Dispositivi IoT e controller industriali
- **Dispositivi mobili**: Smartphone e tablet con capacit√† offline
- **Dispositivi IoT**: Sensori e dispositivi intelligenti con risorse limitate
- **Server edge**: Unit√† di elaborazione locale con risorse GPU limitate
- **Computer personali**: Scenari di deployment su desktop e laptop

## Architettura del Corso

### [Modulo 01: Fondamenti e Trasformazione di EdgeAI](./Module01/README.md)
**Tema**: Il cambiamento trasformativo del deployment Edge AI

#### Struttura dei Capitoli:
- [**Sezione 1: Fondamenti di EdgeAI**](./Module01/01.EdgeAIFundamentals.md)
  - Confronto tra IA cloud tradizionale e IA edge
  - Sfide e vincoli del computing edge
  - Tecnologie chiave: quantizzazione dei modelli, ottimizzazione della compressione, Small Language Models (SLMs)
  - Accelerazione hardware: NPUs, ottimizzazione GPU, ottimizzazione CPU
  - Vantaggi: sicurezza della privacy, bassa latenza, capacit√† offline, efficienza dei costi

- [**Sezione 2: Casi di Studio Reali**](./Module01/02.RealWorldCaseStudies.md)
  - Ecosistema di modelli Microsoft Phi & Mu
  - Caso di studio sul sistema di reporting AI di Japan Airlines
  - Impatto sul mercato e direzioni future
  - Considerazioni sul deployment e migliori pratiche

- [**Sezione 3: Guida Pratica all'Implementazione**](./Module01/03.PracticalImplementationGuide.md)
  - Configurazione dell'ambiente di sviluppo (Python 3.10+, .NET 8+)
  - Requisiti hardware e configurazioni consigliate
  - Risorse della famiglia di modelli principali
  - Strumenti di quantizzazione e ottimizzazione (Llama.cpp, Microsoft Olive, Apple MLX)
  - Checklist di valutazione e verifica

- [**Sezione 4: Piattaforme Hardware per il Deployment Edge AI**](./Module01/04.EdgeDeployment.md)
  - Considerazioni e requisiti per il deployment Edge AI
  - Hardware edge AI Intel e tecniche di ottimizzazione
  - Soluzioni AI Qualcomm per sistemi mobili e embedded
  - Piattaforme di computing edge NVIDIA Jetson
  - Piattaforme PC Windows AI con accelerazione NPU
  - Strategie di ottimizzazione specifiche per hardware

---

### [Modulo 02: Fondamenti dei Small Language Models](./Module02/README.md)
**Tema**: Principi teorici degli SLM, strategie di implementazione e deployment in produzione

#### Struttura dei Capitoli:
- [**Sezione 1: Fondamenti della Famiglia di Modelli Microsoft Phi**](./Module02/01.PhiFamily.md)
  - Evoluzione della filosofia di design (Phi-1 a Phi-4)
  - Design architettonico orientato all'efficienza
  - Capacit√† specializzate (ragionamento, multimodale, deployment edge)

- [**Sezione 2: Fondamenti della Famiglia Qwen**](./Module02/02.QwenFamily.md)
  - Eccellenza open source (Qwen 1.0 a Qwen3) - disponibile tramite Hugging Face
  - Architettura avanzata di ragionamento con capacit√† di modalit√† di pensiero
  - Opzioni di deployment scalabili (0.5B-235B parametri)

- [**Sezione 3: Fondamenti della Famiglia Gemma**](./Module02/03.GemmaFamily.md)
  - Innovazione guidata dalla ricerca (Gemma 3 & 3n)
  - Eccellenza multimodale
  - Architettura orientata ai dispositivi mobili

- [**Sezione 4: Fondamenti della Famiglia BitNET**](./Module02/04.BitNETFamily.md)
  - Tecnologia di quantizzazione rivoluzionaria (1.58-bit)
  - Framework di inferenza specializzato da https://github.com/microsoft/BitNet
  - Leadership AI sostenibile attraverso estrema efficienza

- [**Sezione 5: Fondamenti del Modello Microsoft Mu**](./Module02/05.mumodel.md)
  - Architettura orientata ai dispositivi integrata in Windows 11
  - Integrazione di sistema con le Impostazioni di Windows 11
  - Operazione offline che preserva la privacy

- [**Sezione 6: Fondamenti di Phi-Silica**](./Module02/06.phisilica.md)
  - Architettura ottimizzata per NPU integrata nei PC Windows 11 Copilot+
  - Efficienza eccezionale (650 token/secondo a 1.5W)
  - Integrazione per sviluppatori con Windows App SDK

---

### [Modulo 03: Deployment dei Small Language Models](./Module03/README.md)
**Tema**: Ciclo completo di deployment degli SLM, dalla teoria all'ambiente di produzione

#### Struttura dei Capitoli:
- [**Sezione 1: Apprendimento Avanzato degli SLM**](./Module03/01.SLMAdvancedLearning.md)
  - Framework di classificazione dei parametri (Micro SLM 100M-1.4B, Medium SLM 14B-30B)
  - Tecniche avanzate di ottimizzazione (metodi di quantizzazione, quantizzazione BitNET 1-bit)
  - Strategie di acquisizione dei modelli (Azure AI Foundry per modelli Phi, Hugging Face per modelli selezionati)

- [**Sezione 2: Deployment in Ambiente Locale**](./Module03/02.DeployingSLMinLocalEnv.md)
  - Deployment universale sulla piattaforma Ollama
  - Soluzioni aziendali locali di Microsoft Foundry
  - Analisi comparativa dei framework

- [**Sezione 3: Deployment Cloud Containerizzato**](./Module03/03.DeployingSLMinCloud.md)
  - Deployment di inferenza ad alte prestazioni con vLLM
  - Orchestrazione di container Ollama
  - Implementazione ottimizzata per edge con ONNX Runtime

---

### [Modulo 04: Conversione del Formato dei Modelli e Quantizzazione](./Module04/README.md)
**Tema**: Toolkit completo per l'ottimizzazione dei modelli per il deployment edge su diverse piattaforme

#### Struttura dei Capitoli:
- [**Sezione 1: Fondamenti di Conversione del Formato dei Modelli e Quantizzazione**](./Module04/01.Introduce.md)
  - Framework di classificazione della precisione (ultra-bassa, bassa, media precisione)
  - Vantaggi e casi d'uso dei formati GGUF e ONNX
  - Benefici della quantizzazione per l'efficienza operativa
  - Benchmark delle prestazioni e confronti sull'utilizzo della memoria
- [**Sezione 2: Guida all'implementazione di Llama.cpp**](./Module04/02.Llamacpp.md)
  - Installazione multipiattaforma (Windows, macOS, Linux)
  - Conversione in formato GGUF e livelli di quantizzazione (Q2_K a Q8_0)
  - Accelerazione hardware (CUDA, Metal, OpenCL, Vulkan)
  - Integrazione con Python e distribuzione tramite REST API

- [**Sezione 3: Suite di ottimizzazione Microsoft Olive**](./Module04/03.MicrosoftOlive.md)
  - Ottimizzazione dei modelli basata sull'hardware con oltre 40 componenti integrati
  - Auto-ottimizzazione con quantizzazione dinamica e statica
  - Integrazione aziendale con flussi di lavoro Azure ML
  - Supporto per modelli popolari (Llama, Phi, modelli Qwen selezionati, Gemma)

- [**Sezione 4: Suite di ottimizzazione OpenVINO Toolkit**](./Module04/04.openvino.md)
  - Toolkit open-source di Intel per il deployment AI multipiattaforma
  - Framework di compressione delle reti neurali (NNCF) per ottimizzazioni avanzate
  - OpenVINO GenAI per il deployment di modelli linguistici di grandi dimensioni
  - Accelerazione hardware su CPU, GPU, VPU e acceleratori AI

- [**Sezione 5: Approfondimento sul framework Apple MLX**](./Module04/05.AppleMLX.md)
  - Architettura di memoria unificata per Apple Silicon
  - Supporto per LLaMA, Mistral, Phi-3, modelli Qwen selezionati
  - Fine-tuning LoRA e personalizzazione dei modelli
  - Integrazione con Hugging Face con quantizzazione a 4-bit/8-bit

- [**Sezione 6: Sintesi del flusso di lavoro per lo sviluppo Edge AI**](./Module04/06.workflow-synthesis.md)
  - Architettura del flusso di lavoro unificato che integra pi√π framework di ottimizzazione
  - Alberi decisionali per la selezione dei framework e analisi dei compromessi prestazionali
  - Validazione della prontezza alla produzione e strategie di distribuzione complete
  - Strategie per garantire la compatibilit√† con hardware e architetture di modelli emergenti

---

### [Modulo 05: SLMOps - Operazioni sui modelli linguistici piccoli](./Module05/README.md)
**Tema**: Operazioni complete sul ciclo di vita degli SLM, dalla distillazione alla distribuzione in produzione

#### Struttura dei capitoli:
- [**Sezione 1: Introduzione a SLMOps**](./Module05/01.IntroduceSLMOps.md)
  - Cambiamento di paradigma SLMOps nelle operazioni AI
  - Efficienza dei costi e architettura orientata alla privacy
  - Impatto strategico sul business e vantaggi competitivi
  - Sfide e soluzioni per l'implementazione nel mondo reale

- [**Sezione 2: Distillazione del modello - Dalla teoria alla pratica**](./Module05/02.SLMOps-Distillation.md)
  - Trasferimento di conoscenze dai modelli insegnanti ai modelli studenti
  - Implementazione del processo di distillazione in due fasi
  - Flussi di lavoro di distillazione Azure ML con esempi pratici
  - Riduzione del tempo di inferenza dell'85% con una conservazione della precisione del 92%

- [**Sezione 3: Fine-Tuning - Personalizzazione dei modelli per compiti specifici**](./Module05/03.SLMOps-Finetuing.md)
  - Tecniche di fine-tuning efficienti in termini di parametri (PEFT)
  - Metodi avanzati LoRA e QLoRA
  - Implementazione del fine-tuning con Microsoft Olive
  - Addestramento multi-adattatore e ottimizzazione degli iperparametri

- [**Sezione 4: Distribuzione - Implementazione pronta per la produzione**](./Module05/04.SLMOps.Deployment.md)
  - Conversione e quantizzazione dei modelli per la produzione
  - Configurazione di distribuzione locale con Foundry Local
  - Benchmarking delle prestazioni e validazione della qualit√†
  - Riduzione del 75% delle dimensioni con monitoraggio della produzione

---

### [Modulo 06: Sistemi agentici SLM - Agenti AI e chiamata di funzioni](./Module06/README.md)
**Tema**: Implementazione di sistemi agentici SLM dalle basi alla chiamata avanzata di funzioni e integrazione del Model Context Protocol

#### Struttura dei capitoli:
- [**Sezione 1: Fondamenti degli agenti AI e dei modelli linguistici piccoli**](./Module06/01.IntroduceAgent.md)
  - Framework di classificazione degli agenti (riflessivi, basati su modelli, basati su obiettivi, agenti di apprendimento)
  - Fondamenti degli SLM e strategie di ottimizzazione (GGUF, quantizzazione, framework edge)
  - Analisi dei compromessi tra SLM e LLM (riduzione dei costi del 10-30√ó, efficacia del compito del 70-80%)
  - Distribuzione pratica con Ollama, VLLM e soluzioni edge Microsoft

- [**Sezione 2: Chiamata di funzioni nei modelli linguistici piccoli**](./Module06/02.FunctionCalling.md)
  - Implementazione sistematica del flusso di lavoro (rilevamento dell'intento, output JSON, esecuzione esterna)
  - Implementazioni specifiche per piattaforma (Phi-4-mini, modelli Qwen selezionati, Microsoft Foundry Local)
  - Esempi avanzati (collaborazione multi-agente, selezione dinamica degli strumenti)
  - Considerazioni per la produzione (limitazione del tasso, registrazione degli audit, misure di sicurezza)

- [**Sezione 3: Integrazione del Model Context Protocol (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architettura del protocollo e design del sistema stratificato
  - Supporto multi-backend (Ollama per lo sviluppo, vLLM per la produzione)
  - Protocolli di connessione (modalit√† STDIO e SSE)
  - Applicazioni nel mondo reale (automazione web, elaborazione dati, integrazione API)

---

### [Modulo 07: Esempi di implementazione EdgeAI](./Module07/README.md)
**Tema**: Implementazioni complete di EdgeAI su piattaforme e framework diversi

#### Struttura dei capitoli:
- [**Toolkit AI per Visual Studio Code**](./Module07/aitoolkit.md)
  - Ambiente di sviluppo Edge AI completo all'interno di VS Code
  - Catalogo e scoperta dei modelli per il deployment edge
  - Flussi di lavoro per test locali, ottimizzazione e sviluppo di agenti
  - Monitoraggio delle prestazioni e valutazione per scenari edge

- [**Guida allo sviluppo EdgeAI su Windows**](./Module07/windowdeveloper.md)
  - Panoramica completa della piattaforma Windows AI Foundry
  - API Phi Silica per inferenza NPU efficiente
  - API di visione artificiale per elaborazione immagini e OCR
  - CLI Foundry Local per sviluppo e test locali

- [**EdgeAI in NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Prestazioni AI di 67 TOPS in un formato delle dimensioni di una carta di credito
  - Supporto per modelli AI generativi (trasformatori visivi, LLM, modelli visione-linguaggio)
  - Applicazioni in robotica, droni, telecamere intelligenti, dispositivi autonomi
  - Piattaforma accessibile a $249 per lo sviluppo AI democratizzato

- [**EdgeAI nelle applicazioni mobili con .NET MAUI e ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - AI mobile multipiattaforma con un singolo codice C#
  - Supporto per accelerazione hardware (CPU, GPU, processori AI mobili)
  - Ottimizzazioni specifiche per piattaforma (CoreML per iOS, NNAPI per Android)
  - Implementazione completa del ciclo AI generativo

- [**EdgeAI su Azure con motore Small Language Models**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architettura di distribuzione ibrida cloud-edge
  - Integrazione dei servizi AI di Azure con ONNX Runtime
  - Distribuzione su scala aziendale e gestione continua dei modelli
  - Flussi di lavoro AI ibridi per l'elaborazione intelligente dei documenti

- [**EdgeAI con Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fondamenti di Windows AI Foundry per inferenza performante su dispositivo
  - Supporto hardware universale (AMD, Intel, NVIDIA, Qualcomm silicon)
  - Astrazione e ottimizzazione hardware automatica
  - Framework unificato per l'ecosistema hardware diversificato di Windows

- [**EdgeAI con applicazioni Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Implementazione RAG orientata alla privacy con risorse locali
  - Integrazione del modello linguistico Phi-3 con ricerca semantica (solo modelli Phi)
  - Supporto per database vettoriali locali (SQLite, Qdrant)
  - Sovranit√† dei dati e capacit√† di operazione offline

## Obiettivi di apprendimento del corso

Completando questo corso completo su EdgeAI, svilupperai le competenze necessarie per progettare, implementare e distribuire soluzioni EdgeAI pronte per la produzione. Il nostro approccio strutturato garantisce che tu padroneggi sia le basi teoriche che le competenze pratiche di implementazione.

### Competenze tecniche

**Conoscenze di base**
- Comprendere le differenze fondamentali tra architetture AI basate su cloud e basate su edge
- Padroneggiare i principi di quantizzazione, compressione e ottimizzazione dei modelli per ambienti con risorse limitate
- Comprendere le opzioni di accelerazione hardware (NPU, GPU, CPU) e le loro implicazioni di distribuzione

**Competenze di implementazione**
- Distribuire modelli linguistici piccoli su diverse piattaforme edge (mobile, embedded, IoT, server edge)
- Applicare framework di ottimizzazione tra cui Llama.cpp, Microsoft Olive, ONNX Runtime e Apple MLX
- Implementare sistemi di inferenza in tempo reale con requisiti di risposta sotto il secondo

**Esperienza di produzione**
- Progettare architetture EdgeAI scalabili per applicazioni aziendali
- Implementare strategie di monitoraggio, manutenzione e aggiornamento per sistemi distribuiti
- Applicare le migliori pratiche di sicurezza per implementazioni EdgeAI orientate alla privacy

### Capacit√† strategiche

**Framework decisionale**
- Valutare le opportunit√† EdgeAI e identificare casi d'uso adatti per applicazioni aziendali
- Valutare i compromessi tra precisione del modello, velocit√† di inferenza, consumo energetico e costi hardware
- Selezionare famiglie e configurazioni SLM appropriate in base ai vincoli di distribuzione specifici

**Architettura di sistema**
- Progettare soluzioni EdgeAI end-to-end che si integrino con l'infrastruttura esistente
- Pianificare architetture ibride edge-cloud per prestazioni e costi ottimali
- Implementare flussi di dati e pipeline di elaborazione per applicazioni AI in tempo reale

### Applicazioni industriali

**Scenari di distribuzione pratica**
- **Manifattura**: Sistemi di controllo qualit√†, manutenzione predittiva e ottimizzazione dei processi
- **Sanit√†**: Strumenti diagnostici orientati alla privacy e sistemi di monitoraggio dei pazienti
- **Trasporti**: Decision-making per veicoli autonomi e gestione del traffico
- **Smart Cities**: Infrastrutture intelligenti e sistemi di gestione delle risorse
- **Elettronica di consumo**: Applicazioni mobili AI-powered e dispositivi smart home

## Panoramica degli obiettivi di apprendimento

### Obiettivi di apprendimento del Modulo 01:
- Comprendere le differenze fondamentali tra architetture AI cloud e edge
- Padroneggiare le tecniche di ottimizzazione principali per il deployment edge
- Riconoscere applicazioni reali e storie di successo
- Acquisire competenze pratiche per implementare soluzioni EdgeAI

### Obiettivi di apprendimento del Modulo 02:
- Comprensione approfondita delle diverse filosofie di design SLM e delle loro implicazioni di distribuzione
- Padroneggiare capacit√† decisionali strategiche basate su vincoli computazionali e requisiti prestazionali
- Comprendere i compromessi di flessibilit√† di distribuzione
- Possedere intuizioni future per architetture AI efficienti

### Obiettivi di apprendimento del Modulo 03:
- Capacit√† strategiche di selezione dei modelli
- Padronanza delle tecniche di ottimizzazione
- Padronanza della flessibilit√† di distribuzione
- Capacit√† di configurazione pronta per la produzione

### Obiettivi di apprendimento del Modulo 04:
- Comprensione approfondita dei limiti di quantizzazione e delle applicazioni pratiche
- Esperienza pratica con pi√π framework di ottimizzazione (Llama.cpp, Olive, OpenVINO, MLX)
- Padroneggiare l'ottimizzazione hardware Intel con OpenVINO e NNCF
- Capacit√† di selezione dell'ottimizzazione basata sull'hardware su piattaforme diverse
- Competenze di distribuzione per ambienti di edge computing multipiattaforma
- Sintesi strategica dei framework e dei flussi di lavoro per soluzioni Edge AI ottimali

### Obiettivi di apprendimento del Modulo 05:
- Padroneggiare il paradigma SLMOps e i principi operativi
- Implementare la distillazione del modello per il trasferimento di conoscenze e l'ottimizzazione dell'efficienza
- Applicare tecniche di fine-tuning per la personalizzazione del modello specifica del dominio
- Distribuire soluzioni SLM pronte per la produzione con strategie di monitoraggio e manutenzione

### Obiettivi di apprendimento del Modulo 06:
- Comprendere i concetti fondamentali degli agenti AI e dell'architettura dei modelli linguistici piccoli
- Padroneggiare l'implementazione della chiamata di funzioni su pi√π piattaforme e framework
- Integrare il Model Context Protocol (MCP) per l'interazione standardizzata con strumenti esterni
- Costruire sistemi agentici sofisticati con requisiti minimi di intervento umano

### Obiettivi di apprendimento del Modulo 07:
- Padroneggiare il Toolkit AI per Visual Studio Code per flussi di lavoro di sviluppo Edge AI completi
- Acquisire competenze nella piattaforma Windows AI Foundry e nelle strategie di ottimizzazione NPU
- Acquisire esperienza pratica con diverse piattaforme EdgeAI e strategie di implementazione
- Padroneggiare tecniche di ottimizzazione specifiche per hardware su piattaforme NVIDIA, mobile, Azure e Windows
- Comprendere i compromessi di distribuzione tra prestazioni, costi e requisiti di privacy
- Sviluppare competenze pratiche per costruire applicazioni EdgeAI reali su ecosistemi diversi

## Risultati attesi del corso

Al termine del corso, sarai equipaggiato con le conoscenze, le competenze e la sicurezza per guidare iniziative EdgeAI in ambienti professionali.

### Prontezza professionale

**Leadership tecnica**
- **Architettura delle soluzioni**: Progettare sistemi EdgeAI completi che soddisfino i requisiti aziendali
- **Ottimizzazione delle prestazioni**: Raggiungere un equilibrio ottimale tra precisione, velocit√† e consumo di risorse
- **Distribuzione multipiattaforma**: Implementare soluzioni su Windows, Linux, mobile e piattaforme embedded
- **Operazioni di produzione**: Mantenere e scalare sistemi EdgeAI con affidabilit√† di livello aziendale

**Esperienza industriale**
- **Valutazione tecnologica**: Valutare e raccomandare soluzioni EdgeAI per sfide aziendali specifiche
- **Pianificazione dell'implementazione**: Sviluppare tempistiche realistiche e requisiti di risorse per progetti EdgeAI
- **Gestione del rischio**: Identificare e mitigare rischi tecnici e operativi nelle distribuzioni EdgeAI
- **Ottimizzazione del ROI**: Dimostrare valore aziendale misurabile dalle implementazioni EdgeAI

### Opportunit√† di avanzamento professionale

**Ruoli professionali**
- Architetto di soluzioni EdgeAI
- Ingegnere di machine learning (specializzazione Edge)
- Sviluppatore AI per IoT
- Sviluppatore di applicazioni AI mobili
- Consulente AI aziendale

**Settori industriali**
- Manifattura intelligente e Industria 4.0
- Veicoli autonomi e trasporti
- Tecnologia sanitaria e dispositivi medici
- Tecnologia finanziaria e sicurezza
- Elettronica di consumo e applicazioni mobili

### Certificazione e validazione

**Sviluppo del portfolio**
- Completare progetti EdgeAI end-to-end dimostrando competenza pratica
- Distribuire soluzioni pronte per la produzione su pi√π piattaforme hardware
- Documentare strategie di ottimizzazione e miglioramenti delle prestazioni raggiunti

**Percorso di apprendimento continuo**
- Fondamento per specializzazioni AI avanzate
- Preparazione per architetture ibride cloud-edge
- Porta d'accesso a tecnologie e framework AI emergenti
Questo corso ti posiziona all'avanguardia nell'implementazione della tecnologia AI, dove le capacit√† intelligenti sono integrate senza soluzione di continuit√† nei dispositivi e nei sistemi che alimentano la vita moderna.

## Diagramma della Struttura dei File

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.openvino.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.AppleMLX.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.workflow-synthesis.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îú‚îÄ‚îÄ aitoolkit.md
‚îÇ   ‚îú‚îÄ‚îÄ windowdeveloper.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```

## Caratteristiche del Corso

- **Apprendimento Progressivo**: Avanza gradualmente dai concetti di base alla distribuzione avanzata
- **Integrazione di Teoria e Pratica**: Ogni modulo contiene sia fondamenti teorici che operazioni pratiche
- **Studi di Casi Reali**: Basati su casi reali di Microsoft, Alibaba, Google e altri
- **Pratica Diretta**: File di configurazione completi, procedure di test API e script di distribuzione
- **Benchmark di Prestazioni**: Confronti dettagliati sulla velocit√† di inferenza, utilizzo della memoria e requisiti di risorse
- **Considerazioni di Livello Aziendale**: Pratiche di sicurezza, framework di conformit√† e strategie di protezione dei dati

## Per Iniziare

Percorso di Apprendimento Consigliato:
1. Inizia con **Module01** per costruire una comprensione fondamentale di EdgeAI
2. Procedi con **Module02** per comprendere a fondo le diverse famiglie di modelli SLM
3. Studia **Module03** per padroneggiare le competenze pratiche di distribuzione
4. Continua con **Module04** per l'ottimizzazione avanzata dei modelli, la conversione dei formati e la sintesi dei framework
5. Completa **Module05** per padroneggiare SLMOps per implementazioni pronte per la produzione
6. Esplora **Module06** per comprendere i sistemi agentici SLM e le capacit√† di chiamata delle funzioni
7. Concludi con **Module07** per acquisire esperienza pratica con AI Toolkit e diversi esempi di implementazione EdgeAI

Ogni modulo √® progettato per essere completo in modo indipendente, ma l'apprendimento sequenziale fornir√† i migliori risultati.

## Guida allo Studio

Una [Guida allo Studio](STUDY_GUIDE.md) completa √® disponibile per aiutarti a massimizzare la tua esperienza di apprendimento. La guida allo studio fornisce:

- **Percorsi di Apprendimento Strutturati**: Programmi ottimizzati per completare il corso in 20 ore
- **Indicazioni sulla Allocazione del Tempo**: Raccomandazioni specifiche per bilanciare lettura, esercizi e progetti
- **Focus sui Concetti Chiave**: Obiettivi di apprendimento prioritari per ogni modulo
- **Strumenti di Auto-Valutazione**: Domande ed esercizi per testare la tua comprensione
- **Idee per Mini-Progetti**: Applicazioni pratiche per rafforzare il tuo apprendimento

La guida allo studio √® progettata per adattarsi sia a un apprendimento intensivo (1 settimana) che a uno studio part-time (3 settimane), con indicazioni chiare su come allocare il tuo tempo in modo efficace anche se puoi dedicare solo 10 ore al corso.

---

**Il futuro di EdgeAI risiede nel miglioramento continuo delle architetture dei modelli, delle tecniche di quantizzazione e delle strategie di distribuzione che privilegiano l'efficienza e la specializzazione rispetto alle capacit√† generiche. Le organizzazioni che abbracciano questo cambiamento di paradigma saranno ben posizionate per sfruttare il potenziale trasformativo dell'AI mantenendo il controllo sui propri dati e operazioni.**

## Altri Corsi

Il nostro team produce altri corsi! Dai un'occhiata:

- [MCP for Beginners](https://github.com/microsoft/mcp-for-beginners)
- [AI Agents For Beginners](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Generative AI for Beginners using .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
- [Generative AI for Beginners using JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)
- [Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
- [ML for Beginners](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
- [Data Science for Beginners](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
- [AI for Beginners](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
- [Cybersecurity for Beginners](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)
- [Web Dev for Beginners](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
- [IoT for Beginners](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)
- [XR Development for Beginners](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Mastering GitHub Copilot for AI Paired Programming](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)
- [Mastering GitHub Copilot for C#/.NET Developers](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)
- [Choose Your Own Copilot Adventure](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)

---

**Disclaimer**:  
Questo documento √® stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.