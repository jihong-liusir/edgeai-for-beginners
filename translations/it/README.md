<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a189d7d9d47816a518ca119d79dc19b",
  "translation_date": "2025-09-22T18:09:47+00:00",
  "source_file": "README.md",
  "language_code": "it"
}
-->
# EdgeAI per Principianti

![Immagine di copertina del corso](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.it.png)

[![Contributori GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![Problemi GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![Richieste di pull GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![Osservatori GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![Fork GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![Stelle GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Discord Microsoft Azure AI Foundry](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Segui questi passaggi per iniziare a utilizzare queste risorse:

1. **Fai un Fork del Repository**: Clicca [![Fork GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Clona il Repository**: `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Unisciti al Discord di Azure AI Foundry e incontra esperti e altri sviluppatori**](https://discord.com/invite/ByRwuEEgH4)  

### üåê Supporto Multilingue

#### Supportato tramite GitHub Action (Automatizzato e Sempre Aggiornato)

[Arabo](../ar/README.md) | [Bengalese](../bn/README.md) | [Bulgaro](../bg/README.md) | [Birmano (Myanmar)](../my/README.md) | [Cinese (Semplificato)](../zh/README.md) | [Cinese (Tradizionale, Hong Kong)](../hk/README.md) | [Cinese (Tradizionale, Macao)](../mo/README.md) | [Cinese (Tradizionale, Taiwan)](../tw/README.md) | [Croato](../hr/README.md) | [Ceco](../cs/README.md) | [Danese](../da/README.md) | [Olandese](../nl/README.md) | [Finlandese](../fi/README.md) | [Francese](../fr/README.md) | [Tedesco](../de/README.md) | [Greco](../el/README.md) | [Ebraico](../he/README.md) | [Hindi](../hi/README.md) | [Ungherese](../hu/README.md) | [Indonesiano](../id/README.md) | [Italiano](./README.md) | [Giapponese](../ja/README.md) | [Coreano](../ko/README.md) | [Malese](../ms/README.md) | [Marathi](../mr/README.md) | [Nepalese](../ne/README.md) | [Norvegese](../no/README.md) | [Persiano (Farsi)](../fa/README.md) | [Polacco](../pl/README.md) | [Portoghese (Brasile)](../br/README.md) | [Portoghese (Portogallo)](../pt/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Rumeno](../ro/README.md) | [Russo](../ru/README.md) | [Serbo (Cirillico)](../sr/README.md) | [Slovacco](../sk/README.md) | [Sloveno](../sl/README.md) | [Spagnolo](../es/README.md) | [Swahili](../sw/README.md) | [Svedese](../sv/README.md) | [Tagalog (Filippino)](../tl/README.md) | [Thailandese](../th/README.md) | [Turco](../tr/README.md) | [Ucraino](../uk/README.md) | [Urdu](../ur/README.md) | [Vietnamita](../vi/README.md)

**Se desideri supportare ulteriori lingue, l'elenco delle lingue disponibili √® [qui](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Introduzione

Benvenuto in **EdgeAI per Principianti** ‚Äì il tuo viaggio completo nel mondo trasformativo dell'Intelligenza Artificiale Edge. Questo corso colma il divario tra le potenti capacit√† dell'IA e la loro implementazione pratica su dispositivi edge, permettendoti di sfruttare il potenziale dell'IA direttamente dove i dati vengono generati e le decisioni devono essere prese.

### Cosa Imparerai

Questo corso ti guider√† dai concetti fondamentali fino alle implementazioni pronte per la produzione, trattando:
- **Small Language Models (SLMs)** ottimizzati per il deployment edge
- **Ottimizzazione hardware-aware** su piattaforme diverse
- **Inferenza in tempo reale** con capacit√† di preservare la privacy
- **Strategie di deployment in produzione** per applicazioni aziendali

### Perch√© EdgeAI √® Importante

Edge AI rappresenta un cambiamento di paradigma che affronta sfide moderne cruciali:
- **Privacy e Sicurezza**: Processa dati sensibili localmente senza esposizione al cloud
- **Prestazioni in Tempo Reale**: Elimina la latenza di rete per applicazioni critiche
- **Efficienza dei Costi**: Riduce la larghezza di banda e le spese di calcolo nel cloud
- **Operazioni Resilienti**: Mantiene la funzionalit√† durante interruzioni di rete
- **Conformit√† Normativa**: Rispetta i requisiti di sovranit√† dei dati

### Edge AI

Edge AI si riferisce all'esecuzione di algoritmi di IA e modelli linguistici localmente sull'hardware‚Äîvicino a dove i dati vengono generati‚Äîsenza fare affidamento su risorse cloud per l'inferenza. Riduce la latenza, migliora la privacy e consente decisioni in tempo reale.

### Principi Fondamentali:
- **Inferenza sul dispositivo**: I modelli di IA vengono eseguiti su dispositivi edge (telefoni, router, microcontrollori, PC industriali)
- **Capacit√† offline**: Funziona senza connettivit√† internet persistente
- **Bassa latenza**: Risposte immediate adatte a sistemi in tempo reale
- **Sovranit√† dei dati**: Mantiene i dati sensibili localmente, migliorando sicurezza e conformit√†

### Small Language Models (SLMs)

Gli SLMs come Phi-4, Mistral-7B e Gemma sono versioni ottimizzate di LLMs pi√π grandi‚Äîaddestrati o distillati per:
- **Ridotto utilizzo di memoria**: Uso efficiente della memoria limitata dei dispositivi edge
- **Minore richiesta di calcolo**: Ottimizzati per prestazioni su CPU e GPU edge
- **Tempi di avvio pi√π rapidi**: Inizializzazione veloce per applicazioni reattive

Sbloccano potenti capacit√† NLP rispettando i vincoli di:
- **Sistemi embedded**: Dispositivi IoT e controller industriali
- **Dispositivi mobili**: Smartphone e tablet con capacit√† offline
- **Dispositivi IoT**: Sensori e dispositivi intelligenti con risorse limitate
- **Server edge**: Unit√† di elaborazione locale con risorse GPU limitate
- **Computer personali**: Scenari di deployment su desktop e laptop

## Architettura del Corso

### [Modulo 01: Fondamenti e Trasformazione di EdgeAI](./Module01/README.md)
**Tema**: Il cambiamento trasformativo del deployment Edge AI

#### Struttura dei Capitoli:
- [**Sezione 1: Fondamenti di EdgeAI**](./Module01/01.EdgeAIFundamentals.md)
  - Confronto tra IA tradizionale basata su cloud e IA edge
  - Sfide e vincoli dell'edge computing
  - Tecnologie chiave: quantizzazione dei modelli, ottimizzazione della compressione, Small Language Models (SLMs)
  - Accelerazione hardware: NPUs, ottimizzazione GPU, ottimizzazione CPU
  - Vantaggi: sicurezza della privacy, bassa latenza, capacit√† offline, efficienza dei costi

- [**Sezione 2: Casi Studio Reali**](./Module01/02.RealWorldCaseStudies.md)
  - Ecosistema di modelli Microsoft Phi & Mu
  - Caso studio del sistema di reporting AI di Japan Airlines
  - Impatto sul mercato e direzioni future
  - Considerazioni sul deployment e migliori pratiche

- [**Sezione 3: Guida Pratica all'Implementazione**](./Module01/03.PracticalImplementationGuide.md)
  - Configurazione dell'ambiente di sviluppo (Python 3.10+, .NET 8+)
  - Requisiti hardware e configurazioni consigliate
  - Risorse principali della famiglia di modelli
  - Strumenti di quantizzazione e ottimizzazione (Llama.cpp, Microsoft Olive, Apple MLX)
  - Checklist di valutazione e verifica

- [**Sezione 4: Piattaforme Hardware per il Deployment Edge AI**](./Module01/04.EdgeDeployment.md)
  - Considerazioni e requisiti per il deployment Edge AI
  - Hardware edge AI Intel e tecniche di ottimizzazione
  - Soluzioni AI Qualcomm per sistemi mobili e embedded
  - NVIDIA Jetson e piattaforme di edge computing
  - Piattaforme PC Windows AI con accelerazione NPU
  - Strategie di ottimizzazione specifiche per hardware

---

### [Modulo 02: Fondamenti dei Small Language Models](./Module02/README.md)
**Tema**: Principi teorici degli SLM, strategie di implementazione e deployment in produzione

#### Struttura dei Capitoli:
- [**Sezione 1: Fondamenti della Famiglia di Modelli Microsoft Phi**](./Module02/01.PhiFamily.md)
  - Evoluzione della filosofia di design (Phi-1 a Phi-4)
  - Design architettonico orientato all'efficienza
  - Capacit√† specializzate (ragionamento, multimodale, deployment edge)

- [**Sezione 2: Fondamenti della Famiglia Qwen**](./Module02/02.QwenFamily.md)
  - Eccellenza open source (Qwen 1.0 a Qwen3) - disponibile tramite Hugging Face
  - Architettura avanzata di ragionamento con capacit√† di modalit√† di pensiero
  - Opzioni di deployment scalabili (0.5B-235B parametri)

- [**Sezione 3: Fondamenti della Famiglia Gemma**](./Module02/03.GemmaFamily.md)
  - Innovazione guidata dalla ricerca (Gemma 3 & 3n)
  - Eccellenza multimodale
  - Architettura mobile-first

- [**Sezione 4: Fondamenti della Famiglia BitNET**](./Module02/04.BitNETFamily.md)
  - Tecnologia di quantizzazione rivoluzionaria (1.58-bit)
  - Framework di inferenza specializzato da https://github.com/microsoft/BitNet
  - Leadership AI sostenibile attraverso estrema efficienza

- [**Sezione 5: Fondamenti del Modello Microsoft Mu**](./Module02/05.mumodel.md)
  - Architettura device-first integrata in Windows 11
  - Integrazione di sistema con le Impostazioni di Windows 11
  - Operazione offline che preserva la privacy

- [**Sezione 6: Fondamenti di Phi-Silica**](./Module02/06.phisilica.md)
  - Architettura ottimizzata per NPU integrata nei PC Windows 11 Copilot+
  - Efficienza eccezionale (650 token/secondo a 1.5W)
  - Integrazione per sviluppatori con Windows App SDK

---

### [Modulo 03: Deployment dei Small Language Models](./Module03/README.md)
**Tema**: Ciclo completo di deployment degli SLM, dalla teoria all'ambiente di produzione

#### Struttura dei Capitoli:
- [**Sezione 1: Apprendimento Avanzato degli SLM**](./Module03/01.SLMAdvancedLearning.md)
  - Framework di classificazione dei parametri (Micro SLM 100M-1.4B, Medium SLM 14B-30B)
  - Tecniche avanzate di ottimizzazione (metodi di quantizzazione, quantizzazione BitNET 1-bit)
  - Strategie di acquisizione dei modelli (Azure AI Foundry per modelli Phi, Hugging Face per modelli selezionati)

- [**Sezione 2: Deployment in Ambiente Locale**](./Module03/02.DeployingSLMinLocalEnv.md)
  - Deployment universale sulla piattaforma Ollama
  - Soluzioni aziendali locali di Microsoft Foundry
  - Analisi comparativa dei framework

- [**Sezione 3: Deployment Cloud Containerizzato**](./Module03/03.DeployingSLMinCloud.md)
  - Deployment di inferenza ad alte prestazioni con vLLM
  - Orchestrazione di container Ollama
  - Implementazione ottimizzata per edge con ONNX Runtime

---

### [Modulo 04: Conversione e Quantizzazione del Formato dei Modelli](./Module04/README.md)
**Tema**: Toolkit completo di ottimizzazione dei modelli per il deployment edge su diverse piattaforme

#### Struttura dei Capitoli:
- [**Sezione 1: Fondamenti di Conversione e Quantizzazione del Formato dei Modelli**](./Module04/01.Introduce.md)
  - Framework di classificazione della precisione (ultra-bassa, bassa, media precisione)
  - Vantaggi e casi d'uso dei formati GGUF e ONNX
  - Benefici della quantizzazione per l'efficienza operativa
  - Benchmark delle prestazioni e confronti sull'impronta di memoria
- [**Sezione 2: Guida all'implementazione di Llama.cpp**](./Module04/02.Llamacpp.md)
  - Installazione multipiattaforma (Windows, macOS, Linux)
  - Conversione in formato GGUF e livelli di quantizzazione (da Q2_K a Q8_0)
  - Accelerazione hardware (CUDA, Metal, OpenCL, Vulkan)
  - Integrazione con Python e distribuzione tramite REST API

- [**Sezione 3: Microsoft Olive Optimization Suite**](./Module04/03.MicrosoftOlive.md)
  - Ottimizzazione dei modelli basata sull'hardware con oltre 40 componenti integrati
  - Auto-ottimizzazione con quantizzazione dinamica e statica
  - Integrazione aziendale con flussi di lavoro Azure ML
  - Supporto per modelli popolari (Llama, Phi, modelli Qwen selezionati, Gemma)

- [**Sezione 4: OpenVINO Toolkit Optimization Suite**](./Module04/04.openvino.md)
  - Toolkit open-source di Intel per il deployment AI multipiattaforma
  - Neural Network Compression Framework (NNCF) per ottimizzazioni avanzate
  - OpenVINO GenAI per il deployment di modelli linguistici di grandi dimensioni
  - Accelerazione hardware su CPU, GPU, VPU e acceleratori AI

- [**Sezione 5: Approfondimento sul framework Apple MLX**](./Module04/05.AppleMLX.md)
  - Architettura di memoria unificata per Apple Silicon
  - Supporto per LLaMA, Mistral, Phi, modelli Qwen selezionati
  - Fine-tuning LoRA e personalizzazione dei modelli
  - Integrazione con Hugging Face con quantizzazione a 4-bit/8-bit

- [**Sezione 6: Sintesi del flusso di lavoro per lo sviluppo Edge AI**](./Module04/06.workflow-synthesis.md)
  - Architettura del flusso di lavoro unificato che integra diversi framework di ottimizzazione
  - Alberi decisionali per la selezione dei framework e analisi dei compromessi prestazionali
  - Validazione della prontezza alla produzione e strategie di distribuzione complete
  - Strategie per garantire la compatibilit√† con hardware e architetture di modelli emergenti

---

### [Modulo 05: SLMOps - Operazioni sui modelli linguistici ridotti](./Module05/README.md)
**Tema**: Gestione completa del ciclo di vita degli SLM, dalla distillazione alla distribuzione in produzione

#### Struttura dei capitoli:
- [**Sezione 1: Introduzione a SLMOps**](./Module05/01.IntroduceSLMOps.md)
  - Cambiamento di paradigma nelle operazioni AI con SLMOps
  - Efficienza dei costi e architettura orientata alla privacy
  - Impatto strategico sul business e vantaggi competitivi
  - Sfide e soluzioni per l'implementazione nel mondo reale

- [**Sezione 2: Distillazione del modello - Dalla teoria alla pratica**](./Module05/02.SLMOps-Distillation.md)
  - Trasferimento di conoscenze dai modelli insegnanti ai modelli studenti
  - Implementazione del processo di distillazione in due fasi
  - Flussi di lavoro di distillazione Azure ML con esempi pratici
  - Riduzione del tempo di inferenza dell'85% con una conservazione della precisione del 92%

- [**Sezione 3: Fine-Tuning - Personalizzazione dei modelli per compiti specifici**](./Module05/03.SLMOps-Finetuing.md)
  - Tecniche di fine-tuning efficienti in termini di parametri (PEFT)
  - Metodi avanzati LoRA e QLoRA
  - Implementazione del fine-tuning con Microsoft Olive
  - Addestramento multi-adattatore e ottimizzazione degli iperparametri

- [**Sezione 4: Distribuzione - Implementazione pronta per la produzione**](./Module05/04.SLMOps.Deployment.md)
  - Conversione e quantizzazione dei modelli per la produzione
  - Configurazione di distribuzione locale con Foundry Local
  - Benchmarking delle prestazioni e validazione della qualit√†
  - Riduzione del 75% delle dimensioni con monitoraggio della produzione

---

### [Modulo 06: Sistemi agentici SLM - Agenti AI e chiamata di funzioni](./Module06/README.md)
**Tema**: Implementazione di sistemi agentici SLM, dalla base alla chiamata avanzata di funzioni e integrazione del Model Context Protocol

#### Struttura dei capitoli:
- [**Sezione 1: Fondamenti degli agenti AI e dei modelli linguistici ridotti**](./Module06/01.IntroduceAgent.md)
  - Framework di classificazione degli agenti (riflessivi, basati su modelli, basati su obiettivi, agenti di apprendimento)
  - Fondamenti degli SLM e strategie di ottimizzazione (GGUF, quantizzazione, framework edge)
  - Analisi dei compromessi tra SLM e LLM (riduzione dei costi del 10-30√ó, efficacia del compito del 70-80%)
  - Distribuzione pratica con Ollama, VLLM e soluzioni edge di Microsoft

- [**Sezione 2: Chiamata di funzioni nei modelli linguistici ridotti**](./Module06/02.FunctionCalling.md)
  - Implementazione sistematica del flusso di lavoro (rilevamento dell'intento, output JSON, esecuzione esterna)
  - Implementazioni specifiche per piattaforma (Phi-4-mini, modelli Qwen selezionati, Microsoft Foundry Local)
  - Esempi avanzati (collaborazione multi-agente, selezione dinamica degli strumenti)
  - Considerazioni per la produzione (limitazione del tasso, registrazione degli audit, misure di sicurezza)

- [**Sezione 3: Integrazione del Model Context Protocol (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architettura del protocollo e design del sistema stratificato
  - Supporto multi-backend (Ollama per lo sviluppo, vLLM per la produzione)
  - Protocolli di connessione (modalit√† STDIO e SSE)
  - Applicazioni reali (automazione web, elaborazione dati, integrazione API)

---

### [Modulo 07: Esempi di implementazione EdgeAI](./Module07/README.md)
**Tema**: Implementazioni complete di EdgeAI su diverse piattaforme e framework

#### Struttura dei capitoli:
- [**Toolkit AI per Visual Studio Code**](./Module07/aitoolkit.md)
  - Ambiente di sviluppo Edge AI completo all'interno di VS Code
  - Catalogo e scoperta dei modelli per il deployment edge
  - Flussi di lavoro per test locali, ottimizzazione e sviluppo di agenti
  - Monitoraggio delle prestazioni e valutazione per scenari edge

- [**Guida allo sviluppo EdgeAI su Windows**](./Module07/windowdeveloper.md)
  - Panoramica completa della piattaforma Windows AI Foundry
  - API Phi Silica per inferenza NPU efficiente
  - API di Computer Vision per elaborazione immagini e OCR
  - CLI Foundry Local per sviluppo e test locali

- [**EdgeAI su NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Prestazioni AI di 67 TOPS in un formato delle dimensioni di una carta di credito
  - Supporto per modelli AI generativi (trasformatori visivi, LLM, modelli visione-linguaggio)
  - Applicazioni in robotica, droni, telecamere intelligenti, dispositivi autonomi
  - Piattaforma accessibile da $249 per lo sviluppo AI democratizzato

- [**EdgeAI nelle applicazioni mobili con .NET MAUI e ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - AI mobile multipiattaforma con un singolo codice C#
  - Supporto per accelerazione hardware (CPU, GPU, processori AI mobili)
  - Ottimizzazioni specifiche per piattaforma (CoreML per iOS, NNAPI per Android)
  - Implementazione completa del ciclo AI generativo

- [**EdgeAI su Azure con Small Language Models Engine**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architettura di distribuzione ibrida cloud-edge
  - Integrazione dei servizi AI di Azure con ONNX Runtime
  - Distribuzione su scala aziendale e gestione continua dei modelli
  - Flussi di lavoro AI ibridi per l'elaborazione intelligente dei documenti

- [**EdgeAI con Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fondamenti di Windows AI Foundry per inferenza performante su dispositivo
  - Supporto hardware universale (AMD, Intel, NVIDIA, Qualcomm silicon)
  - Astrazione e ottimizzazione hardware automatica
  - Framework unificato per l'ecosistema hardware diversificato di Windows

- [**EdgeAI con applicazioni Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Implementazione RAG orientata alla privacy con risorse locali
  - Integrazione del modello linguistico Phi-4 con ricerca semantica (solo modelli Phi)
  - Supporto per database vettoriali locali (SQLite, Qdrant)
  - Sovranit√† dei dati e capacit√† di operazione offline

### [Modulo 08: Microsoft Foundry Local ‚Äì Toolkit completo per sviluppatori](./Module08/README.md)
**Tema**: Creare, eseguire e integrare AI localmente con Foundry Local; scalare e ibridare con Azure AI Foundry

#### Struttura dei capitoli:
- [**1: Introduzione a Foundry Local**](./Module08/01.FoundryLocalSetup.md)
- [**2: Creare soluzioni AI con Azure AI Foundry**](./Module08/02.AzureAIFoundryIntegration.md)
- [**3: Modelli open-source Foundry Local**](./Module08/03.OpenSourceModels.md)
- [**4: Modelli all'avanguardia e inferenza su dispositivo**](./Module08/04.CuttingEdgeModels.md)
- [**5: Agenti AI con Foundry Local**](./Module08/05.AIPoweredAgents.md)
- [**6: Modelli come strumenti**](./Module08/06.ModelsAsTools.md)

## Obiettivi di apprendimento del corso

Completando questo corso completo su EdgeAI, svilupperai le competenze necessarie per progettare, implementare e distribuire soluzioni EdgeAI pronte per la produzione. Il nostro approccio strutturato garantisce che tu padroneggi sia le basi teoriche che le competenze pratiche di implementazione.

### Competenze tecniche

**Conoscenze di base**
- Comprendere le differenze fondamentali tra architetture AI basate su cloud e edge
- Padroneggiare i principi di quantizzazione, compressione e ottimizzazione dei modelli per ambienti con risorse limitate
- Comprendere le opzioni di accelerazione hardware (NPU, GPU, CPU) e le loro implicazioni di distribuzione

**Competenze di implementazione**
- Distribuire modelli linguistici ridotti su diverse piattaforme edge (mobile, embedded, IoT, server edge)
- Applicare framework di ottimizzazione come Llama.cpp, Microsoft Olive, ONNX Runtime e Apple MLX
- Implementare sistemi di inferenza in tempo reale con requisiti di risposta sotto il secondo

**Esperienza di produzione**
- Progettare architetture EdgeAI scalabili per applicazioni aziendali
- Implementare strategie di monitoraggio, manutenzione e aggiornamento per sistemi distribuiti
- Applicare le migliori pratiche di sicurezza per implementazioni EdgeAI orientate alla privacy

### Capacit√† strategiche

**Framework decisionale**
- Valutare le opportunit√† EdgeAI e identificare casi d'uso adatti per applicazioni aziendali
- Valutare i compromessi tra precisione del modello, velocit√† di inferenza, consumo energetico e costi hardware
- Selezionare famiglie e configurazioni SLM appropriate in base ai vincoli di distribuzione specifici

**Architettura di sistema**
- Progettare soluzioni EdgeAI end-to-end che si integrino con l'infrastruttura esistente
- Pianificare architetture ibride edge-cloud per prestazioni e costi ottimali
- Implementare flussi di dati e pipeline di elaborazione per applicazioni AI in tempo reale

### Applicazioni industriali

**Scenari di distribuzione pratica**
- **Manifattura**: Sistemi di controllo qualit√†, manutenzione predittiva e ottimizzazione dei processi
- **Sanit√†**: Strumenti diagnostici orientati alla privacy e sistemi di monitoraggio dei pazienti
- **Trasporti**: Decision-making per veicoli autonomi e gestione del traffico
- **Smart Cities**: Infrastrutture intelligenti e sistemi di gestione delle risorse
- **Elettronica di consumo**: Applicazioni mobili AI-powered e dispositivi smart home

## Panoramica degli obiettivi di apprendimento

### Obiettivi di apprendimento del Modulo 01:
- Comprendere le differenze fondamentali tra architetture AI cloud e edge
- Padroneggiare tecniche di ottimizzazione fondamentali per il deployment edge
- Riconoscere applicazioni reali e storie di successo
- Acquisire competenze pratiche per implementare soluzioni EdgeAI

### Obiettivi di apprendimento del Modulo 02:
- Comprensione approfondita delle diverse filosofie di design SLM e delle loro implicazioni di distribuzione
- Padroneggiare capacit√† decisionali strategiche basate su vincoli computazionali e requisiti prestazionali
- Comprendere i compromessi di flessibilit√† nella distribuzione
- Possedere intuizioni future per architetture AI efficienti

### Obiettivi di apprendimento del Modulo 03:
- Capacit√† strategiche di selezione dei modelli
- Padronanza delle tecniche di ottimizzazione
- Padronanza della flessibilit√† di distribuzione
- Capacit√† di configurazione pronta per la produzione

### Obiettivi di apprendimento del Modulo 04:
- Comprensione approfondita dei limiti di quantizzazione e delle applicazioni pratiche
- Esperienza pratica con diversi framework di ottimizzazione (Llama.cpp, Olive, OpenVINO, MLX)
- Padroneggiare l'ottimizzazione hardware Intel con OpenVINO e NNCF
- Capacit√† di selezione dell'ottimizzazione basata sull'hardware su diverse piattaforme
- Competenze di distribuzione per ambienti di calcolo edge multipiattaforma
- Selezione strategica dei framework e sintesi del flusso di lavoro per soluzioni Edge AI ottimali

### Obiettivi di apprendimento del Modulo 05:
- Padroneggiare il paradigma SLMOps e i principi operativi
- Implementare la distillazione del modello per il trasferimento di conoscenze e l'ottimizzazione dell'efficienza
- Applicare tecniche di fine-tuning per la personalizzazione del modello specifica del dominio
- Distribuire soluzioni SLM pronte per la produzione con strategie di monitoraggio e manutenzione

### Obiettivi di apprendimento del Modulo 06:
- Comprendere i concetti fondamentali degli agenti AI e dell'architettura dei modelli linguistici ridotti
- Padroneggiare l'implementazione della chiamata di funzioni su diverse piattaforme e framework
- Integrare il Model Context Protocol (MCP) per l'interazione standardizzata con strumenti esterni
- Costruire sistemi agentici sofisticati con requisiti minimi di intervento umano

### Obiettivi di apprendimento del Modulo 07:
- Padroneggiare il Toolkit AI per Visual Studio Code per flussi di lavoro di sviluppo Edge AI completi
- Acquisire competenze nella piattaforma Windows AI Foundry e nelle strategie di ottimizzazione NPU
- Acquisire esperienza pratica con diverse piattaforme EdgeAI e strategie di implementazione
- Padroneggiare tecniche di ottimizzazione specifiche per hardware su piattaforme NVIDIA, mobile, Azure e Windows
- Comprendere i compromessi di distribuzione tra prestazioni, costi e requisiti di privacy
- Sviluppare competenze pratiche per costruire applicazioni EdgeAI reali su diversi ecosistemi

## Risultati attesi del corso

Al termine del corso, sarai equipaggiato con le conoscenze, le competenze e la sicurezza necessarie per guidare iniziative EdgeAI in ambienti professionali.

### Prontezza professionale

**Leadership tecnica**
- **Architettura delle soluzioni**: Progettare sistemi EdgeAI completi che soddisfino i requisiti aziendali
- **Ottimizzazione delle prestazioni**: Raggiungere un equilibrio ottimale tra precisione, velocit√† e consumo di risorse
- **Distribuzione multipiattaforma**: Implementare soluzioni su Windows, Linux, mobile e piattaforme embedded
- **Operazioni di produzione**: Mantenere e scalare sistemi EdgeAI con affidabilit√† di livello aziendale

**Esperienza industriale**
- **Valutazione tecnologica**: Valutare e raccomandare soluzioni EdgeAI per sfide aziendali specifiche
- **Pianificazione dell'implementazione**: Sviluppare tempistiche realistiche e requisiti di risorse per progetti EdgeAI
- **Gestione del Rischio**: Identificare e mitigare i rischi tecnici e operativi nelle implementazioni EdgeAI
- **Ottimizzazione del ROI**: Dimostrare un valore aziendale misurabile dalle implementazioni EdgeAI

### Opportunit√† di Crescita Professionale

**Ruoli Professionali**
- EdgeAI Solutions Architect
- Machine Learning Engineer (Specializzazione Edge)
- IoT AI Developer
- Mobile AI Application Developer
- Enterprise AI Consultant

**Settori Industriali**
- Smart Manufacturing e Industria 4.0
- Veicoli Autonomi e Trasporti
- Tecnologia Sanitaria e Dispositivi Medici
- Tecnologia Finanziaria e Sicurezza
- Elettronica di Consumo e Applicazioni Mobile

### Certificazione e Validazione

**Sviluppo del Portfolio**
- Completare progetti EdgeAI end-to-end dimostrando competenze pratiche
- Distribuire soluzioni pronte per la produzione su diverse piattaforme hardware
- Documentare strategie di ottimizzazione e miglioramenti delle prestazioni ottenuti

**Percorso di Apprendimento Continuo**
- Base per specializzazioni avanzate in AI
- Preparazione per architetture ibride cloud-edge
- Porta d'accesso a tecnologie e framework AI emergenti

Questo corso ti posiziona all'avanguardia nella distribuzione della tecnologia AI, dove capacit√† intelligenti sono integrate senza soluzione di continuit√† nei dispositivi e nei sistemi che alimentano la vita moderna.

## Diagramma della Struttura dei File

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.openvino.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.AppleMLX.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.workflow-synthesis.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îú‚îÄ‚îÄ aitoolkit.md
‚îÇ   ‚îú‚îÄ‚îÄ windowdeveloper.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module08/ (Hands on with Foundry Local)
‚îÇ   ‚îú‚îÄ‚îÄ 01.FoundryLocalSetup.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.AzureAIFoundryIntegration.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.OpenSourceModels.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.CuttingEdgeModels.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.AIPoweredAgents.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.ModelsAsTools.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```

## Caratteristiche del Corso

- **Apprendimento Progressivo**: Avanzare gradualmente dai concetti di base alla distribuzione avanzata
- **Integrazione di Teoria e Pratica**: Ogni modulo contiene sia fondamenti teorici che operazioni pratiche
- **Casi Reali**: Basati su casi reali di Microsoft, Alibaba, Google e altri
- **Pratica Diretta**: Configurazione completa di file, procedure di test API e script di distribuzione
- **Benchmark delle Prestazioni**: Confronti dettagliati di velocit√† di inferenza, utilizzo della memoria e requisiti di risorse
- **Considerazioni di Livello Aziendale**: Pratiche di sicurezza, framework di conformit√† e strategie di protezione dei dati

## Per Iniziare

Percorso di Apprendimento Consigliato:
1. Inizia con **Module01** per costruire una comprensione fondamentale di EdgeAI
2. Procedi con **Module02** per comprendere a fondo le diverse famiglie di modelli SLM
3. Studia **Module03** per padroneggiare le competenze pratiche di distribuzione
4. Continua con **Module04** per l'ottimizzazione avanzata dei modelli, la conversione dei formati e la sintesi dei framework
5. Completa **Module05** per padroneggiare SLMOps per implementazioni pronte per la produzione
6. Esplora **Module06** per comprendere i sistemi agentici SLM e le capacit√† di chiamata delle funzioni
7. Concludi con **Module07** per acquisire esperienza pratica con AI Toolkit e diversi esempi di implementazione EdgeAI
8. Esplora **Module08** per un toolkit completo Foundry Local per sviluppatori (sviluppo locale con integrazione ibrida Azure)

Ogni modulo √® progettato per essere completo in modo indipendente, ma l'apprendimento sequenziale fornir√† i migliori risultati.

## Guida allo Studio

Una [Guida allo Studio](STUDY_GUIDE.md) completa √® disponibile per aiutarti a massimizzare la tua esperienza di apprendimento. La guida allo studio fornisce:

- **Percorsi di Apprendimento Strutturati**: Programmi ottimizzati per completare il corso in 20 ore
- **Indicazioni per l'Allocazione del Tempo**: Raccomandazioni specifiche per bilanciare lettura, esercizi e progetti
- **Focus sui Concetti Chiave**: Obiettivi di apprendimento prioritari per ogni modulo
- **Strumenti di Autovalutazione**: Domande ed esercizi per testare la tua comprensione
- **Idee per Mini-Progetti**: Applicazioni pratiche per rafforzare il tuo apprendimento

La guida allo studio √® progettata per adattarsi sia a un apprendimento intensivo (1 settimana) che a uno studio part-time (3 settimane), con indicazioni chiare su come allocare il tuo tempo in modo efficace anche se puoi dedicare solo 10 ore al corso.

---

**Il futuro di EdgeAI risiede nel miglioramento continuo delle architetture dei modelli, delle tecniche di quantizzazione e delle strategie di distribuzione che privilegiano efficienza e specializzazione rispetto alle capacit√† generiche. Le organizzazioni che abbracciano questo cambiamento di paradigma saranno ben posizionate per sfruttare il potenziale trasformativo dell'AI mantenendo il controllo sui propri dati e operazioni.**

## Altri Corsi

Il nostro team produce altri corsi! Dai un'occhiata:

- [MCP for Beginners](https://github.com/microsoft/mcp-for-beginners)
- [AI Agents For Beginners](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Generative AI for Beginners using .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
- [Generative AI for Beginners using JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)
- [Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
- [ML for Beginners](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
- [Data Science for Beginners](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
- [AI for Beginners](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
- [Cybersecurity for Beginners](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)
- [Web Dev for Beginners](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
- [IoT for Beginners](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)
- [XR Development for Beginners](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Mastering GitHub Copilot for AI Paired Programming](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)
- [Mastering GitHub Copilot for C#/.NET Developers](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)
- [Choose Your Own Copilot Adventure](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)

---

