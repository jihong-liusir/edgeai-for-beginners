<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-09-17T23:15:20+00:00",
  "source_file": "Module01/README.md",
  "language_code": "it"
}
-->
# Capitolo 01: Trasformare il Deployment dell'AI per l'Edge

EdgeAI rappresenta un cambiamento di paradigma nel deployment dell'intelligenza artificiale, spostando le capacità dell'AI dal processamento basato su cloud ai dispositivi locali edge. Questo capitolo esplora i concetti fondamentali, le tecnologie chiave e le applicazioni pratiche che definiscono questo approccio trasformativo all'implementazione dell'AI.

## Struttura del Modulo

### [Sezione 1: Fondamenti di EdgeAI](./01.EdgeAIFundamentals.md)
Questa sezione stabilisce le basi confrontando i modelli di AI tradizionali basati su cloud con quelli di deployment edge. Esaminiamo le tecnologie abilitanti fondamentali, tra cui la quantizzazione dei modelli, l'ottimizzazione della compressione e i Small Language Models (SLMs) che superano i limiti computazionali dei dispositivi edge. La discussione sottolinea come queste innovazioni offrano una maggiore protezione della privacy, una latenza ultra-bassa e capacità di processamento offline robuste.

### [Sezione 2: Casi di Studio Reali](./02.RealWorldCaseStudies.md)
Attraverso esempi concreti come gli ecosistemi di modelli Phi e Mu di Microsoft e il sistema di reporting AI di Japan Airlines, questa sezione dimostra implementazioni di successo di EdgeAI in diversi settori. Questi casi di studio convalidano le prestazioni eccezionali degli SLMs in compiti specializzati e illustrano i benefici pratici delle strategie di deployment edge.

### [Sezione 3: Guida Pratica all'Implementazione](./03.PracticalImplementationGuide.md)
Questa sezione fornisce linee guida complete per la preparazione dell'ambiente di apprendimento pratico, coprendo strumenti di sviluppo essenziali, requisiti hardware, risorse principali dei modelli e framework di ottimizzazione. Stabilisce la base tecnica necessaria per consentire ai lettori di costruire e implementare le proprie soluzioni EdgeAI.

### [Sezione 4: Piattaforme Hardware per il Deployment Edge](./04.EdgeDeployment.md)
Questa sezione esplora l'ecosistema hardware che consente il deployment dell'AI per l'edge, coprendo piattaforme di Intel, Qualcomm, NVIDIA e Windows AI PCs. Fornisce confronti dettagliati sulle capacità hardware, tecniche di ottimizzazione specifiche per piattaforma e considerazioni pratiche per il deployment in vari scenari di edge computing.

## Risultati Chiave dell'Apprendimento

Entro la fine di questo capitolo, i lettori comprenderanno:
- Le differenze fondamentali tra le architetture AI basate su cloud e quelle edge
- Le tecniche di ottimizzazione principali per il deployment edge
- Applicazioni reali e storie di successo
- Competenze pratiche per implementare soluzioni EdgeAI
- La selezione delle piattaforme hardware e gli approcci di ottimizzazione specifici per piattaforma
- Benchmarking delle prestazioni e migliori pratiche di deployment

## Implicazioni Future

EdgeAI si afferma come una tendenza critica che sta plasmando il futuro del deployment dell'AI, aprendo la strada a sistemi AI distribuiti, efficienti e che preservano la privacy, capaci di operare indipendentemente dalla connettività cloud mantenendo standard di prestazioni elevati.

---

**Disclaimer**:  
Questo documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.