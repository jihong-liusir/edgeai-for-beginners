<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T23:54:22+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "it"
}
-->
# Sezione 3: Fine-Tuning - Personalizzazione dei Modelli per Compiti Specifici

## Indice
1. [Introduzione al Fine-Tuning](../../../Module05)
2. [Perché il Fine-Tuning è Importante](../../../Module05)
3. [Tipi di Fine-Tuning](../../../Module05)
4. [Fine-Tuning con Microsoft Olive](../../../Module05)
5. [Esempi Pratici](../../../Module05)
6. [Best Practices e Linee Guida](../../../Module05)
7. [Tecniche Avanzate](../../../Module05)
8. [Valutazione e Monitoraggio](../../../Module05)
9. [Sfide Comuni e Soluzioni](../../../Module05)
10. [Conclusione](../../../Module05)

## Introduzione al Fine-Tuning

**Fine-tuning** è una tecnica potente di machine learning che consiste nell'adattare un modello pre-addestrato per svolgere compiti specifici o lavorare con dataset specializzati. Piuttosto che addestrare un modello da zero, il fine-tuning sfrutta la conoscenza già acquisita da un modello pre-addestrato e la adatta al tuo caso d'uso particolare.

### Cos'è il Fine-Tuning?

Il fine-tuning è una forma di **transfer learning** in cui:
- Si parte da un modello pre-addestrato che ha appreso schemi generali da grandi dataset
- Si regolano i parametri interni del modello utilizzando il tuo dataset specifico
- Si conserva la conoscenza acquisita, specializzando il modello per il tuo compito

Pensalo come insegnare a uno chef esperto a cucinare una nuova cucina: conosce già le basi della cucina, ma deve imparare tecniche e sapori specifici per il nuovo stile.

### Vantaggi Principali

- **Efficienza Temporale**: Molto più veloce rispetto all'addestramento da zero
- **Efficienza dei Dati**: Richiede dataset più piccoli per ottenere buone prestazioni
- **Convenienza Economica**: Minori requisiti computazionali
- **Prestazioni Migliori**: Spesso raggiunge risultati superiori rispetto all'addestramento da zero
- **Ottimizzazione delle Risorse**: Rende l'IA avanzata accessibile a team e organizzazioni più piccoli

## Perché il Fine-Tuning è Importante

### Applicazioni nel Mondo Reale

Il fine-tuning è essenziale in numerosi scenari:

**1. Adattamento al Dominio**
- AI Medica: Adattare modelli di linguaggio generali alla terminologia medica e alle note cliniche
- Tecnologia Legale: Specializzare modelli per l'analisi di documenti legali e la revisione dei contratti
- Servizi Finanziari: Personalizzare modelli per l'analisi di rapporti finanziari e la valutazione del rischio

**2. Specializzazione del Compito**
- Generazione di Contenuti: Fine-tuning per stili di scrittura o toni specifici
- Generazione di Codice: Adattare modelli per linguaggi di programmazione o framework particolari
- Traduzione: Migliorare le prestazioni per coppie di lingue specifiche o domini tecnici

**3. Applicazioni Aziendali**
- Servizio Clienti: Creare chatbot che comprendano la terminologia specifica dell'azienda
- Documentazione Interna: Costruire assistenti AI familiari con i processi organizzativi
- Soluzioni Specifiche per Settore: Sviluppare modelli che comprendano il gergo e i flussi di lavoro del settore

## Tipi di Fine-Tuning

### 1. Fine-Tuning Completo (Instruction Fine-Tuning)

Nel fine-tuning completo, tutti i parametri del modello vengono aggiornati durante l'addestramento. Questo approccio:
- Offre la massima flessibilità e potenziale di prestazioni
- Richiede risorse computazionali significative
- Risulta in una versione completamente nuova del modello
- Ideale per scenari in cui si dispone di molti dati di addestramento e risorse computazionali

### 2. Fine-Tuning Efficiente dei Parametri (PEFT)

I metodi PEFT aggiornano solo un piccolo sottoinsieme di parametri, rendendo il processo più efficiente:

#### Low-Rank Adaptation (LoRA)
- Aggiunge piccole matrici di decomposizione a basso rango ai pesi esistenti
- Riduce drasticamente il numero di parametri da addestrare
- Mantiene prestazioni vicine al fine-tuning completo
- Consente di passare facilmente tra diverse adattamenti

#### QLoRA (Quantized LoRA)
- Combina LoRA con tecniche di quantizzazione
- Riduce ulteriormente i requisiti di memoria
- Consente il fine-tuning di modelli più grandi su hardware consumer
- Bilancia efficienza e prestazioni

#### Adapters
- Inserisce piccole reti neurali tra i livelli esistenti
- Permette un fine-tuning mirato mantenendo il modello base congelato
- Consente un approccio modulare alla personalizzazione del modello

### 3. Fine-Tuning Specifico per il Compito

Si concentra sull'adattamento dei modelli per compiti specifici downstream:
- **Classificazione**: Regolazione dei modelli per compiti di categorizzazione
- **Generazione**: Ottimizzazione per la creazione di contenuti e generazione di testo
- **Estrazione**: Fine-tuning per l'estrazione di informazioni e il riconoscimento di entità nominate
- **Sintesi**: Specializzazione dei modelli per la sintesi di documenti

## Fine-Tuning con Microsoft Olive

Microsoft Olive è un toolkit completo per l'ottimizzazione dei modelli che semplifica il processo di fine-tuning offrendo funzionalità di livello enterprise.

### Cos'è Microsoft Olive?

Microsoft Olive è uno strumento open-source per l'ottimizzazione dei modelli che:
- Snellisce i flussi di lavoro di fine-tuning per vari target hardware
- Fornisce supporto integrato per architetture di modelli popolari (Llama, Phi, Qwen, Gemma)
- Offre opzioni di distribuzione sia cloud che locale
- Si integra perfettamente con Azure ML e altri servizi AI di Microsoft
- Supporta ottimizzazione e quantizzazione automatica

### Caratteristiche Principali

- **Ottimizzazione Consapevole dell'Hardware**: Ottimizza automaticamente i modelli per hardware specifici (CPU, GPU, NPU)
- **Supporto Multi-Formato**: Funziona con modelli PyTorch, Hugging Face e ONNX
- **Flussi di Lavoro Automatizzati**: Riduce la configurazione manuale e il tentativo-errore
- **Integrazione Aziendale**: Supporto integrato per Azure ML e distribuzioni cloud
- **Architettura Estensibile**: Consente tecniche di ottimizzazione personalizzate

### Installazione e Configurazione

#### Installazione Base

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dipendenze Opzionali

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Verifica dell'Installazione

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Esempi Pratici

### Esempio 1: Fine-Tuning di Base con Olive CLI

Questo esempio dimostra il fine-tuning di un piccolo modello di linguaggio per la classificazione di frasi:

#### Passo 1: Prepara l'Ambiente

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Passo 2: Fine-Tuning del Modello

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Passo 3: Ottimizzazione per la Distribuzione

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Esempio 2: Configurazione Avanzata con Dataset Personalizzato

#### Passo 1: Prepara il Dataset Personalizzato

Crea un file JSON con i tuoi dati di addestramento:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Passo 2: Crea il File di Configurazione

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Passo 3: Esegui il Fine-Tuning

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Esempio 3: Fine-Tuning QLoRA per Efficienza di Memoria

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Best Practices e Linee Guida

### Preparazione dei Dati

**1. Qualità dei Dati sopra la Quantità**
- Dai priorità a esempi di alta qualità e diversificati rispetto a grandi volumi di dati scadenti
- Assicurati che i dati siano rappresentativi del tuo caso d'uso
- Pulisci e pre-elabora i dati in modo coerente

**2. Formato e Template dei Dati**
- Usa formattazioni coerenti per tutti gli esempi di addestramento
- Crea template chiari input-output che corrispondano al tuo caso d'uso
- Includi formattazioni appropriate per modelli istruiti con istruzioni

**3. Suddivisione del Dataset**
- Riserva il 10-20% dei dati per la validazione
- Mantieni distribuzioni simili tra i set di addestramento e validazione
- Considera il campionamento stratificato per compiti di classificazione

### Configurazione dell'Addestramento

**1. Selezione del Learning Rate**
- Inizia con learning rate più piccoli (1e-5 a 1e-4) per il fine-tuning
- Usa la programmazione del learning rate per una migliore convergenza
- Monitora le curve di perdita per regolare i tassi di apprendimento

**2. Ottimizzazione della Dimensione del Batch**
- Bilancia la dimensione del batch con la memoria disponibile
- Usa l'accumulo del gradiente per dimensioni del batch effettive più grandi
- Considera la relazione tra dimensione del batch e learning rate

**3. Durata dell'Addestramento**
- Monitora i metrici di validazione per evitare l'overfitting
- Usa l'interruzione anticipata quando le prestazioni di validazione si stabilizzano
- Salva checkpoint regolarmente per il recupero e l'analisi

### Selezione del Modello

**1. Scelta del Modello Base**
- Seleziona modelli pre-addestrati su domini simili quando possibile
- Considera la dimensione del modello rispetto ai tuoi vincoli computazionali
- Valuta i requisiti di licenza per l'uso commerciale

**2. Selezione del Metodo di Fine-Tuning**
- Usa LoRA/QLoRA per ambienti con risorse limitate
- Scegli il fine-tuning completo quando le prestazioni massime sono critiche
- Considera approcci basati su adapter per scenari con compiti multipli

### Gestione delle Risorse

**1. Ottimizzazione dell'Hardware**
- Scegli hardware appropriato per la dimensione del modello e il metodo
- Utilizza la memoria GPU in modo efficiente con il checkpointing del gradiente
- Considera soluzioni basate su cloud per modelli più grandi

**2. Gestione della Memoria**
- Usa l'addestramento a precisione mista quando disponibile
- Implementa l'accumulo del gradiente per vincoli di memoria
- Monitora l'utilizzo della memoria GPU durante l'addestramento

## Tecniche Avanzate

### Addestramento Multi-Adapter

Addestra più adapter per compiti diversi condividendo il modello base:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Ottimizzazione degli Iperparametri

Implementa una sistematica ottimizzazione degli iperparametri:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Funzioni di Perdita Personalizzate

Implementa funzioni di perdita specifiche per il dominio:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Valutazione e Monitoraggio

### Metriche e Valutazione

**1. Metriche Standard**
- **Accuratezza**: Correttezza complessiva per compiti di classificazione
- **Perplessità**: Misura della qualità del linguaggio modellato
- **BLEU/ROUGE**: Qualità della generazione di testo e sintesi
- **F1 Score**: Equilibrio tra precisione e richiamo per la classificazione

**2. Metriche Specifiche per il Dominio**
- **Benchmark Specifici per il Compito**: Usa benchmark consolidati per il tuo dominio
- **Valutazione Umana**: Includi valutazioni umane per compiti soggettivi
- **Metriche Aziendali**: Allinea con gli obiettivi aziendali reali

**3. Configurazione della Valutazione**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitoraggio del Progresso dell'Addestramento

**1. Tracciamento della Perdita**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Monitoraggio della Validazione**
- Traccia la perdita di validazione insieme alla perdita di addestramento
- Monitora segni di overfitting (perdita di validazione che aumenta mentre la perdita di addestramento diminuisce)
- Usa l'interruzione anticipata basata su metriche di validazione

**3. Monitoraggio delle Risorse**
- Monitora l'utilizzo di GPU/CPU
- Traccia i pattern di utilizzo della memoria
- Monitora la velocità e il throughput dell'addestramento

## Sfide Comuni e Soluzioni

### Sfida 1: Overfitting

**Sintomi:**
- La perdita di addestramento continua a diminuire mentre la perdita di validazione aumenta
- Grande divario tra prestazioni di addestramento e validazione
- Scarsa generalizzazione su nuovi dati

**Soluzioni:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Sfida 2: Limitazioni di Memoria

**Soluzioni:**
- Usa il checkpointing del gradiente
- Implementa l'accumulo del gradiente
- Scegli metodi efficienti per i parametri (LoRA, QLoRA)
- Utilizza il parallelismo del modello per modelli grandi

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Sfida 3: Addestramento Lento

**Soluzioni:**
- Ottimizza le pipeline di caricamento dei dati
- Usa l'addestramento a precisione mista
- Implementa strategie di batching efficienti
- Considera l'addestramento distribuito per dataset grandi

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Sfida 4: Prestazioni Scarse

**Passi Diagnostici:**
1. Verifica la qualità e la formattazione dei dati
2. Controlla il learning rate e la durata dell'addestramento
3. Valuta la scelta del modello base
4. Rivedi la pre-elaborazione e la tokenizzazione

**Soluzioni:**
- Aumenta la diversità dei dati di addestramento
- Regola la programmazione del learning rate
- Prova modelli base diversi
- Implementa tecniche di aumento dei dati

## Conclusione

Il fine-tuning è una tecnica potente che democratizza l'accesso alle capacità IA all'avanguardia. Utilizzando strumenti come Microsoft Olive, le organizzazioni possono adattare efficacemente modelli pre-addestrati alle loro esigenze specifiche ottimizzando al contempo prestazioni e vincoli di risorse.

### Punti Chiave

1. **Scegli l'Approccio Giusto**: Seleziona i metodi di fine-tuning in base alle tue risorse computazionali e ai requisiti di prestazioni
2. **La Qualità dei Dati è Importante**: Investi in dati di addestramento di alta qualità e rappresentativi
3. **Monitora e Itera**: Valuta e migliora continuamente i tuoi modelli
4. **Sfrutta gli Strumenti**: Usa framework come Olive per semplificare e ottimizzare il processo
5. **Considera la Distribuzione**: Pianifica l'ottimizzazione e la distribuzione del modello fin dall'inizio

## ➡️ Prossimi Passi

- [04: Deployment - Implementazione del Modello Pronto per la Produzione](./04.SLMOps.Deployment.md)

---

**Disclaimer**:  
Questo documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.