<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2fcb41618c97e3a41652a0d4eca07765",
  "translation_date": "2025-09-17T22:13:08+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "it"
}
-->
# EdgeAI per Principianti: Percorsi di Apprendimento e Programma di Studio

### Percorso di Apprendimento Concentrato (1 settimana)

| Giorno | Focus | Ore Stimate |
|--------|-------|-------------|
| Giorno 1 | Modulo 1: Fondamenti di EdgeAI | 3 ore |
| Giorno 2 | Modulo 2: Fondamenti di SLM | 3 ore |
| Giorno 3 | Modulo 3: Deployment di SLM | 2 ore |
| Giorno 4-5 | Modulo 4: Ottimizzazione del Modello (6 framework) | 4 ore |
| Giorno 6 | Modulo 5: SLMOps | 3 ore |
| Giorno 7 | Modulo 6-7: Agenti AI & Strumenti di Sviluppo | 5 ore |

### Percorso di Apprendimento Concentrato (2 settimane)

| Giorno | Focus | Ore Stimate |
|--------|-------|-------------|
| Giorno 1-2 | Modulo 1: Fondamenti di EdgeAI | 3 ore |
| Giorno 3-4 | Modulo 2: Fondamenti di SLM | 3 ore |
| Giorno 5-6 | Modulo 3: Deployment di SLM | 2 ore |
| Giorno 7-8 | Modulo 4: Ottimizzazione del Modello | 4 ore |
| Giorno 9-10 | Modulo 5: SLMOps | 3 ore |
| Giorno 11-12 | Modulo 6: Agenti AI | 2 ore |
| Giorno 13-14 | Modulo 7: Strumenti di Sviluppo | 3 ore |

### Studio Part-Time (4 settimane)

| Settimana | Focus | Ore Stimate |
|-----------|-------|-------------|
| Settimana 1 | Modulo 1-2: Fondamenti & Fondamenti di SLM | 6 ore |
| Settimana 2 | Modulo 3-4: Deployment & Ottimizzazione | 6 ore |
| Settimana 3 | Modulo 5-6: SLMOps & Agenti AI | 5 ore |
| Settimana 4 | Modulo 7: Strumenti di Sviluppo & Integrazione | 3 ore |

| Giorno | Focus | Ore Stimate |
|--------|-------|-------------|
| Giorno 1-2 | Modulo 1: Fondamenti di EdgeAI | 3 ore |
| Giorno 3-4 | Modulo 2: Fondamenti di SLM | 3 ore |
| Giorno 5-6 | Modulo 3: Deployment di SLM | 2 ore |
| Giorno 7-8 | Modulo 4: Ottimizzazione del Modello | 4 ore |
| Giorno 9-10 | Modulo 5: SLMOps | 3 ore |
| Giorno 11-12 | Modulo 6: Sistemi Agenti SLM | 2 ore |
| Giorno 13-14 | Modulo 7: Esempi di Implementazione EdgeAI | 2 ore |

| Modulo | Data di Completamento | Ore Trascorse | Principali Conclusioni |
|--------|-----------------------|---------------|------------------------|
| Modulo 1: Fondamenti di EdgeAI | | | |
| Modulo 2: Fondamenti di SLM | | | |
| Modulo 3: Deployment di SLM | | | |
| Modulo 4: Ottimizzazione del Modello (6 framework) | | | |
| Modulo 5: SLMOps | | | |
| Modulo 6: Sistemi Agenti SLM | | | |
| Modulo 7: Esempi di Implementazione EdgeAI | | | |
| Esercizi Pratici | | | |
| Mini-Progetto | | | |

### Studio Part-Time (4 settimane)

| Settimana | Focus | Ore Stimate |
|-----------|-------|-------------|
| Settimana 1 | Modulo 1-2: Fondamenti & Fondamenti di SLM | 6 ore |
| Settimana 2 | Modulo 3-4: Deployment & Ottimizzazione | 6 ore |
| Settimana 3 | Modulo 5-6: SLMOps & Agenti AI | 5 ore |
| Settimana 4 | Modulo 7: Strumenti di Sviluppo & Integrazione | 3 ore |

## Introduzione

Benvenuto nella guida di studio "EdgeAI per Principianti"! Questo documento è progettato per aiutarti a navigare efficacemente nei materiali del corso e massimizzare la tua esperienza di apprendimento. Fornisce percorsi di apprendimento strutturati, programmi di studio suggeriti, riassunti dei concetti chiave e risorse supplementari per approfondire la tua comprensione delle tecnologie EdgeAI.

Questo è un corso conciso di 20 ore che offre conoscenze essenziali su EdgeAI in un formato efficiente, ideale per professionisti e studenti impegnati che desiderano acquisire rapidamente competenze pratiche in questo campo emergente.

## Panoramica del Corso

Il corso è organizzato in sette moduli completi:

1. **Fondamenti e Trasformazione di EdgeAI** - Comprendere i concetti fondamentali e il cambiamento tecnologico
2. **Fondamenti di Modelli Linguistici Ridotti (SLM)** - Esplorare le diverse famiglie di SLM e le loro architetture
3. **Deployment di Modelli Linguistici Ridotti** - Implementare strategie pratiche di deployment
4. **Conversione del Formato del Modello e Quantizzazione** - Ottimizzazione avanzata con 6 framework, inclusi OpenVINO
5. **SLMOps - Operazioni sui Modelli Linguistici Ridotti** - Gestione del ciclo di vita e deployment in produzione
6. **Sistemi Agenti SLM** - Agenti AI, chiamata di funzioni e protocollo di contesto del modello
7. **Esempi di Implementazione EdgeAI** - Toolkit AI, sviluppo su Windows e implementazioni specifiche per piattaforma

## Come Utilizzare Questa Guida di Studio

- **Apprendimento Progressivo**: Segui i moduli in ordine per un'esperienza di apprendimento più coerente
- **Checkpoint di Conoscenza**: Utilizza le domande di autovalutazione dopo ogni sezione
- **Pratica Pratica**: Completa gli esercizi suggeriti per rafforzare i concetti teorici
- **Risorse Supplementari**: Esplora materiali aggiuntivi per gli argomenti che ti interessano di più

## Raccomandazioni per il Programma di Studio

### Percorso di Apprendimento Concentrato (1 settimana)

| Giorno | Focus | Ore Stimate |
|--------|-------|-------------|
| Giorno 1-2 | Modulo 1: Fondamenti di EdgeAI | 6 ore |
| Giorno 3-4 | Modulo 2: Fondamenti di SLM | 8 ore |
| Giorno 5-6 | Modulo 3: Deployment di SLM | 6 ore |

### Studio Part-Time (3 settimane)

| Settimana | Focus | Ore Stimate |
|-----------|-------|-------------|
| Settimana 1 | Modulo 1: Fondamenti di EdgeAI | 6-7 ore |
| Settimana 2 | Modulo 2: Fondamenti di SLM | 7-8 ore |
| Settimana 3 | Modulo 3: Deployment di SLM | 5-6 ore |

## Modulo 1: Fondamenti e Trasformazione di EdgeAI

### Obiettivi Principali di Apprendimento

- Comprendere le differenze tra AI basata su cloud e AI basata su edge
- Padroneggiare le tecniche di ottimizzazione fondamentali per ambienti con risorse limitate
- Analizzare applicazioni reali delle tecnologie EdgeAI
- Configurare un ambiente di sviluppo per progetti EdgeAI

### Aree di Studio

#### Sezione 1: Fondamenti di EdgeAI
- **Concetti Prioritari**: 
  - Paradigmi di calcolo Edge vs. Cloud
  - Tecniche di quantizzazione del modello
  - Opzioni di accelerazione hardware (NPU, GPU, CPU)
  - Vantaggi in termini di privacy e sicurezza

- **Materiali Supplementari**:
  - [Documentazione TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Documentazione Edge Impulse](https://docs.edgeimpulse.com)

#### Sezione 2: Studi di Caso Reali
- **Concetti Prioritari**: 
  - Ecosistema di modelli Microsoft Phi & Mu
  - Implementazioni pratiche in diversi settori
  - Considerazioni sul deployment

#### Sezione 3: Guida Pratica all'Implementazione
- **Concetti Prioritari**: 
  - Configurazione dell'ambiente di sviluppo
  - Strumenti di quantizzazione e ottimizzazione
  - Metodi di valutazione per implementazioni EdgeAI

#### Sezione 4: Hardware per il Deployment Edge
- **Concetti Prioritari**: 
  - Confronti tra piattaforme hardware
  - Strategie di ottimizzazione per hardware specifico
  - Considerazioni sul deployment

### Domande di Autovalutazione

1. Confronta e contrasta l'AI basata su cloud con le implementazioni AI basate su edge.
2. Spiega tre tecniche chiave per ottimizzare i modelli per il deployment edge.
3. Quali sono i principali vantaggi di eseguire modelli AI sull'edge?
4. Descrivi il processo di quantizzazione di un modello e come influisce sulle prestazioni.
5. Spiega come diversi acceleratori hardware (NPU, GPU, CPU) influenzano il deployment EdgeAI.

### Esercizi Pratici

1. **Configurazione Rapida dell'Ambiente**: Configura un ambiente di sviluppo minimo con i pacchetti essenziali (30 minuti)
2. **Esplorazione del Modello**: Scarica ed esamina un modello linguistico ridotto pre-addestrato (1 ora)
3. **Quantizzazione Base**: Prova una semplice quantizzazione su un modello ridotto (1 ora)
- Alberi decisionali per la selezione del framework  
- Validazione della prontezza per la produzione  
- Strategie per garantire la longevità tecnologica  

### Domande di autovalutazione  

1. Confronta le strategie di quantizzazione tra diversi livelli di precisione (da 1-bit a 8-bit).  
2. Spiega i vantaggi del formato GGUF per il deployment su dispositivi edge.  
3. In che modo l'ottimizzazione hardware-aware in Microsoft Olive migliora l'efficienza del deployment?  
4. Quali sono i principali benefici di NNCF di OpenVINO per la compressione dei modelli?  
5. Descrivi come Apple MLX sfrutta l'architettura di memoria unificata per l'ottimizzazione.  
6. In che modo la sintesi del workflow aiuta nella selezione dei framework di ottimizzazione ottimali?  

### Esercizi pratici  

1. **Quantizzazione del modello**: Applica diversi livelli di quantizzazione a un modello e confronta i risultati (1 ora).  
2. **Ottimizzazione con OpenVINO**: Utilizza NNCF per comprimere un modello per hardware Intel (1 ora).  
3. **Confronto tra framework**: Testa lo stesso modello su tre diversi framework di ottimizzazione (1 ora).  
4. **Benchmark delle prestazioni**: Misura l'impatto dell'ottimizzazione sulla velocità di inferenza e sull'uso della memoria (1 ora).  

## Modulo 5: SLMOps - Operazioni sui modelli linguistici piccoli  

### Obiettivi principali di apprendimento  

- Comprendere i principi di gestione del ciclo di vita di SLMOps  
- Padroneggiare le tecniche di distillazione e fine-tuning per il deployment su dispositivi edge  
- Implementare strategie di deployment in produzione con monitoraggio  
- Costruire workflow di operazioni e manutenzione di SLM di livello aziendale  

### Aree di studio  

#### Sezione 1: Introduzione a SLMOps  
- **Concetti prioritari**:  
  - Cambiamento di paradigma di SLMOps nelle operazioni AI  
  - Efficienza dei costi e architettura orientata alla privacy  
  - Impatto strategico sul business e vantaggi competitivi  

#### Sezione 2: Distillazione del modello  
- **Concetti prioritari**:  
  - Tecniche di trasferimento della conoscenza  
  - Implementazione del processo di distillazione a due fasi  
  - Workflow di distillazione con Azure ML  

#### Sezione 3: Strategie di fine-tuning  
- **Concetti prioritari**:  
  - Fine-tuning efficiente dei parametri (PEFT)  
  - Metodi avanzati LoRA e QLoRA  
  - Addestramento multi-adapter e ottimizzazione degli iperparametri  

#### Sezione 4: Deployment in produzione  
- **Concetti prioritari**:  
  - Conversione e quantizzazione del modello per la produzione  
  - Configurazione del deployment con Foundry Local  
  - Benchmark delle prestazioni e validazione della qualità  

### Domande di autovalutazione  

1. In che modo SLMOps differisce da MLOps tradizionali?  
2. Spiega i benefici della distillazione del modello per il deployment su dispositivi edge.  
3. Quali sono le considerazioni chiave per il fine-tuning di SLM in ambienti con risorse limitate?  
4. Descrivi una pipeline completa di deployment in produzione per applicazioni AI su dispositivi edge.  

### Esercizi pratici  

1. **Distillazione di base**: Crea un modello più piccolo partendo da un modello più grande (1 ora).  
2. **Esperimento di fine-tuning**: Effettua il fine-tuning di un modello per un dominio specifico (1 ora).  
3. **Pipeline di deployment**: Configura una pipeline CI/CD di base per il deployment del modello (1 ora).  

## Modulo 6: Sistemi agentici SLM - Agenti AI e chiamata di funzioni  

### Obiettivi principali di apprendimento  

- Costruire agenti AI intelligenti per ambienti edge utilizzando modelli linguistici piccoli  
- Implementare capacità di chiamata di funzioni con workflow sistematici  
- Padroneggiare l'integrazione del Model Context Protocol (MCP) per interazioni standardizzate con strumenti  
- Creare sistemi agentici sofisticati con intervento umano minimo  

### Aree di studio  

#### Sezione 1: Agenti AI e fondamenti SLM  
- **Concetti prioritari**:  
  - Framework di classificazione degli agenti (riflessivi, basati su modelli, basati su obiettivi, agenti di apprendimento)  
  - Analisi dei compromessi tra SLM e LLM  
  - Pattern di progettazione specifici per agenti edge  
  - Ottimizzazione delle risorse per gli agenti  

#### Sezione 2: Chiamata di funzioni nei modelli linguistici piccoli  
- **Concetti prioritari**:  
  - Implementazione di workflow sistematici (rilevamento dell'intento, output JSON, esecuzione esterna)  
  - Implementazioni specifiche per piattaforma (Phi-4-mini, modelli Qwen selezionati, Microsoft Foundry Local)  
  - Esempi avanzati (collaborazione multi-agente, selezione dinamica degli strumenti)  
  - Considerazioni per la produzione (limitazione del tasso, registrazione degli audit, misure di sicurezza)  

#### Sezione 3: Integrazione del Model Context Protocol (MCP)  
- **Concetti prioritari**:  
  - Architettura del protocollo e progettazione del sistema a strati  
  - Supporto multi-backend (Ollama per lo sviluppo, vLLM per la produzione)  
  - Protocolli di connessione (modalità STDIO e SSE)  
  - Applicazioni reali (automazione web, elaborazione dati, integrazione API)  

### Domande di autovalutazione  

1. Quali sono le considerazioni architetturali chiave per gli agenti AI su dispositivi edge?  
2. In che modo la chiamata di funzioni migliora le capacità degli agenti?  
3. Spiega il ruolo del Model Context Protocol nella comunicazione degli agenti.  

### Esercizi pratici  

1. **Agente semplice**: Costruisci un agente AI di base con capacità di chiamata di funzioni (1 ora).  
2. **Integrazione MCP**: Implementa MCP in un'applicazione per agenti (30 minuti).  

## Modulo 7: Esempi di implementazione EdgeAI  

### Obiettivi principali di apprendimento  

- Padroneggiare AI Toolkit per Visual Studio Code per workflow completi di sviluppo EdgeAI  
- Acquisire competenze nella piattaforma Windows AI Foundry e nelle strategie di ottimizzazione NPU  
- Implementare EdgeAI su più piattaforme hardware e scenari di deployment  
- Costruire applicazioni EdgeAI pronte per la produzione con ottimizzazioni specifiche per piattaforma  

### Aree di studio  

#### Sezione 1: AI Toolkit per Visual Studio Code  
- **Concetti prioritari**:  
  - Ambiente di sviluppo Edge AI completo all'interno di VS Code  
  - Catalogo e scoperta dei modelli per il deployment su dispositivi edge  
  - Workflow di test locale, ottimizzazione e sviluppo di agenti  
  - Monitoraggio delle prestazioni e valutazione per scenari edge  

#### Sezione 2: Guida allo sviluppo EdgeAI su Windows  
- **Concetti prioritari**:  
  - Panoramica completa della piattaforma Windows AI Foundry  
  - API Phi Silica per inferenza NPU efficiente  
  - API di visione artificiale per elaborazione immagini e OCR  
  - CLI Foundry Local per sviluppo e test locale  

#### Sezione 3: Implementazioni specifiche per piattaforma  
- **Concetti prioritari**:  
  - Deployment su NVIDIA Jetson Orin Nano (prestazioni AI di 67 TOPS)  
  - Applicazioni mobili con .NET MAUI e ONNX Runtime GenAI  
  - Soluzioni Azure EdgeAI con architettura ibrida cloud-edge  
  - Ottimizzazione Windows ML con supporto hardware universale  
  - Applicazioni Foundry Local con implementazione RAG orientata alla privacy  

### Domande di autovalutazione  

1. In che modo AI Toolkit semplifica il workflow di sviluppo EdgeAI?  
2. Confronta le strategie di deployment su diverse piattaforme hardware.  
3. Quali sono i vantaggi di Windows AI Foundry per lo sviluppo edge?  
4. Spiega il ruolo dell'ottimizzazione NPU nelle moderne applicazioni AI su dispositivi edge.  
5. In che modo l'API Phi Silica sfrutta l'hardware NPU per l'ottimizzazione delle prestazioni?  
6. Confronta i benefici del deployment locale rispetto a quello cloud per applicazioni sensibili alla privacy.  

### Esercizi pratici  

1. **Configurazione AI Toolkit**: Configura AI Toolkit e ottimizza un modello (1 ora).  
2. **Windows AI Foundry**: Costruisci una semplice applicazione AI per Windows utilizzando l'API Phi Silica (1 ora).  
3. **Deployment cross-platform**: Effettua il deployment dello stesso modello su due piattaforme diverse (1 ora).  
4. **Ottimizzazione NPU**: Testa le prestazioni NPU con gli strumenti di Windows AI Foundry (30 minuti).  

## Guida alla distribuzione del tempo  

Per aiutarti a sfruttare al meglio le 20 ore del corso, ecco una suddivisione suggerita:  

| Attività | Allocazione del tempo | Descrizione |  
|----------|-----------------------|-------------|  
| Lettura dei materiali principali | 9 ore | Concentrarsi sui concetti essenziali di ogni modulo |  
| Esercizi pratici | 6 ore | Implementazione pratica delle tecniche chiave |  
| Autovalutazione | 2 ore | Testare la comprensione attraverso domande e riflessioni |  
| Mini-progetto | 3 ore | Applicare le conoscenze a una piccola implementazione pratica |  

### Aree di focus principali in base al tempo disponibile  

**Se hai solo 10 ore:**  
- Completa i Moduli 1, 2 e 3 (concetti fondamentali di EdgeAI).  
- Fai almeno un esercizio pratico per modulo.  
- Concentrati sulla comprensione dei concetti principali piuttosto che sui dettagli di implementazione.  

**Se puoi dedicare l'intero corso di 20 ore:**  
- Completa tutti e sette i moduli.  
- Esegui gli esercizi pratici chiave di ogni modulo.  
- Completa un mini-progetto dal Modulo 7.  
- Esplora almeno 2-3 risorse supplementari.  

**Se hai più di 20 ore:**  
- Completa tutti i moduli con esercizi dettagliati.  
- Costruisci più mini-progetti.  
- Esplora tecniche avanzate di ottimizzazione nel Modulo 4.  
- Implementa il deployment in produzione dal Modulo 5.  

## Risorse essenziali  

Queste risorse selezionate offrono il massimo valore per il tuo tempo di studio limitato:  

### Documentazione da leggere assolutamente  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Lo strumento di ottimizzazione dei modelli più efficiente  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Il modo più veloce per effettuare il deployment di SLM localmente  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Riferimento per un modello ottimizzato per dispositivi edge  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Toolkit di ottimizzazione completo di Intel  
- [AI Toolkit per VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Ambiente di sviluppo EdgeAI integrato  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Piattaforma di sviluppo EdgeAI specifica per Windows  

### Strumenti per risparmiare tempo  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Accesso rapido ai modelli e deployment  
- [Gradio](https://www.gradio.app/docs/interface) - Sviluppo rapido di interfacce per demo AI  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Ottimizzazione semplificata dei modelli  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferenza efficiente su CPU  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework per la compressione delle reti neurali  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit per il deployment di modelli linguistici grandi  

## Template per il monitoraggio dei progressi  

Usa questo template semplificato per monitorare i tuoi progressi di apprendimento durante il corso di 20 ore:  

| Modulo | Data di completamento | Ore dedicate | Principali takeaway |  
|--------|-----------------------|--------------|---------------------|  
| Modulo 1: Fondamenti di EdgeAI | | | |  
| Modulo 2: Fondamenti SLM | | | |  
| Modulo 3: Deployment SLM | | | |  
| Modulo 4: Ottimizzazione del modello | | | |  
| Modulo 5: SLMOps | | | |  
| Modulo 6: Agenti AI | | | |  
| Modulo 7: Strumenti di sviluppo | | | |  
| Esercizi pratici | | | |  
| Mini-progetto | | | |  

## Idee per mini-progetti  

Considera di completare uno di questi progetti per mettere in pratica i concetti di EdgeAI (ognuno progettato per durare 2-4 ore):  

### Progetti per principianti (2-3 ore ciascuno)  
1. **Assistente testuale edge**: Crea uno strumento semplice di completamento del testo offline utilizzando un modello linguistico piccolo.  
2. **Dashboard di confronto modelli**: Costruisci una visualizzazione di base delle metriche di prestazione tra diversi SLM.  
3. **Esperimento di ottimizzazione**: Misura l'impatto di diversi livelli di quantizzazione sullo stesso modello di base.  

### Progetti intermedi (3-4 ore ciascuno)  
4. **Workflow AI Toolkit**: Utilizza AI Toolkit di VS Code per ottimizzare e effettuare il deployment di un modello dall'inizio alla fine.  
5. **Applicazione Windows AI Foundry**: Crea un'app Windows utilizzando l'API Phi Silica e l'ottimizzazione NPU.  
6. **Deployment cross-platform**: Effettua il deployment dello stesso modello ottimizzato su Windows (OpenVINO) e mobile (.NET MAUI).  
7. **Agente con chiamata di funzioni**: Costruisci un agente AI con capacità di chiamata di funzioni per scenari edge.  

### Progetti di integrazione avanzata (4-5 ore ciascuno)  
8. **Pipeline di ottimizzazione OpenVINO**: Implementa l'ottimizzazione completa del modello utilizzando NNCF e il toolkit GenAI.  
9. **Pipeline SLMOps**: Implementa un ciclo di vita completo del modello, dalla formazione al deployment su dispositivi edge.  
10. **Sistema edge multi-modello**: Effettua il deployment di più modelli specializzati che lavorano insieme su hardware edge.  
11. **Sistema di integrazione MCP**: Costruisci un sistema agentico utilizzando il Model Context Protocol per l'interazione con strumenti.  

## Comunità di apprendimento  

Unisciti alla discussione e connettiti con altri studenti:  
- Discussioni su GitHub nel repository [EdgeAI for Beginners](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Conclusione  

EdgeAI rappresenta la frontiera dell'implementazione dell'intelligenza artificiale, portando potenti capacità direttamente sui dispositivi e affrontando preoccupazioni critiche come privacy, latenza e connettività. Questo corso di 20 ore ti fornisce le conoscenze essenziali e le competenze pratiche per iniziare a lavorare immediatamente con le tecnologie EdgeAI.  

Il corso è volutamente conciso e focalizzato sui concetti più importanti, permettendoti di acquisire rapidamente competenze preziose senza un impegno di tempo eccessivo. Ricorda che la pratica pratica, anche con esempi semplici, è la chiave per consolidare ciò che hai imparato.  

Buono studio!  

---

**Disclaimer**:  
Questo documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.