<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddfe62b8e130979b7034bc6fbb7d510c",
  "translation_date": "2025-07-22T03:00:04+00:00",
  "source_file": "Module01/README.md",
  "language_code": "fr"
}
-->
# Chapitre 01 : Transformer le Déploiement de l'IA pour l'Edge

EdgeAI représente un changement de paradigme dans le déploiement de l'intelligence artificielle, en transférant les capacités de l'IA du traitement basé sur le cloud vers des dispositifs locaux en périphérie. Ce chapitre explore les concepts fondamentaux, les technologies clés et les applications pratiques qui définissent cette approche transformatrice de la mise en œuvre de l'IA.

## Structure du Module

### [Section 1 : Fondamentaux de l'EdgeAI](./01.EdgeAIFundamentals.md)
Cette section pose les bases en contrastant les modèles traditionnels d'IA basée sur le cloud avec les modèles de déploiement de l'IA en périphérie. Nous examinons les technologies essentielles telles que la quantification des modèles, l'optimisation de la compression et les Small Language Models (SLMs) qui surmontent les contraintes computationnelles des dispositifs en périphérie. La discussion met en avant comment ces innovations offrent une meilleure protection de la vie privée, une latence ultra-faible et des capacités de traitement robustes hors ligne.

### [Section 2 : Études de Cas Réelles](./02.RealWorldCaseStudies.md)
À travers des exemples concrets tels que les écosystèmes de modèles Phi et Mu de Microsoft et le système de reporting IA de Japan Airlines, cette section illustre des implémentations réussies d'EdgeAI dans divers secteurs. Ces études de cas valident les performances exceptionnelles des SLMs dans des tâches spécialisées et démontrent les avantages pratiques des stratégies de déploiement en périphérie.

### [Section 3 : Guide Pratique de Mise en Œuvre](./03.PracticalImplementationGuide.md)
Cette section fournit des directives complètes pour la préparation de l'environnement d'apprentissage pratique, couvrant les outils de développement essentiels, les exigences matérielles, les ressources de modèles de base et les cadres d'optimisation. Elle établit les bases techniques nécessaires pour permettre aux apprenants de concevoir et de déployer leurs propres solutions EdgeAI.

### [Section 4 : Plateformes Matérielles pour le Déploiement de l'Edge AI](./04.EdgeDeployment.md)
Cette section explore l'écosystème matériel qui permet le déploiement de l'IA en périphérie, en couvrant des plateformes telles qu'Intel, Qualcomm, NVIDIA et les PC Windows AI. Elle propose des comparaisons détaillées des capacités matérielles, des techniques d'optimisation spécifiques aux plateformes et des considérations pratiques pour le déploiement dans divers scénarios de calcul en périphérie.

## Résultats Clés d'Apprentissage

À la fin de ce chapitre, les lecteurs comprendront :
- Les différences fondamentales entre les architectures d'IA cloud et edge
- Les techniques d'optimisation essentielles pour le déploiement en périphérie
- Les applications réelles et les exemples de réussite
- Les compétences pratiques pour mettre en œuvre des solutions EdgeAI
- La sélection des plateformes matérielles et les approches d'optimisation spécifiques aux plateformes
- Les meilleures pratiques pour le benchmarking des performances et le déploiement

## Implications Futures

EdgeAI s'impose comme une tendance clé façonnant l'avenir du déploiement de l'IA, ouvrant la voie à des systèmes d'IA distribués, efficaces et respectueux de la vie privée, capables de fonctionner indépendamment de la connectivité cloud tout en maintenant des standards de performance élevés.

**Avertissement** :  
Ce document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de recourir à une traduction professionnelle réalisée par un humain. Nous déclinons toute responsabilité en cas de malentendus ou d'interprétations erronées résultant de l'utilisation de cette traduction.