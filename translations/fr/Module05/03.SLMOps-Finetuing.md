<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-07-22T04:23:27+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "fr"
}
-->
# Section 3 : Ajustement fin - Personnalisation des modèles pour des tâches spécifiques

## Table des matières
1. [Introduction à l'ajustement fin](../../../Module05)
2. [Pourquoi l'ajustement fin est important](../../../Module05)
3. [Types d'ajustement fin](../../../Module05)
4. [Ajustement fin avec Microsoft Olive](../../../Module05)
5. [Exemples pratiques](../../../Module05)
6. [Meilleures pratiques et recommandations](../../../Module05)
7. [Techniques avancées](../../../Module05)
8. [Évaluation et suivi](../../../Module05)
9. [Défis courants et solutions](../../../Module05)
10. [Conclusion](../../../Module05)

## Introduction à l'ajustement fin

**L'ajustement fin** est une technique puissante d'apprentissage automatique qui consiste à adapter un modèle pré-entraîné pour accomplir des tâches spécifiques ou travailler avec des ensembles de données spécialisés. Plutôt que de former un modèle à partir de zéro, l'ajustement fin exploite les connaissances déjà acquises par un modèle pré-entraîné et les ajuste pour répondre à vos besoins particuliers.

### Qu'est-ce que l'ajustement fin ?

L'ajustement fin est une forme d'**apprentissage par transfert** où vous :
- Commencez avec un modèle pré-entraîné ayant appris des schémas généraux à partir de grands ensembles de données
- Ajustez les paramètres internes du modèle en utilisant votre ensemble de données spécifique
- Conservez les connaissances précieuses tout en spécialisant le modèle pour votre tâche

C'est un peu comme apprendre à un chef expérimenté à cuisiner une nouvelle cuisine : il connaît déjà les bases de la cuisine, mais doit apprendre des techniques et saveurs spécifiques à ce nouveau style.

### Principaux avantages

- **Efficacité temporelle** : Beaucoup plus rapide que de former un modèle à partir de zéro
- **Efficacité des données** : Nécessite des ensembles de données plus petits pour obtenir de bonnes performances
- **Rentabilité** : Réduit les besoins en ressources informatiques
- **Meilleures performances** : Souvent des résultats supérieurs par rapport à un entraînement complet
- **Optimisation des ressources** : Rend l'IA puissante accessible aux petites équipes et organisations

## Pourquoi l'ajustement fin est important

### Applications dans le monde réel

L'ajustement fin est essentiel dans de nombreux scénarios :

**1. Adaptation au domaine**
- IA médicale : Adapter des modèles de langage général pour la terminologie médicale et les notes cliniques
- Technologies juridiques : Spécialiser des modèles pour l'analyse de documents juridiques et la révision de contrats
- Services financiers : Personnaliser des modèles pour l'analyse de rapports financiers et l'évaluation des risques

**2. Spécialisation des tâches**
- Génération de contenu : Ajustement pour des styles ou tons d'écriture spécifiques
- Génération de code : Adapter des modèles pour des langages de programmation ou frameworks particuliers
- Traduction : Améliorer les performances pour des paires de langues spécifiques ou des domaines techniques

**3. Applications en entreprise**
- Service client : Créer des chatbots qui comprennent la terminologie spécifique à l'entreprise
- Documentation interne : Construire des assistants IA familiers avec les processus organisationnels
- Solutions sectorielles : Développer des modèles qui comprennent le jargon et les flux de travail spécifiques à un secteur

## Types d'ajustement fin

### 1. Ajustement fin complet (Instruction Fine-Tuning)

Dans l'ajustement fin complet, tous les paramètres du modèle sont mis à jour pendant l'entraînement. Cette approche :
- Offre une flexibilité et un potentiel de performance maximum
- Nécessite des ressources informatiques importantes
- Produit une version complètement nouvelle du modèle
- Convient aux scénarios où vous disposez de données d'entraînement substantielles et de ressources informatiques suffisantes

### 2. Ajustement fin efficace en paramètres (PEFT)

Les méthodes PEFT mettent à jour uniquement un petit sous-ensemble de paramètres, rendant le processus plus efficace :

#### Low-Rank Adaptation (LoRA)
- Ajoute de petites matrices de décomposition de rang entraînables aux poids existants
- Réduit considérablement le nombre de paramètres à entraîner
- Maintient des performances proches de l'ajustement fin complet
- Permet un changement facile entre différentes adaptations

#### QLoRA (LoRA quantifié)
- Combine LoRA avec des techniques de quantification
- Réduit encore davantage les besoins en mémoire
- Permet l'ajustement fin de modèles plus grands sur du matériel grand public
- Équilibre efficacité et performance

#### Adaptateurs
- Insèrent de petits réseaux neuronaux entre les couches existantes
- Permettent un ajustement ciblé tout en gardant le modèle de base figé
- Offrent une approche modulaire pour la personnalisation des modèles

### 3. Ajustement fin spécifique à une tâche

Se concentre sur l'adaptation des modèles pour des tâches spécifiques en aval :
- **Classification** : Ajustement des modèles pour des tâches de catégorisation
- **Génération** : Optimisation pour la création de contenu et la génération de texte
- **Extraction** : Ajustement pour l'extraction d'informations et la reconnaissance d'entités nommées
- **Résumé** : Spécialisation des modèles pour le résumé de documents

## Ajustement fin avec Microsoft Olive

Microsoft Olive est une boîte à outils complète d'optimisation de modèles qui simplifie le processus d'ajustement fin tout en offrant des fonctionnalités de niveau entreprise.

### Qu'est-ce que Microsoft Olive ?

Microsoft Olive est un outil open-source d'optimisation de modèles qui :
- Simplifie les flux de travail d'ajustement fin pour diverses cibles matérielles
- Offre un support intégré pour les architectures de modèles populaires (Llama, Phi, Qwen, Gemma)
- Propose des options de déploiement en cloud et en local
- S'intègre parfaitement avec Azure ML et d'autres services IA de Microsoft
- Prend en charge l'optimisation et la quantification automatiques

### Principales fonctionnalités

- **Optimisation adaptée au matériel** : Optimise automatiquement les modèles pour un matériel spécifique (CPU, GPU, NPU)
- **Support multi-format** : Fonctionne avec les modèles PyTorch, Hugging Face et ONNX
- **Flux de travail automatisés** : Réduit la configuration manuelle et les essais-erreurs
- **Intégration en entreprise** : Support intégré pour Azure ML et les déploiements cloud
- **Architecture extensible** : Permet des techniques d'optimisation personnalisées

### Installation et configuration

#### Installation de base

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Dépendances optionnelles

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Vérification de l'installation

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Exemples pratiques

### Exemple 1 : Ajustement fin de base avec Olive CLI

Cet exemple montre comment ajuster un petit modèle de langage pour la classification de phrases :

#### Étape 1 : Préparer votre environnement

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Étape 2 : Ajuster le modèle

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Étape 3 : Optimiser pour le déploiement

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Exemple 2 : Configuration avancée avec un ensemble de données personnalisé

#### Étape 1 : Préparer un ensemble de données personnalisé

Créez un fichier JSON avec vos données d'entraînement :

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Étape 2 : Créer un fichier de configuration

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Étape 3 : Exécuter l'ajustement fin

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Exemple 3 : Ajustement fin QLoRA pour une efficacité mémoire

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Meilleures pratiques et recommandations

### Préparation des données

**1. Qualité des données avant quantité**
- Privilégiez des exemples de haute qualité et diversifiés plutôt qu'un grand volume de données médiocres
- Assurez-vous que les données sont représentatives de votre cas d'utilisation cible
- Nettoyez et prétraitez les données de manière cohérente

**2. Format et modèles de données**
- Utilisez un formatage cohérent pour tous les exemples d'entraînement
- Créez des modèles d'entrée-sortie clairs correspondant à votre cas d'utilisation
- Incluez un formatage d'instructions approprié pour les modèles ajustés par instruction

**3. Division des ensembles de données**
- Réservez 10 à 20 % des données pour la validation
- Maintenez des distributions similaires entre les ensembles d'entraînement et de validation
- Envisagez un échantillonnage stratifié pour les tâches de classification

### Configuration de l'entraînement

**1. Sélection du taux d'apprentissage**
- Commencez avec des taux d'apprentissage plus faibles (1e-5 à 1e-4) pour l'ajustement fin
- Utilisez une planification du taux d'apprentissage pour une meilleure convergence
- Surveillez les courbes de perte pour ajuster les taux en conséquence

**2. Optimisation de la taille des lots**
- Équilibrez la taille des lots avec la mémoire disponible
- Utilisez l'accumulation de gradients pour des tailles de lots effectives plus grandes
- Considérez la relation entre la taille des lots et le taux d'apprentissage

**3. Durée de l'entraînement**
- Surveillez les métriques de validation pour éviter le surapprentissage
- Utilisez un arrêt anticipé lorsque les performances de validation plafonnent
- Sauvegardez régulièrement les points de contrôle pour la récupération et l'analyse

### Sélection du modèle

**1. Choix du modèle de base**
- Sélectionnez des modèles pré-entraînés sur des domaines similaires lorsque c'est possible
- Prenez en compte la taille du modèle par rapport à vos contraintes informatiques
- Évaluez les exigences de licence pour une utilisation commerciale

**2. Sélection de la méthode d'ajustement fin**
- Utilisez LoRA/QLoRA pour des environnements à ressources limitées
- Choisissez l'ajustement fin complet lorsque la performance maximale est critique
- Envisagez des approches basées sur des adaptateurs pour des scénarios multi-tâches

### Gestion des ressources

**1. Optimisation matérielle**
- Choisissez un matériel adapté à la taille de votre modèle et à votre méthode
- Utilisez efficacement la mémoire GPU avec le checkpointing des gradients
- Envisagez des solutions basées sur le cloud pour les modèles plus grands

**2. Gestion de la mémoire**
- Utilisez l'entraînement en précision mixte lorsque disponible
- Implémentez l'accumulation de gradients pour les contraintes de mémoire
- Surveillez l'utilisation de la mémoire GPU tout au long de l'entraînement

## Techniques avancées

### Entraînement multi-adaptateurs

Entraînez plusieurs adaptateurs pour différentes tâches tout en partageant le modèle de base :

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Optimisation des hyperparamètres

Implémentez un réglage systématique des hyperparamètres :

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Fonctions de perte personnalisées

Implémentez des fonctions de perte spécifiques au domaine :

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Évaluation et suivi

### Métriques et évaluation

**1. Métriques standard**
- **Précision** : Exactitude globale pour les tâches de classification
- **Perplexité** : Mesure de la qualité de modélisation du langage
- **BLEU/ROUGE** : Qualité de la génération de texte et du résumé
- **Score F1** : Équilibre entre précision et rappel pour la classification

**2. Métriques spécifiques au domaine**
- **Référentiels spécifiques à la tâche** : Utilisez des benchmarks établis pour votre domaine
- **Évaluation humaine** : Incluez une évaluation humaine pour les tâches subjectives
- **Métriques commerciales** : Alignez-vous sur les objectifs commerciaux réels

**3. Configuration de l'évaluation**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Suivi de la progression de l'entraînement

**1. Suivi des pertes**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Suivi de la validation**
- Suivez la perte de validation parallèlement à la perte d'entraînement
- Surveillez les signes de surapprentissage (perte de validation qui augmente alors que la perte d'entraînement diminue)
- Utilisez un arrêt anticipé basé sur les métriques de validation

**3. Suivi des ressources**
- Surveillez l'utilisation du GPU/CPU
- Suivez les schémas d'utilisation de la mémoire
- Surveillez la vitesse et le débit de l'entraînement

## Défis courants et solutions

### Défi 1 : Surapprentissage

**Symptômes :**
- La perte d'entraînement continue de diminuer tandis que la perte de validation augmente
- Écart important entre les performances d'entraînement et de validation
- Mauvaise généralisation aux nouvelles données

**Solutions :**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Défi 2 : Limitations de mémoire

**Solutions :**
- Utilisez le checkpointing des gradients
- Implémentez l'accumulation de gradients
- Choisissez des méthodes efficaces en paramètres (LoRA, QLoRA)
- Utilisez le parallélisme de modèle pour les grands modèles

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Défi 3 : Entraînement lent

**Solutions :**
- Optimisez les pipelines de chargement des données
- Utilisez l'entraînement en précision mixte
- Implémentez des stratégies de regroupement efficaces
- Envisagez un entraînement distribué pour les grands ensembles de données

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Défi 4 : Performances médiocres

**Étapes de diagnostic :**
1. Vérifiez la qualité et le formatage des données
2. Vérifiez le taux d'apprentissage et la durée de l'entraînement
3. Évaluez le choix du modèle de base
4. Passez en revue le prétraitement et la tokenisation

**Solutions :**
- Augmentez la diversité des données d'entraînement
- Ajustez la planification du taux d'apprentissage
- Essayez différents modèles de base
- Implémentez des techniques d'augmentation des données

## Conclusion

L'ajustement fin est une technique puissante qui démocratise l'accès aux capacités d'IA de pointe. En utilisant des outils comme Microsoft Olive, les organisations peuvent adapter efficacement des modèles pré-entraînés à leurs besoins spécifiques tout en optimisant les performances et les contraintes de ressources.

### Points clés à retenir

1. **Choisissez la bonne approche** : Sélectionnez les méthodes d'ajustement fin en fonction de vos ressources informatiques et de vos exigences de performance
2. **La qualité des données est essentielle** : Investissez dans des données d'entraînement de haute qualité et représentatives
3. **Surveillez et itérez** : Évaluez et améliorez continuellement vos modèles
4. **Exploitez les outils** : Utilisez des frameworks comme Olive pour simplifier et optimiser le processus
5. **Pensez au déploiement** : Planifiez l'optimisation et le déploiement des modèles dès le début

## ➡️ Et après ?

- [04 : Déploiement - Mise en œuvre de modèles prêts pour la production](./04.SLMOps.Deployment.md)

**Avertissement** :  
Ce document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de recourir à une traduction professionnelle réalisée par un humain. Nous déclinons toute responsabilité en cas de malentendus ou d'interprétations erronées résultant de l'utilisation de cette traduction.