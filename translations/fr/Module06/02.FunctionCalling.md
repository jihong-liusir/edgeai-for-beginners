<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b05633cf46af274b3724ee2f7140100",
  "translation_date": "2025-07-22T04:33:42+00:00",
  "source_file": "Module06/02.FunctionCalling.md",
  "language_code": "fr"
}
-->
# Section02 : Appel de fonctions dans les modèles de langage réduits (SLMs)

## Table des matières
1. [Qu'est-ce que l'appel de fonctions ?](../../../Module06)
2. [Comment fonctionne l'appel de fonctions](../../../Module06)
3. [Scénarios d'application](../../../Module06)
4. [Configuration de l'appel de fonctions avec Phi-4-mini et Ollama](../../../Module06)
5. [Travailler avec l'appel de fonctions Qwen3](../../../Module06)
6. [Intégration locale Foundry](../../../Module06)
7. [Bonnes pratiques et dépannage](../../../Module06)
8. [Exemples avancés](../../../Module06)

## Qu'est-ce que l'appel de fonctions ?

L'appel de fonctions est une capacité puissante qui permet aux modèles de langage réduits (SLMs) d'interagir avec des outils, des API et des services externes. Au lieu d'être limités à leurs données d'entraînement, les SLMs peuvent désormais :

- **Se connecter à des API externes** (services météo, bases de données, moteurs de recherche)
- **Exécuter des fonctions spécifiques** en fonction des demandes des utilisateurs
- **Récupérer des informations en temps réel** provenant de diverses sources
- **Effectuer des tâches computationnelles** via des outils spécialisés
- **Enchaîner plusieurs opérations** pour des flux de travail complexes

Cette capacité transforme les SLMs de générateurs de texte statiques en agents IA dynamiques capables d'accomplir des tâches concrètes.

## Comment fonctionne l'appel de fonctions

Le processus d'appel de fonctions suit un flux de travail systématique :

### 1. Intégration des outils
- **Outils externes** : Les SLMs peuvent se connecter à des API météo, bases de données, services web et autres systèmes externes
- **Définitions des fonctions** : Chaque outil est défini avec des paramètres spécifiques, des formats d'entrée/sortie et des descriptions
- **Compatibilité API** : Les outils sont intégrés via des interfaces standardisées (API REST, SDK, etc.)

### 2. Définition des fonctions
Les fonctions sont définies avec trois composants clés :
```json
{
  "name": "function_name",
  "description": "Clear description of what the function does",
  "parameters": {
    "parameter_name": {
      "description": "What this parameter represents",
      "type": "data_type",
      "default": "default_value"
    }
  }
}
```

### 3. Détection d'intention
- **Traitement du langage naturel** : Le SLM analyse l'entrée utilisateur pour comprendre l'intention
- **Correspondance des fonctions** : Détermine quelles fonctions sont nécessaires pour répondre à la demande
- **Extraction des paramètres** : Identifie et extrait les paramètres requis du message de l'utilisateur

### 4. Génération de sortie JSON
Le SLM génère un JSON structuré contenant :
- Le nom de la fonction à appeler
- Les paramètres requis avec des valeurs appropriées
- Le contexte d'exécution et les métadonnées

### 5. Exécution externe
- **Validation des paramètres** : Vérifie que tous les paramètres requis sont présents et correctement formatés
- **Exécution de la fonction** : L'application exécute la fonction spécifiée avec les paramètres fournis
- **Gestion des erreurs** : Gère les échecs, les délais d'attente et les réponses invalides

### 6. Intégration des réponses
- **Traitement des résultats** : La sortie de la fonction est renvoyée au SLM
- **Intégration contextuelle** : Le SLM intègre les résultats dans sa réponse
- **Communication avec l'utilisateur** : Présente les informations dans un format naturel et conversationnel

## Scénarios d'application

### Récupération de données
Convertir des requêtes en langage naturel en appels API structurés :
- **"Montre-moi mes commandes récentes"** → Requête de base de données avec ID utilisateur et filtres de date
- **"Quel temps fait-il à Tokyo ?"** → Appel API météo avec paramètre de localisation
- **"Trouve les emails de John la semaine dernière"** → Requête de service email avec expéditeur et filtres de date

### Exécution d'opérations
Transformer les demandes des utilisateurs en appels de fonctions spécifiques :
- **"Planifie une réunion pour demain à 14h"** → Intégration API calendrier
- **"Envoie un message à l'équipe"** → API de plateforme de communication
- **"Crée une sauvegarde de mes fichiers"** → Opération système de fichiers

### Tâches computationnelles
Gérer des opérations mathématiques ou logiques complexes :
- **"Calcule l'intérêt composé sur 10 000 $ à 5 % pendant 10 ans"** → Fonction de calcul financier
- **"Analyse ce jeu de données pour détecter des tendances"** → Outils d'analyse statistique
- **"Optimise cet itinéraire pour la livraison"** → Algorithmes d'optimisation de route

### Flux de travail de traitement de données
Enchaîner plusieurs appels de fonctions pour des opérations complexes :
1. **Récupérer des données** de plusieurs sources
2. **Analyser et valider** les informations
3. **Transformer** les données dans le format requis
4. **Stocker les résultats** dans les systèmes appropriés
5. **Générer des rapports** ou des visualisations

### Intégration UI/UX
Permettre des mises à jour dynamiques de l'interface :
- **"Affiche les données de ventes sur le tableau de bord"** → Génération et affichage de graphiques
- **"Mets à jour la carte avec de nouveaux emplacements"** → Intégration de données géospatiales
- **"Actualise l'affichage des stocks"** → Synchronisation des données en temps réel

## Configuration de l'appel de fonctions avec Phi-4-mini et Ollama

Le modèle Phi-4-mini de Microsoft prend en charge l'appel de fonctions simple et parallèle via Ollama. Voici comment le configurer :

### Prérequis
- Version 0.5.13 ou supérieure d'Ollama
- Modèle Phi-4-mini (recommandé : `phi4-mini:3.8b-fp16`)

### Étapes d'installation

#### 1. Installer et exécuter Phi-4-mini
```bash
# Download the model (if not already present)
ollama run phi4-mini:3.8b-fp16

# Verify the model is available
ollama list
```

#### 2. Créer un modèle personnalisé avec un fichier template
En raison des limitations actuelles des templates par défaut d'Ollama, vous devez créer un fichier ModelFile personnalisé avec le template suivant :

```modelfile
TEMPLATE """
{{- if .Messages }}
{{- if or .System .Tools }}<|system|>
{{ if .System }}{{ .System }}
{{- end }}
In addition to plain text responses, you can chose to call one or more of the provided functions.
Use the following rule to decide when to call a function:
* if the response can be generated from your internal knowledge (e.g., as in the case of queries like "What is the capital of Poland?"), do so
* if you need external information that can be obtained by calling one or more of the provided functions, generate a function calls
If you decide to call functions:
* prefix function calls with functools marker (no closing marker required)
* all function calls should be generated in a single JSON list formatted as functools[{"name": [function name], "arguments": [function arguments as JSON]}, ...]
* follow the provided JSON schema. Do not hallucinate arguments or values. Do to blindly copy values from the provided samples
* respect the argument type formatting. E.g., if the type if number and format is float, write value 7 as 7.0
* make sure you pick the right functions that match the user intent
Available functions as JSON spec:
{{- if .Tools }}
{{ .Tools }}
{{- end }}<|end|>
{{- end }}
{{- range .Messages }}
{{- if ne .Role "system" }}<|{{ .Role }}|>
{{- if and .Content (eq .Role "tools") }}
{"result": {{ .Content }}}
{{- else if .Content }}
{{ .Content }}
{{- else if .ToolCalls }}
functools[
{{- range .ToolCalls }}{{ "{" }}"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}{{ "}" }}
{{- end }}]
{{- end }}<|end|>
{{- end }}
{{- end }}<|assistant|>
{{ else }}
{{- if .System }}<|system|>
{{ .System }}<|end|>{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>{{ end }}<|assistant|>
{{ end }}{{ .Response }}{{ if .Response }}<|user|>{{ end }}
"""
```

#### 3. Créer le modèle personnalisé
```bash
# Save the template above as 'Modelfile' and run:
ollama create phi4-mini-fc:3.8b-fp16 -f ./Modelfile
```

### Exemple d'appel de fonction simple

```python
import json
import requests

# Define the tool/function
tools = [
    {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "parameters": {
            "location": {
                "description": "The city or location name",
                "type": "str",
                "default": "New York"
            },
            "units": {
                "description": "Temperature units (celsius or fahrenheit)",
                "type": "str",
                "default": "celsius"
            }
        }
    }
]

# Create the message with system prompt including tools
messages = [
    {
        "role": "system",
        "content": "You are a helpful weather assistant",
        "tools": json.dumps(tools)
    },
    {
        "role": "user",
        "content": "What's the weather like in London today?"
    }
]

# Make request to Ollama API
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

### Exemple d'appel de fonctions parallèles

```python
import json
import requests

# Define multiple tools for parallel execution
AGENT_TOOLS = {
    "booking_flight": {
        "name": "booking_flight",
        "description": "Book a flight ticket",
        "parameters": {
            "departure": {
                "description": "Departure airport code",
                "type": "str"
            },
            "destination": {
                "description": "Destination airport code", 
                "type": "str"
            },
            "outbound_date": {
                "description": "Departure date (YYYY-MM-DD)",
                "type": "str"
            },
            "return_date": {
                "description": "Return date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    },
    "booking_hotel": {
        "name": "booking_hotel",
        "description": "Book a hotel room",
        "parameters": {
            "city": {
                "description": "City name for hotel booking",
                "type": "str"
            },
            "check_in_date": {
                "description": "Check-in date (YYYY-MM-DD)",
                "type": "str"
            },
            "check_out_date": {
                "description": "Check-out date (YYYY-MM-DD)",
                "type": "str"
            }
        }
    }
}

SYSTEM_PROMPT = """
You are my travel agent with some tools available.
"""

messages = [
    {
        "role": "system",
        "content": SYSTEM_PROMPT,
        "tools": json.dumps(AGENT_TOOLS)
    },
    {
        "role": "user", 
        "content": "I need to travel from London to New York from March 21 2025 to March 27 2025. Please book both flight and hotel."
    }
]

# The model will generate parallel function calls
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "phi4-mini-fc:3.8b-fp16",
        "messages": messages,
        "stream": False
    }
)

print(response.json())
```

## Travailler avec l'appel de fonctions Qwen3

Qwen3 offre des capacités avancées d'appel de fonctions avec une excellente performance et flexibilité. Voici comment l'implémenter :

### Utilisation du framework Qwen-Agent

Qwen-Agent fournit un framework de haut niveau qui simplifie l'implémentation de l'appel de fonctions :

#### Installation
```bash
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

#### Configuration de base

```python
import os
from qwen_agent.agents import Assistant

# Configure the LLM
llm_cfg = {
    'model': 'Qwen3-8B',
    # Option 1: Use Alibaba Model Studio
    'model_type': 'qwen_dashscope',
    'api_key': os.getenv('DASHSCOPE_API_KEY'),
    
    # Option 2: Use local deployment
    # 'model_server': 'http://localhost:8000/v1',
    # 'api_key': 'EMPTY',
    
    # Optional configuration for thinking mode
    'generate_cfg': {
        'thought_in_content': True,  # Include reasoning in response
    }
}

# Define tools using MCP (Model Context Protocol)
tools = [
    {
        'mcpServers': {
            'time': {
                'command': 'uvx',
                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']
            },
            'fetch': {
                'command': 'uvx', 
                'args': ['mcp-server-fetch']
            }
        }
    },
    'code_interpreter',  # Built-in code execution tool
]

# Create the assistant
bot = Assistant(llm=llm_cfg, function_list=tools)

# Example usage
messages = [
    {
        'role': 'user', 
        'content': 'What time is it now? Also, fetch the latest news from https://example.com/news'
    }
]

# Generate response with function calling
for response in bot.run(messages=messages):
    print(response)
```

### Implémentation de fonctions personnalisées

Vous pouvez également définir des fonctions personnalisées pour Qwen3 :

```python
import json
from qwen_agent.tools.base import BaseTool

class WeatherTool(BaseTool):
    description = 'Get weather information for a specific location'
    parameters = [
        {
            'name': 'location',
            'type': 'string', 
            'description': 'City or location name',
            'required': True
        },
        {
            'name': 'units',
            'type': 'string',
            'description': 'Temperature units (celsius or fahrenheit)',
            'required': False,
            'default': 'celsius'
        }
    ]
    
    def call(self, params: str, **kwargs) -> str:
        """Execute the weather lookup"""
        params_dict = json.loads(params)
        location = params_dict.get('location')
        units = params_dict.get('units', 'celsius')
        
        # Simulate weather API call
        weather_data = {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Partly cloudy',
            'humidity': '65%'
        }
        
        return json.dumps(weather_data)

# Use the custom tool
tools = [WeatherTool()]
bot = Assistant(llm=llm_cfg, function_list=tools)

messages = [{'role': 'user', 'content': 'What\'s the weather in Tokyo?'}]
response = bot.run(messages=messages)
print(list(response)[-1])
```

### Fonctionnalités avancées de Qwen3

#### Contrôle du mode de réflexion
Qwen3 prend en charge le basculement dynamique entre les modes de réflexion et non réflexion :

```python
# Enable thinking mode for complex reasoning
messages = [
    {
        'role': 'user',
        'content': '/think Solve this complex math problem: If a train travels 120 km in 1.5 hours, and another train travels 200 km in 2.5 hours, which train is faster and by how much?'
    }
]

# Disable thinking mode for simple queries
messages = [
    {
        'role': 'user', 
        'content': '/no_think What is the capital of France?'
    }
]
```

#### Appels de fonctions multi-étapes
Qwen3 excelle dans l'enchaînement de plusieurs appels de fonctions :

```python
# Complex workflow example
messages = [
    {
        'role': 'user',
        'content': '''
        I need to prepare for a business meeting:
        1. Check my calendar for conflicts tomorrow
        2. Get weather forecast for the meeting location (San Francisco)
        3. Find recent news about the client company (TechCorp)
        4. Calculate travel time from my office to their headquarters
        '''
    }
]

# Qwen3 will automatically determine the sequence of function calls needed
```

## Intégration locale Foundry

Foundry Local de Microsoft fournit une API compatible OpenAI pour exécuter des modèles localement avec une confidentialité et des performances améliorées.

### Configuration et installation

#### Windows
Téléchargez l'installateur depuis la [page des versions Foundry Local](https://github.com/microsoft/Foundry-Local/releases) et suivez les instructions d'installation.

#### macOS
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

#### Utilisation de base

```python
import openai
from foundry_local import FoundryLocalManager

# Initialize with model alias
alias = "phi-3.5-mini"  # Or any supported model
manager = FoundryLocalManager(alias)

# Create OpenAI client pointing to local endpoint
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Define functions for the model
functions = [
    {
        "name": "calculate_tax",
        "description": "Calculate tax amount based on income and rate",
        "parameters": {
            "type": "object",
            "properties": {
                "income": {
                    "type": "number",
                    "description": "Annual income amount"
                },
                "tax_rate": {
                    "type": "number", 
                    "description": "Tax rate as decimal (e.g., 0.25 for 25%)"
                }
            },
            "required": ["income", "tax_rate"]
        }
    }
]

# Make function calling request
response = client.chat.completions.create(
    model=manager.model_info.id,
    messages=[
        {
            "role": "user",
            "content": "Calculate the tax for someone earning $75,000 with a 22% tax rate"
        }
    ],
    functions=functions,
    function_call="auto"
)

print(response.choices[0].message.content)
```

### Fonctionnalités avancées de Foundry Local

#### Gestion des modèles
```bash
# List available models
foundry model list

# Download specific model
foundry model download phi-3.5-mini

# Run model interactively
foundry model run phi-3.5-mini

# Remove model from cache
foundry model remove phi-3.5-mini

# Delete all cached models
foundry model remove "*"
```

#### Optimisation des performances
Foundry Local sélectionne automatiquement la meilleure variante de modèle pour votre matériel :
- **GPU CUDA** : Télécharge des modèles optimisés pour GPU
- **NPU Qualcomm** : Utilise des variantes accélérées par NPU
- **CPU uniquement** : Sélectionne des modèles optimisés pour CPU

## Bonnes pratiques et dépannage

### Bonnes pratiques pour la définition des fonctions

#### 1. Noms clairs et descriptifs
```python
# Good
{
    "name": "get_stock_price",
    "description": "Retrieve current stock price for a given symbol"
}

# Avoid
{
    "name": "get_data", 
    "description": "Gets data"
}
```

#### 2. Définitions complètes des paramètres
```python
{
    "name": "send_email",
    "description": "Send an email message to specified recipients",
    "parameters": {
        "to": {
            "type": "array",
            "items": {"type": "string"},
            "description": "List of recipient email addresses",
            "required": True
        },
        "subject": {
            "type": "string",
            "description": "Email subject line",
            "required": True
        },
        "body": {
            "type": "string", 
            "description": "Email message content",
            "required": True
        },
        "priority": {
            "type": "string",
            "enum": ["low", "normal", "high"],
            "description": "Email priority level",
            "default": "normal",
            "required": False
        }
    }
}
```

#### 3. Validation des entrées et gestion des erreurs
```python
def execute_function(function_name, parameters):
    try:
        # Validate required parameters
        if function_name == "send_email":
            if not parameters.get("to") or not parameters.get("subject"):
                return {"error": "Missing required parameters: to, subject"}
            
            # Validate email format
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            for email in parameters["to"]:
                if not re.match(email_pattern, email):
                    return {"error": f"Invalid email format: {email}"}
        
        # Execute function logic
        result = perform_actual_function(function_name, parameters)
        return {"success": True, "data": result}
        
    except Exception as e:
        return {"error": str(e)}
```

### Problèmes courants et solutions

#### Problème 1 : La fonction n'est pas appelée
**Symptômes** : Le modèle répond avec du texte au lieu d'appeler la fonction

**Solutions** :
1. **Vérifiez la description de la fonction** : Assurez-vous qu'elle correspond clairement à l'intention de l'utilisateur
2. **Vérifiez les définitions des paramètres** : Assurez-vous que tous les paramètres requis sont correctement définis
3. **Revoyez le prompt système** : Incluez des instructions claires sur l'utilisation des fonctions
4. **Testez avec des demandes explicites** : Essayez "Utilisez la fonction météo pour obtenir les données de Londres"

#### Problème 2 : Paramètres incorrects
**Symptômes** : Fonction appelée avec des paramètres erronés ou manquants

**Solutions** :
1. **Ajoutez des exemples de paramètres** : Incluez des valeurs d'exemple dans les descriptions des paramètres
2. **Utilisez des contraintes d'énumération** : Limitez les valeurs des paramètres à des options spécifiques lorsque possible
3. **Implémentez des valeurs de secours** : Fournissez des valeurs par défaut pour les paramètres optionnels

```python
{
    "name": "book_restaurant",
    "parameters": {
        "cuisine": {
            "type": "string",
            "enum": ["italian", "chinese", "mexican", "american", "french"],
            "description": "Type of cuisine (example: 'italian' for Italian food)"
        },
        "party_size": {
            "type": "integer",
            "minimum": 1,
            "maximum": 20,
            "description": "Number of people (example: 4 for a family of four)"
        }
    }
}
```

#### Problème 3 : Échecs d'appels de fonctions parallèles
**Symptômes** : Une seule fonction s'exécute alors que plusieurs devraient fonctionner

**Solutions** :
1. **Vérifiez la compatibilité du modèle** : Assurez-vous que votre modèle prend en charge l'appel de fonctions parallèles
2. **Mettez à jour le prompt système** : Incluez "plusieurs outils" ou "outils multiples" dans le message système
3. **Utilisez les versions appropriées du modèle** : Phi-4-mini:3.8b-fp16 recommandé pour Ollama

#### Problème 4 : Problèmes de template avec Ollama
**Symptômes** : L'appel de fonctions ne fonctionne pas avec la configuration par défaut d'Ollama

**Solutions** :
1. **Utilisez un fichier ModelFile personnalisé** : Appliquez le template corrigé fourni dans ce tutoriel
2. **Mettez à jour Ollama** : Assurez-vous d'utiliser la version 0.5.13 ou supérieure
3. **Vérifiez la quantification du modèle** : Les niveaux de quantification élevés (Q8_0, fp16) fonctionnent mieux que les versions fortement quantifiées

### Optimisation des performances

#### 1. Conception efficace des fonctions
- **Gardez les fonctions ciblées** : Chaque fonction doit avoir un objectif unique et clair
- **Minimisez les dépendances externes** : Réduisez les appels API et les requêtes réseau autant que possible
- **Mettez en cache les résultats** : Stockez les données fréquemment demandées pour améliorer les temps de réponse

#### 2. Regroupement et opérations asynchrones
```python
import asyncio
import aiohttp

async def batch_function_calls(function_calls):
    """Execute multiple function calls concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = []
        for call in function_calls:
            if call["name"] == "fetch_url":
                task = fetch_url_async(session, call["parameters"]["url"])
                tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return results

async def fetch_url_async(session, url):
    async with session.get(url) as response:
        return await response.text()
```

#### 3. Gestion des ressources
- **Regroupement des connexions** : Réutilisez les connexions aux bases de données et aux API
- **Limitation de débit** : Implémentez une limitation de débit appropriée pour les API externes
- **Gestion des délais d'attente** : Définissez des délais raisonnables pour tous les appels externes

## Exemples avancés

### Système de collaboration multi-agents

```python
import json
from typing import List, Dict
from qwen_agent.agents import Assistant

class MultiAgentSystem:
    def __init__(self):
        # Research Agent
        self.research_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[
                {'mcpServers': {'search': {'command': 'uvx', 'args': ['mcp-server-search']}}},
                {'mcpServers': {'fetch': {'command': 'uvx', 'args': ['mcp-server-fetch']}}}
            ]
        )
        
        # Analysis Agent
        self.analysis_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=['code_interpreter']
        )
        
        # Communication Agent
        self.comm_agent = Assistant(
            llm={'model': 'Qwen3-8B', 'model_server': 'http://localhost:8000/v1'},
            function_list=[self.create_email_tool(), self.create_slack_tool()]
        )
    
    def create_email_tool(self):
        """Custom email sending tool"""
        class EmailTool:
            name = "send_email"
            description = "Send email to specified recipients"
            parameters = {
                "to": {"type": "string", "description": "Recipient email"},
                "subject": {"type": "string", "description": "Email subject"},
                "body": {"type": "string", "description": "Email content"}
            }
            
            def call(self, params):
                # Implement actual email sending logic
                return f"Email sent successfully to {params['to']}"
        
        return EmailTool()
    
    def create_slack_tool(self):
        """Custom Slack messaging tool"""  
        class SlackTool:
            name = "send_slack"
            description = "Send message to Slack channel"
            parameters = {
                "channel": {"type": "string", "description": "Slack channel"},
                "message": {"type": "string", "description": "Message content"}
            }
            
            def call(self, params):
                # Implement actual Slack API call
                return f"Message sent to {params['channel']}"
        
        return SlackTool()
    
    async def process_complex_request(self, user_request: str):
        """Process complex multi-step requests using multiple agents"""
        
        # Step 1: Research phase
        research_prompt = f"Research the following topic and gather relevant information: {user_request}"
        research_results = []
        for response in self.research_agent.run([{'role': 'user', 'content': research_prompt}]):
            research_results.append(response)
        
        # Step 2: Analysis phase
        analysis_prompt = f"Analyze the following research data and provide insights: {research_results[-1]}"
        analysis_results = []
        for response in self.analysis_agent.run([{'role': 'user', 'content': analysis_prompt}]):
            analysis_results.append(response)
        
        # Step 3: Communication phase
        comm_prompt = f"Create a summary report and send it via email: {analysis_results[-1]}"
        comm_results = []
        for response in self.comm_agent.run([{'role': 'user', 'content': comm_prompt}]):
            comm_results.append(response)
        
        return {
            'research': research_results[-1],
            'analysis': analysis_results[-1], 
            'communication': comm_results[-1]
        }

# Usage example
async def main():
    system = MultiAgentSystem()
    
    request = """
    Analyze the impact of remote work on productivity in tech companies. 
    Research recent studies, analyze the data, and send a summary to our team.
    """
    
    results = await system.process_complex_request(request)
    print("Multi-agent processing complete:", results)

# Run the example
# asyncio.run(main())
```

### Système de sélection dynamique d'outils

```python
class DynamicToolSelector:
    def __init__(self):
        self.available_tools = {
            'weather': {
                'description': 'Get weather information',
                'domains': ['weather', 'temperature', 'forecast', 'climate'],
                'function': self.get_weather
            },
            'calculator': {
                'description': 'Perform mathematical calculations',
                'domains': ['math', 'calculate', 'compute', 'arithmetic'],
                'function': self.calculate
            },
            'web_search': {
                'description': 'Search the internet for information',
                'domains': ['search', 'find', 'lookup', 'research'],
                'function': self.web_search
            },
            'file_manager': {
                'description': 'Manage files and directories',
                'domains': ['file', 'directory', 'save', 'load', 'delete'],
                'function': self.manage_files
            }
        }
    
    def analyze_intent(self, user_input: str) -> List[str]:
        """Analyze user input to determine which tools might be needed"""
        user_words = user_input.lower().split()
        relevant_tools = []
        
        for tool_name, tool_info in self.available_tools.items():
            for domain in tool_info['domains']:
                if domain in user_words:
                    relevant_tools.append(tool_name)
                    break
        
        return relevant_tools
    
    def get_tool_definitions(self, tool_names: List[str]) -> List[Dict]:
        """Generate function definitions for selected tools"""
        definitions = []
        
        for tool_name in tool_names:
            if tool_name == 'weather':
                definitions.append({
                    'name': 'get_weather',
                    'description': 'Get current weather information',
                    'parameters': {
                        'location': {'type': 'string', 'description': 'City or location name'},
                        'units': {'type': 'string', 'enum': ['celsius', 'fahrenheit'], 'default': 'celsius'}
                    }
                })
            elif tool_name == 'calculator':
                definitions.append({
                    'name': 'calculate',
                    'description': 'Perform mathematical calculations',
                    'parameters': {
                        'expression': {'type': 'string', 'description': 'Mathematical expression to evaluate'},
                        'precision': {'type': 'integer', 'default': 2, 'description': 'Decimal places for result'}
                    }
                })
            # Add more tool definitions as needed
        
        return definitions
    
    def get_weather(self, location: str, units: str = 'celsius') -> Dict:
        """Mock weather function"""
        return {
            'location': location,
            'temperature': '22°C' if units == 'celsius' else '72°F',
            'condition': 'Sunny',
            'humidity': '60%'
        }
    
    def calculate(self, expression: str, precision: int = 2) -> Dict:
        """Safe mathematical calculation"""
        try:
            # Simple evaluation for demo - in production, use a proper math parser
            import math
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            allowed_names.update({"abs": abs, "round": round})
            
            result = eval(expression, {"__builtins__": {}}, allowed_names)
            return {
                'expression': expression,
                'result': round(float(result), precision),
                'success': True
            }
        except Exception as e:
            return {
                'expression': expression,
                'error': str(e),
                'success': False
            }
    
    def web_search(self, query: str, max_results: int = 5) -> Dict:
        """Mock web search function"""
        return {
            'query': query,
            'results': [
                {'title': f'Result {i+1} for {query}', 'url': f'https://example{i+1}.com'}
                for i in range(max_results)
            ]
        }
    
    def manage_files(self, action: str, file_path: str, content: str = None) -> Dict:
        """Mock file management function"""
        return {
            'action': action,
            'file_path': file_path,
            'success': True,
            'message': f'Successfully {action}ed file: {file_path}'
        }

# Usage example
def smart_assistant_with_dynamic_tools():
    selector = DynamicToolSelector()
    
    user_requests = [
        "What's the weather like in New York and calculate 15% tip on $50?",
        "Search for recent AI developments and save the results to a file",
        "Calculate the area of a circle with radius 10 and check weather in Tokyo"
    ]
    
    for request in user_requests:
        print(f"\nUser Request: {request}")
        
        # Analyze which tools might be needed
        relevant_tools = selector.analyze_intent(request)
        print(f"Relevant Tools: {relevant_tools}")
        
        # Get function definitions for the LLM
        tool_definitions = selector.get_tool_definitions(relevant_tools)
        print(f"Tool Definitions: {len(tool_definitions)} functions available")
        
        # In a real implementation, you would pass these to your LLM
        # The LLM would then decide which functions to call and with what parameters

### Enterprise Integration Example

```python
import asyncio
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class FunctionResult:
    """Format standard des résultats pour tous les appels de fonctions"""
    success: bool
    data: Any = None
    error: str = None
    execution_time: float = 0.0
    timestamp: datetime = None

class EnterpriseAIAgent:
    """Agent IA prêt pour la production avec des capacités complètes d'appel de fonctions"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.functions = {}
        self.audit_log = []
        self.rate_limiters = {}
        
        # Initialiser les fonctions principales
        self._register_core_functions()
    
    def _register_core_functions(self):
        """Enregistrer toutes les fonctions disponibles"""
        
        # Fonctions CRM
        self.register_function(
            name="get_customer_info",
            description="Récupérer les informations client depuis le CRM",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "include_history": {"type": "boolean", "default": False}
            },
            handler=self._get_customer_info,
            rate_limit=100  # appels par minute
        )
        
        # Fonctions de vente
        self.register_function(
            name="create_sales_opportunity",
            description="Créer une nouvelle opportunité de vente",
            parameters={
                "customer_id": {"type": "string", "required": True},
                "product_id": {"type": "string", "required": True},
                "estimated_value": {"type": "number", "required": True},
                "expected_close_date": {"type": "string", "required": True}
            },
            handler=self._create_sales_opportunity,
            rate_limit=50
        )
        
        # Fonctions d'analyse
        self.register_function(
            name="generate_sales_report",
            description="Générer un rapport de performance des ventes",
            parameters={
                "period": {"type": "string", "enum": ["daily", "weekly", "monthly", "quarterly"]},
                "region": {"type": "string", "required": False},
                "product_category": {"type": "string", "required": False}
            },
            handler=self._generate_sales_report,
            rate_limit=10
        )
        
        # Fonctions de notification
        self.register_function(
            name="send_notification",
            description="Envoyer une notification aux membres de l'équipe",
            parameters={
                "recipients": {"type": "array", "items": {"type": "string"}},
                "message": {"type": "string", "required": True},
                "priority": {"type": "string", "enum": ["low", "medium", "high"], "default": "medium"},
                "channel": {"type": "string", "enum": ["email", "slack", "teams"], "default": "email"}
            },
            handler=self._send_notification,
            rate_limit=200
        )
    
    def register_function(self, name: str, description: str, parameters: Dict, 
                         handler: callable, rate_limit: int = 60):
        """Enregistrer une nouvelle fonction avec l'agent"""
        self.functions[name] = {
            'description': description,
            'parameters': parameters,
            'handler': handler,
            'rate_limit': rate_limit,
            'call_count': 0,
            'last_reset': datetime.now()
        }
    
    async def execute_function(self, function_name: str, parameters: Dict) -
D'accord, veuillez fournir le fichier Markdown que vous souhaitez traduire.
"""Exécuter une fonction avec une gestion complète des erreurs et un journal détaillé"""
start_time = datetime.now()

try:
    # Valider que la fonction existe
    if function_name not in self.functions:
        return FunctionResult(
            success=False,
            error=f"Fonction '{function_name}' introuvable",
            timestamp=start_time
        )
    
    # Vérifier les limites de fréquence
    if not self._check_rate_limit(function_name):
        return FunctionResult(
            success=False,
            error=f"Limite de fréquence dépassée pour la fonction '{function_name}'",
            timestamp=start_time
        )
    
    # Valider les paramètres
    validation_result = self._validate_parameters(function_name, parameters)
    if not validation_result.success:
        return validation_result
    
    # Exécuter la fonction
    func_info = self.functions[function_name]
    handler = func_info['handler']
    
    if asyncio.iscoroutinefunction(handler):
        result_data = await handler(**parameters)
    else:
        result_data = handler(**parameters)
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    result = FunctionResult(
        success=True,
        data=result_data,
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Journaliser l'exécution réussie
    self._log_function_call(function_name, parameters, result)
    
    return result
    
except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    result = FunctionResult(
        success=False,
        error=str(e),
        execution_time=execution_time,
        timestamp=start_time
    )
    
    # Journaliser l'exécution échouée
    self._log_function_call(function_name, parameters, result)
    
    return result

def _check_rate_limit(self, function_name: str) -> bool:
    """Vérifier si l'appel de la fonction respecte les limites de fréquence"""
    func_info = self.functions[function_name]
    now = datetime.now()
    
    # Réinitialiser le compteur si une minute s'est écoulée
    if (now - func_info['last_reset']).seconds >= 60:
        func_info['call_count'] = 0
        func_info['last_reset'] = now
    
    # Vérifier si la limite est respectée
    if func_info['call_count'] >= func_info['rate_limit']:
        return False
    
    func_info['call_count'] += 1
    return True

def _validate_parameters(self, function_name: str, parameters: Dict) -> FunctionResult:
    """Valider les paramètres de la fonction"""
    func_params = self.functions[function_name]['parameters']
    
    # Vérifier les paramètres requis
    for param_name, param_info in func_params.items():
        if param_info.get('required', False) and param_name not in parameters:
            return FunctionResult(
                success=False,
                error=f"Paramètre requis manquant : {param_name}"
            )
    
    # Valider les types et contraintes des paramètres
    for param_name, value in parameters.items():
        if param_name in func_params:
            param_info = func_params[param_name]
            
            # Validation du type
            expected_type = param_info.get('type')
            if expected_type == 'string' and not isinstance(value, str):
                return FunctionResult(
                    success=False,
                    error=f"Le paramètre '{param_name}' doit être une chaîne de caractères"
                )
            elif expected_type == 'number' and not isinstance(value, (int, float)):
                return FunctionResult(
                    success=False,
                    error=f"Le paramètre '{param_name}' doit être un nombre"
                )
            elif expected_type == 'boolean' and not isinstance(value, bool):
                return FunctionResult(
                    success=False,
                    error=f"Le paramètre '{param_name}' doit être un booléen"
                )
            
            # Validation des valeurs énumérées
            if 'enum' in param_info and value not in param_info['enum']:
                return FunctionResult(
                    success=False,
                    error=f"Le paramètre '{param_name}' doit être l'un des suivants : {param_info['enum']}"
                )
    
    return FunctionResult(success=True)

def _log_function_call(self, function_name: str, parameters: Dict, result: FunctionResult):
    """Journaliser l'appel de la fonction à des fins d'audit"""
    log_entry = {
        'timestamp': result.timestamp.isoformat(),
        'function_name': function_name,
        'parameters': parameters,
        'success': result.success,
        'execution_time': result.execution_time,
        'error': result.error if not result.success else None
    }
    
    self.audit_log.append(log_entry)
    
    # Éventuellement écrire dans un système de journalisation externe
    if self.config.get('enable_external_logging', False):
        self._write_to_external_log(log_entry)

def _write_to_external_log(self, log_entry: Dict):
    """Écrire une entrée de journal dans un système de journalisation externe"""
    # L'implémentation dépendrait de votre infrastructure de journalisation
    # Par exemple, envoyer à ELK stack, CloudWatch, etc.
    pass

# Implémentations des fonctions métier
async def _get_customer_info(self, customer_id: str, include_history: bool = False) -> Dict:
    """Récupérer les informations client depuis le système CRM"""
    # Simuler un appel à une base de données ou une API
    await asyncio.sleep(0.1)  # Simuler un délai réseau
    
    customer_data = {
        'customer_id': customer_id,
        'name': 'John Doe',
        'email': 'john.doe@example.com',
        'phone': '+1-555-0123',
        'status': 'actif',
        'tier': 'premium'
    }
    
    if include_history:
        customer_data['purchase_history'] = [
            {'date': '2024-01-15', 'product': 'Produit A', 'amount': 1500},
            {'date': '2024-03-22', 'product': 'Produit B', 'amount': 2300}
        ]
    
    return customer_data

async def _create_sales_opportunity(self, customer_id: str, product_id: str, 
                                    estimated_value: float, expected_close_date: str) -> Dict:
    """Créer une nouvelle opportunité commerciale"""
    # Simuler un appel à l'API CRM
    await asyncio.sleep(0.2)
    
    opportunity_id = f"OPP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'opportunity_id': opportunity_id,
        'customer_id': customer_id,
        'product_id': product_id,
        'estimated_value': estimated_value,
        'expected_close_date': expected_close_date,
        'status': 'ouverte',
        'created_date': datetime.now().isoformat()
    }

async def _generate_sales_report(self, period: str, region: str = None, 
                                 product_category: str = None) -> Dict:
    """Générer un rapport de ventes complet"""
    # Simuler l'agrégation de données
    await asyncio.sleep(0.5)
    
    return {
        'report_id': f"RPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'period': period,
        'region': region,
        'product_category': product_category,
        'total_sales': 125000.00,
        'total_opportunities': 45,
        'conversion_rate': 0.67,
        'top_products': [
            {'product_id': 'PROD-001', 'sales': 45000},
            {'product_id': 'PROD-002', 'sales': 32000}
        ],
        'generated_at': datetime.now().isoformat()
    }

async def _send_notification(self, recipients: List[str], message: str, 
                              priority: str = 'medium', channel: str = 'email') -> Dict:
    """Envoyer une notification via le canal spécifié"""
    # Simuler un appel au service de notification
    await asyncio.sleep(0.1)
    
    notification_id = f"NOTIF-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    return {
        'notification_id': notification_id,
        'recipients': recipients,
        'channel': channel,
        'priority': priority,
        'status': 'envoyée',
        'sent_at': datetime.now().isoformat()
    }

def get_function_definitions(self) -> List[Dict]:
    """Obtenir les définitions de fonctions compatibles avec OpenAI pour toutes les fonctions enregistrées"""
    definitions = []
    
    for func_name, func_info in self.functions.items():
        definition = {
            'name': func_name,
            'description': func_info['description'],
            'parameters': {
                'type': 'object',
                'properties': {},
                'required': []
            }
        }
        
        for param_name, param_info in func_info['parameters'].items():
            definition['parameters']['properties'][param_name] = {
                'type': param_info['type'],
                'description': param_info.get('description', '')
            }
            
            if 'enum' in param_info:
                definition['parameters']['properties'][param_name]['enum'] = param_info['enum']
            
            if 'default' in param_info:
                definition['parameters']['properties'][param_name]['default'] = param_info['default']
            
            if param_info.get('required', False):
                definition['parameters']['required'].append(param_name)
        
        definitions.append(definition)
    
    return definitions

# Exemple d'utilisation pour l'intégration en entreprise
async def enterprise_demo():
    """Démontrer les capacités d'un agent IA en entreprise"""
    
    config = {
        'enable_external_logging': True,
        'max_concurrent_functions': 10,
        'default_timeout': 30
    }
    
    agent = EnterpriseAIAgent(config)
    
    # Exemple 1 : Traitement des demandes clients
    print("=== Traitement des demandes clients ===")
    
    # Récupérer les informations client
    result = await agent.execute_function(
        'get_customer_info',
        {'customer_id': 'CUST-12345', 'include_history': True}
    )
    
    if result.success:
        print(f"Informations client récupérées : {result.data['name']}")
        print(f"Temps d'exécution : {result.execution_time:.3f}s")
    
    # Exemple 2 : Création d'une opportunité commerciale
    print("\n=== Création d'une opportunité commerciale ===")
    
    result = await agent.execute_function(
        'create_sales_opportunity',
        {
            'customer_id': 'CUST-12345',
            'product_id': 'PROD-001',
            'estimated_value': 15000.0,
            'expected_close_date': '2025-09-30'
        }
    )
    
    if result.success:
        print(f"Opportunité créée : {result.data['opportunity_id']}")
    
    # Exemple 3 : Opérations en lot
    print("\n=== Opérations en lot ===")
    
    tasks = [
        agent.execute_function('generate_sales_report', {'period': 'monthly'}),
        agent.execute_function('send_notification', {
            'recipients': ['manager@company.com'],
            'message': 'Nouvelle opportunité créée',
            'priority': 'high',
            'channel': 'email'
        })
    ]
    
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results):
        if result.success:
            print(f"Tâche {i+1} terminée avec succès")
        else:
            print(f"Tâche {i+1} échouée : {result.error}")
    
    # Afficher le journal d'audit
    print(f"\n=== Journal d'audit ({len(agent.audit_log)} entrées) ===")
    for entry in agent.audit_log[-3:]:  # Afficher les 3 dernières entrées
        print(f"{entry['timestamp']}: {entry['function_name']} - {'SUCCÈS' if entry['success'] else 'ÉCHEC'}")

# Exécuter la démonstration en entreprise
# asyncio.run(enterprise_demo())

## Conclusion

L'appel de fonctions dans les modèles de langage représente un changement de paradigme, passant d'assistants IA statiques à des agents dynamiques capables d'interagir avec le monde réel. Ce tutoriel a couvert :

### Points clés

1. **Compréhension des bases** : L'appel de fonctions permet aux modèles de langage de dépasser leurs données d'entraînement en se connectant à des outils et services externes.

2. **Flexibilité d'implémentation** : Plusieurs approches existent, allant des implémentations bas niveau avec des modèles personnalisés aux frameworks avancés comme Qwen-Agent et Foundry Local.

3. **Considérations pour la production** : Les déploiements en entreprise nécessitent une attention particulière à la gestion des erreurs, aux limites de fréquence, à la sécurité et à la journalisation.

4. **Optimisation des performances** : Une conception appropriée des fonctions, une exécution efficace et une mise en cache intelligente peuvent améliorer considérablement les temps de réponse.

### Perspectives futures

Avec l'évolution continue de la technologie des modèles de langage, nous pouvons nous attendre à :

- **Précision accrue dans l'appel de fonctions** : Meilleure détection des intentions et extraction des paramètres
- **Traitement parallèle amélioré** : Orchestration plus sophistiquée de plusieurs fonctions
- **Normes d'intégration renforcées** : Protocoles standardisés pour l'intégration des outils
- **Fonctionnalités de sécurité avancées** : Mécanismes d'authentification et d'autorisation améliorés
- **Écosystème élargi** : Bibliothèque croissante de fonctions et intégrations préconstruites

### Premiers pas

Pour commencer à implémenter l'appel de fonctions dans vos projets :

1. **Commencez simplement** : Débutez avec des scénarios de fonctions simples
2. **Choisissez votre framework** : Optez pour une implémentation directe (Ollama/Phi-4) ou assistée par framework (Qwen-Agent)
3. **Concevez vos fonctions avec soin** : Mettez l'accent sur des définitions de fonctions claires et bien documentées
4. **Implémentez une gestion des erreurs robuste** : Construisez une gestion des erreurs dès le départ
5. **Évoluez progressivement** : Passez de scénarios simples à complexes à mesure que vous gagnez en expérience

L'appel de fonctions transforme les modèles de langage en agents IA pratiques capables de résoudre des problèmes réels. En suivant les modèles et pratiques décrits dans ce tutoriel, vous pouvez construire des systèmes IA puissants et fiables qui vont bien au-delà des interfaces de chat traditionnelles.

### Ressources et références
- **Modèles Phi-4** : [Collection Hugging Face](https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4)  
- **Documentation Qwen3** : [Documentation officielle de Qwen](https://qwen.readthedocs.io/)  
- **Ollama** : [Site officiel](https://ollama.com/)  
- **Foundry Local** : [Dépôt GitHub](https://github.com/microsoft/Foundry-Local)  
- **Meilleures pratiques pour l'appel de fonctions** : [Guide Hugging Face](https://huggingface.co/docs/hugs/en/guides/function-calling)  

N'oubliez pas que l'appel de fonctions est un domaine en constante évolution. Rester informé des derniers développements dans les frameworks et modèles que vous utilisez vous aidera à créer des agents d'IA plus performants.  

## ➡️ Et après  

- [03 : Intégration du protocole de contexte de modèle (MCP)](./03.IntroduceMCP.md)  

**Avertissement** :  
Ce document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de recourir à une traduction professionnelle réalisée par un humain. Nous ne sommes pas responsables des malentendus ou des interprétations erronées résultant de l'utilisation de cette traduction.