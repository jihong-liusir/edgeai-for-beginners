<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T10:21:19+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "fr"
}
-->
# Exemple 04 : Applications de Chat en Production avec Chainlit

Un exemple complet d√©montrant plusieurs approches pour cr√©er des applications de chat pr√™tes pour la production en utilisant Microsoft Foundry Local, avec des interfaces web modernes, des r√©ponses en streaming et des technologies de navigateur de pointe.

## Contenu Inclus

- **üöÄ Application de Chat Chainlit** (`app.py`) : Application de chat pr√™te pour la production avec streaming
- **üåê D√©mo WebGPU** (`webgpu-demo/`) : Inf√©rence IA bas√©e sur le navigateur avec acc√©l√©ration mat√©rielle
- **üé® Int√©gration Open WebUI** (`open-webui-guide.md`) : Interface professionnelle similaire √† ChatGPT
- **üìö Notebook √âducatif** (`chainlit_app.ipynb`) : Mat√©riel d'apprentissage interactif

## D√©marrage Rapide

### 1. Application de Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Accessible √† : `http://localhost:8080`

### 2. D√©mo WebGPU dans le Navigateur

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Accessible √† : `http://localhost:5173`

### 3. Configuration Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Accessible √† : `http://localhost:3000`

## Mod√®les d'Architecture

### Matrice de D√©cision Local vs Cloud

| Sc√©nario | Recommandation | Raison |
|----------|----------------|--------|
| **Donn√©es Sensibles** | üè† Local (Foundry) | Les donn√©es ne quittent jamais l'appareil |
| **Raisonnement Complexe** | ‚òÅÔ∏è Cloud (Azure OpenAI) | Acc√®s √† des mod√®les plus grands |
| **Chat en Temps R√©el** | üè† Local (Foundry) | Latence r√©duite, r√©ponses plus rapides |
| **Analyse de Documents** | üîÑ Hybride | Extraction locale, analyse dans le cloud |
| **G√©n√©ration de Code** | üè† Local (Foundry) | Confidentialit√© + mod√®les sp√©cialis√©s |
| **T√¢ches de Recherche** | ‚òÅÔ∏è Cloud (Azure OpenAI) | Base de connaissances √©tendue n√©cessaire |

### Comparaison des Technologies

| Technologie | Cas d'Utilisation | Avantages | Inconv√©nients |
|-------------|-------------------|-----------|---------------|
| **Chainlit** | D√©veloppeurs Python, prototypage rapide | Configuration facile, support du streaming | Limit√© √† Python |
| **WebGPU** | Confidentialit√© maximale, sc√©narios hors ligne | Natif au navigateur, pas besoin de serveur | Taille de mod√®le limit√©e |
| **Open WebUI** | D√©ploiement en production, √©quipes | Interface professionnelle, gestion des utilisateurs | N√©cessite Docker |

## Pr√©requis

- **Foundry Local** : Install√© et en cours d'ex√©cution ([T√©l√©charger](https://aka.ms/foundry-local-installer))
- **Python** : Version 3.10+ avec environnement virtuel
- **Mod√®le** : Au moins un mod√®le charg√© (`foundry model run phi-4-mini`)
- **Navigateur** : Chrome/Edge avec support WebGPU pour les d√©mos
- **Docker** : Pour Open WebUI (optionnel)

## Installation & Configuration

### 1. Configuration de l'Environnement Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration de Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## Applications Exemple

### Application de Chat Chainlit

**Caract√©ristiques :**
- üöÄ **Streaming en Temps R√©el** : Les tokens apparaissent au fur et √† mesure de leur g√©n√©ration
- üõ°Ô∏è **Gestion des Erreurs Robuste** : D√©gradation et r√©cup√©ration en douceur
- üé® **Interface Moderne** : Interface de chat professionnelle pr√™te √† l'emploi
- üîß **Configuration Flexible** : Variables d'environnement et d√©tection automatique
- üì± **Design Adaptatif** : Fonctionne sur ordinateurs et appareils mobiles

**D√©marrage Rapide :**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### D√©mo WebGPU dans le Navigateur

**Caract√©ristiques :**
- üåê **IA Natif au Navigateur** : Pas besoin de serveur, fonctionne enti√®rement dans le navigateur
- ‚ö° **Acc√©l√©ration WebGPU** : Acc√©l√©ration mat√©rielle lorsque disponible
- üîí **Confidentialit√© Maximale** : Les donn√©es ne quittent jamais votre appareil
- üéØ **Installation Z√©ro** : Fonctionne dans tout navigateur compatible
- üîÑ **Fallback en Douceur** : Bascule sur le CPU si WebGPU n'est pas disponible

**Ex√©cution :**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Int√©gration Open WebUI

**Caract√©ristiques :**
- üé® **Interface Similaire √† ChatGPT** : UI professionnelle et famili√®re
- üë• **Support Multi-utilisateurs** : Comptes utilisateurs et historique des conversations
- üìÅ **Traitement de Fichiers** : T√©l√©chargement et analyse de documents
- üîÑ **Changement de Mod√®le** : Commutation facile entre diff√©rents mod√®les
- üê≥ **D√©ploiement Docker** : Configuration pr√™te pour la production en conteneur

**Configuration Rapide :**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## R√©f√©rence de Configuration

### Variables d'Environnement

| Variable | Description | Valeur par D√©faut | Exemple |
|----------|-------------|-------------------|---------|
| `MODEL` | Alias du mod√®le √† utiliser | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Point de terminaison Foundry Local | D√©tect√© automatiquement | `http://localhost:51211` |
| `API_KEY` | Cl√© API (optionnelle pour local) | `""` | `your-api-key` |

## R√©solution des Probl√®mes

### Probl√®mes Courants

**Application Chainlit :**

1. **Service non disponible :**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Conflits de port :**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Probl√®mes d'environnement Python :**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P ‚Üí Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**D√©mo WebGPU :**

1. **WebGPU non support√© :**
   - Mettre √† jour vers Chrome/Edge 113+
   - Activer WebGPU : `chrome://flags/#enable-unsafe-webgpu`
   - V√©rifier le statut GPU : `chrome://gpu`
   - La d√©mo basculera automatiquement sur le CPU

2. **Erreurs de chargement de mod√®le :**
   - V√©rifier la connexion internet pour le t√©l√©chargement du mod√®le
   - Consulter la console du navigateur pour les erreurs CORS
   - V√©rifier que vous servez via HTTP (pas file://)

**Open WebUI :**

1. **Connexion refus√©e :**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Mod√®les non visibles :**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Liste de Validation

```cmd
# ‚úÖ 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# ‚úÖ 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# ‚úÖ 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Utilisation Avanc√©e

### Optimisation des Performances

**Chainlit :**
- Utiliser le streaming pour une meilleure perception des performances
- Impl√©menter le pooling de connexions pour une haute concurrence
- Mettre en cache les r√©ponses des mod√®les pour les requ√™tes r√©p√©t√©es
- Surveiller l'utilisation de la m√©moire avec des historiques de conversation volumineux

**WebGPU :**
- Utiliser WebGPU pour une confidentialit√© et une vitesse maximales
- Impl√©menter la quantification des mod√®les pour des mod√®les plus petits
- Utiliser les Web Workers pour le traitement en arri√®re-plan
- Mettre en cache les mod√®les compil√©s dans le stockage du navigateur

**Open WebUI :**
- Utiliser des volumes persistants pour l'historique des conversations
- Configurer des limites de ressources pour le conteneur Docker
- Impl√©menter des strat√©gies de sauvegarde pour les donn√©es utilisateur
- Configurer un proxy inverse pour la terminaison SSL

### Mod√®les d'Int√©gration

**Hybride Local/Cloud :**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Pipeline Multi-modal :**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## D√©ploiement en Production

### Consid√©rations de S√©curit√©

- **Cl√©s API** : Utiliser des variables d'environnement, ne jamais les coder en dur
- **R√©seau** : Utiliser HTTPS en production, envisager un VPN pour l'acc√®s en √©quipe
- **Contr√¥le d'Acc√®s** : Impl√©menter l'authentification pour Open WebUI
- **Confidentialit√© des Donn√©es** : Auditer les donn√©es locales vs celles envoy√©es au cloud
- **Mises √† Jour** : Maintenir Foundry Local et les conteneurs √† jour

### Surveillance et Maintenance

- **V√©rifications de Sant√©** : Impl√©menter la surveillance des points de terminaison
- **Journalisation** : Centraliser les journaux de tous les composants
- **M√©triques** : Suivre les temps de r√©ponse, taux d'erreur, utilisation des ressources
- **Sauvegarde** : Sauvegarde r√©guli√®re des donn√©es de conversation et des configurations

## R√©f√©rences et Ressources

### Documentation
- [Documentation Chainlit](https://docs.chainlit.io/) - Guide complet du framework
- [Documentation Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Documentation officielle de Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - Int√©gration WebGPU
- [Documentation Open WebUI](https://docs.openwebui.com/) - Configuration avanc√©e

### Fichiers Exemple
- [`app.py`](../../../../../Module08/samples/04/app.py) - Application Chainlit en production
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook √©ducatif
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Inf√©rence IA bas√©e sur le navigateur
- [`open-webui-guide.md`](./open-webui-guide.md) - Configuration compl√®te Open WebUI

### Exemples Connexes
- [Documentation Session 4](../../04.CuttingEdgeModels.md) - Guide complet de la session
- [Exemples Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Exemples officiels

---

