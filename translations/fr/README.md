<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f0f8da2fde263594c60dab5c40e0fffc",
  "translation_date": "2025-07-22T07:49:58+00:00",
  "source_file": "README.md",
  "language_code": "fr"
}
-->
# EdgeAI pour D√©butants

Un parcours √©ducatif approfondi √† travers les technologies Edge AI, structur√© en trois modules complets : Fondamentaux de l'EdgeAI, Bases des Petits Mod√®les de Langage, et Strat√©gies de D√©ploiement Pratiques. Ce cours guide les apprenants des concepts de base aux impl√©mentations avanc√©es, avec des √©tudes de cas r√©els, des exercices pratiques et des exemples de d√©ploiement qui montrent comment ex√©cuter efficacement des mod√®les d'IA directement sur des appareils en p√©riph√©rie pour une meilleure confidentialit√©, une latence r√©duite et une efficacit√© accrue.

![Image de couverture du cours](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.fr.png)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![Pull-requests GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Bienvenus](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Discord Microsoft Azure AI Foundry](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Suivez ces √©tapes pour commencer √† utiliser ces ressources :  
1. **Forkez le R√©pertoire** : Cliquez [![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/mcp-for-beginners/fork)  
2. **Clonez le R√©pertoire** : `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Rejoignez le Discord Azure AI Foundry pour rencontrer des experts et d'autres d√©veloppeurs**](https://discord.com/invite/ByRwuEEgH4)  

### üåê Support Multilingue

#### Pris en charge via GitHub Action (Automatis√© et Toujours √† Jour)

[Fran√ßais](./README.md) | [Espagnol](../es/README.md) | [Chinois (Simplifi√©)](../zh/README.md) | [Chinois (Traditionnel, Macao)](../mo/README.md) | [Chinois (Traditionnel, Hong Kong)](../hk/README.md) | [Chinois (Traditionnel, Ta√Øwan)](../tw/README.md) | [Japonais](../ja/README.md) | [Cor√©en](../ko/README.md) |  

Bienvenue dans EdgeAI pour D√©butants, o√π la puissance des mod√®les de langage rencontre l'efficacit√© des appareils locaux. Ce cours introduit comment de petits mod√®les de langage optimis√©s (SLMs) peuvent fonctionner directement sur du mat√©riel en p√©riph√©rie‚Äîsmartphones, cartes IoT et serveurs compacts‚Äîsans n√©cessiter d'acc√®s au cloud. Vous d√©couvrirez comment l'inf√©rence en temps r√©el, respectueuse de la vie priv√©e, r√©volutionne les maisons intelligentes, la surveillance industrielle et les applications hors ligne, gr√¢ce √† des d√©ploiements l√©gers con√ßus pour la rapidit√©, la s√©curit√© et la modularit√©.

**Edge AI**

L'Edge AI consiste √† ex√©cuter des algorithmes d'IA et des mod√®les de langage localement sur du mat√©riel‚Äîpr√®s de l'endroit o√π les donn√©es sont g√©n√©r√©es‚Äîsans d√©pendre des ressources cloud pour l'inf√©rence. Cela r√©duit la latence, am√©liore la confidentialit√© et permet une prise de d√©cision en temps r√©el.

Principes de base :  
- Inf√©rence sur appareil : Les mod√®les d'IA s'ex√©cutent sur des appareils en p√©riph√©rie (t√©l√©phones, routeurs, microcontr√¥leurs, PC industriels).  
- Fonctionnement hors ligne : Fonctionne sans connexion internet permanente.  
- Faible latence : R√©ponses imm√©diates adapt√©es aux syst√®mes en temps r√©el.  
- Souverainet√© des donn√©es : Les donn√©es sensibles restent locales, am√©liorant la s√©curit√© et la conformit√©.  

**Petits Mod√®les de Langage (SLMs)**  
Les SLMs comme Phi-4, Mistral-7B ou Gemma sont des versions optimis√©es de grands mod√®les de langage (LLMs)‚Äîentra√Æn√©es ou distill√©es pour :  
- R√©duire l'empreinte m√©moire  
- Diminuer les besoins en calcul  
- Acc√©l√©rer les temps de d√©marrage  

Ils offrent de puissantes capacit√©s de traitement du langage naturel tout en respectant les contraintes de :  
- Syst√®mes embarqu√©s  
- Appareils mobiles  
- Appareils IoT  
- Serveurs en p√©riph√©rie avec GPU limit√©  
- Ordinateurs personnels  

## Architecture du Cours

### [Module 01 : Fondamentaux et Transformation de l'EdgeAI](./Module01/README.md)  
**Th√®me** : La transformation apport√©e par le d√©ploiement de l'Edge AI  

#### Structure des Chapitres :  
- [**Section 1 : Fondamentaux de l'EdgeAI**](./Module01/01.EdgeAIFundamentals.md)  
  - Comparaison entre l'IA cloud traditionnelle et l'Edge AI  
  - D√©fis et contraintes de l'informatique en p√©riph√©rie  
  - Technologies cl√©s : quantification des mod√®les, optimisation par compression, Petits Mod√®les de Langage (SLMs)  
  - Acc√©l√©ration mat√©rielle : NPUs, optimisation GPU, optimisation CPU  
  - Avantages : s√©curit√© de la confidentialit√©, faible latence, capacit√©s hors ligne, efficacit√© des co√ªts  

- [**Section 2 : √âtudes de Cas R√©els**](./Module01/02.RealWorldCaseStudies.md)  
  - √âcosyst√®me de mod√®les Microsoft Phi & Mu  
    - Phi Silica : int√©gration IA pour Windows  
    - Mod√®les Mu : micro-mod√®les de langage sp√©cifiques √† des t√¢ches  
  - √âtude de cas sur le syst√®me de rapport IA de Japan Airlines  
  - Impact sur le march√© et orientations futures  
  - Consid√©rations et meilleures pratiques pour le d√©ploiement  

- [**Section 3 : Guide Pratique d'Impl√©mentation**](./Module01/03.PracticalImplementationGuide.md)  
  - Configuration de l'environnement de d√©veloppement (Python 3.10+, .NET 8+)  
  - Exigences mat√©rielles et configurations recommand√©es  
  - Ressources des familles de mod√®les principaux  
  - Outils de quantification et d'optimisation (Llama.cpp, Microsoft Olive, Apple MLX)  
  - Liste de v√©rification pour l'√©valuation et la validation  

- [**Section 4 : Plateformes Mat√©rielles pour le D√©ploiement de l'Edge AI**](./Module01/04.EdgeDeployment.md)  
  - Consid√©rations et exigences pour le d√©ploiement de l'Edge AI  
  - Mat√©riel Edge AI d'Intel et techniques d'optimisation  
  - Solutions AI de Qualcomm pour les syst√®mes mobiles et embarqu√©s  
  - Plateformes NVIDIA Jetson et informatique en p√©riph√©rie  
  - Plateformes PC Windows AI avec acc√©l√©ration NPU  
  - Strat√©gies d'optimisation sp√©cifiques au mat√©riel  

---

### [Module 02 : Bases des Petits Mod√®les de Langage](./Module02/README.md)  
**Th√®me** : Principes th√©oriques des SLMs, strat√©gies d'impl√©mentation et d√©ploiement en production  

#### Structure des Chapitres :  
- [**Section 1 : Fondamentaux de la Famille de Mod√®les Microsoft Phi**](./Module02/01.PhiFamily.md)  
  - √âvolution de la philosophie de conception (Phi-1 √† Phi-4)  
  - Conception architecturale ax√©e sur l'efficacit√©  
  - Capacit√©s sp√©cialis√©es (raisonnement, multimodal, d√©ploiement en p√©riph√©rie)  

- [**Section 2 : Fondamentaux de la Famille Qwen**](./Module02/02.QwenFamily.md)  
  - Excellence open source (Qwen 1.0 √† Qwen3) - disponible via Hugging Face  
  - Architecture avanc√©e de raisonnement avec capacit√©s de mode r√©flexion  
  - Options de d√©ploiement √©volutives (0.5B-235B param√®tres)  

- [**Section 3 : Fondamentaux de la Famille Gemma**](./Module02/03.GemmaFamily.md)  
  - Innovation ax√©e sur la recherche (Gemma 3 & 3n)  
  - Excellence multimodale  
  - Architecture mobile-first  

- [**Section 4 : Fondamentaux de la Famille BitNET**](./Module02/04.BitNETFamily.md)  
  - Technologie r√©volutionnaire de quantification (1.58-bit)  
  - Cadre d'inf√©rence sp√©cialis√© depuis https://github.com/microsoft/BitNet  
  - Leadership en IA durable gr√¢ce √† une efficacit√© extr√™me  

- [**Section 5 : Fondamentaux des Mod√®les Microsoft Mu**](./Module02/05.mumodel.md)  
  - Architecture ax√©e sur les appareils int√©gr√©e √† Windows 11  
  - Int√©gration syst√®me avec les Param√®tres de Windows 11  
  - Fonctionnement hors ligne respectueux de la vie priv√©e  

- [**Section 6 : Fondamentaux de Phi-Silica**](./Module02/06.phisilica.md)  
  - Architecture optimis√©e pour NPU int√©gr√©e aux PC Windows 11 Copilot+  
  - Efficacit√© exceptionnelle (650 tokens/seconde √† 1.5W)  
  - Int√©gration pour d√©veloppeurs avec le SDK Windows App  

---  

### [Module 03 : D√©ploiement des Petits Mod√®les de Langage](./Module03/README.md)  
**Th√®me** : Cycle complet de d√©ploiement des SLMs, de la th√©orie √† l'environnement de production  

#### Structure des Chapitres :  
- [**Section 1 : Apprentissage Avanc√© des SLMs**](./Module03/01.SLMAdvancedLearning.md)  
  - Cadre de classification des param√®tres (Micro SLM 100M-1.4B, Medium SLM 14B-30B)  
  - Techniques d'optimisation avanc√©es (m√©thodes de quantification, quantification 1-bit BitNET)  
  - Strat√©gies d'acquisition de mod√®les (Azure AI Foundry pour les mod√®les Phi, Hugging Face pour certains mod√®les)  

- [**Section 2 : D√©ploiement en Environnement Local**](./Module03/02.DeployingSLMinLocalEnv.md)  
  - D√©ploiement universel sur la plateforme Ollama  
  - Solutions locales de niveau entreprise avec Microsoft Foundry  
  - Analyse comparative des cadres  

- [**Section 3 : D√©ploiement Cloud Conteneuris√©**](./Module03/03.DeployingSLMinCloud.md)  
  - D√©ploiement d'inf√©rence haute performance avec vLLM  
  - Orchestration de conteneurs Ollama  
  - Impl√©mentation optimis√©e pour l'edge avec ONNX Runtime  

---  

### [Module 04 : Conversion de Format et Quantification des Mod√®les](./Module04/README.md)  
**Th√®me** : Bo√Æte √† outils compl√®te pour l'optimisation des mod√®les pour le d√©ploiement en p√©riph√©rie sur diff√©rentes plateformes  

#### Structure des Chapitres :  
- [**Section 1 : Bases de la Conversion de Format et de la Quantification des Mod√®les**](./Module04/01.Introduce.md)  
  - Cadre de classification des pr√©cisions (ultra-faible, faible, moyenne pr√©cision)  
  - Avantages et cas d'utilisation des formats GGUF et ONNX  
  - B√©n√©fices de la quantification pour l'efficacit√© op√©rationnelle  
  - Comparaisons des performances et empreintes m√©moire  

- [**Section 2 : Guide d'Impl√©mentation de Llama.cpp**](./Module04/02.Llamacpp.md)  
  - Installation multiplateforme (Windows, macOS, Linux)  
  - Conversion au format GGUF et niveaux de quantification (Q2_K √† Q8_0)  
  - Acc√©l√©ration mat√©rielle (CUDA, Metal, OpenCL, Vulkan)  
  - Int√©gration Python et d√©ploiement REST API  

- [**Section 3 : Suite d'Optimisation Microsoft Olive**](./Module04/03.MicrosoftOlive.md)  
  - Optimisation des mod√®les adapt√©e au mat√©riel avec plus de 40 composants int√©gr√©s  
  - Auto-optimisation avec quantification dynamique et statique  
  - Int√©gration en entreprise avec les workflows Azure ML  
  - Support des mod√®les populaires (Llama, Phi, certains mod√®les Qwen, Gemma)  

- [**Section 4 : Exploration Approfondie du Framework Apple MLX**](./Module04/04.AppleMLX.md)  
  - Architecture m√©moire unifi√©e pour Apple Silicon  
  - Support pour LLaMA, Mistral, Phi-3, certains mod√®les Qwen  
  - Fine-tuning LoRA et personnalisation des mod√®les  
  - Int√©gration Hugging Face avec quantification 4-bit/8-bit  

---  

### [Module 05 : SLMOps - Op√©rations sur les Petits Mod√®les de Langage](./Module05/README.md)  
**Th√®me** : Cycle complet des op√©rations sur les SLMs, de la distillation au d√©ploiement en production  

#### Structure des Chapitres :  
- [**Section 1 : Introduction au SLMOps**](./Module05/01.IntroduceSLMOps.md)  
  - Changement de paradigme du SLMOps dans les op√©rations d'IA  
  - Architecture ax√©e sur l'efficacit√© des co√ªts et la confidentialit√©  
  - Impact strat√©gique sur les entreprises et avantages concurrentiels  
  - D√©fis et solutions pour les impl√©mentations r√©elles  

- [**Section 2 : Distillation des Mod√®les - De la Th√©orie √† la Pratique**](./Module05/02.SLMOps-Distillation.md)  
  - Transfert de connaissances des mod√®les enseignants aux mod√®les √©tudiants  
  - Impl√©mentation du processus de distillation en deux √©tapes  
  - Workflows de distillation Azure ML avec exemples pratiques  
  - R√©duction de 85 % du temps d'inf√©rence avec une r√©tention de pr√©cision de 92 %  

- [**Section 3 : Fine-Tuning - Personnalisation des Mod√®les pour des T√¢ches Sp√©cifiques**](./Module05/03.SLMOps-Finetuing.md)  
  - Techniques de fine-tuning efficaces en param√®tres (PEFT)  
  - M√©thodes avanc√©es LoRA et QLoRA  
  - Impl√©mentation de fine-tuning avec Microsoft Olive  
  - Entra√Ænement multi-adaptateurs et optimisation des hyperparam√®tres  

- [**Section 4 : D√©ploiement - Impl√©mentation Pr√™te pour la Production**](./Module05/04.SLMOps.Deployment.md)  
  - Conversion et quantification des mod√®les pour la production  
  - Configuration de d√©ploiement Foundry Local  
  - Validation de la qualit√© et benchmarking des performances  
  - R√©duction de 75 % de la taille avec surveillance en production  

---  

### [Module 06 : Syst√®mes Agentiques SLM - Agents IA et Appels de Fonction](./Module06/README.md)  
**Th√®me** : Impl√©mentation des syst√®mes agentiques SLM, des bases aux appels de fonction avanc√©s et √† l'int√©gration du Protocole de Contexte de Mod√®le (MCP)  

#### Structure des Chapitres :  
- [**Section 1 : Fondations des Agents IA et des Petits Mod√®les de Langage**](./Module06/01.IntroduceAgent.md)  
- Cadre de classification des agents (r√©flexe, bas√© sur un mod√®le, bas√© sur des objectifs, agents d'apprentissage)
- Fondamentaux des SLM et strat√©gies d'optimisation (GGUF, quantification, frameworks edge)
- Analyse des compromis entre SLM et LLM (r√©duction des co√ªts de 10 √† 30√ó, efficacit√© des t√¢ches de 70 √† 80 %)
- D√©ploiement pratique avec Ollama, VLLM et solutions Microsoft edge

- [**Section 2 : Appels de fonctions dans les Small Language Models**](./Module06/02.FunctionCalling.md)
  - Mise en ≈ìuvre syst√©matique du workflow (d√©tection d'intention, sortie JSON, ex√©cution externe)
  - Impl√©mentations sp√©cifiques aux plateformes (Phi-4-mini, mod√®les Qwen s√©lectionn√©s, Microsoft Foundry Local)
  - Exemples avanc√©s (collaboration multi-agents, s√©lection dynamique d'outils)
  - Consid√©rations pour la production (limitation de d√©bit, journalisation d'audit, mesures de s√©curit√©)

- [**Section 3 : Int√©gration du protocole de contexte de mod√®le (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architecture du protocole et conception de syst√®me en couches
  - Support multi-backend (Ollama pour le d√©veloppement, vLLM pour la production)
  - Protocoles de connexion (modes STDIO et SSE)
  - Applications concr√®tes (automatisation web, traitement de donn√©es, int√©gration API)

---

### [Module 07 : √âchantillons d'impl√©mentation EdgeAI](./Module07/README.md)
**Th√®me** : Impl√©mentations compl√®tes d'EdgeAI sur diverses plateformes et frameworks

#### Structure des chapitres :
- [**EdgeAI sur NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Performance IA de 67 TOPS dans un format de la taille d'une carte de cr√©dit
  - Support des mod√®les d'IA g√©n√©rative (transformateurs de vision, LLMs, mod√®les vision-langage)
  - Applications en robotique, drones, cam√©ras intelligentes, dispositifs autonomes
  - Plateforme abordable √† 249 $ pour un d√©veloppement d'IA d√©mocratis√©

- [**EdgeAI dans les applications mobiles avec .NET MAUI et ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - IA mobile multiplateforme avec un code C# unique
  - Support de l'acc√©l√©ration mat√©rielle (CPU, GPU, processeurs IA mobiles)
  - Optimisations sp√©cifiques aux plateformes (CoreML pour iOS, NNAPI pour Android)
  - Impl√©mentation compl√®te de la boucle d'IA g√©n√©rative

- [**EdgeAI sur Azure avec le moteur Small Language Models**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architecture de d√©ploiement hybride cloud-edge
  - Int√©gration des services Azure AI avec ONNX Runtime
  - D√©ploiement √† l'√©chelle de l'entreprise et gestion continue des mod√®les
  - Workflows hybrides d'IA pour le traitement intelligent de documents

- [**EdgeAI avec Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fondation Windows AI Foundry pour une inf√©rence performante sur appareil
  - Support mat√©riel universel (AMD, Intel, NVIDIA, Qualcomm)
  - Abstraction et optimisation mat√©rielle automatique
  - Framework unifi√© pour un √©cosyst√®me mat√©riel diversifi√© sous Windows

- [**EdgeAI avec les applications Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Impl√©mentation RAG ax√©e sur la confidentialit√© avec des ressources locales
  - Int√©gration du mod√®le de langage Phi-3 avec recherche s√©mantique (mod√®les Phi uniquement)
  - Support des bases de donn√©es vectorielles locales (SQLite, Qdrant)
  - Capacit√©s de souverainet√© des donn√©es et fonctionnement hors ligne

## Aper√ßu des r√©sultats d'apprentissage

### R√©sultats d'apprentissage du Module 01 :
- Comprendre les diff√©rences fondamentales entre les architectures cloud et edge AI
- Ma√Ætriser les techniques d'optimisation de base pour le d√©ploiement edge
- Reconna√Ætre les applications concr√®tes et les histoires de r√©ussite
- Acqu√©rir des comp√©tences pratiques pour impl√©menter des solutions EdgeAI

### R√©sultats d'apprentissage du Module 02 :
- Compr√©hension approfondie des diff√©rentes philosophies de conception des SLM et de leurs implications de d√©ploiement
- Ma√Ætriser les capacit√©s de prise de d√©cision strat√©gique bas√©es sur les contraintes computationnelles et les exigences de performance
- Comprendre les compromis de flexibilit√© de d√©ploiement
- Poss√©der des perspectives pr√™tes pour l'avenir sur les architectures d'IA efficaces

### R√©sultats d'apprentissage du Module 03 :
- Capacit√©s strat√©giques de s√©lection de mod√®les
- Ma√Ætrise des techniques d'optimisation
- Ma√Ætrise de la flexibilit√© de d√©ploiement
- Capacit√©s de configuration pr√™tes pour la production

### R√©sultats d'apprentissage du Module 04 :
- Compr√©hension approfondie des limites de quantification et des applications pratiques
- Exp√©rience pratique avec plusieurs frameworks d'optimisation (Llama.cpp, Olive, MLX)
- Capacit√©s de s√©lection d'optimisation adapt√©es au mat√©riel
- Comp√©tences de d√©ploiement en production pour des environnements edge multiplateformes

### R√©sultats d'apprentissage du Module 05 :
- Ma√Ætriser le paradigme SLMOps et les principes op√©rationnels
- Impl√©menter la distillation de mod√®les pour le transfert de connaissances et l'optimisation de l'efficacit√©
- Appliquer des techniques de fine-tuning pour la personnalisation de mod√®les sp√©cifiques au domaine
- D√©ployer des solutions SLM pr√™tes pour la production avec des strat√©gies de surveillance et de maintenance

### R√©sultats d'apprentissage du Module 06 :
- Comprendre les concepts fondamentaux des agents IA et de l'architecture des Small Language Models
- Ma√Ætriser l'impl√©mentation des appels de fonctions sur plusieurs plateformes et frameworks
- Int√©grer le protocole de contexte de mod√®le (MCP) pour une interaction standardis√©e avec des outils externes
- Construire des syst√®mes agentiques sophistiqu√©s n√©cessitant une intervention humaine minimale

### R√©sultats d'apprentissage du Module 07 :
- Acqu√©rir une exp√©rience pratique avec diverses plateformes EdgeAI et strat√©gies d'impl√©mentation
- Ma√Ætriser les techniques d'optimisation sp√©cifiques au mat√©riel sur les plateformes NVIDIA, mobiles, Azure et Windows
- Comprendre les compromis de d√©ploiement entre performance, co√ªt et exigences de confidentialit√©
- D√©velopper des comp√©tences pratiques pour construire des applications EdgeAI concr√®tes dans diff√©rents √©cosyst√®mes

## Diagramme de structure de fichier

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.AppleMLX.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```

## Caract√©ristiques du cours

- **Apprentissage progressif** : Avancez progressivement des concepts de base au d√©ploiement avanc√©
- **Int√©gration th√©orie et pratique** : Chaque module contient des bases th√©oriques et des op√©rations pratiques
- **√âtudes de cas r√©elles** : Bas√©es sur des cas r√©els de Microsoft, Alibaba, Google et autres
- **Pratique concr√®te** : Fichiers de configuration complets, proc√©dures de test API et scripts de d√©ploiement
- **Benchmarks de performance** : Comparaisons d√©taill√©es de la vitesse d'inf√©rence, de l'utilisation de la m√©moire et des exigences en ressources
- **Consid√©rations de niveau entreprise** : Pratiques de s√©curit√©, cadres de conformit√© et strat√©gies de protection des donn√©es

## D√©marrage

Chemin d'apprentissage recommand√© :
1. Commencez par **Module01** pour construire une compr√©hension fondamentale de l'EdgeAI
2. Passez √† **Module02** pour comprendre en profondeur les diff√©rentes familles de mod√®les SLM
3. Apprenez **Module03** pour ma√Ætriser les comp√©tences pratiques de d√©ploiement
4. Continuez avec **Module04** pour une optimisation avanc√©e des mod√®les et conversion de formats
5. Compl√©tez **Module05** pour ma√Ætriser SLMOps pour des impl√©mentations pr√™tes pour la production
6. Explorez **Module06** pour comprendre les syst√®mes agentiques SLM et les capacit√©s d'appel de fonctions
7. Terminez avec **Module07** pour acqu√©rir une exp√©rience pratique avec des √©chantillons d'impl√©mentation EdgeAI diversifi√©s

Chaque module est con√ßu pour √™tre complet ind√©pendamment, mais un apprentissage s√©quentiel offrira les meilleurs r√©sultats.

## Guide d'√©tude

Un [Guide d'√©tude](STUDY_GUIDE.md) complet est disponible pour vous aider √† maximiser votre exp√©rience d'apprentissage. Le guide d'√©tude fournit :

- **Chemins d'apprentissage structur√©s** : Calendriers optimis√©s pour compl√©ter le cours en 20 heures
- **Conseils sur l'allocation du temps** : Recommandations sp√©cifiques pour √©quilibrer lecture, exercices et projets
- **Focus sur les concepts cl√©s** : Objectifs d'apprentissage prioritaires pour chaque module
- **Outils d'auto-√©valuation** : Questions et exercices pour tester votre compr√©hension
- **Id√©es de mini-projets** : Applications pratiques pour renforcer votre apprentissage

Le guide d'√©tude est con√ßu pour s'adapter √† un apprentissage intensif (1 semaine) ou √† un apprentissage √† temps partiel (3 semaines), avec des indications claires sur la fa√ßon d'allouer votre temps efficacement m√™me si vous ne pouvez consacrer que 10 heures au cours.

---

**L'avenir de l'EdgeAI repose sur l'am√©lioration continue des architectures de mod√®les, des techniques de quantification et des strat√©gies de d√©ploiement qui privil√©gient l'efficacit√© et la sp√©cialisation plut√¥t que les capacit√©s g√©n√©ralistes. Les organisations qui adoptent ce changement de paradigme seront bien positionn√©es pour exploiter le potentiel transformateur de l'IA tout en gardant le contr√¥le sur leurs donn√©es et leurs op√©rations.**

## Autres cours

Notre √©quipe propose d'autres cours ! D√©couvrez :

- [MCP pour les d√©butants](https://github.com/microsoft/mcp-for-beginners)
- [Agents IA pour les d√©butants](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour les d√©butants avec .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour les d√©butants avec JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour les d√©butants](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
- [ML pour les d√©butants](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
- [Data Science pour les d√©butants](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
- [IA pour les d√©butants](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
- [Cybers√©curit√© pour les d√©butants](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)
- [D√©veloppement web pour les d√©butants](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
- [IoT pour les d√©butants](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)
- [D√©veloppement XR pour les d√©butants](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Ma√Ætriser GitHub Copilot pour la programmation assist√©e par IA](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)
- [Ma√Ætriser GitHub Copilot pour les d√©veloppeurs C#/.NET](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)
- [Choisissez votre propre aventure Copilot](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.