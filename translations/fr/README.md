<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c817161ba08864340737d623f761b9ae",
  "translation_date": "2025-09-17T12:09:03+00:00",
  "source_file": "README.md",
  "language_code": "fr"
}
-->
# EdgeAI pour les D√©butants

![Image de couverture du cours](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.fr.png)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![Pull-requests GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Bienvenus](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Discord Microsoft Azure AI Foundry](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Suivez ces √©tapes pour commencer √† utiliser ces ressources :

1. **Forkez le d√©p√¥t** : Cliquez sur [![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Clonez le d√©p√¥t** : `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Rejoignez le Discord Azure AI Foundry et rencontrez des experts et d√©veloppeurs**](https://discord.com/invite/ByRwuEEgH4)

### üåê Support Multilingue

#### Support√© via GitHub Action (Automatis√© et Toujours √† Jour)

[Arabe](../ar/README.md) | [Bengali](../bn/README.md) | [Bulgare](../bg/README.md) | [Birman (Myanmar)](../my/README.md) | [Chinois (Simplifi√©)](../zh/README.md) | [Chinois (Traditionnel, Hong Kong)](../hk/README.md) | [Chinois (Traditionnel, Macao)](../mo/README.md) | [Chinois (Traditionnel, Ta√Øwan)](../tw/README.md) | [Croate](../hr/README.md) | [Tch√®que](../cs/README.md) | [Danois](../da/README.md) | [N√©erlandais](../nl/README.md) | [Finnois](../fi/README.md) | [Fran√ßais](./README.md) | [Allemand](../de/README.md) | [Grec](../el/README.md) | [H√©breu](../he/README.md) | [Hindi](../hi/README.md) | [Hongrois](../hu/README.md) | [Indon√©sien](../id/README.md) | [Italien](../it/README.md) | [Japonais](../ja/README.md) | [Cor√©en](../ko/README.md) | [Malais](../ms/README.md) | [Marathi](../mr/README.md) | [N√©palais](../ne/README.md) | [Norv√©gien](../no/README.md) | [Persan (Farsi)](../fa/README.md) | [Polonais](../pl/README.md) | [Portugais (Br√©sil)](../br/README.md) | [Portugais (Portugal)](../pt/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Roumain](../ro/README.md) | [Russe](../ru/README.md) | [Serbe (Cyrillique)](../sr/README.md) | [Slovaque](../sk/README.md) | [Slov√®ne](../sl/README.md) | [Espagnol](../es/README.md) | [Swahili](../sw/README.md) | [Su√©dois](../sv/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Tha√Ø](../th/README.md) | [Turc](../tr/README.md) | [Ukrainien](../uk/README.md) | [Ourdou](../ur/README.md) | [Vietnamien](../vi/README.md)

**Si vous souhaitez ajouter des langues suppl√©mentaires, les langues support√©es sont list√©es [ici](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Introduction

Bienvenue dans **EdgeAI pour les D√©butants** ‚Äì votre parcours complet dans le monde transformateur de l'Intelligence Artificielle en p√©riph√©rie. Ce cours comble le foss√© entre les capacit√©s puissantes de l'IA et le d√©ploiement pratique sur des appareils p√©riph√©riques, vous permettant de tirer parti du potentiel de l'IA directement l√† o√π les donn√©es sont g√©n√©r√©es et o√π les d√©cisions doivent √™tre prises.

### Ce que vous allez ma√Ætriser

Ce cours vous guide des concepts fondamentaux aux impl√©mentations pr√™tes pour la production, couvrant :
- **Mod√®les de Langage R√©duits (SLMs)** optimis√©s pour le d√©ploiement en p√©riph√©rie
- **Optimisation adapt√©e au mat√©riel** sur diverses plateformes
- **Inf√©rence en temps r√©el** avec des capacit√©s de pr√©servation de la vie priv√©e
- **Strat√©gies de d√©ploiement en production** pour les applications d'entreprise

### Pourquoi EdgeAI est important

Edge AI repr√©sente un changement de paradigme qui r√©pond √† des d√©fis modernes critiques :
- **Confidentialit√© & S√©curit√©** : Traitez les donn√©es sensibles localement sans exposition au cloud
- **Performance en temps r√©el** : √âliminez la latence r√©seau pour les applications critiques
- **Efficacit√© des co√ªts** : R√©duisez les d√©penses de bande passante et de calcul dans le cloud
- **Op√©rations r√©silientes** : Maintenez la fonctionnalit√© pendant les pannes r√©seau
- **Conformit√© r√©glementaire** : Respectez les exigences de souverainet√© des donn√©es

### Edge AI

Edge AI fait r√©f√©rence √† l'ex√©cution d'algorithmes d'IA et de mod√®les de langage localement sur du mat√©riel ‚Äì pr√®s de l'endroit o√π les donn√©es sont g√©n√©r√©es ‚Äì sans d√©pendre des ressources cloud pour l'inf√©rence. Cela r√©duit la latence, am√©liore la confidentialit√© et permet une prise de d√©cision en temps r√©el.

### Principes fondamentaux :
- **Inf√©rence sur appareil** : Les mod√®les d'IA fonctionnent sur des appareils p√©riph√©riques (t√©l√©phones, routeurs, microcontr√¥leurs, PC industriels)
- **Capacit√© hors ligne** : Fonctionne sans connectivit√© Internet persistante
- **Faible latence** : R√©ponses imm√©diates adapt√©es aux syst√®mes en temps r√©el
- **Souverainet√© des donn√©es** : Conserve les donn√©es sensibles localement, am√©liorant la s√©curit√© et la conformit√©

### Mod√®les de Langage R√©duits (SLMs)

Les SLMs comme Phi-4, Mistral-7B et Gemma sont des versions optimis√©es de grands mod√®les de langage ‚Äì entra√Æn√©s ou distill√©s pour :
- **Empreinte m√©moire r√©duite** : Utilisation efficace de la m√©moire limit√©e des appareils p√©riph√©riques
- **Moins de demande de calcul** : Optimis√©s pour les performances CPU et GPU en p√©riph√©rie
- **Temps de d√©marrage plus rapides** : Initialisation rapide pour des applications r√©actives

Ils d√©bloquent des capacit√©s NLP puissantes tout en respectant les contraintes de :
- **Syst√®mes embarqu√©s** : Appareils IoT et contr√¥leurs industriels
- **Appareils mobiles** : Smartphones et tablettes avec capacit√©s hors ligne
- **Appareils IoT** : Capteurs et appareils intelligents avec ressources limit√©es
- **Serveurs p√©riph√©riques** : Unit√©s de traitement locales avec ressources GPU limit√©es
- **Ordinateurs personnels** : Sc√©narios de d√©ploiement sur ordinateurs de bureau et portables

## Architecture du cours

### [Module 01 : Fondamentaux et Transformation de EdgeAI](./Module01/README.md)
**Th√®me** : Le changement transformateur du d√©ploiement de l'IA en p√©riph√©rie

#### Structure des chapitres :
- [**Section 1 : Fondamentaux de EdgeAI**](./Module01/01.EdgeAIFundamentals.md)
  - Comparaison entre l'IA cloud traditionnelle et l'IA en p√©riph√©rie
  - D√©fis et contraintes du calcul en p√©riph√©rie
  - Technologies cl√©s : quantification des mod√®les, optimisation de la compression, Mod√®les de Langage R√©duits (SLMs)
  - Acc√©l√©ration mat√©rielle : NPUs, optimisation GPU, optimisation CPU
  - Avantages : s√©curit√© de la confidentialit√©, faible latence, capacit√©s hors ligne, efficacit√© des co√ªts

- [**Section 2 : √âtudes de cas r√©elles**](./Module01/02.RealWorldCaseStudies.md)
  - √âcosyst√®me de mod√®les Microsoft Phi & Mu
  - √âtude de cas du syst√®me de reporting AI de Japan Airlines
  - Impact sur le march√© et orientations futures
  - Consid√©rations de d√©ploiement et meilleures pratiques

- [**Section 3 : Guide pratique d'impl√©mentation**](./Module01/03.PracticalImplementationGuide.md)
  - Configuration de l'environnement de d√©veloppement (Python 3.10+, .NET 8+)
  - Exigences mat√©rielles et configurations recommand√©es
  - Ressources des familles de mod√®les principaux
  - Outils de quantification et d'optimisation (Llama.cpp, Microsoft Olive, Apple MLX)
  - Liste de v√©rification pour l'√©valuation et la v√©rification

- [**Section 4 : Plateformes mat√©rielles de d√©ploiement Edge AI**](./Module01/04.EdgeDeployment.md)
  - Consid√©rations et exigences pour le d√©ploiement de l'IA en p√©riph√©rie
  - Mat√©riel Intel pour l'IA en p√©riph√©rie et techniques d'optimisation
  - Solutions AI Qualcomm pour les syst√®mes mobiles et embarqu√©s
  - Plateformes NVIDIA Jetson et calcul en p√©riph√©rie
  - Plateformes PC Windows AI avec acc√©l√©ration NPU
  - Strat√©gies d'optimisation sp√©cifiques au mat√©riel

---

### [Module 02 : Fondations des Mod√®les de Langage R√©duits](./Module02/README.md)
**Th√®me** : Principes th√©oriques des SLMs, strat√©gies d'impl√©mentation et d√©ploiement en production

#### Structure des chapitres :
- [**Section 1 : Fondamentaux de la famille de mod√®les Microsoft Phi**](./Module02/01.PhiFamily.md)
  - √âvolution de la philosophie de conception (Phi-1 √† Phi-4)
  - Conception architecturale ax√©e sur l'efficacit√©
  - Capacit√©s sp√©cialis√©es (raisonnement, multimodal, d√©ploiement en p√©riph√©rie)

- [**Section 2 : Fondamentaux de la famille Qwen**](./Module02/02.QwenFamily.md)
  - Excellence open source (Qwen 1.0 √† Qwen3) - disponible via Hugging Face
  - Architecture avanc√©e de raisonnement avec capacit√©s de mode r√©flexion
  - Options de d√©ploiement √©volutives (0.5B-235B param√®tres)

- [**Section 3 : Fondamentaux de la famille Gemma**](./Module02/03.GemmaFamily.md)
  - Innovation ax√©e sur la recherche (Gemma 3 & 3n)
  - Excellence multimodale
  - Architecture ax√©e sur le mobile

- [**Section 4 : Fondamentaux de la famille BitNET**](./Module02/04.BitNETFamily.md)
  - Technologie r√©volutionnaire de quantification (1.58-bit)
  - Cadre d'inf√©rence sp√©cialis√© depuis https://github.com/microsoft/BitNet
  - Leadership en IA durable gr√¢ce √† une efficacit√© extr√™me

- [**Section 5 : Fondamentaux du mod√®le Microsoft Mu**](./Module02/05.mumodel.md)
  - Architecture ax√©e sur les appareils int√©gr√©e √† Windows 11
  - Int√©gration syst√®me avec les param√®tres de Windows 11
  - Fonctionnement hors ligne pr√©servant la confidentialit√©

- [**Section 6 : Fondamentaux de Phi-Silica**](./Module02/06.phisilica.md)
  - Architecture optimis√©e pour NPU int√©gr√©e aux PC Windows 11 Copilot+
  - Efficacit√© exceptionnelle (650 tokens/seconde √† 1.5W)
  - Int√©gration pour les d√©veloppeurs avec Windows App SDK

---

### [Module 03 : D√©ploiement des Mod√®les de Langage R√©duits](./Module03/README.md)
**Th√®me** : Cycle complet de d√©ploiement des SLMs, de la th√©orie √† l'environnement de production

#### Structure des chapitres :
- [**Section 1 : Apprentissage avanc√© des SLMs**](./Module03/01.SLMAdvancedLearning.md)
  - Cadre de classification des param√®tres (Micro SLM 100M-1.4B, Medium SLM 14B-30B)
  - Techniques avanc√©es d'optimisation (m√©thodes de quantification, quantification BitNET 1-bit)
  - Strat√©gies d'acquisition de mod√®les (Azure AI Foundry pour les mod√®les Phi, Hugging Face pour les mod√®les s√©lectionn√©s)

- [**Section 2 : D√©ploiement dans un environnement local**](./Module03/02.DeployingSLMinLocalEnv.md)
  - D√©ploiement universel sur la plateforme Ollama
  - Solutions locales de niveau entreprise Microsoft Foundry
  - Analyse comparative des cadres

- [**Section 3 : D√©ploiement dans le cloud conteneuris√©**](./Module03/03.DeployingSLMinCloud.md)
  - D√©ploiement d'inf√©rence haute performance vLLM
  - Orchestration de conteneurs Ollama
  - Impl√©mentation optimis√©e pour p√©riph√©rie avec ONNX Runtime

---

### [Module 04 : Conversion de format de mod√®le et quantification](./Module04/README.md)
**Th√®me** : Bo√Æte √† outils compl√®te d'optimisation de mod√®les pour le d√©ploiement en p√©riph√©rie sur diverses plateformes

#### Structure des chapitres :
- [**Section 1 : Fondations de la conversion de format de mod√®le et de la quantification**](./Module04/01.Introduce.md)
  - Cadre de classification de pr√©cision (ultra-faible, faible, moyenne pr√©cision)
  - Avantages et cas d'utilisation des formats GGUF et ONNX
  - B√©n√©fices de la quantification pour l'efficacit√© op√©rationnelle
  - Comparaisons de performances et empreintes m√©moire
- [**Section 2 : Guide d'impl√©mentation de Llama.cpp**](./Module04/02.Llamacpp.md)
  - Installation multiplateforme (Windows, macOS, Linux)
  - Conversion au format GGUF et niveaux de quantification (Q2_K √† Q8_0)
  - Acc√©l√©ration mat√©rielle (CUDA, Metal, OpenCL, Vulkan)
  - Int√©gration Python et d√©ploiement d'API REST

- [**Section 3 : Suite d'optimisation Microsoft Olive**](./Module04/03.MicrosoftOlive.md)
  - Optimisation des mod√®les adapt√©e au mat√©riel avec plus de 40 composants int√©gr√©s
  - Auto-optimisation avec quantification dynamique et statique
  - Int√©gration en entreprise avec les workflows Azure ML
  - Support des mod√®les populaires (Llama, Phi, mod√®les Qwen s√©lectionn√©s, Gemma)

- [**Section 4 : Suite d'optimisation OpenVINO Toolkit**](./Module04/04.openvino.md)
  - Toolkit open-source d'Intel pour le d√©ploiement IA multiplateforme
  - Framework de compression de r√©seaux neuronaux (NNCF) pour une optimisation avanc√©e
  - OpenVINO GenAI pour le d√©ploiement de mod√®les de langage de grande taille
  - Acc√©l√©ration mat√©rielle sur CPU, GPU, VPU et acc√©l√©rateurs IA

- [**Section 5 : Exploration approfondie du framework Apple MLX**](./Module04/05.AppleMLX.md)
  - Architecture m√©moire unifi√©e pour Apple Silicon
  - Support pour LLaMA, Mistral, Phi-3, mod√®les Qwen s√©lectionn√©s
  - Fine-tuning LoRA et personnalisation des mod√®les
  - Int√©gration avec Hugging Face et quantification 4 bits/8 bits

- [**Section 6 : Synth√®se des workflows de d√©veloppement Edge AI**](./Module04/06.workflow-synthesis.md)
  - Architecture de workflow unifi√©e int√©grant plusieurs frameworks d'optimisation
  - Arbres de d√©cision pour la s√©lection des frameworks et analyse des compromis de performance
  - Validation de la pr√©paration √† la production et strat√©gies de d√©ploiement compl√®tes
  - Strat√©gies de p√©rennisation pour les architectures mat√©rielles et mod√®les √©mergents

---

### [Module 05 : SLMOps - Op√©rations sur les mod√®les de langage de petite taille](./Module05/README.md)
**Th√®me** : Op√©rations compl√®tes sur le cycle de vie des SLM, de la distillation au d√©ploiement en production

#### Structure des chapitres :
- [**Section 1 : Introduction √† SLMOps**](./Module05/01.IntroduceSLMOps.md)
  - Changement de paradigme SLMOps dans les op√©rations IA
  - Architecture √©conomique et ax√©e sur la confidentialit√©
  - Impact strat√©gique sur les entreprises et avantages comp√©titifs
  - D√©fis et solutions pour la mise en ≈ìuvre dans le monde r√©el

- [**Section 2 : Distillation de mod√®les - De la th√©orie √† la pratique**](./Module05/02.SLMOps-Distillation.md)
  - Transfert de connaissances des mod√®les enseignants aux mod√®les √©tudiants
  - Mise en ≈ìuvre du processus de distillation en deux √©tapes
  - Workflows de distillation Azure ML avec exemples pratiques
  - R√©duction de 85 % du temps d'inf√©rence avec une r√©tention de pr√©cision de 92 %

- [**Section 3 : Fine-tuning - Personnalisation des mod√®les pour des t√¢ches sp√©cifiques**](./Module05/03.SLMOps-Finetuing.md)
  - Techniques de fine-tuning efficaces en param√®tres (PEFT)
  - M√©thodes avanc√©es LoRA et QLoRA
  - Impl√©mentation de fine-tuning avec Microsoft Olive
  - Formation multi-adaptateurs et optimisation des hyperparam√®tres

- [**Section 4 : D√©ploiement - Mise en ≈ìuvre pr√™te pour la production**](./Module05/04.SLMOps.Deployment.md)
  - Conversion et quantification des mod√®les pour la production
  - Configuration de d√©ploiement Foundry Local
  - Benchmarking de performance et validation de qualit√©
  - R√©duction de taille de 75 % avec surveillance en production

---

### [Module 06 : Syst√®mes agentiques SLM - Agents IA et appels de fonctions](./Module06/README.md)
**Th√®me** : Mise en ≈ìuvre des syst√®mes agentiques SLM, des bases aux appels de fonctions avanc√©s et √† l'int√©gration du protocole de contexte de mod√®le (MCP)

#### Structure des chapitres :
- [**Section 1 : Fondations des agents IA et des mod√®les de langage de petite taille**](./Module06/01.IntroduceAgent.md)
  - Cadre de classification des agents (r√©flexes, bas√©s sur des mod√®les, bas√©s sur des objectifs, agents apprenants)
  - Fondamentaux des SLM et strat√©gies d'optimisation (GGUF, quantification, frameworks edge)
  - Analyse des compromis SLM vs LLM (r√©duction des co√ªts de 10 √† 30√ó, efficacit√© des t√¢ches de 70 √† 80 %)
  - D√©ploiement pratique avec Ollama, VLLM et solutions edge Microsoft

- [**Section 2 : Appels de fonctions dans les mod√®les de langage de petite taille**](./Module06/02.FunctionCalling.md)
  - Mise en ≈ìuvre syst√©matique des workflows (d√©tection d'intention, sortie JSON, ex√©cution externe)
  - Impl√©mentations sp√©cifiques aux plateformes (Phi-4-mini, mod√®les Qwen s√©lectionn√©s, Microsoft Foundry Local)
  - Exemples avanc√©s (collaboration multi-agents, s√©lection dynamique d'outils)
  - Consid√©rations pour la production (limitation de taux, journalisation des audits, mesures de s√©curit√©)

- [**Section 3 : Int√©gration du protocole de contexte de mod√®le (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architecture du protocole et conception de syst√®me en couches
  - Support multi-backend (Ollama pour le d√©veloppement, vLLM pour la production)
  - Protocoles de connexion (modes STDIO et SSE)
  - Applications concr√®tes (automatisation web, traitement de donn√©es, int√©gration API)

---

### [Module 07 : Exemples d'impl√©mentation EdgeAI](./Module07/README.md)
**Th√®me** : Impl√©mentations EdgeAI compl√®tes sur diverses plateformes et frameworks

#### Structure des chapitres :
- [**Toolkit IA pour Visual Studio Code**](./Module07/aitoolkit.md)
  - Environnement de d√©veloppement Edge AI complet dans VS Code
  - Catalogue de mod√®les et d√©couverte pour le d√©ploiement edge
  - Workflows de test local, optimisation et d√©veloppement d'agents
  - Surveillance des performances et √©valuation pour les sc√©narios edge

- [**Guide de d√©veloppement EdgeAI sous Windows**](./Module07/windowdeveloper.md)
  - Aper√ßu complet de la plateforme Windows AI Foundry
  - API Phi Silica pour une inf√©rence NPU efficace
  - APIs de vision par ordinateur pour le traitement d'images et OCR
  - CLI Foundry Local pour le d√©veloppement et les tests locaux

- [**EdgeAI dans NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Performance IA de 67 TOPS dans un format de la taille d'une carte de cr√©dit
  - Support des mod√®les IA g√©n√©ratifs (transformateurs de vision, LLMs, mod√®les vision-langage)
  - Applications en robotique, drones, cam√©ras intelligentes, dispositifs autonomes
  - Plateforme abordable √† 249 $ pour un d√©veloppement IA d√©mocratis√©

- [**EdgeAI dans les applications mobiles avec .NET MAUI et ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - IA mobile multiplateforme avec un code C# unique
  - Support d'acc√©l√©ration mat√©rielle (CPU, GPU, processeurs IA mobiles)
  - Optimisations sp√©cifiques aux plateformes (CoreML pour iOS, NNAPI pour Android)
  - Impl√©mentation compl√®te de la boucle IA g√©n√©rative

- [**EdgeAI dans Azure avec Small Language Models Engine**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architecture de d√©ploiement hybride cloud-edge
  - Int√©gration des services Azure AI avec ONNX Runtime
  - D√©ploiement √† l'√©chelle de l'entreprise et gestion continue des mod√®les
  - Workflows IA hybrides pour le traitement intelligent de documents

- [**EdgeAI avec Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fondation Windows AI Foundry pour une inf√©rence performante sur appareil
  - Support mat√©riel universel (AMD, Intel, NVIDIA, Qualcomm)
  - Abstraction et optimisation mat√©rielle automatique
  - Framework unifi√© pour un √©cosyst√®me mat√©riel diversifi√© sous Windows

- [**EdgeAI avec les applications Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Impl√©mentation RAG ax√©e sur la confidentialit√© avec ressources locales
  - Int√©gration du mod√®le de langage Phi-3 avec recherche s√©mantique (mod√®les Phi uniquement)
  - Support des bases de donn√©es vectorielles locales (SQLite, Qdrant)
  - Capacit√©s de souverainet√© des donn√©es et fonctionnement hors ligne

## Objectifs d'apprentissage du cours

En compl√©tant ce cours complet sur EdgeAI, vous d√©velopperez l'expertise n√©cessaire pour concevoir, impl√©menter et d√©ployer des solutions EdgeAI pr√™tes pour la production. Notre approche structur√©e garantit que vous ma√Ætriserez √† la fois les bases th√©oriques et les comp√©tences pratiques.

### Comp√©tences techniques

**Connaissances fondamentales**
- Comprendre les diff√©rences fondamentales entre les architectures IA bas√©es sur le cloud et celles bas√©es sur l'edge
- Ma√Ætriser les principes de quantification, compression et optimisation des mod√®les pour des environnements √† ressources limit√©es
- Comprendre les options d'acc√©l√©ration mat√©rielle (NPUs, GPUs, CPUs) et leurs implications de d√©ploiement

**Comp√©tences en impl√©mentation**
- D√©ployer des mod√®les de langage de petite taille sur diverses plateformes edge (mobile, embarqu√©, IoT, serveurs edge)
- Appliquer des frameworks d'optimisation tels que Llama.cpp, Microsoft Olive, ONNX Runtime et Apple MLX
- Impl√©menter des syst√®mes d'inf√©rence en temps r√©el avec des exigences de r√©ponse sous la seconde

**Expertise en production**
- Concevoir des architectures EdgeAI √©volutives pour des applications d'entreprise
- Impl√©menter des strat√©gies de surveillance, maintenance et mise √† jour pour les syst√®mes d√©ploy√©s
- Appliquer les meilleures pratiques de s√©curit√© pour des impl√©mentations EdgeAI respectueuses de la confidentialit√©

### Capacit√©s strat√©giques

**Cadre de prise de d√©cision**
- √âvaluer les opportunit√©s EdgeAI et identifier les cas d'utilisation adapt√©s aux applications commerciales
- Analyser les compromis entre pr√©cision des mod√®les, vitesse d'inf√©rence, consommation d'√©nergie et co√ªts mat√©riels
- S√©lectionner les familles et configurations SLM appropri√©es en fonction des contraintes sp√©cifiques de d√©ploiement

**Architecture syst√®me**
- Concevoir des solutions EdgeAI de bout en bout qui s'int√®grent √† l'infrastructure existante
- Planifier des architectures hybrides edge-cloud pour une performance et une efficacit√© des co√ªts optimales
- Impl√©menter des pipelines de flux de donn√©es et de traitement pour des applications IA en temps r√©el

### Applications industrielles

**Sc√©narios de d√©ploiement pratiques**
- **Fabrication** : Syst√®mes de contr√¥le qualit√©, maintenance pr√©dictive et optimisation des processus
- **Sant√©** : Outils de diagnostic respectueux de la confidentialit√© et syst√®mes de surveillance des patients
- **Transport** : Prise de d√©cision pour v√©hicules autonomes et gestion du trafic
- **Villes intelligentes** : Infrastructure intelligente et syst√®mes de gestion des ressources
- **√âlectronique grand public** : Applications mobiles aliment√©es par l'IA et dispositifs domestiques intelligents

## Aper√ßu des r√©sultats d'apprentissage

### R√©sultats d'apprentissage du Module 01 :
- Comprendre les diff√©rences fondamentales entre les architectures IA cloud et edge
- Ma√Ætriser les techniques d'optimisation de base pour le d√©ploiement edge
- Reconna√Ætre les applications concr√®tes et les histoires de r√©ussite
- Acqu√©rir des comp√©tences pratiques pour impl√©menter des solutions EdgeAI

### R√©sultats d'apprentissage du Module 02 :
- Compr√©hension approfondie des diff√©rentes philosophies de conception SLM et de leurs implications de d√©ploiement
- Ma√Ætriser les capacit√©s de prise de d√©cision strat√©gique bas√©es sur les contraintes computationnelles et les exigences de performance
- Comprendre les compromis de flexibilit√© de d√©ploiement
- Poss√©der des perspectives pr√™tes pour l'avenir sur des architectures IA efficaces

### R√©sultats d'apprentissage du Module 03 :
- Capacit√©s strat√©giques de s√©lection de mod√®les
- Ma√Ætrise des techniques d'optimisation
- Ma√Ætrise de la flexibilit√© de d√©ploiement
- Capacit√©s de configuration pr√™tes pour la production

### R√©sultats d'apprentissage du Module 04 :
- Compr√©hension approfondie des limites de quantification et des applications pratiques
- Exp√©rience pratique avec plusieurs frameworks d'optimisation (Llama.cpp, Olive, OpenVINO, MLX)
- Ma√Ætrise de l'optimisation mat√©rielle Intel avec OpenVINO et NNCF
- Capacit√©s de s√©lection d'optimisation adapt√©es au mat√©riel sur diverses plateformes
- Comp√©tences de d√©ploiement en production pour des environnements edge multiplateformes
- Synth√®se strat√©gique des frameworks et workflows pour des solutions Edge AI optimales

### R√©sultats d'apprentissage du Module 05 :
- Ma√Ætriser le paradigme SLMOps et les principes op√©rationnels
- Impl√©menter la distillation de mod√®les pour le transfert de connaissances et l'optimisation de l'efficacit√©
- Appliquer des techniques de fine-tuning pour la personnalisation des mod√®les sp√©cifiques au domaine
- D√©ployer des solutions SLM pr√™tes pour la production avec des strat√©gies de surveillance et de maintenance

### R√©sultats d'apprentissage du Module 06 :
- Comprendre les concepts fondamentaux des agents IA et de l'architecture des mod√®les de langage de petite taille
- Ma√Ætriser la mise en ≈ìuvre des appels de fonctions sur plusieurs plateformes et frameworks
- Int√©grer le protocole de contexte de mod√®le (MCP) pour une interaction standardis√©e avec des outils externes
- Construire des syst√®mes agentiques sophistiqu√©s n√©cessitant une intervention humaine minimale

### R√©sultats d'apprentissage du Module 07 :
- Ma√Ætriser le Toolkit IA pour Visual Studio Code pour des workflows de d√©veloppement Edge AI complets
- Acqu√©rir une expertise sur la plateforme Windows AI Foundry et les strat√©gies d'optimisation NPU
- Acqu√©rir une exp√©rience pratique avec diverses plateformes EdgeAI et strat√©gies d'impl√©mentation
- Ma√Ætriser les techniques d'optimisation sp√©cifiques au mat√©riel sur les plateformes NVIDIA, mobiles, Azure et Windows
- Comprendre les compromis de d√©ploiement entre performance, co√ªt et exigences de confidentialit√©
- D√©velopper des comp√©tences pratiques pour construire des applications EdgeAI concr√®tes sur diff√©rents √©cosyst√®mes

## R√©sultats attendus du cours

√Ä l'issue de ce cours, vous serez √©quip√© des connaissances, comp√©tences et confiance n√©cessaires pour diriger des initiatives EdgeAI dans des environnements professionnels.

### Pr√©paration professionnelle

**Leadership technique**
- **Architecture de solutions** : Concevoir des syst√®mes EdgeAI complets r√©pondant aux exigences des entreprises
- **Optimisation des performances** : Atteindre un √©quilibre optimal entre pr√©cision, vitesse et consommation de ressources
- **D√©ploiement multiplateforme** : Impl√©menter des solutions sur Windows, Linux, mobile et plateformes embarqu√©es
- **Op√©rations de production** : Maintenir et faire √©voluer des syst√®mes EdgeAI avec une fiabilit√© de niveau entreprise

**Expertise industrielle**
- **√âvaluation technologique** : √âvaluer et recommander des solutions EdgeAI pour des d√©fis commerciaux sp√©cifiques
- **Planification de l'impl√©mentation** : D√©velopper des calendriers r√©alistes et des besoins en ressources pour les projets EdgeAI
- **Gestion des risques** : Identifier et att√©nuer les risques techniques et op√©rationnels dans les d√©ploiements EdgeAI
- **Optimisation du ROI** : D√©montrer une valeur commerciale mesurable gr√¢ce aux impl√©mentations EdgeAI

### Opportunit√©s d'avancement professionnel

**R√¥les professionnels**
- Architecte de solutions EdgeAI
- Ing√©nieur en apprentissage machine (sp√©cialisation Edge)
- D√©veloppeur IA IoT
- D√©veloppeur d'applications mobiles IA
- Consultant IA en entreprise

**Secteurs industriels**
- Fabrication intelligente et industrie 4.0
- V√©hicules autonomes et transport
- Technologie de sant√© et dispositifs m√©dicaux
- Technologie financi√®re et s√©curit√©
- √âlectronique grand public et applications mobiles

### Certification et validation

**D√©veloppement de portefeuille**
- R√©aliser des projets EdgeAI de bout en bout d√©montrant une comp√©tence pratique
- D√©ployer des solutions pr√™tes pour la production sur plusieurs plateformes mat√©rielles
- Documenter les strat√©gies d'optimisation et les am√©liorations de performance obtenues

**Chemin d'apprentissage continu**
- Base pour des sp√©cialisations avanc√©es en IA
- Pr√©paration aux architectures hybrides cloud-edge
- Porte d'entr√©e vers les technologies et frameworks IA √©mergents
Ce cours vous place √† l'avant-garde du d√©ploiement des technologies d'IA, o√π des capacit√©s intelligentes sont int√©gr√©es de mani√®re transparente dans les appareils et syst√®mes qui alimentent la vie moderne.

## Diagramme de l'arborescence des fichiers

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.openvino.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.AppleMLX.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.workflow-synthesis.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îú‚îÄ‚îÄ aitoolkit.md
‚îÇ   ‚îú‚îÄ‚îÄ windowdeveloper.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```

## Caract√©ristiques du cours

- **Apprentissage progressif** : Avancez progressivement des concepts de base au d√©ploiement avanc√©
- **Int√©gration th√©orie et pratique** : Chaque module contient des bases th√©oriques et des op√©rations pratiques
- **√âtudes de cas r√©elles** : Bas√©es sur des cas concrets de Microsoft, Alibaba, Google et autres
- **Pratique concr√®te** : Fichiers de configuration complets, proc√©dures de test d'API et scripts de d√©ploiement
- **R√©f√©rentiels de performance** : Comparaisons d√©taill√©es de la vitesse d'inf√©rence, de l'utilisation de la m√©moire et des besoins en ressources
- **Consid√©rations de niveau entreprise** : Pratiques de s√©curit√©, cadres de conformit√© et strat√©gies de protection des donn√©es

## D√©marrage

Parcours d'apprentissage recommand√© :
1. Commencez par **Module01** pour acqu√©rir une compr√©hension fondamentale de l'EdgeAI
2. Passez √† **Module02** pour approfondir les diff√©rentes familles de mod√®les SLM
3. Apprenez **Module03** pour ma√Ætriser les comp√©tences pratiques de d√©ploiement
4. Continuez avec **Module04** pour l'optimisation avanc√©e des mod√®les, la conversion de formats et la synth√®se des frameworks
5. Terminez **Module05** pour ma√Ætriser le SLMOps pour des impl√©mentations pr√™tes √† la production
6. Explorez **Module06** pour comprendre les syst√®mes agentiques SLM et les capacit√©s d'appel de fonctions
7. Achevez avec **Module07** pour acqu√©rir une exp√©rience pratique avec l'AI Toolkit et divers exemples d'impl√©mentation EdgeAI

Chaque module est con√ßu pour √™tre complet ind√©pendamment, mais un apprentissage s√©quentiel offrira les meilleurs r√©sultats.

## Guide d'√©tude

Un [Guide d'√©tude](STUDY_GUIDE.md) complet est disponible pour vous aider √† maximiser votre exp√©rience d'apprentissage. Le guide d'√©tude fournit :

- **Parcours d'apprentissage structur√©s** : Calendriers optimis√©s pour terminer le cours en 20 heures
- **Conseils sur l'allocation du temps** : Recommandations sp√©cifiques pour √©quilibrer lecture, exercices et projets
- **Focus sur les concepts cl√©s** : Objectifs d'apprentissage prioritaires pour chaque module
- **Outils d'auto-√©valuation** : Questions et exercices pour tester votre compr√©hension
- **Id√©es de mini-projets** : Applications pratiques pour renforcer votre apprentissage

Le guide d'√©tude est con√ßu pour s'adapter √† un apprentissage intensif (1 semaine) ou √† un apprentissage √† temps partiel (3 semaines), avec des indications claires sur la mani√®re de r√©partir votre temps efficacement, m√™me si vous ne pouvez consacrer que 10 heures au cours.

---

**L'avenir de l'EdgeAI repose sur l'am√©lioration continue des architectures de mod√®les, des techniques de quantification et des strat√©gies de d√©ploiement qui privil√©gient l'efficacit√© et la sp√©cialisation plut√¥t que des capacit√©s g√©n√©ralistes. Les organisations qui adoptent ce changement de paradigme seront bien positionn√©es pour exploiter le potentiel transformateur de l'IA tout en conservant le contr√¥le sur leurs donn√©es et leurs op√©rations.**

## Autres cours

Notre √©quipe propose d'autres cours ! D√©couvrez :

- [MCP pour d√©butants](https://github.com/microsoft/mcp-for-beginners)
- [Agents IA pour d√©butants](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants avec .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants avec JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
- [ML pour d√©butants](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
- [Science des donn√©es pour d√©butants](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
- [IA pour d√©butants](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
- [Cybers√©curit√© pour d√©butants](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)
- [D√©veloppement web pour d√©butants](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
- [IoT pour d√©butants](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)
- [D√©veloppement XR pour d√©butants](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Ma√Ætriser GitHub Copilot pour la programmation assist√©e par IA](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)
- [Ma√Ætriser GitHub Copilot pour les d√©veloppeurs C#/.NET](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)
- [Choisissez votre propre aventure Copilot](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.