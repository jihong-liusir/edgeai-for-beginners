<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T13:02:54+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "nl"
}
-->
# Sectie 3: Fine-Tuning - Modellen aanpassen voor specifieke taken

## Inhoudsopgave
1. [Introductie tot Fine-Tuning](../../../Module05)
2. [Waarom Fine-Tuning belangrijk is](../../../Module05)
3. [Soorten Fine-Tuning](../../../Module05)
4. [Fine-Tuning met Microsoft Olive](../../../Module05)
5. [Praktische voorbeelden](../../../Module05)
6. [Best practices en richtlijnen](../../../Module05)
7. [Geavanceerde technieken](../../../Module05)
8. [Evaluatie en monitoring](../../../Module05)
9. [Veelvoorkomende uitdagingen en oplossingen](../../../Module05)
10. [Conclusie](../../../Module05)

## Introductie tot Fine-Tuning

**Fine-tuning** is een krachtige machine learning-techniek waarbij een vooraf getraind model wordt aangepast om specifieke taken uit te voeren of met gespecialiseerde datasets te werken. In plaats van een model vanaf nul te trainen, maakt fine-tuning gebruik van de kennis die al is geleerd door een vooraf getraind model en past deze aan voor jouw specifieke toepassing.

### Wat is Fine-Tuning?

Fine-tuning is een vorm van **transfer learning** waarbij je:
- Start met een vooraf getraind model dat algemene patronen heeft geleerd uit grote datasets
- De interne parameters van het model aanpast met jouw specifieke dataset
- De waardevolle kennis behoudt terwijl je het model specialiseert voor jouw taak

Vergelijk het met een ervaren chef die een nieuwe keuken leert koken - ze begrijpen al de basisprincipes van koken, maar moeten specifieke technieken en smaken leren voor de nieuwe stijl.

### Belangrijke voordelen

- **Tijdbesparing**: Veel sneller dan trainen vanaf nul
- **Efficiënt gebruik van data**: Vereist kleinere datasets om goede prestaties te bereiken
- **Kostenbesparend**: Lagere computationale vereisten
- **Betere prestaties**: Vaak superieure resultaten in vergelijking met trainen vanaf nul
- **Optimalisatie van middelen**: Maakt krachtige AI toegankelijk voor kleinere teams en organisaties

## Waarom Fine-Tuning belangrijk is

### Toepassingen in de praktijk

Fine-tuning is essentieel in tal van situaties:

**1. Domeinadaptatie**
- Medische AI: Aanpassen van algemene taalmodellen voor medische terminologie en klinische notities
- Juridische technologie: Specialiseren van modellen voor juridische documentanalyse en contractbeoordeling
- Financiële diensten: Modellen aanpassen voor analyse van financiële rapporten en risicobeoordeling

**2. Taakspecialisatie**
- Contentcreatie: Fine-tuning voor specifieke schrijfstijlen of tonen
- Codegeneratie: Modellen aanpassen voor bepaalde programmeertalen of frameworks
- Vertaling: Prestaties verbeteren voor specifieke taalparen of technische domeinen

**3. Bedrijfstoepassingen**
- Klantenservice: Chatbots creëren die bedrijfsspecifieke terminologie begrijpen
- Interne documentatie: AI-assistenten bouwen die bekend zijn met organisatorische processen
- Sector-specifieke oplossingen: Modellen ontwikkelen die sector-specifieke jargon en workflows begrijpen

## Soorten Fine-Tuning

### 1. Volledige Fine-Tuning (Instruction Fine-Tuning)

Bij volledige fine-tuning worden alle modelparameters bijgewerkt tijdens de training. Deze aanpak:
- Biedt maximale flexibiliteit en prestatiepotentieel
- Vereist aanzienlijke computationale middelen
- Resultaat in een volledig nieuwe versie van het model
- Het beste voor situaties waarin je veel trainingsdata en computationale middelen hebt

### 2. Parameter-efficiënte Fine-Tuning (PEFT)

PEFT-methoden werken slechts een klein deel van de parameters bij, waardoor het proces efficiënter wordt:

#### Low-Rank Adaptation (LoRA)
- Voegt kleine trainbare rank-decompositiematrices toe aan bestaande gewichten
- Vermindert het aantal trainbare parameters aanzienlijk
- Behoudt prestaties die dicht bij volledige fine-tuning liggen
- Maakt eenvoudig schakelen tussen verschillende aanpassingen mogelijk

#### QLoRA (Quantized LoRA)
- Combineert LoRA met kwantiseringstechnieken
- Vermindert geheugenvereisten verder
- Maakt fine-tuning van grotere modellen op consumentenhardware mogelijk
- Balanceert efficiëntie met prestaties

#### Adapters
- Voegt kleine neurale netwerken toe tussen bestaande lagen
- Maakt gerichte fine-tuning mogelijk terwijl het basismodel bevroren blijft
- Biedt een modulaire aanpak voor modelaanpassing

### 3. Taak-specifieke Fine-Tuning

Richt zich op het aanpassen van modellen voor specifieke downstream-taken:
- **Classificatie**: Modellen aanpassen voor categorisatietaken
- **Generatie**: Optimaliseren voor contentcreatie en tekstgeneratie
- **Extractie**: Fine-tuning voor informatie-extractie en named entity recognition
- **Samenvatting**: Modellen specialiseren voor documentensamenvatting

## Fine-Tuning met Microsoft Olive

Microsoft Olive is een uitgebreide toolkit voor modeloptimalisatie die het fine-tuningproces vereenvoudigt en tegelijkertijd functies van ondernemingsniveau biedt.

### Wat is Microsoft Olive?

Microsoft Olive is een open-source modeloptimalisatietool die:
- Fine-tuning workflows stroomlijnt voor verschillende hardwaredoelen
- Ingebouwde ondersteuning biedt voor populaire modelarchitecturen (Llama, Phi, Qwen, Gemma)
- Zowel cloud- als lokale implementatieopties biedt
- Naadloos integreert met Azure ML en andere Microsoft AI-diensten
- Ondersteuning biedt voor automatische optimalisatie en kwantisering

### Belangrijke functies

- **Hardware-bewuste optimalisatie**: Optimaliseert modellen automatisch voor specifieke hardware (CPU, GPU, NPU)
- **Multi-format ondersteuning**: Werkt met PyTorch-, Hugging Face- en ONNX-modellen
- **Geautomatiseerde workflows**: Vermindert handmatige configuratie en trial-and-error
- **Integratie voor ondernemingen**: Ingebouwde ondersteuning voor Azure ML en cloudimplementaties
- **Uitbreidbare architectuur**: Maakt aangepaste optimalisatietechnieken mogelijk

### Installatie en configuratie

#### Basisinstallatie

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### Optionele afhankelijkheden

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### Installatie verifiëren

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## Praktische voorbeelden

### Voorbeeld 1: Basis Fine-Tuning met Olive CLI

Dit voorbeeld demonstreert het fine-tunen van een klein taalmodel voor fraseclassificatie:

#### Stap 1: Bereid je omgeving voor

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### Stap 2: Fine-tune het model

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### Stap 3: Optimaliseer voor implementatie

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### Voorbeeld 2: Geavanceerde configuratie met een aangepaste dataset

#### Stap 1: Bereid aangepaste dataset voor

Maak een JSON-bestand met je trainingsdata:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### Stap 2: Maak configuratiebestand

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### Stap 3: Voer Fine-Tuning uit

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### Voorbeeld 3: QLoRA Fine-Tuning voor geheugenefficiëntie

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## Best practices en richtlijnen

### Datavoorbereiding

**1. Kwaliteit boven kwantiteit**
- Geef prioriteit aan hoogwaardige, diverse voorbeelden boven grote hoeveelheden slechte data
- Zorg ervoor dat data representatief is voor je doeltoepassing
- Reinig en verwerk data consistent

**2. Dataformaat en sjablonen**
- Gebruik consistente opmaak voor alle trainingsvoorbeelden
- Maak duidelijke input-output sjablonen die passen bij je toepassing
- Voeg geschikte instructieopmaak toe voor instructie-getunede modellen

**3. Dataset splitsen**
- Reserveer 10-20% van de data voor validatie
- Zorg voor vergelijkbare verdelingen over train/validatie splitsingen
- Overweeg gestratificeerde steekproeven voor classificatietaken

### Trainingsconfiguratie

**1. Leerraatsselectie**
- Begin met kleinere leerrates (1e-5 tot 1e-4) voor fine-tuning
- Gebruik leerrateplanning voor betere convergentie
- Monitor verliescurves om rates aan te passen

**2. Batchgrootte optimalisatie**
- Balanceer batchgrootte met beschikbare geheugen
- Gebruik gradient accumulation voor grotere effectieve batchgroottes
- Houd rekening met de relatie tussen batchgrootte en leerrate

**3. Trainingsduur**
- Monitor validatiemetrics om overfitting te voorkomen
- Gebruik early stopping wanneer validatieprestaties stabiliseren
- Sla regelmatig checkpoints op voor herstel en analyse

### Modelselectie

**1. Basismodelkeuze**
- Kies modellen die vooraf getraind zijn op vergelijkbare domeinen indien mogelijk
- Houd rekening met de modelgrootte in verhouding tot je computationale beperkingen
- Evalueer licentievereisten voor commercieel gebruik

**2. Fine-Tuning methodekeuze**
- Gebruik LoRA/QLoRA voor omgevingen met beperkte middelen
- Kies volledige fine-tuning wanneer maximale prestaties cruciaal zijn
- Overweeg adapter-gebaseerde benaderingen voor meerdere taaksituaties

### Middelenbeheer

**1. Hardwareoptimalisatie**
- Kies geschikte hardware voor je modelgrootte en methode
- Gebruik GPU-geheugen efficiënt met gradient checkpointing
- Overweeg cloud-gebaseerde oplossingen voor grotere modellen

**2. Geheugenbeheer**
- Gebruik mixed precision training indien beschikbaar
- Implementeer gradient accumulation voor geheugenbeperkingen
- Monitor GPU-geheugengebruik tijdens de training

## Geavanceerde technieken

### Multi-Adapter Training

Train meerdere adapters voor verschillende taken terwijl je het basismodel deelt:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### Hyperparameteroptimalisatie

Voer systematische hyperparameterafstemming uit:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### Aangepaste verliesfuncties

Implementeer domeinspecifieke verliesfuncties:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## Evaluatie en monitoring

### Metrics en evaluatie

**1. Standaardmetrics**
- **Nauwkeurigheid**: Algemene correctheid voor classificatietaken
- **Perplexity**: Kwaliteitsmaat voor taalmodellering
- **BLEU/ROUGE**: Kwaliteit van tekstgeneratie en samenvatting
- **F1 Score**: Gebalanceerde precisie en recall voor classificatie

**2. Domeinspecifieke metrics**
- **Taakspecifieke benchmarks**: Gebruik gevestigde benchmarks voor je domein
- **Menselijke evaluatie**: Neem menselijke beoordeling op voor subjectieve taken
- **Bedrijfsmetrics**: Stem af op daadwerkelijke bedrijfsdoelstellingen

**3. Evaluatie-instelling**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### Monitoring van trainingsvoortgang

**1. Verlies bijhouden**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. Validatie monitoring**
- Houd validatieverlies bij naast trainingsverlies
- Monitor tekenen van overfitting (validatieverlies neemt toe terwijl trainingsverlies afneemt)
- Gebruik early stopping op basis van validatiemetrics

**3. Middelenmonitoring**
- Monitor GPU/CPU-gebruik
- Houd geheugenverbruikspatronen bij
- Monitor trainingssnelheid en doorvoer

## Veelvoorkomende uitdagingen en oplossingen

### Uitdaging 1: Overfitting

**Symptomen:**
- Trainingsverlies blijft afnemen terwijl validatieverlies toeneemt
- Grote kloof tussen trainings- en validatieprestaties
- Slechte generalisatie naar nieuwe data

**Oplossingen:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### Uitdaging 2: Geheugenbeperkingen

**Oplossingen:**
- Gebruik gradient checkpointing
- Implementeer gradient accumulation
- Kies parameter-efficiënte methoden (LoRA, QLoRA)
- Gebruik modelparallelisme voor grote modellen

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### Uitdaging 3: Langzame training

**Oplossingen:**
- Optimaliseer dataloading pipelines
- Gebruik mixed precision training
- Implementeer efficiënte batchingstrategieën
- Overweeg gedistribueerde training voor grote datasets

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### Uitdaging 4: Slechte prestaties

**Diagnosestappen:**
1. Controleer datakwaliteit en opmaak
2. Controleer leerrate en trainingsduur
3. Evalueer basismodelkeuze
4. Bekijk preprocessing en tokenisatie

**Oplossingen:**
- Verhoog diversiteit van trainingsdata
- Pas leerrateplanning aan
- Probeer verschillende basismodellen
- Implementeer data-augmentatietechnieken

## Conclusie

Fine-tuning is een krachtige techniek die toegang tot geavanceerde AI-mogelijkheden democratiseert. Door gebruik te maken van tools zoals Microsoft Olive kunnen organisaties vooraf getrainde modellen efficiënt aanpassen aan hun specifieke behoeften, terwijl ze optimaliseren voor prestaties en middelenbeperkingen.

### Belangrijke inzichten

1. **Kies de juiste aanpak**: Selecteer fine-tuning methoden op basis van je computationale middelen en prestatievereisten
2. **Datakwaliteit is belangrijk**: Investeer in hoogwaardige, representatieve trainingsdata
3. **Monitor en verbeter**: Evalueer en verbeter je modellen continu
4. **Maak gebruik van tools**: Gebruik frameworks zoals Olive om het proces te vereenvoudigen en te optimaliseren
5. **Denk aan implementatie**: Plan vanaf het begin voor modeloptimalisatie en implementatie

## ➡️ Wat is de volgende stap

- [04: Implementatie - Productieklaar model implementeren](./04.SLMOps.Deployment.md)

---

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsservice [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u zich ervan bewust te zijn dat geautomatiseerde vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het originele document in zijn oorspronkelijke taal moet worden beschouwd als de gezaghebbende bron. Voor cruciale informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor eventuele misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.