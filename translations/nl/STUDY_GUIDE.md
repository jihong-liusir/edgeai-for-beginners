<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T21:31:11+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "nl"
}
-->
# EdgeAI voor Beginners: Leertrajecten en Studieplanning

### Intensief Leertraject (1 week)

| Dag | Focus | Geschatte Uren |
|------|-------|------------------|
| Dag 1 | Module 1: EdgeAI Basisprincipes | 3 uur |
| Dag 2 | Module 2: SLM Grondslagen | 3 uur |
| Dag 3 | Module 3: SLM Implementatie | 2 uur |
| Dag 4-5 | Module 4: Modeloptimalisatie (6 frameworks) | 4 uur |
| Dag 6 | Module 5: SLMOps | 3 uur |
| Dag 7 | Module 6-7: AI Agents & Ontwikkeltools | 5 uur |

### Intensief Leertraject (2 weken)

| Dag | Focus | Geschatte Uren |
|------|-------|------------------|
| Dag 1-2 | Module 1: EdgeAI Basisprincipes | 3 uur |
| Dag 3-4 | Module 2: SLM Grondslagen | 3 uur |
| Dag 5-6 | Module 3: SLM Implementatie | 2 uur |
| Dag 7-8 | Module 4: Modeloptimalisatie | 4 uur |
| Dag 9-10 | Module 5: SLMOps | 3 uur |
| Dag 11-12 | Module 6: AI Agents | 2 uur |
| Dag 13-14 | Module 7: Ontwikkeltools | 3 uur |

### Deeltijdstudie (4 weken)

| Week | Focus | Geschatte Uren |
|------|-------|------------------|
| Week 1 | Module 1-2: Basisprincipes & SLM Grondslagen | 6 uur |
| Week 2 | Module 3-4: Implementatie & Optimalisatie | 6 uur |
| Week 3 | Module 5-6: SLMOps & AI Agents | 5 uur |
| Week 4 | Module 7: Ontwikkeltools & Integratie | 3 uur |

| Dag | Focus | Geschatte Uren |
|------|-------|------------------|
| Dag 1-2 | Module 1: EdgeAI Basisprincipes | 3 uur |
| Dag 3-4 | Module 2: SLM Grondslagen | 3 uur |
| Dag 5-6 | Module 3: SLM Implementatie | 2 uur |
| Dag 7-8 | Module 4: Modeloptimalisatie | 4 uur |
| Dag 9-10 | Module 5: SLMOps | 3 uur |
| Dag 11-12 | Module 6: SLM Agentische Systemen | 2 uur |
| Dag 13-14 | Module 7: EdgeAI Implementatievoorbeelden | 2 uur |

| Module | Einddatum | Besteedde Uren | Belangrijke Leerpunten |
|--------|----------------|-------------|--------------|
| Module 1: EdgeAI Basisprincipes | | | |
| Module 2: SLM Grondslagen | | | |
| Module 3: SLM Implementatie | | | |
| Module 4: Modeloptimalisatie (6 frameworks) | | | |
| Module 5: SLMOps | | | |
| Module 6: SLM Agentische Systemen | | | |
| Module 7: EdgeAI Implementatievoorbeelden | | | |
| Praktische Oefeningen | | | |
| Mini-project | | | |

### Deeltijdstudie (4 weken)

| Week | Focus | Geschatte Uren |
|------|-------|------------------|
| Week 1 | Module 1-2: Basisprincipes & SLM Grondslagen | 6 uur |
| Week 2 | Module 3-4: Implementatie & Optimalisatie | 6 uur |
| Week 3 | Module 5-6: SLMOps & AI Agents | 5 uur |
| Week 4 | Module 7: Ontwikkeltools & Integratie | 3 uur |

## Introductie

Welkom bij de EdgeAI voor Beginners studiegids! Dit document is ontworpen om je te helpen de cursusmaterialen effectief te doorlopen en je leerervaring te maximaliseren. Het biedt gestructureerde leertrajecten, voorgestelde studieplanningen, samenvattingen van kernconcepten en aanvullende bronnen om je begrip van EdgeAI-technologieën te verdiepen.

Dit is een compacte cursus van 20 uur die essentiële kennis over EdgeAI biedt in een tijdsefficiënt formaat, ideaal voor drukke professionals en studenten die snel praktische vaardigheden willen opdoen in dit opkomende vakgebied.

## Cursusoverzicht

Deze cursus is georganiseerd in zeven uitgebreide modules:

1. **EdgeAI Basisprincipes en Transformatie** - Begrijp de kernconcepten en technologische verschuiving
2. **Small Language Model Grondslagen** - Verken verschillende SLM-families en hun architecturen
3. **Small Language Model Implementatie** - Praktische implementatiestrategieën
4. **Modelformaatconversie en Kwantisatie** - Geavanceerde optimalisatie met 6 frameworks, waaronder OpenVINO
5. **SLMOps - Small Language Model Operations** - Beheer van de productlevenscyclus en implementatie
6. **SLM Agentische Systemen** - AI-agents, functieaanroepen en Model Context Protocol
7. **EdgeAI Implementatievoorbeelden** - AI Toolkit, Windows-ontwikkeling en platformspecifieke implementaties
8. **Microsoft Foundry Local – Complete Ontwikkeltoolkit** - Lokale ontwikkeling met hybride Azure-integratie (Module 08)

## Hoe gebruik je deze studiegids?

- **Progressief leren**: Volg de modules in volgorde voor de meest samenhangende leerervaring
- **Kenniscontrolepunten**: Gebruik de zelfevaluatievragen na elke sectie
- **Praktische oefeningen**: Voltooi de voorgestelde oefeningen om theoretische concepten te versterken
- **Aanvullende bronnen**: Verken extra materialen voor onderwerpen die je het meest interesseren

## Aanbevolen studieplanning

### Intensief Leertraject (1 week)

| Dag | Focus | Geschatte Uren |
|------|-------|-----------------|
| Dag 1-2 | Module 1: EdgeAI Basisprincipes | 6 uur |
| Dag 3-4 | Module 2: SLM Grondslagen | 8 uur |
| Dag 5 | Module 3: SLM Implementatie | 3 uur |
| Dag 6 | Module 8: Foundry Local Toolkit | 3 uur |

### Deeltijdstudie (3 weken)

| Week | Focus | Geschatte Uren |
|------|-------|-----------------|
| Week 1 | Module 1: EdgeAI Basisprincipes | 6-7 uur |
| Week 2 | Module 2: SLM Grondslagen | 7-8 uur |
| Week 3 | Module 3: SLM Implementatie (3u) + Module 8: Foundry Local Toolkit (2-3u) | 5-6 uur |

## Module 1: EdgeAI Basisprincipes en Transformatie

### Belangrijke Leerdoelen

- Begrijp de verschillen tussen cloud-gebaseerde en edge-gebaseerde AI
- Beheers kernoptimalisatietechnieken voor omgevingen met beperkte middelen
- Analyseer toepassingen van EdgeAI-technologieën in de praktijk
- Stel een ontwikkelomgeving op voor EdgeAI-projecten

### Studie Focusgebieden

#### Sectie 1: EdgeAI Basisprincipes
- **Prioriteitsconcepten**: 
  - Edge versus Cloud computing paradigma's
  - Modelkwantisatietechnieken
  - Hardwareversnellingopties (NPUs, GPUs, CPUs)
  - Privacy- en beveiligingsvoordelen

- **Aanvullende Materialen**:
  - [TensorFlow Lite Documentatie](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Documentatie](https://docs.edgeimpulse.com)

#### Sectie 2: Praktijkvoorbeelden
- **Prioriteitsconcepten**: 
  - Microsoft Phi & Mu model ecosysteem
  - Praktische implementaties in verschillende industrieën
  - Overwegingen bij implementatie

#### Sectie 3: Praktische Implementatiegids
- **Prioriteitsconcepten**: 
  - Ontwikkelomgeving opzetten
  - Kwantisatie- en optimalisatietools
  - Beoordelingsmethoden voor EdgeAI-implementaties

#### Sectie 4: Edge Implementatiehardware
- **Prioriteitsconcepten**: 
  - Vergelijking van hardwareplatforms
  - Optimalisatiestrategieën voor specifieke hardware
  - Overwegingen bij implementatie

### Zelfevaluatievragen

1. Vergelijk en contrasteer cloud-gebaseerde AI met edge-gebaseerde AI-implementaties.
2. Leg drie belangrijke technieken uit voor het optimaliseren van modellen voor edge-implementatie.
3. Wat zijn de belangrijkste voordelen van het uitvoeren van AI-modellen aan de edge?
4. Beschrijf het proces van het kwantiseren van een model en hoe dit de prestaties beïnvloedt.
5. Leg uit hoe verschillende hardwareversnellers (NPUs, GPUs, CPUs) invloed hebben op EdgeAI-implementatie.

### Praktische Oefeningen

1. **Snelle Omgevingsinstelling**: Stel een minimale ontwikkelomgeving in met de essentiële pakketten (30 minuten)
2. **Modelverkenning**: Download en bekijk een vooraf getraind klein taalmodel (1 uur)
3. **Basis Kwantisatie**: Probeer eenvoudige kwantisatie op een klein model (1 uur)

## Module 2: Small Language Model Grondslagen

### Belangrijke Leerdoelen

- Begrijp de architectonische principes van verschillende SLM-families
- Vergelijk modelmogelijkheden op verschillende schaalniveaus
- Evalueer modellen op basis van efficiëntie, capaciteit en implementatievereisten
- Herken geschikte toepassingen voor verschillende modelfamilies

### Studie Focusgebieden

#### Sectie 1: Microsoft Phi Modelfamilie
- **Prioriteitsconcepten**: 
  - Ontwikkeling van ontwerpfilosofie
  - Efficiëntiegerichte architectuur
  - Gespecialiseerde mogelijkheden

#### Sectie 2: Qwen Familie
- **Prioriteitsconcepten**: 
  - Open source bijdragen
  - Schaalbare implementatieopties
  - Geavanceerde redeneerarchitectuur

#### Sectie 3: Gemma Familie
- **Prioriteitsconcepten**: 
  - Onderzoeksgedreven innovatie
  - Multimodale mogelijkheden
  - Optimalisatie voor mobiele apparaten

#### Sectie 4: BitNET Familie
- **Prioriteitsconcepten**: 
  - 1-bit kwantisatietechnologie
  - Optimalisatie voor inferentie
  - Duurzaamheidsoverwegingen

#### Sectie 5: Microsoft Mu Model
- **Prioriteitsconcepten**: 
  - Apparaatgerichte architectuur
  - Systeemintegratie met Windows
  - Privacybeschermende werking

#### Sectie 6: Phi-Silica
- **Prioriteitsconcepten**: 
  - NPU-geoptimaliseerde architectuur
  - Prestatiemetrics
  - Integratie voor ontwikkelaars

### Zelfevaluatievragen

1. Vergelijk de architectonische benaderingen van de Phi- en Qwen-modelfamilies.
2. Leg uit hoe BitNET's kwantisatietechnologie verschilt van traditionele kwantisatie.
3. Wat zijn de unieke voordelen van het Mu-model voor Windows-integratie?
4. Beschrijf hoe Phi-Silica NPU-hardware benut voor prestatieoptimalisatie.
5. Voor een mobiele applicatie met beperkte connectiviteit, welke modelfamilie zou het meest geschikt zijn en waarom?

### Praktische Oefeningen

1. **Modelvergelijking**: Snelle benchmark van twee verschillende SLM-modellen (1 uur)
2. **Eenvoudige Tekstgeneratie**: Basisimplementatie van tekstgeneratie met een klein model (1 uur)
3. **Snelle Optimalisatie**: Pas een optimalisatietechniek toe om de inferentiesnelheid te verbeteren (1 uur)

## Module 3: Small Language Model Implementatie

### Belangrijke Leerdoelen

- Kies geschikte modellen op basis van implementatiebeperkingen
- Beheers optimalisatietechnieken voor verschillende implementatiescenario's
- Implementeer SLM's in zowel lokale als cloudomgevingen
- Ontwerp productieklare configuraties voor EdgeAI-toepassingen

### Studie Focusgebieden

#### Sectie 1: Geavanceerd SLM Leren
- **Prioriteitsconcepten**: 
  - Parametersclassificatiekader
  - Geavanceerde optimalisatietechnieken
  - Modelacquisitiestrategieën

#### Sectie 2: Lokale Omgevingsimplementatie
- **Prioriteitsconcepten**: 
  - Ollama platformimplementatie
  - Microsoft Foundry lokale oplossingen
  - Vergelijkende analyse van frameworks

#### Sectie 3: Gecontaineriseerde Cloudimplementatie
- **Prioriteitsconcepten**: 
  - vLLM hoogpresterende inferentie
  - Containerorkestratie
  - ONNX Runtime implementatie

### Zelfevaluatievragen

1. Welke factoren moeten worden overwogen bij het kiezen tussen lokale implementatie en cloudimplementatie?
2. Vergelijk Ollama en Microsoft Foundry Local als implementatieopties.
3. Leg de voordelen van containerisatie voor SLM-implementatie uit.
4. Wat zijn de belangrijkste prestatiemetrics om te monitoren voor een edge-geïmplementeerde SLM?
5. Beschrijf een complete implementatieworkflow van modelselectie tot productieimplementatie.

### Praktische Oefeningen

1. **Basis Lokale Implementatie**: Implementeer een eenvoudige SLM met Ollama (1 uur)
2. **Prestatiecontrole**: Voer een snelle benchmark uit op je geïmplementeerde model (30 minuten)
3. **Eenvoudige Integratie**: Maak een minimale applicatie die je geïmplementeerde model gebruikt (1 uur)

## Module 4: Modelformaatconversie en Kwantisatie

### Belangrijke Leerdoelen

- Beheers geavanceerde kwantisatietechnieken van 1-bit tot 8-bit precisie
- Begrijp strategieën voor formaatconversie (GGUF, ONNX)
- Implementeer optimalisatie over zes frameworks (Llama.cpp, Olive, OpenVINO, MLX, workflow synthese)
- Implementeer geoptimaliseerde modellen voor productie-edge-omgevingen op Intel, Apple en cross-platform hardware

### Studie Focusgebieden

#### Sectie 1: Grondslagen van Kwantisatie
- **Prioriteitsconcepten**: 
  - Precisieclassificatiekader
  - Prestatie versus nauwkeurigheid afwegingen
  - Geheugenvoetafdrukoptimalisatie

#### Sectie 2: Llama.cpp Implementatie
- **Prioriteitsconcepten**: 
  - Cross-platform implementatie
  - GGUF formaatoptimalisatie
  - Hardwareversnellingstechnieken

#### Sectie 3: Microsoft Olive Suite
- **Prioriteitsconcepten**: 
  - Hardwarebewuste optimalisatie
  - Implementatie op ondernemingsniveau
  - Geautomatiseerde optimalisatieworkflows

#### Sectie 4: OpenVINO Toolkit
- **Prioriteitsconcepten**: 
  - Intel hardwareoptimalisatie
  - Neural Network Compression Framework (NNCF)
  - Cross-platform inferentie-implementatie
  - OpenVINO GenAI voor LLM-implementatie

#### Sectie 5: Apple MLX Framework
- **Prioriteitsconcepten**:  
  - Optimalisatie voor Apple Silicon  
  - Geïntegreerde geheugenarchitectuur  
  - LoRA fine-tuning mogelijkheden  

#### Sectie 6: Synthese van Edge AI Ontwikkelworkflow  
- **Prioriteitsconcepten**:  
  - Geïntegreerde workflowarchitectuur  
  - Beslissingsbomen voor frameworkselectie  
  - Validatie van productiegereedheid  
  - Strategieën voor toekomstbestendigheid  

### Zelfevaluatievragen  

1. Vergelijk kwantisatiestrategieën voor verschillende precisieniveaus (1-bit tot 8-bit).  
2. Leg de voordelen uit van het GGUF-formaat voor edge-deployment.  
3. Hoe verbetert hardware-bewuste optimalisatie in Microsoft Olive de efficiëntie van deployment?  
4. Wat zijn de belangrijkste voordelen van OpenVINO's NNCF voor modelcompressie?  
5. Beschrijf hoe Apple MLX gebruikmaakt van de geïntegreerde geheugenarchitectuur voor optimalisatie.  
6. Hoe helpt workflowsynthese bij het selecteren van optimale optimalisatieframeworks?  

### Praktische oefeningen  

1. **Modelkwantisatie**: Pas verschillende kwantisatieniveaus toe op een model en vergelijk de resultaten (1 uur).  
2. **OpenVINO-optimalisatie**: Gebruik NNCF om een model te comprimeren voor Intel-hardware (1 uur).  
3. **Frameworkvergelijking**: Test hetzelfde model in drie verschillende optimalisatieframeworks (1 uur).  
4. **Prestatiebenchmarking**: Meet de impact van optimalisatie op inferentiesnelheid en geheugengebruik (1 uur).  

## Module 5: SLMOps - Operaties voor Kleine Taalmodellen  

### Belangrijke leerdoelen  

- Begrijp de principes van levenscyclusbeheer binnen SLMOps  
- Beheers distillatie- en fine-tuningtechnieken voor edge-deployment  
- Implementeer strategieën voor productie-deployment met monitoring  
- Bouw workflows voor SLM-operaties en onderhoud op ondernemingsniveau  

### Studiegebieden  

#### Sectie 1: Introductie tot SLMOps  
- **Prioriteitsconcepten**:  
  - Paradigmaverschuiving van SLMOps in AI-operaties  
  - Kostenbesparing en privacygerichte architectuur  
  - Strategische bedrijfsimpact en concurrentievoordelen  

#### Sectie 2: Modeldistillatie  
- **Prioriteitsconcepten**:  
  - Technieken voor kennisoverdracht  
  - Implementatie van een tweefasen-distillatieproces  
  - Distillatieworkflows in Azure ML  

#### Sectie 3: Fine-tuningstrategieën  
- **Prioriteitsconcepten**:  
  - Parameter-efficiënte fine-tuning (PEFT)  
  - Geavanceerde methoden zoals LoRA en QLoRA  
  - Multi-adaptertraining en hyperparameteroptimalisatie  

#### Sectie 4: Productiedeployment  
- **Prioriteitsconcepten**:  
  - Modelconversie en kwantisatie voor productie  
  - Configuratie van Foundry Local deployment  
  - Prestatiebenchmarking en kwaliteitsvalidatie  

### Zelfevaluatievragen  

1. Hoe verschilt SLMOps van traditionele MLOps?  
2. Leg de voordelen uit van modeldistillatie voor edge-deployment.  
3. Wat zijn de belangrijkste overwegingen voor fine-tuning van SLM's in omgevingen met beperkte middelen?  
4. Beschrijf een complete productiedeployment-pijplijn voor edge AI-toepassingen.  

### Praktische oefeningen  

1. **Basisdistillatie**: Maak een kleiner model van een groter teachermodel (1 uur).  
2. **Fine-tuningexperiment**: Fine-tune een model voor een specifiek domein (1 uur).  
3. **Deploymentpijplijn**: Stel een basis CI/CD-pijplijn op voor modeldeployment (1 uur).  

## Module 6: SLM Agentische Systemen - AI-agenten en Functieaanroepen  

### Belangrijke leerdoelen  

- Bouw intelligente AI-agenten voor edge-omgevingen met kleine taalmodellen  
- Implementeer functieaanroepmogelijkheden met systematische workflows  
- Beheers Model Context Protocol (MCP)-integratie voor gestandaardiseerde toolinteractie  
- Creëer geavanceerde agentische systemen met minimale menselijke tussenkomst  

### Studiegebieden  

#### Sectie 1: AI-agenten en SLM-grondslagen  
- **Prioriteitsconcepten**:  
  - Framework voor agentclassificatie (reflex-, modelgebaseerde, doelgebaseerde, lerende agenten)  
  - Analyse van afwegingen tussen SLM en LLM  
  - Ontwerppatronen specifiek voor edge-agenten  
  - Optimalisatie van middelen voor agenten  

#### Sectie 2: Functieaanroepen in kleine taalmodellen  
- **Prioriteitsconcepten**:  
  - Implementatie van systematische workflows (intentieherkenning, JSON-output, externe uitvoering)  
  - Platformspecifieke implementaties (Phi-4-mini, geselecteerde Qwen-modellen, Microsoft Foundry Local)  
  - Geavanceerde voorbeelden (samenwerking tussen meerdere agenten, dynamische toolselectie)  
  - Overwegingen voor productie (rate limiting, audit logging, beveiligingsmaatregelen)  

#### Sectie 3: Model Context Protocol (MCP)-integratie  
- **Prioriteitsconcepten**:  
  - Protocolarchitectuur en gelaagd systeemontwerp  
  - Ondersteuning voor meerdere backends (Ollama voor ontwikkeling, vLLM voor productie)  
  - Verbindingsprotocollen (STDIO- en SSE-modi)  
  - Toepassingen in de praktijk (webautomatisering, gegevensverwerking, API-integratie)  

### Zelfevaluatievragen  

1. Wat zijn de belangrijkste architecturale overwegingen voor edge AI-agenten?  
2. Hoe verbeteren functieaanroepen de mogelijkheden van agenten?  
3. Leg de rol van Model Context Protocol uit in agentcommunicatie.  

### Praktische oefeningen  

1. **Eenvoudige agent**: Bouw een basis AI-agent met functieaanroepen (1 uur).  
2. **MCP-integratie**: Implementeer MCP in een agenttoepassing (30 minuten).  

## Module 7: EdgeAI Implementatievoorbeelden  

### Belangrijke leerdoelen  

- Beheers AI Toolkit voor Visual Studio Code voor uitgebreide EdgeAI-ontwikkelworkflows  
- Verkrijg expertise in het Windows AI Foundry-platform en NPU-optimalisatiestrategieën  
- Implementeer EdgeAI op meerdere hardwareplatforms en deploymentscenario's  
- Bouw productieklare EdgeAI-toepassingen met platformspecifieke optimalisaties  

### Studiegebieden  

#### Sectie 1: AI Toolkit voor Visual Studio Code  
- **Prioriteitsconcepten**:  
  - Uitgebreide Edge AI-ontwikkelomgeving binnen VS Code  
  - Modelcatalogus en ontdekking voor edge-deployment  
  - Lokale test-, optimalisatie- en agentontwikkelworkflows  
  - Prestatiemonitoring en evaluatie voor edge-scenario's  

#### Sectie 2: Windows EdgeAI Ontwikkelgids  
- **Prioriteitsconcepten**:  
  - Overzicht van het Windows AI Foundry-platform  
  - Phi Silica API voor efficiënte NPU-inferentie  
  - Computer Vision API's voor beeldverwerking en OCR  
  - Foundry Local CLI voor lokale ontwikkeling en testen  

#### Sectie 3: Platformspecifieke implementaties  
- **Prioriteitsconcepten**:  
  - NVIDIA Jetson Orin Nano deployment (67 TOPS AI-prestaties)  
  - Mobiele toepassingen met .NET MAUI en ONNX Runtime GenAI  
  - Azure EdgeAI-oplossingen met cloud-edge hybride architectuur  
  - Windows ML-optimalisatie met universele hardwareondersteuning  
  - Foundry Local-toepassingen met privacygerichte RAG-implementatie  

### Zelfevaluatievragen  

1. Hoe stroomlijnt AI Toolkit de EdgeAI-ontwikkelworkflow?  
2. Vergelijk deploymentstrategieën op verschillende hardwareplatforms.  
3. Wat zijn de voordelen van Windows AI Foundry voor edge-ontwikkeling?  
4. Leg de rol van NPU-optimalisatie uit in moderne EdgeAI-toepassingen.  
5. Hoe benut de Phi Silica API NPU-hardware voor prestatieoptimalisatie?  
6. Vergelijk de voordelen van lokale versus cloud-deployment voor privacygevoelige toepassingen.  

### Praktische oefeningen  

1. **AI Toolkit Setup**: Configureer AI Toolkit en optimaliseer een model (1 uur).  
2. **Windows AI Foundry**: Bouw een eenvoudige Windows AI-toepassing met Phi Silica API (1 uur).  
3. **Cross-platform deployment**: Deploy hetzelfde model op twee verschillende platforms (1 uur).  
4. **NPU-optimalisatie**: Test NPU-prestaties met Windows AI Foundry-tools (30 minuten).  

## Module 8: Microsoft Foundry Local – Complete ontwikkeltoolkit  

### Belangrijke leerdoelen  

- Installeer en configureer Foundry Local op Windows  
- Voer modellen lokaal uit, ontdek en beheer ze via de Foundry CLI  
- Integreer met OpenAI-compatibele REST- en SDK-clients  
- Bouw praktische voorbeelden: Chainlit-chat, agenten en modelrouter  
- Begrijp hybride patronen met Azure AI Foundry  

### Studiegebieden  

- Installatie en CLI-essentials (model, service, cache)  
- SDK-integratie (OpenAI-compatibele clients en Azure OpenAI)  
- Snelle validatie via Open WebUI  
- Patronen voor agenten en functieaanroepen  
- Modellen-als-tools (ontwerp van router en register)  

### Zelfevaluatievragen  

1. Hoe ontdek je de lokale endpoint en lijst je beschikbare modellen op?  
2. Wat zijn de verschillen tussen Foundry Local REST en Azure OpenAI-gebruik?  
3. Hoe zou je een eenvoudige router ontwerpen om modellen als tools te selecteren?  
4. Welke CLI-categorieën zijn het meest relevant voor dagelijkse ontwikkeling?  
5. Hoe valideer je de gereedheid van Foundry Local voordat je apps uitvoert?  

### Praktische oefeningen  

1. Installeer/upgrade Foundry Local en voer `phi-4-mini` lokaal uit (30 minuten).  
2. Roep `/v1/models` aan en voer een eenvoudige chat uit via REST (30 minuten).  
3. Start het Chainlit-appvoorbeeld en chat lokaal (30 minuten).  
4. Voer de coördinator voor meerdere agenten uit en inspecteer de outputs (30 minuten).  
5. Probeer de router voor modellen-als-tools met omgevingsgebaseerde overrides (30 minuten).  

## Tijdindelingsgids  

Om het meeste uit de 20 uur durende cursus te halen, is hier een voorgestelde tijdsindeling:  

| Activiteit | Tijdindeling | Beschrijving |  
|------------|--------------|--------------|  
| Kernmateriaal lezen | 9 uur | Focus op de essentiële concepten in elke module |  
| Praktische oefeningen | 6 uur | Praktische implementatie van belangrijke technieken |  
| Zelfevaluatie | 2 uur | Test je begrip via vragen en reflectie |  
| Mini-project | 3 uur | Pas kennis toe in een kleine praktische implementatie |  

### Belangrijke focusgebieden bij tijdsbeperkingen  

**Als je slechts 10 uur hebt:**  
- Voltooi Modules 1, 2 en 3 (kernconcepten van EdgeAI).  
- Doe minstens één praktische oefening per module.  
- Focus op het begrijpen van de kernconcepten in plaats van implementatiedetails.  

**Als je de volledige 20 uur kunt besteden:**  
- Voltooi alle zeven modules.  
- Voer belangrijke praktische oefeningen uit van elke module.  
- Voltooi één mini-project uit Module 7.  
- Verken minstens 2-3 aanvullende bronnen.  

**Als je meer dan 20 uur hebt:**  
- Voltooi alle modules met gedetailleerde oefeningen.  
- Bouw meerdere mini-projecten.  
- Verken geavanceerde optimalisatietechnieken in Module 4.  
- Implementeer productie-deployment vanuit Module 5.  

## Essentiële bronnen  

Deze zorgvuldig geselecteerde bronnen bieden de meeste waarde voor je beperkte studietijd:  

### Must-read documentatie  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Het meest efficiënte modeloptimalisatie-tool  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Snelste manier om SLM's lokaal te deployen  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Referentie voor een toonaangevend edge-geoptimaliseerd model  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Intel's uitgebreide optimalisatietoolkit  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Geïntegreerde EdgeAI-ontwikkelomgeving  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specifiek EdgeAI-ontwikkelplatform  

### Tijdbesparende tools  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Snelle toegang tot en deployment van modellen  
- [Gradio](https://www.gradio.app/docs/interface) - Snelle UI-ontwikkeling voor AI-demo's  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Vereenvoudigde modeloptimalisatie  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Efficiënte CPU-inferentie  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Framework voor compressie van neurale netwerken  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit voor deployment van grote taalmodellen  

## Voortgangsvolgsjabloon  

Gebruik deze vereenvoudigde sjabloon om je leerproces door de 20 uur durende cursus te volgen:  

| Module | Voltooiingsdatum | Besteedde uren | Belangrijkste inzichten |  
|--------|------------------|----------------|--------------------------|  
| Module 1: EdgeAI Fundamentals | | | |  
| Module 2: SLM Foundations | | | |  
| Module 3: SLM Deployment | | | |  
| Module 4: Model Optimization | | | |  
| Module 5: SLMOps | | | |  
| Module 6: AI Agents | | | |  
| Module 7: Development Tools | | | |  
| Module 8: Foundry Local Toolkit | | | |  
| Praktische oefeningen | | | |  
| Mini-project | | | |  

## Mini-projectideeën  

Overweeg een van deze projecten te voltooien om EdgeAI-concepten te oefenen (elk ontworpen om 2-4 uur te duren):  

### Beginnersprojecten (2-3 uur elk)  
1. **Edge Tekstassistent**: Maak een eenvoudige offline tekstaanvultool met een klein taalmodel.  
2. **Dashboard voor modelvergelijking**: Bouw een basisvisualisatie van prestatiemetrics voor verschillende SLM's.  
3. **Optimalisatie-experiment**: Meet de impact van verschillende kwantisatieniveaus op hetzelfde basismodel.  

### Intermediaire projecten (3-4 uur elk)  
4. **AI Toolkit Workflow**: Gebruik VS Code AI Toolkit om een model van begin tot eind te optimaliseren en te deployen.  
5. **Windows AI Foundry-toepassing**: Maak een Windows-app met Phi Silica API en NPU-optimalisatie.  
6. **Cross-platform deployment**: Deploy hetzelfde geoptimaliseerde model op Windows (OpenVINO) en mobiel (.NET MAUI).  
7. **Functieaanroepagent**: Bouw een AI-agent met functieaanroepmogelijkheden voor edge-scenario's.  

### Geavanceerde integratieprojecten (4-5 uur elk)  
8. **OpenVINO Optimalisatiepijplijn**: Voer volledige modeloptimalisatie uit met behulp van NNCF en GenAI toolkit  
9. **SLMOps Pijplijn**: Implementeer een complete modellevenscyclus van training tot edge-implementatie  
10. **Multi-Model Edge Systeem**: Implementeer meerdere gespecialiseerde modellen die samenwerken op edge-hardware  
11. **MCP Integratiesysteem**: Bouw een agentisch systeem met behulp van Model Context Protocol voor toolinteractie  

## Referenties

- Microsoft Learn (Foundry Local)  
  - Overzicht: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Aan de slag: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI-referentie: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integreren met inference SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI how-to: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Hugging Face-modellen compileren: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Overzicht: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agents (overzicht): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimalisatie- en inference-tools  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (aan de slag): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive-integratie: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Implementatiekaders en modellen  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (quick start): https://github.com/ollama/ollama#get-started  
- Ontwikkelaarstools (Windows en VS Code)  
  - AI Toolkit voor VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (overzicht): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Leercommunity

Doe mee aan de discussie en kom in contact met medeleerlingen:  
- GitHub Discussions op de [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Conclusie

EdgeAI vertegenwoordigt de voorhoede van kunstmatige intelligentie-implementatie, waarbij krachtige mogelijkheden direct naar apparaten worden gebracht en tegelijkertijd belangrijke zorgen over privacy, latentie en connectiviteit worden aangepakt. Deze cursus van 20 uur biedt je de essentiële kennis en praktische vaardigheden om direct aan de slag te gaan met EdgeAI-technologieën.

De cursus is bewust beknopt en gericht op de belangrijkste concepten, zodat je snel waardevolle expertise kunt opdoen zonder een overweldigende tijdsinvestering. Onthoud dat praktijkervaring, zelfs met eenvoudige voorbeelden, de sleutel is tot het versterken van wat je hebt geleerd.

Veel leerplezier!

---

