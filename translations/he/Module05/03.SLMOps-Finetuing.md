<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T13:03:31+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "he"
}
-->
# סעיף 3: התאמה אישית - התאמת מודלים למשימות ספציפיות

## תוכן עניינים
1. [מבוא להתאמה אישית](../../../Module05)
2. [למה התאמה אישית חשובה](../../../Module05)
3. [סוגי התאמה אישית](../../../Module05)
4. [התאמה אישית עם Microsoft Olive](../../../Module05)
5. [דוגמאות מעשיות](../../../Module05)
6. [שיטות עבודה מומלצות והנחיות](../../../Module05)
7. [טכניקות מתקדמות](../../../Module05)
8. [הערכה ומעקב](../../../Module05)
9. [אתגרים נפוצים ופתרונות](../../../Module05)
10. [סיכום](../../../Module05)

## מבוא להתאמה אישית

**התאמה אישית** היא טכניקת למידת מכונה חזקה שמאפשרת להתאים מודל מאומן מראש לביצוע משימות ספציפיות או לעבודה עם מערכי נתונים ייחודיים. במקום לאמן מודל מאפס, התאמה אישית מנצלת את הידע שכבר נלמד על ידי מודל מאומן מראש ומכווננת אותו לשימוש המיוחד שלך.

### מהי התאמה אישית?

התאמה אישית היא סוג של **למידת העברה** שבה:
- מתחילים עם מודל מאומן מראש שלמד דפוסים כלליים ממערכי נתונים גדולים
- מכווננים את הפרמטרים הפנימיים של המודל באמצעות מערך הנתונים הספציפי שלך
- שומרים על הידע החשוב תוך התאמת המודל למשימה שלך

חשבו על זה כמו ללמד שף מיומן לבשל מטבח חדש - הוא כבר מבין את יסודות הבישול, אבל צריך ללמוד טכניקות וטעמים ספציפיים לסגנון החדש.

### יתרונות מרכזיים

- **יעילות בזמן**: מהיר משמעותית מאימון מאפס
- **יעילות נתונים**: דורש מערכי נתונים קטנים יותר כדי להגיע לביצועים טובים
- **חסכוני**: דרישות חישוביות נמוכות יותר
- **ביצועים טובים יותר**: לעיתים קרובות משיג תוצאות טובות יותר מאימון מאפס
- **אופטימיזציה של משאבים**: הופך AI חזק לנגיש לצוותים וארגונים קטנים יותר

## למה התאמה אישית חשובה

### יישומים בעולם האמיתי

התאמה אישית חיונית במגוון תרחישים:

**1. התאמה לתחום**
- AI רפואי: התאמת מודלים לשפה כללית למונחים רפואיים והערות קליניות
- טכנולוגיה משפטית: התאמת מודלים לניתוח מסמכים משפטיים ובדיקת חוזים
- שירותים פיננסיים: התאמת מודלים לניתוח דוחות פיננסיים והערכת סיכונים

**2. התמחות במשימה**
- יצירת תוכן: התאמה אישית לסגנונות כתיבה או טונים ספציפיים
- יצירת קוד: התאמת מודלים לשפות תכנות או מסגרות מסוימות
- תרגום: שיפור ביצועים לזוגות שפות ספציפיים או תחומים טכניים

**3. יישומים ארגוניים**
- שירות לקוחות: יצירת צ'אטבוטים שמבינים טרמינולוגיה ספציפית לחברה
- תיעוד פנימי: בניית עוזרי AI שמכירים תהליכים ארגוניים
- פתרונות ספציפיים לתעשייה: פיתוח מודלים שמבינים ז'רגון ותהליכי עבודה ייחודיים לתחום

## סוגי התאמה אישית

### 1. התאמה אישית מלאה (Instruction Fine-Tuning)

בהתאמה אישית מלאה, כל פרמטרי המודל מתעדכנים במהלך האימון. גישה זו:
- מספקת גמישות מקסימלית ופוטנציאל ביצועים גבוה
- דורשת משאבים חישוביים משמעותיים
- יוצרת גרסה חדשה לחלוטין של המודל
- מתאימה לתרחישים שבהם יש לך נתוני אימון רבים ומשאבים חישוביים

### 2. התאמה אישית יעילה בפרמטרים (PEFT)

שיטות PEFT מעדכנות רק תת-קבוצה קטנה של פרמטרים, מה שהופך את התהליך ליעיל יותר:

#### Low-Rank Adaptation (LoRA)
- מוסיפה מטריצות פירוק דרגה קטנה הניתנות לאימון למשקלים קיימים
- מפחיתה באופן דרמטי את מספר הפרמטרים הניתנים לאימון
- שומרת על ביצועים קרובים להתאמה אישית מלאה
- מאפשרת מעבר קל בין התאמות שונות

#### QLoRA (Quantized LoRA)
- משלבת LoRA עם טכניקות כימות
- מפחיתה עוד יותר את דרישות הזיכרון
- מאפשרת התאמה אישית של מודלים גדולים על חומרת צרכנים
- מאזנת בין יעילות לביצועים

#### Adapters
- מכניסה רשתות עצביות קטנות בין שכבות קיימות
- מאפשרת התאמה אישית ממוקדת תוך שמירה על המודל הבסיסי קפוא
- מאפשרת גישה מודולרית להתאמת מודלים

### 3. התאמה אישית למשימה ספציפית

מתמקדת בהתאמת מודלים למשימות ספציפיות:
- **סיווג**: התאמת מודלים למשימות קטלוג
- **יצירה**: אופטימיזציה ליצירת תוכן ויצירת טקסט
- **חילוץ**: התאמה אישית לחילוץ מידע וזיהוי ישויות
- **סיכום**: התמחות מודלים לסיכום מסמכים

## התאמה אישית עם Microsoft Olive

Microsoft Olive הוא כלי אופטימיזציה מקיף למודלים שמפשט את תהליך ההתאמה האישית תוך מתן תכונות ברמה ארגונית.

### מהו Microsoft Olive?

Microsoft Olive הוא כלי אופטימיזציה קוד פתוח שמאפשר:
- פישוט תהליכי התאמה אישית למגוון יעדי חומרה
- תמיכה מובנית בארכיטקטורות מודלים פופולריות (Llama, Phi, Qwen, Gemma)
- אפשרויות פריסה בענן ובמקומי
- אינטגרציה חלקה עם Azure ML ושירותי AI אחרים של Microsoft
- תמיכה באופטימיזציה וכימות אוטומטיים

### תכונות מרכזיות

- **אופטימיזציה מודעת חומרה**: אופטימיזציה אוטומטית של מודלים ליעדי חומרה ספציפיים (CPU, GPU, NPU)
- **תמיכה רב-פורמטית**: עובד עם מודלים של PyTorch, Hugging Face ו-ONNX
- **תהליכים אוטומטיים**: מפחית את הצורך בקונפיגורציה ידנית וניסוי וטעייה
- **אינטגרציה ארגונית**: תמיכה מובנית ב-Azure ML ובפריסות ענן
- **ארכיטקטורה ניתנת להרחבה**: מאפשרת טכניקות אופטימיזציה מותאמות אישית

### התקנה והגדרה

#### התקנה בסיסית

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### תלות אופציונלית

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### אימות התקנה

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## דוגמאות מעשיות

### דוגמה 1: התאמה אישית בסיסית עם Olive CLI

דוגמה זו מדגימה התאמה אישית של מודל שפה קטן לסיווג ביטויים:

#### שלב 1: הכנת הסביבה

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### שלב 2: התאמת המודל

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### שלב 3: אופטימיזציה לפריסה

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### דוגמה 2: קונפיגורציה מתקדמת עם מערך נתונים מותאם אישית

#### שלב 1: הכנת מערך נתונים מותאם אישית

צרו קובץ JSON עם נתוני האימון שלכם:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### שלב 2: יצירת קובץ קונפיגורציה

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### שלב 3: ביצוע התאמה אישית

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### דוגמה 3: התאמה אישית עם QLoRA ליעילות בזיכרון

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## שיטות עבודה מומלצות והנחיות

### הכנת נתונים

**1. איכות נתונים על פני כמות**
- תעדפו דוגמאות איכותיות ומגוונות על פני כמויות גדולות של נתונים באיכות נמוכה
- ודאו שהנתונים מייצגים את המקרה השימוש שלכם
- נקו ועבדו את הנתונים באופן עקבי

**2. פורמט נתונים ותבניות**
- השתמשו בפורמט עקבי בכל דוגמאות האימון
- צרו תבניות קלט-פלט ברורות שמתאימות למקרה השימוש שלכם
- כללו פורמט הוראות מתאים למודלים מותאמים להוראות

**3. חלוקת מערך נתונים**
- שמרו 10-20% מהנתונים לאימות
- שמרו על התפלגויות דומות בין חלוקות האימון והאימות
- שקלו דגימה שכבתית למשימות סיווג

### קונפיגורציית אימון

**1. בחירת קצב למידה**
- התחילו עם קצבי למידה קטנים (1e-5 עד 1e-4) להתאמה אישית
- השתמשו בתזמון קצב למידה להתכנסות טובה יותר
- עקבו אחר עקומות אובדן כדי להתאים את הקצב בהתאם

**2. אופטימיזציית גודל אצווה**
- איזנו בין גודל אצווה לזיכרון זמין
- השתמשו בצבירת גרדיאנט לגודל אצווה אפקטיבי גדול יותר
- שקלו את הקשר בין גודל אצווה לקצב למידה

**3. משך האימון**
- עקבו אחר מדדי אימות כדי להימנע מהתאמת יתר
- השתמשו בעצירה מוקדמת כאשר ביצועי האימות מתייצבים
- שמרו נקודות בדיקה באופן קבוע לשחזור וניתוח

### בחירת מודל

**1. בחירת מודל בסיס**
- בחרו מודלים שאומנו מראש על תחומים דומים כשאפשר
- שקלו את גודל המודל ביחס למגבלות החישוביות שלכם
- העריכו דרישות רישוי לשימוש מסחרי

**2. בחירת שיטת התאמה אישית**
- השתמשו ב-LoRA/QLoRA לסביבות עם מגבלות משאבים
- בחרו התאמה אישית מלאה כאשר ביצועים מקסימליים קריטיים
- שקלו גישות מבוססות Adapters לתרחישים עם משימות מרובות

### ניהול משאבים

**1. אופטימיזציית חומרה**
- בחרו חומרה מתאימה לגודל המודל והשיטה שלכם
- נצלו זיכרון GPU ביעילות עם בדיקת גרדיאנט
- שקלו פתרונות מבוססי ענן למודלים גדולים יותר

**2. ניהול זיכרון**
- השתמשו באימון דיוק מעורב כשאפשר
- יישמו צבירת גרדיאנט למגבלות זיכרון
- עקבו אחר שימוש בזיכרון GPU לאורך האימון

## טכניקות מתקדמות

### אימון רב-Adapters

אימנו מספר Adapters למשימות שונות תוך שיתוף המודל הבסיסי:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### אופטימיזציית היפרפרמטרים

יישמו כוונון היפרפרמטרים שיטתי:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### פונקציות אובדן מותאמות אישית

יישמו פונקציות אובדן ספציפיות לתחום:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## הערכה ומעקב

### מדדים והערכה

**1. מדדים סטנדרטיים**
- **דיוק**: נכונות כללית למשימות סיווג
- **Perplexity**: מדד איכות למידת שפה
- **BLEU/ROUGE**: איכות יצירת טקסט וסיכום
- **F1 Score**: איזון בין דיוק ושליפה למשימות סיווג

**2. מדדים ספציפיים לתחום**
- **מדדי משימה ספציפיים**: השתמשו במדדים מבוססים לתחום שלכם
- **הערכה אנושית**: כללו הערכה אנושית למשימות סובייקטיביות
- **מדדי עסק**: התאימו למטרות עסקיות בפועל

**3. הגדרת הערכה**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### מעקב אחר התקדמות האימון

**1. מעקב אחר אובדן**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. מעקב אחר אימות**
- עקבו אחר אובדן אימות לצד אובדן אימון
- עקבו אחר סימני התאמת יתר (אובדן אימות עולה בזמן שאובדן אימון יורד)
- השתמשו בעצירה מוקדמת בהתבסס על מדדי אימות

**3. מעקב אחר משאבים**
- עקבו אחר ניצול GPU/CPU
- עקבו אחר דפוסי שימוש בזיכרון
- עקבו אחר מהירות האימון ותפוקה

## אתגרים נפוצים ופתרונות

### אתגר 1: התאמת יתר

**תסמינים:**
- אובדן אימון ממשיך לרדת בזמן שאובדן אימות עולה
- פער גדול בין ביצועי אימון לאימות
- ביצועים ירודים על נתונים חדשים

**פתרונות:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### אתגר 2: מגבלות זיכרון

**פתרונות:**
- השתמשו בבדיקת גרדיאנט
- יישמו צבירת גרדיאנט
- בחרו שיטות יעילות בפרמטרים (LoRA, QLoRA)
- השתמשו בפרלליזם מודלים למודלים גדולים

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### אתגר 3: אימון איטי

**פתרונות:**
- אופטימיזציית צינורות טעינת נתונים
- השתמשו באימון דיוק מעורב
- יישמו אסטרטגיות אצווה יעילות
- שקלו אימון מבוזר למערכי נתונים גדולים

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### אתגר 4: ביצועים ירודים

**שלבי אבחון:**
1. אימות איכות ופורמט נתונים
2. בדיקת קצב למידה ומשך אימון
3. הערכת בחירת מודל בסיס
4. סקירת עיבוד מקדים וטוקניזציה

**פתרונות:**
- הגדלת מגוון נתוני האימון
- התאמת תזמון קצב למידה
- ניסוי מודלים בסיסיים שונים
- יישום טכניקות העשרת נתונים

## סיכום

התאמה אישית היא טכניקה חזקה שמנגישה יכולות AI מתקדמות. באמצעות כלים כמו Microsoft Olive, ארגונים יכולים להתאים ביעילות מודלים מאומנים מראש לצרכים הספציפיים שלהם תוך אופטימיזציה לביצועים ומגבלות משאבים.

### נקודות מפתח

1. **בחרו את הגישה הנכונה**: בחרו שיטות התאמה אישית בהתאם למשאבים החישוביים ולדרישות הביצועים שלכם
2. **איכות נתונים חשובה**: השקיעו בנתוני אימון איכותיים ומייצגים
3. **עקבו ושפרו**: העריכו ושפרו את המודלים שלכם באופן מתמיד
4. **נצלו כלים**: השתמשו במסגרות כמו Olive לפישוט ואופטימיזציה של התהליך
5. **שקלו פריסה**: תכננו אופטימיזציה ופריסה של מודלים מההתחלה

## ➡️ מה הלאה

- [04: פריסה - יישום מודלים מוכנים לייצור](./04.SLMOps.Deployment.md)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו אחראים לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.