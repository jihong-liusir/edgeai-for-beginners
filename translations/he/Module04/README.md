<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c0cb9f7bcff2bc170532d8870a891f38",
  "translation_date": "2025-09-18T12:44:30+00:00",
  "source_file": "Module04/README.md",
  "language_code": "he"
}
-->
# פרק 04: המרת פורמט מודל וכימות - סקירת הפרק

הופעת EdgeAI הפכה את המרת פורמט המודל וכימות לטכנולוגיות חיוניות לפריסת יכולות למידת מכונה מתקדמות על מכשירים עם משאבים מוגבלים. פרק מקיף זה מספק מדריך מלא להבנה, יישום ואופטימיזציה של מודלים לתרחישי פריסה בקצה.

## 📚 מבנה הפרק ונתיב הלמידה

הפרק מחולק לשישה חלקים מתקדמים, שכל אחד מהם מתבסס על הקודם כדי ליצור הבנה מקיפה של אופטימיזציית מודלים למחשוב בקצה:

---

## [חלק 1: יסודות המרת פורמט מודל וכימות](./01.Introduce.md)

### 🎯 סקירה כללית
חלק יסודי זה מבסס את המסגרת התיאורטית לאופטימיזציית מודלים בסביבות מחשוב בקצה, תוך כיסוי גבולות כימות מרמת דיוק של 1 ביט ועד 8 ביט ואסטרטגיות מרכזיות להמרת פורמטים.

**נושאים מרכזיים:**
- מסגרת סיווג דיוק (דיוק נמוך מאוד, נמוך, בינוני)
- יתרונות ושימושים של פורמטים GGUF ו-ONNX
- יתרונות הכימות ליעילות תפעולית וגמישות בפריסה
- השוואות ביצועים וטביעת זיכרון

**תוצאות למידה:**
- הבנת גבולות וסיווגי כימות
- זיהוי טכניקות מתאימות להמרת פורמטים
- למידת אסטרטגיות אופטימיזציה מתקדמות לפריסה בקצה

---

## [חלק 2: מדריך יישום Llama.cpp](./02.Llamacpp.md)

### 🎯 סקירה כללית
מדריך מקיף ליישום Llama.cpp, מסגרת C++ חזקה המאפשרת הסקת מודלים של שפה גדולה ביעילות עם הגדרות מינימליות על פני תצורות חומרה מגוונות.

**נושאים מרכזיים:**
- התקנה על פלטפורמות Windows, macOS ו-Linux
- המרת פורמט GGUF ורמות כימות שונות (Q2_K עד Q8_0)
- האצת חומרה עם CUDA, Metal, OpenCL ו-Vulkan
- אינטגרציה עם Python ואסטרטגיות פריסה בייצור

**תוצאות למידה:**
- שליטה בהתקנה חוצת פלטפורמות ובנייה מקוד מקור
- יישום טכניקות כימות ואופטימיזציה של מודלים
- פריסת מודלים במצב שרת עם אינטגרציה של REST API

---

## [חלק 3: Microsoft Olive Optimization Suite](./03.MicrosoftOlive.md)

### 🎯 סקירה כללית
חקירה של Microsoft Olive, ערכת כלים לאופטימיזציית מודלים מודעת לחומרה עם יותר מ-40 רכיבי אופטימיזציה מובנים, המיועדת לפריסת מודלים ברמה ארגונית על פני פלטפורמות חומרה מגוונות.

**נושאים מרכזיים:**
- תכונות אוטומטיות לאופטימיזציה עם כימות דינמי וסטטי
- אינטליגנציה מודעת לחומרה לפריסה על CPU, GPU ו-NPU
- תמיכה מובנית במודלים פופולריים (Llama, Phi, Qwen, Gemma)
- אינטגרציה ארגונית עם Azure ML וזרימות עבודה בייצור

**תוצאות למידה:**
- ניצול אופטימיזציה אוטומטית למגוון ארכיטקטורות מודלים
- יישום אסטרטגיות פריסה חוצות פלטפורמות
- הקמת צינורות אופטימיזציה מוכנים לארגונים

---

## [חלק 4: ערכת הכלים OpenVINO Toolkit](./04.openvino.md)

### 🎯 סקירה כללית
חקירה מקיפה של ערכת הכלים OpenVINO של אינטל, פלטפורמת קוד פתוח לפריסת פתרונות AI ביצועים גבוהים בענן, באתר ובסביבות קצה עם יכולות מתקדמות של Neural Network Compression Framework (NNCF).

**נושאים מרכזיים:**
- פריסה חוצת פלטפורמות עם האצת חומרה (CPU, GPU, VPU, מאיצי AI)
- Neural Network Compression Framework (NNCF) לכימות מתקדם וגיזום
- OpenVINO GenAI לאופטימיזציה ופריסת מודלים של שפה גדולה
- יכולות שרת מודלים ברמה ארגונית ואסטרטגיות פריסה בקנה מידה גדול

**תוצאות למידה:**
- שליטה בתהליכי המרת מודלים ואופטימיזציה עם OpenVINO
- יישום טכניקות כימות מתקדמות עם NNCF
- פריסת מודלים אופטימליים על פני פלטפורמות חומרה מגוונות עם Model Server

---

## [חלק 5: סקירה מעמיקה של Apple MLX Framework](./05.AppleMLX.md)

### 🎯 סקירה כללית
כיסוי מקיף של Apple MLX, מסגרת מהפכנית שתוכננה במיוחד ללמידת מכונה יעילה על Apple Silicon, עם דגש על יכולות מודלים של שפה גדולה ופריסה מקומית.

**נושאים מרכזיים:**
- יתרונות ארכיטקטורת זיכרון מאוחדת ו-Metal Performance Shaders
- תמיכה במודלים LLaMA, Mistral, Phi-3, Qwen ו-Code Llama
- כוונון LoRA להתאמה יעילה של מודלים
- אינטגרציה עם Hugging Face ותמיכה בכימות (4 ביט ו-8 ביט)

**תוצאות למידה:**
- שליטה באופטימיזציה של Apple Silicon לפריסת מודלים של שפה גדולה
- יישום טכניקות כוונון והתאמה של מודלים
- בניית יישומי AI ארגוניים עם תכונות פרטיות משופרות

---

## [חלק 6: סינתזת זרימת עבודה לפיתוח Edge AI](./06.workflow-synthesis.md)

### 🎯 סקירה כללית
סינתזה מקיפה של כל מסגרות האופטימיזציה לזרימות עבודה מאוחדות, מטריצות החלטה ופרקטיקות מיטביות לפריסת Edge AI מוכנה לייצור על פני פלטפורמות ושימושים מגוונים.

**נושאים מרכזיים:**
- ארכיטקטורת זרימת עבודה מאוחדת המשלבת מסגרות אופטימיזציה שונות
- עצי החלטה לבחירת מסגרות וניתוח פשרות ביצועים
- אימות מוכנות לייצור ואסטרטגיות פריסה מקיפות
- אסטרטגיות עתידיות להתאמה לחומרה וארכיטקטורות מודלים מתפתחות

**תוצאות למידה:**
- שליטה בבחירת מסגרות שיטתית בהתבסס על דרישות ומגבלות
- יישום צינורות Edge AI מוכנים לייצור עם ניטור מקיף
- עיצוב זרימות עבודה גמישות שמתפתחות עם טכנולוגיות ודרישות מתפתחות

---

## 🎯 תוצאות למידה של הפרק

עם סיום הפרק המקיף הזה, הקוראים ישיגו:

### **שליטה טכנית**
- הבנה מעמיקה של גבולות כימות ויישומים מעשיים
- ניסיון מעשי עם מסגרות אופטימיזציה שונות
- מיומנויות פריסה בייצור בסביבות מחשוב בקצה

### **הבנה אסטרטגית**
- יכולות בחירה מודעת לחומרה באופטימיזציה
- קבלת החלטות מושכלת על פשרות ביצועים
- אסטרטגיות פריסה וניטור מוכנות לארגונים

### **מדדי ביצועים**

| מסגרת | כימות | שימוש בזיכרון | שיפור מהירות | שימוש |
|-------|-------|---------------|---------------|-------|
| Llama.cpp | Q4_K_M | ~4GB | פי 2-3 | פריסה חוצת פלטפורמות |
| Olive | INT4 | הפחתה של 60-75% | פי 2-6 | זרימות עבודה ארגוניות |
| OpenVINO | INT8/INT4 | הפחתה של 50-75% | פי 2-5 | אופטימיזציה לחומרה של אינטל |
| MLX | 4 ביט | ~4GB | פי 2-4 | אופטימיזציה ל-Apple Silicon |

## 🚀 צעדים הבאים ויישומים מתקדמים

פרק זה מספק בסיס מלא ל:
- פיתוח מודלים מותאמים לתחומים ספציפיים
- מחקר באופטימיזציית Edge AI
- פיתוח יישומי AI מסחריים
- פריסות Edge AI ארגוניות בקנה מידה גדול

הידע מששת החלקים הללו מציע ערכת כלים מקיפה לניווט בנוף המתפתח במהירות של אופטימיזציה ופריסת מודלים של Edge AI.

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.