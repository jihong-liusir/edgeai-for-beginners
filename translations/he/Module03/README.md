<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-18T13:06:16+00:00",
  "source_file": "Module03/README.md",
  "language_code": "he"
}
-->
# פרק 03: פריסת מודלים לשוניים קטנים (SLMs)

הפרק המקיף הזה עוסק במחזור החיים המלא של פריסת מודלים לשוניים קטנים (SLMs), כולל יסודות תיאורטיים, אסטרטגיות יישום מעשיות ופתרונות מוכנים לייצור מבוססי קונטיינרים. הפרק מחולק לשלושה חלקים מתקדמים שמובילים את הקוראים מהבנת מושגים בסיסיים ועד לתרחישי פריסה מתקדמים.

## מבנה הפרק ומסלול הלמידה

### **[חלק 1: למידה מתקדמת של SLM - יסודות ואופטימיזציה](./01.SLMAdvancedLearning.md)**
החלק הראשון מניח את הבסיס התיאורטי להבנת מודלים לשוניים קטנים וחשיבותם האסטרטגית בפריסות AI בקצה. חלק זה כולל:

- **מסגרת סיווג פרמטרים**: חקירה מעמיקה של קטגוריות SLM, החל ממודלים קטנים מאוד (100M-1.4B פרמטרים) ועד למודלים בינוניים (14B-30B פרמטרים), עם דגש על מודלים כמו Phi-4-mini-3.8B, סדרת Qwen3 ו-Google Gemma3, כולל ניתוח דרישות חומרה וטביעת זיכרון לכל רמת מודל
- **טכניקות אופטימיזציה מתקדמות**: סקירה מקיפה של שיטות כימות באמצעות Llama.cpp, Microsoft Olive ו-Apple MLX, כולל כימות BitNET 1-bit מתקדם עם דוגמאות קוד מעשיות שמציגות צינורות כימות ותוצאות השוואה
- **אסטרטגיות רכישת מודלים**: ניתוח מעמיק של מערכת Hugging Face וקטלוג המודלים של Azure AI Foundry לפריסות SLM ברמה ארגונית, עם דוגמאות קוד להורדה, אימות והמרת פורמט של מודלים באופן תכנותי
- **ממשקי API למפתחים**: דוגמאות קוד ב-Python, C++ ו-C# שמראות כיצד לטעון מודלים, לבצע הסקה ולשלב עם מסגרות פופולריות כמו PyTorch, TensorFlow ו-ONNX Runtime

החלק הבסיסי הזה מדגיש את האיזון בין יעילות תפעולית, גמישות בפריסה ועלות-תועלת, שהופכים את SLMs לאידיאליים עבור תרחישי מחשוב בקצה, עם דוגמאות קוד מעשיות שמפתחים יכולים ליישם ישירות בפרויקטים שלהם.

### **[חלק 2: פריסה בסביבה מקומית - פתרונות שמקדמים פרטיות](./02.DeployingSLMinLocalEnv.md)**
החלק השני עובר מתיאוריה ליישום מעשי, ומתמקד באסטרטגיות פריסה מקומיות שמעדיפות ריבונות נתונים ועצמאות תפעולית. תחומים מרכזיים כוללים:

- **פלטפורמת Ollama Universal**: חקירה מקיפה של פריסה חוצת פלטפורמות עם דגש על תהליכי עבודה ידידותיים למפתחים, ניהול מחזור חיים של מודלים והתאמה אישית באמצעות Modelfiles, כולל דוגמאות אינטגרציה מלאות של REST API וסקריפטים לאוטומציה ב-CLI
- **Microsoft Foundry Local**: פתרונות פריסה ברמה ארגונית עם אופטימיזציה מבוססת ONNX, אינטגרציה עם Windows ML ותכונות אבטחה מקיפות, עם דוגמאות קוד ב-C# ו-Python לאינטגרציה יישומית מקורית
- **ניתוח השוואתי**: השוואה מפורטת של מסגרות הכוללת ארכיטקטורה טכנית, מאפייני ביצועים והנחיות אופטימיזציה לשימושים, עם קוד השוואה להערכת מהירות הסקה ושימוש בזיכרון על חומרה שונה
- **אינטגרציית API**: יישומים לדוגמה שמראים כיצד לבנות שירותי רשת, אפליקציות צ'אט וצינורות עיבוד נתונים באמצעות פריסות SLM מקומיות, עם דוגמאות קוד ב-Node.js, Python Flask/FastAPI ו-ASP.NET Core
- **מסגרות בדיקה**: גישות בדיקה אוטומטיות להבטחת איכות מודלים, כולל דוגמאות בדיקות יחידה ואינטגרציה ליישומי SLM

חלק זה מספק הדרכה מעשית לארגונים שמחפשים ליישם פתרונות AI שמקדמים פרטיות תוך שמירה על שליטה מלאה בסביבת הפריסה שלהם, עם דוגמאות קוד מוכנות לשימוש שמפתחים יכולים להתאים לדרישותיהם הספציפיות.

### **[חלק 3: פריסה בענן מבוססת קונטיינרים - פתרונות בקנה מידה ייצור](./03.DeployingSLMinCloud.md)**
החלק האחרון מתמקד באסטרטגיות פריסה מתקדמות מבוססות קונטיינרים, עם Phi-4-mini-instruct של Microsoft כמודל מחקר מרכזי. חלק זה כולל:

- **פריסת vLLM**: אופטימיזציה להסקה בעלת ביצועים גבוהים עם APIs תואמי OpenAI, האצת GPU מתקדמת וקונפיגורציה ברמה ייצורית, כולל Dockerfiles מלאים, מניפסטים של Kubernetes ופרמטרי כוונון ביצועים
- **אורקסטרציה של קונטיינרים Ollama**: תהליכי פריסה פשוטים עם Docker Compose, וריאציות אופטימיזציה של מודלים ואינטגרציה עם ממשק משתמש אינטרנטי, עם דוגמאות CI/CD לצינורות פריסה ובדיקה אוטומטיים
- **יישום ONNX Runtime**: פריסה מותאמת לקצה עם המרה מקיפה של מודלים, אסטרטגיות כימות ותאימות חוצת פלטפורמות, כולל דוגמאות קוד מפורטות לאופטימיזציה ופריסה של מודלים
- **מעקב ותצפית**: יישום לוחות מחוונים של Prometheus/Grafana עם מדדים מותאמים למעקב ביצועי SLM, כולל תצורות התראות ואגרגציית לוגים
- **איזון עומסים והרחבה**: דוגמאות מעשיות לאסטרטגיות הרחבה אופקית ואנכית עם תצורות הרחבה אוטומטיות המבוססות על ניצול CPU/GPU ודפוסי בקשות
- **חיזוק אבטחה**: שיטות עבודה מומלצות לאבטחת קונטיינרים כולל הפחתת הרשאות, מדיניות רשת וניהול סודות עבור מפתחות API ואישורי גישה למודלים

כל גישת פריסה מוצגת עם דוגמאות קונפיגורציה מלאות, נהלי בדיקה, רשימות מוכנות לייצור ותבניות Infrastructure-as-Code שמפתחים יכולים ליישם ישירות בתהליכי הפריסה שלהם.

## תוצאות למידה מרכזיות

עם סיום הפרק, הקוראים יוכלו לשלוט ב:

1. **בחירה אסטרטגית של מודלים**: הבנת גבולות פרמטרים ובחירת SLMs מתאימים בהתבסס על מגבלות משאבים ודרישות ביצועים
2. **שליטה באופטימיזציה**: יישום טכניקות כימות מתקדמות על פני מסגרות שונות להשגת איזון מיטבי בין ביצועים ליעילות
3. **גמישות בפריסה**: בחירה בין פתרונות מקומיים שמקדמים פרטיות לבין פריסות מבוססות קונטיינרים בקנה מידה גדול בהתאם לצרכים ארגוניים
4. **מוכנות לייצור**: קונפיגורציה של מערכות מעקב, אבטחה והרחבה לפריסות SLM ברמה ארגונית

## מיקוד מעשי ויישומים בעולם האמיתי

הפרק שומר על אוריינטציה מעשית לאורך כל הדרך, עם:

- **דוגמאות מעשיות**: קבצי קונפיגורציה מלאים, נהלי בדיקת API וסקריפטים לפריסה
- **השוואת ביצועים**: השוואות מפורטות של מהירות הסקה, שימוש בזיכרון ודרישות משאבים
- **שיקולי אבטחה**: שיטות אבטחה ברמה ארגונית, מסגרות תאימות ואסטרטגיות הגנת נתונים
- **שיטות עבודה מומלצות**: הנחיות מוכחות לייצור למעקב, הרחבה ותחזוקה

## מבט עתידי

הפרק מסתיים בתובנות עתידיות על מגמות מתפתחות, כולל:

- ארכיטקטורות מודלים מתקדמות עם יחס יעילות משופר
- אינטגרציה עמוקה יותר עם מאיצי AI ייעודיים
- התפתחות אקוסיסטם לקראת סטנדרטיזציה ואינטרופרביליות
- דפוסי אימוץ ארגוניים המונעים על ידי פרטיות ודרישות תאימות

הגישה המקיפה הזו מבטיחה שהקוראים יהיו מצוידים היטב להתמודד עם אתגרי פריסת SLM הנוכחיים והתפתחויות טכנולוגיות עתידיות, ולקבל החלטות מושכלות שמתאימות לדרישות הארגוניות וההגבלות שלהם.

הפרק משמש כמדריך מעשי ליישום מיידי וכמשאב אסטרטגי לתכנון פריסות AI לטווח ארוך, תוך הדגשת האיזון הקריטי בין יכולת, יעילות ומצוינות תפעולית שמגדיר פריסות SLM מוצלחות.

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.