<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a35d3b47e6ae98ad9b3e89fb73917e90",
  "translation_date": "2025-09-18T12:38:59+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "he"
}
-->
# סעיף 1: יסודות EdgeAI

EdgeAI מייצג שינוי פרדיגמה בפריסת בינה מלאכותית, ומביא את יכולות ה-AI ישירות למכשירי קצה במקום להסתמך רק על עיבוד מבוסס ענן. חשוב להבין כיצד EdgeAI מאפשר עיבוד AI מקומי במכשירים עם משאבים מוגבלים, תוך שמירה על ביצועים סבירים והתמודדות עם אתגרים כמו פרטיות, זמן תגובה, ויכולות עבודה במצב לא מקוון.

## מבוא

בשיעור זה נחקור את EdgeAI ואת מושגי היסוד שלו. נסקור את פרדיגמת המחשוב המסורתית של AI, את האתגרים של מחשוב קצה, את הטכנולוגיות המרכזיות שמאפשרות EdgeAI, ואת היישומים המעשיים בתעשיות שונות.

## מטרות למידה

בסיום השיעור, תוכלו:

- להבין את ההבדל בין גישות AI מבוססות ענן מסורתיות לבין גישות EdgeAI.
- לזהות את הטכנולוגיות המרכזיות שמאפשרות עיבוד AI במכשירי קצה.
- להכיר את היתרונות והמגבלות של יישומי EdgeAI.
- ליישם ידע על EdgeAI בתרחישים ושימושים בעולם האמיתי.

## הבנת פרדיגמת המחשוב המסורתית של AI

באופן מסורתי, יישומי AI גנרטיביים מסתמכים על תשתיות מחשוב בעלות ביצועים גבוהים כדי להפעיל מודלים שפתיים גדולים (LLMs) בצורה יעילה. ארגונים בדרך כלל מפרסים את המודלים הללו על אשכולות GPU בסביבות ענן, ומנגישים את יכולותיהם דרך ממשקי API.

מודל מרכזי זה עובד היטב עבור יישומים רבים, אך יש לו מגבלות מובנות בכל הנוגע לתרחישי מחשוב קצה. הגישה המסורתית כוללת שליחת שאילתות משתמש לשרתים מרוחקים, עיבודן באמצעות חומרה חזקה, והחזרת תוצאות דרך האינטרנט. בעוד ששיטה זו מספקת גישה למודלים מתקדמים, היא יוצרת תלות בחיבור לאינטרנט, מציגה חששות לגבי זמן תגובה, ומעלה סוגיות פרטיות כאשר יש צורך להעביר נתונים רגישים לשרתים חיצוניים.

ישנם מושגים מרכזיים שעלינו להבין בעת עבודה עם פרדיגמות מחשוב AI מסורתיות, והם:

- **☁️ עיבוד מבוסס ענן**: מודלים של AI פועלים על תשתיות שרתים חזקות עם משאבי מחשוב גבוהים.
- **🔌 גישה מבוססת API**: יישומים ניגשים ליכולות AI דרך קריאות API מרוחקות במקום עיבוד מקומי.
- **🎛️ ניהול מודלים מרכזי**: המודלים מתוחזקים ומעודכנים באופן מרכזי, מה שמבטיח עקביות אך דורש חיבור לרשת.
- **📈 יכולת הרחבת משאבים**: תשתית הענן יכולה להתרחב באופן דינמי כדי להתמודד עם דרישות מחשוב משתנות.

## אתגרי מחשוב קצה

מכשירי קצה כמו מחשבים ניידים, טלפונים ניידים, ומכשירי אינטרנט של הדברים (IoT) כמו Raspberry Pi ו-NVIDIA Orin Nano מציגים מגבלות חישוביות ייחודיות. למכשירים אלו בדרך כלל יש כוח עיבוד, זיכרון ומשאבי אנרגיה מוגבלים בהשוואה לתשתיות מרכזי נתונים.

הפעלת מודלים שפתיים גדולים (LLMs) מסורתיים על מכשירים כאלה הייתה היסטורית מאתגרת בשל מגבלות החומרה הללו. עם זאת, הצורך בעיבוד AI בקצה הפך לחשוב יותר ויותר בתרחישים שונים. חשבו על מצבים שבהם חיבור לאינטרנט אינו אמין או אינו זמין, כמו אתרים תעשייתיים מרוחקים, כלי רכב בתנועה, או אזורים עם כיסוי רשת לקוי. בנוסף, יישומים הדורשים סטנדרטים אבטחה גבוהים, כמו מכשירים רפואיים, מערכות פיננסיות, או יישומים ממשלתיים, עשויים להזדקק לעיבוד נתונים רגישים באופן מקומי כדי לשמור על פרטיות ודרישות תאימות.

### מגבלות מרכזיות של מחשוב קצה

סביבות מחשוב קצה מתמודדות עם מספר מגבלות יסודיות שאינן קיימות בפתרונות AI מבוססי ענן מסורתיים:

- **כוח עיבוד מוגבל**: למכשירי קצה יש בדרך כלל פחות ליבות CPU ומהירויות שעון נמוכות יותר בהשוואה לחומרה ברמת שרתים.
- **מגבלות זיכרון**: הזיכרון הזמין (RAM) וקיבולת האחסון מופחתים משמעותית במכשירי קצה.
- **מגבלות אנרגיה**: מכשירים המופעלים על ידי סוללה חייבים לאזן בין ביצועים לצריכת אנרגיה לצורך פעולה ממושכת.
- **ניהול תרמי**: גורמי צורה קומפקטיים מגבילים את יכולות הקירור, ומשפיעים על ביצועים מתמשכים תחת עומס.

## מהו EdgeAI?

### מושג: הגדרת Edge AI

Edge AI מתייחס לפריסה והפעלה של אלגוריתמים בינה מלאכותית ישירות על מכשירי קצה—החומרה הפיזית שנמצאת ב"קצה" הרשת, קרוב למקום שבו נתונים נוצרים ונאספים. מכשירים אלו כוללים סמארטפונים, חיישני IoT, מצלמות חכמות, כלי רכב אוטונומיים, מכשירים לבישים, וציוד תעשייתי. בניגוד למערכות AI מסורתיות שמסתמכות על שרתי ענן לעיבוד, Edge AI מביא את האינטליגנציה ישירות למקור הנתונים.

בלב העניין, Edge AI עוסק בהפצת עיבוד AI, הרחק ממרכזי נתונים מרכזיים והפצה על פני רשת רחבה של מכשירים המרכיבים את האקוסיסטם הדיגיטלי שלנו. זה מייצג שינוי ארכיטקטוני יסודי באופן שבו מערכות AI מתוכננות ומופעלות.

העמודים המרכזיים של Edge AI כוללים:

- **עיבוד קרוב**: חישוב מתבצע פיזית קרוב למקום שבו הנתונים נוצרים.
- **אינטליגנציה מבוזרת**: יכולות קבלת החלטות מופצות על פני מכשירים רבים.
- **ריבונות נתונים**: מידע נשאר בשליטה מקומית, ולעיתים קרובות אינו עוזב את המכשיר.
- **פעולה אוטונומית**: מכשירים יכולים לפעול באופן אינטליגנטי ללא צורך בחיבור מתמיד.
- **AI משובץ**: אינטליגנציה הופכת ליכולת מובנית של מכשירים יומיומיים.

### ויזואליזציה של ארכיטקטורת Edge AI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                  │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                      │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────────────────────────────────────────┐   Direct Response   ┌───────────┐
│              Edge Devices with Embedded AI        │───────────────────>│ End Users │
│  ┌─────────┐  ┌──────────────┐  ┌──────────────┐ │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │ │
│  └─────────┘  └──────────────┘  └──────────────┘ │
└──────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI מייצג שינוי פרדיגמה בפריסת בינה מלאכותית, ומביא את יכולות ה-AI ישירות למכשירי קצה במקום להסתמך רק על עיבוד מבוסס ענן. גישה זו מאפשרת למודלים של AI לפעול באופן מקומי על מכשירים עם משאבי מחשוב מוגבלים, ומספקת יכולות הסקת מסקנות בזמן אמת ללא צורך בחיבור מתמיד לאינטרנט.

EdgeAI כולל מגוון טכנולוגיות וטכניקות שנועדו להפוך את מודלי ה-AI ליעילים ומתאימים יותר לפריסה על מכשירים עם משאבים מוגבלים. המטרה היא לשמור על ביצועים סבירים תוך הפחתה משמעותית של דרישות המחשוב והזיכרון של מודלי AI.

בואו נבחן את הגישות הבסיסיות שמאפשרות יישומי EdgeAI על פני סוגי מכשירים ושימושים שונים.

### עקרונות מרכזיים של EdgeAI

EdgeAI מבוסס על מספר עקרונות יסוד שמבדילים אותו מ-AI מבוסס ענן מסורתי:

- **עיבוד מקומי**: הסקת מסקנות AI מתבצעת ישירות על מכשיר הקצה ללא צורך בחיבור חיצוני.
- **אופטימיזציית משאבים**: מודלים מותאמים במיוחד למגבלות החומרה של מכשירי היעד.
- **ביצועים בזמן אמת**: עיבוד מתבצע עם זמן תגובה מינימלי עבור יישומים רגישים לזמן.
- **פרטיות מובנית**: נתונים רגישים נשארים על המכשיר, מה שמשפר את האבטחה והתאימות.

## טכנולוגיות מרכזיות שמאפשרות EdgeAI

### כימות מודלים

אחת הטכניקות החשובות ביותר ב-EdgeAI היא כימות מודלים. תהליך זה כולל הפחתת דיוק הפרמטרים של המודל, בדרך כלל מ-32 ביטים של מספרים בנקודה צפה ל-8 ביטים של מספרים שלמים או אפילו פורמטים דיוק נמוכים יותר. למרות שהפחתת דיוק זו עשויה להיראות מדאיגה, מחקרים הראו שרבים ממודלי ה-AI יכולים לשמור על ביצועיהם גם עם דיוק מופחת משמעותית.

כימות עובד על ידי מיפוי טווח הערכים בנקודה צפה לקבוצה קטנה יותר של ערכים דיסקרטיים. לדוגמה, במקום להשתמש ב-32 ביטים כדי לייצג כל פרמטר, כימות עשוי להשתמש רק ב-8 ביטים, מה שמוביל להפחתה של פי 4 בדרישות הזיכרון ולעיתים קרובות גם לזמני הסקה מהירים יותר.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

טכניקות כימות שונות כוללות:

- **כימות לאחר אימון (PTQ)**: מיושם לאחר אימון המודל ללא צורך באימון מחדש.
- **אימון מודע לכימות (QAT)**: משלב את השפעות הכימות במהלך האימון לשיפור דיוק.
- **כימות דינמי**: מכמת משקלים ל-int8 אך מחשב הפעלות באופן דינמי.
- **כימות סטטי**: מחשב מראש את כל פרמטרי הכימות עבור משקלים והפעלות.

עבור פריסות EdgeAI, בחירת אסטרטגיית הכימות המתאימה תלויה בארכיטקטורת המודל הספציפית, דרישות הביצועים, ויכולות החומרה של מכשיר היעד.

### דחיסת מודלים ואופטימיזציה

מעבר לכימות, טכניקות דחיסה שונות מסייעות להפחית את גודל המודל ודרישות המחשוב. אלו כוללות:

**גיזום**: טכניקה זו מסירה חיבורים או נוירונים מיותרים מרשתות נוירונים. על ידי זיהוי והסרת פרמטרים שתורמים מעט לביצועי המודל, גיזום יכול להפחית משמעותית את גודל המודל תוך שמירה על דיוק.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**זיקוק ידע**: גישה זו כוללת אימון מודל "תלמיד" קטן לחקות את התנהגות מודל "מורה" גדול. מודל התלמיד לומד להתקרב לתוצאות המורה, ולעיתים קרובות משיג ביצועים דומים עם פחות פרמטרים משמעותית.

**אופטימיזציית ארכיטקטורת מודלים**: חוקרים פיתחו ארכיטקטורות מיוחדות שנועדו במיוחד לפריסה בקצה, כמו MobileNets, EfficientNets, וארכיטקטורות קלות אחרות שמאזנות בין ביצועים ליעילות מחשוב.

### מודלים שפתיים קטנים (SLMs)

מגמה מתפתחת ב-EdgeAI היא פיתוח מודלים שפתיים קטנים (SLMs). מודלים אלו מתוכננים מהיסוד להיות קומפקטיים ויעילים תוך שמירה על יכולות שפה טבעית משמעותיות. SLMs משיגים זאת באמצעות בחירות ארכיטקטוניות מדוקדקות, טכניקות אימון יעילות, ואימון ממוקד על תחומים או משימות ספציפיות.

בניגוד לגישות מסורתיות הכוללות דחיסת מודלים גדולים, SLMs מאומנים לעיתים קרובות עם מערכי נתונים קטנים וארכיטקטורות אופטימליות שנועדו במיוחד לפריסה בקצה. גישה זו יכולה להוביל למודלים שהם לא רק קטנים יותר אלא גם יעילים יותר עבור שימושים ספציפיים.

## האצת חומרה עבור EdgeAI

מכשירי קצה מודרניים כוללים יותר ויותר חומרה מיוחדת שנועדה להאיץ עומסי עבודה של AI:

### יחידות עיבוד נוירוניות (NPUs)

NPUs הם מעבדים מיוחדים שנועדו במיוחד עבור חישובים של רשתות נוירונים. שבבים אלו יכולים לבצע משימות הסקת מסקנות AI בצורה יעילה הרבה יותר ממעבדי CPU מסורתיים, ולעיתים עם צריכת אנרגיה נמוכה יותר. סמארטפונים, מחשבים ניידים, ומכשירי IoT מודרניים רבים כוללים כיום NPUs כדי לאפשר עיבוד AI על המכשיר.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

מכשירים עם NPUs כוללים:

- **Apple**: שבבי סדרת A ו-M עם Neural Engine
- **Qualcomm**: מעבדי Snapdragon עם Hexagon DSP/NPU
- **Samsung**: מעבדי Exynos עם NPU
- **Intel**: מעבדי Movidius VPUs ומאיצי Habana Labs
- **Microsoft**: מחשבי Windows Copilot+ עם NPUs

### 🎮 האצת GPU

בעוד שמכשירי קצה עשויים שלא לכלול את ה-GPU החזקים שנמצאים במרכזי נתונים, רבים עדיין כוללים GPUs משולבים או נפרדים שיכולים להאיץ עומסי עבודה של AI. GPUs ניידים מודרניים ומעבדי גרפיקה משולבים יכולים לספק שיפורי ביצועים משמעותיים עבור משימות הסקת מסקנות AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### אופטימיזציית CPU

גם מכשירים עם CPU בלבד יכולים להפיק תועלת מ-EdgeAI באמצעות יישומים אופטימליים. מעבדי CPU מודרניים כוללים הוראות מיוחדות עבור עומסי עבודה של AI, ומסגרות תוכנה פותחו כדי למקסם את ביצועי ה-CPU עבור הסקת מסקנות AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

עבור מהנדסי תוכנה העובדים עם EdgeAI, הבנת כיצד לנצל את אפשרויות האצת החומרה הללו היא קריטית לאופטימיזציית ביצועי הסקת מסקנות ויעילות אנרגטית במכשירי היעד.

## יתרונות EdgeAI

### פרטיות ואבטחה

אחד היתרונות המשמעותיים ביותר של EdgeAI הוא פרטיות ואבטחה משופרות. על ידי עיבוד נתונים באופן מקומי על המכשיר, מידע רגיש לעולם אינו עוזב את שליטת המשתמש. זה חשוב במיוחד עבור יישומים המטפלים בנתונים אישיים, מידע רפואי, או נתונים עסקיים סודיים.

### הפחתת זמן תגובה

EdgeAI מבטל את הצורך לשלוח נתונים לשרתים מרוחקים לעיבוד, מה שמפחית משמעותית את זמן התגובה. זה קריטי עבור יישומים בזמן אמת כמו כלי רכב אוטונומיים, אוטומציה תעשייתית, או יישומים אינטראקטיביים שבהם נדרשות תגובות מיידיות.

### יכולת עבודה במצב לא מקוון

EdgeAI מאפשר פונקציונליות AI גם כאשר חיבור לאינטרנט אינו זמין. זה חשוב עבור יישומים במיקומים מרוחקים, במהלך נסיעות, או במצבים שבהם אמינות הרשת מהווה דאגה.

### יעילות כלכלית

על ידי הפחתת התלות בשירותי AI מבוססי ענן, EdgeAI יכול לעזור להפחית עלויות תפעול, במיוחד עבור יישומים עם נפחי שימוש גבוהים. ארגונים יכולים להימנע מעלויות API מתמשכות ולהפחית את דרישות רוחב הפס.

### יכולת הרחבה

EdgeAI מפזר את עומס המחשוב על פני מכשירי קצה במקום לרכז אותו במרכזי נתונים. זה יכול לעזור להפחית עלויות תשתית ולשפר את יכולת ההרחבה הכוללת של המערכת.

## יישומי EdgeAI

### מכשירים חכמים ו-IoT

EdgeAI מניע תכונות רבות של מכשירים חכמים, החל מעוזרים קוליים שיכולים לעבד פקודות באופן מקומי ועד מצלמות חכמות שיכולות לזהות אובייקטים ואנשים מבלי לשלוח וידאו לענן. מכשירי IoT משתמשים ב-EdgeAI לתחזוקה חזויה, ניטור סביבתי, וקבלת החלטות אוטומטית.

### יישומים ניידים

סמארטפונים וטאבלטים משתמשים ב-EdgeAI עבור תכונות שונות, כולל שיפור תמונות, תרגום בזמן אמת, מציאות רבודה, והמלצות מותאמות אישית. יישומים אלו נהנים מהיתרונות של זמן תגובה נמוך ופרטיות של עיבוד מקומי.

### יישומים תעשייתיים

סביבות ייצור ותעשייה משתמשות ב-EdgeAI לבקרת איכות, תחזוקה חזויה, ואופטימיזציית תהליכים. יישומים אלו דורשים לעיתים קרובות עיבוד בזמן אמת ועשויים לפעול בסביבות עם חיבור מוגבל.

### בריאות

מכשירים רפואיים ויישומי בריאות משתמשים ב-EdgeAI לניטור מטופלים, סיוע באבחון, והמלצות טיפול. היתרונות של פרטיות ואבטחה בעיבוד מקומי חשובים במיוחד ביישומי בריאות.

## אתגרים ומגבלות

### פשרות ביצועים

EdgeAI בדרך כלל כרוך בפשרות בין גודל המודל, יעילות מחשוב,
## ➡️ מה הלאה

- [02: יישומי EdgeAI](02.RealWorldCaseStudies.md)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.