<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1f5ed7b55962c3dccafd3da6f9ec252",
  "translation_date": "2025-09-18T12:41:56+00:00",
  "source_file": "Module01/04.EdgeDeployment.md",
  "language_code": "he"
}
-->
# פרק 4: פלטפורמות חומרה לפריסת AI בקצה

פריסת AI בקצה מייצגת את השיא של אופטימיזציית מודלים ובחירת חומרה, ומביאה יכולות חכמות ישירות למכשירים שבהם נוצרים הנתונים. פרק זה עוסק בשיקולים מעשיים, דרישות חומרה, והיתרונות האסטרטגיים של פריסת AI בקצה על פני פלטפורמות שונות, עם דגש על פתרונות החומרה המובילים של Intel, Qualcomm, NVIDIA ומחשבי Windows AI.

## משאבים למפתחים

### תיעוד ומשאבי למידה
- [Microsoft Learn: פיתוח AI בקצה](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)
- [משאבי AI של Intel בקצה](https://www.intel.com/content/www/us/en/developer/topic-technology/edge-5g/edge-ai.html)
- [משאבי מפתחים של Qualcomm AI](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk)
- [תיעוד NVIDIA Jetson](https://developer.nvidia.com/embedded/learn/getting-started-jetson)
- [תיעוד Windows AI](https://learn.microsoft.com/windows/ai/)

### כלים ו-SDKs
- [ONNX Runtime](https://onnxruntime.ai/) - מסגרת חוצה פלטפורמות להרצת מודלים
- [OpenVINO Toolkit](https://docs.openvino.ai/) - ערכת האופטימיזציה של Intel
- [TensorRT](https://developer.nvidia.com/tensorrt) - SDK לביצועים גבוהים של NVIDIA
- [DirectML](https://learn.microsoft.com/windows/ai/directml/dml-intro) - API מואץ חומרתית של Microsoft ללמידת מכונה

## מבוא

בפרק זה נחקור את ההיבטים המעשיים של פריסת מודלי AI למכשירי קצה. נסקור את השיקולים החיוניים לפריסה מוצלחת בקצה, בחירת פלטפורמות חומרה, ואסטרטגיות אופטימיזציה המותאמות לתרחישי מחשוב קצה שונים.

## מטרות למידה

בסיום פרק זה, תוכלו:

- להבין את השיקולים המרכזיים לפריסת AI מוצלחת בקצה
- לזהות פלטפורמות חומרה מתאימות לעומסי עבודה שונים של AI בקצה
- להכיר את הפשרות בין פתרונות חומרה שונים ל-AI בקצה
- ליישם טכניקות אופטימיזציה המותאמות לפלטפורמות חומרה שונות בקצה

## שיקולים לפריסת AI בקצה

פריסת AI למכשירי קצה מציבה אתגרים ודרישות ייחודיים בהשוואה לפריסה בענן. יישום מוצלח של AI בקצה דורש התייחסות למספר גורמים:

### מגבלות משאבי חומרה

למכשירי קצה יש בדרך כלל משאבים חישוביים מוגבלים בהשוואה לתשתיות ענן:

- **מגבלות זיכרון**: למכשירי קצה רבים יש זיכרון RAM מוגבל (מכמה MB ועד כמה GB)
- **מגבלות אחסון**: אחסון מתמשך מוגבל משפיע על גודל המודל וניהול הנתונים
- **כוח עיבוד**: יכולות CPU/GPU/NPU מוגבלות משפיעות על מהירות החיזוי
- **צריכת חשמל**: מכשירי קצה רבים פועלים על סוללות או עם מגבלות תרמיות

### שיקולי קישוריות

AI בקצה חייב לתפקד ביעילות עם קישוריות משתנה:

- **קישוריות לא רציפה**: הפעילות חייבת להימשך גם במהלך הפסקות רשת
- **מגבלות רוחב פס**: יכולות העברת נתונים מופחתות בהשוואה למרכזי נתונים
- **דרישות השהיה**: יישומים רבים דורשים עיבוד בזמן אמת או כמעט בזמן אמת
- **סנכרון נתונים**: ניהול עיבוד מקומי עם סנכרון ענן תקופתי

### דרישות אבטחה ופרטיות

AI בקצה מציב אתגרי אבטחה ייחודיים:

- **אבטחה פיזית**: מכשירים עשויים להיות ממוקמים במקומות נגישים פיזית
- **הגנת נתונים**: עיבוד נתונים רגישים על מכשירים שעלולים להיות פגיעים
- **אימות**: בקרת גישה מאובטחת לפונקציונליות של מכשירי קצה
- **ניהול עדכונים**: מנגנונים מאובטחים לעדכוני מודלים ותוכנה

### פריסה וניהול

שיקולים מעשיים לפריסה כוללים:

- **ניהול צי מכשירים**: פריסות קצה רבות כוללות מכשירים מבוזרים רבים
- **ניהול גרסאות**: ניהול גרסאות מודלים על פני מכשירים מבוזרים
- **ניטור**: מעקב ביצועים וזיהוי חריגות בקצה
- **ניהול מחזור חיים**: מהפריסה הראשונית ועד לעדכונים ולפרישה

## אפשרויות פלטפורמות חומרה ל-AI בקצה

### פתרונות AI של Intel בקצה

Intel מציעה מספר פלטפורמות חומרה המותאמות לפריסת AI בקצה:

#### Intel NUC

Intel NUC (Next Unit of Computing) מספק ביצועים ברמת מחשב שולחני בגודל קומפקטי:

- **מעבדי Intel Core** עם גרפיקה משולבת Iris Xe
- **RAM**: תמיכה עד 64GB DDR4
- תאימות ל-Neural Compute Stick 2 להאצת AI נוספת
- **מתאים ל**: עומסי עבודה מתונים עד מורכבים של AI בקצה במיקומים קבועים עם זמינות חשמל

[Intel NUC for Edge AI](https://www.intel.com/content/www/us/en/products/details/nuc.html)

#### Intel Movidius Vision Processing Units (VPUs)

חומרה ייעודית לראייה ממוחשבת והאצת רשתות נוירונים:

- **צריכת חשמל נמוכה במיוחד** (1-3W אופייני)
- **האצת רשתות נוירונים ייעודית**
- **גודל קומפקטי** לשילוב במצלמות וחיישנים
- **מתאים ל**: יישומי ראייה ממוחשבת עם מגבלות צריכת חשמל חמורות

[Intel Movidius VPU](https://www.intel.com/content/www/us/en/products/details/processors/movidius-vpu.html)

#### Intel Neural Compute Stick 2

מאיץ רשתות נוירונים בחיבור USB:

- **Intel Movidius Myriad X VPU**
- **עד 4 TOPS** של ביצועים
- **ממשק USB 3.0** לשילוב קל
- **מתאים ל**: אבטיפוס מהיר והוספת יכולות AI למערכות קיימות

[Intel Neural Compute Stick 2](https://www.intel.com/content/www/us/en/developer/tools/neural-compute-stick/overview.html)

#### גישת פיתוח

Intel מספקת את ערכת OpenVINO לאופטימיזציה ופריסת מודלים:

```python
# Example: Using OpenVINO for edge deployment
from openvino.inference_engine import IECore

# Initialize the Inference Engine
ie = IECore()

# Read the network from IR files
net = ie.read_network(model="optimized_model.xml", weights="optimized_model.bin")

# Prepare input and output blobs
input_blob = next(iter(net.input_info))
output_blob = next(iter(net.outputs))

# Load the network to the device (CPU, GPU, MYRIAD, etc.)
exec_net = ie.load_network(network=net, device_name="CPU")

# Prepare input
input_data = preprocess_image("sample.jpg")

# Run inference
result = exec_net.infer(inputs={input_blob: input_data})

# Process output
output = result[output_blob]
```

### פתרונות AI של Qualcomm

הפלטפורמות של Qualcomm מתמקדות ביישומים ניידים ומוטמעים:

#### Qualcomm Snapdragon

מערכות Snapdragon על שבב (SoCs) כוללות:

- **Qualcomm AI Engine** עם Hexagon DSP
- **Adreno GPU** לגרפיקה ומחשוב מקבילי
- ליבות **Kryo CPU** לעיבוד כללי
- **מתאים ל**: סמארטפונים, טאבלטים, משקפי XR ומצלמות חכמות

[Qualcomm Snapdragon for Edge AI](https://www.qualcomm.com/products/mobile/snapdragon/pcs/product-list)

#### Qualcomm Cloud AI 100

מאיץ ייעודי לחיזוי AI בקצה:

- **עד 400 TOPS** של ביצועי AI
- **יעילות אנרגטית** מותאמת למרכזי נתונים ופריסות קצה
- **ארכיטקטורה ניתנת להרחבה** לתרחישי פריסה שונים
- **מתאים ל**: יישומי AI בקצה עם תפוקה גבוהה בסביבות מבוקרות

[Qualcomm Cloud AI 100](https://www.qualcomm.com/products/technology/processors/cloud-artificial-intelligence)

#### פלטפורמת Qualcomm RB5/RB6 Robotics

מיועדת במיוחד לרובוטיקה ומחשוב קצה מתקדם:

- **קישוריות 5G משולבת**
- **יכולות AI וראייה ממוחשבת מתקדמות**
- **תמיכה מקיפה בחיישנים**
- **מתאים ל**: רובוטים אוטונומיים, רחפנים ומערכות תעשייתיות חכמות

[Qualcomm Robotics Platform](https://www.qualcomm.com/products/application/robotics/qualcomm-robotics-rb6-platform)

#### גישת פיתוח

Qualcomm מספקת את Neural Processing SDK ו-AI Model Efficiency Toolkit:

```python
# Example: Using Qualcomm Neural Processing SDK
from qti.aisw.dlc_utils import modeltools

# Convert your model to DLC format
converter = modeltools.DlcConverter()
converter.convert(
    input_network="model.tflite",
    input_dim=[1, 224, 224, 3],
    output_path="optimized_model.dlc"
)

# Use SNPE runtime for inference
from qti.aisw.snpe_runtime import SnpeRuntime

# Initialize runtime
runtime = SnpeRuntime()
runtime.load("optimized_model.dlc")

# Prepare input
input_tensor = preprocess_image("sample.jpg")

# Run inference
outputs = runtime.execute(input_tensor)

# Process results
predictions = postprocess_output(outputs)
```

### 🎮 פתרונות AI של NVIDIA בקצה

NVIDIA מציעה פלטפורמות מואצות GPU לפריסה בקצה:

#### משפחת NVIDIA Jetson

פלטפורמות מחשוב AI ייעודיות לקצה:

##### סדרת Jetson Orin
- **עד 275 TOPS** של ביצועי AI
- **ארכיטקטורת NVIDIA Ampere** GPU
- **תצורות צריכת חשמל** מ-5W עד 60W
- **מתאים ל**: רובוטיקה מתקדמת, ניתוח וידאו חכם ומכשירים רפואיים

##### Jetson Nano
- **מחשוב AI ברמת כניסה** (472 GFLOPS)
- **GPU Maxwell עם 128 ליבות**
- **יעילות אנרגטית** (5-10W)
- **מתאים ל**: פרויקטים חובבניים, יישומים חינוכיים ופריסות AI פשוטות

[NVIDIA Jetson Platform](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/)

#### NVIDIA Clara Guardian

פלטפורמה ליישומי AI בתחום הבריאות:

- **חישה בזמן אמת** לניטור מטופלים
- **מבוסס על Jetson** או שרתים מואצים GPU
- **אופטימיזציות ייחודיות לתחום הבריאות**
- **מתאים ל**: בתי חולים חכמים, ניטור מטופלים ודימות רפואי

[NVIDIA Clara Guardian](https://developer.nvidia.com/clara)

#### NVIDIA EGX Platform

פתרונות מחשוב קצה ברמת ארגון:

- **ניתן להרחבה מ-NVIDIA A100 ועד T4 GPUs**
- **פתרונות שרתים מאושרים** משותפי OEM
- **כולל חבילת התוכנה NVIDIA AI Enterprise**
- **מתאים ל**: פריסות AI בקצה בקנה מידה גדול בתעשייה ובארגונים

[NVIDIA EGX Platform](https://www.nvidia.com/en-us/data-center/products/egx-edge-computing/)

#### גישת פיתוח

NVIDIA מספקת את TensorRT לפריסת מודלים אופטימלית:

```python
# Example: Using TensorRT for optimized inference
import tensorrt as trt
import numpy as np

# Create builder and network
logger = trt.Logger(trt.Logger.INFO)
builder = trt.Builder(logger)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))

# Parse ONNX model
parser = trt.OnnxParser(network, logger)
with open("model.onnx", "rb") as f:
    parser.parse(f.read())

# Create optimization config
config = builder.create_builder_config()
config.max_workspace_size = 1 << 30  # 1GB
config.set_flag(trt.BuilderFlag.FP16)

# Build and serialize engine
engine = builder.build_engine(network, config)
with open("model.trt", "wb") as f:
    f.write(engine.serialize())

# Create runtime and execute
runtime = trt.Runtime(logger)
engine = runtime.deserialize_cuda_engine(open("model.trt", "rb").read())
context = engine.create_execution_context()

# Run inference
input_data = preprocess_image("sample.jpg")
output = run_inference(context, input_data, engine)
```

### מחשבי Windows AI

מחשבי Windows AI מייצגים קטגוריה חדשה של חומרת AI בקצה, עם יחידות עיבוד נוירונים (NPUs) ייעודיות:

#### Qualcomm Snapdragon X Elite/Plus

הדור הראשון של מחשבי Windows Copilot+ כולל:

- **Hexagon NPU** עם יותר מ-45 TOPS של ביצועי AI
- **מעבד Qualcomm Oryon** עם עד 12 ליבות
- **Adreno GPU** לגרפיקה והאצת AI נוספת
- **מתאים ל**: פרודוקטיביות משופרת ב-AI, יצירת תוכן ופיתוח תוכנה

[Qualcomm Snapdragon X Elite](https://www.qualcomm.com/snapdragon/laptops)

#### Intel Core Ultra (Meteor Lake ומעבר)

מעבדי AI PC של Intel כוללים:

- **Intel AI Boost (NPU)** המספק עד 10 TOPS
- **Intel Arc GPU** להאצת AI נוספת
- **ליבות CPU לביצועים ויעילות**
- **מתאים ל**: מחשבים ניידים עסקיים, תחנות עבודה יצירתיות ומחשוב יומיומי משופר ב-AI

[Intel Core Ultra Processors](https://www.intel.com/content/www/us/en/products/details/processors/core/ultra.html)

#### AMD Ryzen AI Series

מעבדי AMD הממוקדים ב-AI כוללים:

- **NPU מבוסס XDNA** המספק עד 16 TOPS
- **ליבות CPU Zen 4** לעיבוד כללי
- **גרפיקה RDNA 3** ליכולות חישוב נוספות
- **מתאים ל**: אנשי מקצוע יצירתיים, מפתחים ומשתמשים מתקדמים

[AMD Ryzen AI Processors](https://www.amd.com/en/processors/ryzen-ai.html)

#### גישת פיתוח

מחשבי Windows AI משתמשים בפלטפורמת המפתחים של Windows וב-DirectML:

```csharp
// Example: Using Windows App SDK and DirectML
using Microsoft.AI.DirectML;
using Microsoft.Windows.AI;

// Load model
var modelPath = "optimized_model.onnx";
var modelOptions = new OnnxModelOptions
{
    InterOpNumThreads = 4,
    IntraOpNumThreads = 4
};

// Create model
var model = await OnnxModel.CreateFromFileAsync(modelPath, modelOptions);

// Prepare input
var inputFeatures = new List<InputFeature>
{
    new InputFeature
    {
        Name = "input",
        Value = imageData
    }
};

// Run inference
var results = await model.EvaluateAsync(inputFeatures);

// Process output
var output = results.First().Value;
```

## ⚡ טכניקות אופטימיזציה ייחודיות לחומרה

### 🔍 גישות כימות

פלטפורמות חומרה שונות נהנות מטכניקות כימות ייחודיות:

#### אופטימיזציות Intel OpenVINO
- **כימות INT8** ל-CPU ו-GPU משולב
- **דיוק FP16** לשיפור ביצועים עם אובדן דיוק מינימלי
- **כימות אסימטרי** להתמודדות עם התפלגויות אקטיבציה

#### אופטימיזציות Qualcomm AI Engine
- **כימות UINT8** ל-Hexagon DSP
- **דיוק מעורב** המנצל את כל יחידות החישוב הזמינות
- **כימות לפי ערוץ** לשיפור הדיוק

#### אופטימיזציות NVIDIA TensorRT
- **דיוק INT8 ו-FP16** להאצת GPU
- **מיזוג שכבות** להפחתת העברות זיכרון
- **כוונון אוטומטי של ליבות** לארכיטקטורות GPU ספציפיות

#### אופטימיזציות Windows NPU
- **כימות INT8/INT4** לביצועי NPU
- **אופטימיזציות גרף DirectML**
- **האצת זמן ריצה של Windows ML**

### התאמות ייחודיות לארכיטקטורה

חומרות שונות דורשות שיקולים ארכיטקטוניים ייחודיים:

- **Intel**: אופטימיזציה להוראות AVX-512 ו-Intel Deep Learning Boost
- **Qualcomm**: ניצול מחשוב הטרוגני בין Hexagon DSP, Adreno GPU ו-Kryo CPU
- **NVIDIA**: מקסום מקביליות GPU וניצול ליבות CUDA
- **Windows NPU**: תכנון לעיבוד משולב NPU-CPU-GPU

### אסטרטגיות ניהול זיכרון

ניהול זיכרון יעיל משתנה לפי פלטפורמה:

- **Intel**: אופטימיזציה לניצול מטמון ודפוסי גישה לזיכרון
- **Qualcomm**: ניהול זיכרון משותף בין מעבדים הטרוגניים
- **NVIDIA**: שימוש בזיכרון מאוחד CUDA ואופטימיזציה לשימוש ב-VRAM
- **Windows NPU**: איזון עומסים בין זיכרון NPU ייעודי ל-RAM מערכת

## מדדי ביצועים ומדידה

בעת הערכת פריסות AI בקצה, יש להתחשב במדדים מרכזיים:

### מדדי ביצועים

- **זמן חיזוי**: מילישניות לחיזוי (נמוך יותר טוב יותר)
- **תפוקה**: חיזויים לשנייה (גבוה יותר טוב יותר)
- **השהיה**: זמן תגובה מקצה לקצה (נמוך יותר טוב יותר)
- **FPS**: פריימים לשנייה ליישומי ראייה (גבוה יותר טוב יותר)

### מדדי יעילות

- **ביצועים לוואט**: TOPS/W או חיזויים/שנייה/וואט
- **אנרגיה לחיזוי**: ג'אול שנצרך לחיזוי
- **השפעת סוללה**: הפחתת זמן פעולה בעת הרצת עומסי AI
- **יעילות תרמית**: עליית טמפרטורה במהלך פעולה ממושכת

### מדדי דיוק

- **דיוק Top-1/Top-5**: אחוז נכונות הסיווג
- **mAP**: דיוק ממוצע ממוצע לזיהוי אובייקטים
- **ציון F1**: איזון בין דיוק ושליפה
- **השפעת כימות**: הבדל דיוק בין מודלים בדיוק מלא למודלים מכומתים

## דפוסי פריסה ושיטות עבודה מומלצות

### אסטרטגיות פריסה ארגוניות

- **קונטיינריזציה**: שימוש ב-Docker או דומה לפריסה עקבית
- **ניהול צי מכשירים**: פתרונות כמו Azure IoT Edge לניהול מכשירים
- **ניטור**: איסוף טלמטריה ומעקב ביצועים
- **ניהול עדכונים**: מנגנוני עדכון OTA עבור מודלים ותוכנה

### תבניות היברידיות של ענן-קצה

- **אימון בענן, הסקה בקצה**: אימון בענן, פריסה לקצה  
- **עיבוד מקדים בקצה, ניתוח בענן**: עיבוד בסיסי בקצה, ניתוח מורכב בענן  
- **למידה מבוזרת**: שיפור מודלים מבוזר ללא ריכוז נתונים  
- **למידה הדרגתית**: שיפור מתמשך של מודלים מנתוני הקצה  

### תבניות אינטגרציה

- **אינטגרציית חיישנים**: חיבור ישיר למצלמות, מיקרופונים וחיישנים אחרים  
- **שליטה במפעילים**: שליטה בזמן אמת במנועים, תצוגות ופלטים אחרים  
- **אינטגרציית מערכות**: תקשורת עם מערכות ארגוניות קיימות  
- **אינטגרציית IoT**: חיבור לאקוסיסטמות IoT רחבות  

## שיקולים לפריסה בתעשיות ספציפיות

### בריאות

- **פרטיות מטופלים**: עמידה בתקנות HIPAA עבור נתונים רפואיים  
- **תקנות מכשור רפואי**: דרישות רגולטוריות של FDA וגופים אחרים  
- **דרישות אמינות**: סבילות לתקלות עבור יישומים קריטיים  
- **תקני אינטגרציה**: FHIR, HL7 ותקני תאימות אחרים בתחום הבריאות  

### ייצור

- **סביבה תעשייתית**: התאמה לתנאים קשים  
- **דרישות בזמן אמת**: ביצועים דטרמיניסטיים למערכות בקרה  
- **מערכות בטיחות**: אינטגרציה עם פרוטוקולי בטיחות תעשייתיים  
- **אינטגרציה עם מערכות ישנות**: חיבור לתשתיות OT קיימות  

### רכב

- **בטיחות פונקציונלית**: עמידה בתקני ISO 26262  
- **חיזוק סביבתי**: פעולה בטווחי טמפרטורה קיצוניים  
- **ניהול צריכת חשמל**: פעולה חסכונית בסוללה  
- **ניהול מחזור חיים**: תמיכה ארוכת טווח לאורך חיי הרכב  

### ערים חכמות

- **פריסה חיצונית**: עמידות לתנאי מזג אוויר ואבטחה פיזית  
- **ניהול קנה מידה**: אלפי עד מיליוני מכשירים מבוזרים  
- **שונות ברשת**: פעולה בתנאי קישוריות לא עקביים  
- **שיקולי פרטיות**: טיפול אחראי בנתונים משטחים ציבוריים  

## מגמות עתידיות בחומרת AI בקצה

### פיתוחים חדשים בחומרה

- **סיליקון ייעודי ל-AI**: מאיצי AI ו-NPU ייעודיים יותר  
- **מחשוב נוירומורפי**: ארכיטקטורות בהשראת המוח ליעילות משופרת  
- **מחשוב בזיכרון**: הפחתת תנועת נתונים לפעולות AI  
- **אריזת מולטי-שבבים**: אינטגרציה הטרוגנית של מעבדי AI ייעודיים  

### אבולוציה משותפת של תוכנה וחומרה

- **חיפוש ארכיטקטורת רשת מותאם לחומרה**: מודלים מותאמים לחומרה ספציפית  
- **שיפורי קומפיילר**: תרגום משופר של מודלים להוראות חומרה  
- **אופטימיזציות גרף ייעודיות**: טרנספורמציות רשת מותאמות לחומרה  
- **התאמה דינמית**: אופטימיזציה בזמן ריצה על בסיס משאבים זמינים  

### מאמצי סטנדרטיזציה

- **ONNX ו-ONNX Runtime**: תאימות מודלים בין פלטפורמות  
- **MLIR**: ייצוג ביניים רב-שכבתי ללמידת מכונה  
- **OpenXLA**: קומפילציה מואצת לאלגברה לינארית  
- **TMUL**: שכבות הפשטה למעבדי טנסור  

## התחלת עבודה עם פריסת AI בקצה

### הגדרת סביבת פיתוח

1. **בחירת חומרת יעד**: בחרו את הפלטפורמה המתאימה למקרה השימוש שלכם  
2. **התקנת SDK וכלים**: הגדירו את ערכת הפיתוח של היצרן  
3. **הגדרת כלים לאופטימיזציה**: התקינו תוכנות לכימות וקומפילציה  
4. **הקמת צינור CI/CD**: הקימו תהליך אוטומטי לבדיקות ופריסה  

### רשימת בדיקה לפריסה

- **אופטימיזציית מודלים**: כימות, גיזום ואופטימיזציית ארכיטקטורה  
- **בדיקות ביצועים**: בדיקות על חומרת היעד בתנאים מציאותיים  
- **ניתוח צריכת חשמל**: מדידת דפוסי צריכת אנרגיה  
- **בדיקת אבטחה**: אימות הגנת נתונים ובקרות גישה  
- **מנגנון עדכון**: יישום יכולות עדכון מאובטחות  
- **הגדרת ניטור**: פריסת איסוף טלמטריה והתראות  

## ➡️ מה הלאה

- עיינו ב-[סקירת מודול 1](./README.md)  
- חקרו את [מודול 2: יסודות מודלים לשוניים קטנים](../Module02/README.md)  
- המשיכו ל-[מודול 3: אסטרטגיות פריסת SLM](../Module03/README.md)  

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס AI [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.