<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "65a22ed38b95f334dd8a893bf2c55806",
  "translation_date": "2025-10-02T13:32:18+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "he"
}
-->
# ערכת כלים ל-AI עבור Visual Studio Code - מדריך לפיתוח AI בקצה

## מבוא

ברוכים הבאים למדריך המקיף לשימוש בערכת הכלים ל-AI עבור Visual Studio Code בפיתוח AI בקצה. ככל שהבינה המלאכותית עוברת ממחשוב ענן מרכזי למכשירי קצה מבוזרים, מפתחים זקוקים לכלים חזקים ואינטגרטיביים שיכולים להתמודד עם האתגרים הייחודיים של פריסת קצה - החל ממגבלות משאבים ועד לדרישות לפעולה במצב לא מקוון.

ערכת הכלים ל-AI עבור Visual Studio Code מגשרת על הפער הזה על ידי מתן סביבה פיתוחית שלמה שתוכננה במיוחד לבנייה, בדיקה ואופטימיזציה של יישומי AI הפועלים ביעילות על מכשירי קצה. בין אם אתם מפתחים עבור חיישני IoT, מכשירים ניידים, מערכות משובצות או שרתי קצה, ערכת הכלים הזו מפשטת את כל תהליך הפיתוח שלכם בתוך סביבת VS Code המוכרת.

מדריך זה ילווה אתכם דרך המושגים, הכלים והפרקטיקות הטובות ביותר לשימוש בערכת הכלים ל-AI בפרויקטי Edge AI שלכם, החל מבחירת המודל הראשונית ועד לפריסה בייצור.

## סקירה כללית

ערכת הכלים ל-AI עבור Visual Studio Code היא הרחבה חזקה שמייעלת את פיתוח הסוכנים ויצירת יישומי AI. הערכה מספקת יכולות מקיפות לחקר, הערכה ופריסה של מודלי AI ממגוון רחב של ספקים—כולל Anthropic, OpenAI, GitHub, Google—תוך תמיכה בהרצת מודלים מקומית באמצעות ONNX ו-Ollama.

מה שמייחד את ערכת הכלים ל-AI הוא הגישה המקיפה שלה לכל מחזור החיים של פיתוח AI. בניגוד לכלי פיתוח AI מסורתיים שמתמקדים בהיבטים בודדים, ערכת הכלים מספקת סביבה אינטגרטיבית המכסה גילוי מודלים, ניסויים, פיתוח סוכנים, הערכה ופריסה—הכל בתוך סביבת VS Code המוכרת.

הפלטפורמה תוכננה במיוחד לפרוטוטייפ מהיר ולפריסה בייצור, עם תכונות כמו יצירת פקודות, התחלה מהירה, אינטגרציות חלקות עם MCP (Model Context Protocol) וכלי הערכה נרחבים. עבור פיתוח Edge AI, המשמעות היא שתוכלו לפתח, לבדוק ולבצע אופטימיזציה של יישומי AI לתרחישי פריסת קצה ביעילות תוך שמירה על כל תהליך הפיתוח בתוך VS Code.

## מטרות למידה

בסיום מדריך זה, תוכלו:

### מיומנויות ליבה
- **להתקין ולהגדיר** את ערכת הכלים ל-AI עבור תהליכי פיתוח Edge AI
- **לנווט ולהשתמש** בממשק ערכת הכלים ל-AI, כולל קטלוג מודלים, Playground ו-Agent Builder
- **לבחור ולהעריך** מודלי AI המתאימים לפריסת קצה בהתבסס על ביצועים ומגבלות משאבים
- **להמיר ולבצע אופטימיזציה** של מודלים באמצעות פורמט ONNX וטכניקות כימות למכשירי קצה

### מיומנויות פיתוח Edge AI
- **לעצב וליישם** יישומי Edge AI באמצעות סביבת הפיתוח האינטגרטיבית
- **לבצע בדיקות מודלים** בתנאים דמויי קצה באמצעות הסקה מקומית וניטור משאבים
- **ליצור ולהתאים אישית** סוכני AI המותאמים לתרחישי פריסת קצה
- **להעריך ביצועי מודלים** באמצעות מדדים רלוונטיים למחשוב קצה (זמן השהיה, שימוש בזיכרון, דיוק)

### אופטימיזציה ופריסה
- **ליישם טכניקות כימות וגיזום** להפחתת גודל המודל תוך שמירה על ביצועים מקובלים
- **לבצע אופטימיזציה של מודלים** לפלטפורמות חומרה ספציפיות בקצה, כולל האצת CPU, GPU ו-NPU
- **ליישם פרקטיקות מיטביות** לפיתוח Edge AI, כולל ניהול משאבים ואסטרטגיות גיבוי
- **להכין מודלים ויישומים** לפריסה בייצור על מכשירי קצה

### מושגים מתקדמים ב-Edge AI
- **להשתלב עם מסגרות Edge AI** כולל ONNX Runtime, Windows ML ו-TensorFlow Lite
- **ליישם ארכיטקטורות מרובות מודלים** ותסריטי למידה מבוזרת לסביבות קצה
- **לפתור בעיות נפוצות ב-Edge AI** כולל מגבלות זיכרון, מהירות הסקה ותאימות חומרה
- **לעצב אסטרטגיות ניטור ורישום** ליישומי Edge AI בייצור

### יישום מעשי
- **לבנות פתרונות Edge AI מקצה לקצה** מבחירת מודל ועד לפריסה
- **להפגין מיומנות** בתהליכי פיתוח ואופטימיזציה ייחודיים לקצה
- **ליישם מושגים שנלמדו** על מקרי שימוש אמיתיים ב-Edge AI, כולל IoT, ניידים ויישומים משובצים
- **להעריך ולהשוות** בין אסטרטגיות פריסת Edge AI שונות והפשרות שלהן

## תכונות מפתח לפיתוח Edge AI

### 1. קטלוג מודלים וגילוי
- **תמיכה מרובת ספקים**: עיון וגישה למודלי AI מ-Anthropic, OpenAI, GitHub, Google וספקים נוספים
- **אינטגרציה עם מודלים מקומיים**: גילוי פשוט של מודלי ONNX ו-Ollama לפריסת קצה
- **מודלים מ-GitHub**: אינטגרציה ישירה עם אירוח מודלים של GitHub לגישה חלקה
- **השוואת מודלים**: השוואת מודלים זה לצד זה למציאת האיזון האופטימלי למגבלות מכשירי קצה

### 2. Playground אינטראקטיבי
- **סביבת בדיקה אינטראקטיבית**: ניסויים מהירים עם יכולות מודלים בסביבה מבוקרת
- **תמיכה מרובת מצבים**: בדיקה עם תמונות, טקסט וקלטים נוספים האופייניים לתרחישי קצה
- **ניסויים בזמן אמת**: משוב מיידי על תגובות המודל וביצועיו
- **אופטימיזציית פרמטרים**: כוונון פרמטרי מודל לדרישות פריסת קצה

### 3. בונה פקודות (Agent Builder)
- **יצירת שפה טבעית**: יצירת פקודות התחלתיות באמצעות תיאורים בשפה טבעית
- **שיפור איטרטיבי**: שיפור פקודות בהתבסס על תגובות המודל וביצועיו
- **פירוק משימות**: פירוק משימות מורכבות באמצעות שרשור פקודות ותוצרים מובנים
- **תמיכה במשתנים**: שימוש במשתנים בפקודות להתנהגות דינמית של סוכנים
- **יצירת קוד לייצור**: יצירת קוד מוכן לייצור לפיתוח יישומים מהיר

### 4. הרצה והערכה בכמות גדולה
- **בדיקות מרובות מודלים**: הרצת פקודות מרובות על פני מודלים נבחרים בו-זמנית
- **בדיקות יעילות בקנה מידה**: בדיקת קלטים וקונפיגורציות שונות ביעילות
- **מקרי בדיקה מותאמים אישית**: הרצת סוכנים עם מקרי בדיקה לאימות פונקציונליות
- **השוואת ביצועים**: השוואת תוצאות בין מודלים וקונפיגורציות שונות

### 5. הערכת מודלים עם מערכי נתונים
- **מדדים סטנדרטיים**: בדיקת מודלי AI באמצעות מעריכי ביצועים מובנים (F1, רלוונטיות, דמיון, קוהרנטיות)
- **מעריכי ביצועים מותאמים אישית**: יצירת מדדי הערכה מותאמים אישית למקרי שימוש ספציפיים
- **אינטגרציה עם מערכי נתונים**: בדיקת מודלים מול מערכי נתונים מקיפים
- **מדידת ביצועים**: כימות ביצועי מודלים להחלטות פריסת קצה

### 6. יכולות כוונון עדין
- **התאמה אישית של מודלים**: התאמת מודלים למקרי שימוש ותחומים ספציפיים
- **התאמה מיוחדת**: התאמת מודלים לתחומים ודרישות מיוחדות
- **אופטימיזציה לקצה**: כוונון מודלים במיוחד למגבלות פריסת קצה
- **אימון ייחודי לתחום**: יצירת מודלים מותאמים למקרי שימוש ספציפיים בקצה

### 7. אינטגרציה עם כלי MCP
- **חיבור לכלים חיצוניים**: חיבור סוכנים לכלים חיצוניים באמצעות שרתי Model Context Protocol
- **פעולות בעולם האמיתי**: אפשרות לסוכנים לשאול מסדי נתונים, לגשת ל-APIs או לבצע לוגיקה מותאמת אישית
- **שרתי MCP קיימים**: שימוש בכלים מפרוטוקולי פקודה (stdio) או HTTP (אירועים מונחי שרת)
- **פיתוח MCP מותאם אישית**: בנייה והקמת שרתי MCP חדשים עם בדיקות ב-Agent Builder

### 8. פיתוח ובדיקת סוכנים
- **תמיכה בקריאות פונקציות**: אפשרות לסוכנים לקרוא פונקציות חיצוניות באופן דינמי
- **בדיקות אינטגרציה בזמן אמת**: בדיקת אינטגרציות עם הרצות בזמן אמת ושימוש בכלים
- **ניהול גרסאות סוכנים**: ניהול גרסאות לסוכנים עם יכולות השוואה לתוצאות הערכה
- **ניפוי באגים ומעקב**: יכולות מעקב וניפוי באגים מקומיות לפיתוח סוכנים

## תהליך פיתוח Edge AI

### שלב 1: גילוי ובחירת מודלים
1. **חקירת קטלוג המודלים**: השתמשו בקטלוג המודלים למציאת מודלים המתאימים לפריסת קצה
2. **השוואת ביצועים**: הערכת מודלים בהתבסס על גודל, דיוק ומהירות הסקה
3. **בדיקה מקומית**: השתמשו במודלי Ollama או ONNX לבדיקה מקומית לפני פריסת קצה
4. **הערכת דרישות משאבים**: קביעת צרכי זיכרון וחישוב למכשירי הקצה היעדיים

### שלב 2: אופטימיזציית מודלים
1. **המרה ל-ONNX**: המרת מודלים שנבחרו לפורמט ONNX לתאימות קצה
2. **יישום כימות**: הפחתת גודל המודל באמצעות כימות INT8 או INT4
3. **אופטימיזציית חומרה**: אופטימיזציה לחומרת הקצה היעדית (ARM, x86, מאיצים מיוחדים)
4. **אימות ביצועים**: אימות שמודלים מותאמים שומרים על דיוק מקובל

### שלב 3: פיתוח יישומים
1. **עיצוב סוכנים**: השתמשו ב-Agent Builder ליצירת סוכני AI מותאמים לקצה
2. **הנדסת פקודות**: פיתוח פקודות שעובדות ביעילות עם מודלים קטנים יותר לקצה
3. **בדיקות אינטגרציה**: בדיקת סוכנים בתנאי קצה מדומים
4. **יצירת קוד**: יצירת קוד ייצור מותאם לפריסת קצה

### שלב 4: הערכה ובדיקה
1. **הערכה בכמות גדולה**: בדיקת קונפיגורציות מרובות למציאת הגדרות אופטימליות לקצה
2. **פרופיל ביצועים**: ניתוח מהירות הסקה, שימוש בזיכרון ודיוק
3. **סימולציית קצה**: בדיקה בתנאים דומים לסביבת פריסת הקצה היעדית
4. **בדיקות עומס**: הערכת ביצועים תחת תנאי עומס שונים

### שלב 5: הכנה לפריסה
1. **אופטימיזציה סופית**: יישום אופטימיזציות סופיות בהתבסס על תוצאות הבדיקה
2. **אריזת פריסה**: אריזת מודלים וקוד לפריסת קצה
3. **תיעוד**: תיעוד דרישות הפריסה והקונפיגורציה
4. **הגדרת ניטור**: הכנת ניטור ורישום לפריסת קצה

## קהל יעד לפיתוח Edge AI

### מפתחי Edge AI
- מפתחי יישומים הבונים מכשירי קצה חכמים ופתרונות IoT
- מפתחי מערכות משובצות המשלבים יכולות AI במכשירים עם מגבלות משאבים
- מפתחי יישומים ניידים היוצרים יישומי AI על המכשיר לסמארטפונים וטאבלטים

### מהנדסי Edge AI
- מהנדסי AI המבצעים אופטימיזציה למודלים לפריסת קצה ומנהלים צינורות הסקה
- מהנדסי DevOps המפרסים ומנהלים מודלי AI בתשתית קצה מבוזרת
- מהנדסי ביצועים המבצעים אופטימיזציה לעומסי עבודה של AI למגבלות חומרת קצה

### חוקרים ומחנכים
- חוקרי AI המפתחים מודלים ואלגוריתמים יעילים למחשוב קצה
- מחנכים המלמדים מושגי Edge AI ומדגימים טכניקות אופטימיזציה
- סטודנטים הלומדים על האתגרים והפתרונות בפריסת Edge AI

## מקרי שימוש ב-Edge AI

### מכשירי IoT חכמים
- **זיהוי תמונות בזמן אמת**: פריסת מודלי ראייה ממוחשבת על מצלמות וחיישני IoT
- **עיבוד קול**: יישום זיהוי דיבור ועיבוד שפה טבעית על רמקולים חכמים
- **תחזוקה חזויה**: הרצת מודלי זיהוי אנומליות על מכשירי קצה תעשייתיים
- **ניטור סביבתי**: פריסת מודלי ניתוח נתוני חיישנים ליישומים סביבתיים

### יישומים ניידים ומשובצים
- **תרגום על המכשיר**: יישום מודלי תרגום שפות הפועלים במצב לא מקוון
- **מציאות רבודה**: פריסת זיהוי ועקיבה של אובייקטים בזמן אמת ליישומי AR
- **ניטור בריאות**: הרצת מודלי ניתוח בריאות על מכשירים לבישים וציוד רפואי
- **מערכות אוטונומיות**: יישום מודלי קבלת החלטות לרחפנים, רובוטים וכלי רכב

### תשתית מחשוב קצה
- **מרכזי נתונים בקצה**: פריסת מודלי AI במרכזי נתונים בקצה ליישומים בעלי זמן השהיה נמוך
- **אינטגרציה עם CDN**: שילוב יכולות עיבוד AI ברשתות אספקת תוכן
- **קצה 5G**: ניצול מחשוב קצה 5G ליישומים מבוססי AI
- **מחשוב ערפל**: יישום עיבוד AI בסביבות מחשוב ערפל

## התקנה והגדרה

### התקנת ההרחבה
התקינו את ההרחבה AI Toolkit ישירות מ-Marketplace של Visual Studio Code:

**מזהה ההרחבה**: `ms-windows-ai-studio.windows-ai-studio`

**שיטות התקנה**:
1. **Marketplace של VS Code**: חפשו "AI Toolkit" בתצוגת ההרחבות
2. **שורת הפקודה**: `code --install-extension ms-windows-ai-studio.windows-ai-studio`
3. **התקנה ישירה**: הורידו מ-[VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### דרישות מוקדמות לפיתוח Edge AI
- **Visual Studio Code**: מומלץ הגרסה האחרונה
- **סביבת Python**: Python 3.8+ עם ספריות AI נדרשות
- **ONNX Runtime** (אופציונלי): להסקת מודלי ONNX
- **Ollama** (אופציונלי): לשירות מודלים מקומי
- **כלי האצת חומרה**: CUDA, OpenVINO, או מאיצים ייחודיים לפלטפורמה

### הגדרה ראשונית
1. **הפעלת ההרחבה**: פתחו את VS Code ואמתו שערכת הכלים ל-AI מופיעה בסרגל הפעילות
2. **הגדרת ספקי מודלים**: הגדירו גישה ל-GitHub, OpenAI, Anthropic או ספקי מודלים אחרים
3. **סביבה מקומית**: הגדירו סביבת Python והתקינו חבילות נדרשות
4. **האצת חומרה**: הגדירו האצת GPU/NPU אם זמינה
5. **אינטגרציית MCP**: הגדירו שרתי Model Context Protocol אם נדרש

### רשימת בדיקה להגדרה ראשונית
- [ ] ההרחבה AI Toolkit הות
2. יצירת הנחיות התחלתיות באמצעות תיאורים בשפה טבעית  
3. חזרה ושיפור הנחיות על בסיס תגובות המודל  
4. שילוב כלי MCP לשיפור יכולות הסוכן  

#### שלב 3: בדיקה והערכה  
1. השתמשו ב-**Bulk Run** לבדיקת מספר הנחיות על פני מודלים נבחרים  
2. הריצו סוכנים עם מקרי בדיקה כדי לאמת את הפונקציונליות  
3. העריכו דיוק וביצועים באמצעות מדדים מובנים או מותאמים אישית  
4. השוו בין מודלים וקונפיגורציות שונות  

#### שלב 4: כיוונון ואופטימיזציה  
1. התאימו מודלים למקרי שימוש ייחודיים  
2. יישמו כיוונון ספציפי לתחום  
3. בצעו אופטימיזציה למגבלות פריסה בקצה  
4. גרסו והשוו בין קונפיגורציות סוכנים שונות  

#### שלב 5: הכנה לפריסה  
1. צרו קוד מוכן לייצור באמצעות Agent Builder  
2. הגדירו חיבורי שרת MCP לשימוש בייצור  
3. הכינו חבילות פריסה למכשירי קצה  
4. הגדירו מדדי ניטור והערכה  

## שיטות עבודה מומלצות לפיתוח AI בקצה  

### בחירת מודל  
- **מגבלות גודל**: בחרו מודלים שמתאימים למגבלות הזיכרון של מכשירי היעד  
- **מהירות הסקה**: תעדפו מודלים עם זמן הסקה מהיר ליישומים בזמן אמת  
- **פשרות דיוק**: איזנו בין דיוק המודל למגבלות משאבים  
- **תאימות פורמט**: העדיפו פורמטים כמו ONNX או פורמטים מותאמים לחומרה לפריסה בקצה  

### טכניקות אופטימיזציה  
- **כימות**: השתמשו בכימות INT8 או INT4 כדי להקטין את גודל המודל ולשפר את המהירות  
- **גיזום**: הסירו פרמטרים מיותרים במודל כדי להפחית דרישות חישוביות  
- **דיסטילציה ידע**: צרו מודלים קטנים יותר ששומרים על ביצועי מודלים גדולים  
- **האצת חומרה**: נצלו NPUs, GPUs או מאיצים ייעודיים כאשר הם זמינים  

### זרימת עבודה בפיתוח  
- **בדיקות חוזרות**: בצעו בדיקות בתנאים דמויי קצה במהלך הפיתוח  
- **ניטור ביצועים**: עקבו באופן רציף אחר שימוש במשאבים ומהירות הסקה  
- **שליטה בגרסאות**: עקבו אחר גרסאות מודלים והגדרות אופטימיזציה  
- **תיעוד**: תעדו את כל החלטות האופטימיזציה והפשרות בביצועים  

### שיקולי פריסה  
- **ניטור משאבים**: עקבו אחר זיכרון, CPU ושימוש באנרגיה בייצור  
- **אסטרטגיות גיבוי**: יישמו מנגנוני גיבוי לכשלים במודל  
- **מנגנוני עדכון**: תכננו עדכוני מודלים וניהול גרסאות  
- **אבטחה**: יישמו אמצעי אבטחה מתאימים ליישומי AI בקצה  

## שילוב עם מסגרות AI בקצה  

### ONNX Runtime  
- **פריסה חוצת פלטפורמות**: פרסו מודלים של ONNX על פני פלטפורמות קצה שונות  
- **אופטימיזציה לחומרה**: נצלו את האופטימיזציות הספציפיות לחומרה של ONNX Runtime  
- **תמיכה בניידים**: השתמשו ב-ONNX Runtime Mobile ליישומים בסמארטפונים וטאבלטים  
- **שילוב IoT**: פרסו במכשירי IoT באמצעות הפצות קלות של ONNX Runtime  

### Windows ML  
- **מכשירי Windows**: בצעו אופטימיזציה למכשירי קצה מבוססי Windows ומחשבים אישיים  
- **האצת NPU**: נצלו יחידות עיבוד עצבי במכשירי Windows  
- **DirectML**: השתמשו ב-DirectML להאצת GPU בפלטפורמות Windows  
- **שילוב UWP**: שלבו עם יישומי Universal Windows Platform  

### TensorFlow Lite  
- **אופטימיזציה לניידים**: פרסו מודלים של TensorFlow Lite במכשירים ניידים ומוטמעים  
- **נציגי חומרה**: השתמשו בנציגי חומרה ייעודיים להאצה  
- **מיקרו-בקרים**: פרסו במיקרו-בקרים באמצעות TensorFlow Lite Micro  
- **תמיכה חוצת פלטפורמות**: פרסו על פני Android, iOS ומערכות Linux מוטמעות  

### Azure IoT Edge  
- **היבריד ענן-קצה**: שלבו אימון בענן עם הסקה בקצה  
- **פריסת מודולים**: פרסו מודלים של AI כמודולים של IoT Edge  
- **ניהול מכשירים**: נהל מכשירי קצה ועדכוני מודלים מרחוק  
- **טלמטריה**: אספו נתוני ביצועים ומדדי מודלים מפריסות בקצה  

## תרחישים מתקדמים של AI בקצה  

### פריסת מודלים מרובים  
- **אנסמבל מודלים**: פרסו מספר מודלים לשיפור דיוק או יתירות  
- **בדיקות A/B**: בדקו מודלים שונים בו-זמנית במכשירי קצה  
- **בחירה דינמית**: בחרו מודלים על בסיס תנאי המכשיר הנוכחיים  
- **שיתוף משאבים**: בצעו אופטימיזציה לשימוש במשאבים על פני מודלים פרוסים מרובים  

### למידה מבוזרת  
- **אימון מבוזר**: אימנו מודלים על פני מספר מכשירי קצה  
- **שימור פרטיות**: שמרו על נתוני אימון מקומיים תוך שיתוף שיפורי מודלים  
- **למידה שיתופית**: אפשרו למכשירים ללמוד מניסיון קולקטיבי  
- **תיאום קצה-ענן**: תיאמו למידה בין מכשירי קצה לתשתית ענן  

### עיבוד בזמן אמת  
- **עיבוד זרמים**: עבדו זרמי נתונים רציפים במכשירי קצה  
- **הסקה בעלת השהיה נמוכה**: בצעו אופטימיזציה למינימום השהיה בהסקה  
- **עיבוד אצוות**: עבדו אצוות נתונים ביעילות במכשירי קצה  
- **עיבוד אדפטיבי**: התאימו עיבוד על בסיס יכולות המכשיר הנוכחיות  

## פתרון בעיות בפיתוח AI בקצה  

### בעיות נפוצות  
- **מגבלות זיכרון**: המודל גדול מדי עבור זיכרון המכשיר היעד  
- **מהירות הסקה**: ההסקה של המודל איטית מדי לדרישות בזמן אמת  
- **ירידת דיוק**: האופטימיזציה מפחיתה את דיוק המודל באופן בלתי מקובל  
- **תאימות חומרה**: המודל אינו תואם לחומרה היעד  

### אסטרטגיות דיבוג  
- **פרופיל ביצועים**: השתמשו בתכונות מעקב של AI Toolkit לזיהוי צווארי בקבוק  
- **ניטור משאבים**: עקבו אחר שימוש בזיכרון ו-CPU במהלך הפיתוח  
- **בדיקות הדרגתיות**: בדקו אופטימיזציות באופן הדרגתי כדי לבודד בעיות  
- **סימולציית חומרה**: השתמשו בכלי פיתוח לסימולציית חומרה יעד  

### פתרונות אופטימיזציה  
- **כימות נוסף**: יישמו טכניקות כימות אגרסיביות יותר  
- **ארכיטקטורת מודל**: שקלו ארכיטקטורות מודלים שונות המותאמות לקצה  
- **אופטימיזציית עיבוד מקדים**: בצעו אופטימיזציה לעיבוד נתונים מקדים למגבלות קצה  
- **אופטימיזציית הסקה**: השתמשו באופטימיזציות הסקה ספציפיות לחומרה  

## משאבים והשלבים הבאים  

### תיעוד רשמי  
- [תיעוד מפתחי AI Toolkit](https://aka.ms/AIToolkit/doc)  
- [מדריך התקנה והגדרה](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [תיעוד אפליקציות חכמות של VS Code](https://code.visualstudio.com/docs/intelligentapps)  
- [תיעוד פרוטוקול הקשר מודל (MCP)](https://modelcontextprotocol.io/)  

### קהילה ותמיכה  
- [מאגר GitHub של AI Toolkit](https://github.com/microsoft/vscode-ai-toolkit)  
- [בעיות ובקשות תכונה ב-GitHub](https://aka.ms/AIToolkit/feedback)  
- [קהילת Discord של Azure AI Foundry](https://aka.ms/azureaifoundry/discord)  
- [שוק הרחבות של VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### משאבים טכניים  
- [תיעוד ONNX Runtime](https://onnxruntime.ai/)  
- [תיעוד Ollama](https://ollama.ai/)  
- [תיעוד Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [תיעוד Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### מסלולי למידה  
- [קורס יסודות AI בקצה](../Module01/README.md)  
- [מדריך מודלים שפתיים קטנים](../Module02/README.md)  
- [אסטרטגיות פריסה בקצה](../Module03/README.md)  
- [פיתוח AI בקצה ב-Windows](./windowdeveloper.md)  

### משאבים נוספים  
- **סטטיסטיקות מאגר**: 1.8k+ כוכבים, 150+ מזלגות, 18+ תורמים  
- **רישיון**: רישיון MIT  
- **אבטחה**: מדיניות האבטחה של Microsoft חלה  
- **טלמטריה**: מכבד את הגדרות הטלמטריה של VS Code  

## סיכום  

AI Toolkit ל-Visual Studio Code מהווה פלטפורמה מקיפה לפיתוח AI מודרני, המספקת יכולות פיתוח סוכנים יעילות במיוחד ליישומי AI בקצה. עם קטלוג מודלים רחב התומך בספקים כמו Anthropic, OpenAI, GitHub ו-Google, בשילוב עם ביצוע מקומי באמצעות ONNX ו-Ollama, הכלי מציע את הגמישות הנדרשת לתרחישי פריסה מגוונים בקצה.

החוזק של הכלי טמון בגישה המשולבת שלו—מגילוי מודלים וניסויים ב-Playground ועד פיתוח סוכנים מתוחכם עם Prompt Builder, יכולות הערכה מקיפות ושילוב חלק של כלי MCP. עבור מפתחי AI בקצה, זה אומר יצירת אב-טיפוס מהירה ובדיקת סוכני AI לפני פריסה בקצה, עם יכולת לחזור במהירות ולבצע אופטימיזציה לסביבות מוגבלות משאבים.

יתרונות מרכזיים לפיתוח AI בקצה כוללים:  
- **ניסויים מהירים**: בדקו מודלים וסוכנים במהירות לפני התחייבות לפריסה בקצה  
- **גמישות רב-ספקית**: גשו למודלים ממקורות שונים כדי למצוא פתרונות אופטימליים לקצה  
- **פיתוח מקומי**: בדקו עם ONNX ו-Ollama לפיתוח לא מקוון ושומר פרטיות  
- **מוכנות לייצור**: צרו קוד מוכן לייצור ושילבו עם כלים חיצוניים באמצעות MCP  
- **הערכה מקיפה**: השתמשו במדדים מובנים ומותאמים אישית כדי לאמת ביצועי AI בקצה  

ככל ש-AI ממשיך לנוע לכיוון תרחישי פריסה בקצה, AI Toolkit ל-VS Code מספק את סביבת הפיתוח וזרימת העבודה הנדרשות לבנייה, בדיקה ואופטימיזציה של אפליקציות חכמות לסביבות מוגבלות משאבים. בין אם אתם מפתחים פתרונות IoT, אפליקציות AI לנייד או מערכות אינטליגנציה מוטמעות, סט התכונות המקיף של הכלי וזרימת העבודה המשולבת תומכים בכל מחזור החיים של פיתוח AI בקצה.

עם פיתוח מתמשך וקהילה פעילה (1.8k+ כוכבים ב-GitHub), AI Toolkit נשאר בחזית כלי הפיתוח ל-AI, ומתפתח באופן רציף כדי לענות על צרכי מפתחי AI מודרניים הבונים לתרחישי פריסה בקצה.

[Next Foundry Local](./foundrylocal.md)  

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.