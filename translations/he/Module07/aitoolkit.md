<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ab6b3d55f53ea3d498b3c067b17f8816",
  "translation_date": "2025-09-18T13:23:10+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "he"
}
-->
# ערכת כלים AI ל-Visual Studio Code - מדריך לפיתוח AI בקצה

## הקדמה

ברוכים הבאים למדריך המקיף לשימוש בערכת הכלים AI ל-Visual Studio Code בפיתוח AI בקצה. ככל שהבינה המלאכותית עוברת ממחשוב ענן מרכזי למכשירי קצה מבוזרים, מפתחים זקוקים לכלים חזקים ומשולבים שיכולים להתמודד עם האתגרים הייחודיים של פריסת קצה - החל ממגבלות משאבים ועד לדרישות לפעולה במצב לא מקוון.

ערכת הכלים AI ל-Visual Studio Code מגשרת על הפער הזה על ידי מתן סביבת פיתוח מלאה שתוכננה במיוחד לבניית, בדיקה ואופטימיזציה של יישומי AI שפועלים ביעילות על מכשירי קצה. בין אם אתם מפתחים עבור חיישני IoT, מכשירים ניידים, מערכות משובצות או שרתי קצה, ערכת הכלים הזו מפשטת את כל תהליך הפיתוח שלכם בתוך סביבת VS Code המוכרת.

מדריך זה ייקח אתכם דרך המושגים המרכזיים, הכלים והפרקטיקות הטובות ביותר לשימוש בערכת הכלים AI בפרויקטים שלכם בקצה, החל מבחירת מודל ראשונית ועד לפריסה בייצור.

## סקירה כללית

ערכת הכלים AI מספקת סביבת פיתוח משולבת לכל מחזור החיים של יישומי AI בקצה בתוך VS Code. היא מציעה אינטגרציה חלקה עם מודלים פופולריים מספקים כמו OpenAI, Anthropic, Google ו-GitHub, תוך תמיכה בפריסת מודלים מקומית באמצעות ONNX ו-Ollama - יכולות קריטיות ליישומי AI בקצה שדורשים הסקה על המכשיר.

מה שמייחד את ערכת הכלים AI לפיתוח בקצה הוא המיקוד שלה בכל צינור הפריסה בקצה. בניגוד לכלי פיתוח AI מסורתיים שמכוונים בעיקר לפריסת ענן, ערכת הכלים כוללת תכונות מיוחדות לאופטימיזציית מודלים, בדיקה בתנאים מוגבלי משאבים והערכת ביצועים ספציפית לקצה. הערכה מבינה שפיתוח AI בקצה דורש שיקולים שונים - גדלי מודלים קטנים יותר, זמני הסקה מהירים יותר, יכולת עבודה במצב לא מקוון ואופטימיזציות ספציפיות לחומרה.

הפלטפורמה תומכת בתרחישי פריסה מרובים, החל מהסקה פשוטה על המכשיר ועד לארכיטקטורות קצה מורכבות מרובות מודלים. היא מספקת כלים להמרת מודלים, כימות ואופטימיזציה שהם חיוניים לפריסה מוצלחת בקצה, תוך שמירה על פרודוקטיביות המפתחים ש-VS Code ידועה בה.

## מטרות למידה

בסיום המדריך הזה, תוכלו:

### מיומנויות בסיסיות
- **להתקין ולהגדיר** את ערכת הכלים AI ל-Visual Studio Code עבור תהליכי עבודה של פיתוח AI בקצה
- **לנווט ולהשתמש** בממשק ערכת הכלים AI, כולל קטלוג מודלים, סביבת ניסוי ובונה סוכנים
- **לבחור ולהעריך** מודלים AI המתאימים לפריסה בקצה בהתבסס על ביצועים ומגבלות משאבים
- **להמיר ולייעל** מודלים באמצעות פורמט ONNX וטכניקות כימות עבור מכשירי קצה

### מיומנויות פיתוח AI בקצה
- **לעצב וליישם** יישומי AI בקצה באמצעות סביבת הפיתוח המשולבת
- **לבצע בדיקות מודלים** בתנאים דמויי קצה באמצעות הסקה מקומית וניטור משאבים
- **ליצור ולהתאים אישית** סוכני AI המותאמים לתרחישי פריסה בקצה
- **להעריך ביצועי מודלים** באמצעות מדדים רלוונטיים למחשוב בקצה (זמן תגובה, שימוש בזיכרון, דיוק)

### אופטימיזציה ופריסה
- **ליישם טכניקות כימות וגיזום** כדי להקטין את גודל המודל תוך שמירה על ביצועים מקובלים
- **לייעל מודלים** לפלטפורמות חומרה ספציפיות בקצה כולל האצת CPU, GPU ו-NPU
- **ליישם פרקטיקות מומלצות** לפיתוח AI בקצה כולל ניהול משאבים ואסטרטגיות גיבוי
- **להכין מודלים ויישומים** לפריסה בייצור על מכשירי קצה

### מושגים מתקדמים ב-AI בקצה
- **להשתלב עם מסגרות AI בקצה** כולל ONNX Runtime, Windows ML ו-TensorFlow Lite
- **ליישם ארכיטקטורות מרובות מודלים** ותסריטי למידה מבוזרת עבור סביבות קצה
- **לפתור בעיות נפוצות ב-AI בקצה** כולל מגבלות זיכרון, מהירות הסקה ותאימות חומרה
- **לעצב אסטרטגיות ניטור ורישום** עבור יישומי AI בקצה בייצור

### יישום מעשי
- **לבנות פתרונות AI בקצה מקצה לקצה** מבחירת מודל ועד לפריסה
- **להפגין מיומנות** בתהליכי פיתוח ואופטימיזציה ספציפיים לקצה
- **ליישם מושגים שנלמדו** על מקרי שימוש אמיתיים ב-AI בקצה כולל IoT, ניידים ויישומים משובצים
- **להעריך ולהשוות** בין אסטרטגיות פריסה שונות בקצה והפשרות שלהן

## תכונות מרכזיות לפיתוח AI בקצה

### 1. קטלוג מודלים וגילוי
- **תמיכה במודלים מקומיים**: גלו גישה למודלים AI המותאמים במיוחד לפריסה בקצה
- **אינטגרציה עם ONNX**: גישה למודלים בפורמט ONNX להסקה יעילה בקצה
- **תמיכה ב-Ollama**: שימוש במודלים הפועלים מקומית דרך Ollama לפרטיות ועבודה במצב לא מקוון
- **השוואת מודלים**: השוו מודלים זה לצד זה כדי למצוא את האיזון האופטימלי בין ביצועים לצריכת משאבים עבור מכשירי קצה

### 2. סביבת ניסוי אינטראקטיבית
- **סביבת בדיקה מקומית**: בדקו מודלים מקומית לפני פריסה בקצה
- **ניסויים רב-מודליים**: בדקו עם תמונות, טקסט וקלטים אחרים אופייניים לתרחישי קצה
- **כיוונון פרמטרים**: נסו פרמטרים שונים של מודלים כדי להתאים למגבלות קצה
- **ניטור ביצועים בזמן אמת**: צפו במהירות הסקה ובשימוש במשאבים במהלך הפיתוח

### 3. בונה סוכנים ליישומי קצה
- **הנדסת הנחיות**: צרו הנחיות מותאמות שפועלות ביעילות עם מודלים קטנים יותר בקצה
- **אינטגרציה עם כלי MCP**: שלבו כלי Model Context Protocol לשיפור יכולות סוכנים בקצה
- **יצירת קוד**: צרו קוד מוכן לייצור המותאם לתרחישי פריסה בקצה
- **תוצרים מובנים**: עיצבו סוכנים המספקים תגובות עקביות ומובנות המתאימות ליישומי קצה

### 4. הערכת מודלים ובדיקה
- **מדדי ביצועים**: העריכו מודלים באמצעות מדדים רלוונטיים לפריסה בקצה (זמן תגובה, שימוש בזיכרון, דיוק)
- **בדיקות קבוצתיות**: בדקו תצורות מודלים מרובות בו-זמנית כדי למצוא הגדרות אופטימליות לקצה
- **הערכה מותאמת אישית**: צרו קריטריוני הערכה מותאמים ספציפיים למקרי שימוש ב-AI בקצה
- **פרופיל משאבים**: נתחו דרישות זיכרון וחישוב לתכנון פריסה בקצה

### 5. המרת מודלים ואופטימיזציה
- **המרה ל-ONNX**: המירו מודלים מפורמטים שונים ל-ONNX לתאימות בקצה
- **כימות**: הקטינו את גודל המודל ושפרו את מהירות ההסקה באמצעות טכניקות כימות
- **אופטימיזציה לחומרה**: ייעלו מודלים לחומרה ספציפית בקצה (CPU, GPU, NPU)
- **שינוי פורמט**: המירו מודלים מ-Hugging Face ומקורות אחרים לפריסה בקצה

### 6. התאמה אישית לתרחישי קצה
- **התאמת תחום**: התאימו מודלים למקרי שימוש וסביבות ספציפיות בקצה
- **אימון מקומי**: אימנו מודלים מקומית עם תמיכה ב-GPU לדרישות ספציפיות לקצה
- **אינטגרציה עם Azure**: השתמשו ב-Azure Container Apps לאימון בענן לפני פריסה בקצה
- **למידת העברה**: התאימו מודלים מאומנים מראש למשימות ומגבלות ספציפיות לקצה

### 7. ניטור ביצועים ומעקב
- **ניתוח ביצועים בקצה**: עקבו אחר ביצועי מודלים בתנאים דמויי קצה
- **איסוף מעקבים**: אספו נתוני ביצועים מפורטים לאופטימיזציה
- **זיהוי צווארי בקבוק**: זיהו בעיות ביצועים לפני פריסה למכשירי קצה
- **מעקב שימוש במשאבים**: עקבו אחר זיכרון, CPU וזמן הסקה לאופטימיזציה בקצה

## תהליך עבודה לפיתוח AI בקצה

### שלב 1: גילוי ובחירת מודלים
1. **חקירת קטלוג מודלים**: השתמשו בקטלוג המודלים כדי למצוא מודלים המתאימים לפריסה בקצה
2. **השוואת ביצועים**: העריכו מודלים בהתבסס על גודל, דיוק ומהירות הסקה
3. **בדיקה מקומית**: השתמשו ב-Ollama או מודלים ONNX לבדיקה מקומית לפני פריסה בקצה
4. **הערכת דרישות משאבים**: קבעו את צרכי הזיכרון והחישוב עבור מכשירי קצה יעד

### שלב 2: אופטימיזציית מודלים
1. **המרה ל-ONNX**: המירו מודלים שנבחרו לפורמט ONNX לתאימות בקצה
2. **יישום כימות**: הקטינו את גודל המודל באמצעות כימות INT8 או INT4
3. **אופטימיזציה לחומרה**: ייעלו לחומרה יעד בקצה (ARM, x86, מאיצים מיוחדים)
4. **אימות ביצועים**: ודאו שמודלים מותאמים שומרים על דיוק מקובל

### שלב 3: פיתוח יישומים
1. **עיצוב סוכנים**: השתמשו בבונה סוכנים ליצירת סוכני AI מותאמים לקצה
2. **הנדסת הנחיות**: פתחו הנחיות שפועלות ביעילות עם מודלים קטנים יותר
3. **בדיקות אינטגרציה**: בדקו סוכנים בתנאי קצה מדומים
4. **יצירת קוד**: צרו קוד מוכן לייצור המותאם לפריסה בקצה

### שלב 4: הערכה ובדיקה
1. **הערכה קבוצתית**: בדקו תצורות מרובות כדי למצוא הגדרות אופטימליות לקצה
2. **פרופיל ביצועים**: נתחו מהירות הסקה, שימוש בזיכרון ודיוק
3. **סימולציית קצה**: בדקו בתנאים דומים לסביבת פריסה יעד בקצה
4. **בדיקות עומס**: העריכו ביצועים תחת תנאי עומס שונים

### שלב 5: הכנה לפריסה
1. **אופטימיזציה סופית**: יישמו אופטימיזציות סופיות בהתבסס על תוצאות בדיקה
2. **אריזת פריסה**: ארזו מודלים וקוד לפריסה בקצה
3. **תיעוד**: תעדו דרישות פריסה והגדרות
4. **הגדרת ניטור**: הכינו ניטור ורישום לפריסה בייצור

## קהל יעד לפיתוח AI בקצה

### מפתחי AI בקצה
- מפתחי יישומים הבונים מכשירי קצה ופתרונות IoT מבוססי AI
- מפתחי מערכות משובצות המשלבים יכולות AI במכשירים מוגבלי משאבים
- מפתחי ניידים היוצרים יישומי AI על המכשיר עבור סמארטפונים וטאבלטים

### מהנדסי AI בקצה
- מהנדסי AI המייעלים מודלים לפריסה בקצה ומנהלים צינורות הסקה
- מהנדסי DevOps המפרסים ומנהלים מודלים AI בתשתית קצה מבוזרת
- מהנדסי ביצועים המייעלים עומסי עבודה AI למגבלות חומרה בקצה

### חוקרים ומחנכים
- חוקרי AI המפתחים מודלים ואלגוריתמים יעילים למחשוב בקצה
- מחנכים המלמדים מושגי AI בקצה ומדגימים טכניקות אופטימיזציה
- סטודנטים הלומדים על האתגרים והפתרונות בפריסת AI בקצה

## מקרי שימוש ב-AI בקצה

### מכשירי IoT חכמים
- **זיהוי תמונות בזמן אמת**: פריסת מודלים ראייה ממוחשבת על מצלמות וחיישני IoT
- **עיבוד קול**: יישום זיהוי דיבור ועיבוד שפה טבעית על רמקולים חכמים
- **תחזוקה חזויה**: הפעלת מודלים לזיהוי אנומליות על מכשירים תעשייתיים בקצה
- **ניטור סביבתי**: פריסת מודלים לניתוח נתוני חיישנים ליישומים סביבתיים

### יישומים ניידים ומשובצים
- **תרגום על המכשיר**: יישום מודלים לתרגום שפות שפועלים במצב לא מקוון
- **מציאות רבודה**: פריסת זיהוי ועקיבה בזמן אמת עבור יישומי AR
- **ניטור בריאות**: הפעלת מודלים לניתוח בריאות על מכשירים לבישים וציוד רפואי
- **מערכות אוטונומיות**: יישום מודלים לקבלת החלטות עבור רחפנים, רובוטים ורכבים

### תשתית מחשוב בקצה
- **מרכזי נתונים בקצה**: פריסת מודלים AI במרכזי נתונים בקצה ליישומים בעלי זמן תגובה נמוך
- **אינטגרציה עם CDN**: שילוב יכולות עיבוד AI ברשתות אספקת תוכן
- **קצה 5G**: ניצול מחשוב קצה 5G ליישומים מבוססי AI
- **מחשוב ערפל**: יישום עיבוד AI בסביבות מחשוב ערפל

## התקנה והגדרה

### התקנה מהירה
התקינו את הרחבת ערכת הכלים AI ישירות מ-Marketplace של Visual Studio Code:

```
Install: AI Toolkit for Visual Studio Code (ms-windows-ai-studio.windows-ai-studio)
```

### דרישות מוקדמות לפיתוח AI בקצה
- **ONNX Runtime**: התקינו ONNX Runtime להסקת מודלים
- **Ollama** (אופציונלי): התקינו Ollama לשירות מודלים מקומי
- **סביבת Python**: הגדירו Python עם ספריות AI נדרשות
- **כלי חומרה לקצה**: התקינו כלי פיתוח ספציפיים לחומרה (CUDA, OpenVINO וכו')

### הגדרה ראשונית
1. פתחו את VS Code והתקינו את הרחבת ערכת הכלים AI
2. הגדירו מקורות מודלים (ONNX, Ollama, ספקי ענן)
3. הגדירו סביבת פיתוח מקומית לבדיקות קצה
4. הגדירו אפשרויות האצת חומרה למחשב הפיתוח שלכם

## התחלת עבודה עם פיתוח AI בקצה

### שלב 1: בחירת מודל
1. פתחו את תצוגת ערכת הכלים AI בסרגל הפעילות
2. עיינו בקטלוג המודלים למודלים תואמי קצה
3. סננו לפי גודל מודל, פורמט (ONNX) ומאפייני ביצועים
4. השוו מודלים באמצעות כלי ההשוואה המובנים

### שלב 2: בדיקה מקומית
1. השתמשו בסביבת הניסוי לבדיקת מודלים שנבחרו מקומית
2. נסו הנחיות ופרמטרים שונים
3. עקבו אחר מדדי ביצועים במהלך הבדיקה
4. העריכו תגובות מודלים לדרישות מקרי שימוש בקצה

### שלב 3: אופטימיזציית מודלים
1. השתמשו בכלי המרת מודלים לאופטימיזציה לפריסה בקצה
2. יישמו כימות להקטנת גודל המודל
3. בדקו מודלים מותאמים כדי להבטיח ביצועים מקובלים
4. תעדו הגדרות אופטימיזציה והפשרות ביצועים

### שלב 4: פיתוח סוכנים
1. השתמשו בבונה סוכנים ליצירת סוכני AI מותאמים לקצה
2. פתחו הנחיות שפועלות ביעילות עם מודלים קטנים יותר
3. שלבו כלים ו-APIs נדרשים לתרחישי קצה
- **אבטחה**: יש ליישם אמצעי אבטחה מתאימים עבור יישומי AI בקצה

## אינטגרציה עם מסגרות AI בקצה

### ONNX Runtime
- **פריסה חוצת פלטפורמות**: פריסת מודלים של ONNX על פני פלטפורמות קצה שונות  
- **אופטימיזציה לחומרה**: ניצול האופטימיזציות הייחודיות לחומרה של ONNX Runtime  
- **תמיכה במובייל**: שימוש ב-ONNX Runtime Mobile עבור יישומים בסמארטפונים וטאבלטים  
- **אינטגרציה עם IoT**: פריסה על מכשירי IoT באמצעות גרסאות קלות משקל של ONNX Runtime  

### Windows ML
- **מכשירי Windows**: אופטימיזציה למכשירי קצה ומחשבים מבוססי Windows  
- **האצת NPU**: ניצול יחידות עיבוד עצביות (NPU) במכשירי Windows  
- **DirectML**: שימוש ב-DirectML להאצת GPU בפלטפורמות Windows  
- **אינטגרציה עם UWP**: שילוב עם יישומי Universal Windows Platform  

### TensorFlow Lite
- **אופטימיזציה למובייל**: פריסת מודלים של TensorFlow Lite על מכשירים ניידים ומוטמעים  
- **נציגי חומרה**: שימוש בנציגי חומרה ייעודיים להאצה  
- **מיקרו-בקרים**: פריסה על מיקרו-בקרים באמצעות TensorFlow Lite Micro  
- **תמיכה חוצת פלטפורמות**: פריסה על Android, iOS ומערכות Linux מוטמעות  

### Azure IoT Edge
- **היבריד ענן-קצה**: שילוב בין אימון בענן לבין הסקת מסקנות בקצה  
- **פריסת מודולים**: פריסת מודלים של AI כמודולים של IoT Edge  
- **ניהול מכשירים**: ניהול מכשירי קצה ועדכוני מודלים מרחוק  
- **טלמטריה**: איסוף נתוני ביצועים ומדדי מודלים מפריסות בקצה  

## תרחישים מתקדמים של AI בקצה

### פריסת מודלים מרובים
- **אנסמבלים של מודלים**: פריסת מספר מודלים לשיפור דיוק או יתירות  
- **בדיקות A/B**: בדיקת מודלים שונים בו-זמנית על מכשירי קצה  
- **בחירה דינמית**: בחירת מודלים בהתאם לתנאי המכשיר הנוכחיים  
- **שיתוף משאבים**: אופטימיזציה של שימוש במשאבים בין מודלים פרוסים  

### למידה מבוזרת (Federated Learning)
- **אימון מבוזר**: אימון מודלים על פני מספר מכשירי קצה  
- **שמירה על פרטיות**: שמירת נתוני האימון מקומיים תוך שיתוף שיפורי מודלים  
- **למידה שיתופית**: אפשרות למכשירים ללמוד מניסיון קולקטיבי  
- **תיאום קצה-ענן**: תיאום למידה בין מכשירי קצה לתשתית ענן  

### עיבוד בזמן אמת
- **עיבוד זרמים**: עיבוד נתונים רציפים על מכשירי קצה  
- **הסקת מסקנות בזמן אמת**: אופטימיזציה למינימום זמן השהיה בהסקת מסקנות  
- **עיבוד באצוות**: עיבוד יעיל של אצוות נתונים על מכשירי קצה  
- **עיבוד אדפטיבי**: התאמת העיבוד בהתאם ליכולות המכשיר הנוכחיות  

## פתרון בעיות בפיתוח AI בקצה

### בעיות נפוצות
- **מגבלות זיכרון**: מודל גדול מדי עבור זיכרון המכשיר היעד  
- **מהירות הסקה**: הסקת מסקנות איטית מדי לדרישות בזמן אמת  
- **ירידת דיוק**: אופטימיזציה שמפחיתה את דיוק המודל באופן בלתי קביל  
- **תאימות חומרה**: מודל שאינו תואם לחומרה היעד  

### אסטרטגיות דיבוג
- **פרופיל ביצועים**: שימוש בתכונות מעקב של AI Toolkit לזיהוי צווארי בקבוק  
- **מעקב משאבים**: מעקב אחר שימוש בזיכרון ובמעבד במהלך הפיתוח  
- **בדיקות הדרגתיות**: בדיקת אופטימיזציות באופן הדרגתי כדי לבודד בעיות  
- **סימולציית חומרה**: שימוש בכלי פיתוח לסימולציה של חומרת היעד  

### פתרונות אופטימיזציה
- **כימות נוסף**: יישום טכניקות כימות אגרסיביות יותר  
- **ארכיטקטורת מודל**: שקילת ארכיטקטורות מודלים שונות המותאמות לקצה  
- **אופטימיזציית עיבוד מקדים**: אופטימיזציה של עיבוד הנתונים המוקדם למגבלות הקצה  
- **אופטימיזציית הסקה**: שימוש באופטימיזציות הסקה ייחודיות לחומרה  

## משאבים והשלבים הבאים

### תיעוד
- [מדריך מודלים של AI Toolkit](https://code.visualstudio.com/docs/intelligentapps/models)  
- [תיעוד Model Playground](https://code.visualstudio.com/docs/intelligentapps/playground)  
- [תיעוד ONNX Runtime](https://onnxruntime.ai/)  
- [תיעוד Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  

### קהילה ותמיכה
- [GitHub של VS Code AI Toolkit](https://github.com/microsoft/vscode-ai-toolkit)  
- [קהילת ONNX](https://github.com/onnx/onnx)  
- [קהילת מפתחי Edge AI](https://docs.microsoft.com/en-us/azure/iot-edge/community)  
- [Marketplace של תוספי VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### משאבי למידה
- [קורס יסודות AI בקצה](./Module01/README.md)  
- [מדריך מודלים קטנים](./Module02/README.md)  
- [אסטרטגיות פריסה בקצה](./Module03/README.md)  
- [פיתוח AI בקצה עבור Windows](./windowdeveloper.md)  

## סיכום

AI Toolkit עבור Visual Studio Code מספק פלטפורמה מקיפה לפיתוח AI בקצה, החל מגילוי ואופטימיזציה של מודלים ועד לפריסה ומעקב. באמצעות הכלים והזרימות המשולבות שלו, מפתחים יכולים ליצור, לבדוק ולפרוס יישומי AI הפועלים ביעילות על מכשירי קצה עם משאבים מוגבלים.

התמיכה של הכלי ב-ONNX, Ollama וספקי ענן שונים, בשילוב עם יכולות האופטימיזציה וההערכה שלו, הופכת אותו לבחירה אידיאלית לפיתוח AI בקצה. בין אם אתם בונים יישומי IoT, תכונות AI למובייל, או מערכות בינה מוטמעות, AI Toolkit מספק את הכלים והזרימות הדרושים לפריסה מוצלחת של AI בקצה.

ככל ש-AI בקצה ממשיך להתפתח, AI Toolkit עבור VS Code נשאר בחזית, ומספק למפתחים כלים ויכולות מתקדמות לבניית הדור הבא של יישומי קצה חכמים.

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.