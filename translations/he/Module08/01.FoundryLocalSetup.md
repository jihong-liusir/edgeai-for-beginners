<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "93c0b94f58ff29d3227dc67797b93d23",
  "translation_date": "2025-09-22T21:50:56+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "he"
}
-->
# מפגש 1: התחלת עבודה עם Foundry Local

## סקירה כללית

Microsoft Foundry Local מביא את יכולות Azure AI Foundry ישירות לסביבת הפיתוח של Windows 11, ומאפשר פיתוח AI עם שמירה על פרטיות, זמן תגובה נמוך וכלים ברמה ארגונית. מפגש זה מכסה התקנה מלאה, הגדרה ופריסה מעשית של מודלים פופולריים כולל phi, qwen, deepseek ו-GPT-OSS-20B.

## מטרות למידה

בסיום המפגש, תוכלו:
- להתקין ולהגדיר את Foundry Local על Windows 11
- לשלוט בפקודות CLI ובאפשרויות הגדרה
- להבין אסטרטגיות שמירת מודלים לשיפור ביצועים
- להריץ בהצלחה את מודלי phi, qwen, deepseek ו-GPT-OSS-20B
- ליצור את אפליקציית ה-AI הראשונה שלכם באמצעות Foundry Local

## דרישות מקדימות

### דרישות מערכת
- **Windows 11**: גרסה 22H2 או מאוחרת יותר
- **RAM**: מינימום 16GB, מומלץ 32GB
- **אחסון**: 50GB פנויים למודלים ולמטמון
- **חומרה**: מכשיר עם NPU או GPU מומלץ (Copilot+ PC או GPU של NVIDIA)
- **רשת**: אינטרנט מהיר להורדת מודלים

### סביבת פיתוח
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion
```

## חלק 1: התקנה והגדרה

### שלב 1: התקנת Foundry Local

התקינו את Foundry Local באמצעות Winget או הורידו את המתקין מ-GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### שלב 2: אימות התקנה

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## חלק 2: הבנת CLI

### מבנה פקודות מרכזי

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## חלק 3: ניהול ושמירת מודלים

Foundry Local מיישם שמירת מודלים חכמה לשיפור ביצועים ואחסון:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## חלק 4: פריסת מודלים מעשית

### הרצת מודלים של Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### עבודה עם מודלים של Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### הרצת מודלים של DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### הרצת GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## חלק 5: יצירת אפליקציה ראשונה

### ממשק צ'אט פשוט (API תואם OpenAI)

צרו אפליקציית צ'אט בסיסית באמצעות ה-API של Foundry Local התואם ל-OpenAI. ודאו שמודל פועל בחלון טרמינל אחר.

```python
# chat_app.py
import requests
import os

class FoundryLocalChat:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:8000")
        self.api_key = os.getenv("OPENAI_API_KEY", "local-key")
        self.conversation_history = []
    
    def send_message(self, message):
        payload = {
            "model": self.model_name,
            "messages": self.conversation_history + [{"role": "user", "content": message}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {self.api_key}"}
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        result = response.json()
        assistant_message = result["choices"][0]["message"]["content"]
        self.conversation_history.append({"role": "user", "content": message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message

if __name__ == "__main__":
    chat = FoundryLocalChat()
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        try:
            response = chat.send_message(user_input)
            print(f"Assistant: {response}\n")
        except Exception as e:
            print(f"Error: {e}\n")
```

### הרצת אפליקציית הצ'אט

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Configure environment for OpenAI-compatible SDKs/clients (optional)
setx OPENAI_BASE_URL http://localhost:8000
setx OPENAI_API_KEY local-key

# Run the chat app
python chat_app.py
```

## חלק 6: פתרון בעיות והמלצות

### בעיות נפוצות ופתרונות

```powershell
# Issue: Model fails to start
foundry model list
foundry model run phi-4-mini --verbose

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal
```

### ניטור משאבי מערכת (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### המלצות

- העדיפו פקודות `foundry model ...`, `foundry cache ...`, ו-`foundry service ...` (ראו את מדריך CLI)
- שדרגו באופן קבוע כדי לגשת למודלים ותיקונים חדשים
- התחילו עם מודלים קטנים (Phi mini, Qwen 7B) והתקדמו למודלים גדולים יותר
- עקבו אחרי CPU/GPU/זיכרון בזמן כיוונון הנחיות והגדרות

## חלק 7: תרגילים מעשיים

### תרגיל 1: הרצת מודלים מרובים במהירות

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### תרגיל 2: מדידת זמן תגובה בסיסית

```python
# benchmark.py
import time
import requests

def test_model(model_name, prompt="Explain machine learning in 50 words."):
    start = time.time()
    r = requests.post("http://localhost:8000/v1/completions", json={
        "model": model_name,
        "prompt": prompt,
        "max_tokens": 128
    }, timeout=60)
    elapsed = time.time() - start
    r.raise_for_status()
    return {"model": model_name, "latency_sec": round(elapsed, 3)}

for m in ["phi-4-mini", "qwen2.5-7b-instruct"]:
    print(test_model(m))
```

## מקורות

- התחלת עבודה עם Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- מדריך CLI וסקירת פקודות: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- קומפילציה של מודלים Hugging Face עבור Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Microsoft Foundry Local ב-GitHub: https://github.com/microsoft/Foundry-Local

---

