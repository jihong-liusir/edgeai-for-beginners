<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6cf75ae5b01949656a3ad41425c7ffe4",
  "translation_date": "2025-09-17T21:23:23+00:00",
  "source_file": "Module03/README.md",
  "language_code": "ne"
}
-->
# अध्याय ०३: साना भाषा मोडेलहरू (SLMs) को परिनियोजन

यो विस्तृत अध्यायले साना भाषा मोडेलहरू (SLMs) को परिनियोजनको सम्पूर्ण जीवनचक्रलाई अन्वेषण गर्दछ, जसमा सैद्धान्तिक आधार, व्यावहारिक कार्यान्वयन रणनीतिहरू, र उत्पादन-तयार कन्टेनराइज्ड समाधानहरू समावेश छन्। अध्यायलाई तीन प्रगतिशील खण्डहरूमा संरचित गरिएको छ, जसले पाठकहरूलाई आधारभूत अवधारणाबाट उन्नत परिनियोजन परिदृश्यसम्म लैजान्छ।

## अध्यायको संरचना र सिकाइ यात्रा

### **[खण्ड १: SLM उन्नत सिकाइ - आधारभूत र अनुकूलन](./01.SLMAdvancedLearning.md)**
खण्डको सुरुवातले साना भाषा मोडेलहरू बुझ्न र किन तिनीहरू किनार AI परिनियोजनहरूमा रणनीतिक रूपमा महत्त्वपूर्ण छन् भन्ने सैद्धान्तिक आधार तयार गर्दछ। यस खण्डमा समावेश छन्:

- **प्यारामिटर वर्गीकरण फ्रेमवर्क**: माइक्रो SLMs (१००M-१.४B प्यारामिटरहरू) देखि मिडियम SLMs (१४B-३०B प्यारामिटरहरू) सम्मका SLM कोटिहरूको विस्तृत अन्वेषण, Phi-4-mini-3.8B, Qwen3 श्रृंखला, र Google Gemma3 जस्ता मोडेलहरूमा विशेष ध्यान, प्रत्येक मोडेल स्तरको लागि हार्डवेयर आवश्यकताहरू र मेमोरी खपत विश्लेषण
- **उन्नत अनुकूलन प्रविधिहरू**: Llama.cpp, Microsoft Olive, र Apple MLX फ्रेमवर्कहरू प्रयोग गरेर क्वान्टाइजेसन विधिहरूको व्यापक कभरेज, BitNET 1-bit क्वान्टाइजेसनका नवीनतम प्रविधिहरूसहित, क्वान्टाइजेसन पाइपलाइन र बेंचमार्किङ परिणामहरू देखाउने व्यावहारिक कोड उदाहरणहरू
- **मोडेल प्राप्ति रणनीतिहरू**: Hugging Face इकोसिस्टम र Azure AI Foundry Model Catalog को गहिरो विश्लेषण, जसमा प्रोग्रामेटिक मोडेल डाउनलोड, मान्यकरण, र ढाँचा रूपान्तरणका लागि कोड नमूनाहरू
- **डेभलपर APIs**: Python, C++, र C# मा मोडेल लोड गर्ने, इन्फरेन्स गर्ने, र PyTorch, TensorFlow, र ONNX Runtime जस्ता लोकप्रिय फ्रेमवर्कहरूसँग एकीकृत गर्ने कोड उदाहरणहरू

यो आधारभूत खण्डले SLMs लाई किनार कम्प्युटिङ परिदृश्यहरूको लागि आदर्श बनाउने सञ्चालन दक्षता, परिनियोजन लचिलोपन, र लागत-प्रभावकारिताबीचको सन्तुलनलाई जोड दिन्छ, जसमा डेभलपरहरूले आफ्ना परियोजनाहरूमा सिधै कार्यान्वयन गर्न सक्ने व्यावहारिक कोड उदाहरणहरू छन्।

### **[खण्ड २: स्थानीय वातावरण परिनियोजन - गोपनीयता-प्रथम समाधानहरू](./02.DeployingSLMinLocalEnv.md)**
दोस्रो खण्डले सिद्धान्तबाट व्यावहारिक कार्यान्वयनतर्फ रूपान्तरण गर्दछ, जसले डाटा सार्वभौमिकता र सञ्चालन स्वतन्त्रतालाई प्राथमिकता दिने स्थानीय परिनियोजन रणनीतिहरूमा ध्यान केन्द्रित गर्दछ। मुख्य क्षेत्रहरू समावेश छन्:

- **Ollama Universal Platform**: क्रस-प्ल्याटफर्म परिनियोजनको व्यापक अन्वेषण, जसमा डेभलपर-मैत्री कार्यप्रवाहहरू, मोडेल जीवनचक्र व्यवस्थापन, र Modelfiles मार्फत अनुकूलन, REST API एकीकरण उदाहरणहरू र CLI स्वचालन स्क्रिप्टहरू सहित
- **Microsoft Foundry Local**: ONNX-आधारित अनुकूलन, Windows ML एकीकरण, र व्यापक सुरक्षा सुविधाहरू सहितको उद्यम-स्तरीय परिनियोजन समाधानहरू, जसमा देशीय अनुप्रयोग एकीकरणका लागि C# र Python कोड उदाहरणहरू
- **तुलनात्मक विश्लेषण**: प्राविधिक वास्तुकला, प्रदर्शन विशेषताहरू, र प्रयोग केस अनुकूलन दिशानिर्देशहरू समेट्ने विस्तृत फ्रेमवर्क तुलना, विभिन्न हार्डवेयरमा इन्फरेन्स गति र मेमोरी प्रयोग मूल्याङ्कन गर्न बेंचमार्क कोड सहित
- **API एकीकरण**: स्थानीय SLM परिनियोजनहरू प्रयोग गरेर वेब सेवाहरू, च्याट अनुप्रयोगहरू, र डाटा प्रशोधन पाइपलाइनहरू निर्माण गर्ने तरिका देखाउने नमूना अनुप्रयोगहरू, Node.js, Python Flask/FastAPI, र ASP.NET Core मा कोड उदाहरणहरू सहित
- **परीक्षण फ्रेमवर्कहरू**: मोडेल गुणस्तर सुनिश्चितताका लागि स्वचालित परीक्षण दृष्टिकोणहरू, SLM कार्यान्वयनहरूको लागि युनिट र एकीकरण परीक्षण उदाहरणहरू सहित

यो खण्डले गोपनीयता-संरक्षण गर्ने AI समाधानहरू कार्यान्वयन गर्न खोज्ने संगठनहरूलाई व्यावहारिक मार्गदर्शन प्रदान गर्दछ, जसले उनीहरूको विशिष्ट आवश्यकताहरूमा अनुकूलन गर्न सकिने तयार-प्रयोग कोड नमूनाहरू समावेश गर्दछ।

### **[खण्ड ३: कन्टेनराइज्ड क्लाउड परिनियोजन - उत्पादन-स्तरीय समाधानहरू](./03.DeployingSLMinCloud.md)**
अन्तिम खण्डले उन्नत कन्टेनराइज्ड परिनियोजन रणनीतिहरूमा समापन गर्दछ, जसमा Microsoft को Phi-4-mini-instruct प्राथमिक केस स्टडीको रूपमा प्रस्तुत गरिएको छ। यस खण्डमा समावेश छन्:

- **vLLM परिनियोजन**: OpenAI-संगत APIs, उन्नत GPU एक्सेलेरेशन, र उत्पादन-स्तरीय कन्फिगरेसनसहित उच्च-प्रदर्शन इन्फरेन्स अनुकूलन, जसमा पूर्ण Dockerfiles, Kubernetes म्यानिफेस्टहरू, र प्रदर्शन ट्युनिङ प्यारामिटरहरू
- **Ollama कन्टेनर अर्केस्ट्रेसन**: Docker Compose प्रयोग गरेर सरलीकृत परिनियोजन कार्यप्रवाहहरू, मोडेल अनुकूलन भेरियन्टहरू, र वेब UI एकीकरण, स्वचालित परिनियोजन र परीक्षणका लागि CI/CD पाइपलाइन उदाहरणहरू सहित
- **ONNX Runtime कार्यान्वयन**: व्यापक मोडेल रूपान्तरण, क्वान्टाइजेसन रणनीतिहरू, र क्रस-प्ल्याटफर्म अनुकूलतासहितको किनार-उन्मुख परिनियोजन, मोडेल अनुकूलन र परिनियोजनका लागि विस्तृत कोड नमूनाहरू सहित
- **अनुगमन र अवलोकनीयता**: SLM प्रदर्शन अनुगमनका लागि कस्टम मेट्रिक्ससहित Prometheus/Grafana ड्यासबोर्डहरूको कार्यान्वयन, जसमा अलर्ट कन्फिगरेसन र लग एग्रिगेसन
- **लोड ब्यालेन्सिङ र स्केलिङ**: CPU/GPU उपयोग र अनुरोध ढाँचाहरूमा आधारित स्वचालित स्केलिङ कन्फिगरेसनसहित क्षैतिज र ठाडो स्केलिङ रणनीतिहरूका व्यावहारिक उदाहरणहरू
- **सुरक्षा सुदृढीकरण**: कन्टेनर सुरक्षा उत्कृष्ट अभ्यासहरू, जसमा विशेषाधिकार घटाउने, नेटवर्क नीतिहरू, र API कुञ्जीहरू र मोडेल पहुँच प्रमाणहरूका लागि गोप्य व्यवस्थापन

प्रत्येक परिनियोजन दृष्टिकोणलाई पूर्ण कन्फिगरेसन उदाहरणहरू, परीक्षण प्रक्रियाहरू, उत्पादन तयारी चेकलिस्टहरू, र डेभलपरहरूले आफ्ना परिनियोजन कार्यप्रवाहहरूमा सिधै लागू गर्न सक्ने इन्फ्रास्ट्रक्चर-एज-कोड टेम्प्लेटहरूसहित प्रस्तुत गरिएको छ।

## प्रमुख सिकाइ परिणामहरू

यो अध्याय पूरा गरेर, पाठकहरूले निम्न कुरामा निपुणता हासिल गर्नेछन्:

1. **रणनीतिक मोडेल चयन**: स्रोत सीमाहरू र प्रदर्शन आवश्यकताहरूको आधारमा उपयुक्त SLMs चयन गर्ने
2. **अनुकूलन निपुणता**: विभिन्न फ्रेमवर्कहरूमा उन्नत क्वान्टाइजेसन प्रविधिहरू कार्यान्वयन गरेर प्रदर्शन-दक्षताको सन्तुलन हासिल गर्ने
3. **परिनियोजन लचिलोपन**: स्थानीय गोपनीयता-केंद्रित समाधानहरू र स्केलेबल कन्टेनराइज्ड परिनियोजनहरू बीच छनोट गर्ने
4. **उत्पादन तयारी**: उद्यम-स्तरीय SLM परिनियोजनहरूको लागि अनुगमन, सुरक्षा, र स्केलिङ प्रणालीहरू कन्फिगर गर्ने

## व्यावहारिक ध्यान र वास्तविक-विश्व अनुप्रयोगहरू

अध्यायले सम्पूर्ण रूपमा बलियो व्यावहारिक अभिमुखता कायम राख्छ, जसमा समावेश छन्:

- **ह्यान्ड्स-अन उदाहरणहरू**: पूर्ण कन्फिगरेसन फाइलहरू, API परीक्षण प्रक्रियाहरू, र परिनियोजन स्क्रिप्टहरू
- **प्रदर्शन बेंचमार्किङ**: इन्फरेन्स गति, मेमोरी प्रयोग, र स्रोत आवश्यकताहरूको विस्तृत तुलना
- **सुरक्षा विचारहरू**: उद्यम-स्तरीय सुरक्षा अभ्यासहरू, अनुपालन फ्रेमवर्कहरू, र डाटा संरक्षण रणनीतिहरू
- **सर्वोत्तम अभ्यासहरू**: अनुगमन, स्केलिङ, र मर्मतका लागि उत्पादन-प्रमाणित दिशानिर्देशहरू

## भविष्य-तयार दृष्टिकोण

अध्यायले उदीयमान प्रवृत्तिहरूमा अगाडि हेर्ने अन्तर्दृष्टिहरूसहित निष्कर्ष निकाल्छ, जसमा समावेश छन्:

- सुधारिएको दक्षता अनुपातहरूसहित उन्नत मोडेल आर्किटेक्चरहरू
- विशेष AI एक्सेलेरेटरहरूसँग गहिरो हार्डवेयर एकीकरण
- मानकीकरण र अन्तरसञ्चालनतर्फको इकोसिस्टम विकास
- गोपनीयता र अनुपालन आवश्यकताहरूले प्रेरित उद्यम अपनाउने ढाँचाहरू

यो व्यापक दृष्टिकोणले सुनिश्चित गर्दछ कि पाठकहरू हालका SLM परिनियोजन चुनौतीहरू र भविष्यका प्राविधिक विकासहरू दुवैलाई नेभिगेट गर्न राम्रोसँग सुसज्जित छन्, आफ्ना विशिष्ट संगठनात्मक आवश्यकताहरू र सीमाहरूको साथ मेल खाने सूचित निर्णयहरू लिने। 

अध्यायले तत्काल कार्यान्वयनका लागि व्यावहारिक मार्गदर्शक र दीर्घकालीन AI परिनियोजन योजना बनाउने रणनीतिक स्रोतको रूपमा सेवा गर्दछ, जसले सफल SLM परिनियोजनलाई परिभाषित गर्ने क्षमता, दक्षता, र सञ्चालन उत्कृष्टताबीचको महत्वपूर्ण सन्तुलनलाई जोड दिन्छ।

---

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी यथासम्भव शुद्धताको प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटि वा अशुद्धता हुन सक्छ। यसको मूल भाषामा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्त्वपूर्ण जानकारीका लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार हुने छैनौं।