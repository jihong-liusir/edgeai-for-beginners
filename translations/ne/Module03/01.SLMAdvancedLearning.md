<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "38b68a204a9621126d056b0e5b51ab7c",
  "translation_date": "2025-10-09T09:16:19+00:00",
  "source_file": "Module03/01.SLMAdvancedLearning.md",
  "language_code": "ne"
}
-->
# рдЦрдгреНрдб рез: SLM рдЙрдиреНрдирдд рд╢рд┐рдХреНрд╖рдг - рдЖрдзрд╛рд░рднреВрдд рд░ рдЕрдиреБрдХреВрд▓рди

рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ (SLMs) EdgeAI рдорд╛ рдорд╣рддреНрддреНрд╡рдкреВрд░реНрдг рдкреНрд░рдЧрддрд┐ рд╣реБрдиреН, рдЬрд╕рд▓реЗ рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдкрд░рд┐рд╖реНрдХреГрдд рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдкреНрд░рд╢реЛрдзрди рдХреНрд╖рдорддрд╛рд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫрдиреНред SLMs рд▓рд╛рдИ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рд░реВрдкрдорд╛ рддреИрдирд╛рдд, рдЕрдиреБрдХреВрд▓рди, рд░ рдЙрдкрдпреЛрдЧ рдЧрд░реНрдиреЗ рддрд░рд┐рдХрд╛ рдмреБрдЭреНрдиреБ рдХрд┐рдирд╛рд░рд╛рдорд╛ рдЖрдзрд╛рд░рд┐рдд AI рд╕рдорд╛рдзрд╛рдирд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрди рдЖрд╡рд╢реНрдпрдХ рдЫред

## рдкрд░рд┐рдЪрдп

рдпрд╕ рдкрд╛рдардорд╛, рд╣рд╛рдореА рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ (SLMs) рд░ рддрд┐рдиреАрд╣рд░реВрдХреЛ рдЙрдиреНрдирдд рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд░рдгрдиреАрддрд┐рд╣рд░реВ рдЕрдиреНрд╡реЗрд╖рдг рдЧрд░реНрдиреЗрдЫреМрдВред рд╣рд╛рдореА SLMs рдХрд╛ рдЖрдзрд╛рд░рднреВрдд рдЕрд╡рдзрд╛рд░рдгрд╛рд╣рд░реВ, рддрд┐рдиреАрд╣рд░реВрдХреЛ рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рд╕реАрдорд╛рд╣рд░реВ рд░ рд╡рд░реНрдЧреАрдХрд░рдгрд╣рд░реВ, рдЕрдиреБрдХреВрд▓рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ, рд░ рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рд╡рд╛рддрд╛рд╡рд░рдгрдХрд╛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рддреИрдирд╛рддреА рд░рдгрдиреАрддрд┐рд╣рд░реВ рд╕рдореЗрдЯреНрдиреЗрдЫреМрдВред

## рд╕рд┐рдХрд╛рдЗ рдЙрджреНрджреЗрд╢реНрдпрд╣рд░реВ

рдпрд╕ рдкрд╛рдардХреЛ рдЕрдиреНрддреНрдпрд╕рдореНрдо, рддрдкрд╛рдИрдВ рд╕рдХреНрд╖рдо рд╣реБрдиреБрд╣реБрдиреЗрдЫ:

- ЁЯФв рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рд╕реАрдорд╛рд╣рд░реВ рд░ рд╡рд░реНрдЧреАрдХрд░рдгрд╣рд░реВ рдмреБрдЭреНрдиреБрд╣реЛрд╕реНред
- ЁЯЫая╕П рдХрд┐рдирд╛рд░рд╛ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ SLM рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ рдкреНрд░рдореБрдЦ рдЕрдиреБрдХреВрд▓рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ рдкрд╣рд┐рдЪрд╛рди рдЧрд░реНрдиреБрд╣реЛрд╕реНред
- ЁЯЪА SLMs рдХрд╛ рд▓рд╛рдЧрд┐ рдЙрдиреНрдирдд рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд░ рдХрдореНрдкреНрд░реЗрд╕рди рд░рдгрдиреАрддрд┐рд╣рд░реВ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрди рд╕рд┐рдХреНрдиреБрд╣реЛрд╕реНред

## SLM рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рд╕реАрдорд╛рд╣рд░реВ рд░ рд╡рд░реНрдЧреАрдХрд░рдг рдмреБрдЭреНрджреИ

рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ (SLMs) AI рдореЛрдбреЗрд▓рд╣рд░реВ рд╣реБрдиреН, рдЬрд╕рд▓реЗ рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рд╕рд╛рдордЧреНрд░реА рдкреНрд░рд╢реЛрдзрди, рдмреБрдЭреНрди, рд░ рдЙрддреНрдкрдиреНрди рдЧрд░реНрди рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХрд╛ рдЫрдиреН, рдЬрд╕рдорд╛ рддрд┐рдиреАрд╣рд░реВрдХреЛ рдареВрд▓рд╛ рд╕рдордХрдХреНрд╖рд╣рд░реВрдХреЛ рддреБрд▓рдирд╛рдорд╛ рдзреЗрд░реИ рдХрдо рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ рд╣реБрдиреНрдЫрдиреНред рдЬрдмрдХрд┐ рдареВрд▓рд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ (LLMs) рдорд╛ рд╕рдпреМрдВ рдЕрд░реНрдмрджреЗрдЦрд┐ рдЯреНрд░рд┐рд▓рд┐рдпрдирд╕рдореНрдо рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ рд╣реБрдиреНрдЫрдиреН, SLMs рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рджрдХреНрд╖рддрд╛ рд░ рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХрд╛ рдЫрдиреНред

рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ SLMs рдХрд╛ рд╡рд┐рднрд┐рдиреНрди рд╢реНрд░реЗрдгреАрд╣рд░реВ рд░ рддрд┐рдиреАрд╣рд░реВрдХреЛ рдЙрдкрдпреБрдХреНрдд рдкреНрд░рдпреЛрдЧ рдХреЗрд╕рд╣рд░реВ рдмреБрдЭреНрди рдорджреНрджрдд рдЧрд░реНрджрдЫред рдпреЛ рд╡рд░реНрдЧреАрдХрд░рдг рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рд╣реА рдореЛрдбреЗрд▓ рдЪрдпрди рдЧрд░реНрди рдорд╣рддреНрддреНрд╡рдкреВрд░реНрдг рдЫред

### рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдлреНрд░реЗрдорд╡рд░реНрдХ

рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рд╕реАрдорд╛рд╣рд░реВ рдмреБрдЭреНрдирд╛рд▓реЗ рд╡рд┐рднрд┐рдиреНрди рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд рдореЛрдбреЗрд▓рд╣рд░реВ рдЪрдпрди рдЧрд░реНрди рдорджреНрджрдд рдЧрд░реНрджрдЫ:

- **ЁЯФм рдорд╛рдЗрдХреНрд░реЛ SLMs**: резрежрежM - рез.рекB рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ (рдореЛрдмрд╛рдЗрд▓ рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрддрд┐ рд╣рд▓реНрдХрд╛)
- **ЁЯУ▒ рд╕рд╛рдирд╛ SLMs**: рез.релB - резрей.репB рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ (рд╕рдиреНрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рд░ рджрдХреНрд╖рддрд╛)
- **тЪЦя╕П рдордзреНрдпрдо SLMs**: резрекB - рейрежB рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ (LLM рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рдирдЬрд┐рдХ рдкреБрдЧреНрджреИ рджрдХреНрд╖рддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрджреИ)

рдареНрдпрд╛рдХреНрдХреИ рд╕реАрдорд╛ рдЕрдиреБрд╕рдиреНрдзрд╛рди рд╕рдореБрджрд╛рдпрдорд╛ рддрд░рд▓ рд░рд╣рдиреНрдЫ, рддрд░ рдЕрдзрд┐рдХрд╛рдВрд╢ рдЕрднреНрдпрд╛рд╕рдХрд░реНрддрд╛рд╣рд░реВрд▓реЗ рейреж рдЕрд░реНрдмрднрдиреНрджрд╛ рдХрдо рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рднрдПрдХрд╛ рдореЛрдбреЗрд▓рд╣рд░реВрд▓рд╛рдИ "рд╕рд╛рдиреЛ" рдорд╛рдиреНрдЫрдиреН, рдХреЗрд╣реА рд╕реНрд░реЛрддрд╣рд░реВрд▓реЗ рдпреЛ рд╕реАрдорд╛ резреж рдЕрд░реНрдм рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рдорд╛ рдкрдирд┐ рд░рд╛рдЦреНрдЫрдиреНред

### SLMs рдХрд╛ рдкреНрд░рдореБрдЦ рдлрд╛рдЗрджрд╛рд╣рд░реВ

SLMs рд▓реЗ рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢ рдмрдирд╛рдЙрдиреЗ рдХреЗрд╣реА рдЖрдзрд╛рд░рднреВрдд рдлрд╛рдЗрджрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рд╕рдЮреНрдЪрд╛рд▓рди рджрдХреНрд╖рддрд╛**: SLMs рд▓реЗ рдХрдо рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ рдкреНрд░рд╢реЛрдзрди рдЧрд░реНрдиреБрдкрд░реНрдиреЗ рднрдПрдХрд╛рд▓реЗ рдЫрд┐рдЯреЛ рдЕрдиреБрдорд╛рди рд╕рдордп рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рдЬрд╕рд▓реЗ рддрд┐рдиреАрд╣рд░реВрд▓рд╛рдИ рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╕рдордп рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢ рдмрдирд╛рдЙрдБрдЫред рддрд┐рдиреАрд╣рд░реВрд▓реЗ рдХрдо рдХрдореНрдкреНрдпреБрдЯреЗрд╢рдирд▓ рд╕реНрд░реЛрддрд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдкрд╛рд░реНрдЫрдиреН, рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рддреИрдирд╛рддреА рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫрдиреН, рдХрдо рдКрд░реНрдЬрд╛ рдЦрдкрдд рдЧрд░реНрдЫрдиреН, рд░ рдХрдо рдХрд╛рд░реНрдмрди рдлреБрдЯрдкреНрд░рд┐рдиреНрдЯ рдХрд╛рдпрдо рд░рд╛рдЦреНрдЫрдиреНред

**рддреИрдирд╛рддреА рд▓рдЪрдХрддрд╛**: рдпреА рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ рдЗрдиреНрдЯрд░рдиреЗрдЯ рдЬрдбрд╛рди рдЖрд╡рд╢реНрдпрдХрддрд╛рдмрд┐рдирд╛ рдЙрдкрдХрд░рдгрдорд╛ AI рдХреНрд╖рдорддрд╛рд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫрдиреН, рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрди рдорд╛рд░реНрдлрдд рдЧреЛрдкрдиреАрдпрддрд╛ рд░ рд╕реБрд░рдХреНрд╖рд╛ рдмрдврд╛рдЙрдБрдЫрдиреН, рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рдЧрд░реНрди рд╕рдХрд┐рдиреНрдЫ, рд░ рд╡рд┐рднрд┐рдиреНрди рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд рдЫрдиреНред

**рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡рдХрд╛рд░рд┐рддрд╛**: SLMs рд▓реЗ LLMs рдХреЛ рддреБрд▓рдирд╛рдорд╛ рд▓рд╛рдЧрдд-рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд░ рддреИрдирд╛рддреА рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рдХрд┐рдирд╛рд░рд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдХрдо рд╕рдЮреНрдЪрд╛рд▓рди рд▓рд╛рдЧрдд рд░ рдХрдо рдмреНрдпрд╛рдиреНрдбрд╡рд┐рде рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХрд╛ рд╕рд╛рдеред

## рдЙрдиреНрдирдд рдореЛрдбреЗрд▓ рдкреНрд░рд╛рдкреНрддрд┐ рд░рдгрдиреАрддрд┐рд╣рд░реВ

### Hugging Face рдЗрдХреЛрд╕рд┐рд╕реНрдЯрдо

Hugging Face рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ (SLMs) рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрди рд░ рдкрд╣реБрдБрдЪ рдЧрд░реНрдирдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдореБрдЦ рдХреЗрдиреНрджреНрд░рдХреЛ рд░реВрдкрдорд╛ рд╕реЗрд╡рд╛ рдЧрд░реНрджрдЫред рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ рдореЛрдбреЗрд▓ рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрди рд░ рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рдкрдХ рд╕реНрд░реЛрддрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдореЛрдбреЗрд▓ рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрдиреЗ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рдЧрдгрдирд╛, рд▓рд╛рдЗрд╕реЗрдиреНрд╕ рдкреНрд░рдХрд╛рд░, рд░ рдкреНрд░рджрд░реНрд╢рди рдореЗрдЯреНрд░рд┐рдХреНрд╕рджреНрд╡рд╛рд░рд╛ рдЙрдиреНрдирдд рдлрд┐рд▓реНрдЯрд░рд┐рдЩ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛рд╣рд░реВрд▓реЗ рд╕рд╛рдЗрдб-рдмрд╛рдИ-рд╕рд╛рдЗрдб рдореЛрдбреЗрд▓ рддреБрд▓рдирд╛ рдЙрдкрдХрд░рдгрд╣рд░реВ, рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╕рдордп рдкреНрд░рджрд░реНрд╢рди рдмреЗрдВрдЪрдорд╛рд░реНрдХ рд░ рдореВрд▓реНрдпрд╛рдЩреНрдХрди рдкрд░рд┐рдгрд╛рдорд╣рд░реВ, рд░ рддрддреНрдХрд╛рд▓ рдкрд░реАрдХреНрд╖рдгрдХрд╛ рд▓рд╛рдЧрд┐ WebGPU рдбреЗрдореЛрд╣рд░реВ рдкрд╣реБрдБрдЪ рдЧрд░реНрди рд╕рдХреНрдЫрдиреНред

**рдХреНрдпреБрд░реЗрдЯреЗрдб SLM рд╕рдВрдЧреНрд░рд╣рд╣рд░реВ**: рд▓реЛрдХрдкреНрд░рд┐рдп рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рдЙрдиреНрдирдд рддрд░реНрдХ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Phi-4-mini-3.8B, рдмрд╣реБрднрд╛рд╖реА рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ (0.6B/1.7B/4B), рдХреБрд╢рд▓ рд╕рд╛рдорд╛рдиреНрдп-рдЙрджреНрджреЗрд╢реНрдп рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Google Gemma3, рд░ рдЕрддрд┐-рдирд┐рдореНрди рдкрд░рд┐рд╢реБрджреНрдзрддрд╛ рддреИрдирд╛рддреАрдХреЛ рд▓рд╛рдЧрд┐ BitNET рдЬрд╕реНрддрд╛ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдореЛрдбреЗрд▓рд╣рд░реВ рд╕рдорд╛рд╡реЗрд╢ рдЫрдиреНред рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ рд╡рд┐рд╢реЗрд╖ рдбреЛрдореЗрдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рдореЛрдбреЗрд▓рд╣рд░реВ рд╕рд╣рд┐рдд рд╕рдореБрджрд╛рдп-рд╕рдВрдЪрд╛рд▓рд┐рдд рд╕рдВрдЧреНрд░рд╣рд╣рд░реВ рдкрдирд┐ рд╕рдорд╛рд╡реЗрд╢ рдЧрд░реНрджрдЫ, рд░ рд╡рд┐рднрд┐рдиреНрди рдкреНрд░рдпреЛрдЧ рдХреЗрд╕рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рдкреВрд░реНрд╡-рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рд░ рдирд┐рд░реНрджреЗрд╢рди-рдЯреНрдпреБрди рдЧрд░рд┐рдПрдХреЛ рднреЗрд░рд┐рдпрдиреНрдЯрд╣рд░реВред

### Azure AI Foundry рдореЛрдбреЗрд▓ рдХреНрдпрд╛рдЯрд▓рдЧ

Azure AI Foundry рдореЛрдбреЗрд▓ рдХреНрдпрд╛рдЯрд▓рдЧрд▓реЗ рдЙрдиреНрдирдд рдПрдХреАрдХрд░рдг рдХреНрд╖рдорддрд╛рд╣рд░реВрдХрд╛ рд╕рд╛рде рдЙрджреНрдпрдо-рдЧреНрд░реЗрдб SLMs рдкрд╣реБрдБрдЪ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдЙрджреНрдпрдо рдПрдХреАрдХрд░рдг**: рдХреНрдпрд╛рдЯрд▓рдЧрд▓реЗ Azure рджреНрд╡рд╛рд░рд╛ рдкреНрд░рддреНрдпрдХреНрд╖ рд░реВрдкрдорд╛ рдмреЗрдЪрд┐рдПрдХрд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рд╕рдорд╛рд╡реЗрд╢ рдЧрд░реНрджрдЫ, рдЬрд╕рдорд╛ рдЙрдиреНрдирдд рддрд░реНрдХ рдХреНрд╖рдорддрд╛рд╣рд░реВрдХрд╛ рд▓рд╛рдЧрд┐ Phi-4-mini-3.8B рд░ рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ Llama 3-8B рд╕рдорд╛рд╡реЗрд╢ рдЫрдиреНред рдпрд╕рдорд╛ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рддреЗрд╕реНрд░реЛ-рдкрдХреНрд╖ рдЦреБрд▓рд╛ рд╕реНрд░реЛрдд рдореЛрдбреЗрд▓рдмрд╛рдЯ Qwen3 8B рдЬрд╕реНрддрд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рдкрдирд┐ рд╕рдорд╛рд╡реЗрд╢ рдЫрдиреНред

**рдЙрджреНрдпрдо рд▓рд╛рднрд╣рд░реВ**: рдлрд╛рдЗрди-рдЯреНрдпреБрдирд┐рдЩ, рдЕрд╡рд▓реЛрдХрдиреАрдпрддрд╛, рд░ рдЬрд┐рдореНрдореЗрд╡рд╛рд░ AI рдХрд╛ рд▓рд╛рдЧрд┐ рдмрд┐рд▓реНрдЯ-рдЗрди рдЙрдкрдХрд░рдгрд╣рд░реВ рдореЛрдбреЗрд▓ рдкрд░рд┐рд╡рд╛рд░рд╣рд░реВрдорд╛ рдлрдЩреНрдЧрд┐рдмрд▓ Provisioned Throughput рдХрд╛ рд╕рд╛рде рдПрдХреАрдХреГрдд рдЫрдиреНред рдЙрджреНрдпрдо SLA рд╣рд░реВрд╕рд╣рд┐рдд рдкреНрд░рддреНрдпрдХреНрд╖ Microsoft рд╕рдорд░реНрдерди, рдПрдХреАрдХреГрдд рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЕрдиреБрдкрд╛рд▓рди рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ, рд░ рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╣рд░реВрд▓реЗ рдЙрджреНрдпрдо рдЕрдиреБрднрд╡рд▓рд╛рдИ рдмрдврд╛рдЙрдБрдЫрдиреНред

## рдЙрдиреНрдирдд рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд░ рдЕрдиреБрдХреВрд▓рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ

### Llama.cpp рдЕрдиреБрдХреВрд▓рди рдлреНрд░реЗрдорд╡рд░реНрдХ

Llama.cpp рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреАрдорд╛ рдЕрдзрд┐рдХрддрдо рджрдХреНрд╖рддрд╛рдХрд╛ рд▓рд╛рдЧрд┐ рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд╡рд┐рдзрд┐рд╣рд░реВ**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рд╡рд┐рднрд┐рдиреНрди рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░рд╣рд░реВ рд╕рдорд░реНрдерди рдЧрд░реНрджрдЫ, рдЬрд╕рдорд╛ Q4_0 (4-рдмрд┐рдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рдЙрддреНрдХреГрд╖реНрдЯ рдЖрдХрд╛рд░ рдШрдЯрд╛рдЙрдиреЗ - Qwen3-0.6B рдореЛрдмрд╛рдЗрд▓ рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢), Q5_1 (5-рдмрд┐рдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рдЧреБрдгрд╕реНрддрд░ рд░ рдХрдореНрдкреНрд░реЗрд╕рди рд╕рдиреНрддреБрд▓рди рдЧрд░реНрджреИ - Phi-4-mini-3.8B рдХрд┐рдирд╛рд░рд╛ рдЕрдиреБрдорд╛рдирдХрд╛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд), рд░ Q8_0 (рдореВрд▓ рдЧреБрдгрд╕реНрддрд░рдХреЛ рдирдЬрд┐рдХ - Google Gemma3 рдЙрддреНрдкрд╛рджрди рдкреНрд░рдпреЛрдЧрдХрд╛ рд▓рд╛рдЧрд┐ рд╕рд┐рдлрд╛рд░рд┐рд╕ рдЧрд░рд┐рдПрдХреЛ)ред BitNET рдЕрддрд┐ рдХрдореНрдкреНрд░реЗрд╕рди рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рдирдХреЛ рд╕рд╛рде рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдЧрд░реНрджрдЫред

**рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд▓рд╛рднрд╣рд░реВ**: SIMD рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рдирдХреЛ рд╕рд╛рде CPU-рдЕрдиреБрдХреВрд▓рд┐рдд рдЕрдиреБрдорд╛рдирд▓реЗ рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдореЛрдбреЗрд▓ рд▓реЛрдбрд┐рдЩ рд░ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред x86, ARM, рд░ Apple Silicon рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рд╣рд░реВрдорд╛ рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░-рдЕрдЬреНрдЮреЗрдп рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рд╣рд░реВ рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫред

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг**:

```bash
# Clone and build llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release

# Convert Phi-4-mini model from Hugging Face to GGUF format
# First, download the model from Hugging Face
cd ..
python convert.py --outtype f16 --outfile phi-4-mini.gguf /path/to/downloaded/phi-4-mini/model

# Quantize the model to 4-bit precision (Q4_0)
./build/bin/quantize phi-4-mini.gguf phi-4-mini-q4_0.gguf q4_0

# Benchmark the model to check performance
./build/bin/llama-bench -m phi-4-mini-q4_0.gguf -p "Write a function to calculate the Fibonacci sequence"

# Run inference with the quantized model
./build/bin/main -m phi-4-mini-q4_0.gguf -n 512 -p "Explain quantum computing in simple terms"
```

**рдореЗрдореЛрд░реА рдлреБрдЯрдкреНрд░рд┐рдиреНрдЯ рддреБрд▓рдирд╛**:

```python
# Python script to analyze model size differences
import os
import matplotlib.pyplot as plt
import numpy as np

# Model sizes (in GB)
models = ['Phi-4-mini', 'Qwen3-0.6B', 'Gemma3']
original_sizes = [7.6, 1.2, 4.8]  # F16 format
q4_0_sizes = [2.0, 0.35, 1.3]     # Q4_0 format
q8_0_sizes = [3.9, 0.68, 2.5]     # Q8_0 format

# Calculate reduction percentages
q4_reduction = [(orig - q4) / orig * 100 for orig, q4 in zip(original_sizes, q4_0_sizes)]
q8_reduction = [(orig - q8) / orig * 100 for orig, q8 in zip(original_sizes, q8_0_sizes)]

print("Model Size Reduction:")
for i, model in enumerate(models):
    print(f"{model}: Q4_0 reduces size by {q4_reduction[i]:.1f}%, Q8_0 reduces size by {q8_reduction[i]:.1f}%")

# Memory usage during inference will be approximately:
# - Original F16: ~2x model size
# - Q4_0: ~1.2x model size
# - Q8_0: ~1.5x model size
```

### Microsoft Olive рдЕрдиреБрдХреВрд▓рди рд╕реВрдЯ

Microsoft Olive рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдгрдХрд╛ рд▓рд╛рдЧрд┐ рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХреЛ рд╡реНрдпрд╛рдкрдХ рдореЛрдбреЗрд▓ рдЕрдиреБрдХреВрд▓рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдЕрдиреБрдХреВрд▓рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ**: рд╕реВрдЯрд▓реЗ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкрд░рд┐рд╢реБрджреНрдзрддрд╛ рдЪрдпрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЧрддрд┐рд╢реАрд▓ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд╕рдорд╛рд╡реЗрд╢ рдЧрд░реНрджрдЫ (рд╡рд┐рд╢реЗрд╖ рдЧрд░реА Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрд╕рдБрдЧ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА), рдЧреНрд░рд╛рдл рдЕрдиреБрдХреВрд▓рди рд░ рдЕрдкрд░реЗрдЯрд░ рдлреНрдпреБрдЬрди (Google Gemma3 рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рдХрд╛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд), CPU, GPU, рд░ NPU рдХрд╛ рд▓рд╛рдЧрд┐ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдХреВрд▓рдирд╣рд░реВ (ARM рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ Phi-4-mini-3.8B рдХрд╛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рд╕рдорд░реНрдердирдХрд╛ рд╕рд╛рде), рд░ рдмрд╣реБ-рдЪрд░рдг рдЕрдиреБрдХреВрд▓рди рдкрд╛рдЗрдкрд▓рд╛рдЗрдирд╣рд░реВред BitNET рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ Olive рдлреНрд░реЗрдорд╡рд░реНрдХ рднрд┐рддреНрд░ рд╡рд┐рд╢реЗрд╖ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдкрд╛рд░реНрдЫрдиреНред

**рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рд╕реНрд╡рдЪрд╛рд▓рди**: рдЕрдиреБрдХреВрд▓рди рднреЗрд░рд┐рдпрдиреНрдЯрд╣рд░реВрдорд╛ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдмреЗрдВрдЪрдорд╛рд░реНрдХрд┐рдЩрд▓реЗ рдЕрдиреБрдХреВрд▓рдирдХреЛ рдХреНрд░рдордорд╛ рдЧреБрдгрд╕реНрддрд░ рдореЗрдЯреНрд░рд┐рдХ рд╕рдВрд░рдХреНрд╖рдг рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред PyTorch рд░ ONNX рдЬрд╕реНрддрд╛ рд▓реЛрдХрдкреНрд░рд┐рдп ML рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВрд╕рдБрдЧ рдПрдХреАрдХрд░рдгрд▓реЗ рдХреНрд▓рд╛рдЙрдб рд░ рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреА рдЕрдиреБрдХреВрд▓рди рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг**:

```python
# Microsoft Olive optimization workflow for SLM
from olive.model import PyTorchModel, ONNXModel
from olive.workflows import run_workflow
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Define the workflow configuration
def create_olive_config(model_id="microsoft/phi-4-mini-instruct"):
    # Load model and create sample inputs
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)
    
    # Create sample inputs for tracing
    sample_text = "Explain the concept of edge computing"
    inputs = tokenizer(sample_text, return_tensors="pt")
    
    # Export to ONNX first
    model_path = f"{model_id.split('/')[-1]}.onnx"
    torch.onnx.export(
        model,
        (inputs["input_ids"],),
        model_path,
        input_names=["input_ids"],
        output_names=["logits"],
        dynamic_axes={
            "input_ids": {0: "batch", 1: "sequence"},
            "logits": {0: "batch", 1: "sequence"}
        },
        opset_version=15
    )
    
    # Create Olive optimization config
    config = {
        "input_model": ONNXModel(model_path),
        "systems": {
            "local_system": {
                "type": "LocalSystem"
            }
        },
        "passes": {
            # Graph optimization pass
            "graph_optimization": {
                "type": "OrtTransformersOptimization",
                "config": {
                    "optimization_options": {
                        "enable_gelu": True,
                        "enable_layer_norm": True,
                        "enable_attention": True,
                        "use_multi_head_attention": True
                    }
                }
            },
            # Quantization pass for INT8
            "quantization": {
                "type": "OrtQuantization",
                "config": {
                    "quant_mode": "static",
                    "activation_type": "int8",
                    "weight_type": "int8",
                    "op_types_to_quantize": ["MatMul", "Add", "Conv"]
                },
                "disable_search": True
            }
        },
        "engine": {
            "log_severity_level": 0,
            "cache_dir": "./cache"
        }
    }
    
    return config

# Run the optimization workflow
config = create_olive_config()
result = run_workflow(config)

# Save the optimized model
optimized_model = result.optimized_model
optimized_model.save("./optimized_phi4_mini")

# Benchmark performance comparison
print(f"Original model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
print(f"Optimized model size: {os.path.getsize('./optimized_phi4_mini/model.onnx') / (1024 * 1024):.2f} MB")
```

### Apple MLX рдлреНрд░реЗрдорд╡рд░реНрдХ

Apple MLX Apple Silicon рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХреЛ рджреЗрд╢реА рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**Apple Silicon рдЕрдиреБрдХреВрд▓рди**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рдореЗрдЯрд▓ рдкреНрд░рджрд░реНрд╢рди рд╢реЗрдбрд░рд╣рд░реВрдХреЛ рдПрдХреАрдХрд░рдг, рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдорд┐рд╢реНрд░рд┐рдд рдкрд░рд┐рд╢реБрджреНрдзрддрд╛ рдЕрдиреБрдорд╛рди (рд╡рд┐рд╢реЗрд╖ рдЧрд░реА Google Gemma3 рдХрд╛ рд╕рд╛рде рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА), рд░ рдЕрдиреБрдХреВрд▓рд┐рдд рдореЗрдореЛрд░реА рдмреНрдпрд╛рдиреНрдбрд╡рд┐рде рдЙрдкрдпреЛрдЧрдХреЛ рд╕рд╛рде рдПрдХреАрдХреГрдд рдореЗрдореЛрд░реА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрджрдЫред Phi-4-mini-3.8B M-рд╢реНрд░реГрдВрдЦрд▓рд╛ рдЪрд┐рдкреНрд╕рдорд╛ рдЕрд╕рд╛рдзрд╛рд░рдг рдкреНрд░рджрд░реНрд╢рди рджреЗрдЦрд╛рдЙрдБрдЫ, рдЬрдмрдХрд┐ Qwen3-1.7B MacBook Air рддреИрдирд╛рддреАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЗрд╖реНрдЯрддрдо рд╕рдиреНрддреБрд▓рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рд╡рд┐рдХрд╛рд╕ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: NumPy-рд╕рдВрдЧрдд рдПрд░реЗ рдЕрдкрд░реЗрд╕рдирд╣рд░реВ, рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рднрд┐рдиреНрдирддрд╛ рдХреНрд╖рдорддрд╛рд╣рд░реВ, рд░ Apple рд╡рд┐рдХрд╛рд╕ рдЙрдкрдХрд░рдгрд╣рд░реВрд╕рдБрдЧ рд╕рд╣рдЬ рдПрдХреАрдХрд░рдгрдХреЛ рд╕рд╛рде Python рд░ Swift API рд╕рдорд░реНрдердирд▓реЗ рд╡реНрдпрд╛рдкрдХ рд╡рд┐рдХрд╛рд╕ рд╡рд╛рддрд╛рд╡рд░рдг рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг**:

```python
# Apple MLX optimization for Phi-4-mini model
import mlx.core as mx
import mlx.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from mlx_lm import load, generate

# Install the required packages
# pip install mlx transformers mlx-lm

# Load the Phi-4-mini model with MLX optimization
model_path = "microsoft/phi-4-mini-instruct"
model, tokenizer = load(model_path)

# Convert to float16 for better performance on Apple Silicon
model.convert_to_float16()

# Sample inference
prompt = "Write a function to find prime numbers in Python"
results = generate(
    model, 
    tokenizer,
    prompt=prompt,
    max_tokens=512,
    temperature=0.7,
    top_p=0.9,
)

print(results[0]["generation"])

# Benchmark the model
import time

def benchmark_inference(model, tokenizer, prompt, runs=10):
    # Warmup
    generate(model, tokenizer, prompt=prompt, max_tokens=128)
    
    # Benchmark
    start_time = time.time()
    for _ in range(runs):
        generate(model, tokenizer, prompt=prompt, max_tokens=128)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / runs
    return avg_time

avg_inference_time = benchmark_inference(model, tokenizer, "Explain quantum computing")
print(f"Average inference time: {avg_inference_time:.4f} seconds")

# Save the optimized model for later use
model.save_weights("phi4_mini_optimized_mlx.npz")
```

## рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреА рд░ рдЕрдиреБрдорд╛рди рд░рдгрдиреАрддрд┐рд╣рд░реВ

### Ollama: рд╕рд░рд▓реАрдХреГрдд рд╕реНрдерд╛рдиреАрдп рддреИрдирд╛рддреА

Ollama рд╕реНрдерд╛рдиреАрдп рд░ рдХрд┐рдирд╛рд░рд╛ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрджреНрдпрдо-рддрдпрд╛рд░ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВрдХрд╛ рд╕рд╛рде SLM рддреИрдирд╛рддреАрд▓рд╛рдИ рд╕рд░рд▓ рдмрдирд╛рдЙрдБрдЫ:

**рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рд╣рд░реВ**: рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдореЛрдбреЗрд▓ рдкреБрд▓рд┐рдЩ рд░ рдХреНрдпрд╛рд╕рд┐рдЩрдХреЛ рд╕рд╛рде рдПрдХ-рдХрдорд╛рдгреНрдб рдореЛрдбреЗрд▓ рд╕реНрдерд╛рдкрдирд╛ рд░ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрдиред Phi-4-mini-3.8B, рд╕рдореНрдкреВрд░реНрдг Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ (0.6B/1.7B/4B), рд░ Google Gemma3 рдХреЛ рд╕рдорд░реНрдерди REST API рдХреЛ рд╕рд╛рде рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдПрдХреАрдХрд░рдг рд░ рдмрд╣реБ-рдореЛрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рд░ рд╕реНрд╡рд┐рдЪрд┐рдЩ рдХреНрд╖рдорддрд╛рд╣рд░реВред BitNET рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд╕рдорд░реНрдердирдХрд╛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдирд┐рд░реНрдорд╛рдг рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдкрд╛рд░реНрдЫрдиреНред

**рдЙрдиреНрдирдд рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: рдЕрдиреБрдХреВрд▓рд┐рдд рдореЛрдбреЗрд▓ рдлрд╛рдЗрди-рдЯреНрдпреБрдирд┐рдЩ рд╕рдорд░реНрдерди, рдХрдиреНрдЯреЗрдирд░рд╛рдЗрдЬреНрдб рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ Dockerfile рдЙрддреНрдкрд╛рджрди, GPU рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрдиреЗ, рд░ рдореЛрдбреЗрд▓ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд░ рдЕрдиреБрдХреВрд▓рди рд╡рд┐рдХрд▓реНрдкрд╣рд░реВрд▓реЗ рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рд▓рдЪрдХрддрд╛ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

### VLLM: рдЙрдЪреНрдЪ-рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдорд╛рди

VLLM рдЙрдЪреНрдЪ-рдереНрд░реБрдкреБрдЯ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрдкрд╛рджрди-рдЧреНрд░реЗрдб рдЕрдиреБрдорд╛рди рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рдирд╣рд░реВ**: PagedAttention рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдзреНрдпрд╛рди рдЧрдгрдирд╛рдХрд╛ рд▓рд╛рдЧрд┐ (рд╡рд┐рд╢реЗрд╖ рдЧрд░реА Phi-4-mini-3.8B рдХреЛ рдЯреНрд░рд╛рдиреНрд╕рдлрд░реНрдорд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рдХрд╛ рд▓рд╛рдЧрд┐ рд▓рд╛рднрджрд╛рдпрдХ), рдЧрддрд┐рд╢реАрд▓ рдмреНрдпрд╛рдЪрд┐рдЩ рдереНрд░реБрдкреБрдЯ рдЕрдиреБрдХреВрд▓рдирдХрд╛ рд▓рд╛рдЧрд┐ (Qwen3 рд╢реНрд░реГрдВрдЦрд▓рд╛ рд╕рдорд╛рдирд╛рдиреНрддрд░ рдкреНрд░рд╢реЛрдзрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд), рдмрд╣реБ-GPU рд╕реНрдХреЗрд▓рд┐рдЩрдХрд╛ рд▓рд╛рдЧрд┐ рдЯреЗрдиреНрд╕рд░ рд╕рдорд╛рдирд╛рдиреНрддрд░рддрд╛ (Google Gemma3 рд╕рдорд░реНрдерди), рд░ рд╡рд┐рд▓рдореНрдмрддрд╛ рдШрдЯрд╛рдЙрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдорд╛рдирд╛рддреНрдордХ рдбрд┐рдХреЛрдбрд┐рдЩред BitNET рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ 1-рдмрд┐рдЯ рдЕрдкрд░реЗрд╕рдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рдЕрдиреБрдорд╛рди рдХрд░реНрдиреЗрд▓рд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдкрд╛рд░реНрдЫрдиреНред

**рдЙрджреНрдпрдо рдПрдХреАрдХрд░рдг**: OpenAI-рд╕рдВрдЧрдд API рдЕрдиреНрдд рдмрд┐рдиреНрджреБрд╣рд░реВ, Kubernetes рддреИрдирд╛рддреА рд╕рдорд░реНрдерди, рдирд┐рдЧрд░рд╛рдиреА рд░ рдЕрд╡рд▓реЛрдХрдиреАрдпрддрд╛ рдПрдХреАрдХрд░рдг, рд░ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд╕реНрдХреЗрд▓рд┐рдЩ рдХреНрд╖рдорддрд╛рд╣рд░реВрд▓реЗ рдЙрджреНрдпрдо-рдЧреНрд░реЗрдб рддреИрдирд╛рддреА рд╕рдорд╛рдзрд╛рдирд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

### Foundry Local: Microsoft рдХреЛ рдХрд┐рдирд╛рд░рд╛ рд╕рдорд╛рдзрд╛рди

Foundry Local рдЙрджреНрдпрдо рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рдкрдХ рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: рдЕрдлрд▓рд╛рдЗрди-рдкреНрд░рдердо рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдбрд┐рдЬрд╛рдЗрди рд╕реНрд░реЛрдд рд╕реАрдорд╛ рдЕрдиреБрдХреВрд▓рдирдХрд╛ рд╕рд╛рде, рд╕реНрдерд╛рдиреАрдп рдореЛрдбреЗрд▓ рд░рдЬрд┐рд╕реНрдЯреНрд░реА рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди, рд░ рдХрд┐рдирд╛рд░рд╛-рджреЗрдЦрд┐-рдХреНрд▓рд╛рдЙрдб рд╕рдордХреНрд░рдордг рдХреНрд╖рдорддрд╛рд╣рд░реВрд▓реЗ рднрд░рдкрд░реНрджреЛ рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреА рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред

**рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЕрдиреБрдкрд╛рд▓рди**: рдЧреЛрдкрдиреАрдпрддрд╛ рд╕рдВрд░рдХреНрд╖рдгрдХрд╛ рд▓рд╛рдЧрд┐ рд╕реНрдерд╛рдиреАрдп рдбреЗрдЯрд╛ рдкреНрд░рд╢реЛрдзрди, рдЙрджреНрдпрдо рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ, рдЕрдбрд┐рдЯ рд▓рдЧрд┐рдЩ рд░ рдЕрдиреБрдкрд╛рд▓рди рд░рд┐рдкреЛрд░реНрдЯрд┐рдЩ, рд░ рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдкрд╣реБрдБрдЪ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрдирд▓реЗ рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рдкрдХ рд╕реБрд░рдХреНрд╖рд╛ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

## SLM рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЙрддреНрдХреГрд╖реНрдЯ рдЕрднреНрдпрд╛рд╕рд╣рд░реВ

### рдореЛрдбреЗрд▓ рдЪрдпрди рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢рд╣рд░реВ

рдХрд┐рдирд╛рд░рд╛ рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ SLMs рдЪрдпрди рдЧрд░реНрджрд╛, рдирд┐рдореНрди рдХрд╛рд░рдХрд╣рд░реВ рд╡рд┐рдЪрд╛рд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН:

**рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░ рдЧрдгрдирд╛ рд╡рд┐рдЪрд╛рд░рд╣рд░реВ**: рдЕрд▓реНрдЯреНрд░рд╛-рд╣рд▓реНрдХрд╛ рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Qwen3-0.6B рдЬрд╕реНрддрд╛ рдорд╛рдЗрдХреНрд░реЛ SLMs рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд╕рдиреНрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Qwen3-1.7B рд╡рд╛ Google Gemma3 рдЬрд╕реНрддрд╛ рд╕рд╛рдирд╛ SLMs, рд░ LLM рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рдирдЬрд┐рдХ рдкреБрдЧреНрджреИ рджрдХреНрд╖рддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрджреИ Phi-4-mini-3.8B рд╡рд╛ Qwen3-4B рдЬрд╕реНрддрд╛ рдордзреНрдпрдо SLMsред BitNET рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрд╕рдиреНрдзрд╛рди рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдЕрддрд┐-рдХрдореНрдкреНрд░реЗрд╕рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рдкреНрд░рдпреЛрдЧ рдХреЗрд╕ рдорд┐рд▓рд╛рди**: рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЧреБрдгрд╕реНрддрд░, рдЕрдиреБрдорд╛рди рдЧрддрд┐, рдореЗрдореЛрд░реА рд╕реАрдорд╛рд╣рд░реВ, рд░ рдЕрдлрд▓рд╛рдЗрди рдЕрдкрд░реЗрд╕рди рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рдЬрд╕реНрддрд╛ рдХрд╛рд░рдХрд╣рд░реВ рд╡рд┐рдЪрд╛рд░ рдЧрд░реНрджреИ рдореЛрдбреЗрд▓ рдХреНрд╖рдорддрд╛рд╣рд░реВрд▓рд╛рдИ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдорд╛ рдорд┐рд▓рд╛рдЙрдиреБрд╣реЛрд╕реНред

### рдЕрдиреБрдХреВрд▓рди рд░рдгрдиреАрддрд┐ рдЪрдпрди

**рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рджреГрд╖реНрдЯрд┐рдХреЛрдг**: рдЧреБрдгрд╕реНрддрд░ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕реАрдорд╛рд╣рд░реВрдХрд╛ рдЖрдзрд╛рд░рдорд╛ рдЙрдкрдпреБрдХреНрдд рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░рд╣рд░реВ рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реНред рдЕрдзрд┐рдХрддрдо рдХрдореНрдкреНрд░реЗрд╕рдирдХрд╛ рд▓рд╛рдЧрд┐ Q4_0 рд╡рд┐рдЪрд╛рд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН (Qwen3-0.6B рдореЛрдмрд╛рдЗрд▓ рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢), Q5_1 рдЧреБрдгрд╕реНрддрд░-рдХрдореНрдкреНрд░реЗрд╕рди рд╡реНрдпрд╛рдкрд╛рд░-рдЕрдлрд╣рд░реВ рд╕рдиреНрддреБрд▓рди рдЧрд░реНрди (Phi-4-mini-3.8B рд░ Google Gemma3 рдХрд╛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд), рд░ Q8_0 рдореВрд▓ рдЧреБрдгрд╕реНрддрд░ рд╕рдВрд░рдХреНрд╖рдгрдХрд╛ рд▓рд╛рдЧрд┐ (Qwen3-4B рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдгрдХрд╛ рд▓рд╛рдЧрд┐ рд╕рд┐рдлрд╛рд░рд┐рд╕ рдЧрд░рд┐рдПрдХреЛ)ред BitNET рдХреЛ 1-рдмрд┐рдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╢рди рд╡рд┐рд╢реЗрд╖ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрддрд┐ рдХрдореНрдкреНрд░реЗрд╕рди рд╕реАрдорд╛рдХреЛ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдЧрд░реНрджрдЫред

**рдлреНрд░реЗрдорд╡рд░реНрдХ рдЪрдпрди**: рд▓рдХреНрд╖реНрдп рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд░ рддреИрдирд╛рддреА рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХрд╛ рдЖрдзрд╛рд░рдорд╛ рдЕрдиреБрдХреВрд▓рди рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реНред CPU-рдЕрдиреБрдХреВрд▓рд┐рдд рддреИрдирд╛рддреАрдХрд╛ рд▓рд╛рдЧрд┐ Llama.cpp рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд╡реНрдпрд╛рдкрдХ рдЕрдиреБрдХреВрд▓рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Microsoft Olive рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд░ Apple Silicon рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Apple MLX рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реНред

## рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдореЛрдбреЗрд▓ рдЙрджрд╛рд╣рд░рдгрд╣рд░реВ рд░ рдкреНрд░рдпреЛрдЧ рдХреЗрд╕рд╣рд░реВ

### рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╡рд┐рд╢реНрд╡ рддреИрдирд╛рддреА рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВ

**рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ**: Qwen3-0.6B рдиреНрдпреВрдирддрдо рдореЗрдореЛрд░реА рдлреБрдЯрдкреНрд░рд┐рдиреНрдЯрдХрд╛ рд╕рд╛рде рд╕реНрдорд╛рд░реНрдЯрдлреЛрди рдЪреНрдпрд╛рдЯрдмреЛрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдорд╛ рдЙрддреНрдХреГрд╖реНрдЯ рдкреНрд░рджрд░реНрд╢рди рдЧрд░реНрджрдЫ, рдЬрдмрдХрд┐ Google Gemma3 рдЯреНрдпрд╛рдмреНрд▓реЗрдЯ-рдЖрдзрд╛рд░рд┐рдд рд╢реИрдХреНрд╖рд┐рдХ рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдиреНрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред Phi-4-mini-3.8B рдореЛрдмрд╛рдЗрд▓ рдЙрддреНрдкрд╛рджрдХрддрд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрдХреГрд╖реНрдЯ рддрд░реНрдХ рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рдбреЗрд╕реНрдХрдЯрдк рд░ рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ**: Qwen3-1.7B рдбреЗрд╕реНрдХрдЯрдк рд╕рд╣рд╛рдпрдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЗрд╖реНрдЯрддрдо рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, Phi-4-mini-3.8B рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛ рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдиреНрдирдд рдХреЛрдб рдЙрддреНрдкрд╛рджрди рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рд░ Qwen3-4B рд╡рд░реНрдХрд╕реНрдЯреЗрд╢рди рд╡рд╛рддрд╛рд╡рд░рдгрдорд╛ рдкрд░рд┐рд╖реНрдХреГрдд рджрд╕реНрддрд╛рд╡реЗрдЬ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫред

**рдЕрдиреБрд╕рдиреНрдзрд╛рди рд░ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ**: BitNET рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ рдЕрддрд┐-рдирд┐рдореНрди рдкрд░рд┐рд╢реБрджреНрдзрддрд╛ рдЕрдиреБрдорд╛рдирдХреЛ рдЕрдиреНрд╡реЗрд╖рдгрдХрд╛ рд▓рд╛рдЧрд┐ рд╢реИрдХреНрд╖рд┐рдХ рдЕрдиреБрд╕рдиреНрдзрд╛рди рд░ рдЕрддреНрдпрдзрд┐рдХ рд╕реНрд░реЛрдд рд╕реАрдорд╛рд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдкрд░реНрдиреЗ рдкреНрд░рдорд╛рдг-рдЕрд╡рдзрд╛рд░рдгрд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫред

### рдкреНрд░рджрд░реНрд╢рди рдмреЗрдВрдЪрдорд╛рд░реНрдХрд╣рд░реВ рд░ рддреБрд▓рдирд╛

**рдЕрдиреБрдорд╛рди рдЧрддрд┐**: Qwen3-0.6B рдореЛрдмрд╛рдЗрд▓ CPUs рдорд╛ рд╕рдмреИрднрдиреНрджрд╛ рдЫрд┐рдЯреЛ рдЕрдиреБрдорд╛рди рд╕рдордп рдкреНрд░рд╛рдкреНрдд рдЧрд░реНрджрдЫ, Google Gemma3 рд╕рд╛рдорд╛рдиреНрдп рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдиреНрддреБрд▓рд┐рдд рдЧрддрд┐-рдЧреБрдгрд╕реНрддрд░ рдЕрдиреБрдкрд╛рдд рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, Phi-4-mini-3.8B рдЬрдЯрд┐рд▓ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрдХреГрд╖реНрдЯ рддрд░реНрдХ рдЧрддрд┐ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рд░ BitNET рд╡рд┐рд╢реЗрд╖ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдХрд╛ рд╕рд╛рде рд╕реИрджреНрдзрд╛рдиреНрддрд┐рдХ рдЕрдзрд┐рдХрддрдо рдереНрд░реБрдкреБрдЯ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рдореЗрдореЛрд░реА рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ**: рдореЛрдбреЗрд▓ рдореЗрдореЛрд░реА рдлреБрдЯрдкреНрд░рд┐рдиреНрдЯрд╣рд░реВ Qwen3-0.6B (1GB рднрдиреНрджрд╛ рдХрдо рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬ рдЧрд░рд┐рдПрдХреЛ) рджреЗрдЦрд┐ Phi-4-mini-3.8B (

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпреЛ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдЕрдиреБрд╡рд╛рдж рдЧрд░рд┐рдПрдХреЛ рд╣реЛред рд╣рд╛рдореА рдпрдерд╛рд░реНрдерддрд╛рдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпрд╛рд╕ рдЧрд░реНрдЫреМрдВ, рддрд░ рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджрд┐рдиреБрд╣реЛрд╕реН рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рджрдорд╛ рддреНрд░реБрдЯрд┐рд╣рд░реВ рд╡рд╛ рдЕрд╢реБрджреНрдзрддрд╛рд╣рд░реВ рд╣реБрди рд╕рдХреНрдЫред рдпрд╕рдХреЛ рдореВрд▓ рднрд╛рд╖рд╛ рдорд╛ рд░рд╣реЗрдХреЛ рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝рд▓рд╛рдИ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд┐рдиреБрдкрд░реНрдЫред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реАрдХреЛ рд▓рд╛рдЧрд┐, рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рд╕рд┐рдлрд╛рд░рд┐рд╕ рдЧрд░рд┐рдиреНрдЫред рдпрд╕ рдЕрдиреБрд╡рд╛рджрдХреЛ рдкреНрд░рдпреЛрдЧрдмрд╛рдЯ рдЙрддреНрдкрдиреНрди рд╣реБрдиреЗ рдХреБрдиреИ рдкрдирд┐ рдЧрд▓рддрдлрд╣рдореА рд╡рд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛рдХреЛ рд▓рд╛рдЧрд┐ рд╣рд╛рдореА рдЬрд┐рдореНрдореЗрд╡рд╛рд░ рд╣реБрдиреЗ рдЫреИрдиреМрдВред