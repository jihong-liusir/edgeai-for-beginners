<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-17T21:20:54+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "ne"
}
-->
# खण्ड ३: फाइन-ट्युनिङ - विशेष कार्यहरूको लागि मोडेल अनुकूलन

## सामग्री तालिका
1. [फाइन-ट्युनिङको परिचय](../../../Module05)
2. [किन फाइन-ट्युनिङ महत्त्वपूर्ण छ](../../../Module05)
3. [फाइन-ट्युनिङका प्रकारहरू](../../../Module05)
4. [माइक्रोसफ्ट ओलिभसँग फाइन-ट्युनिङ](../../../Module05)
5. [व्यावहारिक उदाहरणहरू](../../../Module05)
6. [सर्वोत्तम अभ्यास र दिशानिर्देशहरू](../../../Module05)
7. [उन्नत प्रविधिहरू](../../../Module05)
8. [मूल्याङ्कन र अनुगमन](../../../Module05)
9. [सामान्य चुनौतीहरू र समाधानहरू](../../../Module05)
10. [निष्कर्ष](../../../Module05)

## फाइन-ट्युनिङको परिचय

**फाइन-ट्युनिङ** एक शक्तिशाली मेसिन लर्निङ प्रविधि हो जसले पहिले नै प्रशिक्षित मोडेललाई विशेष कार्यहरू गर्न वा विशेष डेटासेटहरूसँग काम गर्न अनुकूल बनाउँछ। मोडेललाई सुरुबाट प्रशिक्षण दिनुको सट्टा, फाइन-ट्युनिङले पहिले नै प्रशिक्षित मोडेलले सिकेको ज्ञानलाई उपयोग गरेर तपाईंको विशेष प्रयोगको लागि समायोजन गर्दछ।

### फाइन-ट्युनिङ के हो?

फाइन-ट्युनिङ **ट्रान्सफर लर्निङ**को एक रूप हो, जहाँ तपाईं:
- ठूलो डेटासेटबाट सामान्य ढाँचाहरू सिकेको पहिले नै प्रशिक्षित मोडेलबाट सुरु गर्नुहुन्छ
- तपाईंको विशेष डेटासेट प्रयोग गरेर मोडेलका आन्तरिक प्यारामिटरहरू समायोजन गर्नुहुन्छ
- मूल्यवान ज्ञानलाई कायम राख्दै मोडेललाई तपाईंको कार्यका लागि विशेष बनाउनुहुन्छ

यसलाई एक कुशल शेफलाई नयाँ परिकार बनाउन सिकाउनु जस्तै सोच्नुहोस् - उनीहरूले पहिले नै पकाउने आधारभूत कुरा बुझिसकेका छन्, तर नयाँ शैलीका विशेष प्रविधि र स्वादहरू सिक्न आवश्यक छ।

### मुख्य फाइदाहरू

- **समयको बचत**: सुरुबाट प्रशिक्षण दिनुभन्दा धेरै छिटो
- **डेटाको कुशलता**: राम्रो प्रदर्शन गर्न सानो डेटासेट आवश्यक
- **लागत-प्रभावकारी**: कम कम्प्युटेसनल स्रोतहरू आवश्यक
- **उत्तम प्रदर्शन**: सुरुबाट प्रशिक्षण दिनुभन्दा प्रायः उत्कृष्ट नतिजा प्राप्त
- **स्रोतहरूको अनुकूलन**: साना टोली र संस्थाहरूका लागि शक्तिशाली एआईलाई पहुँचयोग्य बनाउँछ

## किन फाइन-ट्युनिङ महत्त्वपूर्ण छ

### वास्तविक-विश्व अनुप्रयोगहरू

फाइन-ट्युनिङ धेरै परिदृश्यहरूमा आवश्यक छ:

**1. डोमेन अनुकूलन**
- मेडिकल एआई: मेडिकल शब्दावली र क्लिनिकल नोटहरूको लागि सामान्य भाषा मोडेलहरू अनुकूल बनाउने
- कानूनी प्रविधि: कानूनी कागजात विश्लेषण र सम्झौता समीक्षाको लागि मोडेलहरू विशेष बनाउने
- वित्तीय सेवा: वित्तीय प्रतिवेदन विश्लेषण र जोखिम मूल्याङ्कनका लागि मोडेलहरू अनुकूल बनाउने

**2. कार्य विशेषता**
- सामग्री सिर्जना: विशेष लेखन शैली वा स्वरका लागि फाइन-ट्युनिङ
- कोड सिर्जना: विशेष प्रोग्रामिङ भाषा वा फ्रेमवर्कका लागि मोडेलहरू अनुकूल बनाउने
- अनुवाद: विशेष भाषा जोडीहरू वा प्राविधिक डोमेनहरूको लागि प्रदर्शन सुधार गर्ने

**3. कर्पोरेट अनुप्रयोगहरू**
- ग्राहक सेवा: कम्पनी-विशेष शब्दावली बुझ्ने च्याटबटहरू सिर्जना गर्ने
- आन्तरिक दस्तावेजीकरण: संगठनात्मक प्रक्रियाहरूमा परिचित एआई सहायकहरू निर्माण गर्ने
- उद्योग-विशेष समाधानहरू: क्षेत्र-विशेष शब्दावली र कार्यप्रवाहहरू बुझ्ने मोडेलहरू विकास गर्ने

## फाइन-ट्युनिङका प्रकारहरू

### 1. पूर्ण फाइन-ट्युनिङ (निर्देशन फाइन-ट्युनिङ)

पूर्ण फाइन-ट्युनिङमा, सबै मोडेल प्यारामिटरहरू प्रशिक्षणको क्रममा अद्यावधिक गरिन्छ। यो दृष्टिकोण:
- अधिकतम लचिलोपन र प्रदर्शन सम्भावना प्रदान गर्दछ
- महत्त्वपूर्ण कम्प्युटेसनल स्रोतहरू आवश्यक पर्छ
- मोडेलको पूर्ण रूपमा नयाँ संस्करण परिणामस्वरूप प्राप्त हुन्छ
- पर्याप्त प्रशिक्षण डेटा र कम्प्युटेसनल स्रोतहरू भएका परिदृश्यहरूको लागि उत्तम

### 2. प्यारामिटर-कुशल फाइन-ट्युनिङ (PEFT)

PEFT विधिहरूले केवल सानो उपसमूह प्यारामिटरहरू अद्यावधिक गर्छन्, जसले प्रक्रियालाई अधिक कुशल बनाउँछ:

#### लो-र्याङ्क एडाप्टेसन (LoRA)
- अवस्थित तौलहरूमा साना प्रशिक्षणयोग्य र्याङ्क डिकम्पोजिसन म्याट्रिसहरू थप्छ
- प्रशिक्षणयोग्य प्यारामिटरहरूको संख्या नाटकीय रूपमा घटाउँछ
- पूर्ण फाइन-ट्युनिङको नजिकको प्रदर्शन कायम राख्छ
- विभिन्न अनुकूलनहरू बीच सजिलै स्विच गर्न सक्षम बनाउँछ

#### QLoRA (क्वान्टाइज्ड LoRA)
- LoRAलाई क्वान्टाइजेसन प्रविधिहरूसँग संयोजन गर्छ
- मेमोरी आवश्यकताहरू अझै घटाउँछ
- उपभोक्ता हार्डवेयरमा ठूला मोडेलहरूको फाइन-ट्युनिङ सक्षम बनाउँछ
- दक्षता र प्रदर्शनको सन्तुलन कायम राख्छ

#### एडाप्टरहरू
- अवस्थित तहहरू बीच साना न्यूरल नेटवर्कहरू सम्मिलित गर्छ
- आधार मोडेललाई स्थिर राख्दै लक्षित फाइन-ट्युनिङ अनुमति दिन्छ
- मोडेल अनुकूलनको लागि मोड्युलर दृष्टिकोण सक्षम बनाउँछ

### 3. कार्य-विशेष फाइन-ट्युनिङ

विशेष डाउनस्ट्रीम कार्यहरूको लागि मोडेलहरू अनुकूल बनाउन केन्द्रित:
- **वर्गीकरण**: वर्गीकरण कार्यहरूको लागि मोडेलहरू समायोजन गर्ने
- **सिर्जना**: सामग्री सिर्जना र पाठ उत्पादनको लागि अनुकूलन गर्ने
- **निकासी**: जानकारी निकासी र नामित इकाई पहिचानको लागि फाइन-ट्युनिङ गर्ने
- **सारांश**: कागजात सारांशको लागि मोडेलहरू विशेष बनाउने

## माइक्रोसफ्ट ओलिभसँग फाइन-ट्युनिङ

माइक्रोसफ्ट ओलिभ एक व्यापक मोडेल अनुकूलन उपकरण हो जसले फाइन-ट्युनिङ प्रक्रियालाई सरल बनाउँछ र उद्यम-स्तरका सुविधाहरू प्रदान गर्दछ।

### माइक्रोसफ्ट ओलिभ के हो?

माइक्रोसफ्ट ओलिभ एक खुला स्रोत मोडेल अनुकूलन उपकरण हो जसले:
- विभिन्न हार्डवेयर लक्ष्यहरूको लागि फाइन-ट्युनिङ कार्यप्रवाहहरू सरलीकृत गर्दछ
- लोकप्रिय मोडेल आर्किटेक्चरहरूको लागि बिल्ट-इन समर्थन प्रदान गर्दछ (Llama, Phi, Qwen, Gemma)
- क्लाउड र स्थानीय परिनियोजन विकल्पहरू प्रदान गर्दछ
- Azure ML र अन्य माइक्रोसफ्ट एआई सेवाहरूसँग सहज रूपमा एकीकृत हुन्छ
- स्वचालित अनुकूलन र क्वान्टाइजेसन समर्थन गर्दछ

### मुख्य सुविधाहरू

- **हार्डवेयर-जानकार अनुकूलन**: विशिष्ट हार्डवेयर (CPU, GPU, NPU) का लागि मोडेलहरू स्वचालित रूपमा अनुकूलित गर्दछ
- **बहु-ढाँचा समर्थन**: PyTorch, Hugging Face, र ONNX मोडेलहरूसँग काम गर्दछ
- **स्वचालित कार्यप्रवाहहरू**: म्यानुअल कन्फिगरेसन र परीक्षण-त्रुटि घटाउँछ
- **उद्यम एकीकरण**: Azure ML र क्लाउड परिनियोजनको लागि बिल्ट-इन समर्थन
- **विस्तारयोग्य आर्किटेक्चर**: अनुकूलन अनुकूलन प्रविधिहरू अनुमति दिन्छ

### स्थापना र सेटअप

#### आधारभूत स्थापना

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### वैकल्पिक निर्भरताहरू

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### स्थापना प्रमाणित गर्नुहोस्

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## व्यावहारिक उदाहरणहरू

### उदाहरण 1: ओलिभ CLI प्रयोग गरेर आधारभूत फाइन-ट्युनिङ

यो उदाहरणले वाक्यांश वर्गीकरणको लागि सानो भाषा मोडेल फाइन-ट्युनिङ प्रदर्शन गर्दछ:

#### चरण 1: तपाईंको वातावरण तयार गर्नुहोस्

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### चरण 2: मोडेल फाइन-ट्युन गर्नुहोस्

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### चरण 3: परिनियोजनको लागि अनुकूलित गर्नुहोस्

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### उदाहरण 2: अनुकूलन डेटासेटको साथ उन्नत कन्फिगरेसन

#### चरण 1: अनुकूलन डेटासेट तयार गर्नुहोस्

तपाईंको प्रशिक्षण डाटासहित JSON फाइल सिर्जना गर्नुहोस्:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### चरण 2: कन्फिगरेसन फाइल सिर्जना गर्नुहोस्

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### चरण 3: फाइन-ट्युनिङ कार्यान्वयन गर्नुहोस्

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### उदाहरण 3: मेमोरी दक्षताका लागि QLoRA फाइन-ट्युनिङ

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## सर्वोत्तम अभ्यास र दिशानिर्देशहरू

### डेटा तयारी

**1. गुणस्तरलाई प्राथमिकता दिनुहोस्**
- ठूलो मात्रामा खराब डेटाको सट्टा उच्च गुणस्तर, विविध उदाहरणहरूलाई प्राथमिकता दिनुहोस्
- तपाईंको लक्षित प्रयोग केसको प्रतिनिधित्व गर्ने डेटा सुनिश्चित गर्नुहोस्
- डेटा सफा र पूर्वप्रक्रिया लगातार गर्नुहोस्

**2. डेटा ढाँचा र टेम्प्लेटहरू**
- सबै प्रशिक्षण उदाहरणहरूमा निरन्तर ढाँचा प्रयोग गर्नुहोस्
- तपाईंको प्रयोग केससँग मेल खाने स्पष्ट इनपुट-आउटपुट टेम्प्लेटहरू सिर्जना गर्नुहोस्
- निर्देशन-ट्युन गरिएको मोडेलहरूको लागि उपयुक्त निर्देशन ढाँचा समावेश गर्नुहोस्

**3. डेटासेट विभाजन**
- १०-२०% डेटा मान्यताका लागि सुरक्षित गर्नुहोस्
- प्रशिक्षण/मान्यता विभाजनहरूमा समान वितरणहरू कायम राख्नुहोस्
- वर्गीकरण कार्यहरूको लागि स्तरीकृत नमूना विचार गर्नुहोस्

### प्रशिक्षण कन्फिगरेसन

**1. सिकाइ दर चयन**
- फाइन-ट्युनिङका लागि साना सिकाइ दर (1e-5 देखि 1e-4) बाट सुरु गर्नुहोस्
- राम्रो अभिसरणका लागि सिकाइ दर तालिका प्रयोग गर्नुहोस्
- हानि वक्रहरू अनुगमन गरेर दरहरू समायोजन गर्नुहोस्

**2. ब्याच साइज अनुकूलन**
- उपलब्ध मेमोरीसँग ब्याच साइज सन्तुलन गर्नुहोस्
- ठूलो प्रभावकारी ब्याच साइजहरूको लागि ग्रेडियन्ट संचित प्रयोग गर्नुहोस्
- ब्याच साइज र सिकाइ दर बीचको सम्बन्ध विचार गर्नुहोस्

**3. प्रशिक्षण अवधि**
- ओभरफिटिङ रोक्न मान्यता मेट्रिक्स अनुगमन गर्नुहोस्
- मान्यता प्रदर्शन स्थिर हुँदा प्रारम्भिक रोकावट प्रयोग गर्नुहोस्
- पुन: प्राप्ति र विश्लेषणका लागि नियमित रूपमा चेकप्वाइन्टहरू सुरक्षित गर्नुहोस्

### मोडेल चयन

**1. आधार मोडेल छनोट**
- सकेसम्म समान डोमेनमा पूर्व-प्रशिक्षित मोडेलहरू चयन गर्नुहोस्
- तपाईंको कम्प्युटेसनल सीमाहरू सापेक्ष मोडेल आकार विचार गर्नुहोस्
- व्यावसायिक प्रयोगका लागि लाइसेन्स आवश्यकताहरू मूल्याङ्कन गर्नुहोस्

**2. फाइन-ट्युनिङ विधि चयन**
- स्रोत-सीमित वातावरणहरूको लागि LoRA/QLoRA प्रयोग गर्नुहोस्
- अधिकतम प्रदर्शन महत्त्वपूर्ण हुँदा पूर्ण फाइन-ट्युनिङ चयन गर्नुहोस्
- बहु-कार्य परिदृश्यहरूको लागि एडाप्टर-आधारित दृष्टिकोण विचार गर्नुहोस्

### स्रोत व्यवस्थापन

**1. हार्डवेयर अनुकूलन**
- तपाईंको मोडेल आकार र विधिका लागि उपयुक्त हार्डवेयर चयन गर्नुहोस्
- ग्रेडियन्ट चेकप्वाइन्टिङको साथ GPU मेमोरी कुशलतापूर्वक प्रयोग गर्नुहोस्
- ठूला मोडेलहरूको लागि क्लाउड-आधारित समाधानहरू विचार गर्नुहोस्

**2. मेमोरी व्यवस्थापन**
- उपलब्ध हुँदा मिश्रित परिशुद्धता प्रशिक्षण प्रयोग गर्नुहोस्
- मेमोरी सीमाहरूका लागि ग्रेडियन्ट संचित कार्यान्वयन गर्नुहोस्
- प्रशिक्षणको क्रममा GPU मेमोरी प्रयोग अनुगमन गर्नुहोस्

## उन्नत प्रविधिहरू

### बहु-एडाप्टर प्रशिक्षण

विभिन्न कार्यहरूको लागि बहु-एडाप्टरहरू प्रशिक्षण गर्नुहोस् जबकि आधार मोडेल साझा गर्नुहोस्:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### हाइपरप्यारामिटर अनुकूलन

पद्धतिगत हाइपरप्यारामिटर ट्युनिङ कार्यान्वयन गर्नुहोस्:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### अनुकूलन हानि कार्यहरू

डोमेन-विशेष हानि कार्यहरू कार्यान्वयन गर्नुहोस्:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## मूल्याङ्कन र अनुगमन

### मेट्रिक्स र मूल्याङ्कन

**1. मानक मेट्रिक्स**
- **सटीकता**: वर्गीकरण कार्यहरूको लागि समग्र शुद्धता
- **पर्प्लेक्सिटी**: भाषा मोडलिङ गुणस्तर मापन
- **BLEU/ROUGE**: पाठ उत्पादन र सारांशको गुणस्तर
- **F1 स्कोर**: वर्गीकरणका लागि सन्तुलित सटीकता र पुनःप्राप्ति

**2. डोमेन-विशेष मेट्रिक्स**
- **कार्य-विशेष मापदण्डहरू**: तपाईंको डोमेनका लागि स्थापित मापदण्डहरू प्रयोग गर्नुहोस्
- **मानव मूल्याङ्कन**: व्यक्तिपरक कार्यहरूको लागि मानव मूल्याङ्कन समावेश गर्नुहोस्
- **व्यावसायिक मेट्रिक्स**: वास्तविक व्यावसायिक उद्देश्यहरूसँग मेल गर्नुहोस्

**3. मूल्याङ्कन सेटअप**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### प्रशिक्षण प्रगति अनुगमन

**1. हानि ट्र्याकिङ**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. मान्यता अनुगमन**
- प्रशिक्षण हानिसँगै मान्यता हानि ट्र्याक गर्नुहोस्
- ओभरफिटिङका संकेतहरूको अनुगमन गर्नुहोस् (प्रशिक्षण हानि घट्दै गर्दा मान्यता हानि बढ्दै जानु)
- मान्यता मेट्रिक्सको आधारमा प्रारम्भिक रोकावट प्रयोग गर्नुहोस्

**3. स्रोत अनुगमन**
- GPU/CPU उपयोग अनुगमन गर्नुहोस्
- मेमोरी प्रयोग ढाँचाहरू ट्र्याक गर्नुहोस्
- प्रशिक्षण गति र थ्रुपुट अनुगमन गर्नुहोस्

## सामान्य चुनौतीहरू र समाधानहरू

### चुनौती 1: ओभरफिटिङ

**लक्षणहरू:**
- प्रशिक्षण हानि घटिरहन्छ जबकि मान्यता हानि बढ्छ
- प्रशिक्षण र मान्यता प्रदर्शन बीच ठूलो अन्तर
- नयाँ डेटामा खराब सामान्यीकरण

**समाधानहरू:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### चुनौती 2: मेमोरी सीमाहरू

**समाधानहरू:**
- ग्रेडियन्ट चेकप्वाइन्टिङ प्रयोग गर्नुहोस्
- ग्रेडियन्ट संचित कार्यान्वयन गर्नुहोस्
- प्यारामिटर-कुशल विधिहरू (LoRA, QLoRA) चयन गर्नुहोस्
- ठूला मोडेलहरूको लागि मोडेल समानान्तरता प्रयोग गर्नुहोस्

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### चुनौती 3: सुस्त प्रशिक्षण

**समाधानहरू:**
- डेटा लोडिङ पाइपलाइनहरू अनुकूलित गर्नुहोस्
- मिश्रित परिशुद्धता प्रशिक्षण प्रयोग गर्नुहोस्
- कुशल ब्याचिङ रणनीतिहरू कार्यान्वयन गर्नुहोस्
- ठूला डेटासेटहरूको लागि वितरित प्रशिक्षण विचार गर्नुहोस्

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### चुनौती 4: खराब प्रदर्शन

**निदान चरणहरू:**
1. डेटा गुणस्तर र ढाँचाको प्रमाणित गर्नुहोस्
2. सिकाइ दर र प्रशिक्षण अवधिको जाँच गर्नुहोस्
3. आधार मोडेल छनोट मूल्याङ्कन गर्नुहोस्
4. पूर्वप्रक्रिया र टोकनाइजेसन समीक्षा गर्नुहोस्

**समाधानहरू:**
- प्रशिक्षण डेटा विविधता बढाउनुहोस्
- सिकाइ दर तालिका समायोजन गर्नुहोस्
- विभिन्न आधार मोडेलहरू प्रयास गर्नुहोस्
- डेटा वृद्धि प्रविधिहरू कार्यान्वयन गर्नुहोस्

## निष्कर्ष

फाइन-ट्युनिङ एक शक्तिशाली प्रविधि हो जसले अत्याधुनिक एआई क्षमताहरूलाई सबैका लागि पहुँचयोग्य बनाउँछ। माइक्रोसफ्ट ओलिभ जस्ता उपकरणहरूको उपयोग गरेर, संगठनहरूले पहिले नै प्रशिक्षित मोडेलहरूलाई आफ्ना विशेष आवश्यकताहरूका लागि कुशलतापूर्वक अनुकूल बनाउन सक्छन्, जबकि प्रदर्शन र स्रोत सीमाहरूको लागि अनुकूलन गर्न सक्छन्।

### मुख्य बुँदाहरू

1. **सही दृष्टिकोण चयन गर्नुहोस्**: तपाईंका कम्प्युटेसनल स्रोत र प्रदर्शन आवश्यकताहरूका आधारमा फाइन-ट्युनिङ विधिहरू चयन गर्नुहोस्
2. **डेटाको गुणस्तर महत्त्वपूर्ण छ**: उच्च गुणस्तर, प्रतिनिधित्व गर्ने प्रशिक्षण डेटामा लगानी गर्नुहोस्
3. **अनुगमन र पुनरावृत्ति गर्नुहोस्**: तपाईंका मोडेलहरूलाई निरन्तर मूल्याङ्कन र सुधार गर्नुहोस्
4. **उप

---

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी यथासम्भव सटीकता सुनिश्चित गर्न प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटि वा अशुद्धता हुन सक्छ। यसको मूल भाषामा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्त्वपूर्ण जानकारीका लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।