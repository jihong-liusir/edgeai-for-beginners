<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T09:52:32+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "ne"
}
-->
# рдХрд╛рд░реНрдпрд╢рд╛рд▓рд╛ рдиреЛрдЯрдмреБрдХрд╣рд░реВ - рдЫрд┐рдЯреЛ рд╕реБрд░реБ рдЧрд░реНрдиреЗ рдорд╛рд░реНрдЧрджрд░реНрд╢рди

## рд╕рд╛рдордЧреНрд░реА рддрд╛рд▓рд┐рдХрд╛

- [рдкреВрд░реНрд╡рд╛рдкреЗрдХреНрд╖рд╛рд╣рд░реВ](../../../../Workshop/notebooks)
- [рдкреНрд░рд╛рд░рдореНрднрд┐рдХ рд╕реЗрдЯрдЕрдк](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ режрек: рдореЛрдбреЗрд▓ рддреБрд▓рдирд╛](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ режрел: рдмрд╣реБ-рдПрдЬреЗрдиреНрдЯ рд╕рдордиреНрд╡рдпрдХрд░реНрддрд╛](../../../../Workshop/notebooks)
- [рд╕рддреНрд░ режрем: рдЙрджреНрджреЗрд╢реНрдп-рдЖрдзрд╛рд░рд┐рдд рдореЛрдбреЗрд▓ рд░реБрдЯрд┐рдЩ](../../../../Workshop/notebooks)
- [рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░рд╣рд░реВ](../../../../Workshop/notebooks)
- [рд╕рд╛рдорд╛рдиреНрдп рдЖрджреЗрд╢рд╣рд░реВ](../../../../Workshop/notebooks)

---

## рдкреВрд░реНрд╡рд╛рдкреЗрдХреНрд╖рд╛рд╣рд░реВ

### рез. рдлрд╛рдЙрдиреНрдбреНрд░реА рд▓реЛрдХрд▓ рд╕реНрдерд╛рдкрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН

**рд╡рд┐рдиреНрдбреЛрдЬ:**
```bash
winget install Microsoft.FoundryLocal
```

**рдореНрдпрд╛рдХрдУрдПрд╕:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**рд╕реНрдерд╛рдкрдирд╛ рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН:**
```bash
foundry --version
```

### реи. рдкрд╛рдЗрдерди рдирд┐рд░реНрднрд░рддрд╛ рд╕реНрдерд╛рдкрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН

```bash
cd Workshop
pip install -r requirements.txt
```

рд╡рд╛ рд╡реНрдпрдХреНрддрд┐рдЧрдд рд░реВрдкрдорд╛ рд╕реНрдерд╛рдкрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## рдкреНрд░рд╛рд░рдореНрднрд┐рдХ рд╕реЗрдЯрдЕрдк

### рдлрд╛рдЙрдиреНрдбреНрд░реА рд▓реЛрдХрд▓ рд╕реЗрд╡рд╛ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН

**рдХреБрдиреИ рдкрдирд┐ рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдЙрдиреБ рдЕрдШрд┐ рдЖрд╡рд╢реНрдпрдХ:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ:
```
тЬЕ Service started successfully
Endpoint: http://localhost:59959
```

### рдореЛрдбреЗрд▓рд╣рд░реВ рдбрд╛рдЙрдирд▓реЛрдб рд░ рд▓реЛрдб рдЧрд░реНрдиреБрд╣реЛрд╕реН

рдиреЛрдЯрдмреБрдХрд╣рд░реВрд▓реЗ рдпреА рдореЛрдбреЗрд▓рд╣рд░реВрд▓рд╛рдИ рдбрд┐рдлрд▓реНрдЯ рд░реВрдкрдорд╛ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдЫрдиреН:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### рд╕реЗрдЯрдЕрдк рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## рд╕рддреНрд░ режрек: рдореЛрдбреЗрд▓ рддреБрд▓рдирд╛

### рдЙрджреНрджреЗрд╢реНрдп
рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ (SLM) рд░ рдареВрд▓рд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ (LLM) рдмреАрдЪрдХреЛ рдкреНрд░рджрд░реНрд╢рди рддреБрд▓рдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реНред

### рдЫрд┐рдЯреЛ рд╕реЗрдЯрдЕрдк

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдЙрдиреЗ

1. **рдЦреЛрд▓реНрдиреБрд╣реЛрд╕реН** `session04_model_compare.ipynb` VS Code рд╡рд╛ Jupyter рдорд╛
2. **рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН** (рдХрд░реНрдиреЗрд▓ тЖТ рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН)
3. **рд╕рдмреИ рд╕реЗрд▓рд╣рд░реВ рдХреНрд░рдо рдЕрдиреБрд╕рд╛рд░ рдЪрд▓рд╛рдЙрдиреБрд╣реЛрд╕реН**

### рдореБрдЦреНрдп рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди

**рдбрд┐рдлрд▓реНрдЯ рдореЛрдбреЗрд▓рд╣рд░реВ:**
- **SLM:** `phi-4-mini` (~4GB RAM, рдЫрд┐рдЯреЛ)
- **LLM:** `qwen2.5-3b` (~3GB RAM, рдореЗрдореЛрд░реА-рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреНрдб)

**рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░рд╣рд░реВ (рд╡реИрдХрд▓реНрдкрд┐рдХ):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

ЁЯТб SLM is 1.99x faster than LLM for this prompt
```

### рдЕрдиреБрдХреВрд▓рди

**рд╡рд┐рднрд┐рдиреНрди рдореЛрдбреЗрд▓рд╣рд░реВ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**рдЕрдиреБрдХреВрд▓рд┐рдд рдкреНрд░рдореНрдкреНрдЯ:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### рдорд╛рдиреНрдпрдХрд░рдг рдЪреЗрдХрд▓рд┐рд╕реНрдЯ

- [ ] рд╕реЗрд▓ резреи рд╕рд╣реА рдореЛрдбреЗрд▓рд╣рд░реВ рджреЗрдЦрд╛рдЙрдБрдЫ (phi-4-mini, qwen2.5-3b)
- [ ] рд╕реЗрд▓ резреи рд╕рд╣реА рдЕрдиреНрдд рдмрд┐рдиреНрджреБ рджреЗрдЦрд╛рдЙрдБрдЫ (рдкреЛрд░реНрдЯ 59959)
- [ ] рд╕реЗрд▓ резрем рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рдкрд╛рд╕ рд╣реБрдиреНрдЫ (тЬЕ рд╕реЗрд╡рд╛ рдЪрд▓рд┐рд░рд╣реЗрдХреЛ рдЫ)
- [ ] рд╕реЗрд▓ реиреж рдкреНрд░рд┐-рдлреНрд▓рд╛рдЗрдЯ рдЪреЗрдХ рдкрд╛рд╕ рд╣реБрдиреНрдЫ (рджреБрдмреИ рдореЛрдбреЗрд▓ рдареАрдХ рдЫрдиреН)
- [ ] рд╕реЗрд▓ реиреи рддреБрд▓рдирд╛ рдкреВрд░рд╛ рд╣реБрдиреНрдЫ рд╡рд┐рд▓рдореНрдм рдорд╛рдирд╣рд░реВрд╕рдБрдЧ
- [ ] рд╕реЗрд▓ реирек рдорд╛рдиреНрдпрдХрд░рдг рджреЗрдЦрд╛рдЙрдБрдЫ ЁЯОЙ рд╕рдмреИ рдЪреЗрдХ рдкрд╛рд╕ рднрдпреЛ!

### рд╕рдордп рдЕрдиреБрдорд╛рди
- **рдкрд╣рд┐рд▓реЛ рд░рди:** рел-резреж рдорд┐рдиреЗрдЯ (рдореЛрдбреЗрд▓ рдбрд╛рдЙрдирд▓реЛрдб рд╕рд╣рд┐рдд)
- **рдкрдЫрд┐рд▓реНрд▓рд╛ рд░рдирд╣рд░реВ:** рез-реи рдорд┐рдиреЗрдЯ

---

## рд╕рддреНрд░ режрел: рдмрд╣реБ-рдПрдЬреЗрдиреНрдЯ рд╕рдордиреНрд╡рдпрдХрд░реНрддрд╛

### рдЙрджреНрджреЗрд╢реНрдп
рдлрд╛рдЙрдиреНрдбреНрд░реА рд▓реЛрдХрд▓ SDK рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдмрд╣реБ-рдПрдЬреЗрдиреНрдЯ рд╕рд╣рдпреЛрдЧ рдкреНрд░рджрд░реНрд╢рди рдЧрд░реНрдиреБрд╣реЛрд╕реН - рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдкрд░рд┐рд╖реНрдХреГрдд рдЖрдЙрдЯрдкреБрдЯ рдЙрддреНрдкрд╛рджрди рдЧрд░реНрди рд╕рдБрдЧреИ рдХрд╛рдо рдЧрд░реНрдЫрдиреНред

### рдЫрд┐рдЯреЛ рд╕реЗрдЯрдЕрдк

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдЙрдиреЗ

1. **рдЦреЛрд▓реНрдиреБрд╣реЛрд╕реН** `session05_agents_orchestrator.ipynb`
2. **рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН**
3. **рд╕рдмреИ рд╕реЗрд▓рд╣рд░реВ рдХреНрд░рдо рдЕрдиреБрд╕рд╛рд░ рдЪрд▓рд╛рдЙрдиреБрд╣реЛрд╕реН**

### рдореБрдЦреНрдп рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди

**рдбрд┐рдлрд▓реНрдЯ рд╕реЗрдЯрдЕрдк (рджреБрдмреИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдорд╛рди рдореЛрдбреЗрд▓):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**рдЙрдиреНрдирдд рд╕реЗрдЯрдЕрдк (рд╡рд┐рднрд┐рдиреНрди рдореЛрдбреЗрд▓рд╣рд░реВ):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### рд╡рд╛рд╕реНрддреБрдХрд▓рд╛

```
User Question
    тЖУ
Researcher Agent (phi-4-mini)
  тЖТ Gathers bullet points
    тЖУ
Editor Agent (phi-4-mini or qwen2.5-7b)
  тЖТ Refines into executive summary
    тЖУ
Final Output
```

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: тАв Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### рд╡рд┐рд╕реНрддрд╛рд░рд╣рд░реВ

**рдердк рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдердкреНрдиреБрд╣реЛрд╕реН:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**рдмреНрдпрд╛рдЪ рдкрд░реАрдХреНрд╖рдг:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### рд╕рдордп рдЕрдиреБрдорд╛рди
- **рдкрд╣рд┐рд▓реЛ рд░рди:** рей-рел рдорд┐рдиреЗрдЯ
- **рдкрдЫрд┐рд▓реНрд▓рд╛ рд░рдирд╣рд░реВ:** рдкреНрд░рддрд┐ рдкреНрд░рд╢реНрди рез-реи рдорд┐рдиреЗрдЯ

---

## рд╕рддреНрд░ режрем: рдЙрджреНрджреЗрд╢реНрдп-рдЖрдзрд╛рд░рд┐рдд рдореЛрдбреЗрд▓ рд░реБрдЯрд┐рдЩ

### рдЙрджреНрджреЗрд╢реНрдп
рдкрддреНрддрд╛ рд▓рд╛рдЧреЗрдХреЛ рдЙрджреНрджреЗрд╢реНрдпрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдкреНрд░рдореНрдкреНрдЯрд╣рд░реВрд▓рд╛рдИ рд╡рд┐рд╢реЗрд╖ рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рдмреБрджреНрдзрд┐рдорд╛рдиреАрдкреВрд░реНрд╡рдХ рд░реБрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реНред

### рдЫрд┐рдЯреЛ рд╕реЗрдЯрдЕрдк

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**рдиреЛрдЯ:** рд╕рддреНрд░ режрем CPU рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рдбрд┐рдлрд▓реНрдЯ рд╣реБрдиреНрдЫ рдЕрдзрд┐рдХрддрдо рдЕрдиреБрдХреВрд▓рддрд╛рдХрд╛ рд▓рд╛рдЧрд┐ред

### рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдЙрдиреЗ

1. **рдЦреЛрд▓реНрдиреБрд╣реЛрд╕реН** `session06_models_router.ipynb`
2. **рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН**
3. **рд╕рдмреИ рд╕реЗрд▓рд╣рд░реВ рдХреНрд░рдо рдЕрдиреБрд╕рд╛рд░ рдЪрд▓рд╛рдЙрдиреБрд╣реЛрд╕реН**

### рдореБрдЦреНрдп рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди

**рдбрд┐рдлрд▓реНрдЯ рдХреНрдпрд╛рдЯрд▓рдЧ (CPU рдореЛрдбреЗрд▓рд╣рд░реВ):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**рд╡реИрдХрд▓реНрдкрд┐рдХ (GPU рдореЛрдбреЗрд▓рд╣рд░реВ):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### рдЙрджреНрджреЗрд╢реНрдп рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрдиреЗ

рд░рд╛рдЙрдЯрд░рд▓реЗ рдЙрджреНрджреЗрд╢реНрдп рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрди regex рдврд╛рдБрдЪрд╛рд╣рд░реВ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрджрдЫ:

| рдЙрджреНрджреЗрд╢реНрдп | рдврд╛рдБрдЪрд╛ рдЙрджрд╛рд╣рд░рдгрд╣рд░реВ | рд░реБрдЯ рдЧрд░рд┐рдПрдХреЛ рдореЛрдбреЗрд▓ |
|---------|------------------|------------------|
| `code` | "refactor", "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize", "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize", "tl;dr" | phi-4-mini-cpu |
| `general` | рдЕрдиреНрдп рд╕рдмреИ | phi-4-mini-cpu |

### рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ

```
тЬУ Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

тЬУ Success! All prompts routed correctly.
```

### рдЕрдиреБрдХреВрд▓рди

**рдЕрдиреБрдХреВрд▓рд┐рдд рдЙрджреНрджреЗрд╢реНрдп рдердкреНрдиреБрд╣реЛрд╕реН:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ч┐╗шпС', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**рдЯреЛрдХрди рдЯреНрд░реНрдпрд╛рдХрд┐рдЩ рд╕рдХреНрд╖рдо рдЧрд░реНрдиреБрд╣реЛрд╕реН:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### GPU рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рд╕реНрд╡рд┐рдЪ рдЧрд░реНрджреИ

рдпрджрд┐ рддрдкрд╛рдИрдВрд╕рдБрдЧ реоGB+ VRAM рдЫ рднрдиреЗ:

1. **рд╕реЗрд▓ #рем** рдорд╛, CPU рдХреНрдпрд╛рдЯрд▓рдЧрд▓рд╛рдИ рдЯрд┐рдкреНрдкрдгреА рдЧрд░реНрдиреБрд╣реЛрд╕реН
2. GPU рдХреНрдпрд╛рдЯрд▓рдЧ рдЕрдирдЯрд┐рдкреНрдкрдгреА рдЧрд░реНрдиреБрд╣реЛрд╕реН
3. GPU рдореЛрдбреЗрд▓рд╣рд░реВ рд▓реЛрдб рдЧрд░реНрдиреБрд╣реЛрд╕реН:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН рд░ рдиреЛрдЯрдмреБрдХ рдкреБрдирдГ рдЪрд▓рд╛рдЙрдиреБрд╣реЛрд╕реН

### рд╕рдордп рдЕрдиреБрдорд╛рди
- **рдкрд╣рд┐рд▓реЛ рд░рди:** рел-резреж рдорд┐рдиреЗрдЯ (рдореЛрдбреЗрд▓ рд▓реЛрдб рдЧрд░реНрджреИ)
- **рдкрдЫрд┐рд▓реНрд▓рд╛ рд░рдирд╣рд░реВ:** рдкреНрд░рддрд┐ рдкрд░реАрдХреНрд╖рдг рейреж-ремреж рд╕реЗрдХреЗрдиреНрдб

---

## рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░рд╣рд░реВ

### рдЧреНрд▓реЛрдмрд▓ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди

Jupyter/VS Code рд╕реБрд░реБ рдЧрд░реНрдиреБ рдЕрдШрд┐ рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН:

**рд╡рд┐рдиреНрдбреЛрдЬ (рдХрдорд╛рдгреНрдб рдкреНрд░рдореНрдкреНрдЯ):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**рд╡рд┐рдиреНрдбреЛрдЬ (рдкрд╛рд╡рд░рд╢реЗрд▓):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**рдореНрдпрд╛рдХрдУрдПрд╕/рд▓рд┐рдирдХреНрд╕:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### рдиреЛрдЯрдмреБрдХрдорд╛ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди

рдХреБрдиреИ рдкрдирд┐ рдиреЛрдЯрдмреБрдХрдХреЛ рд╕реБрд░реБрдорд╛ рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## рд╕рд╛рдорд╛рдиреНрдп рдЖрджреЗрд╢рд╣рд░реВ

### рд╕реЗрд╡рд╛ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### рдореЛрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### рдЕрдиреНрдд рдмрд┐рдиреНрджреБ рдкрд░реАрдХреНрд╖рдг

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рдЖрджреЗрд╢рд╣рд░реВ

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## рдЙрддреНрдХреГрд╖реНрдЯ рдЕрднреНрдпрд╛рд╕рд╣рд░реВ

### рдХреБрдиреИ рдкрдирд┐ рдиреЛрдЯрдмреБрдХ рд╕реБрд░реБ рдЧрд░реНрдиреБ рдЕрдШрд┐

1. **рд╕реЗрд╡рд╛ рдЪрд▓рд┐рд░рд╣реЗрдХреЛ рдЫ рдЬрд╛рдБрдЪ рдЧрд░реНрдиреБрд╣реЛрд╕реН:**
   ```bash
   foundry service status
   ```

2. **рдореЛрдбреЗрд▓рд╣рд░реВ рд▓реЛрдб рдЧрд░рд┐рдПрдХреЛ рдЫ рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН:**
   ```bash
   foundry model ls
   ```

3. **рдиреЛрдЯрдмреБрдХ рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН** рдпрджрд┐ рдкреБрдирдГ рдЪрд▓рд╛рдЙрдБрджреИ

4. **рд╕рдмреИ рдЖрдЙрдЯрдкреБрдЯрд╣рд░реВ рдЦрд╛рд▓реА рдЧрд░реНрдиреБрд╣реЛрд╕реН** рд╕рдлрд╛ рд░рдирдХреЛ рд▓рд╛рдЧрд┐

### рд╕реНрд░реЛрдд рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

1. **CPU рдореЛрдбреЗрд▓рд╣рд░реВ рдбрд┐рдлрд▓реНрдЯ рд░реВрдкрдорд╛ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН** рдЕрдиреБрдХреВрд▓рддрд╛рдХрд╛ рд▓рд╛рдЧрд┐
2. **GPU рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рд╕реНрд╡рд┐рдЪ рдЧрд░реНрдиреБрд╣реЛрд╕реН** рдпрджрд┐ рддрдкрд╛рдИрдВрд╕рдБрдЧ реоGB+ VRAM рдЫ рднрдиреЗ
3. **GPU рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рдмрдиреНрдж рдЧрд░реНрдиреБрд╣реЛрд╕реН** рдиреЛрдЯрдмреБрдХ рдЪрд▓рд╛рдЙрдиреБ рдЕрдШрд┐
4. **рд╕реЗрд╡рд╛ рдЪрд▓рд┐рд░рд╣реЗрдХреЛ рд░рд╛рдЦреНрдиреБрд╣реЛрд╕реН** рдиреЛрдЯрдмреБрдХ рд╕рддреНрд░рд╣рд░реВ рдмреАрдЪ
5. **рд╕реНрд░реЛрдд рдЙрдкрдпреЛрдЧ рдирд┐рдЧрд░рд╛рдиреА рдЧрд░реНрдиреБрд╣реЛрд╕реН** рдЯрд╛рд╕реНрдХ рдореНрдпрд╛рдиреЗрдЬрд░ / nvidia-smi рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░

### рд╕рдорд╕реНрдпрд╛ рд╕рдорд╛рдзрд╛рди

1. **рдХреЛрдб рдбрд┐рдмрдЧрд┐рдЩ рдЧрд░реНрдиреБ рдЕрдШрд┐ рд╕рдзреИрдВ рд╕реЗрд╡рд╛ рдЬрд╛рдБрдЪ рдЧрд░реНрдиреБрд╣реЛрд╕реН**
2. **рдХрд░реНрдиреЗрд▓ рдкреБрдирдГ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН** рдпрджрд┐ рдкреБрд░рд╛рдиреЛ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди рджреЗрдЦрд┐рдиреНрдЫ
3. **рдХреБрдиреИ рдкрдирд┐ рдкрд░рд┐рд╡рд░реНрддрдирдкрдЫрд┐ рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рд╕реЗрд▓рд╣рд░реВ рдкреБрдирдГ рдЪрд▓рд╛рдЙрдиреБрд╣реЛрд╕реН**
4. **рдореЛрдбреЗрд▓ рдирд╛рдорд╣рд░реВ рдЬрд╛рдБрдЪ рдЧрд░реНрдиреБрд╣реЛрд╕реН** рд▓реЛрдб рдЧрд░рд┐рдПрдХреЛрд╕рдБрдЧ рдореЗрд▓ рдЦрд╛рдиреНрдЫ
5. **рдЕрдиреНрдд рдмрд┐рдиреНрджреБ рдкреЛрд░реНрдЯ рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН** рд╕реЗрд╡рд╛ рд╕реНрдерд┐рддрд┐рд╕рдБрдЧ рдореЗрд▓ рдЦрд╛рдиреНрдЫ

---

## рдЫрд┐рдЯреЛ рд╕рдиреНрджрд░реНрдн: рдореЛрдбреЗрд▓ рдЙрдкрдирд╛рдорд╣рд░реВ

### рд╕рд╛рдорд╛рдиреНрдп рдореЛрдбреЗрд▓рд╣рд░реВ

| рдЙрдкрдирд╛рдо | рдЖрдХрд╛рд░ | рдЙрддреНрддрдо рдкреНрд░рдпреЛрдЧ | RAM/VRAM | рднреЗрд░рд┐рдпрдиреНрдЯрд╣рд░реВ |
|-------|------|--------------|----------|-------------|
| `phi-4-mini` | ~4B | рд╕рд╛рдорд╛рдиреНрдп рдЪреНрдпрд╛рдЯ, рд╕рдВрдХреНрд╖реЗрдкрдг | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | рдХреЛрдб рдЙрддреНрдкрд╛рджрди, рдкреБрдирдГ рд╕рдВрд░рдЪрдирд╛ | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | рд╕рд╛рдорд╛рдиреНрдп рдХрд╛рд░реНрдпрд╣рд░реВ, рдХреБрд╢рд▓ | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | рдЫрд┐рдЯреЛ, рдХрдо рд╕реНрд░реЛрдд | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | рд╡рд░реНрдЧреАрдХрд░рдг, рдиреНрдпреВрдирддрдо рд╕реНрд░реЛрдд | 1-2GB | `-cpu`, `-cuda-gpu` |

### рднреЗрд░рд┐рдпрдиреНрдЯ рдирд╛рдордХрд░рдг

- **рдЖрдзрд╛рд░ рдирд╛рдо** (рдЬрд╕реНрддреИ, `phi-4-mini`): рддрдкрд╛рдИрдВрдХреЛ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрддрдо рднреЗрд░рд┐рдпрдиреНрдЯ рд╕реНрд╡рддрдГ рдЪрдпрди рдЧрд░реНрджрдЫ
- **`-cpu`**: CPU-рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреНрдб, рд╕рдмреИ рдард╛рдЙрдБрдорд╛ рдХрд╛рдо рдЧрд░реНрдЫ
- **`-cuda-gpu`**: NVIDIA GPU-рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреНрдб, реоGB+ VRAM рдЖрд╡рд╢реНрдпрдХ
- **`-npu`**: Qualcomm NPU-рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреНрдб, NPU рдбреНрд░рд╛рдЗрднрд░рд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ

**рд╕рд┐рдлрд╛рд░рд┐рд╕:** рдЖрдзрд╛рд░ рдирд╛рдорд╣рд░реВ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН (рд╕рдлрд┐рдХреНрд╕ рдмрд┐рдирд╛) рд░ рдлрд╛рдЙрдиреНрдбреНрд░реА рд▓реЛрдХрд▓рд▓рд╛рдИ рдЙрддреНрддрдо рднреЗрд░рд┐рдпрдиреНрдЯ рд╕реНрд╡рддрдГ рдЪрдпрди рдЧрд░реНрди рджрд┐рдиреБрд╣реЛрд╕реНред

---

## рд╕рдлрд▓рддрд╛ рд╕рдВрдХреЗрддрдХрд╣рд░реВ

рддрдкрд╛рдИрдВ рддрдпрд╛рд░ рд╣реБрдиреБрд╣реБрдиреНрдЫ рдЬрдм рддрдкрд╛рдИрдВ рджреЗрдЦреНрдиреБрд╣реБрдиреНрдЫ:

тЬЕ `foundry service status` "running" рджреЗрдЦрд╛рдЙрдБрдЫ  
тЬЕ `foundry model ls` рддрдкрд╛рдИрдВрдХреЛ рдЖрд╡рд╢реНрдпрдХ рдореЛрдбреЗрд▓рд╣рд░реВ рджреЗрдЦрд╛рдЙрдБрдЫ  
тЬЕ рд╕реЗрд╡рд╛ рд╕рд╣реА рдЕрдиреНрдд рдмрд┐рдиреНрджреБрдорд╛ рдкрд╣реБрдБрдЪрдпреЛрдЧреНрдп рдЫ  
тЬЕ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдЬрд╛рдБрдЪ реирежреж OK рдлрд░реНрдХрд╛рдЙрдБрдЫ  
тЬЕ рдиреЛрдЯрдмреБрдХ рдбрд╛рдпрдЧреНрдиреЛрд╕реНрдЯрд┐рдХ рд╕реЗрд▓рд╣рд░реВ рдкрд╛рд╕ рд╣реБрдиреНрдЫ  
тЬЕ рдЖрдЙрдЯрдкреБрдЯрдорд╛ рдХреБрдиреИ рдЬрдбрд╛рди рддреНрд░реБрдЯрд┐рд╣рд░реВ рдЫреИрдирдиреН  

---

## рд╕рд╣рдпреЛрдЧ рдкреНрд░рд╛рдкреНрдд рдЧрд░реНрджреИ

### рджрд╕реНрддрд╛рд╡реЗрдЬреАрдХрд░рдг
- **рдореБрдЦреНрдп рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/Foundry-Local  
- **рдкрд╛рдЗрдерди SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python  
- **CLI рд╕рдиреНрджрд░реНрдн**: https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md  
- **рд╕рдорд╕реНрдпрд╛ рд╕рдорд╛рдзрд╛рди**: рдпрд╕ рдирд┐рд░реНрджреЗрд╢рд┐рдХрд╛рдорд╛ `troubleshooting.md` рд╣реЗрд░реНрдиреБрд╣реЛрд╕реН  

### GitHub рдореБрджреНрджрд╛рд╣рд░реВ
- https://github.com/microsoft/Foundry-Local/issues  
- https://github.com/microsoft/edgeai-for-beginners/issues  

---

**рдЕрдиреНрддрд┐рдо рдЕрджреНрдпрд╛рд╡рдзрд┐рдХ:** рдЕрдХреНрдЯреЛрдмрд░ рео, реирежреирел  
**рд╕рдВрд╕реНрдХрд░рдг:** рдХрд╛рд░реНрдпрд╢рд╛рд▓рд╛ рдиреЛрдЯрдмреБрдХрд╣рд░реВ реи.реж  

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпреЛ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдкреНрд░рдпреЛрдЧ рдЧрд░реА рдЕрдиреБрд╡рд╛рдж рдЧрд░рд┐рдПрдХреЛ рд╣реЛред рд╣рд╛рдореА рдпрдерд╛рд╕рдореНрднрд╡ рд╕рдЯреАрдХрддрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрди рдкреНрд░рдпрд╛рд╕ рдЧрд░реНрдЫреМрдВ, рддрд░ рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджрд┐рдиреБрд╣реЛрд╕реН рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рджрд╣рд░реВрдорд╛ рддреНрд░реБрдЯрд┐рд╣рд░реВ рд╡рд╛ рдЕрд╢реБрджреНрдзрддрд╛рд╣рд░реВ рд╣реБрди рд╕рдХреНрдЫрдиреНред рдпрд╕рдХреЛ рдореВрд▓ рднрд╛рд╖рд╛рдорд╛ рд░рд╣реЗрдХреЛ рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝рд▓рд╛рдИ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд┐рдиреБрдкрд░реНрдЫред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реАрдХрд╛ рд▓рд╛рдЧрд┐, рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рд╕рд┐рдлрд╛рд░рд┐рд╕ рдЧрд░рд┐рдиреНрдЫред рдпрд╕ рдЕрдиреБрд╡рд╛рджрдХреЛ рдкреНрд░рдпреЛрдЧрдмрд╛рдЯ рдЙрддреНрдкрдиреНрди рд╣реБрдиреЗ рдХреБрдиреИ рдкрдирд┐ рдЧрд▓рддрдлрд╣рдореА рд╡рд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛рдХрд╛ рд▓рд╛рдЧрд┐ рд╣рд╛рдореА рдЬрд┐рдореНрдореЗрд╡рд╛рд░ рд╣реБрдиреЗ рдЫреИрдиреМрдВред