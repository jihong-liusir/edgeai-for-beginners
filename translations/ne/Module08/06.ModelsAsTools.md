<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "33ecd8ecf0e9347a2b4839a9916e49fb",
  "translation_date": "2025-09-30T23:57:21+00:00",
  "source_file": "Module08/06.ModelsAsTools.md",
  "language_code": "ne"
}
-->
## ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§®

Foundry Local ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ AI ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§Æ‡•ã‡§°‡•ç‡§Ø‡•Å‡§≤‡§∞, ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§â‡§™‡§ï‡§∞‡§£‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§™‡§ï‡§∞‡§£‡§Æ‡•à ‡§∏‡§ø‡§ß‡•à ‡§ö‡§≤‡•ç‡§õ‡•§ ‡§Ø‡•ã ‡§∏‡§§‡•ç‡§∞‡§≤‡•á ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡•ç‡§®‡•á, ‡§ï‡§Æ ‡§µ‡§ø‡§≤‡§Æ‡•ç‡§¨‡§§‡§æ ‡§≠‡§è‡§ï‡•ã ‡§á‡§®‡§´‡§∞‡•á‡§®‡•ç‡§∏‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§™‡•ç‡§∞‡§µ‡§æ‡§π‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§ú‡•ã‡§° ‡§¶‡§ø‡§®‡•ç‡§õ ‡§∞ SDKs, APIs, ‡§µ‡§æ CLI ‡§Æ‡§æ‡§∞‡•ç‡§´‡§§ ‡§Ø‡•Ä ‡§â‡§™‡§ï‡§∞‡§£‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡§ø‡§ï‡§æ‡§â‡§Å‡§õ‡•§ ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§™‡§∞‡•á‡§Æ‡§æ Azure AI Foundry ‡§Æ‡§æ ‡§∏‡•ç‡§ï‡•á‡§≤ ‡§ó‡§∞‡•ç‡§®‡•á ‡§§‡§∞‡§ø‡§ï‡§æ ‡§™‡§®‡§ø ‡§∏‡§ø‡§ï‡•ç‡§®‡•Å‡§π‡•Å‡§®‡•á‡§õ‡•§

> **üîÑ ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï SDK ‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§Ö‡§¶‡•ç‡§Ø‡§æ‡§µ‡§ß‡§ø‡§ï ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã**: ‡§Ø‡•ã ‡§Æ‡•ã‡§°‡•ç‡§Ø‡•Å‡§≤‡§≤‡§æ‡§à ‡§™‡§õ‡§ø‡§≤‡•ç‡§≤‡•ã Microsoft Foundry-Local ‡§∞‡§ø‡§™‡•ã‡§ú‡§ø‡§ü‡§∞‡•Ä ‡§¢‡§æ‡§Å‡§ö‡§æ‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§∏‡§Æ‡§æ‡§Ø‡•ã‡§ú‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ ‡§∞ `samples/06/` ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§∞‡§æ‡§â‡§ü‡§ø‡§ô ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§®‡§∏‡§Å‡§ó ‡§Æ‡•á‡§≤ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•§ ‡§â‡§¶‡§æ‡§π‡§∞‡§£‡§π‡§∞‡•Ç‡§≤‡•á ‡§Ö‡§¨ ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï `foundry-local-sdk` ‡§∞ ‡§â‡§®‡•ç‡§®‡§§ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§ö‡§Ø‡§® ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§õ‡§®‡•ç‡•§

**üèóÔ∏è ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡•Å‡§Å‡§¶‡§æ‡§π‡§∞‡•Ç:**
- **‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∞‡§æ‡§â‡§ü‡§ø‡§ô**: ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø, ‡§§‡§∞‡•ç‡§ï, ‡§ï‡•ã‡§°, ‡§∞ ‡§∏‡§ø‡§∞‡•ç‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç ‡§¨‡•Ä‡§ö ‡§ï‡•Å‡§û‡•ç‡§ú‡•Ä‡§∂‡§¨‡•ç‡§¶-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ö‡§Ø‡§®
- **‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï SDK ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£**: ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∏‡•á‡§µ‡§æ ‡§™‡§§‡•ç‡§§‡§æ ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§≠‡§è‡§ï‡•ã `FoundryLocalManager` ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§¶‡§õ
- **‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§ï‡§®‡•ç‡§´‡§ø‡§ó‡§∞‡•á‡§∏‡§®**: ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ö‡§∞‡§π‡§∞‡•Ç ‡§Æ‡§æ‡§∞‡•ç‡§´‡§§ ‡§≤‡§ö‡§ø‡§≤‡•ã ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§Ö‡§∏‡§æ‡§á‡§®‡§Æ‡•á‡§®‡•ç‡§ü
- **‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§Ö‡§®‡•Å‡§ó‡§Æ‡§®**: ‡§∏‡•á‡§µ‡§æ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£ ‡§∞ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß‡§§‡§æ ‡§ú‡§æ‡§Å‡§ö
- **‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§§‡§Ø‡§æ‡§∞**: ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•ç‡§Ø‡§æ‡§®‡•ç‡§°‡§≤‡§ø‡§ô ‡§∞ ‡§´‡§≤‡§¨‡•ç‡§Ø‡§æ‡§ï ‡§∏‡§Ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§π‡§∞‡•Ç

**üìÅ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§®:**
- `samples/06/router.py` - ‡§ï‡•Å‡§û‡•ç‡§ú‡•Ä‡§∂‡§¨‡•ç‡§¶-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ö‡§Ø‡§®‡§∏‡§π‡§ø‡§§‡§ï‡•ã ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∞‡§æ‡§â‡§ü‡§∞
- `samples/06/model_router.ipynb` - ‡§Ö‡§®‡•ç‡§§‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§â‡§¶‡§æ‡§π‡§∞‡§£‡§π‡§∞‡•Ç ‡§∞ ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï‡§π‡§∞‡•Ç
- `samples/06/README.md` - ‡§ï‡§®‡•ç‡§´‡§ø‡§ó‡§∞‡•á‡§∏‡§® ‡§∞ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§π‡§∞‡•Ç

‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§π‡§∞‡•Ç:
- Foundry Local ‡§°‡§ï‡§π‡§∞‡•Ç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ‡§á‡§®‡§´‡§∞‡•á‡§®‡•ç‡§∏ SDKs ‡§∏‡§Å‡§ó ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç ‡§ï‡§Æ‡•ç‡§™‡§æ‡§á‡§≤ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§®

Foundry Local ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ AI ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§Æ‡•ã‡§°‡•ç‡§Ø‡•Å‡§≤‡§∞, ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§â‡§™‡§ï‡§∞‡§£‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§™‡§ï‡§∞‡§£‡§Æ‡•à ‡§∏‡§ø‡§ß‡•à ‡§ö‡§≤‡•ç‡§õ‡•§ ‡§Ø‡•ã ‡§∏‡§§‡•ç‡§∞‡§≤‡•á ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡•ç‡§®‡•á, ‡§ï‡§Æ ‡§µ‡§ø‡§≤‡§Æ‡•ç‡§¨‡§§‡§æ ‡§≠‡§è‡§ï‡•ã ‡§á‡§®‡§´‡§∞‡•á‡§®‡•ç‡§∏‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§™‡•ç‡§∞‡§µ‡§æ‡§π‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§ú‡•ã‡§° ‡§¶‡§ø‡§®‡•ç‡§õ ‡§∞ SDKs, APIs, ‡§µ‡§æ CLI ‡§Æ‡§æ‡§∞‡•ç‡§´‡§§ ‡§Ø‡•Ä ‡§â‡§™‡§ï‡§∞‡§£‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡§ø‡§ï‡§æ‡§â‡§Å‡§õ‡•§ ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§™‡§∞‡•á‡§Æ‡§æ Azure AI Foundry ‡§Æ‡§æ ‡§∏‡•ç‡§ï‡•á‡§≤ ‡§ó‡§∞‡•ç‡§®‡•á ‡§§‡§∞‡§ø‡§ï‡§æ ‡§™‡§®‡§ø ‡§∏‡§ø‡§ï‡•ç‡§®‡•Å‡§π‡•Å‡§®‡•á‡§õ‡•§

‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§π‡§∞‡•Ç:
- Foundry Local ‡§°‡§ï‡§π‡§∞‡•Ç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ‡§á‡§®‡§´‡§∞‡•á‡§®‡•ç‡§∏ SDKs ‡§∏‡§Å‡§ó ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç ‡§ï‡§Æ‡•ç‡§™‡§æ‡§á‡§≤ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## ‡§∏‡§ø‡§ï‡•ç‡§®‡•á ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡§π‡§∞‡•Ç
- ‡§â‡§™‡§ï‡§∞‡§£‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§°‡§ø‡§ú‡§æ‡§á‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§¢‡§æ‡§Å‡§ö‡§æ‡§π‡§∞‡•Ç ‡§â‡§™‡§ï‡§∞‡§£‡§Æ‡•à ‡§¨‡§®‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç
- OpenAI-‡§∏‡§Å‡§ó ‡§Æ‡§ø‡§≤‡•ç‡§®‡•á REST API ‡§µ‡§æ SDKs ‡§Æ‡§æ‡§∞‡•ç‡§´‡§§ ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
- ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§°‡•ã‡§Æ‡•á‡§®-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
- Azure AI Foundry ‡§Æ‡§æ ‡§π‡§æ‡§á‡§¨‡•ç‡§∞‡§ø‡§° ‡§∏‡•ç‡§ï‡•á‡§≤‡§ø‡§ô‡§ï‡•ã ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§¨‡§®‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç

## ‡§≠‡§æ‡§ó ‡•ß: ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∞‡§æ‡§â‡§ü‡§∞ (‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§®)

‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø: ‡§∏‡•ã‡§ß‡§™‡•Å‡§õ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§Æ‡§æ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡§æ‡§â‡§ü‡§ø‡§ô‡§∏‡§π‡§ø‡§§ ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§ö‡§Ø‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§

> **üìã ‡§®‡•ã‡§ü**: ‡§Ø‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® `samples/06/router.py` ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§¢‡§æ‡§Å‡§ö‡§æ‡§∏‡§Å‡§ó ‡§Æ‡•á‡§≤ ‡§ñ‡§æ‡§®‡•ç‡§õ, ‡§ú‡§∏‡§Æ‡§æ ‡§â‡§®‡•ç‡§®‡§§ ‡§ï‡•Å‡§û‡•ç‡§ú‡•Ä‡§∂‡§¨‡•ç‡§¶-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§ö‡§Ø‡§® ‡§õ‡•§

‡§ö‡§∞‡§£ ‡•ß) FoundryLocalManager ‡§∏‡§Å‡§ó ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∞‡§æ‡§â‡§ü‡§∞ ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```python
# router/intelligent_router.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
from typing import Dict, Any, Optional
import os
import json

class ModelRouter:
    """Intelligent model router that selects appropriate models for different task types."""
    
    def __init__(self):
        self.client = None
        self.base_url = None
        self.tools = self._load_tool_registry()
        self._initialize_client()
    
    def _load_tool_registry(self) -> Dict[str, Dict[str, Any]]:
        """Load tool registry from environment or use defaults."""
        default_tools = {
            "general": {
                "model": os.environ.get("GENERAL_MODEL", "phi-4-mini"),
                "notes": "Fast general-purpose chat and Q&A",
                "temperature": 0.7
            },
            "reasoning": {
                "model": os.environ.get("REASONING_MODEL", "deepseek-r1-7b"),
                "notes": "Step-by-step analysis and logical reasoning",
                "temperature": 0.3
            },
            "code": {
                "model": os.environ.get("CODE_MODEL", "qwen2.5-7b"),
                "notes": "Code generation, debugging, and technical tasks",
                "temperature": 0.2
            },
            "creative": {
                "model": os.environ.get("CREATIVE_MODEL", "phi-4-mini"),
                "notes": "Creative writing and storytelling",
                "temperature": 0.9
            }
        }
        
        # Check for environment override
        tools_env = os.environ.get("TOOL_REGISTRY")
        if tools_env:
            try:
                return json.loads(tools_env)
            except json.JSONDecodeError:
                print("Warning: Invalid TOOL_REGISTRY JSON, using defaults")
        
        return default_tools
```
  
‡§ö‡§∞‡§£ ‡•®) ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï SDK ‡§∞ ‡§∏‡•á‡§µ‡§æ ‡§™‡§§‡•ç‡§§‡§æ ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§∏‡§π‡§ø‡§§ ‡§ï‡•ç‡§≤‡§æ‡§á‡§®‡•ç‡§ü ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```python
    def _initialize_client(self):
        """Initialize OpenAI client with Foundry Local or fallback configuration."""
        try:
            from foundry_local import FoundryLocalManager
            # Try to use any available model for client initialization
            first_model = next(iter(self.tools.values()))["model"]
            manager = FoundryLocalManager(first_model)
            
            self.client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            self.base_url = manager.endpoint
            print(f"‚úÖ Foundry Local SDK initialized")
        except Exception as e:
            print(f"Warning: Could not use Foundry SDK ({e}), falling back to manual configuration")
            # Fallback to manual configuration
            self.base_url = os.environ.get("BASE_URL", "http://localhost:8000")
            api_key = os.environ.get("API_KEY", "")
            
            self.client = OpenAI(
                base_url=f"{self.base_url}/v1",
                api_key=api_key
            )
            print(f"Initialized manual configuration at {self.base_url}")
    
    def select_tool(self, user_query: str) -> str:
        """Select the most appropriate tool based on the user query."""
        query_lower = user_query.lower()
        
        # Code-related keywords
        code_keywords = ["code", "python", "function", "class", "method", "bug", "debug", 
                        "programming", "script", "algorithm", "implementation", "refactor"]
        if any(keyword in query_lower for keyword in code_keywords):
            return "code"
        
        # Reasoning keywords
        reasoning_keywords = ["why", "how", "explain", "step-by-step", "reason", "analyze", 
                             "think", "logic", "because", "cause", "compare", "evaluate"]
        if any(keyword in query_lower for keyword in reasoning_keywords):
            return "reasoning"
        
        # Creative keywords
        creative_keywords = ["story", "poem", "creative", "imagine", "write", "tale", 
                           "narrative", "fiction", "character", "plot"]
        if any(keyword in query_lower for keyword in creative_keywords):
            return "creative"
        
        # Default to general
        return "general"
    
    def chat(self, model: str, content: str, max_tokens: int = 300, temperature: Optional[float] = None) -> str:
        """Send chat completion request to the specified model."""
        try:
            params = {
                "model": model,
                "messages": [{"role": "user", "content": content}],
                "max_tokens": max_tokens
            }
            
            if temperature is not None:
                params["temperature"] = temperature
            
            response = self.client.chat.completions.create(**params)
            return response.choices[0].message.content
        except Exception as e:
            return f"Error generating response with model {model}: {str(e)}"
```
  
‡§ö‡§∞‡§£ ‡•©) ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§∞‡§æ‡§â‡§ü‡§ø‡§ô ‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç (`samples/06/router.py` ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç)  
```python
    def route_and_run(self, prompt: str) -> Dict[str, Any]:
        """Route the prompt to the appropriate model and generate response."""
        tool_key = self.select_tool(prompt)
        tool_config = self.tools[tool_key]
        model = tool_config["model"]
        temperature = tool_config.get("temperature", 0.7)
        
        print(f"üéØ Selected tool: {tool_key} (model: {model})")
        
        answer = self.chat(
            model=model, 
            content=prompt, 
            max_tokens=400, 
            temperature=temperature
        )
        
        return {
            "tool": tool_key,
            "model": model,
            "tool_description": tool_config["notes"],
            "temperature": temperature,
            "answer": answer
        }
    
    def check_service_health(self) -> Dict[str, Any]:
        """Check Foundry Local service health and available models."""
        try:
            models_response = self.client.models.list()
            available_models = [model.id for model in models_response.data]
            
            return {
                "status": "healthy",
                "base_url": self.base_url,
                "available_models": available_models,
                "tools_configured": list(self.tools.keys())
            }
        except Exception as e:
            return {
                "status": "error",
                "base_url": self.base_url,
                "error": str(e)
            }

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    router = ModelRouter()
    
    # Check health
    health = router.check_service_health()
    print(f"Service Health: {json.dumps(health, indent=2)}")
    
    # Test different query types
    queries = [
        "Write a Python function to calculate fibonacci numbers",  # -> code
        "Explain step-by-step why the sky is blue",  # -> reasoning
        "Tell me a creative story about AI",  # -> creative
        "What's the weather like today?"  # -> general
    ]
    
    for query in queries:
        result = router.route_and_run(query)
        print(f"\nQuery: {query}")
        print(f"Selected: {result['tool']} -> {result['model']}")
        print(f"Answer: {result['answer'][:100]}...")
```
  

## ‡§≠‡§æ‡§ó ‡•®: ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï SDK ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ (‡§ö‡§∞‡§£-‡§¶‡§∞-‡§ö‡§∞‡§£)

‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø: OpenAI Python SDK ‡§∏‡§Å‡§ó Foundry Local SDK ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§∏‡§π‡§ú ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§

‡§ö‡§∞‡§£ ‡•ß) ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞‡§§‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```cmd
cd Module08
.\.venv\Scripts\activate
pip install foundry-local-sdk openai
```
  
‡§ö‡§∞‡§£ ‡•®) ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡§®‡•ç‡§´‡§ø‡§ó‡§∞ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï - `samples/06/README.md` ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç)  
```cmd
REM Override default models per tool
set GENERAL_MODEL=phi-4-mini
set REASONING_MODEL=deepseek-r1-7b
set CODE_MODEL=qwen2.5-7b
REM Or provide a full JSON registry
set TOOL_REGISTRY={"general":{"model":"phi-4-mini"},"reasoning":{"model":"deepseek-r1-7b"}}
```
  
‡§ö‡§∞‡§£ ‡•©) ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï SDK ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```python
# modern_sdk_demo.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
import sys

def main():
    """Demonstrate modern SDK integration."""
    try:
        # Initialize with FoundryLocalManager
        alias = "phi-4-mini"
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client using Foundry Local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Get model info
        model_info = manager.get_model_info(alias)
        print(f"Using model: {model_info.id}")
        
        # Make request with streaming
        stream = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Explain edge AI benefits in one paragraph."}],
            stream=True,
            max_tokens=200
        )
        
        print("Response: ", end="")
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print()
        
    except Exception as e:
        print(f"Error: {e}")
        print("Ensure Foundry Local is running with: foundry model run phi-4-mini")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
  

## ‡§≠‡§æ‡§ó ‡•©: ‡§°‡•ã‡§Æ‡•á‡§® ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® (‡§ö‡§∞‡§£-‡§¶‡§∞-‡§ö‡§∞‡§£)

‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø: ‡§™‡•ç‡§∞‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ü‡•á‡§Æ‡•ç‡§™‡•ç‡§≤‡•á‡§ü‡§π‡§∞‡•Ç ‡§∞ JSON ‡§∏‡•ç‡§ï‡§ø‡§Æ‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§°‡•ã‡§Æ‡•á‡§®‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü‡§π‡§∞‡•Ç ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§

‡§ö‡§∞‡§£ ‡•ß) ‡§°‡•ã‡§Æ‡•á‡§® ‡§™‡•ç‡§∞‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ü‡•á‡§Æ‡•ç‡§™‡•ç‡§≤‡•á‡§ü ‡§¨‡§®‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```python
# domain/templates.py
BUSINESS_ANALYST_SYSTEM = """
You are a senior business analyst. Provide:
1) Key insights
2) Risks
3) Next steps
Respond in valid JSON with fields: insights, risks, next_steps.
"""
```
  
‡§ö‡§∞‡§£ ‡•®) JSON ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§≤‡§æ‡§ó‡•Ç ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```python
# domain/analyst.py
import requests, os, json

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}

from domain.templates import BUSINESS_ANALYST_SYSTEM

def analyze(text: str) -> dict:
    messages = [
        {"role":"system","content": BUSINESS_ANALYST_SYSTEM},
        {"role":"user","content": f"Analyze this business text:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
    "model":"phi-4-mini",
        "messages": messages,
        "response_format": {"type":"json_object"},
        "temperature": 0.3
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    # Parse JSON content
    content = r.json()["choices"][0]["message"]["content"]
    return json.loads(content)

if __name__ == "__main__":
    print(analyze("Sales dipped 12% in Q3 due to supply constraints and marketing cuts."))
```
  

## ‡§≠‡§æ‡§ó ‡•™: ‡§Ö‡§´‡§≤‡§æ‡§á‡§® ‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø (‡§ö‡§∞‡§£-‡§¶‡§∞-‡§ö‡§∞‡§£)

‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø: ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§â‡§™‡§ï‡§∞‡§£‡§ï‡•ã ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§ö‡§≤‡§æ‡§â‡§Å‡§¶‡§æ ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∞ ‡§≤‡§ö‡§ø‡§≤‡•ã‡§™‡§® ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§

‡§ö‡§∞‡§£ ‡•ß) ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Ö‡§®‡•ç‡§§ ‡§¨‡§ø‡§®‡•ç‡§¶‡•Å‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§ø-‡§µ‡§æ‡§∞‡•ç‡§Æ ‡§∞ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```cmd
foundry model run phi-4-mini
curl http://localhost:8000/v1/models
```
  
‡§ö‡§∞‡§£ ‡•®) ‡§á‡§®‡§™‡•Å‡§ü‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§∏‡§´‡§æ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç  
```python
# security/sanitize.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
‡§ö‡§∞‡§£ ‡•©) ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø-‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§ù‡§£‡•ç‡§°‡§æ ‡§∞ ‡§≤‡§ó‡§ø‡§ô  
```python
# security/local_only.py
import os, json, time
LOG = os.getenv("MODELS_AS_TOOLS_LOG", "./tools_logs.jsonl")

def record(event: dict):
    with open(LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")

# Usage before each call
def before_call(tool_name, payload):
    record({"ts": time.time(), "tool": tool_name, "event": "before_call"})

# After each call
def after_call(tool_name, result):
    record({"ts": time.time(), "tool": tool_name, "event": "after_call"})
```
  

## ‡§≠‡§æ‡§ó ‡•´: ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡§∞‡§ø‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§∞ ‡§∏‡•ç‡§ï‡•á‡§≤‡§ø‡§ô

‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø: ‡§Ö‡§®‡•Å‡§ó‡§Æ‡§® ‡§∞ Azure AI Foundry ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£‡§∏‡§π‡§ø‡§§ ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§∞‡§æ‡§â‡§ü‡§∞ ‡§™‡§∞‡§ø‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§

> **üìã ‡§®‡•ã‡§ü**: `samples/06/model_router.ipynb` ‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§®‡§≤‡•á ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡§∞‡§ø‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§¢‡§æ‡§Å‡§ö‡§æ‡§π‡§∞‡•Ç‡§ï‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§â‡§¶‡§æ‡§π‡§∞‡§£‡§π‡§∞‡•Ç ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§

‡§ö‡§∞‡§£ ‡•ß) ‡§Ö‡§®‡•Å‡§ó‡§Æ‡§®‡§∏‡§π‡§ø‡§§ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§∞‡§æ‡§â‡§ü‡§∞ (`samples/06/router.py` ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç)  
```python
# production/router.py
from router.intelligent_router import ModelRouter
import json
import time
import sys

class ProductionModelRouter(ModelRouter):
    """Production-ready model router with monitoring and logging."""
    
    def __init__(self):
        super().__init__()
        self.request_count = 0
        self.error_count = 0
        self.start_time = time.time()
    
    def route_and_run_with_monitoring(self, prompt: str) -> Dict[str, Any]:
        """Route with comprehensive monitoring and error handling."""
        start_time = time.time()
        self.request_count += 1
        
        try:
            result = self.route_and_run(prompt)
            processing_time = time.time() - start_time
            
            # Log successful request
            self._log_request({
                "status": "success",
                "tool": result["tool"],
                "model": result["model"],
                "processing_time": processing_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            result["processing_time"] = processing_time
            return result
            
        except Exception as e:
            self.error_count += 1
            error_result = {
                "status": "error",
                "error": str(e),
                "processing_time": time.time() - start_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            self._log_request(error_result)
            return error_result
    
    def _log_request(self, data: Dict[str, Any]):
        """Log request data for monitoring."""
        print(f"üìä {json.dumps(data)}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get router statistics."""
        uptime = time.time() - self.start_time
        return {
            "uptime_seconds": uptime,
            "total_requests": self.request_count,
            "error_count": self.error_count,
            "success_rate": (self.request_count - self.error_count) / max(1, self.request_count),
            "requests_per_minute": self.request_count / max(1, uptime / 60)
        }

def main():
    """Production router demo."""
    router = ProductionModelRouter()
    
    # Health check
    health = router.check_service_health()
    if health["status"] == "error":
        print(f"‚ùå Service health check failed: {health['error']}")
        sys.exit(1)
    
    print(f"‚úÖ Service healthy with {len(health['available_models'])} models")
    
    # Process user query
    user_prompt = " ".join(sys.argv[1:]) or "Write three benefits of on-device AI in JSON format."
    print(f"\nüéØ Processing: {user_prompt}")
    
    result = router.route_and_run_with_monitoring(user_prompt)
    
    if result.get("status") == "error":
        print(f"‚ùå Error: {result['error']}")
    else:
        print(f"\nüìã Result:")
        print(f"Tool: {result['tool']} -> Model: {result['model']}")
        print(f"Processing Time: {result['processing_time']:.2f}s")
        print(f"Answer: {result['answer']}")
    
    # Show stats
    stats = router.get_stats()
    print(f"\nüìä Statistics: {json.dumps(stats, indent=2)}")

if __name__ == "__main__":
    main()
```
  

## ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§ö‡•á‡§ï‡§≤‡§ø‡§∏‡•ç‡§ü
- [ ] ‡§ï‡•Å‡§û‡•ç‡§ú‡•Ä‡§∂‡§¨‡•ç‡§¶-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ö‡§Ø‡§®‡§∏‡§π‡§ø‡§§ ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∞‡§æ‡§â‡§ü‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç (`samples/06/router.py`)
- [ ] ‡§ß‡•á‡§∞‡•à ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç ‡§ï‡§®‡•ç‡§´‡§ø‡§ó‡§∞ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç (‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø, ‡§§‡§∞‡•ç‡§ï, ‡§ï‡•ã‡§°, ‡§∏‡§ø‡§∞‡•ç‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï)
- [ ] ‡§Ö‡§®‡•ç‡§§‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï Jupyter ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç (`samples/06/model_router.ipynb`)
- [ ] ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§ï‡§®‡•ç‡§´‡§ø‡§ó‡§∞‡•á‡§∏‡§® ‡§∏‡•á‡§ü ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
- [ ] ‡§∏‡•á‡§µ‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§Ö‡§®‡•Å‡§ó‡§Æ‡§® ‡§∞ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•ç‡§Ø‡§æ‡§®‡•ç‡§°‡§≤‡§ø‡§ô ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
- [ ] ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§≤‡§ó‡§ø‡§ô‡§∏‡§π‡§ø‡§§ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§∞‡§æ‡§â‡§ü‡§∞ ‡§™‡§∞‡§ø‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç

## ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§®‡§Æ‡•Ç‡§®‡§æ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£

‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ö‡§≤‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç:  
```cmd
cd Module08
.\.venv\Scripts\activate

REM Start required models
foundry model run phi-4-mini
foundry model run qwen2.5-7b
foundry model run deepseek-r1-7b

REM Test the intelligent router
python samples\06\router.py "Write a Python function to sort a list"
python samples\06\router.py "Explain step-by-step how bubble sort works"
python samples\06\router.py "Tell me a creative story about robots"

REM Explore the interactive notebook
jupyter notebook samples/06/model_router.ipynb
```
  

## ‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§π‡§∞‡•Ç ‡§∞ ‡§Ü‡§ó‡§æ‡§Æ‡•Ä ‡§ï‡§¶‡§Æ‡§π‡§∞‡•Ç
- **‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§®**: `samples/06/` - ‡§ß‡•á‡§∞‡•à ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®‡§∏‡§π‡§ø‡§§‡§ï‡•ã ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§∞‡§æ‡§â‡§ü‡§∞
- **Microsoft ‡§®‡§Æ‡•Ç‡§®‡§æ‡§π‡§∞‡•Ç**: [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)
- **‡§è‡§ï‡•Ä‡§ï‡§∞‡§£ ‡§°‡§ï‡§π‡§∞‡•Ç**: [‡§á‡§®‡§´‡§∞‡•á‡§®‡•ç‡§∏ SDKs ‡§∏‡§Å‡§ó ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks)
- **‡§â‡§®‡•ç‡§®‡§§ ‡§¢‡§æ‡§Å‡§ö‡§æ‡§π‡§∞‡•Ç**: ‡§Æ‡•ã‡§°‡•ç‡§Ø‡•Å‡§≤ ‡•´ ‡§Æ‡§æ ‡§´‡§ô‡•ç‡§∏‡§® ‡§ï‡§≤‡§ø‡§ô ‡§∞ ‡§Æ‡§≤‡•ç‡§ü‡§ø-‡§è‡§ú‡•á‡§®‡•ç‡§ü ‡§Ö‡§∞‡•ç‡§ï‡•á‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∏‡§® ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç

## ‡§∏‡§Æ‡§æ‡§™‡§®

Foundry Local ‡§≤‡•á ‡§â‡§™‡§ï‡§∞‡§£‡§Æ‡•à ‡§ö‡§≤‡•ç‡§®‡•á ‡§¨‡§≤‡§ø‡§Ø‡•ã AI ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§æ‡§â‡§Å‡§õ, ‡§ú‡§π‡§æ‡§Å ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï, ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§â‡§™‡§ï‡§∞‡§£‡§π‡§∞‡•Ç ‡§¨‡§®‡•ç‡§õ‡§®‡•ç‡•§ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§ö‡§Ø‡§®, ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§Ö‡§®‡•Å‡§ó‡§Æ‡§®, ‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡§Ø‡§æ‡§∞ ‡§¢‡§æ‡§Å‡§ö‡§æ‡§π‡§∞‡•Ç‡§ï‡•ã ‡§∏‡§æ‡§•, ‡§ü‡•ã‡§≤‡•Ä‡§π‡§∞‡•Ç‡§≤‡•á ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§æ‡§Ø‡§Æ ‡§∞‡§æ‡§ñ‡•ç‡§¶‡•à ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤ ‡§π‡•Å‡§®‡•á ‡§™‡§∞‡§ø‡§∑‡•ç‡§ï‡•É‡§§ AI ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§π‡§∞‡•Ç ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ‡§®‡•ç‡•§ ‡§Ø‡§π‡§æ‡§Å ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§¨‡•å‡§¶‡•ç‡§ß‡§ø‡§ï ‡§∞‡§æ‡§â‡§ü‡§∞ ‡§¢‡§æ‡§Å‡§ö‡§æ‡§≤‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§µ‡§ø‡§ï‡§æ‡§∏‡§¶‡•á‡§ñ‡§ø ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡§∞‡§ø‡§®‡§ø‡§Ø‡•ã‡§ú‡§®‡§∏‡§Æ‡•ç‡§Æ ‡§∏‡•ç‡§ï‡•á‡§≤ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á ‡§ú‡§ü‡§ø‡§≤ AI ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä‡§π‡§∞‡•Ç ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§

---

**‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£**:  
‡§Ø‡•ã ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º AI ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡•á‡§µ‡§æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§ ‡§π‡§æ‡§Æ‡•Ä ‡§Ø‡§•‡§æ‡§∞‡•ç‡§•‡§§‡§æ‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§õ‡•å‡§Ç, ‡§§‡§∞ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡§ø‡§®‡•Å‡§π‡•ã‡§∏‡•ç ‡§ï‡§ø ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§Æ‡§æ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§π‡§∞‡•Ç ‡§µ‡§æ ‡§Ö‡§∂‡•Å‡§¶‡•ç‡§ß‡§§‡§æ‡§π‡§∞‡•Ç ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ‡•§ ‡§Ø‡§∏‡§ï‡•ã ‡§Æ‡•Ç‡§≤ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§Æ‡•Ç‡§≤ ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡§≤‡§æ‡§à ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Æ‡§æ‡§®‡§ø‡§®‡•Å‡§™‡§∞‡•ç‡§õ‡•§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡§æ‡§®‡§µ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∏ ‡§ó‡§∞‡§ø‡§®‡•ç‡§õ‡•§ ‡§Ø‡§∏ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§¨‡§æ‡§ü ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§π‡•Å‡§®‡•á ‡§ï‡•Å‡§®‡•à ‡§™‡§®‡§ø ‡§ó‡§≤‡§§‡§´‡§π‡§Æ‡•Ä ‡§µ‡§æ ‡§ó‡§≤‡§§ ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§π‡§æ‡§Æ‡•Ä ‡§ú‡§ø‡§Æ‡•ç‡§Æ‡•á‡§µ‡§æ‡§∞ ‡§π‡•Å‡§®‡•á ‡§õ‡•à‡§®‡•å‡§Ç‡•§