<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T19:57:02+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "ne"
}
-->
# Section 1: माइक्रोसफ्ट फाई मोडेल परिवारको आधारभूत जानकारी

माइक्रोसफ्ट फाई मोडेल परिवारले कृत्रिम बुद्धिमत्तामा नयाँ दृष्टिकोण प्रस्तुत गर्दछ, जसले देखाउँछ कि सानो र प्रभावकारी मोडेलहरूले परम्परागत ठूला भाषा मोडेलहरूको तुलनामा कम स्रोत प्रयोग गर्दै उत्कृष्ट प्रदर्शन हासिल गर्न सक्छ। फाई परिवारले कसरी कम कम्प्युटेशनल आवश्यकतासहित विभिन्न कार्यहरूमा उच्च प्रदर्शन कायम राख्दै शक्तिशाली एआई क्षमता सक्षम बनाउँछ भन्ने कुरा बुझ्न महत्त्वपूर्ण छ।

## विकासकर्ताहरूका लागि स्रोतहरू

### Azure AI Foundry मोडेल क्याटलग
फाई मोडेल परिवार (फाई-सिलिका बाहेक) [Azure AI Foundry मोडेल क्याटलग](https://ai.azure.com/explore/models?q=phi) मार्फत उपलब्ध छ, जसले विकासकर्ताहरूलाई यी मोडेलहरूलाई सजिलै पहुँच गर्न, फाइन-ट्यून गर्न, र आफ्ना एप्लिकेसनहरूमा प्रयोग गर्न सजिलो बनाउँछ। क्याटलगले विभिन्न फाई भेरियन्टहरूमा प्रयोग गर्न र तिनीहरूलाई तपाईंको परियोजनामा समाहित गर्नको लागि सरल तरिका प्रदान गर्दछ।

### Azure AI Foundry
तपाईं [Azure AI Foundry](https://ai.azure.com) प्रयोग गरेर फाई मोडेलहरूलाई तैनाथ गर्न र परीक्षण गर्न सक्नुहुन्छ, जसले न्यूनतम सेटअपसहित एआई समाधानहरू निर्माण, परीक्षण, र तैनाथ गर्न व्यापक वातावरण प्रदान गर्दछ।

### Foundry Local
स्थानीय विकास र तैनाथका लागि, [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) हेर्नुहोस्, जसले तपाईंलाई फाई मोडेलहरूलाई तपाईंको विकास मेसिनमा अनुकूलित कन्फिगरेसनहरूसहित चलाउन सक्षम बनाउँछ।

### दस्तावेजीकरण स्रोतहरू
- [Microsoft Research: फाई मोडेल प्राविधिक रिपोर्टहरू](https://ai.azure.com/labs/projects/phi-4)
- [फाई कुकबुक](https://aka.ms/phicookbook)

## परिचय

यस पाठमा, हामी माइक्रोसफ्टको फाई मोडेल परिवार र यसको आधारभूत अवधारणाहरूको अन्वेषण गर्नेछौं। हामी फाई परिवारको विकास, फाई मोडेलहरूलाई प्रभावकारी बनाउने नवीन प्रशिक्षण विधिहरू, परिवारका प्रमुख भेरियन्टहरू, र विभिन्न परिदृश्यहरूमा व्यावहारिक अनुप्रयोगहरू समेट्नेछौं।

## सिकाइका उद्देश्यहरू

यस पाठको अन्त्यसम्म, तपाईं सक्षम हुनुहुनेछ:

- माइक्रोसफ्टको फाई मोडेल परिवारको डिजाइन दर्शन र विकासलाई बुझ्न।
- फाई मोडेलहरूले कम प्यारामिटरहरूसहित उच्च प्रदर्शन हासिल गर्न सक्षम बनाउने प्रमुख नवीनताहरू पहिचान गर्न।
- विभिन्न फाई मोडेल भेरियन्टहरूको फाइदा र सीमाहरू चिन्न।
- वास्तविक संसारका परिदृश्यहरूको लागि उपयुक्त भेरियन्ट चयन गर्न फाई मोडेलहरूको ज्ञान लागू गर्न।

## परम्परागत एआई मोडेल दृष्टिकोणको समझ

परम्परागत रूपमा, प्राकृतिक भाषा प्रशोधनमा उच्च प्रदर्शन हासिल गर्न अर्बौं वा सयौं अर्ब प्यारामिटरहरू भएका ठूला भाषा मोडेलहरू आवश्यक पर्दछ। संगठनहरूले सामान्यतया यी मोडेलहरूलाई शक्तिशाली GPU क्लस्टरहरूमा तैनाथ गर्छन्, API इन्टरफेस वा विशेष हार्डवेयर पूर्वाधारमार्फत तिनीहरूको क्षमता पहुँच गर्दै।

यो दृष्टिकोण धेरै अनुप्रयोगहरूको लागि राम्रोसँग काम गर्दछ तर व्यावहारिक तैनाथ परिदृश्यहरूमा सीमितताहरू हुन्छन्। परम्परागत विधिले धेरै कम्प्युटेशनल स्रोतहरू, ठूलो मेमोरी, र महत्वपूर्ण ऊर्जा खपत आवश्यक पर्ने मोडेलहरू प्रयोग गर्दछ। यसले अत्याधुनिक क्षमताहरूको पहुँच प्रदान गरे पनि, यो महँगो हार्डवेयरमा निर्भरता सिर्जना गर्दछ, उच्च सञ्चालन लागतहरू परिचय गराउँछ, र तैनाथको लचकता सीमित गर्दछ।

## प्रभावकारी एआई तैनाथको चुनौती

विभिन्न परिदृश्यहरूमा प्रभावकारी एआईको आवश्यकता बढ्दो रूपमा महत्त्वपूर्ण हुँदै गएको छ। गोपनीयता कारणले स्थानीय तैनाथ आवश्यक पर्ने अनुप्रयोगहरू, क्लाउड API लागत महँगो हुने लागत-संवेदनशील कार्यान्वयनहरू, सीमित हार्डवेयर स्रोतहरू भएका एज कम्प्युटिङ परिदृश्यहरू, वा विलम्बता महत्त्वपूर्ण हुने वास्तविक-समय अनुप्रयोगहरूलाई विचार गर्नुहोस्।

### प्रमुख तैनाथ सीमाहरू

परम्परागत ठूला मोडेल तैनाथहरूले व्यावहारिक प्रयोगलाई सीमित गर्ने केही आधारभूत सीमाहरू सामना गर्छन्:

- **लागत सीमाहरू**: उच्च कम्प्युटेशनल लागतले धेरै संगठनहरूको लागि निरन्तर तैनाथ महँगो बनाउँछ।
- **स्रोत सीमाहरू**: उच्च-अन्त GPU पूर्वाधारको सीमित पहुँचले तैनाथ विकल्पहरू प्रतिबन्धित गर्दछ।
- **गोपनीयता आवश्यकताहरू**: संवेदनशील अनुप्रयोगहरूले डाटा गोपनीयता कायम राख्न स्थानीय प्रशोधन आवश्यक पर्दछ।
- **विलम्बता संवेदनशीलता**: वास्तविक-समय अनुप्रयोगहरूले क्लाउड राउन्ड-ट्रिप ढिलाइ बिना तुरुन्त प्रतिक्रिया आवश्यक पर्दछ।

## माइक्रोसफ्ट फाई मोडेल दर्शन

माइक्रोसफ्ट फाई मोडेल परिवारले एआई मोडेल डिजाइन दर्शनमा आधारभूत परिवर्तनको प्रतिनिधित्व गर्दछ, दक्षता र व्यावहारिक तैनाथलाई प्राथमिकता दिँदै बलियो प्रदर्शन विशेषताहरू कायम राख्छ। फाई मोडेलहरूले नवीन वास्तुकला, उच्च-गुणस्तर प्रशिक्षण विधिहरू, र विशेष अनुकूलन प्रविधिहरू मार्फत यो हासिल गर्छन्।

फाई परिवारले प्यारामिटर प्रति प्रदर्शनलाई अधिकतम बनाउन डिजाइन गरिएका विभिन्न दृष्टिकोणहरू समेट्छ, मानक हार्डवेयरमा तैनाथ सक्षम बनाउँदै अर्थपूर्ण एआई क्षमता प्रदान गर्दछ। लक्ष्य भनेको कम्प्युटेशनल आवश्यकताहरू, मेमोरी प्रयोग, र सञ्चालन लागतलाई नाटकीय रूपमा घटाउँदै प्रतिस्पर्धात्मक प्रदर्शन कायम राख्नु हो।

### फाई डिजाइनका मुख्य सिद्धान्तहरू

फाई मोडेलहरू परम्परागत ठूला भाषा मोडेलहरूबाट फरक पार्ने केही आधारभूत सिद्धान्तहरूमा निर्माण गरिएका छन्:

- **पहिलो दक्षता**: पूर्ण स्केलभन्दा प्यारामिटर प्रति अधिकतम प्रदर्शनको लागि अनुकूलित।
- **गुणस्तरीय प्रशिक्षण**: विशाल डेटासेटहरूभन्दा उच्च-गुणस्तर, क्युरेटेड प्रशिक्षण डाटामा ध्यान केन्द्रित।
- **तैनाथ लचकता**: विभिन्न हार्डवेयर कन्फिगरेसनहरूमा प्रभावकारी रूपमा चल्न डिजाइन गरिएको।
- **विशेष क्षमताहरू**: विशिष्ट कार्यहरू वा डोमेनहरूको लागि अक्सर अनुकूलित प्रभावकारिता अधिकतम गर्न। 

## फाई परिवारलाई सक्षम बनाउने प्रमुख प्रविधिहरू

### "पाठ्यपुस्तक" प्रशिक्षण दृष्टिकोण

फाई परिवारको सबैभन्दा क्रान्तिकारी पक्ष भनेको "पाठ्यपुस्तक गुणस्तर" प्रशिक्षण विधि हो। अनफिल्टर्ड इन्टरनेट डाटामा प्रशिक्षण गर्ने सट्टा, फाई मोडेलहरूले तर्क, गणित, कोडिङ, र सामान्य ज्ञानलाई प्रभावकारी रूपमा सिकाउन डिजाइन गरिएको सावधानीपूर्वक क्युरेटेड, उच्च-गुणस्तर शैक्षिक सामग्री प्रयोग गर्दछ।

यो दृष्टिकोणले उच्च-गुणस्तर पाठ्यपुस्तकहरू र शैक्षिक सामग्रीलाई प्रतिबिम्बित गर्ने कृत्रिम शैक्षिक सामग्री सिर्जना गरेर काम गर्दछ। प्रशिक्षण डाटा विशेष रूपमा स्पष्ट व्याख्या, चरण-दर-चरण तर्क, र संरचित ज्ञान प्रस्तुतीकरणमा ध्यान केन्द्रित गर्दै शैक्षिक रूपमा सुदृढ बनाइएको छ।

### उन्नत तर्क प्रशिक्षण

हालका फाई मोडेलहरूले जटिल बहु-चरण समस्या समाधान सक्षम गर्ने परिष्कृत तर्क प्रशिक्षण विधिहरू समावेश गर्छन्। यी प्रविधिहरूमा समावेश छन्:

**चेन-ऑफ-थट प्रशिक्षण**: मोडेलहरूले जटिल समस्याहरूलाई अन्तरिम तर्क चरणहरूमा तोड्न सिक्छन्, तिनीहरूको समस्या समाधान प्रक्रिया अधिक पारदर्शी र भरपर्दो बनाउँदै।

**इन्फरेन्स-टाइम स्केलिङ**: मोडेलहरूले प्रतिक्रिया उत्पन्न गर्दा थप कम्प्युटेशनल स्रोतहरू प्रयोग गरेर विस्तृत तर्क श्रृंखला उत्पन्न गर्छन्, जसले सटीकता सुधार गर्दछ।

**क्षमताको किनार प्रशिक्षण**: प्रशिक्षण डाटा विशेष रूपमा मोडेललाई यसको वर्तमान क्षमताको किनारमा चुनौती दिन चयन गरिएको छ, जटिल तर्क ढाँचाहरूको सिकाइलाई प्रवर्द्धन गर्दै।

### वास्तुकला नवप्रवर्तनहरू

फाई परिवारले विशेष रूपमा दक्षताका लागि डिजाइन गरिएका केही वास्तुकला अनुकूलनहरू समावेश गर्दछ:

**प्यारामिटर दक्षता**: मोडेलको प्रत्येक प्यारामिटरको प्रभाव अधिकतम गर्न सावधानीपूर्वक वास्तुकला विकल्पहरू।

**मल्टि-मोडल एकीकरण**: सानो वास्तुकलाहरूभित्र पाठ, दृष्टि, र भाषण प्रशोधन क्षमताहरूको प्रभावकारी एकीकरण।

**हार्डवेयर अनुकूलन**: विशिष्ट हार्डवेयर प्लेटफर्महरू र तैनाथ परिदृश्यहरूको लागि अनुकूलित विशेष भेरियन्टहरू। 

## फाई मोडेलहरूको हार्डवेयर अनुकूलन

आधुनिक तैनाथ वातावरणहरूले विभिन्न हार्डवेयर कन्फिगरेसनहरूमा फाई मोडेलहरूको दक्षताबाट लाभ उठाउँछन्:

### CPU-अनुकूलित तैनाथ

फाई मोडेलहरू CPU-मात्र हार्डवेयरमा प्रभावकारी रूपमा चल्न डिजाइन गरिएको छ, जसले विशेष एआई एक्सेलेरेटरहरू आवश्यक बिना मानक कम्प्युटिङ पूर्वाधारमा तैनाथलाई पहुँचयोग्य बनाउँछ।

### GPU एक्सेलेरेशन

शक्तिशाली GPU आवश्यक नपरे पनि, फाई मोडेलहरूले उपलब्ध GPU स्रोतहरूलाई प्रदर्शन सुधारका लागि उपयोग गर्न सक्छन्, तैनाथ कन्फिगरेसनहरूमा लचकता प्रदान गर्दै।

### एज उपकरण एकीकरण

फाई-3-सिलिका जस्ता विशेष भेरियन्टहरू विशिष्ट एज कम्प्युटिङ प्लेटफर्महरूको लागि अनुकूलित छन्, 1.5W पावर खपतमा प्रति सेकेन्ड 650 टोकन जस्ता उल्लेखनीय दक्षता मेट्रिक्स हासिल गर्दै। 

## फाई मोडेल परिवारका फाइदाहरू

### लागत दक्षता

फाई मोडेलहरूले कम्प्युटेशनल पूर्वाधारको आवश्यकता नाटकीय रूपमा घटाएर सञ्चालन लागत कम गर्छन्, प्रतिस्पर्धात्मक प्रदर्शन कायम राख्दै। यसले सीमित बजेट भएका संगठनहरू वा उच्च-भोल्युम अनुप्रयोगहरूलाई जहाँ प्रति इन्फरेन्स लागत महत्त्वपूर्ण छ, एआई पहुँचयोग्य बनाउँछ।

### तैनाथ लचकता

फाई मोडेलहरूको दक्षताले व्यक्तिगत ल्यापटपदेखि उद्यम सर्भरहरूसम्मका हार्डवेयर कन्फिगरेसनहरूमा तैनाथ सक्षम बनाउँछ, संगठनहरूलाई उनीहरूको एआई पूर्वाधार विकल्पहरूमा अधिक लचकता प्रदान गर्दै।

### गोपनीयता र सुरक्षा

फाई मोडेलहरूको दक्षताले गोपनीयता-संवेदनशील अनुप्रयोगहरूको लागि स्थानीय तैनाथ सक्षम बनाउँछ, जसले सुनिश्चित गर्दछ कि संवेदनशील डाटा कहिल्यै संगठनको नियन्त्रण बाहिर जान्दैन, शक्तिशाली एआई क्षमता प्रदान गर्दै।

### वास्तविक-समय प्रदर्शन

कम कम्प्युटेशनल आवश्यकताहरूले छिटो इन्फरेन्स समयमा अनुवाद गर्दछ, वास्तविक-समय अनुप्रयोगहरू सक्षम बनाउँदै जसले एआई क्षमता गुणस्तरमा सम्झौता नगरी तुरुन्त प्रतिक्रिया आवश्यक पर्दछ।

### पहुँचयोग्य एआई

तैनाथका लागि बाधाहरू घटाएर, फाई मोडेलहरूले उन्नत एआई क्षमताहरू सीमित स्रोत भएका संगठनहरूलाई पहुँचयोग्य बनाउँछन्, साना टोलीहरू र व्यक्तिगत विकासकर्ताहरूलाई परिष्कृत भाषा समझको लाभ उठाउन सक्षम बनाउँदै। 

## व्यावहारिक उदाहरणहरू र प्रयोगका केसहरू

प्राविधिक विकासमा प्रवेश गर्नु अघि, फाई मोडेलहरूले के गर्न सक्छन् भन्ने केही ठोस उदाहरणहरू अन्वेषण गरौं:

### गणितीय तर्क उदाहरण

फाई-4-मिनी-तर्क चरण-दर-चरण गणितीय समस्या समाधानमा उत्कृष्ट छ। उदाहरणका लागि, "3*x^2+4*x+5=1 कसरी समाधान गर्ने?" भनेर सोध्दा, मोडेलले विस्तृत तर्क चरणहरू प्रदान गर्दछ:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x² + 4x + 5 = 1
3x² + 4x + 5 - 1 = 0  
3x² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ± √(b² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b² - 4ac = 4² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ± √(-32)) / 6 = (-4 ± 4i√2) / 6 = (-2 ± 2i√2) / 3
```

### बहुभाषी समर्थन उदाहरण

फाई-3.5-मिनी-इन्स्ट्रक्टले विभिन्न भाषाहरूमा बलियो बहुभाषी क्षमता प्रदर्शन गर्दछ। यहाँ एक उदाहरण प्रम्प्ट ढाँचा छ:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### मल्टि-मोडल क्षमता उदाहरण

फाई-4-मल्टि-मोडलले पाठ, छवि, र भाषणलाई एकैसाथ प्रशोधन गर्न सक्छ। यहाँ केही व्यावहारिक अनुप्रयोगहरू छन्:

**अडियो इनपुटको साथ यात्रा योजना:**
फाई-4 मल्टि-मोडलले बोलिएको भाषालाई विश्लेषण गरेर सिएटलको यात्रा योजना बनाउन मद्दत गरेको हेर्नुहोस्, यसको उन्नत अडियो प्रशोधन र सिफारिस क्षमताहरू प्रदर्शन गर्दै।

**छविबाट गणितीय समस्या समाधान:**
फाई-4 मल्टि-मोडलले छविमा प्रस्तुत गरिएको समीकरणहरू प्रशोधन र समाधान गर्ने क्षमता प्रदर्शन गर्दै जटिल गणितीय समस्याहरूलाई सम्बोधन गरेको हेर्नुहोस्।

**फंक्शन कलिङ उदाहरण:**
फंक्शन कलिङको साथ, फाई-4-मिनी र फाई-4-मल्टि-मोडलले खोज इन्जिनहरू समाहित गरेर, विभिन्न उपकरणहरू जडान गरेर, र थप क्षमताहरू विस्तार गर्न सक्छ। जस्तै, मोडेलले फाई-4-मिनी मार्फत प्रिमियर लिगको खेल जानकारी पुनःप्राप्त गर्न सक्छ, यसको बाह्य डाटा स्रोतहरूसँग सहज रूपमा अन्तरक्रिया गर्ने क्षमता प्रदर्शन गर्दै।

### कोड जेनेरेशन उदाहरण

फाई-4-मल्टि-मोडलले छवि सामग्री र प्रदान गरिएको प्रम्प्टको आधारमा संरचित परियोजना कोड उत्पन्न गर्न सक्छ, जस्तै यो व्यावहारिक कार्यप्रवाहमा देखाइएको छ:

1. वायरफ्रेम वा डिजाइनको छवि अपलोड गर्नुहोस्
2. परियोजना आवश्यकताहरूको बारेमा सन्दर्भ प्रदान गर्नुहोस्
3. मोडेलले पूर्ण, कार्यात्मक कोड संरचना उत्पन्न गर्दछ
4. कोडलाई विशिष्ट फ्रेमवर्क वा भाषाहरूको आधारमा अनुकूलित गर्न सकिन्छ

### एज तैनाथ उदाहरण

हामी क्वान्टाइज गरिएको मोडेललाई एज उपकरणहरूमा तैनाथ गर्न सक्छौं। माइक्रोसफ्ट ओलिभ र ONNX GenAI Runtime को संयोजन गरेर, हामी फाई-4-मिनीलाई विन्डोज, आइफोन, एन्ड्रोइड र अन्य उपकरणहरूमा तैनाथ गर्न सक्छौं। यो आइफोन 12 प्रोमा चलिरहेको उदाहरण हो।

तैनाथ प्रक्रिया समावेश गर्दछ:
- मोबाइल अनुकूलनको लागि मोडेल क्वान्टाइजेशन
- क्रस-प्ल्याटफर्म अनुकूलताको लागि ONNX रनटाइम एकीकरण
- इन्टरनेट कनेक्टिविटी बिना स्थानीय इन्फरेन्स
- न्यूनतम पावर खपतमा वास्तविक-समय प्रदर्शन

## फाई परिवारको विकास

### फाई-1 र फाई-2: आधारभूत मोडेलहरू

प्रारम्भिक फाई मोडेलहरूले उच्च-गुणस्तर प्रशिक्षण डाटा र प्रभावकारी वास्तुकलाहरूको आधारभूत सिद्धान्तहरू स्थापना गरे:

- **फाई-1 (1.3B प्यारामिटरहरू)**: आधारभूत भाषा समझ र कोड जेनेरेशनका लागि क्युरेटेड प्रशिक्षण डाटाको अवधारणा प्रस्तुत गर्यो।
- **फाई-2 (2.7B प्यारामिटरहरू)**: सावधानीपूर्वक फिल्टर गरिएको वेब सामग्री र कृत्रिम NLP डाटाको माध्यमबाट तर्क क्षमता सुधार गर्यो।

### फाई-3 परिवार: मुख्यधारा अपनत्व

फाई-3 श्रृंखलाले SLM क्षमताहरूमा ब्रेकथ्रु ल्यायो, धेरै विशेष भेरियन्टहरूसहित:

- **फाई-3-मिनी (3.8B प्यारामिटरहरू)**: असाधारण दक्षतासहित सामान्य भाषा कार्यहरू, यसको आकारको दोब्बर मोडेलहरूलाई हराउँदै।
- **फाई-3-सानो (7B प्यारामिटरहरू)**: GPT-3.5 टर्बोलाई विभिन्न बेंचमार्कहरूमा हराउँदै उन्नत प्रदर्शन।
- **फाई-3-मध्यम (14B प्यारामिटरहरू)**: उद्यम-ग्रेड प्रदर्शन, Gemini 1.0 Pro लाई हराउँदै।
- **फाई-3-भिजन (4.2B प्यारामिटरहरू)**: छवि र पाठ प्रशोधनका लागि मल्टि-मोडल क्षमता।
- **फाई-3-सिलिका (3.3B प्यारामिटरहरू)**: विन्डोज 11 बिल्ट-इन तैनाथको लागि विशेष अनुकूलन।

### फाई-4 परिवार: उन्नत तर्क

नवीनतम पुस्ताले तर्क क्षमताहरूको सीमालाई धकेल्छ:

- **फाई-4 (14B प्यारामिटरहरू)**: गणितमा विशेष जटिल तर्क।
- **फाई-4-मिनी (3.8B प्यारामिटरहरू)**: फंक्शन कलिङ र लामो सन्दर्भ समर्थनसहित उन्नत तर्क।
- **फाई-4-मल्टि-मोडल**: एकैसाथ भाषण, दृष्टि, र पाठ प्रशोधन क्षमता।
- **फाई-4-तर्क (14B प्यारामिटरहरू)**: जटिल बहु-चरण तर्क कार्यहरूको लागि विशेष।
- **फाई-4-तर्क-प्लस (14B प्यार
Phi परिवारले देखाउँछ कि एआईको भविष्य केवल ठूला मोडेल निर्माणमा मात्र निर्भर छैन, बरु स्मार्ट र प्रभावकारी मोडेल निर्माणमा निर्भर छ, जसले विभिन्न हार्डवेयर वातावरणमा उच्च प्रदर्शन मापदण्ड कायम राख्दै प्रभावकारी रूपमा काम गर्न सक्छ।

## विकास र एकीकरणका उदाहरणहरू

### ट्रान्सफर्मरहरूसँग छिटो सुरु गर्नुहोस्

Phi मोडेलहरू Hugging Face Transformers लाइब्रेरी प्रयोग गरेर सुरु गर्ने तरिका यहाँ छ:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### फाइन-ट्युनिङको उदाहरण

तलको उदाहरणले Phi-4-mini-instruct लाई विशेष कार्यहरूको लागि कसरी फाइन-ट्युन गर्ने देखाउँछ:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### विशेष प्रम्प्ट ढाँचाहरू

**तर्क कार्यहरूको लागि (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**गणितीय कार्यहरूको लागि (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### मोबाइलमा ONNX प्रयोग गरेर डिप्लोयमेन्ट

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## प्रदर्शन मापदण्ड र उपलब्धिहरू

Phi मोडेल परिवारले विभिन्न मापदण्डहरूमा उल्लेखनीय प्रदर्शन हासिल गरेको छ, प्रायः धेरै ठूला मोडेलहरूलाई उछिन्ने:

### प्रमुख प्रदर्शन हाइलाइटहरू

**गणितीय तर्कमा उत्कृष्टता:**
- Phi-4 ले AIME 2025 (Math Olympiad क्वालिफायर) मा ८२.५% शुद्धता हासिल गरेको छ
- Phi-4-reasoning (14B) ले reasoning मापदण्डहरूमा DeepSeek-R1-Distill-70B (५ गुणा ठूलो) लाई उछिन्ने प्रदर्शन गरेको छ
- Phi-4-mini-reasoning (3.8B) ले गणितीय तर्क कार्यहरूमा दुई गुणा ठूलो मोडेलहरूसँग प्रतिस्पर्धा गरेको छ

**क्षमतामा उपलब्धिहरू:**
- Phi-3-Silica ले केवल १.५W पावर खपतमा ६५० टोकन प्रति सेकेन्ड हासिल गरेको छ
- Phi-4-mini (3.8B) ले धेरै ठूला मोडेलहरूसँग समान प्रदर्शन हासिल गरेको छ

**मापदण्ड प्रदर्शन:**
- **MMLU (Massive Multitask Language Understanding)**: ५७ शैक्षिक विषयहरूमा प्रतिस्पर्धात्मक प्रदर्शन
- **HumanEval**: विशेष गरी Python मा बलियो कोड जेनेरेशन क्षमता
- **MGSM**: बहुभाषिक प्राथमिक विद्यालय गणित समस्या समाधान
- **DROP**: जटिल बुझाइ र तर्क कार्यहरू
- **SimpleQA**: तथ्यात्मक उत्तरको शुद्धता

### 📊 मोडेल तुलना म्याट्रिक्स

| मोडेल | प्यारामिटरहरू | कन्क्स्ट लम्बाइ | प्रमुख बलहरू | उत्तम प्रयोग केसहरू |
|-------|------------|----------------|---------------|----------------|
| **Phi-3-mini** | 3.8B | 4K/128K | सामान्य क्षमता | मोबाइल एप्स, आधारभूत च्याटबटहरू |
| **Phi-3.5-mini** | 3.8B | 128K | बहुभाषिक समर्थन | अन्तर्राष्ट्रिय अनुप्रयोगहरू |
| **Phi-4-mini** | 3.8B | 128K | उन्नत तर्क, फङ्क्सन कलिङ | व्यापार स्वचालन |
| **Phi-4-mini-reasoning** | 3.8B | 128K | गणितीय तर्क | शैक्षिक प्लेटफर्महरू |
| **Phi-4** | 14B | 32K | जटिल तर्क | अनुसन्धान, उन्नत विश्लेषण |
| **Phi-4-reasoning** | 14B | 32K/64K | बहु-चरण तर्क | वैज्ञानिक गणना |
| **Phi-4-reasoning-plus** | 14B | 32K | अधिकतम शुद्धता तर्क | महत्वपूर्ण निर्णय लिने |
| **Phi-4-multimodal** | 5.6B | परिवर्तनशील | आवाज, दृश्य, पाठ | मल्टिमिडिया अनुप्रयोगहरू |

## मोडेल चयन मार्गदर्शन

### आधारभूत अनुप्रयोगहरूको लागि
- **Phi-3-mini**: साधारण पाठ जेनेरेशन, आधारभूत प्रश्न उत्तर, छिटो प्रतिक्रिया
- **Phi-4-mini**: फङ्क्सन कलिङ क्षमतासहित उन्नत तर्क

### गणितीय र तर्क कार्यहरूको लागि
- **Phi-4**: जटिल गणितीय समस्या समाधान र तर्क
- **Phi-4-reasoning**: विस्तृत व्याख्यासहित बहु-चरण तर्क
- **Phi-4-reasoning-plus**: महत्वपूर्ण तर्क अनुप्रयोगहरूको लागि अधिकतम शुद्धता
- **Phi-4-mini-reasoning**: स्रोत-सीमित वातावरणहरूको लागि प्रभावकारी गणितीय तर्क

### मल्टिमोडल अनुप्रयोगहरूको लागि
- **Phi-3-vision**: छवि र पाठ प्रशोधन संयोजनहरू
- **Phi-4-multimodal**: व्यापक आवाज, दृश्य, र पाठ क्षमताहरू

### उद्यम डिप्लोयमेन्टको लागि
- **Phi-3-medium**: व्यापार अनुप्रयोगहरूको लागि उन्नत भाषा बुझाइ
- **Phi-3-Silica**: विशिष्ट हार्डवेयर प्लेटफर्महरूको लागि अनुकूलित

## डिप्लोयमेन्ट प्लेटफर्महरू र पहुँचयोग्यता

### क्लाउड प्लेटफर्महरू
- **Azure AI Foundry**: उद्यम उपकरणहरूसहित पूर्ण-विशेषता डिप्लोयमेन्ट
- **Hugging Face**: ओपन-सोर्स मोडेल रिपोजिटरी र समुदाय स्रोतहरू
- **NVIDIA API Catalog**: माइक्रोसर्भिस डिप्लोयमेन्ट विकल्पहरू

### स्थानीय विकास फ्रेमवर्कहरू
- **Ollama**: स्थानीय मोडेल डिप्लोयमेन्टको लागि हल्का फ्रेमवर्क
- **ONNX Runtime**: विभिन्न हार्डवेयर कन्फिगरेसनहरूको लागि अनुकूलित  
- **DirectML**: Windows-अनुकूलित प्रदर्शन
- **llama.cpp**: क्रस-प्लेटफर्म इन्फरेन्स इन्जिन

### सिकाइ स्रोतहरू
- **Phi Portal**: Microsoft Phi को आधिकारिक दस्तावेज केन्द्र
- **Phi Cookbook**: व्यापक उदाहरणहरू र ट्युटोरियलहरू
- **Technical Reports**: arxiv मा गहन अनुसन्धान पत्रहरू
- **Community Spaces**: Hugging Face अन्तरक्रियात्मक डेमोहरू

### Phi मोडेलहरूसँग सुरु गर्नुहोस्

#### विकास प्लेटफर्महरू
1. **Azure AI Foundry**: सरल स्थानीय CLI र मोडेल व्यवस्थापन।
2. **Hugging Face Transformers**: छिटो स्थानीय प्रयोग
3. **Ollama**: परीक्षणको लागि सरल स्थानीय डिप्लोयमेन्ट

#### सिकाइ मार्ग
1. **मुख्य अवधारणाहरू बुझ्नुहोस्**: आधारभूत डिजाइन सिद्धान्तहरू अध्ययन गर्नुहोस्
2. **भिन्नताहरूको प्रयोग गर्नुहोस्**: विभिन्न Phi मोडेलहरूको क्षमता बुझ्न प्रयास गर्नुहोस्
3. **कार्यान्वयन अभ्यास गर्नुहोस्**: परीक्षण वातावरणमा मोडेलहरू डिप्लोय गर्नुहोस्
4. **डिप्लोयमेन्ट विस्तार गर्नुहोस्**: सफल परीक्षणहरूमा आधारित प्रयोग विस्तार गर्नुहोस्

#### उत्तम अभ्यासहरू
- **सानोबाट सुरु गर्नुहोस्**: प्रारम्भिक विकासको लागि Phi-mini मोडेलहरूसँग सुरु गर्नुहोस्
- **प्रम्प्टहरू अनुकूलित गर्नुहोस्**: उत्तम परिणामहरूको लागि सही च्याट ढाँचाको प्रयोग गर्नुहोस्
- **प्रदर्शन अनुगमन गर्नुहोस्**: इन्फरेन्स गति र शुद्धता मेट्रिक्स ट्र्याक गर्नुहोस्
- **हार्डवेयर विचार गर्नुहोस्**: उपलब्ध कम्प्युटेशनल स्रोतहरूसँग मोडेल आकार मिलाउनुहोस्

## निष्कर्ष

Microsoft Phi मोडेल परिवारले एआई मोडेल डिजाइनमा क्रान्तिकारी दृष्टिकोण प्रस्तुत गर्दछ, देखाउँदै कि साना, अधिक प्रभावकारी मोडेलहरूले विभिन्न कार्यहरूमा उल्लेखनीय प्रदर्शन हासिल गर्न सक्छ। उच्च-गुणस्तरको प्रशिक्षण डाटा र वास्तुकला अनुकूलनमा ध्यान केन्द्रित गरेर, Phi परिवारले परम्परागत ठूला भाषा मोडेलहरूको तुलनामा उल्लेखनीय रूपमा कम कम्प्युटेशनल आवश्यकताहरूका साथ असाधारण क्षमता प्रदान गर्दछ।

## प्रमुख सिकाइ उद्देश्यहरू

1. Microsoft को Phi मोडेल परिवारको डिजाइन दर्शन र विकासलाई Phi-1 देखि Phi-4 सम्म बुझ्नुहोस्
2. "पाठ्यपुस्तक गुणस्तर" प्रशिक्षण र वास्तुकला अनुकूलन सहित प्रमुख नवप्रवर्तनहरू पहिचान गर्नुहोस्
3. विभिन्न डिप्लोयमेन्ट परिदृश्यहरूमा विभिन्न Phi भेरियन्टहरूको फाइदा र सीमाहरूलाई मान्यता दिनुहोस्
4. विशिष्ट प्रयोग केसहरू र हार्डवेयर सीमाहरूको लागि उपयुक्त Phi मोडेल चयन गर्न ज्ञान लागू गर्नुहोस्
5. स्रोत-सीमित उपकरणहरूमा Phi मोडेल डिप्लोय गर्न अनुकूलन प्रविधिहरू कार्यान्वयन गर्नुहोस्
6. परम्परागत ठूला भाषा मोडेलहरूको तुलनामा Phi मोडेल परिवारको वास्तुकला लाभहरू व्याख्या गर्नुहोस्
7. विशिष्ट अनुप्रयोग आवश्यकताहरू र हार्डवेयर सीमाहरूको आधारमा उपयुक्त Phi भेरियन्ट चयन गर्नुहोस्
8. अनुकूलित कन्फिगरेसनहरूसहित क्लाउड र एज डिप्लोयमेन्ट परिदृश्यहरूमा Phi मोडेलहरू कार्यान्वयन गर्नुहोस्
9. लक्ष्य उपकरणहरूमा Phi मोडेल प्रदर्शन सुधार गर्न क्वान्टाइजेशन र अनुकूलन प्रविधिहरू लागू गर्नुहोस्
10. Phi परिवारभर मोडेल आकार, प्रदर्शन, र क्षमताहरू बीचको व्यापार-सम्झौता मूल्याङ्कन गर्नुहोस्

## अब के गर्ने

- [02: Qwen परिवारको आधारभूत जानकारी](02.QwenFamily.md)

---

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको छ। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छ। यसको मूल भाषा मा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।