<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b17bf7f849519fac995c24ab9e2d0be8",
  "translation_date": "2025-09-18T07:22:46+00:00",
  "source_file": "Module06/README.md",
  "language_code": "th"
}
-->
# บทที่ 06 : ระบบ SLM Agentic: ภาพรวมที่ครอบคลุม

ภูมิทัศน์ของปัญญาประดิษฐ์กำลังเปลี่ยนแปลงอย่างลึกซึ้ง เมื่อเราก้าวจากแชทบอทธรรมดาไปสู่เอเจนต์ AI ที่ซับซ้อนซึ่งขับเคลื่อนด้วย Small Language Models (SLMs) คู่มือฉบับนี้จะสำรวจสามแง่มุมสำคัญของระบบ SLM agentic สมัยใหม่: แนวคิดพื้นฐานและกลยุทธ์การใช้งาน ความสามารถในการเรียกฟังก์ชัน และการบูรณาการ Model Context Protocol (MCP) ที่ปฏิวัติวงการ

## [ส่วนที่ 1: พื้นฐานของ AI Agents และ Small Language Models](./01.IntroduceAgent.md)

ส่วนแรกนี้จะสร้างความเข้าใจพื้นฐานเกี่ยวกับ AI agents และ Small Language Models โดยระบุปี 2025 เป็นปีแห่ง AI agents หลังจากยุคแชทบอทในปี 2023 และการเติบโตของ copilot ในปี 2024 ส่วนนี้แนะนำ **ระบบ AI agentic** ที่สามารถคิด วิเคราะห์ วางแผน ใช้เครื่องมือ และดำเนินการงานต่าง ๆ ด้วยการป้อนข้อมูลจากมนุษย์เพียงเล็กน้อย

### แนวคิดสำคัญที่ครอบคลุม:
- **กรอบการจำแนกประเภทเอเจนต์**: ตั้งแต่เอเจนต์ที่ตอบสนองแบบง่ายไปจนถึงเอเจนต์ที่เรียนรู้ โดยให้การจัดประเภทที่ครอบคลุมสำหรับสถานการณ์การคำนวณที่แตกต่างกัน
- **พื้นฐานของ SLM**: กำหนด Small Language Models เป็นโมเดลที่มีพารามิเตอร์น้อยกว่า 10 พันล้าน ซึ่งสามารถดำเนินการวิเคราะห์ได้อย่างมีประสิทธิภาพบนอุปกรณ์ผู้บริโภค
- **กลยุทธ์การปรับแต่งขั้นสูง**: ครอบคลุมการใช้งานรูปแบบ GGUF เทคนิคการลดขนาด (Q4_K_M, Q5_K_S, Q8_0) และเฟรมเวิร์กที่ปรับแต่งสำหรับอุปกรณ์ปลายทาง เช่น Llama.cpp และ Apple MLX
- **การเปรียบเทียบ SLM กับ LLM**: แสดงให้เห็นถึงการลดต้นทุน 10-30 เท่า ด้วย SLMs ในขณะที่ยังคงประสิทธิภาพสำหรับ 70-80% ของงานเอเจนต์ทั่วไป

ส่วนนี้สรุปด้วยกลยุทธ์การใช้งานจริงโดยใช้ Ollama, VLLM และโซลูชันสำหรับอุปกรณ์ปลายทางของ Microsoft ซึ่งสร้าง SLMs ให้เป็นอนาคตของการใช้งาน AI agentic ที่คุ้มค่าและรักษาความเป็นส่วนตัว

## [ส่วนที่ 2: การเรียกฟังก์ชันใน Small Language Models](./02.FunctionCalling.md)

ส่วนที่สองเจาะลึกถึง **ความสามารถในการเรียกฟังก์ชัน** ซึ่งเป็นกลไกที่เปลี่ยนโมเดลภาษาที่นิ่งเฉยให้กลายเป็นเอเจนต์ AI แบบไดนามิกที่สามารถโต้ตอบกับโลกจริงได้ การวิเคราะห์เชิงเทคนิคนี้ครอบคลุมกระบวนการทำงานทั้งหมดตั้งแต่การตรวจจับเจตนาไปจนถึงการรวมการตอบสนอง

### พื้นที่การใช้งานหลัก:
- **กระบวนการทำงานอย่างเป็นระบบ**: การสำรวจรายละเอียดเกี่ยวกับการรวมเครื่องมือ การกำหนดฟังก์ชัน การตรวจจับเจตนา การสร้างผลลัพธ์ JSON และการดำเนินการภายนอก
- **การใช้งานเฉพาะแพลตฟอร์ม**: คู่มือที่ครอบคลุมสำหรับ Phi-4-mini กับ Ollama, Qwen3 function calling และการบูรณาการ Microsoft Foundry Local
- **ตัวอย่างขั้นสูง**: ระบบการทำงานร่วมกันของหลายเอเจนต์ การเลือกเครื่องมือแบบไดนามิก และรูปแบบการบูรณาการในองค์กรพร้อมการจัดการข้อผิดพลาดอย่างครอบคลุม
- **ข้อควรพิจารณาในการใช้งานจริง**: การจำกัดอัตรา การบันทึกการตรวจสอบ มาตรการรักษาความปลอดภัย และกลยุทธ์การปรับปรุงประสิทธิภาพ

ส่วนนี้ให้ทั้งความเข้าใจเชิงทฤษฎีและรูปแบบการใช้งานจริง ช่วยให้นักพัฒนาสร้างระบบการเรียกฟังก์ชันที่แข็งแกร่งซึ่งสามารถจัดการได้ตั้งแต่การเรียก API แบบง่ายไปจนถึงกระบวนการทำงานในองค์กรที่ซับซ้อนหลายขั้นตอน

## [ส่วนที่ 3: การบูรณาการ Model Context Protocol (MCP)](./03.IntroduceMCP.md)

ส่วนสุดท้ายแนะนำ **Model Context Protocol (MCP)** ซึ่งเป็นกรอบการทำงานที่ปฏิวัติวงการซึ่งมาตรฐานการโต้ตอบระหว่างโมเดลภาษาและเครื่องมือหรือระบบภายนอก ส่วนนี้แสดงให้เห็นว่า MCP สร้างสะพานเชื่อมระหว่างโมเดล AI และโลกจริงผ่านโปรโตคอลที่กำหนดไว้อย่างดี

### ไฮไลต์การบูรณาการ:
- **สถาปัตยกรรมโปรโตคอล**: การออกแบบระบบแบบเลเยอร์ที่ครอบคลุมชั้นแอปพลิเคชัน LLM client MCP client และชั้นการประมวลผลเครื่องมือ
- **การรองรับหลาย backend**: การใช้งานที่ยืดหยุ่นรองรับทั้ง Ollama (การพัฒนาท้องถิ่น) และ vLLM (การใช้งานจริง)
- **โปรโตคอลการเชื่อมต่อ**: โหมด STDIO สำหรับการสื่อสารกระบวนการโดยตรง และโหมด SSE สำหรับการสตรีมผ่าน HTTP
- **การใช้งานในโลกจริง**: ตัวอย่างการทำงานอัตโนมัติบนเว็บ การประมวลผลข้อมูล และการบูรณาการ API พร้อมการจัดการข้อผิดพลาดอย่างครอบคลุม

การบูรณาการ MCP แสดงให้เห็นว่า SLMs สามารถเพิ่มความสามารถภายนอกได้อย่างไร โดยชดเชยจำนวนพารามิเตอร์ที่น้อยลงด้วยฟังก์ชันที่เพิ่มขึ้น ในขณะที่ยังคงรักษาประโยชน์ของการใช้งานในท้องถิ่นและประสิทธิภาพทรัพยากร

## ผลกระทบเชิงกลยุทธ์

ทั้งสามส่วนนี้นำเสนอกรอบการทำงานที่ครอบคลุมสำหรับการทำความเข้าใจและการใช้งานระบบ SLM agentic การพัฒนาจากแนวคิดพื้นฐานผ่านการเรียกฟังก์ชันไปจนถึงการบูรณาการ MCP แสดงให้เห็นเส้นทางที่ชัดเจนสู่การใช้งาน AI ที่เป็นประชาธิปไตย ซึ่ง:

- **ประสิทธิภาพพบกับความสามารถ** ผ่านโมเดลขนาดเล็กที่ปรับแต่ง
- **ความคุ้มค่า** ช่วยให้เกิดการใช้งานอย่างแพร่หลาย
- **โปรโตคอลมาตรฐาน** รับรองการทำงานร่วมกัน
- **การใช้งานในท้องถิ่น** รักษาความเป็นส่วนตัวและลดความล่าช้า

ความก้าวหน้านี้ไม่ได้เป็นเพียงการพัฒนาทางเทคโนโลยี แต่เป็นการเปลี่ยนแปลงแนวคิดสู่ระบบ AI ที่เข้าถึงได้ มีประสิทธิภาพ และใช้งานได้จริง ซึ่งสามารถทำงานได้อย่างมีประสิทธิภาพในสภาพแวดล้อมที่มีทรัพยากรจำกัด ในขณะที่ยังคงมอบความสามารถ agentic ที่ซับซ้อน

การผสมผสานระหว่าง SLMs กับกลยุทธ์การใช้งานขั้นสูง การเรียกฟังก์ชันที่แข็งแกร่ง และโปรโตคอลการบูรณาการเครื่องมือที่ได้มาตรฐาน ทำให้ระบบเหล่านี้เป็นรากฐานสำหรับเอเจนต์ AI รุ่นต่อไปที่จะเปลี่ยนแปลงวิธีที่เราโต้ตอบและได้รับประโยชน์จากปัญญาประดิษฐ์ในอุตสาหกรรมและการใช้งานต่าง ๆ

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษาจากผู้เชี่ยวชาญ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้