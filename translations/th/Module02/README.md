<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7c65ab2fd757b5fce2f114a3118d05da",
  "translation_date": "2025-09-18T06:27:25+00:00",
  "source_file": "Module02/README.md",
  "language_code": "th"
}
-->
# บทที่ 02: พื้นฐานของโมเดลภาษาขนาดเล็ก

บทนี้เป็นบทพื้นฐานที่ครอบคลุมการสำรวจโมเดลภาษาขนาดเล็ก (SLMs) โดยเน้นทั้งหลักการทางทฤษฎี กลยุทธ์การใช้งานในทางปฏิบัติ และการนำไปใช้ในระดับการผลิต บทนี้สร้างฐานความรู้สำคัญสำหรับการทำความเข้าใจสถาปัตยกรรม AI ที่มีประสิทธิภาพในยุคปัจจุบัน และการนำไปใช้ในสภาพแวดล้อมการคำนวณที่หลากหลาย

## สถาปัตยกรรมบทและกรอบการเรียนรู้แบบก้าวหน้า

### **[ส่วนที่ 1: พื้นฐานของตระกูลโมเดล Microsoft Phi](./01.PhiFamily.md)**
ส่วนเปิดตัวนี้แนะนำตระกูลโมเดล Phi ของ Microsoft ที่เป็นนวัตกรรมใหม่ โดยแสดงให้เห็นว่าโมเดลที่กะทัดรัดและมีประสิทธิภาพสามารถสร้างผลลัพธ์ที่ยอดเยี่ยมได้อย่างไร ในขณะที่ลดความต้องการการคำนวณลงอย่างมาก หัวข้อที่ครอบคลุมในส่วนนี้ได้แก่:

- **วิวัฒนาการปรัชญาการออกแบบ**: การสำรวจอย่างละเอียดเกี่ยวกับการพัฒนาตระกูล Phi ตั้งแต่ Phi-1 ถึง Phi-4 โดยเน้นวิธีการฝึกอบรมที่มีคุณภาพระดับ "ตำราเรียน" และการปรับขนาดในช่วงการอนุมาน
- **สถาปัตยกรรมที่เน้นประสิทธิภาพ**: การวิเคราะห์เชิงลึกเกี่ยวกับการเพิ่มประสิทธิภาพพารามิเตอร์ ความสามารถในการรวมหลายรูปแบบ และการปรับแต่งเฉพาะฮาร์ดแวร์สำหรับ CPU, GPU และอุปกรณ์ Edge
- **ความสามารถเฉพาะทาง**: การครอบคลุมเชิงลึกเกี่ยวกับตัวแปรเฉพาะด้าน เช่น Phi-4-mini-reasoning สำหรับงานคณิตศาสตร์ Phi-4-multimodal สำหรับการประมวลผลภาพและภาษา และ Phi-3-Silica สำหรับการใช้งานใน Windows 11

ส่วนนี้สร้างหลักการพื้นฐานที่ว่า ประสิทธิภาพของโมเดลและความสามารถสามารถอยู่ร่วมกันได้ผ่านวิธีการฝึกอบรมที่เป็นนวัตกรรมและการปรับแต่งสถาปัตยกรรม

### **[ส่วนที่ 2: พื้นฐานของตระกูล Qwen](./02.QwenFamily.md)**
ส่วนที่สองเปลี่ยนไปสู่แนวทางโอเพ่นซอร์สของ Alibaba โดยแสดงให้เห็นว่าโมเดลที่โปร่งใสและเข้าถึงได้สามารถสร้างผลลัพธ์ที่แข่งขันได้ ในขณะที่ยังคงความยืดหยุ่นในการนำไปใช้ หัวข้อสำคัญที่เน้นได้แก่:

- **ความเป็นเลิศในโอเพ่นซอร์ส**: การสำรวจอย่างละเอียดเกี่ยวกับวิวัฒนาการของ Qwen ตั้งแต่ Qwen 1.0 ถึง Qwen3 โดยเน้นการฝึกอบรมขนาดใหญ่ (36 ล้านล้านโทเค็น) และความสามารถหลายภาษาใน 119 ภาษา
- **สถาปัตยกรรมการคิดขั้นสูง**: การครอบคลุมเชิงลึกเกี่ยวกับความสามารถ "โหมดการคิด" ของ Qwen3 การใช้งาน mixture-of-experts และตัวแปรเฉพาะทางสำหรับการเขียนโค้ด (Qwen-Coder) และคณิตศาสตร์ (Qwen-Math)
- **ตัวเลือกการนำไปใช้ที่ปรับขนาดได้**: การวิเคราะห์เชิงลึกเกี่ยวกับช่วงพารามิเตอร์ตั้งแต่ 0.5B ถึง 235B ซึ่งช่วยให้สามารถนำไปใช้ได้ตั้งแต่อุปกรณ์มือถือไปจนถึงคลัสเตอร์องค์กร

ส่วนนี้เน้นการทำให้เทคโนโลยี AI เข้าถึงได้ผ่านโอเพ่นซอร์ส ในขณะที่ยังคงลักษณะการทำงานที่แข่งขันได้

### **[ส่วนที่ 3: พื้นฐานของตระกูล Gemma](./03.GemmaFamily.md)**
ส่วนที่สามสำรวจแนวทางของ Google ในการพัฒนา AI หลายรูปแบบแบบโอเพ่นซอร์ส โดยแสดงให้เห็นว่าการพัฒนาที่ขับเคลื่อนด้วยการวิจัยสามารถส่งมอบความสามารถ AI ที่ทรงพลังและเข้าถึงได้ หัวข้อที่ครอบคลุมในส่วนนี้ได้แก่:

- **นวัตกรรมที่ขับเคลื่อนด้วยการวิจัย**: การครอบคลุมอย่างละเอียดเกี่ยวกับสถาปัตยกรรม Gemma 3 และ Gemma 3n ที่มีเทคโนโลยี Per-Layer Embeddings (PLE) และกลยุทธ์การปรับแต่งสำหรับมือถือ
- **ความเป็นเลิศในหลายรูปแบบ**: การสำรวจเชิงลึกเกี่ยวกับการรวมภาพและภาษา ความสามารถในการประมวลผลเสียง และฟีเจอร์การเรียกฟังก์ชันที่ช่วยให้เกิดประสบการณ์ AI ที่ครอบคลุม
- **สถาปัตยกรรมที่เน้นมือถือ**: การวิเคราะห์เชิงลึกเกี่ยวกับความสำเร็จด้านประสิทธิภาพของ Gemma 3n ที่ปฏิวัติวงการ โดยให้ประสิทธิภาพพารามิเตอร์ 2B-4B ด้วยการใช้หน่วยความจำเพียง 2-3GB

ส่วนนี้แสดงให้เห็นว่าการวิจัยล้ำสมัยสามารถแปลเป็นโซลูชัน AI ที่ใช้งานได้จริงและเข้าถึงได้ ซึ่งช่วยให้เกิดหมวดหมู่แอปพลิเคชันใหม่

### **[ส่วนที่ 4: พื้นฐานของตระกูล BitNET](./04.BitNETFamily.md)**
ส่วนที่สี่นำเสนอแนวทางปฏิวัติของ Microsoft ในการทำให้ AI มีประสิทธิภาพสูงสุดผ่านการควอนไทซ์แบบ 1 บิต ซึ่งเป็นแนวหน้าของการนำ AI ไปใช้ที่มีประสิทธิภาพสูง หัวข้อขั้นสูงที่ครอบคลุมได้แก่:

- **การควอนไทซ์ที่ปฏิวัติวงการ**: การสำรวจอย่างละเอียดเกี่ยวกับการควอนไทซ์ 1.58 บิตโดยใช้น้ำหนักแบบ ternary {-1, 0, +1} ซึ่งให้ความเร็วเพิ่มขึ้น 1.37x ถึง 6.17x พร้อมลดการใช้พลังงานลง 55-82%
- **กรอบการอนุมานที่ปรับแต่ง**: การครอบคลุมเชิงลึกเกี่ยวกับการใช้งาน bitnet.cpp จาก [https://github.com/microsoft/BitNet](https://github.com/microsoft/BitNet) เคอร์เนลเฉพาะทาง และการปรับแต่งข้ามแพลตฟอร์มที่ให้ประสิทธิภาพสูงสุด
- **ความเป็นผู้นำด้าน AI ที่ยั่งยืน**: การวิเคราะห์เชิงลึกเกี่ยวกับประโยชน์ด้านสิ่งแวดล้อม ความสามารถในการนำไปใช้ที่เข้าถึงได้ และสถานการณ์การใช้งานใหม่ที่เกิดจากประสิทธิภาพสูงสุด

ส่วนนี้แสดงให้เห็นว่าเทคนิคการควอนไทซ์ที่ปฏิวัติวงการสามารถปรับปรุงประสิทธิภาพ AI ได้อย่างมาก ในขณะที่ยังคงรักษาประสิทธิภาพที่แข่งขันได้

### **[ส่วนที่ 5: พื้นฐานของโมเดล Microsoft Mu](./05.mumodel.md)**
ส่วนที่ห้าสำรวจโมเดล Mu ของ Microsoft ที่ออกแบบมาโดยเฉพาะสำหรับการใช้งานบนอุปกรณ์ใน Windows ส่วนนี้ครอบคลุมหัวข้อเฉพาะทางได้แก่:

- **สถาปัตยกรรมที่เน้นอุปกรณ์**: การสำรวจอย่างละเอียดเกี่ยวกับโมเดลเฉพาะทางของ Microsoft ที่สร้างขึ้นในอุปกรณ์ Windows 11
- **การบูรณาการระบบ**: การวิเคราะห์เชิงลึกเกี่ยวกับการบูรณาการ Windows 11 อย่างลึกซึ้ง โดยแสดงให้เห็นว่า AI สามารถเพิ่มประสิทธิภาพการทำงานของระบบผ่านการใช้งานแบบเนทีฟได้อย่างไร
- **การออกแบบที่รักษาความเป็นส่วนตัว**: การครอบคลุมเชิงลึกเกี่ยวกับการทำงานแบบออฟไลน์ การประมวลผลในเครื่อง และสถาปัตยกรรมที่เน้นความเป็นส่วนตัวซึ่งเก็บข้อมูลผู้ใช้ไว้ในอุปกรณ์

ส่วนนี้แสดงให้เห็นว่าโมเดลเฉพาะทางสามารถเพิ่มประสิทธิภาพการทำงานของระบบปฏิบัติการ Windows 11 ได้อย่างไร ในขณะที่ยังคงรักษาความเป็นส่วนตัวและประสิทธิภาพ

### **[ส่วนที่ 6: พื้นฐานของ Phi-Silica](./06.phisilica.md)**
ส่วนสุดท้ายตรวจสอบ Phi-Silica ของ Microsoft ซึ่งเป็นโมเดลภาษาที่มีประสิทธิภาพสูงสุดที่สร้างขึ้นใน Windows 11 สำหรับ PC Copilot+ ที่มีฮาร์ดแวร์ NPU หัวข้อขั้นสูงที่ครอบคลุมได้แก่:

- **ตัวชี้วัดประสิทธิภาพที่ยอดเยี่ยม**: การวิเคราะห์เชิงลึกเกี่ยวกับความสามารถด้านประสิทธิภาพที่โดดเด่นของ Phi-Silica โดยให้ผลลัพธ์ 650 โทเค็นต่อวินาทีด้วยการใช้พลังงานเพียง 1.5 วัตต์
- **การปรับแต่ง NPU**: การสำรวจเชิงลึกเกี่ยวกับสถาปัตยกรรมเฉพาะทางที่ออกแบบมาสำหรับ Neural Processing Units ใน PC Copilot+ ของ Windows 11
- **การบูรณาการสำหรับนักพัฒนา**: การครอบคลุมเชิงลึกเกี่ยวกับการบูรณาการ Windows App SDK เทคนิคการออกแบบ prompt และแนวทางปฏิบัติที่ดีที่สุดสำหรับการใช้งาน Phi-Silica ในแอปพลิเคชัน Windows 11

ส่วนนี้แสดงให้เห็นถึงความล้ำหน้าของโมเดลภาษาที่ปรับแต่งฮาร์ดแวร์บนอุปกรณ์ โดยแสดงให้เห็นว่าสถาปัตยกรรมโมเดลเฉพาะทางที่รวมกับฮาร์ดแวร์ประสาทเฉพาะทางสามารถให้ประสิทธิภาพ AI ที่ยอดเยี่ยมในอุปกรณ์ผู้บริโภค Windows 11 ได้อย่างไร

## ผลลัพธ์การเรียนรู้ที่ครอบคลุม

เมื่อจบบทพื้นฐานนี้ ผู้อ่านจะมีความเชี่ยวชาญใน:

1. **ความเข้าใจด้านสถาปัตยกรรม**: ความเข้าใจเชิงลึกเกี่ยวกับปรัชญาการออกแบบ SLM ที่แตกต่างกันและผลกระทบต่อสถานการณ์การนำไปใช้
2. **สมดุลระหว่างประสิทธิภาพและประสิทธิผล**: ความสามารถในการตัดสินใจเชิงกลยุทธ์สำหรับการเลือกสถาปัตยกรรมโมเดลที่เหมาะสมตามข้อจำกัดด้านการคำนวณและความต้องการด้านประสิทธิภาพ
3. **ความยืดหยุ่นในการนำไปใช้**: ความเข้าใจเกี่ยวกับการแลกเปลี่ยนระหว่างการปรับแต่งเฉพาะทาง (Phi) การเข้าถึงแบบโอเพ่นซอร์ส (Qwen) นวัตกรรมที่ขับเคลื่อนด้วยการวิจัย (Gemma) และประสิทธิภาพที่ปฏิวัติวงการ (BitNET)
4. **มุมมองที่พร้อมสำหรับอนาคต**: ข้อมูลเชิงลึกเกี่ยวกับแนวโน้มที่เกิดขึ้นใหม่ในสถาปัตยกรรม AI ที่มีประสิทธิภาพและผลกระทบต่อกลยุทธ์การนำไปใช้ในอนาคต

## การมุ่งเน้นการใช้งานในทางปฏิบัติ

บทนี้รักษาแนวทางปฏิบัติที่แข็งแกร่งตลอด โดยมี:

- **ตัวอย่างโค้ดที่สมบูรณ์**: ตัวอย่างการใช้งานในระดับการผลิตสำหรับแต่ละตระกูลโมเดล รวมถึงขั้นตอนการปรับแต่ง กลยุทธ์การเพิ่มประสิทธิภาพ และการกำหนดค่าการนำไปใช้
- **การเปรียบเทียบประสิทธิภาพที่ครอบคลุม**: การเปรียบเทียบประสิทธิภาพอย่างละเอียดระหว่างสถาปัตยกรรมโมเดลต่างๆ รวมถึงตัวชี้วัดประสิทธิภาพ การประเมินความสามารถ และการปรับแต่งกรณีการใช้งาน
- **ความปลอดภัยระดับองค์กร**: การใช้งานด้านความปลอดภัยในระดับการผลิต กลยุทธ์การตรวจสอบ และแนวทางปฏิบัติที่ดีที่สุดสำหรับการนำไปใช้ที่เชื่อถือได้
- **การบูรณาการกรอบงาน**: คำแนะนำในทางปฏิบัติสำหรับการบูรณาการกับกรอบงานยอดนิยม เช่น Hugging Face Transformers, vLLM, ONNX Runtime และเครื่องมือเพิ่มประสิทธิภาพเฉพาะทาง

## แผนที่เทคโนโลยีเชิงกลยุทธ์

บทนี้สรุปด้วยการวิเคราะห์ที่มุ่งไปข้างหน้าเกี่ยวกับ:

- **วิวัฒนาการของสถาปัตยกรรม**: แนวโน้มที่เกิดขึ้นใหม่ในการออกแบบโมเดลที่มีประสิทธิภาพและการเพิ่มประสิทธิภาพ
- **การบูรณาการฮาร์ดแวร์**: ความก้าวหน้าในตัวเร่ง AI เฉพาะทางและผลกระทบต่อกลยุทธ์การนำไปใช้
- **การพัฒนาอีโคซิสเต็ม**: ความพยายามในการสร้างมาตรฐานและการปรับปรุงการทำงานร่วมกันระหว่างตระกูลโมเดลต่างๆ
- **การนำไปใช้ในองค์กร**: การพิจารณาเชิงกลยุทธ์สำหรับการวางแผนการนำ AI ไปใช้ในองค์กร

## สถานการณ์การใช้งานจริง

แต่ละส่วนให้การครอบคลุมที่ครอบคลุมเกี่ยวกับการใช้งานในทางปฏิบัติ:

- **การคำนวณบนมือถือและ Edge**: กลยุทธ์การนำไปใช้ที่ปรับแต่งสำหรับสภาพแวดล้อมที่มีทรัพยากรจำกัด
- **แอปพลิเคชันในองค์กร**: โซลูชันที่ปรับขนาดได้สำหรับการวิเคราะห์ธุรกิจ ระบบอัตโนมัติ และการบริการลูกค้า
- **เทคโนโลยีการศึกษา**: AI ที่เข้าถึงได้สำหรับการเรียนรู้แบบเฉพาะบุคคลและการสร้างเนื้อหา
- **การนำไปใช้ทั่วโลก**: แอปพลิเคชัน AI หลายภาษาและข้ามวัฒนธรรม

## มาตรฐานความเป็นเลิศทางเทคนิค

บทนี้เน้นการใช้งานในระดับการผลิตผ่าน:

- **ความเชี่ยวชาญด้านการเพิ่มประสิทธิภาพ**: เทคนิคการควอนไทซ์ขั้นสูง การเพิ่มประสิทธิภาพการอนุมาน และการจัดการทรัพยากร
- **การตรวจสอบประสิทธิภาพ**: การรวบรวมตัวชี้วัดที่ครอบคลุม ระบบแจ้งเตือน และการวิเคราะห์ประสิทธิภาพ
- **การใช้งานด้านความปลอดภัย**: มาตรการความปลอดภัยระดับองค์กร การปกป้องความเป็นส่วนตัว และกรอบการปฏิบัติตามข้อกำหนด
- **การวางแผนการปรับขนาด**: กลยุทธ์การปรับขนาดแนวนอนและแนวตั้งสำหรับความต้องการการคำนวณที่เพิ่มขึ้น

บทพื้นฐานนี้ทำหน้าที่เป็นข้อกำหนดเบื้องต้นที่สำคัญสำหรับกลยุทธ์การนำ SLM ไปใช้ขั้นสูง โดยสร้างทั้งความเข้าใจทางทฤษฎีและความสามารถในทางปฏิบัติที่จำเป็นสำหรับการใช้งานที่ประสบความสำเร็จ การครอบคลุมที่ครอบคลุมช่วยให้ผู้อ่านมีความพร้อมในการตัดสินใจด้านสถาปัตยกรรมอย่างมีข้อมูลและนำโซลูชัน AI ที่มีประสิทธิภาพและแข็งแกร่งไปใช้ซึ่งตอบสนองความต้องการเฉพาะขององค์กร ในขณะที่เตรียมพร้อมสำหรับการพัฒนาเทคโนโลยีในอนาคต

บทนี้เชื่อมโยงช่องว่างระหว่างการวิจัย AI ล้ำสมัยและความเป็นจริงในการนำไปใช้ในทางปฏิบัติ โดยเน้นว่า สถาปัตยกรรม SLM สมัยใหม่สามารถให้ประสิทธิภาพที่ยอดเยี่ยม ในขณะที่ยังคงรักษาประสิทธิภาพการดำเนินงาน ความคุ้มค่า และความยั่งยืนด้านสิ่งแวดล้อม

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้องมากที่สุด แต่โปรดทราบว่าการแปลโดยอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้