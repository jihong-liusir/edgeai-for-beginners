<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "65a22ed38b95f334dd8a893bf2c55806",
  "translation_date": "2025-10-02T13:01:31+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "th"
}
-->
# AI Toolkit สำหรับ Visual Studio Code - คู่มือการพัฒนา Edge AI

## บทนำ

ยินดีต้อนรับสู่คู่มือฉบับสมบูรณ์สำหรับการใช้งาน AI Toolkit ใน Visual Studio Code เพื่อการพัฒนา Edge AI เมื่อปัญญาประดิษฐ์ก้าวเข้าสู่การประมวลผลแบบกระจายบนอุปกรณ์ปลายทาง นักพัฒนาจำเป็นต้องมีเครื่องมือที่ทรงพลังและครบวงจรเพื่อจัดการกับความท้าทายเฉพาะ เช่น ข้อจำกัดด้านทรัพยากรและความต้องการในการทำงานแบบออฟไลน์

AI Toolkit สำหรับ Visual Studio Code ช่วยเติมเต็มช่องว่างนี้ด้วยการมอบสภาพแวดล้อมการพัฒนาที่สมบูรณ์แบบ ซึ่งออกแบบมาเพื่อสร้าง ทดสอบ และปรับแต่งแอปพลิเคชัน AI ที่ทำงานได้อย่างมีประสิทธิภาพบนอุปกรณ์ปลายทาง ไม่ว่าคุณจะพัฒนาสำหรับเซ็นเซอร์ IoT อุปกรณ์มือถือ ระบบฝังตัว หรือเซิร์ฟเวอร์ปลายทาง เครื่องมือนี้ช่วยให้กระบวนการพัฒนาทั้งหมดของคุณง่ายขึ้นภายในสภาพแวดล้อมที่คุ้นเคยของ VS Code

คู่มือนี้จะนำคุณผ่านแนวคิดสำคัญ เครื่องมือ และแนวปฏิบัติที่ดีที่สุดในการใช้ AI Toolkit ในโครงการ Edge AI ของคุณ ตั้งแต่การเลือกโมเดลเริ่มต้นไปจนถึงการปรับใช้ในระดับการผลิต

## ภาพรวม

AI Toolkit สำหรับ Visual Studio Code เป็นส่วนขยายที่ทรงพลังซึ่งช่วยให้การพัฒนาเอเจนต์และการสร้างแอปพลิเคชัน AI เป็นเรื่องง่าย เครื่องมือนี้มีความสามารถครบวงจรในการสำรวจ ประเมิน และปรับใช้โมเดล AI จากผู้ให้บริการหลากหลาย เช่น Anthropic, OpenAI, GitHub, Google พร้อมรองรับการทำงานของโมเดลในเครื่องผ่าน ONNX และ Ollama

สิ่งที่ทำให้ AI Toolkit โดดเด่นคือแนวทางที่ครอบคลุมตลอดวงจรการพัฒนา AI ต่างจากเครื่องมือพัฒนา AI แบบดั้งเดิมที่มุ่งเน้นเพียงด้านเดียว AI Toolkit มอบสภาพแวดล้อมแบบบูรณาการที่ครอบคลุมการค้นหาโมเดล การทดลอง การพัฒนาเอเจนต์ การประเมิน และการปรับใช้ ทั้งหมดนี้อยู่ในสภาพแวดล้อมที่คุ้นเคยของ VS Code

แพลตฟอร์มนี้ออกแบบมาเพื่อการสร้างต้นแบบอย่างรวดเร็วและการปรับใช้ในระดับการผลิต ด้วยฟีเจอร์ต่างๆ เช่น การสร้างคำสั่งเริ่มต้น ตัวช่วยเริ่มต้นอย่างรวดเร็ว การผสานรวมเครื่องมือ MCP (Model Context Protocol) อย่างไร้รอยต่อ และความสามารถในการประเมินที่ครอบคลุม สำหรับการพัฒนา Edge AI หมายความว่าคุณสามารถพัฒนา ทดสอบ และปรับแต่งแอปพลิเคชัน AI สำหรับสถานการณ์การปรับใช้ปลายทางได้อย่างมีประสิทธิภาพ พร้อมทั้งรักษากระบวนการพัฒนาเต็มรูปแบบภายใน VS Code

## วัตถุประสงค์การเรียนรู้

เมื่อจบคู่มือนี้ คุณจะสามารถ:

### ความสามารถหลัก
- **ติดตั้งและกำหนดค่า** AI Toolkit สำหรับ Visual Studio Code เพื่อการพัฒนา Edge AI
- **นำทางและใช้งาน** อินเทอร์เฟซ AI Toolkit รวมถึง Model Catalog, Playground และ Agent Builder
- **เลือกและประเมิน** โมเดล AI ที่เหมาะสมสำหรับการปรับใช้ปลายทางโดยพิจารณาจากประสิทธิภาพและข้อจำกัดด้านทรัพยากร
- **แปลงและปรับแต่ง** โมเดลโดยใช้รูปแบบ ONNX และเทคนิคการลดขนาดสำหรับอุปกรณ์ปลายทาง

### ทักษะการพัฒนา Edge AI
- **ออกแบบและพัฒนา** แอปพลิเคชัน Edge AI โดยใช้สภาพแวดล้อมการพัฒนาแบบบูรณาการ
- **ทดสอบโมเดล** ในสภาพแวดล้อมที่คล้ายกับปลายทางโดยใช้การอนุมานในเครื่องและการตรวจสอบทรัพยากร
- **สร้างและปรับแต่ง** เอเจนต์ AI ที่เหมาะสมสำหรับสถานการณ์การปรับใช้ปลายทาง
- **ประเมินประสิทธิภาพของโมเดล** โดยใช้เมตริกที่เกี่ยวข้องกับการประมวลผลปลายทาง (ความหน่วง, การใช้หน่วยความจำ, ความแม่นยำ)

### การปรับแต่งและการปรับใช้
- **ใช้เทคนิคการลดขนาดและการตัดแต่ง** เพื่อลดขนาดโมเดลในขณะที่ยังคงรักษาประสิทธิภาพที่ยอมรับได้
- **ปรับแต่งโมเดล** สำหรับแพลตฟอร์มฮาร์ดแวร์ปลายทางเฉพาะ เช่น CPU, GPU และ NPU
- **นำแนวปฏิบัติที่ดีที่สุดมาใช้** สำหรับการพัฒนา Edge AI รวมถึงการจัดการทรัพยากรและกลยุทธ์สำรอง
- **เตรียมโมเดลและแอปพลิเคชัน** สำหรับการปรับใช้ในระดับการผลิตบนอุปกรณ์ปลายทาง

### แนวคิดขั้นสูงของ Edge AI
- **ผสานรวมกับเฟรมเวิร์ก Edge AI** เช่น ONNX Runtime, Windows ML และ TensorFlow Lite
- **ใช้สถาปัตยกรรมหลายโมเดล** และสถานการณ์การเรียนรู้แบบกระจายสำหรับสภาพแวดล้อมปลายทาง
- **แก้ไขปัญหาทั่วไปของ Edge AI** เช่น ข้อจำกัดด้านหน่วยความจำ ความเร็วในการอนุมาน และความเข้ากันได้ของฮาร์ดแวร์
- **ออกแบบกลยุทธ์การตรวจสอบและบันทึก** สำหรับแอปพลิเคชัน Edge AI ในระดับการผลิต

### การประยุกต์ใช้งานจริง
- **สร้างโซลูชัน Edge AI แบบครบวงจร** ตั้งแต่การเลือกโมเดลไปจนถึงการปรับใช้
- **แสดงความเชี่ยวชาญ** ในกระบวนการพัฒนาและเทคนิคการปรับแต่งเฉพาะปลายทาง
- **นำแนวคิดที่เรียนรู้ไปใช้** กับกรณีการใช้งาน Edge AI ในโลกจริง เช่น IoT, มือถือ และแอปพลิเคชันฝังตัว
- **ประเมินและเปรียบเทียบ** กลยุทธ์การปรับใช้ Edge AI ต่างๆ และข้อดีข้อเสียของแต่ละกลยุทธ์

## คุณสมบัติสำคัญสำหรับการพัฒนา Edge AI

### 1. Model Catalog และการค้นหา
- **รองรับผู้ให้บริการหลายราย**: เรียกดูและเข้าถึงโมเดล AI จาก Anthropic, OpenAI, GitHub, Google และผู้ให้บริการอื่นๆ
- **การผสานรวมโมเดลในเครื่อง**: การค้นหาโมเดล ONNX และ Ollama สำหรับการปรับใช้ปลายทางที่ง่ายขึ้น
- **โมเดล GitHub**: การผสานรวมโดยตรงกับการโฮสต์โมเดลของ GitHub เพื่อการเข้าถึงที่ง่ายดาย
- **การเปรียบเทียบโมเดล**: เปรียบเทียบโมเดลแบบเคียงข้างกันเพื่อค้นหาสมดุลที่เหมาะสมสำหรับข้อจำกัดของอุปกรณ์ปลายทาง

### 2. Interactive Playground
- **สภาพแวดล้อมการทดสอบแบบโต้ตอบ**: ทดลองความสามารถของโมเดลอย่างรวดเร็วในสภาพแวดล้อมที่ควบคุมได้
- **รองรับหลายรูปแบบ**: ทดสอบด้วยภาพ ข้อความ และอินพุตอื่นๆ ที่พบในสถานการณ์ปลายทาง
- **การทดลองแบบเรียลไทม์**: รับผลตอบกลับทันทีเกี่ยวกับการตอบสนองและประสิทธิภาพของโมเดล
- **การปรับแต่งพารามิเตอร์**: ปรับแต่งพารามิเตอร์ของโมเดลให้เหมาะสมกับข้อกำหนดการปรับใช้ปลายทาง

### 3. Prompt (Agent) Builder
- **การสร้างคำสั่งด้วยภาษาธรรมชาติ**: สร้างคำสั่งเริ่มต้นโดยใช้คำอธิบายภาษาธรรมชาติ
- **การปรับแต่งแบบวนซ้ำ**: ปรับปรุงคำสั่งตามการตอบสนองและประสิทธิภาพของโมเดล
- **การแบ่งงาน**: แบ่งงานที่ซับซ้อนด้วยการเชื่อมโยงคำสั่งและผลลัพธ์ที่มีโครงสร้าง
- **รองรับตัวแปร**: ใช้ตัวแปรในคำสั่งเพื่อพฤติกรรมเอเจนต์แบบไดนามิก
- **การสร้างโค้ดสำหรับการผลิต**: สร้างโค้ดพร้อมใช้งานสำหรับการพัฒนาแอปอย่างรวดเร็ว

### 4. Bulk Run และการประเมินผล
- **การทดสอบหลายโมเดล**: รันคำสั่งหลายคำสั่งพร้อมกันในโมเดลที่เลือก
- **การทดสอบที่มีประสิทธิภาพในระดับใหญ่**: ทดสอบอินพุตและการกำหนดค่าต่างๆ ได้อย่างมีประสิทธิภาพ
- **กรณีทดสอบแบบกำหนดเอง**: รันเอเจนต์ด้วยกรณีทดสอบเพื่อยืนยันการทำงาน
- **การเปรียบเทียบประสิทธิภาพ**: เปรียบเทียบผลลัพธ์ในโมเดลและการกำหนดค่าต่างๆ

### 5. การประเมินโมเดลด้วยชุดข้อมูล
- **เมตริกมาตรฐาน**: ทดสอบโมเดล AI โดยใช้ตัวประเมินในตัว (F1 score, ความเกี่ยวข้อง, ความคล้ายคลึง, ความสอดคล้อง)
- **ตัวประเมินแบบกำหนดเอง**: สร้างเมตริกการประเมินของคุณเองสำหรับกรณีการใช้งานเฉพาะ
- **การผสานรวมชุดข้อมูล**: ทดสอบโมเดลกับชุดข้อมูลที่ครอบคลุม
- **การวัดประสิทธิภาพ**: วัดประสิทธิภาพของโมเดลเพื่อการตัดสินใจปรับใช้ปลายทาง

### 6. ความสามารถในการปรับแต่ง
- **การปรับแต่งโมเดล**: ปรับแต่งโมเดลสำหรับกรณีการใช้งานและโดเมนเฉพาะ
- **การปรับแต่งเฉพาะทาง**: ปรับโมเดลให้เหมาะสมกับข้อกำหนดและโดเมนเฉพาะ
- **การปรับแต่งปลายทาง**: ปรับแต่งโมเดลโดยเฉพาะสำหรับข้อจำกัดการปรับใช้ปลายทาง
- **การฝึกอบรมเฉพาะโดเมน**: สร้างโมเดลที่ปรับแต่งสำหรับกรณีการใช้งานปลายทางเฉพาะ

### 7. การผสานรวมเครื่องมือ MCP
- **การเชื่อมต่อเครื่องมือภายนอก**: เชื่อมต่อเอเจนต์กับเครื่องมือภายนอกผ่านเซิร์ฟเวอร์ Model Context Protocol
- **การดำเนินการในโลกจริง**: เปิดใช้งานเอเจนต์เพื่อสอบถามฐานข้อมูล เข้าถึง API หรือดำเนินการตรรกะที่กำหนดเอง
- **เซิร์ฟเวอร์ MCP ที่มีอยู่**: ใช้เครื่องมือจากโปรโตคอลคำสั่ง (stdio) หรือ HTTP (server-sent event)
- **การพัฒนา MCP แบบกำหนดเอง**: สร้างและตั้งค่าเซิร์ฟเวอร์ MCP ใหม่พร้อมการทดสอบใน Agent Builder

### 8. การพัฒนาและการทดสอบเอเจนต์
- **รองรับการเรียกฟังก์ชัน**: เปิดใช้งานเอเจนต์เพื่อเรียกใช้ฟังก์ชันภายนอกแบบไดนามิก
- **การทดสอบการผสานรวมแบบเรียลไทม์**: ทดสอบการผสานรวมด้วยการรันแบบเรียลไทม์และการใช้เครื่องมือ
- **การจัดการเวอร์ชันเอเจนต์**: การควบคุมเวอร์ชันสำหรับเอเจนต์พร้อมความสามารถในการเปรียบเทียบผลการประเมิน
- **การดีบักและการติดตาม**: ความสามารถในการติดตามและดีบักในเครื่องสำหรับการพัฒนาเอเจนต์

## กระบวนการพัฒนา Edge AI

### เฟส 1: การค้นหาและเลือกโมเดล
1. **สำรวจ Model Catalog**: ใช้ Model Catalog เพื่อค้นหาโมเดลที่เหมาะสมสำหรับการปรับใช้ปลายทาง
2. **เปรียบเทียบประสิทธิภาพ**: ประเมินโมเดลตามขนาด ความแม่นยำ และความเร็วในการอนุมาน
3. **ทดสอบในเครื่อง**: ใช้โมเดล Ollama หรือ ONNX เพื่อทดสอบในเครื่องก่อนการปรับใช้ปลายทาง
4. **ประเมินความต้องการทรัพยากร**: กำหนดความต้องการด้านหน่วยความจำและการประมวลผลสำหรับอุปกรณ์ปลายทางเป้าหมาย

### เฟส 2: การปรับแต่งโมเดล
1. **แปลงเป็น ONNX**: แปลงโมเดลที่เลือกเป็นรูปแบบ ONNX เพื่อความเข้ากันได้กับปลายทาง
2. **ใช้การลดขนาด**: ลดขนาดโมเดลผ่านการลดขนาด INT8 หรือ INT4
3. **การปรับแต่งฮาร์ดแวร์**: ปรับแต่งสำหรับฮาร์ดแวร์ปลายทางเป้าหมาย (ARM, x86, ตัวเร่งความเร็วเฉพาะทาง)
4. **การตรวจสอบประสิทธิภาพ**: ตรวจสอบว่าโมเดลที่ปรับแต่งยังคงรักษาความแม่นยำที่ยอมรับได้

### เฟส 3: การพัฒนาแอปพลิเคชัน
1. **การออกแบบเอเจนต์**: ใช้ Agent Builder เพื่อสร้างเอเจนต์ AI ที่ปรับแต่งสำหรับปลายทาง
2. **การออกแบบคำสั่ง**: พัฒนาคำสั่งที่ทำงานได้อย่างมีประสิทธิภาพกับโมเดลปลายทางขนาดเล็ก
3. **การทดสอบการผสานรวม**: ทดสอบเอเจนต์ในสภาพแวดล้อมจำลองปลายทาง
4. **การสร้างโค้ด**: สร้างโค้ดสำหรับการผลิตที่ปรับแต่งสำหรับการปรับใช้ปลายทาง

### เฟส 4: การประเมินและการทดสอบ
1. **การประเมินแบบแบทช์**: ทดสอบการกำหนดค่าหลายแบบเพื่อค้นหาการตั้งค่าปลายทางที่เหมาะสมที่สุด
2. **การวิเคราะห์ประสิทธิภาพ**: วิเคราะห์ความเร็วในการอนุมาน การใช้หน่วยความจำ และความแม่นยำ
3. **การจำลองปลายทาง**: ทดสอบในสภาพแวดล้อมที่คล้ายกับการปรับใช้ปลายทางเป้าหมาย
4. **การทดสอบความทนทาน**: ประเมินประสิทธิภาพภายใต้เงื่อนไขการโหลดต่างๆ

### เฟส 5: การเตรียมการปรับใช้
1. **การปรับแต่งขั้นสุดท้าย**: ใช้การปรับแต่งขั้นสุดท้ายตามผลการทดสอบ
2. **การบรรจุสำหรับการปรับใช้**: บรรจุโมเดลและโค้ดสำหรับการปรับใช้ปลายทาง
3. **การจัดทำเอกสาร**: จัดทำเอกสารข้อกำหนดและการกำหนดค่าการปรับใช้
4. **การตั้งค่าการตรวจสอบ**: เตรียมการตรวจสอบและบันทึกสำหรับการปรับใช้ปลายทาง

## กลุ่มเป้าหมายสำหรับการพัฒนา Edge AI

### นักพัฒนา Edge AI
- นักพัฒนาแอปพลิเคชันที่สร้างอุปกรณ์ปลายทางและโซลูชัน IoT ที่ขับเคลื่อนด้วย AI
- นักพัฒนาระบบฝังตัวที่ผสานรวมความสามารถ AI เข้ากับอุปกรณ์ที่มีข้อจำกัดด้านทรัพยากร
- นักพัฒนามือถือที่สร้างแอปพลิเคชัน AI บนอุปกรณ์สำหรับสมาร์ทโฟนและแท็บเล็ต

### วิศวกร Edge AI
- วิศวกร AI ที่ปรับแต่งโมเดลสำหรับการปรับใช้ปลายทางและจัดการกระบวนการอนุมาน
- วิศวกร DevOps ที่ปรับใช้และจัดการโมเดล AI ในโครงสร้างพื้นฐานปลายทางแบบกระจาย
- วิศวกรประสิทธิภาพที่ปรับแต่งงาน AI ให้เหมาะสมกับข้อจำกัดฮาร์ดแวร์ปลายทาง

### นักวิจัยและผู้สอน
- นักวิจัย AI ที่พัฒนาโมเดลและอัลกอริทึมที่มีประสิทธิภาพสำหรับการประมวลผลปลายทาง
- ผู้สอนที่สอนแนวคิด Edge AI และสาธิตเทคนิคการปรับแต่ง
- นักเรียนที่เรียนรู้เกี่ยวกับความท้าทายและวิธีแก้ปัญหาในการปรับใช้ Edge AI

## กรณีการใช้งาน Edge AI

### อุปกรณ์ IoT อัจฉริยะ
- **การจดจำภาพแบบเรียลไทม์**: ปรับใช้โมเดลการมองเห็นคอมพิวเตอร์บนกล้อง IoT และเซ็นเซอร์
- **การประมวลผลเสียง**
2. สร้างข้อความเริ่มต้นโดยใช้คำอธิบายภาษาธรรมชาติ  
3. ปรับปรุงและแก้ไขข้อความตามผลลัพธ์ของโมเดล  
4. ผสานเครื่องมือ MCP เพื่อเพิ่มความสามารถของตัวแทน  

#### ขั้นตอนที่ 3: การทดสอบและการประเมินผล  
1. ใช้ **Bulk Run** เพื่อทดสอบข้อความหลายชุดกับโมเดลที่เลือก  
2. รันตัวแทนด้วยกรณีทดสอบเพื่อยืนยันการทำงาน  
3. ประเมินความถูกต้องและประสิทธิภาพโดยใช้เมตริกที่มีอยู่หรือเมตริกที่กำหนดเอง  
4. เปรียบเทียบโมเดลและการตั้งค่าต่าง ๆ  

#### ขั้นตอนที่ 4: การปรับแต่งและการเพิ่มประสิทธิภาพ  
1. ปรับแต่งโมเดลสำหรับกรณีการใช้งานเฉพาะ  
2. ใช้การปรับแต่งเฉพาะด้าน  
3. เพิ่มประสิทธิภาพสำหรับข้อจำกัดในการใช้งานที่ขอบ  
4. สร้างเวอร์ชันและเปรียบเทียบการตั้งค่าตัวแทนต่าง ๆ  

#### ขั้นตอนที่ 5: การเตรียมการสำหรับการใช้งาน  
1. สร้างโค้ดที่พร้อมใช้งานจริงโดยใช้ Agent Builder  
2. ตั้งค่าการเชื่อมต่อเซิร์ฟเวอร์ MCP สำหรับการใช้งานจริง  
3. เตรียมแพ็กเกจการใช้งานสำหรับอุปกรณ์ที่ขอบ  
4. กำหนดค่าการตรวจสอบและเมตริกการประเมินผล  

## แนวทางปฏิบัติที่ดีที่สุดสำหรับการพัฒนา Edge AI  

### การเลือกโมเดล  
- **ข้อจำกัดด้านขนาด**: เลือกโมเดลที่เหมาะสมกับข้อจำกัดด้านหน่วยความจำของอุปกรณ์เป้าหมาย  
- **ความเร็วในการอนุมาน**: ให้ความสำคัญกับโมเดลที่มีความเร็วในการอนุมานสูงสำหรับการใช้งานแบบเรียลไทม์  
- **การแลกเปลี่ยนความแม่นยำ**: ปรับสมดุลระหว่างความแม่นยำของโมเดลกับข้อจำกัดด้านทรัพยากร  
- **ความเข้ากันได้ของรูปแบบ**: เลือกรูปแบบ ONNX หรือรูปแบบที่ปรับแต่งสำหรับฮาร์ดแวร์เพื่อการใช้งานที่ขอบ  

### เทคนิคการเพิ่มประสิทธิภาพ  
- **Quantization**: ใช้การลดขนาดโมเดลเป็น INT8 หรือ INT4 เพื่อปรับปรุงความเร็วและลดขนาด  
- **Pruning**: ลบพารามิเตอร์โมเดลที่ไม่จำเป็นเพื่อลดความต้องการในการคำนวณ  
- **Knowledge Distillation**: สร้างโมเดลขนาดเล็กที่ยังคงรักษาประสิทธิภาพของโมเดลขนาดใหญ่  
- **Hardware Acceleration**: ใช้ NPUs, GPUs หรือตัวเร่งความเร็วเฉพาะเมื่อมี  

### เวิร์กโฟลว์การพัฒนา  
- **การทดสอบแบบวนซ้ำ**: ทดสอบบ่อยครั้งในสภาพแวดล้อมที่คล้ายกับการใช้งานที่ขอบ  
- **การตรวจสอบประสิทธิภาพ**: ตรวจสอบการใช้งานทรัพยากรและความเร็วในการอนุมานอย่างต่อเนื่อง  
- **การควบคุมเวอร์ชัน**: ติดตามเวอร์ชันของโมเดลและการตั้งค่าการเพิ่มประสิทธิภาพ  
- **การจัดทำเอกสาร**: บันทึกการตัดสินใจเกี่ยวกับการเพิ่มประสิทธิภาพและการแลกเปลี่ยนประสิทธิภาพ  

### ข้อควรพิจารณาในการใช้งาน  
- **การตรวจสอบทรัพยากร**: ตรวจสอบการใช้งานหน่วยความจำ, CPU และพลังงานในสภาพแวดล้อมจริง  
- **กลยุทธ์สำรอง**: ใช้กลไกสำรองสำหรับกรณีที่โมเดลล้มเหลว  
- **กลไกการอัปเดต**: วางแผนสำหรับการอัปเดตโมเดลและการจัดการเวอร์ชัน  
- **ความปลอดภัย**: ใช้มาตรการรักษาความปลอดภัยที่เหมาะสมสำหรับแอปพลิเคชัน Edge AI  

## การผสานรวมกับเฟรมเวิร์ก Edge AI  

### ONNX Runtime  
- **การใช้งานข้ามแพลตฟอร์ม**: ใช้โมเดล ONNX บนอุปกรณ์ขอบที่หลากหลาย  
- **การเพิ่มประสิทธิภาพฮาร์ดแวร์**: ใช้การปรับแต่งเฉพาะฮาร์ดแวร์ของ ONNX Runtime  
- **รองรับมือถือ**: ใช้ ONNX Runtime Mobile สำหรับแอปพลิเคชันบนสมาร์ทโฟนและแท็บเล็ต  
- **การผสาน IoT**: ใช้ ONNX Runtime รุ่นน้ำหนักเบาสำหรับอุปกรณ์ IoT  

### Windows ML  
- **อุปกรณ์ Windows**: ปรับแต่งสำหรับอุปกรณ์ขอบที่ใช้ Windows และ PC  
- **การเร่งความเร็วด้วย NPU**: ใช้ Neural Processing Units บนอุปกรณ์ Windows  
- **DirectML**: ใช้ DirectML สำหรับการเร่งความเร็ว GPU บนแพลตฟอร์ม Windows  
- **การผสาน UWP**: ผสานรวมกับแอปพลิเคชัน Universal Windows Platform  

### TensorFlow Lite  
- **การปรับแต่งสำหรับมือถือ**: ใช้โมเดล TensorFlow Lite บนอุปกรณ์มือถือและฝังตัว  
- **Hardware Delegates**: ใช้ตัวแทนฮาร์ดแวร์เฉพาะสำหรับการเร่งความเร็ว  
- **ไมโครคอนโทรลเลอร์**: ใช้ TensorFlow Lite Micro บนไมโครคอนโทรลเลอร์  
- **การรองรับข้ามแพลตฟอร์ม**: ใช้บน Android, iOS และระบบ Linux ฝังตัว  

### Azure IoT Edge  
- **ไฮบริดคลาวด์-ขอบ**: ผสานการฝึกอบรมบนคลาวด์กับการอนุมานที่ขอบ  
- **การใช้งานโมดูล**: ใช้โมเดล AI เป็นโมดูล IoT Edge  
- **การจัดการอุปกรณ์**: จัดการอุปกรณ์ขอบและการอัปเดตโมเดลจากระยะไกล  
- **Telemetry**: รวบรวมข้อมูลประสิทธิภาพและเมตริกโมเดลจากการใช้งานที่ขอบ  

## สถานการณ์ Edge AI ขั้นสูง  

### การใช้งานหลายโมเดล  
- **Model Ensembles**: ใช้โมเดลหลายตัวเพื่อเพิ่มความแม่นยำหรือความซ้ำซ้อน  
- **A/B Testing**: ทดสอบโมเดลต่าง ๆ พร้อมกันบนอุปกรณ์ขอบ  
- **การเลือกแบบไดนามิก**: เลือกโมเดลตามสภาพของอุปกรณ์ปัจจุบัน  
- **การแบ่งปันทรัพยากร**: เพิ่มประสิทธิภาพการใช้งานทรัพยากรระหว่างโมเดลที่ใช้งานหลายตัว  

### Federated Learning  
- **การฝึกอบรมแบบกระจาย**: ฝึกอบรมโมเดลบนอุปกรณ์ขอบหลายตัว  
- **การรักษาความเป็นส่วนตัว**: เก็บข้อมูลการฝึกอบรมไว้ในเครื่องขณะแบ่งปันการปรับปรุงโมเดล  
- **การเรียนรู้ร่วมกัน**: ให้อุปกรณ์เรียนรู้จากประสบการณ์ร่วมกัน  
- **การประสานงานขอบ-คลาวด์**: ประสานการเรียนรู้ระหว่างอุปกรณ์ขอบและโครงสร้างพื้นฐานคลาวด์  

### การประมวลผลแบบเรียลไทม์  
- **Stream Processing**: ประมวลผลข้อมูลแบบต่อเนื่องบนอุปกรณ์ขอบ  
- **Low-latency Inference**: ปรับแต่งเพื่อให้การอนุมานมีความหน่วงต่ำที่สุด  
- **Batch Processing**: ประมวลผลข้อมูลเป็นชุดอย่างมีประสิทธิภาพบนอุปกรณ์ขอบ  
- **Adaptive Processing**: ปรับการประมวลผลตามความสามารถของอุปกรณ์ปัจจุบัน  

## การแก้ไขปัญหาการพัฒนา Edge AI  

### ปัญหาทั่วไป  
- **ข้อจำกัดด้านหน่วยความจำ**: โมเดลมีขนาดใหญ่เกินไปสำหรับหน่วยความจำของอุปกรณ์เป้าหมาย  
- **ความเร็วในการอนุมาน**: การอนุมานของโมเดลช้าเกินไปสำหรับความต้องการแบบเรียลไทม์  
- **การลดความแม่นยำ**: การเพิ่มประสิทธิภาพลดความแม่นยำของโมเดลในระดับที่ไม่ยอมรับได้  
- **ความเข้ากันได้ของฮาร์ดแวร์**: โมเดลไม่เข้ากันกับฮาร์ดแวร์เป้าหมาย  

### กลยุทธ์การดีบัก  
- **การวิเคราะห์ประสิทธิภาพ**: ใช้ฟีเจอร์การติดตามของ AI Toolkit เพื่อระบุปัญหาคอขวด  
- **การตรวจสอบทรัพยากร**: ตรวจสอบการใช้งานหน่วยความจำและ CPU ระหว่างการพัฒนา  
- **การทดสอบแบบเพิ่มทีละขั้น**: ทดสอบการเพิ่มประสิทธิภาพทีละขั้นเพื่อแยกปัญหา  
- **การจำลองฮาร์ดแวร์**: ใช้เครื่องมือพัฒนาเพื่อจำลองฮาร์ดแวร์เป้าหมาย  

### วิธีแก้ไขการเพิ่มประสิทธิภาพ  
- **การลดขนาดเพิ่มเติม**: ใช้เทคนิคการลดขนาดที่เข้มข้นขึ้น  
- **สถาปัตยกรรมโมเดล**: พิจารณาสถาปัตยกรรมโมเดลที่แตกต่างกันซึ่งปรับแต่งสำหรับขอบ  
- **การเพิ่มประสิทธิภาพการเตรียมข้อมูล**: ปรับแต่งการเตรียมข้อมูลสำหรับข้อจำกัดที่ขอบ  
- **การเพิ่มประสิทธิภาพการอนุมาน**: ใช้การเพิ่มประสิทธิภาพการอนุมานเฉพาะฮาร์ดแวร์  

## แหล่งข้อมูลและขั้นตอนถัดไป  

### เอกสารทางการ  
- [AI Toolkit Developer Documentation](https://aka.ms/AIToolkit/doc)  
- [Installation and Setup Guide](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [VS Code Intelligent Apps Documentation](https://code.visualstudio.com/docs/intelligentapps)  
- [Model Context Protocol (MCP) Documentation](https://modelcontextprotocol.io/)  

### ชุมชนและการสนับสนุน  
- [AI Toolkit GitHub Repository](https://github.com/microsoft/vscode-ai-toolkit)  
- [GitHub Issues and Feature Requests](https://aka.ms/AIToolkit/feedback)  
- [Azure AI Foundry Discord Community](https://aka.ms/azureaifoundry/discord)  
- [VS Code Extension Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### แหล่งข้อมูลทางเทคนิค  
- [ONNX Runtime Documentation](https://onnxruntime.ai/)  
- [Ollama Documentation](https://ollama.ai/)  
- [Windows ML Documentation](https://docs.microsoft.com/en-us/windows/ai/)  
- [Azure AI Foundry Documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### เส้นทางการเรียนรู้  
- [Edge AI Fundamentals Course](../Module01/README.md)  
- [Small Language Models Guide](../Module02/README.md)  
- [Edge Deployment Strategies](../Module03/README.md)  
- [Windows Edge AI Development](./windowdeveloper.md)  

### แหล่งข้อมูลเพิ่มเติม  
- **สถิติของ Repository**: 1.8k+ ดาว, 150+ forks, 18+ ผู้ร่วมพัฒนา  
- **ใบอนุญาต**: ใบอนุญาต MIT  
- **ความปลอดภัย**: ใช้นโยบายความปลอดภัยของ Microsoft  
- **Telemetry**: เคารพการตั้งค่า telemetry ของ VS Code  

## สรุป  

AI Toolkit สำหรับ Visual Studio Code เป็นแพลตฟอร์มที่ครอบคลุมสำหรับการพัฒนา AI สมัยใหม่ โดยมีความสามารถในการพัฒนาตัวแทนที่มีประสิทธิภาพซึ่งมีคุณค่าอย่างยิ่งสำหรับแอปพลิเคชัน Edge AI ด้วยแคตตาล็อกโมเดลที่หลากหลายที่รองรับผู้ให้บริการอย่าง Anthropic, OpenAI, GitHub และ Google รวมถึงการใช้งานในเครื่องผ่าน ONNX และ Ollama เครื่องมือนี้มอบความยืดหยุ่นที่จำเป็นสำหรับสถานการณ์การใช้งานที่ขอบที่หลากหลาย  

จุดแข็งของเครื่องมืออยู่ที่แนวทางแบบบูรณาการ—ตั้งแต่การค้นหาและทดลองโมเดลใน Playground ไปจนถึงการพัฒนาตัวแทนที่ซับซ้อนด้วย Prompt Builder ความสามารถในการประเมินผลที่ครอบคลุม และการผสานเครื่องมือ MCP อย่างไร้รอยต่อ สำหรับนักพัฒนา Edge AI นี่หมายถึงการสร้างต้นแบบและการทดสอบตัวแทน AI อย่างรวดเร็วก่อนการใช้งานที่ขอบ พร้อมความสามารถในการปรับปรุงและเพิ่มประสิทธิภาพสำหรับสภาพแวดล้อมที่มีข้อจำกัดด้านทรัพยากร  

ข้อดีสำคัญสำหรับการพัฒนา Edge AI ได้แก่:  
- **การทดลองอย่างรวดเร็ว**: ทดสอบโมเดลและตัวแทนอย่างรวดเร็วก่อนการใช้งานที่ขอบ  
- **ความยืดหยุ่นหลายผู้ให้บริการ**: เข้าถึงโมเดลจากแหล่งต่าง ๆ เพื่อค้นหาโซลูชันที่เหมาะสมที่สุด  
- **การพัฒนาในเครื่อง**: ทดสอบด้วย ONNX และ Ollama สำหรับการพัฒนาแบบออฟไลน์และการรักษาความเป็นส่วนตัว  
- **ความพร้อมใช้งานจริง**: สร้างโค้ดที่พร้อมใช้งานจริงและผสานรวมกับเครื่องมือภายนอกผ่าน MCP  
- **การประเมินผลที่ครอบคลุม**: ใช้เมตริกที่มีอยู่และเมตริกที่กำหนดเองเพื่อยืนยันประสิทธิภาพ Edge AI  

ในขณะที่ AI ยังคงมุ่งสู่สถานการณ์การใช้งานที่ขอบ AI Toolkit สำหรับ VS Code มอบสภาพแวดล้อมการพัฒนาและเวิร์กโฟลว์ที่จำเป็นในการสร้าง ทดสอบ และเพิ่มประสิทธิภาพแอปพลิเคชันอัจฉริยะสำหรับสภาพแวดล้อมที่มีข้อจำกัดด้านทรัพยากร ไม่ว่าคุณจะพัฒนาโซลูชัน IoT แอปพลิเคชัน AI บนมือถือ หรือระบบอัจฉริยะฝังตัว เครื่องมือที่ครอบคลุมและเวิร์กโฟลว์แบบบูรณาการของ Toolkit รองรับวงจรการพัฒนา Edge AI ทั้งหมด  

ด้วยการพัฒนาอย่างต่อเนื่องและชุมชนที่มีความเคลื่อนไหว (1.8k+ ดาวบน GitHub) AI Toolkit ยังคงเป็นเครื่องมือที่ล้ำหน้าสำหรับนักพัฒนา AI สมัยใหม่ที่สร้างสำหรับสถานการณ์การใช้งานที่ขอบ  

[Next Foundry Local](./foundrylocal.md)  

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้องมากที่สุด แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์ที่มีความเชี่ยวชาญ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้