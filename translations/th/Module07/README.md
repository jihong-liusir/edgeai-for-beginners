<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "142e0d1a5b794b8333cfd4895804ced5",
  "translation_date": "2025-09-18T08:29:39+00:00",
  "source_file": "Module07/README.md",
  "language_code": "th"
}
-->
# บทที่ 07 : ตัวอย่าง EdgeAI

Edge AI คือการผสมผสานระหว่างปัญญาประดิษฐ์และการประมวลผลที่ปลายทาง (Edge Computing) ซึ่งช่วยให้สามารถประมวลผลข้อมูลอย่างชาญฉลาดได้โดยตรงบนอุปกรณ์ โดยไม่ต้องพึ่งพาการเชื่อมต่อกับคลาวด์ บทนี้จะสำรวจการใช้งาน EdgeAI ห้ารูปแบบที่แตกต่างกันบนแพลตฟอร์มและเฟรมเวิร์กต่าง ๆ เพื่อแสดงให้เห็นถึงความหลากหลายและพลังของการรันโมเดล AI ที่ปลายทาง

## 1. EdgeAI บน NVIDIA Jetson Orin Nano

NVIDIA Jetson Orin Nano เป็นการปฏิวัติการประมวลผล Edge AI ที่เข้าถึงได้ง่าย โดยให้ประสิทธิภาพ AI สูงถึง 67 TOPS ในรูปแบบที่กะทัดรัดขนาดเท่าบัตรเครดิต แพลตฟอร์ม Edge AI ที่ทรงพลังนี้ช่วยให้การพัฒนา Generative AI เป็นเรื่องง่ายสำหรับผู้ที่สนใจ นักเรียน และนักพัฒนามืออาชีพ

### คุณสมบัติเด่น
- ให้ประสิทธิภาพ AI สูงถึง 67 TOPS—เพิ่มขึ้น 1.7 เท่าจากรุ่นก่อนหน้า
- มี 1024 CUDA cores และสูงสุด 32 Tensor Cores สำหรับการประมวลผล AI
- CPU Arm Cortex-A78AE v8.2 แบบ 6-core 64-bit ที่มีความถี่สูงสุด 1.5 GHz
- ราคาเพียง $249 ทำให้เป็นแพลตฟอร์มที่เข้าถึงได้ง่ายที่สุดสำหรับนักพัฒนา นักเรียน และผู้สร้าง

### การใช้งาน
Jetson Orin Nano เหมาะสำหรับการรันโมเดล Generative AI สมัยใหม่ เช่น Vision Transformers, Large Language Models และ Vision-Language Models ออกแบบมาเพื่อรองรับการใช้งาน GenAI และสามารถรัน LLMs หลายตัวบนอุปกรณ์ขนาดเล็กได้ การใช้งานที่นิยม ได้แก่ หุ่นยนต์ที่ขับเคลื่อนด้วย AI โดรนอัจฉริยะ กล้องอัจฉริยะ และอุปกรณ์ปลายทางอัตโนมัติ

**เรียนรู้เพิ่มเติม**: [NVIDIA's Jetson Orin Nano SuperComputer: The Next Big Thing in EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI ในแอปพลิเคชันมือถือด้วย .NET MAUI และ ONNX Runtime GenAI

โซลูชันนี้แสดงให้เห็นถึงวิธีการผสาน Generative AI และ Large Language Models (LLMs) เข้ากับแอปพลิเคชันมือถือข้ามแพลตฟอร์มโดยใช้ .NET MAUI (Multi-platform App UI) และ ONNX Runtime GenAI วิธีนี้ช่วยให้นักพัฒนา .NET สร้างแอปพลิเคชันมือถือที่ขับเคลื่อนด้วย AI ที่ทำงานได้บนอุปกรณ์ Android และ iOS

### คุณสมบัติเด่น
- สร้างบนเฟรมเวิร์ก .NET MAUI ที่ให้โค้ดเบสเดียวสำหรับแอปพลิเคชัน Android และ iOS
- การผสาน ONNX Runtime GenAI ช่วยให้สามารถรันโมเดล Generative AI ได้โดยตรงบนอุปกรณ์มือถือ
- รองรับตัวเร่งฮาร์ดแวร์ต่าง ๆ ที่ปรับแต่งสำหรับอุปกรณ์มือถือ เช่น CPU, GPU และโปรเซสเซอร์ AI เฉพาะทาง
- การปรับแต่งเฉพาะแพลตฟอร์ม เช่น CoreML สำหรับ iOS และ NNAPI สำหรับ Android ผ่าน ONNX Runtime
- ครอบคลุมกระบวนการ Generative AI ทั้งหมด รวมถึงการประมวลผลก่อนและหลัง การอนุมาน การประมวลผล logits การค้นหาและสุ่มตัวอย่าง และการจัดการ KV cache

### ประโยชน์ในการพัฒนา
วิธีการ .NET MAUI ช่วยให้นักพัฒนาสามารถใช้ทักษะ C# และ .NET ที่มีอยู่ในการสร้างแอปพลิเคชัน AI ข้ามแพลตฟอร์ม เฟรมเวิร์ก ONNX Runtime GenAI รองรับสถาปัตยกรรมโมเดลหลายแบบ เช่น Llama, Mistral, Phi, Gemma และอื่น ๆ อีกมากมาย เคอร์เนล ARM64 ที่ปรับแต่งช่วยเร่งการคูณเมทริกซ์ INT4 ที่มีประสิทธิภาพบนฮาร์ดแวร์มือถือ พร้อมกับประสบการณ์การพัฒนา .NET ที่คุ้นเคย

### การใช้งาน
โซลูชันนี้เหมาะสำหรับนักพัฒนาที่ต้องการสร้างแอปพลิเคชันมือถือที่ขับเคลื่อนด้วย AI โดยใช้เทคโนโลยี .NET เช่น แชทบอทอัจฉริยะ แอปพลิเคชันจดจำภาพ เครื่องมือแปลภาษา และระบบแนะนำส่วนบุคคลที่ทำงานบนอุปกรณ์โดยสมบูรณ์เพื่อความเป็นส่วนตัวและความสามารถในการทำงานแบบออฟไลน์

**เรียนรู้เพิ่มเติม**: [.NET MAUI ONNX Runtime GenAI Example](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI บน Azure ด้วย Small Language Models Engine

โซลูชัน EdgeAI บน Azure ของ Microsoft มุ่งเน้นไปที่การปรับใช้ Small Language Models (SLMs) อย่างมีประสิทธิภาพในสภาพแวดล้อมแบบไฮบริดระหว่างคลาวด์และปลายทาง วิธีนี้ช่วยเชื่อมช่องว่างระหว่างบริการ AI ขนาดใหญ่ในคลาวด์และความต้องการการปรับใช้ที่ปลายทาง

### ข้อดีของสถาปัตยกรรม
- การผสานรวมกับบริการ Azure AI อย่างไร้รอยต่อ
- รัน SLMs/LLMs และโมเดลหลายรูปแบบบนอุปกรณ์และในคลาวด์ด้วย ONNX Runtime
- ปรับแต่งสำหรับการปรับใช้ระดับองค์กร
- รองรับการอัปเดตและการจัดการโมเดลอย่างต่อเนื่อง

### การใช้งาน
การใช้งาน EdgeAI บน Azure เหมาะสำหรับสถานการณ์ที่ต้องการการปรับใช้ AI ระดับองค์กรพร้อมความสามารถในการจัดการผ่านคลาวด์ เช่น การประมวลผลเอกสารอัจฉริยะ การวิเคราะห์แบบเรียลไทม์ และเวิร์กโฟลว์ AI แบบไฮบริดที่ใช้ทรัพยากรทั้งคลาวด์และปลายทาง

**เรียนรู้เพิ่มเติม**: [Azure EdgeAI SLM Engine](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## 4. EdgeAI ด้วย Windows ML

Windows ML เป็นรันไทม์ล้ำสมัยของ Microsoft ที่ปรับแต่งสำหรับการอนุมานโมเดลบนอุปกรณ์และการปรับใช้ที่ง่ายดาย โดยเป็นพื้นฐานของ Windows AI Foundry แพลตฟอร์มนี้ช่วยให้นักพัฒนาสร้างแอปพลิเคชัน Windows ที่ขับเคลื่อนด้วย AI โดยใช้ฮาร์ดแวร์ PC อย่างเต็มประสิทธิภาพ

### ความสามารถของแพลตฟอร์ม
- ทำงานบน Windows 11 PCs ทุกรุ่นที่ใช้เวอร์ชัน 24H2 (build 26100) หรือสูงกว่า
- ทำงานบนฮาร์ดแวร์ PC x64 และ ARM64 ทั้งหมด แม้แต่ PCs ที่ไม่มี NPUs หรือ GPUs
- ช่วยให้นักพัฒนานำโมเดลของตนเองมาใช้และปรับใช้ได้อย่างมีประสิทธิภาพในระบบนิเวศของพันธมิตรด้านซิลิคอน เช่น AMD, Intel, NVIDIA และ Qualcomm ครอบคลุม CPU, GPU, NPU
- ด้วย API โครงสร้างพื้นฐาน นักพัฒนาไม่จำเป็นต้องสร้างแอปหลายเวอร์ชันเพื่อรองรับซิลิคอนที่แตกต่างกัน

### ประโยชน์สำหรับนักพัฒนา
Windows ML ช่วยลดความซับซ้อนของฮาร์ดแวร์และผู้ให้บริการการประมวลผล ทำให้นักพัฒนาสามารถมุ่งเน้นไปที่การเขียนโค้ดได้ นอกจากนี้ Windows ML ยังอัปเดตโดยอัตโนมัติเพื่อรองรับ NPUs, GPUs และ CPUs รุ่นล่าสุดเมื่อมีการเปิดตัว แพลตฟอร์มนี้ให้เฟรมเวิร์กที่เป็นหนึ่งเดียวสำหรับการพัฒนา AI บนฮาร์ดแวร์ Windows ที่หลากหลาย

**เรียนรู้เพิ่มเติม**: 
- [Windows ML Overview](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Windows EdgeAI Development Guide](../windowdeveloper.md) - คู่มือฉบับสมบูรณ์สำหรับการพัฒนา Windows Edge AI

## 5. EdgeAI ด้วย Foundry Local Applications

Foundry Local ช่วยให้นักพัฒนาสร้างแอปพลิเคชัน Retrieval Augmented Generation (RAG) โดยใช้ทรัพยากรในเครื่องใน .NET ซึ่งผสมผสานโมเดลภาษาท้องถิ่นเข้ากับความสามารถในการค้นหาเชิงความหมาย วิธีนี้ให้โซลูชัน AI ที่เน้นความเป็นส่วนตัวซึ่งทำงานบนโครงสร้างพื้นฐานในเครื่องทั้งหมด

### สถาปัตยกรรมทางเทคนิค
- ผสมผสานโมเดลภาษา Phi-3, Local Embeddings และ Semantic Kernel เพื่อสร้างสถานการณ์ RAG
- ใช้ embeddings เป็นเวกเตอร์ (อาร์เรย์) ของค่าลอยตัวที่แสดงถึงเนื้อหาและความหมายเชิงความหมาย
- Semantic Kernel ทำหน้าที่เป็นตัวประสานหลัก โดยผสาน Phi-3 และ Smart Components เพื่อสร้าง RAG pipeline ที่ไร้รอยต่อ
- รองรับฐานข้อมูลเวกเตอร์ในเครื่อง เช่น SQLite และ Qdrant

### ประโยชน์ในการใช้งาน
RAG หรือ Retrieval Augmented Generation เป็นวิธีการที่ช่วยให้สามารถ "ค้นหาข้อมูลและนำมาใส่ใน prompt" การใช้งานในเครื่องนี้ช่วยให้มั่นใจในความเป็นส่วนตัวของข้อมูล พร้อมกับการตอบสนองที่ชาญฉลาดซึ่งอ้างอิงจากฐานความรู้ที่ปรับแต่ง วิธีนี้มีคุณค่าอย่างยิ่งสำหรับสถานการณ์ระดับองค์กรที่ต้องการอธิปไตยของข้อมูลและความสามารถในการทำงานแบบออฟไลน์

**เรียนรู้เพิ่มเติม**: [Foundry Local RAG Samples](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

## ทรัพยากรการพัฒนา Windows EdgeAI

สำหรับนักพัฒนาที่มุ่งเน้นไปที่แพลตฟอร์ม Windows เราได้สร้างคู่มือฉบับสมบูรณ์ที่ครอบคลุมระบบนิเวศ Windows EdgeAI ทั้งหมด ทรัพยากรนี้ให้ข้อมูลรายละเอียดเกี่ยวกับ Windows AI Foundry รวมถึง API เครื่องมือ และแนวทางปฏิบัติที่ดีที่สุดสำหรับการพัฒนา EdgeAI บน Windows

### แพลตฟอร์ม Windows AI Foundry
แพลตฟอร์ม Windows AI Foundry ให้ชุดเครื่องมือและ API ที่ครอบคลุมซึ่งออกแบบมาโดยเฉพาะสำหรับการพัฒนา Edge AI บนอุปกรณ์ Windows ซึ่งรวมถึงการรองรับฮาร์ดแวร์ที่เร่งด้วย NPU การผสาน Windows ML และเทคนิคการปรับแต่งเฉพาะแพลตฟอร์ม

**คู่มือฉบับสมบูรณ์**: [Windows EdgeAI Development Guide](../windowdeveloper.md)

คู่มือครอบคลุม:
- ภาพรวมและองค์ประกอบของแพลตฟอร์ม Windows AI Foundry
- Phi Silica API สำหรับการอนุมานที่มีประสิทธิภาพบนฮาร์ดแวร์ NPU
- Computer Vision APIs สำหรับการประมวลผลภาพและ OCR
- การผสานและการปรับแต่ง Windows ML runtime
- Foundry Local CLI สำหรับการพัฒนาและทดสอบในเครื่อง
- กลยุทธ์การปรับแต่งฮาร์ดแวร์สำหรับอุปกรณ์ Windows
- ตัวอย่างการใช้งานจริงและแนวทางปฏิบัติที่ดีที่สุด

### AI Toolkit สำหรับการพัฒนา Edge AI
สำหรับนักพัฒนาที่ใช้ Visual Studio Code ส่วนขยาย AI Toolkit ให้สภาพแวดล้อมการพัฒนาที่ครอบคลุมซึ่งออกแบบมาโดยเฉพาะสำหรับการสร้าง ทดสอบ และปรับใช้แอปพลิเคชัน Edge AI Toolkit นี้ช่วยลดความยุ่งยากในกระบวนการพัฒนา Edge AI ทั้งหมดภายใน VS Code

**คู่มือการพัฒนา**: [AI Toolkit for Edge AI Development](../aitoolkit.md)

คู่มือ AI Toolkit ครอบคลุม:
- การค้นหาและเลือกโมเดลสำหรับการปรับใช้ที่ปลายทาง
- เวิร์กโฟลว์การทดสอบและการปรับแต่งในเครื่อง
- การผสาน ONNX และ Ollama สำหรับโมเดลปลายทาง
- เทคนิคการแปลงและการลดขนาดโมเดล
- การพัฒนา Agent สำหรับสถานการณ์ปลายทาง
- การประเมินผลและการตรวจสอบประสิทธิภาพ
- การเตรียมการปรับใช้และแนวทางปฏิบัติที่ดีที่สุด

## สรุป

การใช้งาน EdgeAI ทั้งห้ารูปแบบนี้แสดงให้เห็นถึงความก้าวหน้าและความหลากหลายของโซลูชัน Edge AI ที่มีอยู่ในปัจจุบัน ตั้งแต่ฮาร์ดแวร์ที่เร่งการประมวลผลปลายทางอย่าง Jetson Orin Nano ไปจนถึงเฟรมเวิร์กซอฟต์แวร์อย่าง ONNX Runtime GenAI และ Windows ML นักพัฒนามีตัวเลือกที่ไม่เคยมีมาก่อนสำหรับการปรับใช้แอปพลิเคชันอัจฉริยะที่ปลายทาง

จุดร่วมของแพลตฟอร์มเหล่านี้คือการทำให้ความสามารถ AI เข้าถึงได้ง่ายขึ้น ทำให้การเรียนรู้ของเครื่องขั้นสูงเป็นเรื่องง่ายสำหรับนักพัฒนาที่มีระดับทักษะและกรณีการใช้งานที่แตกต่างกัน ไม่ว่าจะเป็นการสร้างแอปพลิเคชันมือถือ ซอฟต์แวร์เดสก์ท็อป หรือระบบฝังตัว โซลูชัน EdgeAI เหล่านี้ให้พื้นฐานสำหรับแอปพลิเคชันอัจฉริยะรุ่นต่อไปที่ทำงานได้อย่างมีประสิทธิภาพและเป็นส่วนตัวที่ปลายทาง

แต่ละแพลตฟอร์มมีข้อได้เปรียบเฉพาะตัว: Jetson Orin Nano สำหรับการประมวลผลปลายทางที่เร่งด้วยฮาร์ดแวร์ ONNX Runtime GenAI สำหรับการพัฒนามือถือข้ามแพลตฟอร์ม Azure EdgeAI สำหรับการผสานคลาวด์และปลายทางระดับองค์กร Windows ML สำหรับแอปพลิเคชันที่เน้น Windows และ Foundry Local สำหรับการใช้งาน RAG ที่เน้นความเป็นส่วนตัว ทั้งหมดนี้รวมกันเป็นระบบนิเวศที่ครอบคลุมสำหรับการพัฒนา EdgeAI

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์ที่เป็นมืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้