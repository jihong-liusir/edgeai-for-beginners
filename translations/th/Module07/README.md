<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e9e31a2b5ff0f6a682a258fa859a8ff5",
  "translation_date": "2025-09-26T19:35:23+00:00",
  "source_file": "Module07/README.md",
  "language_code": "th"
}
-->
# บทที่ 07 : ตัวอย่าง EdgeAI

Edge AI คือการผสมผสานระหว่างปัญญาประดิษฐ์และการประมวลผลที่ขอบเครือข่าย ซึ่งช่วยให้สามารถประมวลผลข้อมูลอย่างชาญฉลาดได้โดยตรงบนอุปกรณ์ โดยไม่ต้องพึ่งพาการเชื่อมต่อกับคลาวด์ บทนี้จะสำรวจการใช้งาน EdgeAI ห้ารูปแบบที่แตกต่างกันบนแพลตฟอร์มและเฟรมเวิร์กต่าง ๆ เพื่อแสดงให้เห็นถึงความหลากหลายและพลังของการรันโมเดล AI ที่ขอบเครือข่าย

## 1. EdgeAI บน NVIDIA Jetson Orin Nano

NVIDIA Jetson Orin Nano เป็นการก้าวกระโดดในด้านการประมวลผล Edge AI ที่เข้าถึงได้ โดยให้ประสิทธิภาพ AI สูงถึง 67 TOPS ในรูปแบบที่เล็กเท่าบัตรเครดิต แพลตฟอร์ม Edge AI ที่ทรงพลังนี้ช่วยให้การพัฒนา Generative AI เป็นเรื่องง่ายสำหรับผู้ที่สนใจ นักเรียน และนักพัฒนามืออาชีพ

### คุณสมบัติเด่น
- ให้ประสิทธิภาพ AI สูงถึง 67 TOPS ซึ่งเพิ่มขึ้น 1.7 เท่าจากรุ่นก่อนหน้า
- มี 1024 CUDA cores และสูงสุด 32 Tensor Cores สำหรับการประมวลผล AI
- CPU Arm Cortex-A78AE v8.2 แบบ 64 บิต 6 คอร์ ที่มีความถี่สูงสุด 1.5 GHz
- ราคาเพียง $249 ทำให้เป็นแพลตฟอร์มที่เข้าถึงได้ง่ายที่สุดสำหรับนักพัฒนา นักเรียน และผู้สร้าง

### การใช้งาน
Jetson Orin Nano เหมาะสำหรับการรันโมเดล Generative AI สมัยใหม่ เช่น Vision Transformers, Large Language Models และ Vision-Language Models ออกแบบมาเพื่อรองรับการใช้งาน GenAI และสามารถรัน LLMs หลายตัวบนอุปกรณ์ขนาดเล็กได้ การใช้งานที่นิยม ได้แก่ หุ่นยนต์ที่ขับเคลื่อนด้วย AI โดรนอัจฉริยะ กล้องอัจฉริยะ และอุปกรณ์ Edge อัตโนมัติ

**เรียนรู้เพิ่มเติม**: [NVIDIA's Jetson Orin Nano SuperComputer: The Next Big Thing in EdgeAI](https://medium.com/data-science-in-your-pocket/nvidias-jetson-orin-nano-supercomputer-the-next-big-thing-in-edgeai-e9eff687ae62)

## 2. EdgeAI ในแอปพลิเคชันมือถือด้วย .NET MAUI และ ONNX Runtime GenAI

โซลูชันนี้แสดงให้เห็นถึงวิธีการผสาน Generative AI และ Large Language Models (LLMs) เข้ากับแอปพลิเคชันมือถือข้ามแพลตฟอร์มโดยใช้ .NET MAUI (Multi-platform App UI) และ ONNX Runtime GenAI วิธีนี้ช่วยให้นักพัฒนา .NET สร้างแอปพลิเคชันมือถือที่ขับเคลื่อนด้วย AI ซึ่งทำงานได้โดยตรงบนอุปกรณ์ Android และ iOS

### คุณสมบัติเด่น
- สร้างบนเฟรมเวิร์ก .NET MAUI ที่ให้โค้ดเบสเดียวสำหรับแอปพลิเคชัน Android และ iOS
- การผสาน ONNX Runtime GenAI ช่วยให้สามารถรันโมเดล Generative AI ได้โดยตรงบนอุปกรณ์มือถือ
- รองรับตัวเร่งฮาร์ดแวร์ต่าง ๆ ที่ปรับแต่งสำหรับอุปกรณ์มือถือ เช่น CPU, GPU และโปรเซสเซอร์ AI เฉพาะทาง
- การปรับแต่งเฉพาะแพลตฟอร์ม เช่น CoreML สำหรับ iOS และ NNAPI สำหรับ Android ผ่าน ONNX Runtime
- ครอบคลุมวงจร Generative AI ทั้งหมด รวมถึงการประมวลผลก่อนและหลัง การอนุมาน การประมวลผล logits การค้นหาและสุ่มตัวอย่าง และการจัดการ KV cache

### ประโยชน์สำหรับนักพัฒนา
วิธีการ .NET MAUI ช่วยให้นักพัฒนาสามารถใช้ทักษะ C# และ .NET ที่มีอยู่ในการสร้างแอปพลิเคชัน AI ข้ามแพลตฟอร์ม เฟรมเวิร์ก ONNX Runtime GenAI รองรับสถาปัตยกรรมโมเดลหลายแบบ เช่น Llama, Mistral, Phi, Gemma และอื่น ๆ อีกมากมาย เคอร์เนล ARM64 ที่ปรับแต่งช่วยเร่งการคูณเมทริกซ์ INT4 แบบควอนไทซ์ ทำให้มั่นใจได้ถึงประสิทธิภาพที่มีประสิทธิภาพบนฮาร์ดแวร์มือถือ พร้อมกับประสบการณ์การพัฒนาที่คุ้นเคยใน .NET

### การใช้งาน
โซลูชันนี้เหมาะสำหรับนักพัฒนาที่ต้องการสร้างแอปพลิเคชันมือถือที่ขับเคลื่อนด้วย AI โดยใช้เทคโนโลยี .NET เช่น แชทบอทอัจฉริยะ แอปจดจำภาพ เครื่องมือแปลภาษา และระบบแนะนำส่วนบุคคลที่ทำงานบนอุปกรณ์โดยสมบูรณ์เพื่อความเป็นส่วนตัวและความสามารถในการทำงานแบบออฟไลน์

**เรียนรู้เพิ่มเติม**: [.NET MAUI ONNX Runtime GenAI Example](https://github.com/microsoft/onnxruntime-genai/tree/jialli/genny-maui/examples/csharp/GennyMaui)

## 3. EdgeAI บน Azure ด้วย Small Language Models Engine

โซลูชัน EdgeAI บน Azure ของ Microsoft มุ่งเน้นไปที่การปรับใช้ Small Language Models (SLMs) อย่างมีประสิทธิภาพในสภาพแวดล้อมแบบไฮบริดระหว่างคลาวด์และขอบเครือข่าย วิธีนี้ช่วยเชื่อมช่องว่างระหว่างบริการ AI ขนาดใหญ่ในคลาวด์และความต้องการการปรับใช้ที่ขอบเครือข่าย

### ข้อดีของสถาปัตยกรรม
- การผสานรวมกับบริการ Azure AI อย่างไร้รอยต่อ
- รัน SLMs/LLMs และโมเดลมัลติโหมดบนอุปกรณ์และในคลาวด์ด้วย ONNX Runtime
- ปรับแต่งสำหรับการปรับใช้ในระดับองค์กร
- รองรับการอัปเดตและการจัดการโมเดลอย่างต่อเนื่อง

### การใช้งาน
การใช้งาน EdgeAI บน Azure เหมาะสำหรับสถานการณ์ที่ต้องการการปรับใช้ AI ในระดับองค์กรพร้อมความสามารถในการจัดการผ่านคลาวด์ เช่น การประมวลผลเอกสารอัจฉริยะ การวิเคราะห์แบบเรียลไทม์ และเวิร์กโฟลว์ AI แบบไฮบริดที่ใช้ทรัพยากรทั้งในคลาวด์และขอบเครือข่าย

**เรียนรู้เพิ่มเติม**: [Azure EdgeAI SLM Engine](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/slm_engine)

## [4. EdgeAI ด้วย Windows ML](./windowdeveloper.md)

Windows ML เป็นรันไทม์ที่ล้ำหน้าของ Microsoft ซึ่งได้รับการปรับแต่งสำหรับการอนุมานโมเดลบนอุปกรณ์ที่มีประสิทธิภาพและการปรับใช้ที่ง่ายดาย โดยเป็นรากฐานของ Windows AI Foundry แพลตฟอร์มนี้ช่วยให้นักพัฒนาสร้างแอปพลิเคชัน Windows ที่ขับเคลื่อนด้วย AI ซึ่งใช้ประโยชน์จากฮาร์ดแวร์ PC ได้อย่างเต็มที่

### ความสามารถของแพลตฟอร์ม
- ใช้งานได้บน Windows 11 PCs ทุกรุ่นที่รันเวอร์ชัน 24H2 (build 26100) หรือสูงกว่า
- ใช้งานได้บนฮาร์ดแวร์ PC x64 และ ARM64 ทั้งหมด แม้แต่ PCs ที่ไม่มี NPUs หรือ GPUs
- ช่วยให้นักพัฒนานำโมเดลของตนเองมาใช้และปรับใช้ได้อย่างมีประสิทธิภาพในระบบนิเวศของพันธมิตรด้านซิลิคอน เช่น AMD, Intel, NVIDIA และ Qualcomm ครอบคลุม CPU, GPU, NPU
- ด้วย API โครงสร้างพื้นฐาน นักพัฒนาไม่จำเป็นต้องสร้างหลายบิลด์ของแอปเพื่อกำหนดเป้าหมายซิลิคอนที่แตกต่างกัน

### ประโยชน์สำหรับนักพัฒนา
Windows ML ช่วยลดความซับซ้อนของฮาร์ดแวร์และผู้ให้บริการการประมวลผล ทำให้นักพัฒนาสามารถมุ่งเน้นไปที่การเขียนโค้ดได้ นอกจากนี้ Windows ML ยังอัปเดตโดยอัตโนมัติเพื่อรองรับ NPUs, GPUs และ CPUs รุ่นล่าสุดเมื่อมีการเปิดตัว แพลตฟอร์มนี้ให้เฟรมเวิร์กที่เป็นหนึ่งเดียวสำหรับการพัฒนา AI ในระบบนิเวศฮาร์ดแวร์ Windows ที่หลากหลาย

**เรียนรู้เพิ่มเติม**: 
- [Windows ML Overview](https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview)
- [Windows EdgeAI Development Guide](./windowdeveloper.md) - คู่มือฉบับสมบูรณ์สำหรับการพัฒนา Windows Edge AI

## [5. EdgeAI ด้วย Foundry Local Applications](./foundrylocal.md)

Foundry Local ช่วยให้นักพัฒนาบน Windows และ Mac สร้างแอปพลิเคชัน Retrieval Augmented Generation (RAG) โดยใช้ทรัพยากรในเครื่องใน .NET ซึ่งผสมผสานโมเดลภาษาท้องถิ่นเข้ากับความสามารถในการค้นหาเชิงความหมาย วิธีนี้ให้โซลูชัน AI ที่เน้นความเป็นส่วนตัวซึ่งทำงานบนโครงสร้างพื้นฐานในเครื่องทั้งหมด

### สถาปัตยกรรมทางเทคนิค
- ผสมผสานโมเดลภาษา Phi, Local Embeddings และ Semantic Kernel เพื่อสร้างสถานการณ์ RAG
- ใช้ embeddings เป็นเวกเตอร์ (อาร์เรย์) ของค่าจุดลอยตัวที่แสดงถึงเนื้อหาและความหมายเชิงความหมาย
- Semantic Kernel ทำหน้าที่เป็นตัวประสานหลัก โดยผสาน Phi และ Smart Components เพื่อสร้าง RAG pipeline ที่ไร้รอยต่อ
- รองรับฐานข้อมูลเวกเตอร์ในเครื่อง เช่น SQLite และ Qdrant

### ประโยชน์ของการใช้งาน
RAG หรือ Retrieval Augmented Generation เป็นวิธีการที่ช่วยให้สามารถค้นหาข้อมูลและนำมาใช้ใน prompt ได้ การใช้งานในเครื่องนี้ช่วยให้มั่นใจในความเป็นส่วนตัวของข้อมูล พร้อมกับการตอบสนองที่ชาญฉลาดซึ่งอ้างอิงจากฐานความรู้ที่กำหนดเอง วิธีนี้มีคุณค่าอย่างยิ่งสำหรับสถานการณ์ในองค์กรที่ต้องการอธิปไตยของข้อมูลและความสามารถในการทำงานแบบออฟไลน์

**เรียนรู้เพิ่มเติม**: 
- [Foundry Local](./foundrylocal.md)
- [Foundry Local RAG Samples](https://github.com/microsoft/Foundry-Local/tree/main/samples/dotNET/rag)

### Windows Foundry Local

Microsoft Foundry Local ให้บริการ REST server ที่เข้ากันได้กับ OpenAI ซึ่งขับเคลื่อนโดย ONNX Runtime สำหรับการรันโมเดลในเครื่องบน Windows ด้านล่างนี้คือสรุปข้อมูลที่ผ่านการตรวจสอบแล้ว ดูเอกสารอย่างเป็นทางการสำหรับรายละเอียดเพิ่มเติม

- เริ่มต้น: https://learn.microsoft.com/azure/ai-foundry/foundry-local/get-started
- สถาปัตยกรรม: https://learn.microsoft.com/azure/ai-foundry/foundry-local/concepts/foundry-local-architecture
- CLI reference: https://learn.microsoft.com/azure/ai-foundry/foundry-local/reference/reference-cli
- คู่มือ Windows ฉบับเต็มใน repo นี้: [foundrylocal.md](./foundrylocal.md)

ติดตั้งหรืออัปเกรดบน Windows (cmd.exe):
```cmd
winget install Microsoft.FoundryLocal
winget upgrade --id Microsoft.FoundryLocal
foundry --version
```

สำรวจหมวดหมู่ CLI:
```cmd
foundry model --help
foundry service --help
foundry cache --help
```

รันโมเดลและค้นพบ endpoint แบบไดนามิก:
```cmd
foundry model run gpt-oss-20b
foundry service status
```

ตรวจสอบ REST อย่างรวดเร็วเพื่อแสดงรายการโมเดล (แทนที่ PORT จากสถานะ):
```cmd
curl -s http://localhost:PORT/v1/models
```

เคล็ดลับ:
- การผสาน SDK: https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- นำโมเดลของคุณเองมาใช้ (compile): https://learn.microsoft.com/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## ทรัพยากรการพัฒนา Windows EdgeAI

สำหรับนักพัฒนาที่มุ่งเน้นไปที่แพลตฟอร์ม Windows เราได้สร้างคู่มือฉบับสมบูรณ์ที่ครอบคลุมระบบนิเวศ Windows EdgeAI ทั้งหมด ทรัพยากรนี้ให้ข้อมูลรายละเอียดเกี่ยวกับ Windows AI Foundry รวมถึง API เครื่องมือ และแนวทางปฏิบัติที่ดีที่สุดสำหรับการพัฒนา EdgeAI บน Windows

### แพลตฟอร์ม Windows AI Foundry
แพลตฟอร์ม Windows AI Foundry ให้ชุดเครื่องมือและ API ที่ครอบคลุมซึ่งออกแบบมาโดยเฉพาะสำหรับการพัฒนา Edge AI บนอุปกรณ์ Windows ซึ่งรวมถึงการสนับสนุนฮาร์ดแวร์ที่เร่งด้วย NPU การผสาน Windows ML และเทคนิคการปรับแต่งเฉพาะแพลตฟอร์ม

**คู่มือฉบับสมบูรณ์**: [Windows EdgeAI Development Guide](../windowdeveloper.md)

คู่มือนี้ครอบคลุม:
- ภาพรวมและองค์ประกอบของแพลตฟอร์ม Windows AI Foundry
- Phi Silica API สำหรับการอนุมานที่มีประสิทธิภาพบนฮาร์ดแวร์ NPU
- Computer Vision APIs สำหรับการประมวลผลภาพและ OCR
- การผสานและการปรับแต่งรันไทม์ Windows ML
- Foundry Local CLI สำหรับการพัฒนาและทดสอบในเครื่อง
- กลยุทธ์การปรับแต่งฮาร์ดแวร์สำหรับอุปกรณ์ Windows
- ตัวอย่างการใช้งานจริงและแนวทางปฏิบัติที่ดีที่สุด

### [AI Toolkit สำหรับการพัฒนา Edge AI](./aitoolkit.md)
สำหรับนักพัฒนาที่ใช้ Visual Studio Code ส่วนขยาย AI Toolkit ให้สภาพแวดล้อมการพัฒนาที่ครอบคลุมซึ่งออกแบบมาโดยเฉพาะสำหรับการสร้าง ทดสอบ และปรับใช้แอปพลิเคชัน Edge AI Toolkit นี้ช่วยปรับปรุงกระบวนการพัฒนา Edge AI ทั้งหมดภายใน VS Code

**คู่มือการพัฒนา**: [AI Toolkit สำหรับการพัฒนา Edge AI](./aitoolkit.md)

คู่มือ AI Toolkit ครอบคลุม:
- การค้นหาและเลือกโมเดลสำหรับการปรับใช้ที่ขอบเครือข่าย
- เวิร์กโฟลว์การทดสอบและการปรับแต่งในเครื่อง
- การผสาน ONNX และ Ollama สำหรับโมเดล Edge
- เทคนิคการแปลงและควอนไทซ์โมเดล
- การพัฒนา Agent สำหรับสถานการณ์ Edge
- การประเมินผลและการตรวจสอบประสิทธิภาพ
- การเตรียมการปรับใช้และแนวทางปฏิบัติที่ดีที่สุด

## สรุป

การใช้งาน EdgeAI ทั้งห้ารูปแบบนี้แสดงให้เห็นถึงความก้าวหน้าและความหลากหลายของโซลูชัน Edge AI ที่มีอยู่ในปัจจุบัน ตั้งแต่ฮาร์ดแวร์ที่เร่งด้วย Edge เช่น Jetson Orin Nano ไปจนถึงเฟรมเวิร์กซอฟต์แวร์อย่าง ONNX Runtime GenAI และ Windows ML นักพัฒนามีตัวเลือกที่ไม่เคยมีมาก่อนสำหรับการปรับใช้แอปพลิเคชันอัจฉริยะที่ขอบเครือข่าย

จุดร่วมของแพลตฟอร์มเหล่านี้คือการทำให้ความสามารถ AI เข้าถึงได้ง่ายขึ้น ทำให้การเรียนรู้ของเครื่องขั้นสูงเป็นเรื่องง่ายสำหรับนักพัฒนาที่มีระดับทักษะและกรณีการใช้งานที่แตกต่างกัน ไม่ว่าจะเป็นการสร้างแอปพลิเคชันมือถือ ซอฟต์แวร์เดสก์ท็อป หรือระบบฝังตัว โซลูชัน EdgeAI เหล่านี้ให้รากฐานสำหรับแอปพลิเคชันอัจฉริยะรุ่นต่อไปที่ทำงานได้อย่างมีประสิทธิภาพและเป็นส่วนตัวที่ขอบเครือข่าย

แต่ละแพลตฟอร์มมีข้อได้เปรียบเฉพาะตัว: Jetson Orin Nano สำหรับการประมวลผล Edge ที่เร่งด้วยฮาร์ดแวร์, ONNX Runtime GenAI สำหรับการพัฒนามือถือข้ามแพลตฟอร์ม, Azure EdgeAI สำหรับการผสานคลาวด์และขอบเครือข่ายในระดับองค์กร, Windows ML สำหรับแอปพลิเคชันที่เน้น Windows และ Foundry Local สำหรับการใช้งาน RAG ที่เน้นความเป็นส่วนตัว ทั้งหมดนี้รวมกันเป็นระบบนิเวศที่ครอบคลุมสำหรับการพัฒนา EdgeAI

---

