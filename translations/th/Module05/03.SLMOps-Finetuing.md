<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6485323e2963241723d26eb0e0e9a492",
  "translation_date": "2025-09-18T08:13:57+00:00",
  "source_file": "Module05/03.SLMOps-Finetuing.md",
  "language_code": "th"
}
-->
# ส่วนที่ 3: การปรับแต่ง - การปรับแต่งโมเดลสำหรับงานเฉพาะ

## สารบัญ
1. [แนะนำการปรับแต่ง](../../../Module05)
2. [เหตุผลที่การปรับแต่งสำคัญ](../../../Module05)
3. [ประเภทของการปรับแต่ง](../../../Module05)
4. [การปรับแต่งด้วย Microsoft Olive](../../../Module05)
5. [ตัวอย่างการใช้งานจริง](../../../Module05)
6. [แนวทางปฏิบัติที่ดีที่สุดและคำแนะนำ](../../../Module05)
7. [เทคนิคขั้นสูง](../../../Module05)
8. [การประเมินผลและการติดตาม](../../../Module05)
9. [ความท้าทายทั่วไปและวิธีแก้ไข](../../../Module05)
10. [บทสรุป](../../../Module05)

## แนะนำการปรับแต่ง

**การปรับแต่ง** เป็นเทคนิคการเรียนรู้ของเครื่องที่ทรงพลัง ซึ่งเกี่ยวข้องกับการปรับโมเดลที่ผ่านการฝึกมาแล้วให้เหมาะสมกับงานเฉพาะหรือชุดข้อมูลเฉพาะ โดยไม่ต้องเริ่มฝึกโมเดลใหม่ตั้งแต่ต้น การปรับแต่งใช้ประโยชน์จากความรู้ที่โมเดลได้เรียนรู้มาแล้ว และปรับให้เข้ากับกรณีการใช้งานของคุณ

### การปรับแต่งคืออะไร?

การปรับแต่งเป็นรูปแบบหนึ่งของ **การเรียนรู้แบบถ่ายโอน** ซึ่งคุณจะ:
- เริ่มต้นด้วยโมเดลที่ผ่านการฝึกมาแล้วซึ่งได้เรียนรู้รูปแบบทั่วไปจากชุดข้อมูลขนาดใหญ่
- ปรับพารามิเตอร์ภายในของโมเดลโดยใช้ชุดข้อมูลเฉพาะของคุณ
- รักษาความรู้ที่มีค่าไว้ในขณะที่ปรับโมเดลให้เหมาะสมกับงานของคุณ

เปรียบเสมือนการสอนเชฟที่มีความชำนาญให้ทำอาหารในสไตล์ใหม่ พวกเขาเข้าใจพื้นฐานการทำอาหารอยู่แล้ว แต่ต้องเรียนรู้เทคนิคและรสชาติที่เฉพาะเจาะจงสำหรับสไตล์ใหม่นั้น

### ประโยชน์สำคัญ

- **ประหยัดเวลา**: เร็วกว่าการฝึกโมเดลใหม่ตั้งแต่ต้นอย่างมาก
- **ประหยัดข้อมูล**: ใช้ชุดข้อมูลขนาดเล็กเพื่อให้ได้ผลลัพธ์ที่ดี
- **ประหยัดค่าใช้จ่าย**: ลดความต้องการด้านการประมวลผล
- **ประสิทธิภาพที่ดีขึ้น**: มักให้ผลลัพธ์ที่ดีกว่าการฝึกใหม่ตั้งแต่ต้น
- **การใช้ทรัพยากรอย่างเหมาะสม**: ทำให้ AI ที่ทรงพลังเข้าถึงได้สำหรับทีมและองค์กรขนาดเล็ก

## เหตุผลที่การปรับแต่งสำคัญ

### การใช้งานในโลกจริง

การปรับแต่งมีความสำคัญในหลายสถานการณ์:

**1. การปรับให้เข้ากับโดเมน**
- AI ด้านการแพทย์: ปรับโมเดลภาษาทั่วไปให้เหมาะกับคำศัพท์ทางการแพทย์และบันทึกทางคลินิก
- เทคโนโลยีกฎหมาย: ปรับโมเดลให้เหมาะกับการวิเคราะห์เอกสารทางกฎหมายและการตรวจสอบสัญญา
- บริการทางการเงิน: ปรับแต่งโมเดลสำหรับการวิเคราะห์รายงานทางการเงินและการประเมินความเสี่ยง

**2. ความเชี่ยวชาญในงาน**
- การสร้างเนื้อหา: ปรับแต่งให้เหมาะกับสไตล์การเขียนหรือโทนเสียงเฉพาะ
- การสร้างโค้ด: ปรับโมเดลให้เหมาะกับภาษาโปรแกรมหรือเฟรมเวิร์กเฉพาะ
- การแปลภาษา: ปรับปรุงประสิทธิภาพสำหรับคู่ภาษาหรือโดเมนทางเทคนิคเฉพาะ

**3. การใช้งานในองค์กร**
- การบริการลูกค้า: สร้างแชทบอทที่เข้าใจคำศัพท์เฉพาะของบริษัท
- เอกสารภายใน: สร้างผู้ช่วย AI ที่คุ้นเคยกับกระบวนการขององค์กร
- โซลูชันเฉพาะอุตสาหกรรม: พัฒนาโมเดลที่เข้าใจคำศัพท์และเวิร์กโฟลว์เฉพาะของอุตสาหกรรม

## ประเภทของการปรับแต่ง

### 1. การปรับแต่งเต็มรูปแบบ (Instruction Fine-Tuning)

ในการปรับแต่งเต็มรูปแบบ พารามิเตอร์ทั้งหมดของโมเดลจะถูกปรับระหว่างการฝึก วิธีนี้:
- ให้ความยืดหยุ่นและศักยภาพด้านประสิทธิภาพสูงสุด
- ต้องการทรัพยากรการประมวลผลจำนวนมาก
- ส่งผลให้เกิดเวอร์ชันใหม่ของโมเดลโดยสมบูรณ์
- เหมาะสำหรับสถานการณ์ที่มีข้อมูลการฝึกและทรัพยากรการประมวลผลจำนวนมาก

### 2. การปรับแต่งพารามิเตอร์อย่างมีประสิทธิภาพ (PEFT)

วิธี PEFT จะปรับเฉพาะพารามิเตอร์บางส่วน ทำให้กระบวนการมีประสิทธิภาพมากขึ้น:

#### Low-Rank Adaptation (LoRA)
- เพิ่มเมทริกซ์การแยกอันดับที่สามารถฝึกได้ขนาดเล็กลงในน้ำหนักที่มีอยู่
- ลดจำนวนพารามิเตอร์ที่สามารถฝึกได้อย่างมาก
- รักษาประสิทธิภาพใกล้เคียงกับการปรับแต่งเต็มรูปแบบ
- ช่วยให้สามารถสลับระหว่างการปรับแต่งต่าง ๆ ได้ง่าย

#### QLoRA (Quantized LoRA)
- รวม LoRA กับเทคนิคการควอนไทซ์
- ลดความต้องการหน่วยความจำลงอีก
- ช่วยให้สามารถปรับแต่งโมเดลขนาดใหญ่บนฮาร์ดแวร์สำหรับผู้บริโภค
- สมดุลระหว่างประสิทธิภาพและประสิทธิผล

#### Adapters
- แทรกเครือข่ายประสาทขนาดเล็กระหว่างเลเยอร์ที่มีอยู่
- อนุญาตให้ปรับแต่งเฉพาะจุดในขณะที่รักษาโมเดลพื้นฐานไว้
- ช่วยให้สามารถปรับแต่งโมเดลแบบแยกส่วนได้

### 3. การปรับแต่งเฉพาะงาน

มุ่งเน้นไปที่การปรับโมเดลสำหรับงานปลายทางเฉพาะ:
- **การจัดประเภท**: ปรับโมเดลสำหรับงานการจัดหมวดหมู่
- **การสร้างเนื้อหา**: ปรับแต่งสำหรับการสร้างเนื้อหาและข้อความ
- **การดึงข้อมูล**: ปรับแต่งสำหรับการดึงข้อมูลและการจดจำชื่อหน่วยงาน
- **การสรุปข้อมูล**: ปรับแต่งโมเดลสำหรับการสรุปเอกสาร

## การปรับแต่งด้วย Microsoft Olive

Microsoft Olive เป็นชุดเครื่องมือการปรับแต่งโมเดลที่ครอบคลุม ซึ่งช่วยให้กระบวนการปรับแต่งง่ายขึ้นและมีคุณสมบัติระดับองค์กร

### Microsoft Olive คืออะไร?

Microsoft Olive เป็นเครื่องมือโอเพ่นซอร์สสำหรับการปรับแต่งโมเดลที่:
- ทำให้เวิร์กโฟลว์การปรับแต่งง่ายขึ้นสำหรับฮาร์ดแวร์เป้าหมายต่าง ๆ
- มีการสนับสนุนในตัวสำหรับสถาปัตยกรรมโมเดลยอดนิยม (Llama, Phi, Qwen, Gemma)
- มีตัวเลือกการปรับใช้ทั้งแบบคลาวด์และแบบโลคอล
- ผสานรวมกับ Azure ML และบริการ AI อื่น ๆ ของ Microsoft ได้อย่างราบรื่น
- สนับสนุนการปรับแต่งและการควอนไทซ์อัตโนมัติ

### คุณสมบัติสำคัญ

- **การปรับแต่งตามฮาร์ดแวร์**: ปรับแต่งโมเดลโดยอัตโนมัติสำหรับฮาร์ดแวร์เฉพาะ (CPU, GPU, NPU)
- **การสนับสนุนหลายรูปแบบ**: ใช้งานได้กับโมเดล PyTorch, Hugging Face และ ONNX
- **เวิร์กโฟลว์อัตโนมัติ**: ลดการตั้งค่าด้วยตนเองและการลองผิดลองถูก
- **การผสานรวมระดับองค์กร**: มีการสนับสนุนในตัวสำหรับ Azure ML และการปรับใช้บนคลาวด์
- **สถาปัตยกรรมที่ขยายได้**: อนุญาตให้ใช้เทคนิคการปรับแต่งแบบกำหนดเอง

### การติดตั้งและการตั้งค่า

#### การติดตั้งพื้นฐาน

```bash
# Create a virtual environment
python -m venv olive-env
source olive-env/bin/activate  # On Windows: olive-env\Scripts\activate

# Install Olive with auto-optimization features
pip install olive-ai[auto-opt]

# Install additional dependencies
pip install transformers onnxruntime-genai
```

#### การติดตั้งส่วนเสริม

```bash
# For CPU optimization
pip install olive-ai[cpu]

# For GPU optimization
pip install olive-ai[gpu]

# For DirectML (Windows)
pip install olive-ai[directml]

# For Azure ML integration
pip install olive-ai[azureml]
```

#### ตรวจสอบการติดตั้ง

```bash
# Check Olive CLI is available
olive --help

# Verify installation
python -c "import olive; print('Olive installed successfully')"
```

## ตัวอย่างการใช้งานจริง

### ตัวอย่างที่ 1: การปรับแต่งพื้นฐานด้วย Olive CLI

ตัวอย่างนี้แสดงการปรับแต่งโมเดลภาษาขนาดเล็กสำหรับการจัดประเภทวลี:

#### ขั้นตอนที่ 1: เตรียมสภาพแวดล้อมของคุณ

```bash
# Set up the environment
mkdir fine-tuning-project
cd fine-tuning-project

# Download sample data (optional - Olive can fetch data automatically)
huggingface-cli login  # If using private datasets
```

#### ขั้นตอนที่ 2: ปรับแต่งโมเดล

```bash
# Basic fine-tuning command
olive finetune \
  --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \
  --trust_remote_code \
  --output_path models/llama/ft \
  --data_name xxyyzzz/phrase_classification \
  --text_template "<|start_header_id|>user<|end_header_id|>\n{phrase}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{tone}" \
  --method lora \
  --max_steps 100 \
  --log_level 1
```

#### ขั้นตอนที่ 3: ปรับแต่งเพื่อการปรับใช้

```bash
# Convert to ONNX format for optimized inference
olive auto-opt \
  --model_name_or_path models/llama/ft/model \
  --adapter_path models/llama/ft/adapter \
  --device cpu \
  --provider CPUExecutionProvider \
  --use_ort_genai \
  --output_path models/llama/onnx \
  --log_level 1
```

### ตัวอย่างที่ 2: การตั้งค่าขั้นสูงด้วยชุดข้อมูลแบบกำหนดเอง

#### ขั้นตอนที่ 1: เตรียมชุดข้อมูลแบบกำหนดเอง

สร้างไฟล์ JSON ที่มีข้อมูลการฝึกของคุณ:

```json
[
  {
    "input": "What is machine learning?",
    "output": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."
  },
  {
    "input": "Explain neural networks",
    "output": "Neural networks are computing systems inspired by biological neural networks that learn from data through interconnected nodes or neurons."
  }
]
```

#### ขั้นตอนที่ 2: สร้างไฟล์การตั้งค่า

```yaml
# olive-config.yaml
model:
  type: PyTorchModel
  config:
    model_path: "microsoft/DialoGPT-medium"
    task: "text-generation"

data_configs:
  - name: "custom_dataset"
    type: "HuggingfaceContainer"
    load_dataset_config:
      data_files: "path/to/your/dataset.json"
      split: "train"
    pre_process_data_config:
      text_template: "User: {input}\nAssistant: {output}"

passes:
  lora:
    type: LoRA
    config:
      r: 16
      lora_alpha: 32
      target_modules: ["c_attn", "c_proj"]
      modules_to_save: ["ln_f", "lm_head"]
```

#### ขั้นตอนที่ 3: ดำเนินการปรับแต่ง

```bash
# Run with custom configuration
olive run --config olive-config.yaml --setup
```

### ตัวอย่างที่ 3: การปรับแต่ง QLoRA เพื่อประหยัดหน่วยความจำ

```bash
# Fine-tune with QLoRA for better memory efficiency
olive finetune \
  --method qlora \
  --model_name_or_path meta-llama/Meta-Llama-3-8B \
  --data_name nampdn-ai/tiny-codes \
  --train_split "train[:4096]" \
  --eval_split "train[4096:4224]" \
  --text_template "### Language: {programming_language} \n### Question: {prompt} \n### Answer: {response}" \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --max_steps 150 \
  --logging_steps 50 \
  --output_path adapters/tiny-codes
```

## แนวทางปฏิบัติที่ดีที่สุดและคำแนะนำ

### การเตรียมข้อมูล

**1. คุณภาพข้อมูลสำคัญกว่าปริมาณ**
- ให้ความสำคัญกับตัวอย่างที่มีคุณภาพสูงและหลากหลายมากกว่าปริมาณข้อมูลที่มากแต่คุณภาพต่ำ
- ตรวจสอบให้แน่ใจว่าข้อมูลเป็นตัวแทนของกรณีการใช้งานเป้าหมายของคุณ
- ทำความสะอาดและเตรียมข้อมูลอย่างสม่ำเสมอ

**2. รูปแบบข้อมูลและเทมเพลต**
- ใช้รูปแบบที่สม่ำเสมอในตัวอย่างการฝึกทั้งหมด
- สร้างเทมเพลตอินพุต-เอาต์พุตที่ชัดเจนซึ่งตรงกับกรณีการใช้งานของคุณ
- รวมรูปแบบคำสั่งที่เหมาะสมสำหรับโมเดลที่ปรับแต่งคำสั่ง

**3. การแบ่งชุดข้อมูล**
- สำรองข้อมูล 10-20% สำหรับการตรวจสอบ
- รักษาการกระจายที่คล้ายกันระหว่างชุดข้อมูลการฝึกและการตรวจสอบ
- พิจารณาการสุ่มตัวอย่างแบบแบ่งชั้นสำหรับงานการจัดประเภท

### การตั้งค่าการฝึก

**1. การเลือกอัตราการเรียนรู้**
- เริ่มต้นด้วยอัตราการเรียนรู้ที่เล็กกว่า (1e-5 ถึง 1e-4) สำหรับการปรับแต่ง
- ใช้การตั้งค่าอัตราการเรียนรู้เพื่อการบรรจบที่ดีขึ้น
- ติดตามกราฟการสูญเสียเพื่อปรับอัตราให้เหมาะสม

**2. การปรับขนาดแบตช์**
- ปรับขนาดแบตช์ให้เหมาะสมกับหน่วยความจำที่มีอยู่
- ใช้การสะสมเกรเดียนต์เพื่อเพิ่มขนาดแบตช์ที่มีประสิทธิภาพ
- พิจารณาความสัมพันธ์ระหว่างขนาดแบตช์และอัตราการเรียนรู้

**3. ระยะเวลาการฝึก**
- ติดตามเมตริกการตรวจสอบเพื่อหลีกเลี่ยงการฝึกมากเกินไป
- ใช้การหยุดก่อนเมื่อประสิทธิภาพการตรวจสอบคงที่
- บันทึกจุดตรวจเป็นประจำเพื่อการกู้คืนและการวิเคราะห์

### การเลือกโมเดล

**1. การเลือกโมเดลพื้นฐาน**
- เลือกโมเดลที่ผ่านการฝึกในโดเมนที่คล้ายกันเมื่อเป็นไปได้
- พิจารณาขนาดโมเดลตามข้อจำกัดด้านการประมวลผลของคุณ
- ประเมินข้อกำหนดด้านลิขสิทธิ์สำหรับการใช้งานเชิงพาณิชย์

**2. การเลือกวิธีการปรับแต่ง**
- ใช้ LoRA/QLoRA สำหรับสภาพแวดล้อมที่มีทรัพยากรจำกัด
- เลือกการปรับแต่งเต็มรูปแบบเมื่อประสิทธิภาพสูงสุดเป็นสิ่งสำคัญ
- พิจารณาแนวทางที่ใช้ตัวปรับแต่งสำหรับสถานการณ์ที่มีหลายงาน

### การจัดการทรัพยากร

**1. การปรับแต่งฮาร์ดแวร์**
- เลือกฮาร์ดแวร์ที่เหมาะสมกับขนาดโมเดลและวิธีการ
- ใช้หน่วยความจำ GPU อย่างมีประสิทธิภาพด้วยการตรวจสอบจุดเกรเดียนต์
- พิจารณาโซลูชันบนคลาวด์สำหรับโมเดลขนาดใหญ่

**2. การจัดการหน่วยความจำ**
- ใช้การฝึกแบบความแม่นยำผสมเมื่อเป็นไปได้
- ใช้การสะสมเกรเดียนต์สำหรับข้อจำกัดด้านหน่วยความจำ
- ติดตามการใช้งานหน่วยความจำ GPU ตลอดการฝึก

## เทคนิคขั้นสูง

### การฝึกตัวปรับแต่งหลายตัว

ฝึกตัวปรับแต่งหลายตัวสำหรับงานต่าง ๆ ในขณะที่ใช้โมเดลพื้นฐานร่วมกัน:

```bash
# Train multiple LoRA adapters
olive finetune --method lora --task_name "classification" --output_path adapters/classifier
olive finetune --method lora --task_name "generation" --output_path adapters/generator

# Generate multi-adapter ONNX model
olive generate-adapter \
  --base_model_path models/base \
  --adapter_paths adapters/classifier,adapters/generator \
  --output_path models/multi-adapter
```

### การปรับแต่งไฮเปอร์พารามิเตอร์

ดำเนินการปรับแต่งไฮเปอร์พารามิเตอร์อย่างเป็นระบบ:

```yaml
# hyperparameter-search.yaml
search_strategy:
  type: "random"
  num_trials: 20

search_space:
  learning_rate:
    type: "float"
    low: 1e-6
    high: 1e-3
    log: true
  
  lora_r:
    type: "int"
    low: 8
    high: 64
  
  batch_size:
    type: "choice"
    values: [8, 16, 32]
```

### ฟังก์ชันการสูญเสียแบบกำหนดเอง

ใช้ฟังก์ชันการสูญเสียที่เฉพาะเจาะจงกับโดเมน:

```python
# custom_loss.py
import torch
import torch.nn as nn

class CustomContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(CustomContrastiveLoss, self).__init__()
        self.margin = margin
        
    def forward(self, output1, output2, label):
        euclidean_distance = nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))
        return loss_contrastive
```

## การประเมินผลและการติดตาม

### เมตริกและการประเมินผล

**1. เมตริกมาตรฐาน**
- **ความถูกต้อง**: ความถูกต้องโดยรวมสำหรับงานการจัดประเภท
- **Perplexity**: ตัววัดคุณภาพการสร้างภาษา
- **BLEU/ROUGE**: คุณภาพการสร้างข้อความและการสรุป
- **F1 Score**: ความสมดุลระหว่างความแม่นยำและการเรียกคืนสำหรับการจัดประเภท

**2. เมตริกเฉพาะโดเมน**
- **เกณฑ์มาตรฐานเฉพาะงาน**: ใช้เกณฑ์มาตรฐานที่ได้รับการยอมรับในโดเมนของคุณ
- **การประเมินโดยมนุษย์**: รวมการประเมินโดยมนุษย์สำหรับงานที่ต้องใช้วิจารณญาณ
- **เมตริกทางธุรกิจ**: สอดคล้องกับวัตถุประสงค์ทางธุรกิจจริง

**3. การตั้งค่าการประเมินผล**

```python
# evaluation_script.py
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import torch

def evaluate_model(model_path, test_dataset, metric_type="accuracy"):
    """
    Evaluate fine-tuned model performance
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)
    
    # Evaluation logic here
    results = {}
    
    for example in test_dataset:
        # Process example and calculate metrics
        pass
    
    return results
```

### การติดตามความคืบหน้าการฝึก

**1. การติดตามการสูญเสีย**
```bash
# Enable detailed logging
olive finetune \
  --logging_steps 10 \
  --eval_steps 50 \
  --save_steps 100 \
  --logging_dir ./logs \
  --report_to tensorboard
```

**2. การติดตามการตรวจสอบ**
- ติดตามการสูญเสียการตรวจสอบควบคู่ไปกับการสูญเสียการฝึก
- ติดตามสัญญาณของการฝึกมากเกินไป (การสูญเสียการตรวจสอบเพิ่มขึ้นในขณะที่การสูญเสียการฝึกลดลง)
- ใช้การหยุดก่อนตามเมตริกการตรวจสอบ

**3. การติดตามทรัพยากร**
- ติดตามการใช้งาน GPU/CPU
- ติดตามรูปแบบการใช้งานหน่วยความจำ
- ติดตามความเร็วและปริมาณงานการฝึก

## ความท้าทายทั่วไปและวิธีแก้ไข

### ความท้าทาย 1: การฝึกมากเกินไป

**อาการ:**
- การสูญเสียการฝึกยังคงลดลงในขณะที่การสูญเสียการตรวจสอบเพิ่มขึ้น
- ช่องว่างขนาดใหญ่ระหว่างประสิทธิภาพการฝึกและการตรวจสอบ
- การทั่วไปที่ไม่ดีต่อข้อมูลใหม่

**วิธีแก้ไข:**
```yaml
# Regularization techniques
passes:
  lora:
    type: LoRA
    config:
      r: 16  # Reduce rank to prevent overfitting
      lora_alpha: 16  # Lower alpha value
      lora_dropout: 0.1  # Add dropout
      weight_decay: 0.01  # L2 regularization
```

### ความท้าทาย 2: ข้อจำกัดด้านหน่วยความจำ

**วิธีแก้ไข:**
- ใช้การตรวจสอบจุดเกรเดียนต์
- ใช้การสะสมเกรเดียนต์
- เลือกวิธีการที่มีประสิทธิภาพด้านพารามิเตอร์ (LoRA, QLoRA)
- ใช้การขนานโมเดลสำหรับโมเดลขนาดใหญ่

```bash
# Memory-efficient training
olive finetune \
  --method qlora \
  --gradient_checkpointing true \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16
```

### ความท้าทาย 3: การฝึกช้า

**วิธีแก้ไข:**
- ปรับปรุงกระบวนการโหลดข้อมูล
- ใช้การฝึกแบบความแม่นยำผสม
- ใช้กลยุทธ์การจัดแบตช์ที่มีประสิทธิภาพ
- พิจารณาการฝึกแบบกระจายสำหรับชุดข้อมูลขนาดใหญ่

```yaml
# Performance optimization
training_config:
  fp16: true  # Mixed precision
  dataloader_num_workers: 4
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
```

### ความท้าทาย 4: ประสิทธิ

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลโดยอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษาจากผู้เชี่ยวชาญ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้