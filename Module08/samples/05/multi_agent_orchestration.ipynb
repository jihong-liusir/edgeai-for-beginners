{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b861ae53",
   "metadata": {},
   "source": [
    "# Sample 05: Multi-Agent Orchestration System\n",
    "\n",
    "This notebook demonstrates a sophisticated multi-agent architecture for building AI-powered agent systems using Microsoft Foundry Local.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This sample implements a **multi-agent coordinator** that orchestrates specialized agents:\n",
    "\n",
    "- 🔍 **Retrieval Agent**: Extracts relevant information from knowledge sources\n",
    "- 🧠 **Reasoning Agent**: Performs step-by-step analysis and logical reasoning\n",
    "- ⚡ **Execution Agent**: Creates actionable plans in structured formats\n",
    "- 🎯 **Coordinator**: Orchestrates the entire agent workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840290d",
   "metadata": {},
   "source": [
    "## Architecture Pattern\n",
    "\n",
    "```\n",
    "User Goal → Coordinator\n",
    "     ↓\n",
    "1. Retrieval Agent → Context\n",
    "     ↓\n",
    "2. Reasoning Agent → Decision\n",
    "     ↓\n",
    "3. Execution Agent → Actions\n",
    "     ↓\n",
    "Structured Result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240650a",
   "metadata": {},
   "source": [
    "## Prerequisites and Setup\n",
    "\n",
    "Make sure you have Foundry Local running with a capable model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai foundry-local-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fe9e",
   "metadata": {},
   "source": [
    "## Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    from foundry_local import FoundryLocalManager\n",
    "    FOUNDRY_SDK_AVAILABLE = True\n",
    "    print(\"✅ Foundry Local SDK is available\")\n",
    "except ImportError:\n",
    "    FOUNDRY_SDK_AVAILABLE = False\n",
    "    print(\"⚠️ Foundry Local SDK not available, will use manual configuration\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_ALIAS = \"phi-4-mini\"  # Change to your preferred model\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a90f",
   "metadata": {},
   "source": [
    "## Foundry Client Setup\n",
    "\n",
    "Create a shared client for all agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc80453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryClient:\n",
    "    \"\"\"Shared client for all specialist agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = MODEL_ALIAS):\n",
    "        self.client = None\n",
    "        self.model_name = None\n",
    "        self.model_alias = model_alias\n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize OpenAI client with Foundry Local or fallback configuration.\"\"\"\n",
    "        if FOUNDRY_SDK_AVAILABLE:\n",
    "            try:\n",
    "                print(f\"🔄 Initializing Foundry Local with model: {self.model_alias}...\")\n",
    "                manager = FoundryLocalManager(self.model_alias)\n",
    "                model_info = manager.get_model_info(self.model_alias)\n",
    "                \n",
    "                self.client = OpenAI(\n",
    "                    base_url=manager.endpoint,\n",
    "                    api_key=manager.api_key\n",
    "                )\n",
    "                self.model_name = model_info.id\n",
    "                print(f\"✅ Foundry Local SDK initialized with model: {self.model_name}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not use Foundry SDK ({e}), falling back to manual configuration\")\n",
    "        \n",
    "        # Fallback to manual configuration\n",
    "        self.client = OpenAI(\n",
    "            base_url=f\"{BASE_URL}/v1\",\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        self.model_name = self.model_alias\n",
    "        print(f\"🔧 Manual configuration initialized with model: {self.model_name}\")\n",
    "    \n",
    "    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:\n",
    "        \"\"\"Send chat completion request to the model.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def check_health(self) -> bool:\n",
    "        \"\"\"Check if the client is working properly.\"\"\"\n",
    "        try:\n",
    "            test_response = self.chat(\n",
    "                [{\"role\": \"user\", \"content\": \"Say 'OK'\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return \"OK\" in test_response and \"Error\" not in test_response\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Initialize the shared client\n",
    "print(\"Initializing Foundry Client...\")\n",
    "foundry_client = FoundryClient()\n",
    "\n",
    "# Health check\n",
    "if foundry_client.check_health():\n",
    "    print(\"✅ Client health check passed!\")\n",
    "else:\n",
    "    print(\"❌ Client health check failed. Please ensure Foundry Local is running with a model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e6e2b",
   "metadata": {},
   "source": [
    "## Specialized Agent Classes\n",
    "\n",
    "Each agent is optimized for specific cognitive tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAgent:\n",
    "    \"\"\"Agent specialized in retrieving relevant information from knowledge sources.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized retrieval agent. Your job is to extract and retrieve \n",
    "    the most relevant information from knowledge sources based on a given query. Focus on key facts, \n",
    "    data points, and contextual information that would be useful for decision-making.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant information based on the query.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Query: {query}\n",
    "\n",
    "Retrieve the most relevant key facts, data points, and contextual information that would \n",
    "help answer this query or support decision-making around it. Provide specific, actionable \n",
    "information rather than general statements.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages)\n",
    "\n",
    "\n",
    "class ReasoningAgent:\n",
    "    \"\"\"Agent specialized in step-by-step analysis and reasoning.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized reasoning agent. Your job is to analyze inputs \n",
    "    step-by-step and produce structured, logical conclusions. Break down complex problems \n",
    "    into manageable parts and provide clear reasoning for your conclusions.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, context: str, question: str) -> str:\n",
    "        \"\"\"Analyze context and question to produce structured conclusions.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Analyze this step-by-step and provide a structured, logical conclusion with clear reasoning. \n",
    "Break down the problem, consider different angles, and provide a well-reasoned decision or recommendation.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400)\n",
    "\n",
    "\n",
    "class ExecutionAgent:\n",
    "    \"\"\"Agent specialized in creating actionable execution plans.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized execution agent. Your job is to transform decisions \n",
    "    and conclusions into concrete, actionable steps. Always format your response as valid JSON \n",
    "    with an array of action items. Each action should be specific, measurable, and achievable.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, decision: str) -> str:\n",
    "        \"\"\"Transform decision into actionable steps in JSON format.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Decision/Conclusion:\n",
    "{decision}\n",
    "\n",
    "Create 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n",
    "{{\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"description\": \"Specific action description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"timeline\": \"timeframe for completion\",\n",
    "      \"resources\": [\"required resources or people\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400, temperature=0.3)\n",
    "\n",
    "print(\"✅ Agent classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6288d",
   "metadata": {},
   "source": [
    "## Multi-Agent Coordinator\n",
    "\n",
    "The coordinator orchestrates all agents to handle complex tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    \"\"\"Multi-agent coordinator that orchestrates specialist agents to handle complex tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        \"\"\"Initialize the coordinator with specialist agents.\"\"\"\n",
    "        self.client = client\n",
    "        self.retrieval = RetrievalAgent(client)\n",
    "        self.reasoning = ReasoningAgent(client)\n",
    "        self.execution = ExecutionAgent(client)\n",
    "    \n",
    "    def handle(self, user_goal: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Orchestrate multiple agents to handle a complex user goal.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the goal, context, decision, and actions\n",
    "        \"\"\"\n",
    "        print(f\"🎯 **Coordinator:** Processing goal: {user_goal}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Retrieve relevant context\n",
    "        print(\"📚 **Step 1:** Retrieving context...\")\n",
    "        context = self.retrieval.run(user_goal)\n",
    "        print(f\"   ✅ Context retrieved ({len(context)} chars)\")\n",
    "        print(f\"   📄 Preview: {context[:150]}...\\n\")\n",
    "        \n",
    "        # Step 2: Analyze and reason about the context\n",
    "        print(\"🧠 **Step 2:** Analyzing and reasoning...\")\n",
    "        decision = self.reasoning.run(context, user_goal)\n",
    "        print(f\"   ✅ Analysis completed ({len(decision)} chars)\")\n",
    "        print(f\"   💡 Preview: {decision[:150]}...\\n\")\n",
    "        \n",
    "        # Step 3: Create actionable execution plan\n",
    "        print(\"⚡ **Step 3:** Creating execution plan...\")\n",
    "        actions = self.execution.run(decision)\n",
    "        print(f\"   ✅ Execution plan created ({len(actions)} chars)\")\n",
    "        \n",
    "        # Try to parse actions as JSON for preview\n",
    "        try:\n",
    "            actions_json = json.loads(actions)\n",
    "            action_count = len(actions_json.get('actions', []))\n",
    "            print(f\"   📋 Actions planned: {action_count}\\n\")\n",
    "        except:\n",
    "            print(f\"   📋 Actions: {actions[:100]}...\\n\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"goal\": user_goal,\n",
    "            \"context\": context,\n",
    "            \"decision\": decision,\n",
    "            \"actions\": actions,\n",
    "            \"agent_flow\": [\"retrieval\", \"reasoning\", \"execution\"],\n",
    "            \"processing_time\": processing_time,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ **Coordination Complete** (⏱️ {processing_time:.2f}s)\")\n",
    "        return result\n",
    "    \n",
    "    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle a goal with multiple feedback rounds for refinement.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            feedback_rounds: Number of feedback rounds to perform\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the refined result\n",
    "        \"\"\"\n",
    "        result = self.handle(user_goal)\n",
    "        \n",
    "        for round_num in range(feedback_rounds):\n",
    "            print(f\"\\n🔄 **Feedback Round {round_num + 1}:**\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Use reasoning agent to refine the execution plan\n",
    "            refinement_prompt = f\"\"\"\n",
    "            Original Goal: {user_goal}\n",
    "            Current Decision: {result['decision']}\n",
    "            Current Actions: {result['actions']}\n",
    "            \n",
    "            Review the above and suggest improvements or refinements to make the execution plan more effective.\n",
    "            Consider potential challenges, resource optimization, and success metrics.\n",
    "            \"\"\"\n",
    "            \n",
    "            refined_decision = self.reasoning.run(result['context'], refinement_prompt)\n",
    "            refined_actions = self.execution.run(refined_decision)\n",
    "            \n",
    "            result['decision'] = refined_decision\n",
    "            result['actions'] = refined_actions\n",
    "            result['refinement_rounds'] = round_num + 1\n",
    "            \n",
    "            print(f\"   ✅ Round {round_num + 1} refinement completed\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize coordinator\n",
    "coordinator = Coordinator(foundry_client)\n",
    "print(\"✅ Multi-agent coordinator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97499608",
   "metadata": {},
   "source": [
    "## Example 1: Business Planning\n",
    "\n",
    "Let's test the coordinator with a business planning goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business planning example\n",
    "business_goal = \"Create a plan to onboard 5 new customers this month\"\n",
    "\n",
    "print(f\"🚀 **Business Planning Example**\")\n",
    "print(f\"📋 Goal: {business_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "business_result = coordinator.handle(business_goal)\n",
    "\n",
    "print(\"\\n📊 **Final Result Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🎯 **Goal:** {business_result['goal']}\")\n",
    "print(f\"⏱️ **Processing Time:** {business_result['processing_time']:.2f} seconds\")\n",
    "print(f\"🕒 **Timestamp:** {business_result['timestamp']}\")\n",
    "\n",
    "print(f\"\\n📚 **Context (Retrieval Agent):**\")\n",
    "print(business_result['context'])\n",
    "\n",
    "print(f\"\\n🧠 **Decision (Reasoning Agent):**\")\n",
    "print(business_result['decision'])\n",
    "\n",
    "print(f\"\\n⚡ **Actions (Execution Agent):**\")\n",
    "print(business_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1159c3",
   "metadata": {},
   "source": [
    "## Example 2: Strategy Development\n",
    "\n",
    "Test with a more complex strategy development goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy development example\n",
    "strategy_goal = \"Develop a strategy to improve team productivity by 20% while maintaining work-life balance\"\n",
    "\n",
    "print(f\"🎯 **Strategy Development Example**\")\n",
    "print(f\"📋 Goal: {strategy_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "strategy_result = coordinator.handle(strategy_goal)\n",
    "\n",
    "print(\"\\n📊 **Structured Action Plan:**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try to parse and display actions in a structured format\n",
    "try:\n",
    "    actions_data = json.loads(strategy_result['actions'])\n",
    "    if 'actions' in actions_data:\n",
    "        for i, action in enumerate(actions_data['actions'], 1):\n",
    "            print(f\"\\n📌 **Action {i}:**\")\n",
    "            print(f\"   📝 Description: {action.get('description', 'N/A')}\")\n",
    "            print(f\"   🔥 Priority: {action.get('priority', 'N/A')}\")\n",
    "            print(f\"   ⏰ Timeline: {action.get('timeline', 'N/A')}\")\n",
    "            print(f\"   🛠️ Resources: {', '.join(action.get('resources', ['N/A']))}\")\n",
    "    else:\n",
    "        print(strategy_result['actions'])\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Raw actions output:\")\n",
    "    print(strategy_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b319",
   "metadata": {},
   "source": [
    "## Example 3: Feedback Loop Refinement\n",
    "\n",
    "Demonstrate the feedback mechanism for iterative improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedback loop example\n",
    "feedback_goal = \"Design a customer feedback collection system for a software product\"\n",
    "\n",
    "print(f\"🔄 **Feedback Loop Refinement Example**\")\n",
    "print(f\"📋 Goal: {feedback_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process with 2 feedback rounds\n",
    "feedback_result = coordinator.handle_with_feedback(feedback_goal, feedback_rounds=2)\n",
    "\n",
    "print(\"\\n🏆 **Final Refined Result:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🎯 **Goal:** {feedback_result['goal']}\")\n",
    "print(f\"🔄 **Refinement Rounds:** {feedback_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"⏱️ **Total Processing Time:** {feedback_result['processing_time']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\n🧠 **Final Decision:**\")\n",
    "print(feedback_result['decision'])\n",
    "\n",
    "print(f\"\\n⚡ **Final Action Plan:**\")\n",
    "print(feedback_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed152f7",
   "metadata": {},
   "source": [
    "## Interactive Agent Testing\n",
    "\n",
    "Test individual agents separately to understand their specialized capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_individual_agents(query: str):\n",
    "    \"\"\"Test each agent individually with the same query.\"\"\"\n",
    "    print(f\"🧪 **Individual Agent Testing**\")\n",
    "    print(f\"❓ Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test Retrieval Agent\n",
    "    print(\"\\n🔍 **Retrieval Agent:**\")\n",
    "    retrieval_result = coordinator.retrieval.run(query)\n",
    "    print(retrieval_result)\n",
    "    \n",
    "    # Test Reasoning Agent (using retrieval result as context)\n",
    "    print(\"\\n🧠 **Reasoning Agent:**\")\n",
    "    reasoning_result = coordinator.reasoning.run(retrieval_result, query)\n",
    "    print(reasoning_result)\n",
    "    \n",
    "    # Test Execution Agent (using reasoning result)\n",
    "    print(\"\\n⚡ **Execution Agent:**\")\n",
    "    execution_result = coordinator.execution.run(reasoning_result)\n",
    "    print(execution_result)\n",
    "\n",
    "# Test with a simple query\n",
    "test_query = \"How can we reduce customer support response time?\"\n",
    "test_individual_agents(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb3f9c",
   "metadata": {},
   "source": [
    "## Custom Goal Testing\n",
    "\n",
    "Use this cell to test your own goals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom goal testing - modify the goal below\n",
    "custom_goal = \"Create a training program for new AI engineers joining our company\"\n",
    "\n",
    "print(f\"🎨 **Custom Goal Testing**\")\n",
    "print(f\"📋 Your Goal: {custom_goal}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose processing method\n",
    "use_feedback = True  # Set to True for feedback rounds, False for basic processing\n",
    "feedback_rounds = 1  # Number of feedback rounds if use_feedback is True\n",
    "\n",
    "if use_feedback:\n",
    "    custom_result = coordinator.handle_with_feedback(custom_goal, feedback_rounds=feedback_rounds)\n",
    "    print(f\"\\n✨ **Result with {feedback_rounds} feedback round(s):**\")\n",
    "else:\n",
    "    custom_result = coordinator.handle(custom_goal)\n",
    "    print(f\"\\n✨ **Basic Result:**\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"📚 **Context:** {custom_result['context'][:200]}...\")\n",
    "print(f\"\\n🧠 **Decision:** {custom_result['decision'][:200]}...\")\n",
    "print(f\"\\n⚡ **Actions:** {custom_result['actions'][:200]}...\")\n",
    "\n",
    "# Show processing stats\n",
    "print(f\"\\n📊 **Statistics:**\")\n",
    "print(f\"   ⏱️ Processing Time: {custom_result['processing_time']:.2f}s\")\n",
    "print(f\"   🔄 Refinement Rounds: {custom_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"   📏 Total Content Length: {len(custom_result['context']) + len(custom_result['decision']) + len(custom_result['actions'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d1c2",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Analyze the performance of the multi-agent system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_benchmark(goals: List[str], iterations: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"Benchmark the coordinator performance with multiple goals.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"📊 **Performance Benchmark**\")\n",
    "    print(f\"🎯 Goals: {len(goals)}\")\n",
    "    print(f\"🔄 Iterations per goal: {iterations}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, goal in enumerate(goals, 1):\n",
    "        print(f\"\\n🎯 **Goal {i}:** {goal[:50]}...\")\n",
    "        goal_times = []\n",
    "        \n",
    "        for j in range(iterations):\n",
    "            print(f\"   🔄 Iteration {j+1}/{iterations}...\", end=\" \")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = coordinator.handle(goal)\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                goal_times.append(processing_time)\n",
    "                print(f\"✅ {processing_time:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error: {e}\")\n",
    "        \n",
    "        if goal_times:\n",
    "            avg_time = sum(goal_times) / len(goal_times)\n",
    "            results.append({\n",
    "                \"goal\": goal,\n",
    "                \"avg_time\": avg_time,\n",
    "                \"min_time\": min(goal_times),\n",
    "                \"max_time\": max(goal_times),\n",
    "                \"times\": goal_times\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark with different types of goals\n",
    "benchmark_goals = [\n",
    "    \"Create a social media marketing strategy\",\n",
    "    \"Improve employee onboarding process\",\n",
    "    \"Design a mobile app user interface\",\n",
    "    \"Plan a product launch campaign\"\n",
    "]\n",
    "\n",
    "benchmark_results = performance_benchmark(benchmark_goals, iterations=2)\n",
    "\n",
    "# Display benchmark summary\n",
    "print(\"\\n🏆 **Benchmark Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "for result in benchmark_results:\n",
    "    print(f\"📝 {result['goal'][:40]}...\")\n",
    "    print(f\"   ⏱️ Average: {result['avg_time']:.2f}s\")\n",
    "    print(f\"   ⚡ Fastest: {result['min_time']:.2f}s\")\n",
    "    print(f\"   🐌 Slowest: {result['max_time']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "if benchmark_results:\n",
    "    overall_avg = sum(r['avg_time'] for r in benchmark_results) / len(benchmark_results)\n",
    "    print(f\"📊 **Overall Average Processing Time:** {overall_avg:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cca35",
   "metadata": {},
   "source": [
    "## Production Deployment Helper\n",
    "\n",
    "Example of how to wrap the coordinator for production use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionCoordinator:\n",
    "    \"\"\"Production-ready wrapper for the multi-agent coordinator.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = \"phi-4-mini\"):\n",
    "        self.client = FoundryClient(model_alias)\n",
    "        self.coordinator = Coordinator(self.client)\n",
    "        self.request_count = 0\n",
    "        self.total_processing_time = 0\n",
    "    \n",
    "    def process_goal(self, goal: str, include_feedback: bool = False, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Process a goal with production monitoring.\"\"\"\n",
    "        self.request_count += 1\n",
    "        \n",
    "        try:\n",
    "            if include_feedback:\n",
    "                result = self.coordinator.handle_with_feedback(goal, feedback_rounds=feedback_rounds)\n",
    "            else:\n",
    "                result = self.coordinator.handle(goal)\n",
    "            \n",
    "            self.total_processing_time += result['processing_time']\n",
    "            \n",
    "            # Add production metadata\n",
    "            result['request_id'] = self.request_count\n",
    "            result['status'] = 'success'\n",
    "            result['model'] = self.client.model_name\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'request_id': self.request_count,\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'goal': goal,\n",
    "                'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get production statistics.\"\"\"\n",
    "        avg_processing_time = self.total_processing_time / max(1, self.request_count)\n",
    "        \n",
    "        return {\n",
    "            'total_requests': self.request_count,\n",
    "            'total_processing_time': self.total_processing_time,\n",
    "            'average_processing_time': avg_processing_time,\n",
    "            'model': self.client.model_name,\n",
    "            'client_healthy': self.client.check_health()\n",
    "        }\n",
    "\n",
    "# Example production usage\n",
    "prod_coordinator = ProductionCoordinator()\n",
    "\n",
    "# Process a goal\n",
    "prod_goal = \"Create a quarterly business review presentation\"\n",
    "prod_result = prod_coordinator.process_goal(prod_goal)\n",
    "\n",
    "print(f\"🏭 **Production Processing Result:**\")\n",
    "print(f\"📊 Status: {prod_result['status']}\")\n",
    "print(f\"🔢 Request ID: {prod_result['request_id']}\")\n",
    "print(f\"⏱️ Processing Time: {prod_result.get('processing_time', 'N/A')}s\")\n",
    "print(f\"🤖 Model: {prod_result.get('model', 'N/A')}\")\n",
    "\n",
    "# Show production stats\n",
    "stats = prod_coordinator.get_stats()\n",
    "print(f\"\\n📊 **Production Statistics:**\")\n",
    "print(f\"   📈 Total Requests: {stats['total_requests']}\")\n",
    "print(f\"   ⏱️ Average Processing Time: {stats['average_processing_time']:.2f}s\")\n",
    "print(f\"   💚 Client Health: {'✅ Healthy' if stats['client_healthy'] else '❌ Unhealthy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d3849",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This notebook demonstrated a sophisticated multi-agent orchestration system:\n",
    "\n",
    "### ✅ Key Features Demonstrated\n",
    "\n",
    "1. **🏗️ Agent Specialization**: Each agent optimized for specific cognitive tasks\n",
    "2. **🎯 Workflow Orchestration**: Coordinated multi-step processing\n",
    "3. **📋 Structured Output**: JSON-formatted action plans\n",
    "4. **🔄 Feedback Loops**: Multi-round refinement capabilities\n",
    "5. **⚡ Performance Monitoring**: Processing time and health checks\n",
    "6. **🏭 Production Ready**: Enterprise-grade wrapper with monitoring\n",
    "\n",
    "### 🧠 Agent Roles Summary\n",
    "\n",
    "| Agent | Purpose | Input | Output |\n",
    "|-------|---------|-------|--------|\n",
    "| **🔍 Retrieval** | Extract relevant information | User query | Contextual facts and data |\n",
    "| **🧠 Reasoning** | Logical analysis | Context + question | Structured decision |\n",
    "| **⚡ Execution** | Create action plans | Decision | JSON action steps |\n",
    "| **🎯 Coordinator** | Orchestrate workflow | User goal | Complete result |\n",
    "\n",
    "### 🚀 Use Cases\n",
    "\n",
    "- **Business Planning**: Strategic planning and execution\n",
    "- **Project Management**: Task decomposition and scheduling  \n",
    "- **Research**: Information gathering and analysis\n",
    "- **Decision Support**: Complex decision-making processes\n",
    "- **Workflow Automation**: Multi-step business processes\n",
    "\n",
    "### 💡 Best Practices\n",
    "\n",
    "1. **🎯 Single Responsibility**: Each agent has one clear purpose\n",
    "2. **🔗 Clear Interfaces**: Standardized input/output formats\n",
    "3. **🛡️ Error Handling**: Graceful degradation on failures\n",
    "4. **📊 Monitoring**: Comprehensive logging and performance tracking\n",
    "5. **🔄 Feedback Loops**: Iterative improvement mechanisms\n",
    "6. **⚖️ Load Balancing**: Consider parallel processing for independent tasks\n",
    "\n",
    "### 🔮 Next Steps\n",
    "\n",
    "- **🔧 Function Calling**: Integrate with external APIs and tools\n",
    "- **🧠 Memory Systems**: Add persistent memory for agents\n",
    "- **🎭 Specialized Models**: Use different models for different agents\n",
    "- **👥 Human-in-the-Loop**: Add human review and approval steps\n",
    "- **📊 Advanced Analytics**: Comprehensive monitoring and metrics\n",
    "\n",
    "This multi-agent system demonstrates how to build sophisticated AI workflows that combine the strengths of specialized agents while maintaining the privacy and performance benefits of local inference with Microsoft Foundry Local."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
